{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este notebook y todos los que tienen un nombre similar a este son prácticamente iguales. Su contenido también es muy similar al del notebook \"IBM_MSE\", la principal diferencia es que en esta serie de notebooks, en lugar de utilizar una secuencia temporal diaria, utilizo una secuencia temporal en la que los días van de 2 en 2, de 3 en 3...\n",
    "\n",
    "El objetivo es tener diferentes modelos que puedan hacer predicciones en este orden (el de \"IBM_MSE\" hará las predicciones para hoy, el de 2 días las hará para mañana, el de 3 para pasado mañana, etc.)\n",
    "\n",
    "Veremos como según vamos aumentando el tamaño de los saltos en el tiempo, los modelos empiezan a ser cada vez más imprecisos. El objetivo no es conseguir predicciones exactas, ya que creo que se trata de una tarea imposible, sino que al final lo que busco con estos modelos es tener un conjunto de predicciones que me puedan, en cierto modo y de forma conjunta, \"asegurar\" que los valores van a seguir una cierta tendencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from joblib import load\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 5\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(len(data) * train_size)\n",
    "\n",
    "train = data.to_numpy()[:split]\n",
    "test = data.to_numpy()[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalisers\n",
    "normaliser = load('./normalisers/x_normaliser.joblib')\n",
    "y_normaliser = load('./normalisers/y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "train_norm = normaliser.transform(train)\n",
    "test_norm = normaliser.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now I get indexes for chunks from 5 in 5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(train),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_train = np.array([train_norm[ix].copy() for ix in ordered_index])\n",
    "Y_train = np.array([train_norm[ordered_index[i+days][-1],3].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_train = np.expand_dims(Y_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_train = X_train[:Y_train.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(test),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_test = np.array([test_norm[ix].copy() for ix in ordered_index])\n",
    "Y_test = np.array([test_norm[ordered_index[i+days][-1],3].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_test = np.expand_dims(Y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_test = X_test[:Y_test.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0628 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0111 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0046 - val_loss: 0.0073\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 154us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 164us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 163us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 158us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 161us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 156us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 157us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 155us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 155us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 151us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 155us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 150us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 178us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 154us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 155us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 1s 254us/step - loss: 0.1382 - val_loss: 0.0576\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0155 - val_loss: 0.0229\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0101 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 163us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 164us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 163us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 163us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 163us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 164us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 164us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 164us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 164us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 164us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 163us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 164us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 164us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 1s 289us/step - loss: 0.0684 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0187 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0051 - val_loss: 0.0074\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 9.8560e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 9.6564e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 9.5307e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 165us/step - loss: 9.3630e-04 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.1551 - val_loss: 0.0744\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0644 - val_loss: 0.0385\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0556 - val_loss: 0.0279\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0515 - val_loss: 0.0252\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0482 - val_loss: 0.0228\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0451 - val_loss: 0.0214\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0420 - val_loss: 0.0201\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0390 - val_loss: 0.0185\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0360 - val_loss: 0.0173\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0330 - val_loss: 0.0161\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0300 - val_loss: 0.0147\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0271 - val_loss: 0.0135\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0242 - val_loss: 0.0119\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0215 - val_loss: 0.0103\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0190 - val_loss: 0.0087\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0167 - val_loss: 0.0077\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0147 - val_loss: 0.0064\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0129 - val_loss: 0.0054\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0114 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0102 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0091 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0083 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0076 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0071 - val_loss: 0.0034\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0736 - val_loss: 0.0332\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0356 - val_loss: 0.0178\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0302 - val_loss: 0.0137\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0263 - val_loss: 0.0115\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0229 - val_loss: 0.0096\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0198 - val_loss: 0.0083\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0170 - val_loss: 0.0071\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0146 - val_loss: 0.0060\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0125 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0108 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0094 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0082 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0073 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0065 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0055 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 0.2818 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0190 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 408us/step - loss: 0.0117 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0102 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0092 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0086 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 411us/step - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0078 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0080 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0076 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0072 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0065 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0065 - val_loss: 0.0040\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 410us/step - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 410us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 408us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0058 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 696us/step - loss: 0.1256 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0082 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 464us/step - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 463us/step - loss: 0.0063 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 463us/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 462us/step - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 462us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 463us/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 464us/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 467us/step - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 464us/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 462us/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 462us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 463us/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 464us/step - loss: 0.0045 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0045 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 463us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 764us/step - loss: 0.7150 - val_loss: 0.0400\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0626 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0684 - val_loss: 0.0287\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0484 - val_loss: 0.0133\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0206 - val_loss: 0.1731\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0379 - val_loss: 0.0119\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0069 - val_loss: 0.0121\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0059 - val_loss: 0.0088\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0082 - val_loss: 0.0082\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0100 - val_loss: 0.0060\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0036 - val_loss: 0.0059\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0037 - val_loss: 0.0077\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 782us/step - loss: 0.9972 - val_loss: 0.0114\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0383 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0068 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0030 - val_loss: 0.0063\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 666us/step - loss: 0.2281 - val_loss: 0.0169\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0134 - val_loss: 0.0057\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0056 - val_loss: 0.0118\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0024 - val_loss: 0.0060\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 2s 420us/step - loss: 0.0859 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0128 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0029 - val_loss: 0.0198\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0109 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0021 - val_loss: 0.0055\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0023 - val_loss: 0.0086\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0022 - val_loss: 0.0076\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0022 - val_loss: 0.0056\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0022 - val_loss: 0.0069\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0037 - val_loss: 0.0079\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 165us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0018 - val_loss: 0.0066\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0030 - val_loss: 0.0093\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0917 - val_loss: 0.0188\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0190 - val_loss: 0.0112\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0080 - val_loss: 0.0107\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 150us/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 151us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 151us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 151us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 154us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 157us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 151us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 151us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 0.0832 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0264 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 306us/step - loss: 0.0124 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 308us/step - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0050 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 310us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 305us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 305us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 314us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 305us/step - loss: 0.0016 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 304us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 306us/step - loss: 0.0015 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 306us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 304us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 306us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 309us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 305us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 306us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 306us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 308us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 661us/step - loss: 0.0837 - val_loss: 0.0434\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0216 - val_loss: 0.0087\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 306us/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0066 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 310us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 316us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 306us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 306us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 306us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 308us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 308us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 310us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 308us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 308us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 308us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 315us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 309us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 307us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 666us/step - loss: 0.1546 - val_loss: 0.0367\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 319us/step - loss: 0.0732 - val_loss: 0.0279\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 321us/step - loss: 0.0625 - val_loss: 0.0237\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 319us/step - loss: 0.0552 - val_loss: 0.0192\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 321us/step - loss: 0.0474 - val_loss: 0.0167\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 325us/step - loss: 0.0401 - val_loss: 0.0146\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 319us/step - loss: 0.0339 - val_loss: 0.0110\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 321us/step - loss: 0.0281 - val_loss: 0.0080\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0231 - val_loss: 0.0064\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 326us/step - loss: 0.0191 - val_loss: 0.0048\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0158 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 319us/step - loss: 0.0128 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 319us/step - loss: 0.0111 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 319us/step - loss: 0.0100 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 318us/step - loss: 0.0092 - val_loss: 0.0042\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0085 - val_loss: 0.0046\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 319us/step - loss: 0.0079 - val_loss: 0.0055\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 323us/step - loss: 0.0077 - val_loss: 0.0061\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0076 - val_loss: 0.0061\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 318us/step - loss: 0.0074 - val_loss: 0.0063\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 319us/step - loss: 0.0074 - val_loss: 0.0064\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0074 - val_loss: 0.0068\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 319us/step - loss: 0.0074 - val_loss: 0.0065\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 874us/step - loss: 0.2473 - val_loss: 0.2919\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.1805 - val_loss: 0.2165\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.1386 - val_loss: 0.1647\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.1118 - val_loss: 0.1274\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0941 - val_loss: 0.1013\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0828 - val_loss: 0.0825\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0756 - val_loss: 0.0688\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0708 - val_loss: 0.0588\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0678 - val_loss: 0.0512\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0656 - val_loss: 0.0459\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0642 - val_loss: 0.0418\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0632 - val_loss: 0.0388\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0624 - val_loss: 0.0363\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0617 - val_loss: 0.0343\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0611 - val_loss: 0.0330\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0607 - val_loss: 0.0320\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0602 - val_loss: 0.0312\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0597 - val_loss: 0.0302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0593 - val_loss: 0.0293\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0588 - val_loss: 0.0284\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0582 - val_loss: 0.0279\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0578 - val_loss: 0.0275\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0574 - val_loss: 0.0271\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0567 - val_loss: 0.0268\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 879us/step - loss: 0.2378 - val_loss: 0.2725\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.1581 - val_loss: 0.1694\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.1078 - val_loss: 0.1045\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0794 - val_loss: 0.0674\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0633 - val_loss: 0.0438\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0555 - val_loss: 0.0308\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0505 - val_loss: 0.0235\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0469 - val_loss: 0.0189\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0446 - val_loss: 0.0160\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0415 - val_loss: 0.0139\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0393 - val_loss: 0.0125\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0372 - val_loss: 0.0111\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0346 - val_loss: 0.0100\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0318 - val_loss: 0.0091\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0300 - val_loss: 0.0081\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0280 - val_loss: 0.0070\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0260 - val_loss: 0.0062\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0236 - val_loss: 0.0053\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0219 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0198 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0183 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0168 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0157 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0142 - val_loss: 0.0034\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 909us/step - loss: 0.0991 - val_loss: 0.0688\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0252 - val_loss: 0.0288\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0110 - val_loss: 0.0086\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0081 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0063 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0053 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 927us/step - loss: 0.2560 - val_loss: 0.2098\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0888 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0427 - val_loss: 0.0157\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0153 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0040 - val_loss: 0.0047\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0027 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0651 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0160 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0065 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0038 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 9.7615e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 9.6385e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 9.4216e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 9.3651e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 9.4535e-04 - val_loss: 9.4758e-04\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 9.2486e-04 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0739 - val_loss: 0.0077\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0200 - val_loss: 0.0075\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 154us/step - loss: 0.0059 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 154us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 152us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 154us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 155us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 157us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 154us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 153us/step - loss: 9.8935e-04 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 812us/step - loss: 0.1074 - val_loss: 0.0069\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 321us/step - loss: 0.0174 - val_loss: 0.0098\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 321us/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 322us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 322us/step - loss: 0.0040 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 323us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 322us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 321us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 321us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 321us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 321us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 323us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 326us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 322us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 320us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 321us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 0.2092 - val_loss: 0.0111\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0657 - val_loss: 0.0584\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0422 - val_loss: 0.0037\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 0.1190 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 0.0065 - val_loss: 0.0588\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0113 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0070 - val_loss: 0.0318\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0092 - val_loss: 0.0049\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 0.0034 - val_loss: 0.0075\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: 0.0052 - val_loss: 0.0111\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0061 - val_loss: 0.0067\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0044 - val_loss: 0.0059\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0034 - val_loss: 0.0098\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0036 - val_loss: 0.0063\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0041 - val_loss: 0.0175\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 243618058866497935798347759616.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 2942659789703475385883587860496384.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 8769859328225785454765036011520.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 166892817477101883273916299870208.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 3203104388697709165636965367808.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 878608988328389769073566679040.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 75103632748520444077516259328.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: 324008011970430040182653714432.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 601892582050887813959098826752.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 300533967670992899973415174144.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 895296754345878543409332636090368.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 620558141689772792002108404531200.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 11683326726566197012124766568448.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 6621520421251429299403565826048.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 29571461012494416381475337273344.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 927206506358846610648583897088.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 568617493367450147248115023872.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 3760381938216254635008556269568.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 1276472904476435337908292943872.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 286897334864811132638386454528.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 119273983490187111376938319478784.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 90533032457236900749928441053184.0000 - val_loss: 18993929176635253194752.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 674804902281010822451738705920.0000 - val_loss: 18993929176635253194752.0000\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 6303397200973189340850489917440.0000 - val_loss: 18993929176635253194752.0000\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 0.2547 - val_loss: 0.0173\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0320 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0170 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0068 - val_loss: 0.0157\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0049 - val_loss: 0.0078\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0032 - val_loss: 0.0075\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0043 - val_loss: 0.0082\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0037 - val_loss: 0.0055\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0032 - val_loss: 0.0068\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0029 - val_loss: 0.0052\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0037 - val_loss: 0.0107\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0033 - val_loss: 0.0071\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 745us/step - loss: 0.0461 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0068 - val_loss: 0.0113\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0077 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0106 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0077 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0073 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0051 - val_loss: 0.0063\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0085 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 166us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0053 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0056 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0029 - val_loss: 0.0064\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0075 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0047 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - ETA: 0s - loss: 0.004 - 1s 171us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 742us/step - loss: 0.1180 - val_loss: 0.0202\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0290 - val_loss: 0.0241\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0158 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0064 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0052 - val_loss: 0.0071\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 167us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 168us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 9.8962e-04 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 9.8647e-04 - val_loss: 0.0012\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 782us/step - loss: 0.0480 - val_loss: 0.0264\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0099 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0051 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0054 - val_loss: 0.0245\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0021 - val_loss: 0.0118\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0023 - val_loss: 0.0072\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0021 - val_loss: 0.0068\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0027 - val_loss: 0.0090\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0032 - val_loss: 0.0067\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0021 - val_loss: 0.0070\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0038 - val_loss: 0.0129\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0039 - val_loss: 0.0066\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0019 - val_loss: 0.0061\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 169us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0604 - val_loss: 0.0055\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0126 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0082 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0070 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0051 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0638 - val_loss: 0.9343\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.1005 - val_loss: 0.0352\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0078 - val_loss: 0.0064\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0026 - val_loss: 0.0058\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0048 - val_loss: 0.0124\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0023 - val_loss: 0.0060\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0026 - val_loss: 0.0074\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0033 - val_loss: 0.0061\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0577 - val_loss: 0.0067\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0151 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0072 - val_loss: 0.0108\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0093 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0082 - val_loss: 0.0239\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0130 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0019 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0040 - val_loss: 0.0107\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0684 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0152 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0103 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0069 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0044 - val_loss: 0.0072\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0277 - val_loss: 0.0226\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0104 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0070 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0027 - val_loss: 0.0080\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0031 - val_loss: 0.0083\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0029 - val_loss: 0.0064\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0031 - val_loss: 0.0092\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0026 - val_loss: 0.0102\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0038 - val_loss: 0.0053\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 1ms/step - loss: 0.3934 - val_loss: 0.0370\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0753 - val_loss: 0.0149\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0194 - val_loss: 0.1380\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0320 - val_loss: 0.0131\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0106 - val_loss: 0.0589\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0226 - val_loss: 0.0066\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0055 - val_loss: 0.0090\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0259 - val_loss: 0.0130\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0089 - val_loss: 0.0063\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0169 - val_loss: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0133 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0089 - val_loss: 0.0053\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0102 - val_loss: 0.0058\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0071 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0086 - val_loss: 0.0072\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0111 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 6.2103 - val_loss: 1.3640\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.3900 - val_loss: 0.0269\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.1214 - val_loss: 0.1616\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0875 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0834 - val_loss: 0.0587\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0749 - val_loss: 0.0479\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0702 - val_loss: 0.0231\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0697 - val_loss: 0.0436\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0693 - val_loss: 0.0374\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0688 - val_loss: 0.0316\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0680 - val_loss: 0.0380\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0677 - val_loss: 0.0328\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0669 - val_loss: 0.0306\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0664 - val_loss: 0.0339\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0645 - val_loss: 0.0364\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0633 - val_loss: 0.0288\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0599 - val_loss: 0.0215\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0552 - val_loss: 0.0186\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0479 - val_loss: 0.0094\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0433 - val_loss: 0.0632\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0554 - val_loss: 0.0421\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0429 - val_loss: 0.0062\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0271 - val_loss: 0.0110\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0160 - val_loss: 0.0215\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0956 - val_loss: 0.0086\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0270 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0202 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0153 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0126 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0117 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0107 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0102 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0099 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0093 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0093 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0091 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0086 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0086 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0080 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0081 - val_loss: 0.0044\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0079 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0079 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0077 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0071 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0069 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0068 - val_loss: 0.0037\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 0.0465 - val_loss: 0.0209\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0072 - val_loss: 0.0098\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 178us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0012 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 0.0941 - val_loss: 0.0132\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0217 - val_loss: 0.0106\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0080 - val_loss: 0.0093\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 178us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 9.8951e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 9.7567e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 9.7427e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 9.4741e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 9.4140e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 9.5846e-04 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.1270 - val_loss: 0.0628\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 347us/step - loss: 0.0587 - val_loss: 0.0333\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0519 - val_loss: 0.0258\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 362us/step - loss: 0.0481 - val_loss: 0.0235\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 359us/step - loss: 0.0446 - val_loss: 0.0213\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0410 - val_loss: 0.0196\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 360us/step - loss: 0.0373 - val_loss: 0.0180\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 360us/step - loss: 0.0335 - val_loss: 0.0160\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 358us/step - loss: 0.0298 - val_loss: 0.0135\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0263 - val_loss: 0.0116\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0231 - val_loss: 0.0098\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0202 - val_loss: 0.0082\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0175 - val_loss: 0.0068\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0153 - val_loss: 0.0057\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0133 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0117 - val_loss: 0.0042\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 358us/step - loss: 0.0103 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0092 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0083 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 361us/step - loss: 0.0076 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 362us/step - loss: 0.0070 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0066 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0062 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 1ms/step - loss: 0.5087 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0068 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 467us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 463us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 463us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 464us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 463us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 463us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 464us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 467us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 463us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0024 - val_loss: 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.7879 - val_loss: 0.0073\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0352 - val_loss: 0.0083\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0159 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0076 - val_loss: 0.0067\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 1.3307 - val_loss: 0.0262\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0542 - val_loss: 0.0099\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0257 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0090 - val_loss: 0.0153\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0055 - val_loss: 0.0050\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.9707 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0474 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0195 - val_loss: 0.0139\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0092 - val_loss: 0.0184\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0084 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0065 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.0594 - val_loss: 0.0054\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0066 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0036 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.1146 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0053 - val_loss: 0.0263\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0031 - val_loss: 0.0077\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0114 - val_loss: 0.0077\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0039 - val_loss: 0.0092\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0055 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0047 - val_loss: 0.0120\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0065 - val_loss: 0.0058\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0475 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 253us/step - loss: 0.0044 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 253us/step - loss: 0.0038 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 254us/step - loss: 0.0084 - val_loss: 0.0213\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 253us/step - loss: 0.0073 - val_loss: 0.0093\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 253us/step - loss: 0.0057 - val_loss: 0.0076\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 257us/step - loss: 0.0044 - val_loss: 0.0090\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 253us/step - loss: 0.0061 - val_loss: 0.0114\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 254us/step - loss: 0.0060 - val_loss: 0.0137\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 252us/step - loss: 0.0054 - val_loss: 0.0066\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 254us/step - loss: 0.0032 - val_loss: 0.0069\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 253us/step - loss: 0.0035 - val_loss: 0.0132\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 254us/step - loss: 0.0084 - val_loss: 0.0142\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 252us/step - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 252us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 252us/step - loss: 0.0029 - val_loss: 0.0104\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 253us/step - loss: 0.0061 - val_loss: 0.0117\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 252us/step - loss: 0.0055 - val_loss: 0.0087\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 252us/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 253us/step - loss: 0.0027 - val_loss: 0.0063\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 252us/step - loss: 0.0040 - val_loss: 0.0127\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 252us/step - loss: 0.0067 - val_loss: 0.0101\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 254us/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 254us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0985 - val_loss: 0.0110\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0225 - val_loss: 0.0105\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0088 - val_loss: 0.0063\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0038 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 171us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 9.9526e-04 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 170us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.0765 - val_loss: 0.0244\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0369 - val_loss: 0.0155\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0288 - val_loss: 0.0123\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0223 - val_loss: 0.0099\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0173 - val_loss: 0.0069\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0135 - val_loss: 0.0056\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0107 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0087 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0073 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0064 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0049 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0046 - val_loss: 0.0043\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.0742 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0072 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0135 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0079 - val_loss: 0.0133\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0143 - val_loss: 0.0061\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0107 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0070 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0088 - val_loss: 0.0049\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0100 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0060 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0080 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0029 - val_loss: 0.0083\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0082 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0068 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.0787 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0148 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0076 - val_loss: 0.0176\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0132 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0115 - val_loss: 0.0108\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0177 - val_loss: 0.0096\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0053 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0100 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0051 - val_loss: 0.0059\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0109 - val_loss: 0.0305\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0101 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0088 - val_loss: 0.0031\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0088 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0054 - val_loss: 0.0115\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0065 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0090 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.0533 - val_loss: 0.0205\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0201 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0120 - val_loss: 0.0094\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0109 - val_loss: 0.0199\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0085 - val_loss: 0.0132\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0109 - val_loss: 0.0425\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0122 - val_loss: 0.0104\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0065 - val_loss: 0.0149\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0058 - val_loss: 0.0219\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0070 - val_loss: 0.0131\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0086 - val_loss: 0.0158\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0048 - val_loss: 0.0089\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0086 - val_loss: 0.0236\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0045 - val_loss: 0.0074\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 349us/step - loss: 0.0068 - val_loss: 0.0197\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0048 - val_loss: 0.0084\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0054 - val_loss: 0.0164\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 349us/step - loss: 0.0048 - val_loss: 0.0170\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0080 - val_loss: 0.0129\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0068 - val_loss: 0.0224\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0037 - val_loss: 0.0080\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0046 - val_loss: 0.0128\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0042 - val_loss: 0.0110\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0887 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0183 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0091 - val_loss: 0.0304\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0117 - val_loss: 0.0257\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0174 - val_loss: 0.0183\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0059 - val_loss: 0.0160\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0120 - val_loss: 0.0262\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0097 - val_loss: 0.0140\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0070 - val_loss: 0.0157\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0147 - val_loss: 0.0101\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0069 - val_loss: 0.0191\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0080 - val_loss: 0.0194\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0068 - val_loss: 0.0105\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0074 - val_loss: 0.0157\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0074 - val_loss: 0.0082\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0059 - val_loss: 0.0175\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0075 - val_loss: 0.0171\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0045 - val_loss: 0.0146\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0086 - val_loss: 0.0107\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0070 - val_loss: 0.0070\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0058 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0043 - val_loss: 0.0066\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0801 - val_loss: 0.0360\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0147 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0056 - val_loss: 0.0136\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 349us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.0684 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0174 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0054 - val_loss: 0.0081\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 9.6292e-04 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 9.4586e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 9.3108e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 9.3288e-04 - val_loss: 9.8415e-04\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 178us/step - loss: 9.1293e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 8.9186e-04 - val_loss: 0.0010\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.4191 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0087 - val_loss: 0.0228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "3811/3811 [==============================] - ETA: 0s - loss: 0.007 - 1s 177us/step - loss: 0.0075 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0056 - val_loss: 0.0159\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0086 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 178us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0045 - val_loss: 0.0474\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0253 - val_loss: 0.0097\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 9.9509e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.8802 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0095 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0065 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0119 - val_loss: 0.0139\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0073 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0064 - val_loss: 0.0175\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0123 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 418us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 419us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 420us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.1111 - val_loss: 0.0203\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0695 - val_loss: 0.0451\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 418us/step - loss: 0.0695 - val_loss: 0.0389\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0692 - val_loss: 0.0383\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0691 - val_loss: 0.0358\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 418us/step - loss: 0.0690 - val_loss: 0.0328\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0690 - val_loss: 0.0392\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0691 - val_loss: 0.0362\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0690 - val_loss: 0.0352\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0690 - val_loss: 0.0376\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0691 - val_loss: 0.0364\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0691 - val_loss: 0.0359\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0691 - val_loss: 0.0318\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0690 - val_loss: 0.0336\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0690 - val_loss: 0.0352\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0690 - val_loss: 0.0353\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0686 - val_loss: 0.0343\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 420us/step - loss: 0.0679 - val_loss: 0.0241\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0616 - val_loss: 0.0172\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0346 - val_loss: 0.0069\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0172 - val_loss: 0.0137\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0258 - val_loss: 0.0090\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0161 - val_loss: 0.0160\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0138 - val_loss: 0.0148\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0748 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0194 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0113 - val_loss: 0.0098\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0134 - val_loss: 0.0107\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0120 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0106 - val_loss: 0.0348\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0150 - val_loss: 0.0027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0048 - val_loss: 0.0211\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0090 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0076 - val_loss: 0.0132\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0111 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0049 - val_loss: 0.0060\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0076 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0084 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0035 - val_loss: 0.0076\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0070 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0061 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0973 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0163 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0146 - val_loss: 0.0102\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0114 - val_loss: 0.0146\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0118 - val_loss: 0.0130\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0121 - val_loss: 0.0209\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0161 - val_loss: 0.0094\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0067 - val_loss: 0.0224\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0170 - val_loss: 0.0156\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0054 - val_loss: 0.0223\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0083 - val_loss: 0.0156\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0079 - val_loss: 0.0255\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0125 - val_loss: 0.0067\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0101 - val_loss: 0.0311\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0064 - val_loss: 0.0087\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0050 - val_loss: 0.0287\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0074 - val_loss: 0.0103\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0071 - val_loss: 0.0171\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0048 - val_loss: 0.0186\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0083 - val_loss: 0.0116\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0080 - val_loss: 0.0186\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0763 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0234 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0111 - val_loss: 0.0222\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0089 - val_loss: 0.0250\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0165 - val_loss: 0.0464\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0124 - val_loss: 0.0083\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0093 - val_loss: 0.0215\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0064 - val_loss: 0.0348\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0129 - val_loss: 0.0179\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0050 - val_loss: 0.0113\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0087 - val_loss: 0.0253\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0084 - val_loss: 0.0066\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0042 - val_loss: 0.0335\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0112 - val_loss: 0.0168\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0065 - val_loss: 0.0171\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0058 - val_loss: 0.0119\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0047 - val_loss: 0.0096\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0058 - val_loss: 0.0173\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0032 - val_loss: 0.0220\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0072 - val_loss: 0.0066\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0032 - val_loss: 0.0198\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0062 - val_loss: 0.0121\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0628 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0115 - val_loss: 0.0104\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0108 - val_loss: 0.0087\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0104 - val_loss: 0.0072\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0101 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0106 - val_loss: 0.0072\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0077 - val_loss: 0.0071\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0084 - val_loss: 0.0023\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0085 - val_loss: 0.0097\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0067 - val_loss: 0.0067\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0068 - val_loss: 0.0041\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0029 - val_loss: 0.0154\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0081 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0851 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0110 - val_loss: 0.0296\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0067 - val_loss: 0.0147\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0088 - val_loss: 0.0121\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0029 - val_loss: 0.0061\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 358us/step - loss: 0.0055 - val_loss: 0.0193\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 360us/step - loss: 0.0087 - val_loss: 0.0156\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0045 - val_loss: 0.0108\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0049 - val_loss: 0.0072\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0023 - val_loss: 0.0051\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0058 - val_loss: 0.0135\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0070 - val_loss: 0.0076\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0023 - val_loss: 0.0066\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0044 - val_loss: 0.0116\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 359us/step - loss: 0.0072 - val_loss: 0.0071\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0955 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0222 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0075 - val_loss: 0.0069\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0050 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 179us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 179us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 178us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 178us/step - loss: 9.9148e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 9.7414e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 9.6371e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 179us/step - loss: 9.4722e-04 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0872 - val_loss: 0.0331\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0177 - val_loss: 0.0103\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0062 - val_loss: 0.0097\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 358us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 365us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0016 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 0.0865 - val_loss: 0.0184\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0144 - val_loss: 0.0077\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0088 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0014 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 0.0998 - val_loss: 0.0295\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0460 - val_loss: 0.0203\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0393 - val_loss: 0.0158\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0337 - val_loss: 0.0156\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0288 - val_loss: 0.0119\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0244 - val_loss: 0.0105\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0205 - val_loss: 0.0085\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0172 - val_loss: 0.0066\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0144 - val_loss: 0.0057\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0120 - val_loss: 0.0047\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0101 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0087 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0075 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0067 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0056 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0629 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0095 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0091 - val_loss: 0.0150\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0111 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0062 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0070 - val_loss: 0.0138\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0077 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0073 - val_loss: 0.0080\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0075 - val_loss: 0.0065\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0083 - val_loss: 0.0082\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0074 - val_loss: 0.0090\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0056 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0084 - val_loss: 0.0089\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0082 - val_loss: 0.0094\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0075 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.3757 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0074 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0026 - val_loss: 0.0082\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0015 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0015 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0016 - val_loss: 0.0048\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0016 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 172us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 173us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 174us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0909 - val_loss: 0.0161\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0214 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0082 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 178us/step - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 179us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 178us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 178us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 178us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 9.9999e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 177us/step - loss: 9.9124e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 176us/step - loss: 9.9970e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 9.4970e-04 - val_loss: 9.9185e-04\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 175us/step - loss: 9.3763e-04 - val_loss: 9.9804e-04\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 0.0742 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0187 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0067 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0049 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 9.8750e-04 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 9.4422e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 9.3415e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 9.2492e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 9.1752e-04 - val_loss: 9.5186e-04\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 9.1012e-04 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 9.2843e-04 - val_loss: 9.4685e-04\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 0.0603 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0129 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0030 - val_loss: 0.0072\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0137 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0045 - val_loss: 0.0183\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0068 - val_loss: 0.0120\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0071 - val_loss: 0.0108\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0042 - val_loss: 0.0079\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0096 - val_loss: 0.0161\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0022 - val_loss: 0.0152\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0072 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0035 - val_loss: 0.0056\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0053 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 179us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0056 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 179us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - ETA: 0s - loss: 0.003 - 1s 180us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0948 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0108 - val_loss: 0.0301\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0090 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0158 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0097 - val_loss: 0.0089\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0125 - val_loss: 0.0137\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0134 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0065 - val_loss: 0.0182\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0198 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0093 - val_loss: 0.0137\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0095 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0152 - val_loss: 0.0119\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0059 - val_loss: 0.0186\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0060 - val_loss: 0.0118\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0061 - val_loss: 0.0140\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0064 - val_loss: 0.0124\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0053 - val_loss: 0.0093\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0054 - val_loss: 0.0254\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0072 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0028 - val_loss: 0.0194\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0076 - val_loss: 0.0085\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0840 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0231 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0100 - val_loss: 0.0139\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0122 - val_loss: 0.0076\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0130 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0099 - val_loss: 0.0145\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0108 - val_loss: 0.0058\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0157 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0091 - val_loss: 0.0117\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0084 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0074 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0081 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0097 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0069 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0065 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0053 - val_loss: 0.0085\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0036 - val_loss: 0.0116\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0073 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.7706 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0413 - val_loss: 0.0091\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0233 - val_loss: 0.0135\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0133 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0081 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0063 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0062 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0049 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0048 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 1.6330 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.1169 - val_loss: 0.0170\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0286 - val_loss: 0.0253\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0229 - val_loss: 0.0083\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0150 - val_loss: 0.0140\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0105 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0099 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0088 - val_loss: 0.0069\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0079 - val_loss: 0.0052\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0075 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0067 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0067 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0062 - val_loss: 0.0042\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0059 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 1.4845 - val_loss: 0.0079\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 337us/step - loss: 0.0857 - val_loss: 0.0098\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 338us/step - loss: 0.0405 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 337us/step - loss: 0.0170 - val_loss: 0.0318\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 340us/step - loss: 0.0130 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 340us/step - loss: 0.0096 - val_loss: 0.0050\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 340us/step - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 339us/step - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 337us/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 337us/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 337us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 341us/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 338us/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 337us/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 338us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 337us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 339us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 336us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 338us/step - loss: 0.0042 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 338us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 340us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 337us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 338us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 337us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0817 - val_loss: 0.0389\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 362us/step - loss: 0.0145 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 362us/step - loss: 0.0062 - val_loss: 0.0133\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 363us/step - loss: 0.0047 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 364us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 363us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 365us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 363us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 363us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 363us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 364us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 363us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 362us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 365us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 363us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 363us/step - loss: 0.0014 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 365us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 365us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 362us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 363us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0680 - val_loss: 0.0061\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0174 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0069 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 179us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 9.8975e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 9.7748e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 9.5700e-04 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 9.5215e-04 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0792 - val_loss: 0.0570\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0178 - val_loss: 0.0240\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0038 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 9.9100e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 9.7843e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 9.6663e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 9.5239e-04 - val_loss: 9.8143e-04\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 9.4442e-04 - val_loss: 9.8936e-04\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 9.3013e-04 - val_loss: 9.9721e-04\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 12s 3ms/step - loss: 0.0716 - val_loss: 0.0382\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0156 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0067 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0040 - val_loss: 0.0065\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 12s 3ms/step - loss: 0.1482 - val_loss: 0.0612\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0547 - val_loss: 0.0266\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0467 - val_loss: 0.0188\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0423 - val_loss: 0.0166\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0383 - val_loss: 0.0137\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0343 - val_loss: 0.0125\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0305 - val_loss: 0.0109\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0271 - val_loss: 0.0091\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0239 - val_loss: 0.0079\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0210 - val_loss: 0.0072\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0181 - val_loss: 0.0059\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0156 - val_loss: 0.0051\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0132 - val_loss: 0.0044\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0114 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0097 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0084 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0073 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0065 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0050 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 12s 3ms/step - loss: 0.0561 - val_loss: 0.0069\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0175 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0112 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0085 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0070 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0056 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 12s 3ms/step - loss: 0.0641 - val_loss: 0.0088\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0231 - val_loss: 0.0058\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0158 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0116 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0089 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0072 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0054 - val_loss: 0.0045\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0050 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0046 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 13s 3ms/step - loss: 0.0877 - val_loss: 0.0201\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0304 - val_loss: 0.0097\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0243 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0197 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0157 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0126 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0102 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0082 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0059 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 13s 3ms/step - loss: 0.0829 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0248 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0166 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0115 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0082 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0066 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0058 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 12s 3ms/step - loss: 0.0762 - val_loss: 0.0108\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0164 - val_loss: 0.0075\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0070 - val_loss: 0.0107\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0037 - val_loss: 0.0074\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 12s 3ms/step - loss: 0.0778 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0171 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0049 - val_loss: 0.0079\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0017 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 9.8176e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 179us/step - loss: 9.4860e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 9.3208e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 181us/step - loss: 9.2574e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 180us/step - loss: 9.0626e-04 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 12s 3ms/step - loss: 0.0950 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0203 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0075 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 182us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 13s 4ms/step - loss: 0.0506 - val_loss: 0.0204\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0117 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0067 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 14s 4ms/step - loss: 0.0618 - val_loss: 0.0097\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0069 - val_loss: 0.0126\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0049 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0023 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 14s 4ms/step - loss: 0.7371 - val_loss: 0.1172\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0493 - val_loss: 0.0502\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0205 - val_loss: 0.0130\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0104 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0038 - val_loss: 0.0066\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 14s 4ms/step - loss: 3.3247 - val_loss: 0.0754\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0919 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0345 - val_loss: 0.0129\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0095 - val_loss: 0.0222\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0094 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0053 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: 0.9480 - val_loss: 0.2632\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0563 - val_loss: 0.0235\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0133 - val_loss: 0.0223\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0087 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0068 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0028 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 14s 4ms/step - loss: 0.5314 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 339us/step - loss: 0.0053 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 340us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 339us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 340us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 338us/step - loss: 0.0077 - val_loss: 0.0529\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 337us/step - loss: 0.0216 - val_loss: 0.0109\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 339us/step - loss: 0.0056 - val_loss: 0.0086\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 339us/step - loss: 0.0101 - val_loss: 0.0433\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 340us/step - loss: 0.0189 - val_loss: 0.0169\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 340us/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 338us/step - loss: 0.0051 - val_loss: 0.0219\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0215 - val_loss: 0.0656\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 338us/step - loss: 0.1101 - val_loss: 0.0540\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 338us/step - loss: 0.0106 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 338us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 340us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 339us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 341us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 339us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 341us/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0069 - val_loss: 0.0064\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 339us/step - loss: 0.0077 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 340us/step - loss: 0.0063 - val_loss: 0.0061\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: 3.4923 - val_loss: 1.0693\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.6738 - val_loss: 0.0191\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 365us/step - loss: 0.1304 - val_loss: 0.2970\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.1473 - val_loss: 0.0627\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 365us/step - loss: 0.0736 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.0784 - val_loss: 0.0201\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.0596 - val_loss: 0.0416\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.0426 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0213 - val_loss: 0.0052\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.0103 - val_loss: 0.0078\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0075 - val_loss: 0.0136\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0060 - val_loss: 0.0082\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.0053 - val_loss: 0.0061\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0041 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 365us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 14s 4ms/step - loss: 0.0512 - val_loss: 0.0186\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0154 - val_loss: 0.0106\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0048 - val_loss: 0.0082\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 9.9258e-04 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 9.5210e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 9.3880e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 9.2110e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 9.1128e-04 - val_loss: 9.5126e-04\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 9.0586e-04 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 8.8994e-04 - val_loss: 9.9877e-04\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 14s 4ms/step - loss: 0.0866 - val_loss: 0.0059\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0222 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0087 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 9.9412e-04 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 9.8285e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 9.7684e-04 - val_loss: 9.8895e-04\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 9.4782e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 183us/step - loss: 9.3224e-04 - val_loss: 9.9162e-04\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 9.1926e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 9.2113e-04 - val_loss: 9.4045e-04\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 184us/step - loss: 9.0571e-04 - val_loss: 9.6619e-04\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 185us/step - loss: 8.9546e-04 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: 0.0584 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 190us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0058 - val_loss: 0.0395\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0112 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0070 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0048 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0021 - val_loss: 9.6652e-04\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 16s 4ms/step - loss: 0.1043 - val_loss: 0.0103\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0158 - val_loss: 0.0049\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0088 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0067 - val_loss: 0.0094\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0058 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0053 - val_loss: 0.0060\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0047 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 16s 4ms/step - loss: 0.0540 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0070 - val_loss: 0.0238\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0105 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0065 - val_loss: 0.0078\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0061 - val_loss: 0.0127\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0081 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0045 - val_loss: 0.0039\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0062 - val_loss: 0.0052\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0025 - val_loss: 0.0055\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0068 - val_loss: 0.0081\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0050 - val_loss: 0.0059\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.3917 - val_loss: 0.0451\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0593 - val_loss: 0.0091\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 349us/step - loss: 0.0419 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0092 - val_loss: 0.0232\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0171 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 358us/step - loss: 0.0079 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0112 - val_loss: 0.0210\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0142 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0079 - val_loss: 0.0047\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 358us/step - loss: 0.0079 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0072 - val_loss: 0.0067\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0074 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0109 - val_loss: 0.0061\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0085 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0078 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 345us/step - loss: 0.0069 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 349us/step - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 345us/step - loss: 0.0090 - val_loss: 0.0055\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0092 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.3487 - val_loss: 0.0083\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0855 - val_loss: 0.6626\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.1389 - val_loss: 0.0113\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0203 - val_loss: 0.1288\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0186 - val_loss: 0.0070\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0050 - val_loss: 0.0191\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0153 - val_loss: 0.0157\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0157 - val_loss: 0.0114\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0104 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0068 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0076 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0076 - val_loss: 0.0034\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.1031 - val_loss: 0.0967\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0372 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0371 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0063 - val_loss: 0.0108\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0164 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0075 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0100 - val_loss: 0.0103\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0101 - val_loss: 0.0033\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0077 - val_loss: 0.0074\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0145 - val_loss: 0.0083\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0101 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0039 - val_loss: 0.0102\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0148 - val_loss: 0.0149\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0110 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0040 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0066 - val_loss: 0.0066\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0090 - val_loss: 0.0093\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0084 - val_loss: 0.0042\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 16s 4ms/step - loss: 0.0777 - val_loss: 0.0110\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 263us/step - loss: 0.0114 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 268us/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 262us/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 263us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 265us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 266us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 263us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 264us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 263us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 263us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 265us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 265us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 263us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 264us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 264us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 265us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 265us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 269us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 264us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 266us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 264us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 267us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 264us/step - loss: 9.9484e-04 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 16s 4ms/step - loss: 0.0843 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0183 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 0.0071 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 9.9491e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 9.7626e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 9.6376e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 9.5128e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 9.4435e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 9.3388e-04 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0598 - val_loss: 0.0172\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 344us/step - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0081 - val_loss: 0.0123\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 344us/step - loss: 0.0068 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0053 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0046 - val_loss: 0.0066\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 344us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 344us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 347us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 348us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 344us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 342us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 344us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 342us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 342us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 344us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 19s 5ms/step - loss: 0.0621 - val_loss: 0.0125\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0118 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0080 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0039 - val_loss: 0.0077\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 19s 5ms/step - loss: 0.0785 - val_loss: 0.0140\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0123 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0081 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0056 - val_loss: 0.0096\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0052 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 19s 5ms/step - loss: 0.3600 - val_loss: 0.0996\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0747 - val_loss: 0.0371\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0690 - val_loss: 0.0355\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0689 - val_loss: 0.0398\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0661 - val_loss: 0.0527\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0551 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0324 - val_loss: 0.0124\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0191 - val_loss: 0.0113\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0204 - val_loss: 0.0146\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0154 - val_loss: 0.0075\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0151 - val_loss: 0.0373\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0108 - val_loss: 0.0064\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0129 - val_loss: 0.0158\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0076 - val_loss: 0.0468\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0124 - val_loss: 0.0226\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0090 - val_loss: 0.0309\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0100 - val_loss: 0.0157\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0086 - val_loss: 0.0260\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0072 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0116 - val_loss: 0.0138\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0053 - val_loss: 0.0110\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0080 - val_loss: 0.0302\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0060 - val_loss: 0.0125\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 19s 5ms/step - loss: 0.2572 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0104 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0115 - val_loss: 0.0210\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0140 - val_loss: 0.0177\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0146 - val_loss: 0.0181\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0150 - val_loss: 0.0245\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0157 - val_loss: 0.0111\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0144 - val_loss: 0.0203\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0122 - val_loss: 0.0154\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0123 - val_loss: 0.0154\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0113 - val_loss: 0.0175\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0101 - val_loss: 0.0107\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0115 - val_loss: 0.0153\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0114 - val_loss: 0.0105\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0084 - val_loss: 0.0151\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0084 - val_loss: 0.0059\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0062 - val_loss: 0.0066\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0087 - val_loss: 0.0136\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0068 - val_loss: 0.0037\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 20s 5ms/step - loss: 0.9253 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0066 - val_loss: 0.0097\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0090 - val_loss: 0.0063\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0115 - val_loss: 0.0148\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0114 - val_loss: 0.0241\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0147 - val_loss: 0.0241\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0131 - val_loss: 0.0180\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0152 - val_loss: 0.0222\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0144 - val_loss: 0.0153\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0140 - val_loss: 0.0071\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0121 - val_loss: 0.0159\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0131 - val_loss: 0.0083\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0092 - val_loss: 0.0091\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0104 - val_loss: 0.0153\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0098 - val_loss: 0.0156\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0076 - val_loss: 0.0111\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0096 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0062 - val_loss: 0.0147\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0076 - val_loss: 0.0078\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 19s 5ms/step - loss: 0.1055 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0055 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0167 - val_loss: 0.0069\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 344us/step - loss: 0.0112 - val_loss: 0.0263\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 344us/step - loss: 0.0145 - val_loss: 0.0138\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0136 - val_loss: 0.0136\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 345us/step - loss: 0.0119 - val_loss: 0.0139\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0143 - val_loss: 0.0135\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 343us/step - loss: 0.0076 - val_loss: 0.0114\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 345us/step - loss: 0.0107 - val_loss: 0.0099\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0126 - val_loss: 0.0146\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 348us/step - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 345us/step - loss: 0.0089 - val_loss: 0.0055\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0100 - val_loss: 0.0075\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 345us/step - loss: 0.0057 - val_loss: 0.0084\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 345us/step - loss: 0.0097 - val_loss: 0.0062\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 349us/step - loss: 0.0058 - val_loss: 0.0152\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 345us/step - loss: 0.0113 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0077 - val_loss: 0.0097\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 345us/step - loss: 0.0079 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 346us/step - loss: 0.0038 - val_loss: 0.0097\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 345us/step - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 347us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 20s 5ms/step - loss: 0.0443 - val_loss: 0.0132\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0090 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0722 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 186us/step - loss: 0.0151 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 9.8280e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 9.6704e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 9.5708e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 9.3885e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 9.3047e-04 - val_loss: 0.0012\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 20s 5ms/step - loss: 0.1154 - val_loss: 0.0497\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0207 - val_loss: 0.0198\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0080 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0030 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 21s 5ms/step - loss: 0.0590 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0064 - val_loss: 0.0150\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0128 - val_loss: 0.0099\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0081 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0088 - val_loss: 0.0106\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0089 - val_loss: 0.0062\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0075 - val_loss: 0.0074\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0065 - val_loss: 0.0106\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0064 - val_loss: 0.0092\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0076 - val_loss: 0.0085\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0070 - val_loss: 0.0046\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0065 - val_loss: 0.0046\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0061 - val_loss: 0.0095\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 21s 5ms/step - loss: 0.0463 - val_loss: 0.0137\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0129 - val_loss: 0.0115\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0081 - val_loss: 0.0181\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0063 - val_loss: 0.0111\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0067 - val_loss: 0.0145\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0086 - val_loss: 0.0205\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0071 - val_loss: 0.0137\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0065 - val_loss: 0.0104\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0065 - val_loss: 0.0087\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0060 - val_loss: 0.0130\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0059 - val_loss: 0.0120\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0064 - val_loss: 0.0104\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0049 - val_loss: 0.0110\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0060 - val_loss: 0.0100\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0029 - val_loss: 0.0086\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0083 - val_loss: 0.0102\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0065 - val_loss: 0.0100\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0057 - val_loss: 0.0087\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0057 - val_loss: 0.0145\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0080 - val_loss: 0.0118\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0056 - val_loss: 0.0070\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0047 - val_loss: 0.0116\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 22s 6ms/step - loss: 0.2052 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0131 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0073 - val_loss: 0.0068\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0051 - val_loss: 0.0082\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0023 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0027 - val_loss: 0.0048\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0042 - val_loss: 0.0081\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0036 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0025 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0028 - val_loss: 0.0080\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0028 - val_loss: 0.0075\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 22s 6ms/step - loss: 0.0718 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0176 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0070 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0060 - val_loss: 0.0126\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0084 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0083 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0063 - val_loss: 0.0080\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0081 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0060 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0051 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0036 - val_loss: 0.0095\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0062 - val_loss: 0.0094\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0047 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0043 - val_loss: 0.0321\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 22s 6ms/step - loss: 0.1755 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0125 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0041 - val_loss: 0.0081\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0073 - val_loss: 0.0095\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0063 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0040 - val_loss: 0.0049\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0071 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0036 - val_loss: 0.0049\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 22s 6ms/step - loss: 0.0624 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0211 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0072 - val_loss: 0.0112\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0081 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0066 - val_loss: 0.0048\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0061 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 23s 6ms/step - loss: 0.2165 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0056 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0136 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0088 - val_loss: 0.0258\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0131 - val_loss: 0.0127\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0123 - val_loss: 0.0095\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0254 - val_loss: 0.0634\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0192 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0172 - val_loss: 0.0177\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0055 - val_loss: 0.0086\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0130 - val_loss: 0.0640\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0139 - val_loss: 0.0050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0045 - val_loss: 0.0203\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0077 - val_loss: 0.0098\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0083 - val_loss: 0.0312\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0139 - val_loss: 0.0049\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0025 - val_loss: 0.0209\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0091 - val_loss: 0.0215\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0174 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0068 - val_loss: 0.0061\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 22s 6ms/step - loss: 0.0734 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 190us/step - loss: 0.0156 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0073 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 190us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 190us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 9.9837e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 9.9471e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 9.7668e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 9.5991e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 9.4499e-04 - val_loss: 9.9614e-04\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 23s 6ms/step - loss: 0.0672 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0113 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0088 - val_loss: 0.0200\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0111 - val_loss: 0.0150\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0090 - val_loss: 0.0117\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0122 - val_loss: 0.0058\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0126 - val_loss: 0.0196\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0066 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0052 - val_loss: 0.0114\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0109 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0032 - val_loss: 0.0069\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0060 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0051 - val_loss: 0.0122\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0071 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0047 - val_loss: 0.0078\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0090 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0074 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 23s 6ms/step - loss: 0.1137 - val_loss: 0.0055\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0090 - val_loss: 0.0156\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0105 - val_loss: 0.0162\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0137 - val_loss: 0.0130\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0118 - val_loss: 0.0088\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0103 - val_loss: 0.0260\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0104 - val_loss: 0.0237\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0102 - val_loss: 0.0200\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0116 - val_loss: 0.0142\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0104 - val_loss: 0.0112\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0067 - val_loss: 0.0103\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0100 - val_loss: 0.0078\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0062 - val_loss: 0.0111\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0082 - val_loss: 0.0128\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0078 - val_loss: 0.0061\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0066 - val_loss: 0.0114\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0074 - val_loss: 0.0128\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0055 - val_loss: 0.0064\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0064 - val_loss: 0.0101\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0048 - val_loss: 0.0068\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0071 - val_loss: 0.0054\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 24s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 25s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 25s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 25s 7ms/step - loss: 735741966673.4803 - val_loss: 97943.1484\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 560us/step - loss: 810851.5662 - val_loss: 97501.2812\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 789510.2406 - val_loss: 96912.6016\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 827596.7754 - val_loss: 95828.7734\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 928128.1397 - val_loss: 93544.1328\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 808804.7320 - val_loss: 91515.7891\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 815680.2686 - val_loss: 88425.5156\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 871645.9502 - val_loss: 82787.8125\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 809242.2425 - val_loss: 77340.8594\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 736419.5954 - val_loss: 72136.5312\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 710052.9447 - val_loss: 66215.4922\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 665823.6909 - val_loss: 59593.4727\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 631100.7494 - val_loss: 51490.9805\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 592400.4372 - val_loss: 42685.4688\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 550963.0097 - val_loss: 33963.9609\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 465180.8820 - val_loss: 26451.5117\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 413375.2951 - val_loss: 19732.7969\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 330176.3775 - val_loss: 13743.8984\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 263314.6284 - val_loss: 8432.5830\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 192535.5952 - val_loss: 4019.0054\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 127872.5538 - val_loss: 1617.6415\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 67427.5369 - val_loss: 261.4144\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 31343.1551 - val_loss: 177.3241\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 13656.6073 - val_loss: 260.3198\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 26s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 25s 7ms/step - loss: 0.0526 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0082 - val_loss: 0.0103\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 25s 6ms/step - loss: 0.0444 - val_loss: 0.0183\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 0.0125 - val_loss: 0.0126\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 0.0040 - val_loss: 0.0058\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 9.8122e-04 - val_loss: 9.5848e-04\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 9.3910e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 9.0376e-04 - val_loss: 9.9114e-04\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 9.0988e-04 - val_loss: 9.0533e-04\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 8.7423e-04 - val_loss: 8.8922e-04\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 8.8431e-04 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 9.0892e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 9.0310e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 8.6186e-04 - val_loss: 8.6822e-04\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 25s 7ms/step - loss: 0.0862 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 0.0169 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 0.0074 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 192us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 193us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 25s 7ms/step - loss: 0.1005 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0055 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0081 - val_loss: 0.0084\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 191us/step - loss: 0.0077 - val_loss: 0.0110\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0082 - val_loss: 0.0080\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0070 - val_loss: 0.0110\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0066 - val_loss: 0.0100\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0061 - val_loss: 0.0105\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0053 - val_loss: 0.0135\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0063 - val_loss: 0.0051\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0040 - val_loss: 0.0096\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 187us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0042 - val_loss: 0.0120\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 188us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 189us/step - loss: 0.0034 - val_loss: 0.0072\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 26s 7ms/step - loss: 0.0944 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 196us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0093 - val_loss: 0.0070\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 201us/step - loss: 0.0087 - val_loss: 0.0128\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0068 - val_loss: 0.0099\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 196us/step - loss: 0.0085 - val_loss: 0.0078\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 196us/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0056 - val_loss: 0.0085\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0063 - val_loss: 0.0083\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 196us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 194us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0037 - val_loss: 0.0073\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 196us/step - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0045 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0025 - val_loss: 0.0068\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 29s 8ms/step - loss: 0.1521 - val_loss: 0.0467\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0602 - val_loss: 0.0219\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0484 - val_loss: 0.0084\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0371 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0225 - val_loss: 0.0086\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0163 - val_loss: 0.0070\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0143 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0155 - val_loss: 0.0104\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 425us/step - loss: 0.0112 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0093 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0113 - val_loss: 0.0056\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0093 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 394us/step - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0083 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0086 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0087 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 412us/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0071 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0105 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 408us/step - loss: 0.0095 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0050 - val_loss: 0.0084\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0093 - val_loss: 0.0021\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 28s 7ms/step - loss: 0.2711 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0077 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0072 - val_loss: 0.0143\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0073 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0107 - val_loss: 0.0102\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0123 - val_loss: 0.0217\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0137 - val_loss: 0.0157\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0144 - val_loss: 0.0070\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0125 - val_loss: 0.0140\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 394us/step - loss: 0.0103 - val_loss: 0.0186\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0121 - val_loss: 0.0140\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0118 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0122 - val_loss: 0.0099\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0085 - val_loss: 0.0060\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0101 - val_loss: 0.0056\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0089 - val_loss: 0.0081\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0086 - val_loss: 0.0073\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0069 - val_loss: 0.0057\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0071 - val_loss: 0.0086\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0068 - val_loss: 0.0062\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 28s 7ms/step - loss: 0.0733 - val_loss: 0.0174\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0140 - val_loss: 0.0102\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0140 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0122 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0064 - val_loss: 0.0070\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0097 - val_loss: 0.0069\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0087 - val_loss: 0.0123\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0088 - val_loss: 0.0090\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0066 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0066 - val_loss: 0.0118\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0076 - val_loss: 0.0064\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0063 - val_loss: 0.0068\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0064 - val_loss: 0.0085\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0056 - val_loss: 0.0056\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 28s 7ms/step - loss: 0.2176 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0095 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0080 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0070 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0071 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0080 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0122 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0076 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0094 - val_loss: 0.0111\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0127 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0092 - val_loss: 0.0046\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0101 - val_loss: 0.0063\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0092 - val_loss: 0.0051\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0107 - val_loss: 0.0140\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0113 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0060 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 394us/step - loss: 0.0078 - val_loss: 0.0152\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0092 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0049 - val_loss: 0.0061\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0199 - val_loss: 0.0256\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0238 - val_loss: 0.0053\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 26s 7ms/step - loss: 0.0738 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0168 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0053 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 9.9416e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 9.8352e-04 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 9.6189e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 9.4483e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 9.3769e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 9.4521e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 9.1506e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 9.2476e-04 - val_loss: 9.6448e-04\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 201us/step - loss: 9.1105e-04 - val_loss: 9.7662e-04\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 27s 7ms/step - loss: 0.0673 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0187 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 9.9574e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 9.6923e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 9.5122e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 9.5094e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 9.4899e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 9.1471e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 9.0424e-04 - val_loss: 9.8295e-04\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 27s 7ms/step - loss: 0.0852 - val_loss: 0.0289\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0358 - val_loss: 0.0145\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0296 - val_loss: 0.0115\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0248 - val_loss: 0.0090\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0206 - val_loss: 0.0075\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0171 - val_loss: 0.0057\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0141 - val_loss: 0.0046\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0117 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0097 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0082 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0069 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 201us/step - loss: 0.0060 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 28s 7ms/step - loss: 0.1234 - val_loss: 0.0589\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 0.0453 - val_loss: 0.0250\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0360 - val_loss: 0.0168\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 0.0321 - val_loss: 0.0132\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0289 - val_loss: 0.0112\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0260 - val_loss: 0.0102\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0233 - val_loss: 0.0092\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0209 - val_loss: 0.0081\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 0.0187 - val_loss: 0.0070\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 0.0167 - val_loss: 0.0064\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0149 - val_loss: 0.0057\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 0.0133 - val_loss: 0.0050\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0118 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 0.0105 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 0.0093 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0083 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0075 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 0.0067 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 0.0060 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0055 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0046 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0043 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 27s 7ms/step - loss: 0.1432 - val_loss: 0.0392\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 0.0441 - val_loss: 0.0153\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 0.0356 - val_loss: 0.0112\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0304 - val_loss: 0.0085\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0257 - val_loss: 0.0073\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0218 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 0.0184 - val_loss: 0.0050\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0159 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0135 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0115 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0101 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0085 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 0.0075 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0068 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0052 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 0.0045 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 0.0042 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 30s 8ms/step - loss: 0.1345 - val_loss: 0.0530\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0487 - val_loss: 0.0227\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0410 - val_loss: 0.0160\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 420us/step - loss: 0.0369 - val_loss: 0.0144\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 420us/step - loss: 0.0333 - val_loss: 0.0124\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 420us/step - loss: 0.0306 - val_loss: 0.0109\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 423us/step - loss: 0.0276 - val_loss: 0.0094\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0249 - val_loss: 0.0089\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0224 - val_loss: 0.0076\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 425us/step - loss: 0.0198 - val_loss: 0.0067\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 423us/step - loss: 0.0178 - val_loss: 0.0059\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0159 - val_loss: 0.0053\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0139 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0124 - val_loss: 0.0043\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0112 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0101 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0092 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 423us/step - loss: 0.0084 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 424us/step - loss: 0.0076 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 427us/step - loss: 0.0071 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 424us/step - loss: 0.0064 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 420us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 29s 8ms/step - loss: 0.0785 - val_loss: 0.0279\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 437us/step - loss: 0.0152 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 440us/step - loss: 0.0074 - val_loss: 0.0192\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 441us/step - loss: 0.0058 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 437us/step - loss: 0.0045 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 437us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 441us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 440us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 441us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 437us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 441us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 443us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.1483 - val_loss: 0.2816\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.1192 - val_loss: 0.0115\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0194 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0147 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0077 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0043 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.7991 - val_loss: 0.0423\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0685 - val_loss: 0.0210\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0672 - val_loss: 0.0120\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0446 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0462 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0087 - val_loss: 0.0258\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0042 - val_loss: 0.0058\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0056 - val_loss: 0.0112\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0040 - val_loss: 0.0066\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0042 - val_loss: 0.0075\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0612 - val_loss: 0.0282\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0130 - val_loss: 0.0051\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0056 - val_loss: 0.0132\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 30s 8ms/step - loss: 0.0713 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0151 - val_loss: 0.0078\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0073 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0052 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 196us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 195us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 9.7639e-04 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 198us/step - loss: 9.4603e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 9.2006e-04 - val_loss: 9.8808e-04\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 9.1193e-04 - val_loss: 9.7729e-04\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 8.9426e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 197us/step - loss: 8.8021e-04 - val_loss: 0.0011\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0637 - val_loss: 0.0247\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0158 - val_loss: 0.0115\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0066 - val_loss: 0.0063\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0042 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 359us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 0.0593 - val_loss: 0.0289\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0149 - val_loss: 0.0089\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0056 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0047 - val_loss: 0.0063\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0040 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 360us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 33s 9ms/step - loss: 0.0815 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0209 - val_loss: 0.0050\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0087 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 359us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 33s 9ms/step - loss: 0.0543 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0082 - val_loss: 0.0070\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0076 - val_loss: 0.0158\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0082 - val_loss: 0.0136\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0086 - val_loss: 0.0174\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0073 - val_loss: 0.0138\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0081 - val_loss: 0.0166\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0067 - val_loss: 0.0105\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0064 - val_loss: 0.0129\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0085 - val_loss: 0.0113\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0074 - val_loss: 0.0135\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0076 - val_loss: 0.0126\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0076 - val_loss: 0.0113\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0065 - val_loss: 0.0115\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0054 - val_loss: 0.0063\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0043 - val_loss: 0.0152\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0094 - val_loss: 0.0180\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0040 - val_loss: 0.0068\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0046 - val_loss: 0.0134\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0058 - val_loss: 0.0123\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0053 - val_loss: 0.0128\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0054 - val_loss: 0.0111\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 34s 9ms/step - loss: 0.0588 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0101 - val_loss: 0.0132\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0116 - val_loss: 0.0150\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0083 - val_loss: 0.0157\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 361us/step - loss: 0.0074 - val_loss: 0.0146\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0089 - val_loss: 0.0134\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0068 - val_loss: 0.0153\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0066 - val_loss: 0.0115\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0080 - val_loss: 0.0128\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0085 - val_loss: 0.0166\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 358us/step - loss: 0.0075 - val_loss: 0.0109\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0063 - val_loss: 0.0117\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 359us/step - loss: 0.0049 - val_loss: 0.0093\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0047 - val_loss: 0.0159\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0089 - val_loss: 0.0165\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 361us/step - loss: 0.0073 - val_loss: 0.0112\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0046 - val_loss: 0.0120\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0052 - val_loss: 0.0079\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 34s 9ms/step - loss: 0.0638 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0112 - val_loss: 0.0257\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0119 - val_loss: 0.0137\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0074 - val_loss: 0.0114\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0088 - val_loss: 0.0167\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0056 - val_loss: 0.0078\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0066 - val_loss: 0.0251\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0114 - val_loss: 0.0149\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0069 - val_loss: 0.0071\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0055 - val_loss: 0.0092\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0064 - val_loss: 0.0169\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0055 - val_loss: 0.0135\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0072 - val_loss: 0.0190\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0073 - val_loss: 0.0123\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0061 - val_loss: 0.0107\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0047 - val_loss: 0.0084\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0042 - val_loss: 0.0125\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0061 - val_loss: 0.0159\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0068 - val_loss: 0.0146\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0063 - val_loss: 0.0140\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0051 - val_loss: 0.0073\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0038 - val_loss: 0.0117\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 35s 9ms/step - loss: 0.3835 - val_loss: 0.0115\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0257 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0109 - val_loss: 0.0120\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0085 - val_loss: 0.0142\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0052 - val_loss: 0.0084\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0049 - val_loss: 0.0219\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0046 - val_loss: 0.0116\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0042 - val_loss: 0.0092\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0039 - val_loss: 0.0067\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 34s 9ms/step - loss: 0.0409 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0071 - val_loss: 0.0072\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0124 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0042 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 35s 9ms/step - loss: 0.0875 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0159 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0070 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 201us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 9.9502e-04 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 201us/step - loss: 9.8356e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 9.6854e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 9.6964e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 201us/step - loss: 9.7480e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 9.4530e-04 - val_loss: 0.0012\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 35s 9ms/step - loss: 0.0620 - val_loss: 0.0171\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0041 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 201us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 201us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 9.9958e-04 - val_loss: 0.0012\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 35s 9ms/step - loss: 0.0628 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 0.0113 - val_loss: 0.0058\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0047 - val_loss: 0.0098\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 200us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 201us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 203us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 201us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 201us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 199us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 202us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 37s 10ms/step - loss: 0.0601 - val_loss: 0.0218\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0129 - val_loss: 0.0160\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0045 - val_loss: 0.0072\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 408us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 425us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 37s 10ms/step - loss: 0.0825 - val_loss: 0.0264\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0332 - val_loss: 0.0088\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0098 - val_loss: 0.0059\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0075 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0029 - val_loss: 0.0051\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 420us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 38s 10ms/step - loss: 0.3505 - val_loss: 0.0080\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 431us/step - loss: 0.0796 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 430us/step - loss: 0.0112 - val_loss: 0.0619\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0753 - val_loss: 0.0151\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 426us/step - loss: 0.0096 - val_loss: 0.0420\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0581 - val_loss: 0.0105\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 431us/step - loss: 0.0086 - val_loss: 0.0245\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 408us/step - loss: 0.0569 - val_loss: 0.0111\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0082 - val_loss: 0.0119\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0411 - val_loss: 0.0045\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 411us/step - loss: 0.0100 - val_loss: 0.0045\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 420us/step - loss: 0.0288 - val_loss: 0.0043\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0138 - val_loss: 0.0112\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0218 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0173 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0186 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0149 - val_loss: 0.0062\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0127 - val_loss: 0.0098\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0161 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0138 - val_loss: 0.0042\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0129 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0120 - val_loss: 0.0043\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0103 - val_loss: 0.0108\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0114 - val_loss: 0.0042\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 39s 10ms/step - loss: 0.3295 - val_loss: 0.0109\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0515 - val_loss: 0.0279\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0522 - val_loss: 0.0267\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0490 - val_loss: 0.0323\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0336 - val_loss: 0.0766\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0346 - val_loss: 0.0243\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0386 - val_loss: 0.0194\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0257 - val_loss: 0.0395\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0260 - val_loss: 0.0081\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0285 - val_loss: 0.0096\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0205 - val_loss: 0.0097\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0220 - val_loss: 0.0249\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0194 - val_loss: 0.0097\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0209 - val_loss: 0.0055\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0160 - val_loss: 0.0099\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0200 - val_loss: 0.0083\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0144 - val_loss: 0.0115\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0136 - val_loss: 0.0154\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0140 - val_loss: 0.0081\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0152 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0120 - val_loss: 0.0083\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0111 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0114 - val_loss: 0.0139\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 41s 11ms/step - loss: 1.5797 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0773 - val_loss: 0.0421\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0580 - val_loss: 0.0925\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0895 - val_loss: 0.0589\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0929 - val_loss: 0.0351\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0814 - val_loss: 0.0541\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0686 - val_loss: 0.0508\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0696 - val_loss: 0.0389\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0645 - val_loss: 0.0470\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0509 - val_loss: 0.0669\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0484 - val_loss: 0.0561\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0435 - val_loss: 0.0726\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0361 - val_loss: 0.0688\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0389 - val_loss: 0.0476\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0364 - val_loss: 0.0513\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0324 - val_loss: 0.0502\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0301 - val_loss: 0.0651\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0287 - val_loss: 0.0543\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0256 - val_loss: 0.0619\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0252 - val_loss: 0.0638\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0249 - val_loss: 0.0543\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0227 - val_loss: 0.0439\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0202 - val_loss: 0.0507\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0208 - val_loss: 0.0451\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 40s 11ms/step - loss: 0.0443 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0137 - val_loss: 0.0056\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0065 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0053 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0094 - val_loss: 0.0111\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0108 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0051 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0086 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0063 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0080 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0074 - val_loss: 0.0060\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0060 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0053 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 40s 10ms/step - loss: 0.0511 - val_loss: 0.0286\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0144 - val_loss: 0.0169\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 0.0067 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 0.0049 - val_loss: 0.0082\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 9.9115e-04 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 9.6553e-04 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 9.4149e-04 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 9.2571e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 9.2000e-04 - val_loss: 9.6318e-04\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 9.0966e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 8.8366e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 9.1494e-04 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 9.1317e-04 - val_loss: 8.8900e-04\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 42s 11ms/step - loss: 0.3656 - val_loss: 0.1236\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0778 - val_loss: 0.0051\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0972 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0788 - val_loss: 0.0297\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0697 - val_loss: 0.0568\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0715 - val_loss: 0.0488\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0690 - val_loss: 0.0320\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0685 - val_loss: 0.0284\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0670 - val_loss: 0.0318\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0656 - val_loss: 0.0344\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0601 - val_loss: 0.0273\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0546 - val_loss: 0.0160\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0492 - val_loss: 0.0759\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0369 - val_loss: 0.0054\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0254 - val_loss: 0.0048\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0176 - val_loss: 0.0077\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0095 - val_loss: 0.0143\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0083 - val_loss: 0.0171\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0076 - val_loss: 0.0146\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0054 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 41s 11ms/step - loss: 0.3349 - val_loss: 0.1030\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0768 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0979 - val_loss: 0.0068\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0756 - val_loss: 0.0392\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0707 - val_loss: 0.0602\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0713 - val_loss: 0.0431\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0692 - val_loss: 0.0289\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0694 - val_loss: 0.0310\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0691 - val_loss: 0.0383\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0691 - val_loss: 0.0385\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0690 - val_loss: 0.0348\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0690 - val_loss: 0.0329\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0691 - val_loss: 0.0360\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0690 - val_loss: 0.0348\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0690 - val_loss: 0.0367\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0690 - val_loss: 0.0351\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0689 - val_loss: 0.0349\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0689 - val_loss: 0.0360\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0690 - val_loss: 0.0351\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0690 - val_loss: 0.0331\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0688 - val_loss: 0.0377\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0681 - val_loss: 0.0343\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0663 - val_loss: 0.0334\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0645 - val_loss: 0.0257\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 43s 11ms/step - loss: 0.1831 - val_loss: 0.1001\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0739 - val_loss: 0.0159\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0776 - val_loss: 0.0113\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0744 - val_loss: 0.0261\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0692 - val_loss: 0.0440\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0700 - val_loss: 0.0463\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0693 - val_loss: 0.0360\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0690 - val_loss: 0.0313\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0691 - val_loss: 0.0336\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0689 - val_loss: 0.0360\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0688 - val_loss: 0.0362\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0684 - val_loss: 0.0339\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0675 - val_loss: 0.0336\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0660 - val_loss: 0.0310\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0641 - val_loss: 0.0288\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0621 - val_loss: 0.0276\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0600 - val_loss: 0.0225\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0577 - val_loss: 0.0202\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0558 - val_loss: 0.0176\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0542 - val_loss: 0.0152\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0532 - val_loss: 0.0116\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0526 - val_loss: 0.0116\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0541 - val_loss: 0.0129\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0579 - val_loss: 0.0139\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 43s 11ms/step - loss: 0.0788 - val_loss: 0.0636\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0691 - val_loss: 0.0314\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0590 - val_loss: 0.0151\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0478 - val_loss: 0.0118\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0346 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0245 - val_loss: 0.0057\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0225 - val_loss: 0.0131\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0217 - val_loss: 0.0206\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0195 - val_loss: 0.0234\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.0166 - val_loss: 0.0211\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0143 - val_loss: 0.0178\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0145 - val_loss: 0.0149\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0140 - val_loss: 0.0154\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0137 - val_loss: 0.0176\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0135 - val_loss: 0.0180\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0132 - val_loss: 0.0165\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0127 - val_loss: 0.0159\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0118 - val_loss: 0.0157\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0108 - val_loss: 0.0148\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 3s 731us/step - loss: 0.0099 - val_loss: 0.0151\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 0.0093 - val_loss: 0.0164\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0090 - val_loss: 0.0179\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0087 - val_loss: 0.0188\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0085 - val_loss: 0.0188\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 50s 13ms/step - loss: 1.5595 - val_loss: 1.0235\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.4904 - val_loss: 0.3140\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.1387 - val_loss: 0.0808\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0717 - val_loss: 0.0275\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0706 - val_loss: 0.0209\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0709 - val_loss: 0.0253\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0696 - val_loss: 0.0319\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0690 - val_loss: 0.0358\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0690 - val_loss: 0.0367\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0690 - val_loss: 0.0357\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0690 - val_loss: 0.0348\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0690 - val_loss: 0.0346\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0690 - val_loss: 0.0353\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0690 - val_loss: 0.0361\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0690 - val_loss: 0.0362\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0690 - val_loss: 0.0363\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0690 - val_loss: 0.0356\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0690 - val_loss: 0.0362\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0690 - val_loss: 0.0365\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0690 - val_loss: 0.0355\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0690 - val_loss: 0.0354\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0690 - val_loss: 0.0365\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0690 - val_loss: 0.0368\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 0.0690 - val_loss: 0.0363\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 46s 12ms/step - loss: 1.0991 - val_loss: 0.7186\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.3353 - val_loss: 0.2341\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.1161 - val_loss: 0.0786\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0725 - val_loss: 0.0357\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0693 - val_loss: 0.0261\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0699 - val_loss: 0.0270\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0695 - val_loss: 0.0307\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0691 - val_loss: 0.0340\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0690 - val_loss: 0.0358\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0690 - val_loss: 0.0361\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0690 - val_loss: 0.0355\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0690 - val_loss: 0.0360\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0690 - val_loss: 0.0365\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0690 - val_loss: 0.0364\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0690 - val_loss: 0.0364\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0690 - val_loss: 0.0360\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0690 - val_loss: 0.0361\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0690 - val_loss: 0.0364\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0690 - val_loss: 0.0360\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0690 - val_loss: 0.0365\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0690 - val_loss: 0.0357\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0690 - val_loss: 0.0352\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0690 - val_loss: 0.0352\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0690 - val_loss: 0.0351\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 44s 12ms/step - loss: 0.1120 - val_loss: 0.0437\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 460us/step - loss: 0.0691 - val_loss: 0.0368\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 456us/step - loss: 0.0663 - val_loss: 0.0302\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 458us/step - loss: 0.0610 - val_loss: 0.0129\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 458us/step - loss: 0.0379 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0212 - val_loss: 0.1435\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 458us/step - loss: 0.0204 - val_loss: 0.0104\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 458us/step - loss: 0.0121 - val_loss: 0.0148\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 461us/step - loss: 0.0118 - val_loss: 0.0202\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 462us/step - loss: 0.0102 - val_loss: 0.0237\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 457us/step - loss: 0.0111 - val_loss: 0.0056\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 452us/step - loss: 0.0115 - val_loss: 0.0138\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 452us/step - loss: 0.0089 - val_loss: 0.0140\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 451us/step - loss: 0.0082 - val_loss: 0.0230\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 452us/step - loss: 0.0081 - val_loss: 0.0270\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 450us/step - loss: 0.0081 - val_loss: 0.0280\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 451us/step - loss: 0.0074 - val_loss: 0.0297\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 452us/step - loss: 0.0081 - val_loss: 0.0125\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 451us/step - loss: 0.0070 - val_loss: 0.0279\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 450us/step - loss: 0.0062 - val_loss: 0.0195\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 453us/step - loss: 0.0085 - val_loss: 0.0189\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 453us/step - loss: 0.0057 - val_loss: 0.0359\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 454us/step - loss: 0.0068 - val_loss: 0.0068\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 449us/step - loss: 0.0073 - val_loss: 0.0195\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.01826084963977337,\n",
       " 0.012631704099476337,\n",
       " 0.0014728951500728726,\n",
       " 0.005815340671688318,\n",
       " 0.0016750592039898038,\n",
       " 0.0026102224364876747,\n",
       " 0.0029148038011044264,\n",
       " 0.001930467551574111,\n",
       " 0.0015726684359833598,\n",
       " 0.0017376557225361466,\n",
       " 0.001749676768667996,\n",
       " 0.001490045222453773,\n",
       " 0.0012396228266879916,\n",
       " 0.0013619951205328107,\n",
       " 0.0010872536804527044,\n",
       " 0.0009584769723005593,\n",
       " 0.0010840313043445349,\n",
       " 0.0009911361848935485,\n",
       " 0.0009053258108906448,\n",
       " 0.0008892153855413198,\n",
       " 0.0013362239114940166,\n",
       " 0.001036342466250062,\n",
       " 0.0011177314445376396,\n",
       " 0.0008682223851792514]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "activation: softsign\n",
      "shuffle: True\n",
      "lstmsize: 104\n",
      "full_density: True\n",
      "twice: False\n",
      "optimizer: adam\n",
      "density: 180\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_138\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_242 (LSTM)              (None, 104)               45760     \n",
      "_________________________________________________________________\n",
      "dense_701 (Dense)            (None, 180)               18900     \n",
      "_________________________________________________________________\n",
      "dense_702 (Dense)            (None, 90)                16290     \n",
      "_________________________________________________________________\n",
      "dense_703 (Dense)            (None, 45)                4095      \n",
      "_________________________________________________________________\n",
      "dense_704 (Dense)            (None, 22)                1012      \n",
      "_________________________________________________________________\n",
      "dense_705 (Dense)            (None, 1)                 23        \n",
      "=================================================================\n",
      "Total params: 86,080\n",
      "Trainable params: 86,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/2000\n",
      "3811/3811 [==============================] - 44s 12ms/step - loss: 0.0799 - val_loss: 0.0031\n",
      "Epoch 2/2000\n",
      "3811/3811 [==============================] - 1s 222us/step - loss: 0.0190 - val_loss: 0.0021\n",
      "Epoch 3/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 0.0077 - val_loss: 0.0021\n",
      "Epoch 4/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 0.0052 - val_loss: 0.0080\n",
      "Epoch 5/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 6/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 7/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 8/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 9/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 10/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 11/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 12/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 13/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 15/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 16/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 17/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 18/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.9860e-04 - val_loss: 0.0010\n",
      "Epoch 20/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.5453e-04 - val_loss: 0.0011\n",
      "Epoch 21/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.4212e-04 - val_loss: 0.0012\n",
      "Epoch 22/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.3581e-04 - val_loss: 0.0010\n",
      "Epoch 23/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.2587e-04 - val_loss: 9.6906e-04\n",
      "Epoch 24/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.1178e-04 - val_loss: 0.0011\n",
      "Epoch 25/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.1868e-04 - val_loss: 9.5723e-04\n",
      "Epoch 26/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 9.0600e-04 - val_loss: 0.0011\n",
      "Epoch 27/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 9.0992e-04 - val_loss: 9.2818e-04\n",
      "Epoch 28/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.8540e-04 - val_loss: 9.3372e-04\n",
      "Epoch 29/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 8.6332e-04 - val_loss: 9.6308e-04\n",
      "Epoch 30/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.5448e-04 - val_loss: 9.8209e-04\n",
      "Epoch 31/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.5129e-04 - val_loss: 9.0530e-04\n",
      "Epoch 32/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.6009e-04 - val_loss: 9.1099e-04\n",
      "Epoch 33/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.4472e-04 - val_loss: 8.8281e-04\n",
      "Epoch 34/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 8.2560e-04 - val_loss: 8.6584e-04\n",
      "Epoch 35/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 8.3187e-04 - val_loss: 9.5082e-04\n",
      "Epoch 36/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.3347e-04 - val_loss: 8.9922e-04\n",
      "Epoch 37/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.1027e-04 - val_loss: 8.3087e-04\n",
      "Epoch 38/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 8.2119e-04 - val_loss: 9.8997e-04\n",
      "Epoch 39/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 9.3902e-04 - val_loss: 0.0011\n",
      "Epoch 40/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 8.4238e-04 - val_loss: 9.2376e-04\n",
      "Epoch 41/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.4330e-04 - val_loss: 8.2043e-04\n",
      "Epoch 42/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.2396e-04 - val_loss: 8.5913e-04\n",
      "Epoch 43/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 7.8823e-04 - val_loss: 7.9858e-04\n",
      "Epoch 44/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.7840e-04 - val_loss: 7.9294e-04\n",
      "Epoch 45/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.7421e-04 - val_loss: 7.8186e-04\n",
      "Epoch 46/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.8372e-04 - val_loss: 0.0011\n",
      "Epoch 47/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 8.0990e-04 - val_loss: 7.6933e-04\n",
      "Epoch 48/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.6847e-04 - val_loss: 8.0601e-04\n",
      "Epoch 49/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.6710e-04 - val_loss: 7.6032e-04\n",
      "Epoch 50/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.5690e-04 - val_loss: 8.2348e-04\n",
      "Epoch 51/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 8.3245e-04 - val_loss: 7.6446e-04\n",
      "Epoch 52/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.1307e-04 - val_loss: 7.4732e-04\n",
      "Epoch 53/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.9044e-04 - val_loss: 7.8918e-04\n",
      "Epoch 54/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 7.6193e-04 - val_loss: 8.5671e-04\n",
      "Epoch 55/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.5619e-04 - val_loss: 8.2815e-04\n",
      "Epoch 56/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.4874e-04 - val_loss: 8.6146e-04\n",
      "Epoch 57/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.4368e-04 - val_loss: 7.3455e-04\n",
      "Epoch 58/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.5289e-04 - val_loss: 7.3113e-04\n",
      "Epoch 59/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 7.3184e-04 - val_loss: 7.7876e-04\n",
      "Epoch 60/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 7.3340e-04 - val_loss: 8.5416e-04\n",
      "Epoch 61/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.3734e-04 - val_loss: 7.8627e-04\n",
      "Epoch 62/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.3939e-04 - val_loss: 7.4269e-04\n",
      "Epoch 63/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 7.9058e-04 - val_loss: 8.4834e-04\n",
      "Epoch 64/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 7.5593e-04 - val_loss: 9.6966e-04\n",
      "Epoch 65/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 7.5083e-04 - val_loss: 7.1369e-04\n",
      "Epoch 66/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.1630e-04 - val_loss: 7.2686e-04\n",
      "Epoch 67/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.2328e-04 - val_loss: 7.0644e-04\n",
      "Epoch 68/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.3700e-04 - val_loss: 0.0010\n",
      "Epoch 69/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 8.0955e-04 - val_loss: 9.9487e-04\n",
      "Epoch 70/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 7.3730e-04 - val_loss: 0.0010\n",
      "Epoch 71/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.2512e-04 - val_loss: 8.7142e-04\n",
      "Epoch 72/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 7.1843e-04 - val_loss: 8.4649e-04\n",
      "Epoch 73/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 7.2109e-04 - val_loss: 8.9158e-04\n",
      "Epoch 74/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 7.3132e-04 - val_loss: 8.6558e-04\n",
      "Epoch 75/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.4903e-04 - val_loss: 6.9718e-04\n",
      "Epoch 76/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.0821e-04 - val_loss: 7.5605e-04\n",
      "Epoch 77/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.2856e-04 - val_loss: 6.9548e-04\n",
      "Epoch 78/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.0536e-04 - val_loss: 8.3351e-04\n",
      "Epoch 79/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 7.2200e-04 - val_loss: 9.7959e-04\n",
      "Epoch 80/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 7.2762e-04 - val_loss: 9.1244e-04\n",
      "Epoch 81/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.0872e-04 - val_loss: 7.1045e-04\n",
      "Epoch 82/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.9520e-04 - val_loss: 6.9850e-04\n",
      "Epoch 83/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.2804e-04 - val_loss: 7.4607e-04\n",
      "Epoch 84/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 7.3878e-04 - val_loss: 6.9175e-04\n",
      "Epoch 85/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.1362e-04 - val_loss: 7.4407e-04\n",
      "Epoch 86/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.1858e-04 - val_loss: 8.3438e-04\n",
      "Epoch 87/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.8798e-04 - val_loss: 6.9090e-04\n",
      "Epoch 88/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.8548e-04 - val_loss: 6.8090e-04\n",
      "Epoch 89/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.2228e-04 - val_loss: 7.4500e-04\n",
      "Epoch 90/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.4857e-04 - val_loss: 9.5715e-04\n",
      "Epoch 91/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 7.5110e-04 - val_loss: 8.4204e-04\n",
      "Epoch 92/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.3412e-04 - val_loss: 7.0674e-04\n",
      "Epoch 93/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 7.1606e-04 - val_loss: 6.7751e-04\n",
      "Epoch 94/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.0819e-04 - val_loss: 6.9791e-04\n",
      "Epoch 95/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.9210e-04 - val_loss: 7.5491e-04\n",
      "Epoch 96/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.8849e-04 - val_loss: 7.1080e-04\n",
      "Epoch 97/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.8028e-04 - val_loss: 7.4134e-04\n",
      "Epoch 98/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.7927e-04 - val_loss: 8.0078e-04\n",
      "Epoch 99/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.0489e-04 - val_loss: 9.0162e-04\n",
      "Epoch 100/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.1796e-04 - val_loss: 8.7128e-04\n",
      "Epoch 101/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.8842e-04 - val_loss: 8.1077e-04\n",
      "Epoch 102/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.6880e-04 - val_loss: 7.8538e-04\n",
      "Epoch 103/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.7925e-04 - val_loss: 8.5181e-04\n",
      "Epoch 104/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.8495e-04 - val_loss: 0.0016\n",
      "Epoch 105/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 8.9962e-04 - val_loss: 0.0010\n",
      "Epoch 106/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 7.2868e-04 - val_loss: 8.7096e-04\n",
      "Epoch 107/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.7217e-04 - val_loss: 6.7021e-04\n",
      "Epoch 108/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.8303e-04 - val_loss: 6.7755e-04\n",
      "Epoch 109/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.7479e-04 - val_loss: 6.9447e-04\n",
      "Epoch 110/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.8488e-04 - val_loss: 7.1812e-04\n",
      "Epoch 111/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.7722e-04 - val_loss: 7.4931e-04\n",
      "Epoch 112/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.7461e-04 - val_loss: 7.2922e-04\n",
      "Epoch 113/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.9922e-04 - val_loss: 8.3523e-04\n",
      "Epoch 114/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 7.4321e-04 - val_loss: 7.7066e-04\n",
      "Epoch 115/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.7951e-04 - val_loss: 8.3963e-04\n",
      "Epoch 116/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.6433e-04 - val_loss: 6.7193e-04\n",
      "Epoch 117/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.7775e-04 - val_loss: 8.2944e-04\n",
      "Epoch 118/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.6338e-04 - val_loss: 7.3586e-04\n",
      "Epoch 119/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.6982e-04 - val_loss: 6.7007e-04\n",
      "Epoch 120/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.6465e-04 - val_loss: 7.1881e-04\n",
      "Epoch 121/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.8418e-04 - val_loss: 6.6463e-04\n",
      "Epoch 122/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.5427e-04 - val_loss: 6.7610e-04\n",
      "Epoch 123/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.6090e-04 - val_loss: 6.8397e-04\n",
      "Epoch 124/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.5405e-04 - val_loss: 6.6425e-04\n",
      "Epoch 125/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.5916e-04 - val_loss: 8.4055e-04\n",
      "Epoch 126/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.0401e-04 - val_loss: 6.8717e-04\n",
      "Epoch 127/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.4481e-04 - val_loss: 7.2404e-04\n",
      "Epoch 128/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.6365e-04 - val_loss: 9.9615e-04\n",
      "Epoch 129/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.9333e-04 - val_loss: 6.6021e-04\n",
      "Epoch 130/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.8359e-04 - val_loss: 0.0011\n",
      "Epoch 131/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 7.7913e-04 - val_loss: 7.2387e-04\n",
      "Epoch 132/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.8638e-04 - val_loss: 6.7737e-04\n",
      "Epoch 133/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.5495e-04 - val_loss: 9.4723e-04\n",
      "Epoch 134/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.8166e-04 - val_loss: 7.7844e-04\n",
      "Epoch 135/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.7961e-04 - val_loss: 7.0832e-04\n",
      "Epoch 136/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.6809e-04 - val_loss: 6.6072e-04\n",
      "Epoch 137/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.4632e-04 - val_loss: 7.2301e-04\n",
      "Epoch 138/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.4779e-04 - val_loss: 6.9845e-04\n",
      "Epoch 139/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3706e-04 - val_loss: 6.6556e-04\n",
      "Epoch 140/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.4401e-04 - val_loss: 8.6010e-04\n",
      "Epoch 141/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.7747e-04 - val_loss: 0.0010\n",
      "Epoch 142/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.8264e-04 - val_loss: 7.3252e-04\n",
      "Epoch 143/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.5674e-04 - val_loss: 7.1411e-04\n",
      "Epoch 144/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.4192e-04 - val_loss: 6.7604e-04\n",
      "Epoch 145/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.3402e-04 - val_loss: 6.6376e-04\n",
      "Epoch 146/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3762e-04 - val_loss: 8.3983e-04\n",
      "Epoch 147/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.5847e-04 - val_loss: 6.6540e-04\n",
      "Epoch 148/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.3504e-04 - val_loss: 6.5659e-04\n",
      "Epoch 149/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 6.3066e-04 - val_loss: 6.5454e-04\n",
      "Epoch 150/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.3130e-04 - val_loss: 6.8392e-04\n",
      "Epoch 151/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.5369e-04 - val_loss: 6.5241e-04\n",
      "Epoch 152/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.3635e-04 - val_loss: 6.6478e-04\n",
      "Epoch 153/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.3076e-04 - val_loss: 8.2056e-04\n",
      "Epoch 154/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.5487e-04 - val_loss: 6.5120e-04\n",
      "Epoch 155/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.6291e-04 - val_loss: 6.4754e-04\n",
      "Epoch 156/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.3035e-04 - val_loss: 6.5700e-04\n",
      "Epoch 157/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2735e-04 - val_loss: 6.8920e-04\n",
      "Epoch 158/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.3325e-04 - val_loss: 6.5494e-04\n",
      "Epoch 159/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.2677e-04 - val_loss: 6.7262e-04\n",
      "Epoch 160/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.4056e-04 - val_loss: 6.5930e-04\n",
      "Epoch 161/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.3036e-04 - val_loss: 6.5022e-04\n",
      "Epoch 162/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.4082e-04 - val_loss: 6.7199e-04\n",
      "Epoch 163/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.5040e-04 - val_loss: 8.3766e-04\n",
      "Epoch 164/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 6.7583e-04 - val_loss: 6.5275e-04\n",
      "Epoch 165/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.6446e-04 - val_loss: 6.4935e-04\n",
      "Epoch 166/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.5588e-04 - val_loss: 0.0012\n",
      "Epoch 167/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.3805e-04 - val_loss: 6.5687e-04\n",
      "Epoch 168/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.2063e-04 - val_loss: 7.6147e-04\n",
      "Epoch 169/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.7830e-04 - val_loss: 7.4287e-04\n",
      "Epoch 170/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 6.9792e-04 - val_loss: 6.5089e-04\n",
      "Epoch 171/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.7593e-04 - val_loss: 6.5230e-04\n",
      "Epoch 172/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.5185e-04 - val_loss: 6.8673e-04\n",
      "Epoch 173/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.2680e-04 - val_loss: 7.0267e-04\n",
      "Epoch 174/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2807e-04 - val_loss: 6.8160e-04\n",
      "Epoch 175/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.4857e-04 - val_loss: 6.5235e-04\n",
      "Epoch 176/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.3166e-04 - val_loss: 6.6267e-04\n",
      "Epoch 177/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.3142e-04 - val_loss: 6.7316e-04\n",
      "Epoch 178/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.3299e-04 - val_loss: 7.6828e-04\n",
      "Epoch 179/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.3394e-04 - val_loss: 9.0170e-04\n",
      "Epoch 180/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.7383e-04 - val_loss: 6.6010e-04\n",
      "Epoch 181/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.3249e-04 - val_loss: 6.5745e-04\n",
      "Epoch 182/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.3977e-04 - val_loss: 9.0032e-04\n",
      "Epoch 183/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.6015e-04 - val_loss: 9.7522e-04\n",
      "Epoch 184/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.0329e-04 - val_loss: 6.6862e-04\n",
      "Epoch 185/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3501e-04 - val_loss: 6.7468e-04\n",
      "Epoch 186/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.5827e-04 - val_loss: 7.1140e-04\n",
      "Epoch 187/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.7098e-04 - val_loss: 6.5491e-04\n",
      "Epoch 188/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2525e-04 - val_loss: 6.6178e-04\n",
      "Epoch 189/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.3753e-04 - val_loss: 8.3270e-04\n",
      "Epoch 190/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.6868e-04 - val_loss: 6.5188e-04\n",
      "Epoch 191/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.8481e-04 - val_loss: 8.3788e-04\n",
      "Epoch 192/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 6.8243e-04 - val_loss: 6.8798e-04\n",
      "Epoch 193/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.3736e-04 - val_loss: 6.5599e-04\n",
      "Epoch 194/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.1901e-04 - val_loss: 6.8941e-04\n",
      "Epoch 195/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2222e-04 - val_loss: 7.4028e-04\n",
      "Epoch 196/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.4005e-04 - val_loss: 6.6790e-04\n",
      "Epoch 197/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.5619e-04 - val_loss: 6.4150e-04\n",
      "Epoch 198/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.2091e-04 - val_loss: 6.4654e-04\n",
      "Epoch 199/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2031e-04 - val_loss: 6.5804e-04\n",
      "Epoch 200/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.2113e-04 - val_loss: 6.5094e-04\n",
      "Epoch 201/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1382e-04 - val_loss: 7.2205e-04\n",
      "Epoch 202/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.3413e-04 - val_loss: 9.3089e-04\n",
      "Epoch 203/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.7908e-04 - val_loss: 6.5154e-04\n",
      "Epoch 204/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1938e-04 - val_loss: 6.9239e-04\n",
      "Epoch 205/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.1454e-04 - val_loss: 6.5442e-04\n",
      "Epoch 206/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.3692e-04 - val_loss: 6.4144e-04\n",
      "Epoch 207/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.4286e-04 - val_loss: 6.4837e-04\n",
      "Epoch 208/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.4525e-04 - val_loss: 8.9766e-04\n",
      "Epoch 209/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.3469e-04 - val_loss: 6.6261e-04\n",
      "Epoch 210/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1581e-04 - val_loss: 6.7008e-04\n",
      "Epoch 211/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1658e-04 - val_loss: 6.6160e-04\n",
      "Epoch 212/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.2155e-04 - val_loss: 7.0825e-04\n",
      "Epoch 213/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 6.4580e-04 - val_loss: 6.4782e-04\n",
      "Epoch 214/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0631e-04 - val_loss: 7.8068e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.9006e-04 - val_loss: 6.6587e-04\n",
      "Epoch 216/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 6.8551e-04 - val_loss: 9.0072e-04\n",
      "Epoch 217/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.2403e-04 - val_loss: 6.4706e-04\n",
      "Epoch 218/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.5268e-04 - val_loss: 6.5279e-04\n",
      "Epoch 219/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.9072e-04 - val_loss: 6.6249e-04\n",
      "Epoch 220/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.5557e-04 - val_loss: 8.7239e-04\n",
      "Epoch 221/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.5283e-04 - val_loss: 8.7638e-04\n",
      "Epoch 222/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.3971e-04 - val_loss: 7.7209e-04\n",
      "Epoch 223/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.4598e-04 - val_loss: 9.6262e-04\n",
      "Epoch 224/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.8904e-04 - val_loss: 0.0012\n",
      "Epoch 225/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.2567e-04 - val_loss: 7.6170e-04\n",
      "Epoch 226/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1672e-04 - val_loss: 6.4769e-04\n",
      "Epoch 227/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.1063e-04 - val_loss: 6.7396e-04\n",
      "Epoch 228/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.2377e-04 - val_loss: 6.4753e-04\n",
      "Epoch 229/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1620e-04 - val_loss: 6.6093e-04\n",
      "Epoch 230/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.2468e-04 - val_loss: 7.6336e-04\n",
      "Epoch 231/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.2669e-04 - val_loss: 7.3665e-04\n",
      "Epoch 232/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.1902e-04 - val_loss: 6.4695e-04\n",
      "Epoch 233/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.1108e-04 - val_loss: 6.6392e-04\n",
      "Epoch 234/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.0983e-04 - val_loss: 6.4480e-04\n",
      "Epoch 235/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.4313e-04 - val_loss: 7.2430e-04\n",
      "Epoch 236/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.6906e-04 - val_loss: 6.9468e-04\n",
      "Epoch 237/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3200e-04 - val_loss: 6.5868e-04\n",
      "Epoch 238/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.2012e-04 - val_loss: 6.4510e-04\n",
      "Epoch 239/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.0657e-04 - val_loss: 6.7247e-04\n",
      "Epoch 240/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.4593e-04 - val_loss: 7.5429e-04\n",
      "Epoch 241/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.6221e-04 - val_loss: 6.5433e-04\n",
      "Epoch 242/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1973e-04 - val_loss: 6.4629e-04\n",
      "Epoch 243/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2076e-04 - val_loss: 6.4702e-04\n",
      "Epoch 244/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.2056e-04 - val_loss: 6.7490e-04\n",
      "Epoch 245/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.4253e-04 - val_loss: 6.4013e-04\n",
      "Epoch 246/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1683e-04 - val_loss: 6.3867e-04\n",
      "Epoch 247/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.2111e-04 - val_loss: 6.4392e-04\n",
      "Epoch 248/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.6208e-04 - val_loss: 6.5824e-04\n",
      "Epoch 249/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.2690e-04 - val_loss: 9.1849e-04\n",
      "Epoch 250/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 7.4690e-04 - val_loss: 7.9094e-04\n",
      "Epoch 251/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 7.0714e-04 - val_loss: 6.5704e-04\n",
      "Epoch 252/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.7772e-04 - val_loss: 6.7060e-04\n",
      "Epoch 253/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.4418e-04 - val_loss: 7.6865e-04\n",
      "Epoch 254/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3922e-04 - val_loss: 7.6178e-04\n",
      "Epoch 255/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.3203e-04 - val_loss: 0.0011\n",
      "Epoch 256/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 7.1977e-04 - val_loss: 6.8421e-04\n",
      "Epoch 257/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.3351e-04 - val_loss: 6.4859e-04\n",
      "Epoch 258/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.0488e-04 - val_loss: 7.2342e-04\n",
      "Epoch 259/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1864e-04 - val_loss: 6.5082e-04\n",
      "Epoch 260/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.0248e-04 - val_loss: 6.7729e-04\n",
      "Epoch 261/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 6.1080e-04 - val_loss: 6.4461e-04\n",
      "Epoch 262/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0939e-04 - val_loss: 6.9024e-04\n",
      "Epoch 263/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.1667e-04 - val_loss: 6.8012e-04\n",
      "Epoch 264/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1495e-04 - val_loss: 6.7699e-04\n",
      "Epoch 265/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.1279e-04 - val_loss: 6.7126e-04\n",
      "Epoch 266/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.9996e-04 - val_loss: 6.3975e-04\n",
      "Epoch 267/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1117e-04 - val_loss: 6.5831e-04\n",
      "Epoch 268/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.1437e-04 - val_loss: 7.1657e-04\n",
      "Epoch 269/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.5152e-04 - val_loss: 6.4016e-04\n",
      "Epoch 270/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1168e-04 - val_loss: 6.6129e-04\n",
      "Epoch 271/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.0977e-04 - val_loss: 7.1817e-04\n",
      "Epoch 272/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 6.3295e-04 - val_loss: 6.7439e-04\n",
      "Epoch 273/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.9934e-04 - val_loss: 6.5469e-04\n",
      "Epoch 274/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0681e-04 - val_loss: 6.4405e-04\n",
      "Epoch 275/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0632e-04 - val_loss: 7.3646e-04\n",
      "Epoch 276/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.2476e-04 - val_loss: 6.5391e-04\n",
      "Epoch 277/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1266e-04 - val_loss: 6.6119e-04\n",
      "Epoch 278/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0278e-04 - val_loss: 7.4488e-04\n",
      "Epoch 279/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.8777e-04 - val_loss: 7.6394e-04\n",
      "Epoch 280/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2392e-04 - val_loss: 7.5299e-04\n",
      "Epoch 281/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3051e-04 - val_loss: 7.3208e-04\n",
      "Epoch 282/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0917e-04 - val_loss: 7.3556e-04\n",
      "Epoch 283/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.0229e-04 - val_loss: 6.5214e-04\n",
      "Epoch 284/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.0599e-04 - val_loss: 7.0823e-04\n",
      "Epoch 285/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.1564e-04 - val_loss: 6.4459e-04\n",
      "Epoch 286/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 6.0585e-04 - val_loss: 6.6336e-04\n",
      "Epoch 287/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1640e-04 - val_loss: 6.7317e-04\n",
      "Epoch 288/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.4463e-04 - val_loss: 6.6842e-04\n",
      "Epoch 289/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1361e-04 - val_loss: 6.4057e-04\n",
      "Epoch 290/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0357e-04 - val_loss: 6.8263e-04\n",
      "Epoch 291/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.1386e-04 - val_loss: 7.3520e-04\n",
      "Epoch 292/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0902e-04 - val_loss: 6.4161e-04\n",
      "Epoch 293/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1121e-04 - val_loss: 7.6559e-04\n",
      "Epoch 294/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3451e-04 - val_loss: 7.0957e-04\n",
      "Epoch 295/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.4832e-04 - val_loss: 6.3706e-04\n",
      "Epoch 296/2000\n",
      "3811/3811 [==============================] - 1s 222us/step - loss: 6.1290e-04 - val_loss: 6.3994e-04\n",
      "Epoch 297/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.2159e-04 - val_loss: 7.8655e-04\n",
      "Epoch 298/2000\n",
      "3811/3811 [==============================] - 1s 224us/step - loss: 6.6042e-04 - val_loss: 7.8144e-04\n",
      "Epoch 299/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.4496e-04 - val_loss: 6.8808e-04\n",
      "Epoch 300/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.1399e-04 - val_loss: 6.8919e-04\n",
      "Epoch 301/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1419e-04 - val_loss: 6.7337e-04\n",
      "Epoch 302/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.5263e-04 - val_loss: 6.4238e-04\n",
      "Epoch 303/2000\n",
      "3811/3811 [==============================] - 1s 222us/step - loss: 6.7823e-04 - val_loss: 6.5518e-04\n",
      "Epoch 304/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.3434e-04 - val_loss: 7.0451e-04\n",
      "Epoch 305/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.2927e-04 - val_loss: 6.4620e-04\n",
      "Epoch 306/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.2692e-04 - val_loss: 7.4998e-04\n",
      "Epoch 307/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.5866e-04 - val_loss: 7.0375e-04\n",
      "Epoch 308/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.4971e-04 - val_loss: 6.7781e-04\n",
      "Epoch 309/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.3035e-04 - val_loss: 7.4034e-04\n",
      "Epoch 310/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.5356e-04 - val_loss: 7.1375e-04\n",
      "Epoch 311/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.4211e-04 - val_loss: 7.0802e-04\n",
      "Epoch 312/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.8447e-04 - val_loss: 9.1408e-04\n",
      "Epoch 313/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 6.9587e-04 - val_loss: 6.4105e-04\n",
      "Epoch 314/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0434e-04 - val_loss: 6.4028e-04\n",
      "Epoch 315/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1502e-04 - val_loss: 6.9578e-04\n",
      "Epoch 316/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.9623e-04 - val_loss: 9.1290e-04\n",
      "Epoch 317/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.6212e-04 - val_loss: 6.4040e-04\n",
      "Epoch 318/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.1293e-04 - val_loss: 6.6518e-04\n",
      "Epoch 319/2000\n",
      "3811/3811 [==============================] - 1s 229us/step - loss: 6.1605e-04 - val_loss: 6.9470e-04\n",
      "Epoch 320/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.0552e-04 - val_loss: 6.3834e-04\n",
      "Epoch 321/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.2935e-04 - val_loss: 6.7851e-04\n",
      "Epoch 322/2000\n",
      "3811/3811 [==============================] - 1s 238us/step - loss: 6.1216e-04 - val_loss: 6.3653e-04\n",
      "Epoch 323/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.0088e-04 - val_loss: 6.6441e-04\n",
      "Epoch 324/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.2163e-04 - val_loss: 6.8271e-04\n",
      "Epoch 325/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.4055e-04 - val_loss: 6.4007e-04\n",
      "Epoch 326/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.0146e-04 - val_loss: 6.7632e-04\n",
      "Epoch 327/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.0500e-04 - val_loss: 6.9362e-04\n",
      "Epoch 328/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.1042e-04 - val_loss: 7.3396e-04\n",
      "Epoch 329/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.0968e-04 - val_loss: 7.0166e-04\n",
      "Epoch 330/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.0438e-04 - val_loss: 6.7011e-04\n",
      "Epoch 331/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.1393e-04 - val_loss: 7.0855e-04\n",
      "Epoch 332/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1848e-04 - val_loss: 6.3664e-04\n",
      "Epoch 333/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0934e-04 - val_loss: 8.9671e-04\n",
      "Epoch 334/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.4842e-04 - val_loss: 6.3467e-04\n",
      "Epoch 335/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0595e-04 - val_loss: 6.6136e-04\n",
      "Epoch 336/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.0351e-04 - val_loss: 6.6914e-04\n",
      "Epoch 337/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.2729e-04 - val_loss: 6.3792e-04\n",
      "Epoch 338/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0282e-04 - val_loss: 6.3535e-04\n",
      "Epoch 339/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.1226e-04 - val_loss: 7.1464e-04\n",
      "Epoch 340/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 6.3189e-04 - val_loss: 6.3887e-04\n",
      "Epoch 341/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0860e-04 - val_loss: 6.7272e-04\n",
      "Epoch 342/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3258e-04 - val_loss: 6.7131e-04\n",
      "Epoch 343/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3052e-04 - val_loss: 6.3787e-04\n",
      "Epoch 344/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2694e-04 - val_loss: 7.2530e-04\n",
      "Epoch 345/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0087e-04 - val_loss: 6.4853e-04\n",
      "Epoch 346/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0337e-04 - val_loss: 6.7390e-04\n",
      "Epoch 347/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0287e-04 - val_loss: 6.4465e-04\n",
      "Epoch 348/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.0063e-04 - val_loss: 6.5597e-04\n",
      "Epoch 349/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 6.0671e-04 - val_loss: 6.7390e-04\n",
      "Epoch 350/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.2689e-04 - val_loss: 6.4157e-04\n",
      "Epoch 351/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.1375e-04 - val_loss: 7.2506e-04\n",
      "Epoch 352/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.3577e-04 - val_loss: 7.5735e-04\n",
      "Epoch 353/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.5153e-04 - val_loss: 7.1260e-04\n",
      "Epoch 354/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.1798e-04 - val_loss: 6.5116e-04\n",
      "Epoch 355/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.2301e-04 - val_loss: 6.4108e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.1202e-04 - val_loss: 6.4530e-04\n",
      "Epoch 357/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.0989e-04 - val_loss: 6.6243e-04\n",
      "Epoch 358/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.2028e-04 - val_loss: 7.0345e-04\n",
      "Epoch 359/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2427e-04 - val_loss: 6.6010e-04\n",
      "Epoch 360/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.1661e-04 - val_loss: 6.3950e-04\n",
      "Epoch 361/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0745e-04 - val_loss: 6.3777e-04\n",
      "Epoch 362/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.9511e-04 - val_loss: 7.0507e-04\n",
      "Epoch 363/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.2795e-04 - val_loss: 7.8714e-04\n",
      "Epoch 364/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.6086e-04 - val_loss: 7.0165e-04\n",
      "Epoch 365/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.2049e-04 - val_loss: 6.4986e-04\n",
      "Epoch 366/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1498e-04 - val_loss: 9.7115e-04\n",
      "Epoch 367/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.4814e-04 - val_loss: 6.4597e-04\n",
      "Epoch 368/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.9573e-04 - val_loss: 6.4671e-04\n",
      "Epoch 369/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.2474e-04 - val_loss: 6.4734e-04\n",
      "Epoch 370/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.1763e-04 - val_loss: 7.0000e-04\n",
      "Epoch 371/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.5206e-04 - val_loss: 7.5791e-04\n",
      "Epoch 372/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.5665e-04 - val_loss: 6.6359e-04\n",
      "Epoch 373/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1532e-04 - val_loss: 6.4462e-04\n",
      "Epoch 374/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0290e-04 - val_loss: 6.7024e-04\n",
      "Epoch 375/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1357e-04 - val_loss: 6.4887e-04\n",
      "Epoch 376/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.6508e-04 - val_loss: 7.3922e-04\n",
      "Epoch 377/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 6.5737e-04 - val_loss: 6.9424e-04\n",
      "Epoch 378/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.1114e-04 - val_loss: 6.5166e-04\n",
      "Epoch 379/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.9855e-04 - val_loss: 6.4208e-04\n",
      "Epoch 380/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0479e-04 - val_loss: 8.2671e-04\n",
      "Epoch 381/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2469e-04 - val_loss: 6.4017e-04\n",
      "Epoch 382/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.9811e-04 - val_loss: 6.7145e-04\n",
      "Epoch 383/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0157e-04 - val_loss: 6.7209e-04\n",
      "Epoch 384/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2411e-04 - val_loss: 6.3727e-04\n",
      "Epoch 385/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.9890e-04 - val_loss: 6.4055e-04\n",
      "Epoch 386/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0149e-04 - val_loss: 7.0169e-04\n",
      "Epoch 387/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.2123e-04 - val_loss: 6.4537e-04\n",
      "Epoch 388/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 6.2397e-04 - val_loss: 6.3547e-04\n",
      "Epoch 389/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 5.9658e-04 - val_loss: 7.5781e-04\n",
      "Epoch 390/2000\n",
      "3811/3811 [==============================] - 1s 222us/step - loss: 6.7948e-04 - val_loss: 6.6541e-04\n",
      "Epoch 391/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.6233e-04 - val_loss: 6.4181e-04\n",
      "Epoch 392/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.2216e-04 - val_loss: 8.4575e-04\n",
      "Epoch 393/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.4413e-04 - val_loss: 8.9887e-04\n",
      "Epoch 394/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.4019e-04 - val_loss: 6.8284e-04\n",
      "Epoch 395/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 5.9917e-04 - val_loss: 6.3782e-04\n",
      "Epoch 396/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1489e-04 - val_loss: 6.7178e-04\n",
      "Epoch 397/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.9658e-04 - val_loss: 6.6705e-04\n",
      "Epoch 398/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.0740e-04 - val_loss: 6.7804e-04\n",
      "Epoch 399/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.2990e-04 - val_loss: 6.5283e-04\n",
      "Epoch 400/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.4590e-04 - val_loss: 6.6923e-04\n",
      "Epoch 401/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.9072e-04 - val_loss: 8.5483e-04\n",
      "Epoch 402/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.0196e-04 - val_loss: 8.4797e-04\n",
      "Epoch 403/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.5305e-04 - val_loss: 6.9209e-04\n",
      "Epoch 404/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1253e-04 - val_loss: 6.9340e-04\n",
      "Epoch 405/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.2279e-04 - val_loss: 6.3779e-04\n",
      "Epoch 406/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.0578e-04 - val_loss: 6.6154e-04\n",
      "Epoch 407/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1812e-04 - val_loss: 6.4352e-04\n",
      "Epoch 408/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1795e-04 - val_loss: 6.3355e-04\n",
      "Epoch 409/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0906e-04 - val_loss: 6.3588e-04\n",
      "Epoch 410/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.0224e-04 - val_loss: 6.5181e-04\n",
      "Epoch 411/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0319e-04 - val_loss: 7.2194e-04\n",
      "Epoch 412/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.4807e-04 - val_loss: 6.9944e-04\n",
      "Epoch 413/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.1476e-04 - val_loss: 6.4724e-04\n",
      "Epoch 414/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.0458e-04 - val_loss: 7.9512e-04\n",
      "Epoch 415/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.3528e-04 - val_loss: 6.4163e-04\n",
      "Epoch 416/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.7004e-04 - val_loss: 6.4427e-04\n",
      "Epoch 417/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.7365e-04 - val_loss: 7.3581e-04\n",
      "Epoch 418/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.6283e-04 - val_loss: 7.3133e-04\n",
      "Epoch 419/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.3875e-04 - val_loss: 7.4787e-04\n",
      "Epoch 420/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0088e-04 - val_loss: 6.5495e-04\n",
      "Epoch 421/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 5.9728e-04 - val_loss: 6.3700e-04\n",
      "Epoch 422/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.9975e-04 - val_loss: 6.5058e-04\n",
      "Epoch 423/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.0433e-04 - val_loss: 6.7618e-04\n",
      "Epoch 424/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2742e-04 - val_loss: 6.4774e-04\n",
      "Epoch 425/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.1496e-04 - val_loss: 9.4448e-04\n",
      "Epoch 426/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.2000e-04 - val_loss: 6.6782e-04\n",
      "Epoch 427/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.9441e-04 - val_loss: 6.9358e-04\n",
      "Epoch 428/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.9541e-04 - val_loss: 6.4412e-04\n",
      "Epoch 429/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 5.9916e-04 - val_loss: 6.4006e-04\n",
      "Epoch 430/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 6.0466e-04 - val_loss: 6.9707e-04\n",
      "Epoch 431/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.6306e-04 - val_loss: 0.0010\n",
      "Epoch 432/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.3645e-04 - val_loss: 6.8002e-04\n",
      "Epoch 433/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3794e-04 - val_loss: 6.4149e-04\n",
      "Epoch 434/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.1780e-04 - val_loss: 7.2978e-04\n",
      "Epoch 435/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.2939e-04 - val_loss: 7.6606e-04\n",
      "Epoch 436/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.2440e-04 - val_loss: 6.7167e-04\n",
      "Epoch 437/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.9506e-04 - val_loss: 6.4556e-04\n",
      "Epoch 438/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.0908e-04 - val_loss: 6.4197e-04\n",
      "Epoch 439/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.9844e-04 - val_loss: 7.2740e-04\n",
      "Epoch 440/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.5071e-04 - val_loss: 8.4617e-04\n",
      "Epoch 441/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.3959e-04 - val_loss: 6.3799e-04\n",
      "Epoch 442/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.0598e-04 - val_loss: 7.1967e-04\n",
      "Epoch 443/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.1457e-04 - val_loss: 6.4724e-04\n",
      "Epoch 444/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.9737e-04 - val_loss: 6.4035e-04\n",
      "Epoch 445/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.0172e-04 - val_loss: 6.9032e-04\n",
      "Epoch 446/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1416e-04 - val_loss: 8.0586e-04\n",
      "Epoch 447/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.7851e-04 - val_loss: 8.4080e-04\n",
      "Epoch 448/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.7399e-04 - val_loss: 6.4804e-04\n",
      "Epoch 449/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.3199e-04 - val_loss: 6.3865e-04\n",
      "Epoch 450/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.9915e-04 - val_loss: 6.3537e-04\n",
      "Epoch 451/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.9115e-04 - val_loss: 6.4233e-04\n",
      "Epoch 452/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0035e-04 - val_loss: 6.3118e-04\n",
      "Epoch 453/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 5.9901e-04 - val_loss: 6.3219e-04\n",
      "Epoch 454/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.9772e-04 - val_loss: 6.7345e-04\n",
      "Epoch 455/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1943e-04 - val_loss: 6.8599e-04\n",
      "Epoch 456/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.9454e-04 - val_loss: 6.4807e-04\n",
      "Epoch 457/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.8707e-04 - val_loss: 6.6554e-04\n",
      "Epoch 458/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.0054e-04 - val_loss: 6.4141e-04\n",
      "Epoch 459/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.9679e-04 - val_loss: 6.4091e-04\n",
      "Epoch 460/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1397e-04 - val_loss: 6.8596e-04\n",
      "Epoch 461/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3156e-04 - val_loss: 6.3821e-04\n",
      "Epoch 462/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.1967e-04 - val_loss: 7.7472e-04\n",
      "Epoch 463/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.5027e-04 - val_loss: 7.2502e-04\n",
      "Epoch 464/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.7995e-04 - val_loss: 6.5795e-04\n",
      "Epoch 465/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.6141e-04 - val_loss: 8.1639e-04\n",
      "Epoch 466/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.9359e-04 - val_loss: 7.9420e-04\n",
      "Epoch 467/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3975e-04 - val_loss: 6.3280e-04\n",
      "Epoch 468/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1599e-04 - val_loss: 6.6102e-04\n",
      "Epoch 469/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 6.0954e-04 - val_loss: 6.7840e-04\n",
      "Epoch 470/2000\n",
      "3811/3811 [==============================] - 1s 222us/step - loss: 6.0341e-04 - val_loss: 6.7869e-04\n",
      "Epoch 471/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.9290e-04 - val_loss: 6.5759e-04\n",
      "Epoch 472/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.0601e-04 - val_loss: 6.4660e-04\n",
      "Epoch 473/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 5.9955e-04 - val_loss: 6.5939e-04\n",
      "Epoch 474/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1321e-04 - val_loss: 6.4827e-04\n",
      "Epoch 475/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.9418e-04 - val_loss: 7.4576e-04\n",
      "Epoch 476/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.0918e-04 - val_loss: 6.3725e-04\n",
      "Epoch 477/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.9605e-04 - val_loss: 6.3607e-04\n",
      "Epoch 478/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.8903e-04 - val_loss: 6.3583e-04\n",
      "Epoch 479/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0175e-04 - val_loss: 6.3796e-04\n",
      "Epoch 480/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.0199e-04 - val_loss: 6.4286e-04\n",
      "Epoch 481/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.9202e-04 - val_loss: 6.3482e-04\n",
      "Epoch 482/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.8753e-04 - val_loss: 6.5003e-04\n",
      "Epoch 483/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.9958e-04 - val_loss: 7.4699e-04\n",
      "Epoch 484/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 6.1468e-04 - val_loss: 7.1644e-04\n",
      "Epoch 485/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 6.0287e-04 - val_loss: 7.0535e-04\n",
      "Epoch 486/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 6.0516e-04 - val_loss: 6.6393e-04\n",
      "Epoch 487/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.8549e-04 - val_loss: 6.8880e-04\n",
      "Epoch 488/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.8947e-04 - val_loss: 6.3617e-04\n",
      "Epoch 489/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.0257e-04 - val_loss: 6.6327e-04\n",
      "Epoch 490/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.0534e-04 - val_loss: 6.3391e-04\n",
      "Epoch 491/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3156e-04 - val_loss: 6.4015e-04\n",
      "Epoch 492/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.4265e-04 - val_loss: 6.5819e-04\n",
      "Epoch 493/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1871e-04 - val_loss: 7.2174e-04\n",
      "Epoch 494/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.3458e-04 - val_loss: 6.5825e-04\n",
      "Epoch 495/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.1223e-04 - val_loss: 6.4442e-04\n",
      "Epoch 496/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.1489e-04 - val_loss: 6.3355e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.9177e-04 - val_loss: 6.3037e-04\n",
      "Epoch 498/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.8713e-04 - val_loss: 7.4772e-04\n",
      "Epoch 499/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3959e-04 - val_loss: 6.3919e-04\n",
      "Epoch 500/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.1281e-04 - val_loss: 6.5438e-04\n",
      "Epoch 501/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 6.0952e-04 - val_loss: 6.9993e-04\n",
      "Epoch 502/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 6.0219e-04 - val_loss: 6.3637e-04\n",
      "Epoch 503/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.0795e-04 - val_loss: 6.3039e-04\n",
      "Epoch 504/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 6.1775e-04 - val_loss: 7.5352e-04\n",
      "Epoch 505/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.0620e-04 - val_loss: 6.5674e-04\n",
      "Epoch 506/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.0502e-04 - val_loss: 6.5896e-04\n",
      "Epoch 507/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.0028e-04 - val_loss: 6.6467e-04\n",
      "Epoch 508/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.1634e-04 - val_loss: 6.3104e-04\n",
      "Epoch 509/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.0248e-04 - val_loss: 6.3765e-04\n",
      "Epoch 510/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.8896e-04 - val_loss: 6.8167e-04\n",
      "Epoch 511/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.1799e-04 - val_loss: 7.3292e-04\n",
      "Epoch 512/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.5735e-04 - val_loss: 6.5747e-04\n",
      "Epoch 513/2000\n",
      "3811/3811 [==============================] - 1s 222us/step - loss: 7.1093e-04 - val_loss: 6.2918e-04\n",
      "Epoch 514/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.1785e-04 - val_loss: 7.7548e-04\n",
      "Epoch 515/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.3686e-04 - val_loss: 7.1325e-04\n",
      "Epoch 516/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.5002e-04 - val_loss: 9.8440e-04\n",
      "Epoch 517/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.4270e-04 - val_loss: 7.4698e-04\n",
      "Epoch 518/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.4218e-04 - val_loss: 6.3321e-04\n",
      "Epoch 519/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.1875e-04 - val_loss: 6.3173e-04\n",
      "Epoch 520/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.8574e-04 - val_loss: 7.1299e-04\n",
      "Epoch 521/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.9808e-04 - val_loss: 6.7062e-04\n",
      "Epoch 522/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.9105e-04 - val_loss: 6.3208e-04\n",
      "Epoch 523/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.9631e-04 - val_loss: 7.4561e-04\n",
      "Epoch 524/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.2266e-04 - val_loss: 6.3078e-04\n",
      "Epoch 525/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.8768e-04 - val_loss: 6.4110e-04\n",
      "Epoch 526/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 5.8563e-04 - val_loss: 7.1013e-04\n",
      "Epoch 527/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.2418e-04 - val_loss: 6.6495e-04\n",
      "Epoch 528/2000\n",
      "3811/3811 [==============================] - 1s 225us/step - loss: 5.9958e-04 - val_loss: 6.6990e-04\n",
      "Epoch 529/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 5.8924e-04 - val_loss: 6.4584e-04\n",
      "Epoch 530/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 5.8906e-04 - val_loss: 7.1533e-04\n",
      "Epoch 531/2000\n",
      "3811/3811 [==============================] - 1s 226us/step - loss: 5.9456e-04 - val_loss: 7.1337e-04\n",
      "Epoch 532/2000\n",
      "3811/3811 [==============================] - 1s 231us/step - loss: 6.2323e-04 - val_loss: 6.9278e-04\n",
      "Epoch 533/2000\n",
      "3811/3811 [==============================] - 1s 235us/step - loss: 6.0357e-04 - val_loss: 7.1577e-04\n",
      "Epoch 534/2000\n",
      "3811/3811 [==============================] - 1s 236us/step - loss: 6.3219e-04 - val_loss: 8.0979e-04\n",
      "Epoch 535/2000\n",
      "3811/3811 [==============================] - 1s 228us/step - loss: 6.1353e-04 - val_loss: 6.3734e-04\n",
      "Epoch 536/2000\n",
      "3811/3811 [==============================] - 1s 224us/step - loss: 5.9713e-04 - val_loss: 6.5298e-04\n",
      "Epoch 537/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.0218e-04 - val_loss: 6.3375e-04\n",
      "Epoch 538/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.9029e-04 - val_loss: 6.3392e-04\n",
      "Epoch 539/2000\n",
      "3811/3811 [==============================] - 1s 233us/step - loss: 5.8380e-04 - val_loss: 6.3297e-04\n",
      "Epoch 540/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.9594e-04 - val_loss: 6.4255e-04\n",
      "Epoch 541/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.9391e-04 - val_loss: 6.3542e-04\n",
      "Epoch 542/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.9720e-04 - val_loss: 6.5106e-04\n",
      "Epoch 543/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.0661e-04 - val_loss: 6.5340e-04\n",
      "Epoch 544/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.8442e-04 - val_loss: 6.5059e-04\n",
      "Epoch 545/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.9118e-04 - val_loss: 6.4170e-04\n",
      "Epoch 546/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.8952e-04 - val_loss: 6.8705e-04\n",
      "Epoch 547/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.0360e-04 - val_loss: 6.4115e-04\n",
      "Epoch 548/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.8169e-04 - val_loss: 6.9447e-04\n",
      "Epoch 549/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.0574e-04 - val_loss: 7.2172e-04\n",
      "Epoch 550/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1647e-04 - val_loss: 7.5997e-04\n",
      "Epoch 551/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.1683e-04 - val_loss: 6.4364e-04\n",
      "Epoch 552/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 6.0571e-04 - val_loss: 6.7278e-04\n",
      "Epoch 553/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.3352e-04 - val_loss: 6.4141e-04\n",
      "Epoch 554/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.8927e-04 - val_loss: 6.3116e-04\n",
      "Epoch 555/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.8683e-04 - val_loss: 6.3454e-04\n",
      "Epoch 556/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.8683e-04 - val_loss: 6.4762e-04\n",
      "Epoch 557/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.8318e-04 - val_loss: 6.3694e-04\n",
      "Epoch 558/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.8492e-04 - val_loss: 6.9195e-04\n",
      "Epoch 559/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 5.9880e-04 - val_loss: 6.4992e-04\n",
      "Epoch 560/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.8110e-04 - val_loss: 6.7531e-04\n",
      "Epoch 561/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.1454e-04 - val_loss: 6.9536e-04\n",
      "Epoch 562/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.8765e-04 - val_loss: 6.4755e-04\n",
      "Epoch 563/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0450e-04 - val_loss: 6.6524e-04\n",
      "Epoch 564/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.1023e-04 - val_loss: 6.3561e-04\n",
      "Epoch 565/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 5.9860e-04 - val_loss: 6.7538e-04\n",
      "Epoch 566/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.9507e-04 - val_loss: 6.3813e-04\n",
      "Epoch 567/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.8472e-04 - val_loss: 6.6507e-04\n",
      "Epoch 568/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.9785e-04 - val_loss: 7.0079e-04\n",
      "Epoch 569/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.2152e-04 - val_loss: 6.5175e-04\n",
      "Epoch 570/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 5.8842e-04 - val_loss: 7.6387e-04\n",
      "Epoch 571/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.8101e-04 - val_loss: 7.2018e-04\n",
      "Epoch 572/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 6.4755e-04 - val_loss: 8.2101e-04\n",
      "Epoch 573/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.1294e-04 - val_loss: 8.7411e-04\n",
      "Epoch 574/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.4000e-04 - val_loss: 6.4419e-04\n",
      "Epoch 575/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.0804e-04 - val_loss: 6.3225e-04\n",
      "Epoch 576/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0624e-04 - val_loss: 6.8141e-04\n",
      "Epoch 577/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 6.0522e-04 - val_loss: 0.0010\n",
      "Epoch 578/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.8548e-04 - val_loss: 6.9325e-04\n",
      "Epoch 579/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 6.1755e-04 - val_loss: 6.3780e-04\n",
      "Epoch 580/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.2273e-04 - val_loss: 6.4949e-04\n",
      "Epoch 581/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1255e-04 - val_loss: 6.8386e-04\n",
      "Epoch 582/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.8305e-04 - val_loss: 6.4678e-04\n",
      "Epoch 583/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.9144e-04 - val_loss: 6.8982e-04\n",
      "Epoch 584/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1717e-04 - val_loss: 6.5794e-04\n",
      "Epoch 585/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.9557e-04 - val_loss: 6.6952e-04\n",
      "Epoch 586/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.1123e-04 - val_loss: 6.4019e-04\n",
      "Epoch 587/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 6.5006e-04 - val_loss: 6.4595e-04\n",
      "Epoch 588/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.4615e-04 - val_loss: 6.6802e-04\n",
      "Epoch 589/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 6.0469e-04 - val_loss: 6.8009e-04\n",
      "Epoch 590/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.0522e-04 - val_loss: 6.7370e-04\n",
      "Epoch 591/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.9838e-04 - val_loss: 6.7041e-04\n",
      "Epoch 592/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.7634e-04 - val_loss: 6.5051e-04\n",
      "Epoch 593/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.9411e-04 - val_loss: 6.5557e-04\n",
      "Epoch 594/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.9005e-04 - val_loss: 6.4823e-04\n",
      "Epoch 595/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.8287e-04 - val_loss: 7.7413e-04\n",
      "Epoch 596/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.9424e-04 - val_loss: 6.9272e-04\n",
      "Epoch 597/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.8926e-04 - val_loss: 7.3216e-04\n",
      "Epoch 598/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.0021e-04 - val_loss: 6.5448e-04\n",
      "Epoch 599/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.9141e-04 - val_loss: 8.3149e-04\n",
      "Epoch 600/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0276e-04 - val_loss: 7.0785e-04\n",
      "Epoch 601/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.3180e-04 - val_loss: 7.0267e-04\n",
      "Epoch 602/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.0743e-04 - val_loss: 6.5247e-04\n",
      "Epoch 603/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.8168e-04 - val_loss: 6.6576e-04\n",
      "Epoch 604/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 5.8179e-04 - val_loss: 6.6589e-04\n",
      "Epoch 605/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.9596e-04 - val_loss: 6.5643e-04\n",
      "Epoch 606/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0563e-04 - val_loss: 6.5823e-04\n",
      "Epoch 607/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.9843e-04 - val_loss: 6.5690e-04\n",
      "Epoch 608/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.7479e-04 - val_loss: 6.5790e-04\n",
      "Epoch 609/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 5.9140e-04 - val_loss: 7.4922e-04\n",
      "Epoch 610/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1680e-04 - val_loss: 6.8539e-04\n",
      "Epoch 611/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0666e-04 - val_loss: 7.9009e-04\n",
      "Epoch 612/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2144e-04 - val_loss: 9.1765e-04\n",
      "Epoch 613/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2843e-04 - val_loss: 7.5428e-04\n",
      "Epoch 614/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0162e-04 - val_loss: 6.8877e-04\n",
      "Epoch 615/2000\n",
      "3811/3811 [==============================] - 1s 228us/step - loss: 5.7591e-04 - val_loss: 6.4838e-04\n",
      "Epoch 616/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.6780e-04 - val_loss: 7.2406e-04\n",
      "Epoch 617/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.7865e-04 - val_loss: 6.7183e-04\n",
      "Epoch 618/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.1016e-04 - val_loss: 6.5315e-04\n",
      "Epoch 619/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.8542e-04 - val_loss: 6.8400e-04\n",
      "Epoch 620/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.8817e-04 - val_loss: 7.2865e-04\n",
      "Epoch 621/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.8903e-04 - val_loss: 6.5093e-04\n",
      "Epoch 622/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.9719e-04 - val_loss: 7.4556e-04\n",
      "Epoch 623/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.6706e-04 - val_loss: 7.6057e-04\n",
      "Epoch 624/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.8789e-04 - val_loss: 7.2819e-04\n",
      "Epoch 625/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.9897e-04 - val_loss: 6.5730e-04\n",
      "Epoch 626/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.9626e-04 - val_loss: 6.8290e-04\n",
      "Epoch 627/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.0155e-04 - val_loss: 6.7540e-04\n",
      "Epoch 628/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.8407e-04 - val_loss: 6.5198e-04\n",
      "Epoch 629/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.8424e-04 - val_loss: 6.5330e-04\n",
      "Epoch 630/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.9665e-04 - val_loss: 7.0755e-04\n",
      "Epoch 631/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.7541e-04 - val_loss: 6.7044e-04\n",
      "Epoch 632/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.7195e-04 - val_loss: 6.5700e-04\n",
      "Epoch 633/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.7994e-04 - val_loss: 6.5668e-04\n",
      "Epoch 634/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.8432e-04 - val_loss: 6.5253e-04\n",
      "Epoch 635/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.6661e-04 - val_loss: 6.6563e-04\n",
      "Epoch 636/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.7881e-04 - val_loss: 6.7897e-04\n",
      "Epoch 637/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.7973e-04 - val_loss: 6.8253e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 638/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 5.9057e-04 - val_loss: 7.5402e-04\n",
      "Epoch 639/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.2112e-04 - val_loss: 7.8222e-04\n",
      "Epoch 640/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.6154e-04 - val_loss: 7.2891e-04\n",
      "Epoch 641/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.0951e-04 - val_loss: 6.6807e-04\n",
      "Epoch 642/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.7096e-04 - val_loss: 8.1189e-04\n",
      "Epoch 643/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.4216e-04 - val_loss: 8.6469e-04\n",
      "Epoch 644/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.3416e-04 - val_loss: 8.7204e-04\n",
      "Epoch 645/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.8402e-04 - val_loss: 6.6016e-04\n",
      "Epoch 646/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.5033e-04 - val_loss: 6.5794e-04\n",
      "Epoch 647/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 6.2529e-04 - val_loss: 7.2142e-04\n",
      "Epoch 648/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 6.0432e-04 - val_loss: 7.2214e-04\n",
      "Epoch 649/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.9620e-04 - val_loss: 6.5412e-04\n",
      "Epoch 650/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.0791e-04 - val_loss: 7.7692e-04\n",
      "Epoch 651/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.0141e-04 - val_loss: 6.7760e-04\n",
      "Epoch 652/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.6984e-04 - val_loss: 6.6206e-04\n",
      "Epoch 653/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.5628e-04 - val_loss: 7.0654e-04\n",
      "Epoch 654/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.6276e-04 - val_loss: 6.9372e-04\n",
      "Epoch 655/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 5.7267e-04 - val_loss: 6.7317e-04\n",
      "Epoch 656/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.6647e-04 - val_loss: 7.1649e-04\n",
      "Epoch 657/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.8582e-04 - val_loss: 6.9883e-04\n",
      "Epoch 658/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.5671e-04 - val_loss: 6.9154e-04\n",
      "Epoch 659/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.4992e-04 - val_loss: 6.8057e-04\n",
      "Epoch 660/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.7174e-04 - val_loss: 7.5143e-04\n",
      "Epoch 661/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.5270e-04 - val_loss: 7.8251e-04\n",
      "Epoch 662/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.7452e-04 - val_loss: 6.9687e-04\n",
      "Epoch 663/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 6.0403e-04 - val_loss: 6.8122e-04\n",
      "Epoch 664/2000\n",
      "3811/3811 [==============================] - 1s 222us/step - loss: 5.8831e-04 - val_loss: 7.0691e-04\n",
      "Epoch 665/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 5.7119e-04 - val_loss: 7.0361e-04\n",
      "Epoch 666/2000\n",
      "3811/3811 [==============================] - 1s 226us/step - loss: 5.5315e-04 - val_loss: 7.5847e-04\n",
      "Epoch 667/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.6988e-04 - val_loss: 7.1148e-04\n",
      "Epoch 668/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.6609e-04 - val_loss: 7.0136e-04\n",
      "Epoch 669/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.4721e-04 - val_loss: 7.6808e-04\n",
      "Epoch 670/2000\n",
      "3811/3811 [==============================] - 1s 222us/step - loss: 5.5912e-04 - val_loss: 6.9149e-04\n",
      "Epoch 671/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 5.5188e-04 - val_loss: 7.0493e-04\n",
      "Epoch 672/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.5294e-04 - val_loss: 6.9743e-04\n",
      "Epoch 673/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.3570e-04 - val_loss: 7.5676e-04\n",
      "Epoch 674/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.5411e-04 - val_loss: 7.3439e-04\n",
      "Epoch 675/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.7659e-04 - val_loss: 7.2731e-04\n",
      "Epoch 676/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.5509e-04 - val_loss: 6.8913e-04\n",
      "Epoch 677/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.5493e-04 - val_loss: 7.1984e-04\n",
      "Epoch 678/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 5.4016e-04 - val_loss: 7.2245e-04\n",
      "Epoch 679/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.4977e-04 - val_loss: 7.7663e-04\n",
      "Epoch 680/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 5.6063e-04 - val_loss: 7.4931e-04\n",
      "Epoch 681/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.6012e-04 - val_loss: 7.1662e-04\n",
      "Epoch 682/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.7775e-04 - val_loss: 8.1163e-04\n",
      "Epoch 683/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.6992e-04 - val_loss: 8.2291e-04\n",
      "Epoch 684/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.6363e-04 - val_loss: 7.5695e-04\n",
      "Epoch 685/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.4190e-04 - val_loss: 7.1062e-04\n",
      "Epoch 686/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 5.3685e-04 - val_loss: 7.4403e-04\n",
      "Epoch 687/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.5778e-04 - val_loss: 7.1378e-04\n",
      "Epoch 688/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 5.4139e-04 - val_loss: 7.3941e-04\n",
      "Epoch 689/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.4139e-04 - val_loss: 7.6440e-04\n",
      "Epoch 690/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.6174e-04 - val_loss: 7.9709e-04\n",
      "Epoch 691/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.8367e-04 - val_loss: 8.4855e-04\n",
      "Epoch 692/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.1509e-04 - val_loss: 8.7688e-04\n",
      "Epoch 693/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.9087e-04 - val_loss: 7.9870e-04\n",
      "Epoch 694/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.8747e-04 - val_loss: 6.5509e-04\n",
      "Epoch 695/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 5.4631e-04 - val_loss: 7.5164e-04\n",
      "Epoch 696/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.8311e-04 - val_loss: 7.3807e-04\n",
      "Epoch 697/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.4170e-04 - val_loss: 7.1695e-04\n",
      "Epoch 698/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.2704e-04 - val_loss: 8.0552e-04\n",
      "Epoch 699/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.4178e-04 - val_loss: 8.4403e-04\n",
      "Epoch 700/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 5.7446e-04 - val_loss: 7.4694e-04\n",
      "Epoch 701/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.4364e-04 - val_loss: 7.6737e-04\n",
      "Epoch 702/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.4419e-04 - val_loss: 7.7744e-04\n",
      "Epoch 703/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.3478e-04 - val_loss: 8.3540e-04\n",
      "Epoch 704/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.2680e-04 - val_loss: 8.1737e-04\n",
      "Epoch 705/2000\n",
      "3811/3811 [==============================] - 1s 223us/step - loss: 5.2021e-04 - val_loss: 7.6029e-04\n",
      "Epoch 706/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.1602e-04 - val_loss: 7.6616e-04\n",
      "Epoch 707/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.2014e-04 - val_loss: 8.3507e-04\n",
      "Epoch 708/2000\n",
      "3811/3811 [==============================] - 1s 227us/step - loss: 5.3537e-04 - val_loss: 7.3378e-04\n",
      "Epoch 709/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 5.1443e-04 - val_loss: 7.8872e-04\n",
      "Epoch 710/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 5.2507e-04 - val_loss: 7.7415e-04\n",
      "Epoch 711/2000\n",
      "3811/3811 [==============================] - 1s 264us/step - loss: 5.0940e-04 - val_loss: 8.2670e-04\n",
      "Epoch 712/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.3385e-04 - val_loss: 7.9993e-04\n",
      "Epoch 713/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.2681e-04 - val_loss: 7.5977e-04\n",
      "Epoch 714/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.1512e-04 - val_loss: 8.3411e-04\n",
      "Epoch 715/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.3117e-04 - val_loss: 7.8021e-04\n",
      "Epoch 716/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.1238e-04 - val_loss: 0.0010\n",
      "Epoch 717/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.3227e-04 - val_loss: 9.7977e-04\n",
      "Epoch 718/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.5675e-04 - val_loss: 8.1729e-04\n",
      "Epoch 719/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.2573e-04 - val_loss: 8.7266e-04\n",
      "Epoch 720/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.2779e-04 - val_loss: 8.1663e-04\n",
      "Epoch 721/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.2162e-04 - val_loss: 8.5358e-04\n",
      "Epoch 722/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.8699e-04 - val_loss: 8.0333e-04\n",
      "Epoch 723/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.4513e-04 - val_loss: 7.9537e-04\n",
      "Epoch 724/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 5.3377e-04 - val_loss: 7.7160e-04\n",
      "Epoch 725/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.3575e-04 - val_loss: 8.1580e-04\n",
      "Epoch 726/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.2392e-04 - val_loss: 8.0304e-04\n",
      "Epoch 727/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.6691e-04 - val_loss: 8.0575e-04\n",
      "Epoch 728/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 5.4350e-04 - val_loss: 8.0534e-04\n",
      "Epoch 729/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.1271e-04 - val_loss: 8.7199e-04\n",
      "Epoch 730/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.2902e-04 - val_loss: 8.1758e-04\n",
      "Epoch 731/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.3217e-04 - val_loss: 8.2103e-04\n",
      "Epoch 732/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.1111e-04 - val_loss: 8.7854e-04\n",
      "Epoch 733/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.2901e-04 - val_loss: 8.0831e-04\n",
      "Epoch 734/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.4149e-04 - val_loss: 8.1310e-04\n",
      "Epoch 735/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.1865e-04 - val_loss: 8.4996e-04\n",
      "Epoch 736/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.1818e-04 - val_loss: 9.7183e-04\n",
      "Epoch 737/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.3159e-04 - val_loss: 9.2099e-04\n",
      "Epoch 738/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.2273e-04 - val_loss: 8.5264e-04\n",
      "Epoch 739/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.0258e-04 - val_loss: 9.1871e-04\n",
      "Epoch 740/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.3070e-04 - val_loss: 9.3519e-04\n",
      "Epoch 741/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.1333e-04 - val_loss: 8.8350e-04\n",
      "Epoch 742/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.0650e-04 - val_loss: 8.1071e-04\n",
      "Epoch 743/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 5.0411e-04 - val_loss: 9.2410e-04\n",
      "Epoch 744/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 5.1758e-04 - val_loss: 9.0635e-04\n",
      "Epoch 745/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.0042e-04 - val_loss: 8.1955e-04\n",
      "Epoch 746/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.0324e-04 - val_loss: 8.7127e-04\n",
      "Epoch 747/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.2136e-04 - val_loss: 9.2669e-04\n",
      "Epoch 748/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.1830e-04 - val_loss: 9.7668e-04\n",
      "Epoch 749/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.1424e-04 - val_loss: 9.0856e-04\n",
      "Epoch 750/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.9608e-04 - val_loss: 9.4754e-04\n",
      "Epoch 751/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 4.9682e-04 - val_loss: 0.0010\n",
      "Epoch 752/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.1454e-04 - val_loss: 0.0012\n",
      "Epoch 753/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.4004e-04 - val_loss: 0.0011\n",
      "Epoch 754/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.2485e-04 - val_loss: 0.0012\n",
      "Epoch 755/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 5.0584e-04 - val_loss: 0.0012\n",
      "Epoch 756/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 5.1783e-04 - val_loss: 9.9406e-04\n",
      "Epoch 757/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.9192e-04 - val_loss: 0.0010\n",
      "Epoch 758/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.0213e-04 - val_loss: 0.0010\n",
      "Epoch 759/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 5.0695e-04 - val_loss: 0.0012\n",
      "Epoch 760/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.0255e-04 - val_loss: 0.0010\n",
      "Epoch 761/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.0541e-04 - val_loss: 0.0011\n",
      "Epoch 762/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.0787e-04 - val_loss: 9.8937e-04\n",
      "Epoch 763/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.1080e-04 - val_loss: 0.0011\n",
      "Epoch 764/2000\n",
      "3811/3811 [==============================] - 1s 224us/step - loss: 4.9848e-04 - val_loss: 0.0011\n",
      "Epoch 765/2000\n",
      "3811/3811 [==============================] - 1s 223us/step - loss: 4.9811e-04 - val_loss: 0.0011\n",
      "Epoch 766/2000\n",
      "3811/3811 [==============================] - 1s 223us/step - loss: 4.9960e-04 - val_loss: 0.0013\n",
      "Epoch 767/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 5.6905e-04 - val_loss: 0.0010\n",
      "Epoch 768/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.1436e-04 - val_loss: 0.0011\n",
      "Epoch 769/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 4.8264e-04 - val_loss: 0.0010\n",
      "Epoch 770/2000\n",
      "3811/3811 [==============================] - 1s 230us/step - loss: 4.8719e-04 - val_loss: 0.0010\n",
      "Epoch 771/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 4.8798e-04 - val_loss: 0.0011\n",
      "Epoch 772/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 4.6708e-04 - val_loss: 0.0011\n",
      "Epoch 773/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.8012e-04 - val_loss: 0.0011\n",
      "Epoch 774/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 4.9185e-04 - val_loss: 0.0011\n",
      "Epoch 775/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 4.7606e-04 - val_loss: 0.0012\n",
      "Epoch 776/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 4.6049e-04 - val_loss: 0.0011\n",
      "Epoch 777/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 4.8962e-04 - val_loss: 0.0011\n",
      "Epoch 778/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 4.7892e-04 - val_loss: 0.0012\n",
      "Epoch 779/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 220us/step - loss: 4.7323e-04 - val_loss: 0.0013\n",
      "Epoch 780/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.9381e-04 - val_loss: 0.0012\n",
      "Epoch 781/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 4.8319e-04 - val_loss: 0.0012\n",
      "Epoch 782/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 4.6806e-04 - val_loss: 0.0011\n",
      "Epoch 783/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 4.6875e-04 - val_loss: 0.0013\n",
      "Epoch 784/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 4.7342e-04 - val_loss: 0.0013\n",
      "Epoch 785/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 5.1068e-04 - val_loss: 0.0011\n",
      "Epoch 786/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 4.9548e-04 - val_loss: 0.0012\n",
      "Epoch 787/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 4.9726e-04 - val_loss: 0.0011\n",
      "Epoch 788/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 5.1739e-04 - val_loss: 0.0011\n",
      "Epoch 789/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.8357e-04 - val_loss: 0.0011\n",
      "Epoch 790/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.6306e-04 - val_loss: 0.0012\n",
      "Epoch 791/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.6183e-04 - val_loss: 0.0011\n",
      "Epoch 792/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.7219e-04 - val_loss: 0.0015\n",
      "Epoch 793/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.0635e-04 - val_loss: 0.0012\n",
      "Epoch 794/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 4.9752e-04 - val_loss: 0.0012\n",
      "Epoch 795/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 5.1315e-04 - val_loss: 0.0013\n",
      "Epoch 796/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.8948e-04 - val_loss: 0.0015\n",
      "Epoch 797/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.8759e-04 - val_loss: 0.0014\n",
      "Epoch 798/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.9321e-04 - val_loss: 0.0016\n",
      "Epoch 799/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.8800e-04 - val_loss: 0.0016\n",
      "Epoch 800/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.8175e-04 - val_loss: 0.0013\n",
      "Epoch 801/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.7283e-04 - val_loss: 0.0014\n",
      "Epoch 802/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 4.7604e-04 - val_loss: 0.0017\n",
      "Epoch 803/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 5.2233e-04 - val_loss: 0.0017\n",
      "Epoch 804/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 5.0995e-04 - val_loss: 0.0011\n",
      "Epoch 805/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 5.0509e-04 - val_loss: 0.0013\n",
      "Epoch 806/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 4.8706e-04 - val_loss: 0.0013\n",
      "Epoch 807/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 4.6040e-04 - val_loss: 0.0012-\n",
      "Epoch 808/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 4.7655e-04 - val_loss: 0.0014\n",
      "Epoch 809/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 5.2453e-04 - val_loss: 0.0014\n",
      "Epoch 810/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 5.2557e-04 - val_loss: 0.0013\n",
      "Epoch 811/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 4.9129e-04 - val_loss: 0.0014\n",
      "Epoch 812/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 4.7677e-04 - val_loss: 0.0014\n",
      "Epoch 813/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.7109e-04 - val_loss: 0.0013\n",
      "Epoch 814/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 4.5858e-04 - val_loss: 0.0015\n",
      "Epoch 815/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 4.5065e-04 - val_loss: 0.0016\n",
      "Epoch 816/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.4477e-04 - val_loss: 0.0015\n",
      "Epoch 817/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.3569e-04 - val_loss: 0.0016\n",
      "Epoch 818/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.4932e-04 - val_loss: 0.0015\n",
      "Epoch 819/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 4.4920e-04 - val_loss: 0.0019\n",
      "Epoch 820/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 4.5626e-04 - val_loss: 0.0016\n",
      "Epoch 821/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 4.4565e-04 - val_loss: 0.0016\n",
      "Epoch 822/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.3862e-04 - val_loss: 0.0015\n",
      "Epoch 823/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.1855e-04 - val_loss: 0.0016\n",
      "Epoch 824/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.3637e-04 - val_loss: 0.0018\n",
      "Epoch 825/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 4.4127e-04 - val_loss: 0.0017\n",
      "Epoch 826/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 4.2371e-04 - val_loss: 0.0019\n",
      "Epoch 827/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 4.4547e-04 - val_loss: 0.0016\n",
      "Epoch 828/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.3255e-04 - val_loss: 0.0017\n",
      "Epoch 829/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.2817e-04 - val_loss: 0.0018\n",
      "Epoch 830/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.2420e-04 - val_loss: 0.0022\n",
      "Epoch 831/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.2338e-04 - val_loss: 0.0018\n",
      "Epoch 832/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.2268e-04 - val_loss: 0.0017\n",
      "Epoch 833/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.4053e-04 - val_loss: 0.0020\n",
      "Epoch 834/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 4.6222e-04 - val_loss: 0.0017\n",
      "Epoch 835/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 4.4479e-04 - val_loss: 0.0017\n",
      "Epoch 836/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 4.5004e-04 - val_loss: 0.0016\n",
      "Epoch 837/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.4296e-04 - val_loss: 0.0017\n",
      "Epoch 838/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.2284e-04 - val_loss: 0.0022\n",
      "Epoch 839/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 4.3406e-04 - val_loss: 0.0021\n",
      "Epoch 840/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 4.4122e-04 - val_loss: 0.0024\n",
      "Epoch 841/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 4.5170e-04 - val_loss: 0.0021\n",
      "Epoch 842/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.3131e-04 - val_loss: 0.0018\n",
      "Epoch 843/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 4.3246e-04 - val_loss: 0.0019\n",
      "Epoch 844/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.2058e-04 - val_loss: 0.0019\n",
      "Epoch 845/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.1282e-04 - val_loss: 0.0017\n",
      "Epoch 846/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.0198e-04 - val_loss: 0.0017\n",
      "Epoch 847/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 3.9756e-04 - val_loss: 0.0020\n",
      "Epoch 848/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.0307e-04 - val_loss: 0.0020\n",
      "Epoch 849/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.9379e-04 - val_loss: 0.0021\n",
      "Epoch 850/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 3.9535e-04 - val_loss: 0.0020\n",
      "Epoch 851/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.1626e-04 - val_loss: 0.0018\n",
      "Epoch 852/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 3.9993e-04 - val_loss: 0.0019\n",
      "Epoch 853/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.1521e-04 - val_loss: 0.0020\n",
      "Epoch 854/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.1078e-04 - val_loss: 0.0021\n",
      "Epoch 855/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 3.9739e-04 - val_loss: 0.0021\n",
      "Epoch 856/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.9468e-04 - val_loss: 0.0019\n",
      "Epoch 857/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 3.9975e-04 - val_loss: 0.0020\n",
      "Epoch 858/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 3.9885e-04 - val_loss: 0.0023\n",
      "Epoch 859/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.9350e-04 - val_loss: 0.0021\n",
      "Epoch 860/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 3.9842e-04 - val_loss: 0.0022\n",
      "Epoch 861/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 4.1586e-04 - val_loss: 0.0026\n",
      "Epoch 862/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 4.1553e-04 - val_loss: 0.0023\n",
      "Epoch 863/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.0317e-04 - val_loss: 0.0021\n",
      "Epoch 864/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.2685e-04 - val_loss: 0.0023\n",
      "Epoch 865/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 4.0892e-04 - val_loss: 0.0018\n",
      "Epoch 866/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.9347e-04 - val_loss: 0.0026\n",
      "Epoch 867/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.8585e-04 - val_loss: 0.0024\n",
      "Epoch 868/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.8697e-04 - val_loss: 0.0026\n",
      "Epoch 869/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.0678e-04 - val_loss: 0.0023\n",
      "Epoch 870/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.1014e-04 - val_loss: 0.0022\n",
      "Epoch 871/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.0866e-04 - val_loss: 0.0023\n",
      "Epoch 872/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.1856e-04 - val_loss: 0.0027\n",
      "Epoch 873/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 4.4698e-04 - val_loss: 0.0024\n",
      "Epoch 874/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.1319e-04 - val_loss: 0.0025\n",
      "Epoch 875/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 4.1078e-04 - val_loss: 0.0021\n",
      "Epoch 876/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.1107e-04 - val_loss: 0.0019\n",
      "Epoch 877/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 3.9241e-04 - val_loss: 0.0022\n",
      "Epoch 878/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 3.8790e-04 - val_loss: 0.0024\n",
      "Epoch 879/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.7983e-04 - val_loss: 0.0022\n",
      "Epoch 880/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 3.6684e-04 - val_loss: 0.0025\n",
      "Epoch 881/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.0186e-04 - val_loss: 0.0028\n",
      "Epoch 882/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.2722e-04 - val_loss: 0.0028\n",
      "Epoch 883/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 4.8723e-04 - val_loss: 0.0028\n",
      "Epoch 884/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 4.1482e-04 - val_loss: 0.0026\n",
      "Epoch 885/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 4.1728e-04 - val_loss: 0.0023\n",
      "Epoch 886/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.9361e-04 - val_loss: 0.0023\n",
      "Epoch 887/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 3.7555e-04 - val_loss: 0.0021\n",
      "Epoch 888/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.8331e-04 - val_loss: 0.0026\n",
      "Epoch 889/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.8304e-04 - val_loss: 0.0027\n",
      "Epoch 890/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.7406e-04 - val_loss: 0.0024\n",
      "Epoch 891/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 3.5947e-04 - val_loss: 0.0029\n",
      "Epoch 892/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 3.6241e-04 - val_loss: 0.0023\n",
      "Epoch 893/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.6616e-04 - val_loss: 0.0025\n",
      "Epoch 894/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 3.8270e-04 - val_loss: 0.0029\n",
      "Epoch 895/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.6520e-04 - val_loss: 0.0025\n",
      "Epoch 896/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 3.6348e-04 - val_loss: 0.0026\n",
      "Epoch 897/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 3.5942e-04 - val_loss: 0.0026\n",
      "Epoch 898/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 3.6451e-04 - val_loss: 0.0027\n",
      "Epoch 899/2000\n",
      "3811/3811 [==============================] - 1s 229us/step - loss: 3.7159e-04 - val_loss: 0.0031\n",
      "Epoch 900/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 3.7556e-04 - val_loss: 0.0028\n",
      "Epoch 901/2000\n",
      "3811/3811 [==============================] - 1s 224us/step - loss: 3.9594e-04 - val_loss: 0.0029\n",
      "Epoch 902/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 3.9875e-04 - val_loss: 0.0022\n",
      "Epoch 903/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 4.1381e-04 - val_loss: 0.0025\n",
      "Epoch 904/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 3.9917e-04 - val_loss: 0.0029\n",
      "Epoch 905/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 3.8569e-04 - val_loss: 0.0029\n",
      "Epoch 906/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 3.7780e-04 - val_loss: 0.0027\n",
      "Epoch 907/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 3.5391e-04 - val_loss: 0.0029\n",
      "Epoch 908/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 3.5265e-04 - val_loss: 0.0025\n",
      "Epoch 909/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 3.5824e-04 - val_loss: 0.0030\n",
      "Epoch 910/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 3.5199e-04 - val_loss: 0.0029\n",
      "Epoch 911/2000\n",
      "3811/3811 [==============================] - 1s 226us/step - loss: 3.5969e-04 - val_loss: 0.0031\n",
      "Epoch 912/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.5997e-04 - val_loss: 0.0026\n",
      "Epoch 913/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.6330e-04 - val_loss: 0.0030\n",
      "Epoch 914/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.5710e-04 - val_loss: 0.0029\n",
      "Epoch 915/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 3.3486e-04 - val_loss: 0.0035\n",
      "Epoch 916/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 3.3898e-04 - val_loss: 0.0032\n",
      "Epoch 917/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 3.5393e-04 - val_loss: 0.0027\n",
      "Epoch 918/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 3.4457e-04 - val_loss: 0.0030\n",
      "Epoch 919/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 3.3821e-04 - val_loss: 0.0028\n",
      "Epoch 920/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 3.3491e-04 - val_loss: 0.0031\n",
      "Epoch 921/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 3.4493e-04 - val_loss: 0.0030\n",
      "Epoch 922/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 3.3106e-04 - val_loss: 0.0034\n",
      "Epoch 923/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 3.3400e-04 - val_loss: 0.0033\n",
      "Epoch 924/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.4261e-04 - val_loss: 0.0027\n",
      "Epoch 925/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 227us/step - loss: 3.4973e-04 - val_loss: 0.0032\n",
      "Epoch 926/2000\n",
      "3811/3811 [==============================] - 1s 223us/step - loss: 3.5484e-04 - val_loss: 0.0033\n",
      "Epoch 927/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 3.5357e-04 - val_loss: 0.0027\n",
      "Epoch 928/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.7682e-04 - val_loss: 0.0028\n",
      "Epoch 929/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 3.6423e-04 - val_loss: 0.0031\n",
      "Epoch 930/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 3.5397e-04 - val_loss: 0.0028\n",
      "Epoch 931/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 3.5862e-04 - val_loss: 0.0027\n",
      "Epoch 932/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.5240e-04 - val_loss: 0.0029\n",
      "Epoch 933/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 3.4227e-04 - val_loss: 0.0027\n",
      "Epoch 934/2000\n",
      "3811/3811 [==============================] - 1s 224us/step - loss: 3.3190e-04 - val_loss: 0.0027\n",
      "Epoch 935/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 3.4971e-04 - val_loss: 0.0030\n",
      "Epoch 936/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 3.9179e-04 - val_loss: 0.0028\n",
      "Epoch 937/2000\n",
      "3811/3811 [==============================] - 1s 237us/step - loss: 3.8385e-04 - val_loss: 0.0033\n",
      "Epoch 938/2000\n",
      "3811/3811 [==============================] - 1s 235us/step - loss: 3.8079e-04 - val_loss: 0.0027\n",
      "Epoch 939/2000\n",
      "3811/3811 [==============================] - 1s 222us/step - loss: 3.8160e-04 - val_loss: 0.0035\n",
      "Epoch 940/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 3.6110e-04 - val_loss: 0.0031\n",
      "Epoch 941/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.4650e-04 - val_loss: 0.0030\n",
      "Epoch 942/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 3.5473e-04 - val_loss: 0.0030\n",
      "Epoch 943/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 3.3630e-04 - val_loss: 0.0027\n",
      "Epoch 944/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.2556e-04 - val_loss: 0.0030\n",
      "Epoch 945/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 3.3017e-04 - val_loss: 0.0034\n",
      "Epoch 946/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.2714e-04 - val_loss: 0.0030\n",
      "Epoch 947/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 3.2998e-04 - val_loss: 0.0027\n",
      "Epoch 948/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 3.3887e-04 - val_loss: 0.0029\n",
      "Epoch 949/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 3.4557e-04 - val_loss: 0.0030\n",
      "Epoch 950/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 3.1435e-04 - val_loss: 0.0033\n",
      "Epoch 951/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 3.0198e-04 - val_loss: 0.0028\n",
      "Epoch 952/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 3.4131e-04 - val_loss: 0.0030\n",
      "Epoch 953/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.0793e-04 - val_loss: 0.0031\n",
      "Epoch 954/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 3.2831e-04 - val_loss: 0.0037\n",
      "Epoch 955/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 3.2129e-04 - val_loss: 0.0036\n",
      "Epoch 956/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 3.2614e-04 - val_loss: 0.0031\n",
      "Epoch 957/2000\n",
      "3811/3811 [==============================] - 1s 223us/step - loss: 3.1611e-04 - val_loss: 0.0029\n",
      "Epoch 958/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 3.1508e-04 - val_loss: 0.0034\n",
      "Epoch 959/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 3.1433e-04 - val_loss: 0.0034\n",
      "Epoch 960/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 3.1120e-04 - val_loss: 0.0031\n",
      "Epoch 961/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 3.3025e-04 - val_loss: 0.0036\n",
      "Epoch 962/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 3.3553e-04 - val_loss: 0.0035\n",
      "Epoch 963/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 3.2196e-04 - val_loss: 0.0034\n",
      "Epoch 964/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 3.1433e-04 - val_loss: 0.0029\n",
      "Epoch 965/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 3.0972e-04 - val_loss: 0.0033\n",
      "Epoch 966/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 3.1048e-04 - val_loss: 0.0029\n",
      "Epoch 967/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 3.1332e-04 - val_loss: 0.0036\n",
      "Epoch 968/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 3.2504e-04 - val_loss: 0.0038\n",
      "Epoch 969/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 3.0384e-04 - val_loss: 0.0033\n",
      "Epoch 970/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 3.0248e-04 - val_loss: 0.0035\n",
      "Epoch 971/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 3.0628e-04 - val_loss: 0.0032\n",
      "Epoch 972/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 3.0236e-04 - val_loss: 0.0036\n",
      "Epoch 973/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 2.9767e-04 - val_loss: 0.0034\n",
      "Epoch 974/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 3.0322e-04 - val_loss: 0.0033\n",
      "Epoch 975/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 2.9580e-04 - val_loss: 0.0030\n",
      "Epoch 976/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 2.9452e-04 - val_loss: 0.0034\n",
      "Epoch 977/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 3.2153e-04 - val_loss: 0.0034\n",
      "Epoch 978/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 3.3870e-04 - val_loss: 0.0031\n",
      "Epoch 979/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 3.1648e-04 - val_loss: 0.0038\n",
      "Epoch 980/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 3.1298e-04 - val_loss: 0.0035\n",
      "Epoch 981/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 3.0785e-04 - val_loss: 0.0032\n",
      "Epoch 982/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 3.0715e-04 - val_loss: 0.0034\n",
      "Epoch 983/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 3.1427e-04 - val_loss: 0.0032\n",
      "Epoch 984/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 3.0425e-04 - val_loss: 0.0035\n",
      "Epoch 985/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.8518e-04 - val_loss: 0.0033\n",
      "Epoch 986/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 3.0449e-04 - val_loss: 0.0029\n",
      "Epoch 987/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.9975e-04 - val_loss: 0.0034\n",
      "Epoch 988/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.8797e-04 - val_loss: 0.0038\n",
      "Epoch 989/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.9274e-04 - val_loss: 0.0034\n",
      "Epoch 990/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 3.0609e-04 - val_loss: 0.0036\n",
      "Epoch 991/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.9761e-04 - val_loss: 0.0037\n",
      "Epoch 992/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 3.0163e-04 - val_loss: 0.0035\n",
      "Epoch 993/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 2.8249e-04 - val_loss: 0.0030\n",
      "Epoch 994/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 3.0301e-04 - val_loss: 0.0035\n",
      "Epoch 995/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.9004e-04 - val_loss: 0.0033\n",
      "Epoch 996/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.8623e-04 - val_loss: 0.0032\n",
      "Epoch 997/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 2.9705e-04 - val_loss: 0.0031\n",
      "Epoch 998/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 3.1523e-04 - val_loss: 0.0031\n",
      "Epoch 999/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 3.1155e-04 - val_loss: 0.0042\n",
      "Epoch 1000/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 3.1534e-04 - val_loss: 0.0038\n",
      "Epoch 1001/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 3.0148e-04 - val_loss: 0.0036\n",
      "Epoch 1002/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.8119e-04 - val_loss: 0.0038\n",
      "Epoch 1003/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.7379e-04 - val_loss: 0.0035\n",
      "Epoch 1004/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.8079e-04 - val_loss: 0.0035\n",
      "Epoch 1005/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.8209e-04 - val_loss: 0.0041\n",
      "Epoch 1006/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.7386e-04 - val_loss: 0.0038\n",
      "Epoch 1007/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.7082e-04 - val_loss: 0.0033\n",
      "Epoch 1008/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.8059e-04 - val_loss: 0.0037\n",
      "Epoch 1009/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.9733e-04 - val_loss: 0.0030\n",
      "Epoch 1010/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 3.0110e-04 - val_loss: 0.0032\n",
      "Epoch 1011/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 3.1440e-04 - val_loss: 0.0039\n",
      "Epoch 1012/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.8711e-04 - val_loss: 0.0041\n",
      "Epoch 1013/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.8360e-04 - val_loss: 0.0038\n",
      "Epoch 1014/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.8797e-04 - val_loss: 0.0031\n",
      "Epoch 1015/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 3.0736e-04 - val_loss: 0.0035\n",
      "Epoch 1016/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.8005e-04 - val_loss: 0.0040\n",
      "Epoch 1017/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 2.5430e-04 - val_loss: 0.0037\n",
      "Epoch 1018/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.7080e-04 - val_loss: 0.0041\n",
      "Epoch 1019/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.8982e-04 - val_loss: 0.0037\n",
      "Epoch 1020/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.8758e-04 - val_loss: 0.0031\n",
      "Epoch 1021/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.9395e-04 - val_loss: 0.0037\n",
      "Epoch 1022/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.9132e-04 - val_loss: 0.0037\n",
      "Epoch 1023/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.7274e-04 - val_loss: 0.0040\n",
      "Epoch 1024/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.8512e-04 - val_loss: 0.0035\n",
      "Epoch 1025/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.9276e-04 - val_loss: 0.0040\n",
      "Epoch 1026/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 2.9767e-04 - val_loss: 0.0036\n",
      "Epoch 1027/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.6887e-04 - val_loss: 0.0037\n",
      "Epoch 1028/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.6063e-04 - val_loss: 0.0038\n",
      "Epoch 1029/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.4921e-04 - val_loss: 0.0043\n",
      "Epoch 1030/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.6737e-04 - val_loss: 0.0038\n",
      "Epoch 1031/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.7686e-04 - val_loss: 0.0041\n",
      "Epoch 1032/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.7596e-04 - val_loss: 0.0042\n",
      "Epoch 1033/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 2.7452e-04 - val_loss: 0.0042\n",
      "Epoch 1034/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.6851e-04 - val_loss: 0.0042\n",
      "Epoch 1035/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.7251e-04 - val_loss: 0.0033\n",
      "Epoch 1036/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.7804e-04 - val_loss: 0.0038\n",
      "Epoch 1037/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 2.7154e-04 - val_loss: 0.0039\n",
      "Epoch 1038/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.6533e-04 - val_loss: 0.0039\n",
      "Epoch 1039/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 2.5512e-04 - val_loss: 0.0042\n",
      "Epoch 1040/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.5065e-04 - val_loss: 0.0039\n",
      "Epoch 1041/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.5605e-04 - val_loss: 0.0036\n",
      "Epoch 1042/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.4578e-04 - val_loss: 0.0041\n",
      "Epoch 1043/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.3939e-04 - val_loss: 0.0044\n",
      "Epoch 1044/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 2.4722e-04 - val_loss: 0.0041\n",
      "Epoch 1045/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.5238e-04 - val_loss: 0.0043\n",
      "Epoch 1046/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.4328e-04 - val_loss: 0.0041\n",
      "Epoch 1047/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.4718e-04 - val_loss: 0.0040\n",
      "Epoch 1048/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.5639e-04 - val_loss: 0.0038\n",
      "Epoch 1049/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.5620e-04 - val_loss: 0.0045\n",
      "Epoch 1050/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.5726e-04 - val_loss: 0.0040\n",
      "Epoch 1051/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.4660e-04 - val_loss: 0.0045\n",
      "Epoch 1052/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 2.4760e-04 - val_loss: 0.0045\n",
      "Epoch 1053/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.5755e-04 - val_loss: 0.0043\n",
      "Epoch 1054/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.6221e-04 - val_loss: 0.0040\n",
      "Epoch 1055/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.5044e-04 - val_loss: 0.0042\n",
      "Epoch 1056/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.6930e-04 - val_loss: 0.0047\n",
      "Epoch 1057/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 2.5930e-04 - val_loss: 0.0044\n",
      "Epoch 1058/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.6951e-04 - val_loss: 0.0044\n",
      "Epoch 1059/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 2.3955e-04 - val_loss: 0.0041\n",
      "Epoch 1060/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 2.4542e-04 - val_loss: 0.0043\n",
      "Epoch 1061/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 2.5839e-04 - val_loss: 0.0036\n",
      "Epoch 1062/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.7103e-04 - val_loss: 0.0041\n",
      "Epoch 1063/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.5640e-04 - val_loss: 0.0043\n",
      "Epoch 1064/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.4358e-04 - val_loss: 0.0041\n",
      "Epoch 1065/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.4431e-04 - val_loss: 0.0041\n",
      "Epoch 1066/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.3021e-04 - val_loss: 0.0042\n",
      "Epoch 1067/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.3680e-04 - val_loss: 0.0046\n",
      "Epoch 1068/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.3282e-04 - val_loss: 0.0044\n",
      "Epoch 1069/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.2830e-04 - val_loss: 0.0043\n",
      "Epoch 1070/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.4274e-04 - val_loss: 0.0040\n",
      "Epoch 1071/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.6920e-04 - val_loss: 0.0044\n",
      "Epoch 1072/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.5866e-04 - val_loss: 0.0047\n",
      "Epoch 1073/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.3855e-04 - val_loss: 0.0038\n",
      "Epoch 1074/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.2802e-04 - val_loss: 0.0044\n",
      "Epoch 1075/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 2.2190e-04 - val_loss: 0.0047\n",
      "Epoch 1076/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.2895e-04 - val_loss: 0.0043\n",
      "Epoch 1077/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 2.3574e-04 - val_loss: 0.0050\n",
      "Epoch 1078/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.3652e-04 - val_loss: 0.0046\n",
      "Epoch 1079/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.2325e-04 - val_loss: 0.0046\n",
      "Epoch 1080/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.2547e-04 - val_loss: 0.0044\n",
      "Epoch 1081/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.1482e-04 - val_loss: 0.0044\n",
      "Epoch 1082/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.2637e-04 - val_loss: 0.0045\n",
      "Epoch 1083/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.4528e-04 - val_loss: 0.0048\n",
      "Epoch 1084/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.2934e-04 - val_loss: 0.0053\n",
      "Epoch 1085/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.3716e-04 - val_loss: 0.0053\n",
      "Epoch 1086/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.3138e-04 - val_loss: 0.0045\n",
      "Epoch 1087/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.3989e-04 - val_loss: 0.0046\n",
      "Epoch 1088/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.2533e-04 - val_loss: 0.0046\n",
      "Epoch 1089/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.2074e-04 - val_loss: 0.0047\n",
      "Epoch 1090/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.1076e-04 - val_loss: 0.0050\n",
      "Epoch 1091/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.2243e-04 - val_loss: 0.0048\n",
      "Epoch 1092/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.3145e-04 - val_loss: 0.0045\n",
      "Epoch 1093/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.2012e-04 - val_loss: 0.0047\n",
      "Epoch 1094/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.2357e-04 - val_loss: 0.0050\n",
      "Epoch 1095/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.2526e-04 - val_loss: 0.0049\n",
      "Epoch 1096/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 2.6306e-04 - val_loss: 0.0047\n",
      "Epoch 1097/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 2.4600e-04 - val_loss: 0.0043\n",
      "Epoch 1098/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 2.2624e-04 - val_loss: 0.0043\n",
      "Epoch 1099/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.3074e-04 - val_loss: 0.0049\n",
      "Epoch 1100/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.1279e-04 - val_loss: 0.0046\n",
      "Epoch 1101/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 2.1695e-04 - val_loss: 0.0050\n",
      "Epoch 1102/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.1617e-04 - val_loss: 0.0050\n",
      "Epoch 1103/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.1603e-04 - val_loss: 0.0052\n",
      "Epoch 1104/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 2.1547e-04 - val_loss: 0.0046\n",
      "Epoch 1105/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 2.0420e-04 - val_loss: 0.0049\n",
      "Epoch 1106/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 2.1045e-04 - val_loss: 0.0049\n",
      "Epoch 1107/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 2.1233e-04 - val_loss: 0.0051\n",
      "Epoch 1108/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.0647e-04 - val_loss: 0.0045\n",
      "Epoch 1109/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.0095e-04 - val_loss: 0.0051\n",
      "Epoch 1110/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.9952e-04 - val_loss: 0.0049\n",
      "Epoch 1111/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.1446e-04 - val_loss: 0.0048\n",
      "Epoch 1112/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.2694e-04 - val_loss: 0.0057\n",
      "Epoch 1113/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.2274e-04 - val_loss: 0.0046\n",
      "Epoch 1114/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 2.2495e-04 - val_loss: 0.0046\n",
      "Epoch 1115/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 2.2574e-04 - val_loss: 0.0052\n",
      "Epoch 1116/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.1502e-04 - val_loss: 0.0048\n",
      "Epoch 1117/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 2.0567e-04 - val_loss: 0.0050\n",
      "Epoch 1118/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.0818e-04 - val_loss: 0.0050\n",
      "Epoch 1119/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.9951e-04 - val_loss: 0.0053\n",
      "Epoch 1120/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.0624e-04 - val_loss: 0.0056\n",
      "Epoch 1121/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 2.2136e-04 - val_loss: 0.0053\n",
      "Epoch 1122/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.1550e-04 - val_loss: 0.0053\n",
      "Epoch 1123/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.2791e-04 - val_loss: 0.0053\n",
      "Epoch 1124/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 2.3877e-04 - val_loss: 0.0051\n",
      "Epoch 1125/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 2.3701e-04 - val_loss: 0.0051\n",
      "Epoch 1126/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.0772e-04 - val_loss: 0.0047\n",
      "Epoch 1127/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.1254e-04 - val_loss: 0.0049\n",
      "Epoch 1128/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 2.0906e-04 - val_loss: 0.0048\n",
      "Epoch 1129/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.9879e-04 - val_loss: 0.0045\n",
      "Epoch 1130/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.9739e-04 - val_loss: 0.0052\n",
      "Epoch 1131/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.9858e-04 - val_loss: 0.0045\n",
      "Epoch 1132/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.8732e-04 - val_loss: 0.0051\n",
      "Epoch 1133/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 1.9436e-04 - val_loss: 0.0056\n",
      "Epoch 1134/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.9669e-04 - val_loss: 0.0051\n",
      "Epoch 1135/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.9628e-04 - val_loss: 0.0045\n",
      "Epoch 1136/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 1.9429e-04 - val_loss: 0.0049\n",
      "Epoch 1137/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 2.0052e-04 - val_loss: 0.0049\n",
      "Epoch 1138/2000\n",
      "3811/3811 [==============================] - 1s 221us/step - loss: 1.8955e-04 - val_loss: 0.0050\n",
      "Epoch 1139/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 1.9130e-04 - val_loss: 0.0054\n",
      "Epoch 1140/2000\n",
      "3811/3811 [==============================] - 1s 219us/step - loss: 2.1126e-04 - val_loss: 0.0051\n",
      "Epoch 1141/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.9639e-04 - val_loss: 0.0047\n",
      "Epoch 1142/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 2.0301e-04 - val_loss: 0.0048\n",
      "Epoch 1143/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 2.0796e-04 - val_loss: 0.0051\n",
      "Epoch 1144/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 2.0167e-04 - val_loss: 0.0049\n",
      "Epoch 1145/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.9582e-04 - val_loss: 0.0049\n",
      "Epoch 1146/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 1.8754e-04 - val_loss: 0.0051\n",
      "Epoch 1147/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 1.9146e-04 - val_loss: 0.0054\n",
      "Epoch 1148/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.9158e-04 - val_loss: 0.0047\n",
      "Epoch 1149/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 2.0160e-04 - val_loss: 0.0049\n",
      "Epoch 1150/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.9868e-04 - val_loss: 0.0051\n",
      "Epoch 1151/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.9234e-04 - val_loss: 0.0048\n",
      "Epoch 1152/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.0156e-04 - val_loss: 0.0050\n",
      "Epoch 1153/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.9601e-04 - val_loss: 0.0044\n",
      "Epoch 1154/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.2159e-04 - val_loss: 0.0051\n",
      "Epoch 1155/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.9621e-04 - val_loss: 0.0047\n",
      "Epoch 1156/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.8994e-04 - val_loss: 0.0048\n",
      "Epoch 1157/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.8901e-04 - val_loss: 0.0050\n",
      "Epoch 1158/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.8167e-04 - val_loss: 0.0052\n",
      "Epoch 1159/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.9047e-04 - val_loss: 0.0050\n",
      "Epoch 1160/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 1.8253e-04 - val_loss: 0.0049\n",
      "Epoch 1161/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.8976e-04 - val_loss: 0.0048\n",
      "Epoch 1162/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.8415e-04 - val_loss: 0.0050\n",
      "Epoch 1163/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 1.8319e-04 - val_loss: 0.0054\n",
      "Epoch 1164/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 1.8525e-04 - val_loss: 0.0055\n",
      "Epoch 1165/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 1.9401e-04 - val_loss: 0.0048\n",
      "Epoch 1166/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.8760e-04 - val_loss: 0.0051\n",
      "Epoch 1167/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.7852e-04 - val_loss: 0.0050\n",
      "Epoch 1168/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.7789e-04 - val_loss: 0.0055\n",
      "Epoch 1169/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.7583e-04 - val_loss: 0.0051\n",
      "Epoch 1170/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6382e-04 - val_loss: 0.0055\n",
      "Epoch 1171/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.8351e-04 - val_loss: 0.0054\n",
      "Epoch 1172/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.9470e-04 - val_loss: 0.0053\n",
      "Epoch 1173/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 2.0102e-04 - val_loss: 0.0054\n",
      "Epoch 1174/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.7973e-04 - val_loss: 0.0053\n",
      "Epoch 1175/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.7277e-04 - val_loss: 0.0050\n",
      "Epoch 1176/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.7615e-04 - val_loss: 0.0053\n",
      "Epoch 1177/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 1.8203e-04 - val_loss: 0.0054\n",
      "Epoch 1178/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.7374e-04 - val_loss: 0.0054\n",
      "Epoch 1179/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.7409e-04 - val_loss: 0.0051\n",
      "Epoch 1180/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 1.9644e-04 - val_loss: 0.0057\n",
      "Epoch 1181/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 2.0467e-04 - val_loss: 0.0050\n",
      "Epoch 1182/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.9323e-04 - val_loss: 0.0050\n",
      "Epoch 1183/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.8424e-04 - val_loss: 0.0052\n",
      "Epoch 1184/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.8744e-04 - val_loss: 0.0050\n",
      "Epoch 1185/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.8673e-04 - val_loss: 0.0050\n",
      "Epoch 1186/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.8125e-04 - val_loss: 0.0048\n",
      "Epoch 1187/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.9228e-04 - val_loss: 0.0054\n",
      "Epoch 1188/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.8255e-04 - val_loss: 0.0048\n",
      "Epoch 1189/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6732e-04 - val_loss: 0.0051\n",
      "Epoch 1190/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.8533e-04 - val_loss: 0.0050\n",
      "Epoch 1191/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.9209e-04 - val_loss: 0.0053\n",
      "Epoch 1192/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.8978e-04 - val_loss: 0.0050\n",
      "Epoch 1193/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.8401e-04 - val_loss: 0.0051\n",
      "Epoch 1194/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.6759e-04 - val_loss: 0.0053\n",
      "Epoch 1195/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6779e-04 - val_loss: 0.0056\n",
      "Epoch 1196/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.7365e-04 - val_loss: 0.0049\n",
      "Epoch 1197/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.7244e-04 - val_loss: 0.0052\n",
      "Epoch 1198/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6546e-04 - val_loss: 0.0052\n",
      "Epoch 1199/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6253e-04 - val_loss: 0.0054\n",
      "Epoch 1200/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.7499e-04 - val_loss: 0.0050\n",
      "Epoch 1201/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.6722e-04 - val_loss: 0.0053\n",
      "Epoch 1202/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.7036e-04 - val_loss: 0.0055\n",
      "Epoch 1203/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.7701e-04 - val_loss: 0.0053\n",
      "Epoch 1204/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.8889e-04 - val_loss: 0.0060\n",
      "Epoch 1205/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.8243e-04 - val_loss: 0.0053\n",
      "Epoch 1206/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.8349e-04 - val_loss: 0.0051\n",
      "Epoch 1207/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.7059e-04 - val_loss: 0.0056\n",
      "Epoch 1208/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6175e-04 - val_loss: 0.0049\n",
      "Epoch 1209/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6576e-04 - val_loss: 0.0052\n",
      "Epoch 1210/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6852e-04 - val_loss: 0.0050\n",
      "Epoch 1211/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6754e-04 - val_loss: 0.0050\n",
      "Epoch 1212/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.6997e-04 - val_loss: 0.0054\n",
      "Epoch 1213/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.6947e-04 - val_loss: 0.0054\n",
      "Epoch 1214/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.7433e-04 - val_loss: 0.0049\n",
      "Epoch 1215/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.7275e-04 - val_loss: 0.0053\n",
      "Epoch 1216/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.6024e-04 - val_loss: 0.0052\n",
      "Epoch 1217/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.7352e-04 - val_loss: 0.0053\n",
      "Epoch 1218/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.5812e-04 - val_loss: 0.0055\n",
      "Epoch 1219/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.5808e-04 - val_loss: 0.0053\n",
      "Epoch 1220/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6110e-04 - val_loss: 0.0053\n",
      "Epoch 1221/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.6213e-04 - val_loss: 0.0051\n",
      "Epoch 1222/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.8842e-04 - val_loss: 0.0048\n",
      "Epoch 1223/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.9285e-04 - val_loss: 0.0052\n",
      "Epoch 1224/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.9741e-04 - val_loss: 0.0056\n",
      "Epoch 1225/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.7617e-04 - val_loss: 0.0052\n",
      "Epoch 1226/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6305e-04 - val_loss: 0.0054\n",
      "Epoch 1227/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.7178e-04 - val_loss: 0.0048\n",
      "Epoch 1228/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.8268e-04 - val_loss: 0.0057\n",
      "Epoch 1229/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6284e-04 - val_loss: 0.0046\n",
      "Epoch 1230/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.6800e-04 - val_loss: 0.0051\n",
      "Epoch 1231/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6413e-04 - val_loss: 0.0050\n",
      "Epoch 1232/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6540e-04 - val_loss: 0.0050\n",
      "Epoch 1233/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.6426e-04 - val_loss: 0.0049\n",
      "Epoch 1234/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6291e-04 - val_loss: 0.0049\n",
      "Epoch 1235/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.7247e-04 - val_loss: 0.0050\n",
      "Epoch 1236/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6648e-04 - val_loss: 0.0052\n",
      "Epoch 1237/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 1.5860e-04 - val_loss: 0.0053\n",
      "Epoch 1238/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.7596e-04 - val_loss: 0.0055\n",
      "Epoch 1239/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.8625e-04 - val_loss: 0.0053\n",
      "Epoch 1240/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.7019e-04 - val_loss: 0.0051\n",
      "Epoch 1241/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6203e-04 - val_loss: 0.0049\n",
      "Epoch 1242/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.5944e-04 - val_loss: 0.0049\n",
      "Epoch 1243/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6476e-04 - val_loss: 0.0047\n",
      "Epoch 1244/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.7173e-04 - val_loss: 0.0049\n",
      "Epoch 1245/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.7068e-04 - val_loss: 0.0050\n",
      "Epoch 1246/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6984e-04 - val_loss: 0.0053\n",
      "Epoch 1247/2000\n",
      "3811/3811 [==============================] - 1s 204us/step - loss: 1.6739e-04 - val_loss: 0.0052\n",
      "Epoch 1248/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.5512e-04 - val_loss: 0.0060\n",
      "Epoch 1249/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.6930e-04 - val_loss: 0.0056\n",
      "Epoch 1250/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.5039e-04 - val_loss: 0.0052\n",
      "Epoch 1251/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.6237e-04 - val_loss: 0.0056\n",
      "Epoch 1252/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.4671e-04 - val_loss: 0.0055\n",
      "Epoch 1253/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4001e-04 - val_loss: 0.0048\n",
      "Epoch 1254/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.4051e-04 - val_loss: 0.0051\n",
      "Epoch 1255/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.4586e-04 - val_loss: 0.0052\n",
      "Epoch 1256/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4813e-04 - val_loss: 0.0054\n",
      "Epoch 1257/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.4632e-04 - val_loss: 0.0053\n",
      "Epoch 1258/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4958e-04 - val_loss: 0.0051\n",
      "Epoch 1259/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.5834e-04 - val_loss: 0.0053\n",
      "Epoch 1260/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.5108e-04 - val_loss: 0.0050\n",
      "Epoch 1261/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.4828e-04 - val_loss: 0.0051\n",
      "Epoch 1262/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.4404e-04 - val_loss: 0.0056\n",
      "Epoch 1263/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4916e-04 - val_loss: 0.0049\n",
      "Epoch 1264/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.6407e-04 - val_loss: 0.0049\n",
      "Epoch 1265/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.7102e-04 - val_loss: 0.0054\n",
      "Epoch 1266/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.5361e-04 - val_loss: 0.0046\n",
      "Epoch 1267/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6222e-04 - val_loss: 0.0055\n",
      "Epoch 1268/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6882e-04 - val_loss: 0.0051\n",
      "Epoch 1269/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.7688e-04 - val_loss: 0.0053\n",
      "Epoch 1270/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.7642e-04 - val_loss: 0.0050\n",
      "Epoch 1271/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.5319e-04 - val_loss: 0.0051\n",
      "Epoch 1272/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4658e-04 - val_loss: 0.0054\n",
      "Epoch 1273/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.3922e-04 - val_loss: 0.0055\n",
      "Epoch 1274/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3887e-04 - val_loss: 0.0050\n",
      "Epoch 1275/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3638e-04 - val_loss: 0.0055\n",
      "Epoch 1276/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.5340e-04 - val_loss: 0.0052\n",
      "Epoch 1277/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.5125e-04 - val_loss: 0.0052-\n",
      "Epoch 1278/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.4117e-04 - val_loss: 0.0054\n",
      "Epoch 1279/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.3547e-04 - val_loss: 0.0055\n",
      "Epoch 1280/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.5133e-04 - val_loss: 0.0055\n",
      "Epoch 1281/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.4284e-04 - val_loss: 0.0057\n",
      "Epoch 1282/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3471e-04 - val_loss: 0.0057\n",
      "Epoch 1283/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3397e-04 - val_loss: 0.0055\n",
      "Epoch 1284/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.3166e-04 - val_loss: 0.0050\n",
      "Epoch 1285/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2514e-04 - val_loss: 0.0054\n",
      "Epoch 1286/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.3445e-04 - val_loss: 0.0051\n",
      "Epoch 1287/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.4909e-04 - val_loss: 0.0053\n",
      "Epoch 1288/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.4704e-04 - val_loss: 0.0057\n",
      "Epoch 1289/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4953e-04 - val_loss: 0.0050\n",
      "Epoch 1290/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.4352e-04 - val_loss: 0.0055\n",
      "Epoch 1291/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3812e-04 - val_loss: 0.0057\n",
      "Epoch 1292/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.6657e-04 - val_loss: 0.0050\n",
      "Epoch 1293/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.5297e-04 - val_loss: 0.0062\n",
      "Epoch 1294/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.5279e-04 - val_loss: 0.0054\n",
      "Epoch 1295/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.6622e-04 - val_loss: 0.0052\n",
      "Epoch 1296/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6928e-04 - val_loss: 0.0047\n",
      "Epoch 1297/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.6283e-04 - val_loss: 0.0048\n",
      "Epoch 1298/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.6747e-04 - val_loss: 0.0053\n",
      "Epoch 1299/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.5674e-04 - val_loss: 0.0051\n",
      "Epoch 1300/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4721e-04 - val_loss: 0.0053\n",
      "Epoch 1301/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.5412e-04 - val_loss: 0.0056\n",
      "Epoch 1302/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.4632e-04 - val_loss: 0.0051\n",
      "Epoch 1303/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.4493e-04 - val_loss: 0.0053\n",
      "Epoch 1304/2000\n",
      "3811/3811 [==============================] - 1s 220us/step - loss: 1.4880e-04 - val_loss: 0.0054\n",
      "Epoch 1305/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.4858e-04 - val_loss: 0.0053\n",
      "Epoch 1306/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.4977e-04 - val_loss: 0.0055\n",
      "Epoch 1307/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.5812e-04 - val_loss: 0.0057\n",
      "Epoch 1308/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.5953e-04 - val_loss: 0.0054\n",
      "Epoch 1309/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.4091e-04 - val_loss: 0.0051\n",
      "Epoch 1310/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.4485e-04 - val_loss: 0.0051\n",
      "Epoch 1311/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.5309e-04 - val_loss: 0.0052\n",
      "Epoch 1312/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3431e-04 - val_loss: 0.0054\n",
      "Epoch 1313/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 1.3753e-04 - val_loss: 0.0051\n",
      "Epoch 1314/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3686e-04 - val_loss: 0.0054\n",
      "Epoch 1315/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3303e-04 - val_loss: 0.0049\n",
      "Epoch 1316/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.3557e-04 - val_loss: 0.0053\n",
      "Epoch 1317/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 1.3286e-04 - val_loss: 0.0053\n",
      "Epoch 1318/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3794e-04 - val_loss: 0.0054\n",
      "Epoch 1319/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.3406e-04 - val_loss: 0.0054\n",
      "Epoch 1320/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.3168e-04 - val_loss: 0.0058\n",
      "Epoch 1321/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.2948e-04 - val_loss: 0.0056\n",
      "Epoch 1322/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.2768e-04 - val_loss: 0.0058\n",
      "Epoch 1323/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2947e-04 - val_loss: 0.0056\n",
      "Epoch 1324/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3845e-04 - val_loss: 0.0058\n",
      "Epoch 1325/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.4341e-04 - val_loss: 0.0061\n",
      "Epoch 1326/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 1.4889e-04 - val_loss: 0.0055\n",
      "Epoch 1327/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.3836e-04 - val_loss: 0.0063\n",
      "Epoch 1328/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.5703e-04 - val_loss: 0.0058\n",
      "Epoch 1329/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6554e-04 - val_loss: 0.0058\n",
      "Epoch 1330/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.6522e-04 - val_loss: 0.0055\n",
      "Epoch 1331/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.5722e-04 - val_loss: 0.0056\n",
      "Epoch 1332/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.4104e-04 - val_loss: 0.0055\n",
      "Epoch 1333/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3555e-04 - val_loss: 0.0052\n",
      "Epoch 1334/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3839e-04 - val_loss: 0.0056\n",
      "Epoch 1335/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.3506e-04 - val_loss: 0.0058\n",
      "Epoch 1336/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.2753e-04 - val_loss: 0.0057\n",
      "Epoch 1337/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.2538e-04 - val_loss: 0.0053\n",
      "Epoch 1338/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4191e-04 - val_loss: 0.0055\n",
      "Epoch 1339/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3652e-04 - val_loss: 0.0054\n",
      "Epoch 1340/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2998e-04 - val_loss: 0.0053\n",
      "Epoch 1341/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2133e-04 - val_loss: 0.0049\n",
      "Epoch 1342/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.3400e-04 - val_loss: 0.0053\n",
      "Epoch 1343/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.4556e-04 - val_loss: 0.0055\n",
      "Epoch 1344/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3456e-04 - val_loss: 0.0054\n",
      "Epoch 1345/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.4165e-04 - val_loss: 0.0054\n",
      "Epoch 1346/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.3524e-04 - val_loss: 0.0054\n",
      "Epoch 1347/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6264e-04 - val_loss: 0.0047\n",
      "Epoch 1348/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.7044e-04 - val_loss: 0.0051\n",
      "Epoch 1349/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.5382e-04 - val_loss: 0.0055\n",
      "Epoch 1350/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4144e-04 - val_loss: 0.0051\n",
      "Epoch 1351/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2972e-04 - val_loss: 0.0052\n",
      "Epoch 1352/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.4208e-04 - val_loss: 0.0054\n",
      "Epoch 1353/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4127e-04 - val_loss: 0.0051\n",
      "Epoch 1354/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.3920e-04 - val_loss: 0.0049\n",
      "Epoch 1355/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.5136e-04 - val_loss: 0.0057\n",
      "Epoch 1356/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.3733e-04 - val_loss: 0.0051\n",
      "Epoch 1357/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.3358e-04 - val_loss: 0.0059\n",
      "Epoch 1358/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3187e-04 - val_loss: 0.0057\n",
      "Epoch 1359/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2409e-04 - val_loss: 0.0056\n",
      "Epoch 1360/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.4403e-04 - val_loss: 0.0058\n",
      "Epoch 1361/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4598e-04 - val_loss: 0.0055\n",
      "Epoch 1362/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.3260e-04 - val_loss: 0.0053\n",
      "Epoch 1363/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.4192e-04 - val_loss: 0.0051\n",
      "Epoch 1364/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3626e-04 - val_loss: 0.0056\n",
      "Epoch 1365/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2403e-04 - val_loss: 0.0054\n",
      "Epoch 1366/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2084e-04 - val_loss: 0.0054\n",
      "Epoch 1367/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.2264e-04 - val_loss: 0.0058\n",
      "Epoch 1368/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3408e-04 - val_loss: 0.0056\n",
      "Epoch 1369/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.3204e-04 - val_loss: 0.0056\n",
      "Epoch 1370/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.4041e-04 - val_loss: 0.0056\n",
      "Epoch 1371/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.5123e-04 - val_loss: 0.0057\n",
      "Epoch 1372/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.5606e-04 - val_loss: 0.0062\n",
      "Epoch 1373/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.4450e-04 - val_loss: 0.0057\n",
      "Epoch 1374/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3800e-04 - val_loss: 0.0058\n",
      "Epoch 1375/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.3212e-04 - val_loss: 0.0061\n",
      "Epoch 1376/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.5066e-04 - val_loss: 0.0057\n",
      "Epoch 1377/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.4119e-04 - val_loss: 0.0055\n",
      "Epoch 1378/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3635e-04 - val_loss: 0.0054\n",
      "Epoch 1379/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3635e-04 - val_loss: 0.0057\n",
      "Epoch 1380/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4384e-04 - val_loss: 0.0054\n",
      "Epoch 1381/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4491e-04 - val_loss: 0.0055\n",
      "Epoch 1382/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4032e-04 - val_loss: 0.0052\n",
      "Epoch 1383/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2856e-04 - val_loss: 0.0057\n",
      "Epoch 1384/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.3554e-04 - val_loss: 0.0056\n",
      "Epoch 1385/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.3406e-04 - val_loss: 0.0058\n",
      "Epoch 1386/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3252e-04 - val_loss: 0.0057\n",
      "Epoch 1387/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.2721e-04 - val_loss: 0.0056\n",
      "Epoch 1388/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.3009e-04 - val_loss: 0.0061\n",
      "Epoch 1389/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2935e-04 - val_loss: 0.0059\n",
      "Epoch 1390/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.2455e-04 - val_loss: 0.0056\n",
      "Epoch 1391/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1856e-04 - val_loss: 0.0057\n",
      "Epoch 1392/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1763e-04 - val_loss: 0.0056\n",
      "Epoch 1393/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1675e-04 - val_loss: 0.0053\n",
      "Epoch 1394/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2841e-04 - val_loss: 0.0054\n",
      "Epoch 1395/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.2619e-04 - val_loss: 0.0059\n",
      "Epoch 1396/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.3007e-04 - val_loss: 0.0060\n",
      "Epoch 1397/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.2010e-04 - val_loss: 0.0055\n",
      "Epoch 1398/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.1817e-04 - val_loss: 0.0058\n",
      "Epoch 1399/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2068e-04 - val_loss: 0.0057\n",
      "Epoch 1400/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1501e-04 - val_loss: 0.0060\n",
      "Epoch 1401/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1783e-04 - val_loss: 0.0060\n",
      "Epoch 1402/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2516e-04 - val_loss: 0.0057\n",
      "Epoch 1403/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1356e-04 - val_loss: 0.0056\n",
      "Epoch 1404/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2291e-04 - val_loss: 0.0060\n",
      "Epoch 1405/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2311e-04 - val_loss: 0.0056\n",
      "Epoch 1406/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.3089e-04 - val_loss: 0.0055\n",
      "Epoch 1407/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.2669e-04 - val_loss: 0.0057\n",
      "Epoch 1408/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2980e-04 - val_loss: 0.0061\n",
      "Epoch 1409/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1874e-04 - val_loss: 0.0056\n",
      "Epoch 1410/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1397e-04 - val_loss: 0.0061\n",
      "Epoch 1411/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2650e-04 - val_loss: 0.0056\n",
      "Epoch 1412/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.2600e-04 - val_loss: 0.0056\n",
      "Epoch 1413/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1994e-04 - val_loss: 0.0060\n",
      "Epoch 1414/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3368e-04 - val_loss: 0.0058\n",
      "Epoch 1415/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.2240e-04 - val_loss: 0.0055\n",
      "Epoch 1416/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2283e-04 - val_loss: 0.0057\n",
      "Epoch 1417/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.2259e-04 - val_loss: 0.0053\n",
      "Epoch 1418/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.2482e-04 - val_loss: 0.0054\n",
      "Epoch 1419/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.2216e-04 - val_loss: 0.0053\n",
      "Epoch 1420/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1583e-04 - val_loss: 0.0060\n",
      "Epoch 1421/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1261e-04 - val_loss: 0.0056\n",
      "Epoch 1422/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1807e-04 - val_loss: 0.0061\n",
      "Epoch 1423/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2130e-04 - val_loss: 0.0055\n",
      "Epoch 1424/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.1615e-04 - val_loss: 0.0059\n",
      "Epoch 1425/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.1551e-04 - val_loss: 0.0057\n",
      "Epoch 1426/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.1628e-04 - val_loss: 0.0053\n",
      "Epoch 1427/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.2204e-04 - val_loss: 0.0057\n",
      "Epoch 1428/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2272e-04 - val_loss: 0.0058\n",
      "Epoch 1429/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3354e-04 - val_loss: 0.0059\n",
      "Epoch 1430/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.3590e-04 - val_loss: 0.0054\n",
      "Epoch 1431/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.3212e-04 - val_loss: 0.0062\n",
      "Epoch 1432/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2587e-04 - val_loss: 0.0055\n",
      "Epoch 1433/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2310e-04 - val_loss: 0.0052\n",
      "Epoch 1434/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.3899e-04 - val_loss: 0.0056\n",
      "Epoch 1435/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.6433e-04 - val_loss: 0.0053\n",
      "Epoch 1436/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.5266e-04 - val_loss: 0.0054\n",
      "Epoch 1437/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3979e-04 - val_loss: 0.0054\n",
      "Epoch 1438/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.3284e-04 - val_loss: 0.0058\n",
      "Epoch 1439/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2409e-04 - val_loss: 0.0054\n",
      "Epoch 1440/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.3055e-04 - val_loss: 0.0062\n",
      "Epoch 1441/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.2652e-04 - val_loss: 0.0057\n",
      "Epoch 1442/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2789e-04 - val_loss: 0.0059\n",
      "Epoch 1443/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.5000e-04 - val_loss: 0.0060\n",
      "Epoch 1444/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.3799e-04 - val_loss: 0.0061\n",
      "Epoch 1445/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2476e-04 - val_loss: 0.0054\n",
      "Epoch 1446/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.1020e-04 - val_loss: 0.0056\n",
      "Epoch 1447/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1946e-04 - val_loss: 0.0054\n",
      "Epoch 1448/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1170e-04 - val_loss: 0.0055\n",
      "Epoch 1449/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1225e-04 - val_loss: 0.0061\n",
      "Epoch 1450/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2316e-04 - val_loss: 0.0061\n",
      "Epoch 1451/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4055e-04 - val_loss: 0.0059\n",
      "Epoch 1452/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.5004e-04 - val_loss: 0.0063\n",
      "Epoch 1453/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.4661e-04 - val_loss: 0.0055\n",
      "Epoch 1454/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2961e-04 - val_loss: 0.0058\n",
      "Epoch 1455/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2472e-04 - val_loss: 0.0052\n",
      "Epoch 1456/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.2192e-04 - val_loss: 0.0054\n",
      "Epoch 1457/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.1533e-04 - val_loss: 0.0056\n",
      "Epoch 1458/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.0579e-04 - val_loss: 0.0061\n",
      "Epoch 1459/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1851e-04 - val_loss: 0.0059\n",
      "Epoch 1460/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1315e-04 - val_loss: 0.0056\n",
      "Epoch 1461/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1441e-04 - val_loss: 0.0057\n",
      "Epoch 1462/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1364e-04 - val_loss: 0.0059\n",
      "Epoch 1463/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1694e-04 - val_loss: 0.0059\n",
      "Epoch 1464/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0959e-04 - val_loss: 0.0058\n",
      "Epoch 1465/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.2841e-04 - val_loss: 0.0060\n",
      "Epoch 1466/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1812e-04 - val_loss: 0.0058\n",
      "Epoch 1467/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.2077e-04 - val_loss: 0.0059\n",
      "Epoch 1468/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2201e-04 - val_loss: 0.0060\n",
      "Epoch 1469/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2920e-04 - val_loss: 0.0049\n",
      "Epoch 1470/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2253e-04 - val_loss: 0.0059\n",
      "Epoch 1471/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1268e-04 - val_loss: 0.0057\n",
      "Epoch 1472/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0870e-04 - val_loss: 0.0058\n",
      "Epoch 1473/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0084e-04 - val_loss: 0.0058\n",
      "Epoch 1474/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0242e-04 - val_loss: 0.0057\n",
      "Epoch 1475/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.0277e-04 - val_loss: 0.0055\n",
      "Epoch 1476/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0942e-04 - val_loss: 0.0057\n",
      "Epoch 1477/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0561e-04 - val_loss: 0.0061\n",
      "Epoch 1478/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.1084e-04 - val_loss: 0.0058\n",
      "Epoch 1479/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.0667e-04 - val_loss: 0.0060\n",
      "Epoch 1480/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0252e-04 - val_loss: 0.0056\n",
      "Epoch 1481/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0243e-04 - val_loss: 0.0060\n",
      "Epoch 1482/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0658e-04 - val_loss: 0.0056\n",
      "Epoch 1483/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1104e-04 - val_loss: 0.0056\n",
      "Epoch 1484/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.1260e-04 - val_loss: 0.0060\n",
      "Epoch 1485/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1526e-04 - val_loss: 0.0061\n",
      "Epoch 1486/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.1556e-04 - val_loss: 0.0056\n",
      "Epoch 1487/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.2364e-04 - val_loss: 0.0057\n",
      "Epoch 1488/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1353e-04 - val_loss: 0.0059\n",
      "Epoch 1489/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1642e-04 - val_loss: 0.0061\n",
      "Epoch 1490/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1130e-04 - val_loss: 0.0059\n",
      "Epoch 1491/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0957e-04 - val_loss: 0.0059\n",
      "Epoch 1492/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0373e-04 - val_loss: 0.0060\n",
      "Epoch 1493/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0739e-04 - val_loss: 0.0058\n",
      "Epoch 1494/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0461e-04 - val_loss: 0.0055\n",
      "Epoch 1495/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0767e-04 - val_loss: 0.0058\n",
      "Epoch 1496/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1163e-04 - val_loss: 0.0056\n",
      "Epoch 1497/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0831e-04 - val_loss: 0.0056\n",
      "Epoch 1498/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.1430e-04 - val_loss: 0.0057\n",
      "Epoch 1499/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0214e-04 - val_loss: 0.0058\n",
      "Epoch 1500/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0363e-04 - val_loss: 0.0059\n",
      "Epoch 1501/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1376e-04 - val_loss: 0.0060\n",
      "Epoch 1502/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1469e-04 - val_loss: 0.0063\n",
      "Epoch 1503/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1614e-04 - val_loss: 0.0057\n",
      "Epoch 1504/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.1750e-04 - val_loss: 0.0060\n",
      "Epoch 1505/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1240e-04 - val_loss: 0.0060\n",
      "Epoch 1506/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.0856e-04 - val_loss: 0.0062\n",
      "Epoch 1507/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0041e-04 - val_loss: 0.0061\n",
      "Epoch 1508/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0283e-04 - val_loss: 0.0065\n",
      "Epoch 1509/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.0768e-04 - val_loss: 0.0061\n",
      "Epoch 1510/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2240e-04 - val_loss: 0.0060\n",
      "Epoch 1511/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0635e-04 - val_loss: 0.0058\n",
      "Epoch 1512/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0673e-04 - val_loss: 0.0058\n",
      "Epoch 1513/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.0183e-04 - val_loss: 0.0062\n",
      "Epoch 1514/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.1357e-04 - val_loss: 0.0061\n",
      "Epoch 1515/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.0822e-04 - val_loss: 0.0060\n",
      "Epoch 1516/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0724e-04 - val_loss: 0.0058\n",
      "Epoch 1517/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1667e-04 - val_loss: 0.0058\n",
      "Epoch 1518/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.1026e-04 - val_loss: 0.0059\n",
      "Epoch 1519/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0805e-04 - val_loss: 0.0057\n",
      "Epoch 1520/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2529e-04 - val_loss: 0.0058\n",
      "Epoch 1521/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2626e-04 - val_loss: 0.0061\n",
      "Epoch 1522/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.3108e-04 - val_loss: 0.0057\n",
      "Epoch 1523/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.4100e-04 - val_loss: 0.0058\n",
      "Epoch 1524/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.3374e-04 - val_loss: 0.0056\n",
      "Epoch 1525/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.3047e-04 - val_loss: 0.0053\n",
      "Epoch 1526/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2535e-04 - val_loss: 0.0058\n",
      "Epoch 1527/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.1676e-04 - val_loss: 0.0057\n",
      "Epoch 1528/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1298e-04 - val_loss: 0.0060\n",
      "Epoch 1529/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1048e-04 - val_loss: 0.0059\n",
      "Epoch 1530/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.0587e-04 - val_loss: 0.0058\n",
      "Epoch 1531/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0358e-04 - val_loss: 0.0059\n",
      "Epoch 1532/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0064e-04 - val_loss: 0.0060\n",
      "Epoch 1533/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0094e-04 - val_loss: 0.0063\n",
      "Epoch 1534/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0019e-04 - val_loss: 0.0057\n",
      "Epoch 1535/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.0217e-04 - val_loss: 0.0060\n",
      "Epoch 1536/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0535e-04 - val_loss: 0.0056\n",
      "Epoch 1537/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.5000e-05 - val_loss: 0.0061\n",
      "Epoch 1538/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 9.7246e-05 - val_loss: 0.0058\n",
      "Epoch 1539/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.3909e-05 - val_loss: 0.0059\n",
      "Epoch 1540/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.1917e-05 - val_loss: 0.0059\n",
      "Epoch 1541/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.9747e-05 - val_loss: 0.0059\n",
      "Epoch 1542/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.2036e-05 - val_loss: 0.0060\n",
      "Epoch 1543/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.6344e-05 - val_loss: 0.0060\n",
      "Epoch 1544/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.0713e-04 - val_loss: 0.0060\n",
      "Epoch 1545/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0686e-04 - val_loss: 0.0059\n",
      "Epoch 1546/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0474e-04 - val_loss: 0.0063\n",
      "Epoch 1547/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.3634e-05 - val_loss: 0.0056\n",
      "Epoch 1548/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.4835e-05 - val_loss: 0.0060\n",
      "Epoch 1549/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 9.7924e-05 - val_loss: 0.0059\n",
      "Epoch 1550/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0384e-04 - val_loss: 0.0057\n",
      "Epoch 1551/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0004e-04 - val_loss: 0.0059\n",
      "Epoch 1552/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0099e-04 - val_loss: 0.0062\n",
      "Epoch 1553/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.0467e-04 - val_loss: 0.0058\n",
      "Epoch 1554/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.9909e-05 - val_loss: 0.0062\n",
      "Epoch 1555/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.7035e-05 - val_loss: 0.0062\n",
      "Epoch 1556/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.5379e-05 - val_loss: 0.0061\n",
      "Epoch 1557/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 9.3094e-05 - val_loss: 0.0063\n",
      "Epoch 1558/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 9.6798e-05 - val_loss: 0.0062\n",
      "Epoch 1559/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 9.7848e-05 - val_loss: 0.0060\n",
      "Epoch 1560/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0485e-04 - val_loss: 0.0059\n",
      "Epoch 1561/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0334e-04 - val_loss: 0.0061\n",
      "Epoch 1562/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0129e-04 - val_loss: 0.0061\n",
      "Epoch 1563/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.4738e-05 - val_loss: 0.0058\n",
      "Epoch 1564/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.7719e-05 - val_loss: 0.0058\n",
      "Epoch 1565/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 9.5354e-05 - val_loss: 0.0060\n",
      "Epoch 1566/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1235e-04 - val_loss: 0.0058\n",
      "Epoch 1567/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0387e-04 - val_loss: 0.0057\n",
      "Epoch 1568/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 9.6142e-05 - val_loss: 0.0060\n",
      "Epoch 1569/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0224e-04 - val_loss: 0.0057\n",
      "Epoch 1570/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0011e-04 - val_loss: 0.0058\n",
      "Epoch 1571/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0564e-04 - val_loss: 0.0063\n",
      "Epoch 1572/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1131e-04 - val_loss: 0.0058\n",
      "Epoch 1573/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1758e-04 - val_loss: 0.0063\n",
      "Epoch 1574/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1842e-04 - val_loss: 0.0058\n",
      "Epoch 1575/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1965e-04 - val_loss: 0.0059\n",
      "Epoch 1576/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0964e-04 - val_loss: 0.0055\n",
      "Epoch 1577/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0489e-04 - val_loss: 0.0061\n",
      "Epoch 1578/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.0382e-04 - val_loss: 0.0061\n",
      "Epoch 1579/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 9.8489e-05 - val_loss: 0.0063\n",
      "Epoch 1580/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0101e-04 - val_loss: 0.0061\n",
      "Epoch 1581/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.4877e-05 - val_loss: 0.0061\n",
      "Epoch 1582/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.9118e-05 - val_loss: 0.0061\n",
      "Epoch 1583/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.4659e-05 - val_loss: 0.0060\n",
      "Epoch 1584/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.9691e-05 - val_loss: 0.0060\n",
      "Epoch 1585/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.8672e-05 - val_loss: 0.0061\n",
      "Epoch 1586/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0004e-04 - val_loss: 0.0064\n",
      "Epoch 1587/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 9.6390e-05 - val_loss: 0.0058\n",
      "Epoch 1588/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.6206e-05 - val_loss: 0.0057\n",
      "Epoch 1589/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1130e-04 - val_loss: 0.0064\n",
      "Epoch 1590/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.1086e-04 - val_loss: 0.0063\n",
      "Epoch 1591/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.0723e-04 - val_loss: 0.0064\n",
      "Epoch 1592/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0969e-04 - val_loss: 0.0062\n",
      "Epoch 1593/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0898e-04 - val_loss: 0.0060\n",
      "Epoch 1594/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.0638e-04 - val_loss: 0.0059\n",
      "Epoch 1595/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.8505e-05 - val_loss: 0.0058\n",
      "Epoch 1596/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.9166e-05 - val_loss: 0.0061\n",
      "Epoch 1597/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.0672e-05 - val_loss: 0.0062\n",
      "Epoch 1598/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.1068e-05 - val_loss: 0.0061\n",
      "Epoch 1599/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 8.6956e-05 - val_loss: 0.0061\n",
      "Epoch 1600/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.1760e-05 - val_loss: 0.0061\n",
      "Epoch 1601/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.9143e-05 - val_loss: 0.0058\n",
      "Epoch 1602/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.7100e-05 - val_loss: 0.0063\n",
      "Epoch 1603/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.2173e-05 - val_loss: 0.0062\n",
      "Epoch 1604/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.9197e-05 - val_loss: 0.0062\n",
      "Epoch 1605/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0109e-04 - val_loss: 0.0063\n",
      "Epoch 1606/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0468e-04 - val_loss: 0.0064\n",
      "Epoch 1607/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1386e-04 - val_loss: 0.0060\n",
      "Epoch 1608/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.1328e-04 - val_loss: 0.0059\n",
      "Epoch 1609/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0296e-04 - val_loss: 0.0066\n",
      "Epoch 1610/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1518e-04 - val_loss: 0.0061\n",
      "Epoch 1611/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.6413e-05 - val_loss: 0.0063\n",
      "Epoch 1612/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.0306e-05 - val_loss: 0.0061\n",
      "Epoch 1613/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.7973e-05 - val_loss: 0.0066\n",
      "Epoch 1614/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0358e-04 - val_loss: 0.0067\n",
      "Epoch 1615/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0322e-04 - val_loss: 0.0061\n",
      "Epoch 1616/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0062e-04 - val_loss: 0.0062\n",
      "Epoch 1617/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.6410e-05 - val_loss: 0.0060\n",
      "Epoch 1618/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.9579e-05 - val_loss: 0.0062\n",
      "Epoch 1619/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 9.4812e-05 - val_loss: 0.0061\n",
      "Epoch 1620/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.7686e-05 - val_loss: 0.0061\n",
      "Epoch 1621/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.4243e-05 - val_loss: 0.0065\n",
      "Epoch 1622/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.5658e-05 - val_loss: 0.0068\n",
      "Epoch 1623/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.9930e-05 - val_loss: 0.0059\n",
      "Epoch 1624/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.5162e-05 - val_loss: 0.0057\n",
      "Epoch 1625/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 9.5190e-05 - val_loss: 0.0056\n",
      "Epoch 1626/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.9672e-05 - val_loss: 0.0062\n",
      "Epoch 1627/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.4487e-05 - val_loss: 0.0058\n",
      "Epoch 1628/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.0818e-05 - val_loss: 0.0058\n",
      "Epoch 1629/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 8.7883e-05 - val_loss: 0.0059\n",
      "Epoch 1630/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 9.4537e-05 - val_loss: 0.0062\n",
      "Epoch 1631/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.0558e-05 - val_loss: 0.0063\n",
      "Epoch 1632/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 9.2509e-05 - val_loss: 0.0063\n",
      "Epoch 1633/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 8.7624e-05 - val_loss: 0.0058\n",
      "Epoch 1634/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.8027e-05 - val_loss: 0.0061\n",
      "Epoch 1635/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 9.4747e-05 - val_loss: 0.0058\n",
      "Epoch 1636/2000\n",
      "3811/3811 [==============================] - 1s 217us/step - loss: 1.0635e-04 - val_loss: 0.0059\n",
      "Epoch 1637/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.1535e-04 - val_loss: 0.0061\n",
      "Epoch 1638/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 1.0456e-04 - val_loss: 0.0058\n",
      "Epoch 1639/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 9.9641e-05 - val_loss: 0.0062\n",
      "Epoch 1640/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.8122e-05 - val_loss: 0.0062\n",
      "Epoch 1641/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.2239e-05 - val_loss: 0.0060\n",
      "Epoch 1642/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 8.3625e-05 - val_loss: 0.0062\n",
      "Epoch 1643/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.8158e-05 - val_loss: 0.0061\n",
      "Epoch 1644/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.2283e-05 - val_loss: 0.0061\n",
      "Epoch 1645/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.6168e-05 - val_loss: 0.0061\n",
      "Epoch 1646/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.9785e-05 - val_loss: 0.0062\n",
      "Epoch 1647/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.0561e-04 - val_loss: 0.0062\n",
      "Epoch 1648/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.4289e-05 - val_loss: 0.0059\n",
      "Epoch 1649/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.2700e-05 - val_loss: 0.0063\n",
      "Epoch 1650/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.8055e-05 - val_loss: 0.0058\n",
      "Epoch 1651/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0789e-04 - val_loss: 0.0060\n",
      "Epoch 1652/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0328e-04 - val_loss: 0.0063\n",
      "Epoch 1653/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0309e-04 - val_loss: 0.0063\n",
      "Epoch 1654/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.1966e-05 - val_loss: 0.0061\n",
      "Epoch 1655/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 9.1371e-05 - val_loss: 0.0063\n",
      "Epoch 1656/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 9.1401e-05 - val_loss: 0.0062\n",
      "Epoch 1657/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.4245e-05 - val_loss: 0.0060\n",
      "Epoch 1658/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.7179e-05 - val_loss: 0.0060\n",
      "Epoch 1659/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 9.3470e-05 - val_loss: 0.0060\n",
      "Epoch 1660/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 1.0234e-04 - val_loss: 0.0059\n",
      "Epoch 1661/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.9098e-05 - val_loss: 0.0062\n",
      "Epoch 1662/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 9.8516e-05 - val_loss: 0.0063\n",
      "Epoch 1663/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.0916e-04 - val_loss: 0.0057\n",
      "Epoch 1664/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.2528e-04 - val_loss: 0.0059\n",
      "Epoch 1665/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0922e-04 - val_loss: 0.0064\n",
      "Epoch 1666/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 1.0537e-04 - val_loss: 0.0058\n",
      "Epoch 1667/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 9.7759e-05 - val_loss: 0.0059\n",
      "Epoch 1668/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0062e-04 - val_loss: 0.0061\n",
      "Epoch 1669/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1178e-04 - val_loss: 0.0059\n",
      "Epoch 1670/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 9.8245e-05 - val_loss: 0.0063\n",
      "Epoch 1671/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.6542e-05 - val_loss: 0.0061\n",
      "Epoch 1672/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 9.6743e-05 - val_loss: 0.0061\n",
      "Epoch 1673/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0325e-04 - val_loss: 0.0060\n",
      "Epoch 1674/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0102e-04 - val_loss: 0.0064\n",
      "Epoch 1675/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1179e-04 - val_loss: 0.0060\n",
      "Epoch 1676/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1847e-04 - val_loss: 0.0061\n",
      "Epoch 1677/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1311e-04 - val_loss: 0.0059\n",
      "Epoch 1678/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 1.0218e-04 - val_loss: 0.0062\n",
      "Epoch 1679/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 9.0235e-05 - val_loss: 0.0063\n",
      "Epoch 1680/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.4627e-05 - val_loss: 0.0063\n",
      "Epoch 1681/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.8340e-05 - val_loss: 0.0061\n",
      "Epoch 1682/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.9920e-05 - val_loss: 0.0062\n",
      "Epoch 1683/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.1742e-05 - val_loss: 0.0060\n",
      "Epoch 1684/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.4843e-05 - val_loss: 0.0059\n",
      "Epoch 1685/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.5497e-05 - val_loss: 0.0060\n",
      "Epoch 1686/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.7844e-05 - val_loss: 0.0061\n",
      "Epoch 1687/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.1334e-05 - val_loss: 0.0059\n",
      "Epoch 1688/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.7957e-05 - val_loss: 0.0063\n",
      "Epoch 1689/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.2460e-05 - val_loss: 0.0064\n",
      "Epoch 1690/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.3312e-05 - val_loss: 0.0064\n",
      "Epoch 1691/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.3360e-05 - val_loss: 0.0062\n",
      "Epoch 1692/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.9660e-05 - val_loss: 0.0062\n",
      "Epoch 1693/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.8363e-05 - val_loss: 0.0062\n",
      "Epoch 1694/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.3773e-05 - val_loss: 0.0062\n",
      "Epoch 1695/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.2618e-05 - val_loss: 0.0062\n",
      "Epoch 1696/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.9193e-05 - val_loss: 0.0062\n",
      "Epoch 1697/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.2347e-05 - val_loss: 0.0062\n",
      "Epoch 1698/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.2598e-05 - val_loss: 0.0060\n",
      "Epoch 1699/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 9.0146e-05 - val_loss: 0.0061\n",
      "Epoch 1700/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 8.6857e-05 - val_loss: 0.0058\n",
      "Epoch 1701/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 8.6629e-05 - val_loss: 0.0060\n",
      "Epoch 1702/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 1.0432e-04 - val_loss: 0.0060\n",
      "Epoch 1703/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 9.8705e-05 - val_loss: 0.0063\n",
      "Epoch 1704/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.5646e-05 - val_loss: 0.0064\n",
      "Epoch 1705/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.8346e-05 - val_loss: 0.0062\n",
      "Epoch 1706/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.8162e-05 - val_loss: 0.0061\n",
      "Epoch 1707/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 7.8886e-05 - val_loss: 0.0062\n",
      "Epoch 1708/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.8858e-05 - val_loss: 0.0062\n",
      "Epoch 1709/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.9084e-05 - val_loss: 0.0061\n",
      "Epoch 1710/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.4026e-05 - val_loss: 0.0060\n",
      "Epoch 1711/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.7643e-05 - val_loss: 0.0064\n",
      "Epoch 1712/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 8.1802e-05 - val_loss: 0.0061\n",
      "Epoch 1713/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 8.8793e-05 - val_loss: 0.0062\n",
      "Epoch 1714/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 9.2675e-05 - val_loss: 0.0067\n",
      "Epoch 1715/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1170e-04 - val_loss: 0.0059\n",
      "Epoch 1716/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0555e-04 - val_loss: 0.0063\n",
      "Epoch 1717/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0880e-04 - val_loss: 0.0065\n",
      "Epoch 1718/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.1134e-04 - val_loss: 0.0060\n",
      "Epoch 1719/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 1.0216e-04 - val_loss: 0.0064\n",
      "Epoch 1720/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.8320e-05 - val_loss: 0.0060\n",
      "Epoch 1721/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.8450e-05 - val_loss: 0.0060\n",
      "Epoch 1722/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.1052e-05 - val_loss: 0.0062\n",
      "Epoch 1723/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.6234e-05 - val_loss: 0.0062\n",
      "Epoch 1724/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.2778e-05 - val_loss: 0.0061\n",
      "Epoch 1725/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.0799e-05 - val_loss: 0.0061\n",
      "Epoch 1726/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 9.1613e-05 - val_loss: 0.0061\n",
      "Epoch 1727/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.3442e-05 - val_loss: 0.0061\n",
      "Epoch 1728/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.4663e-05 - val_loss: 0.0058\n",
      "Epoch 1729/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 8.3912e-05 - val_loss: 0.0063\n",
      "Epoch 1730/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.7291e-05 - val_loss: 0.0061\n",
      "Epoch 1731/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.0140e-05 - val_loss: 0.0063\n",
      "Epoch 1732/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.3432e-05 - val_loss: 0.0062\n",
      "Epoch 1733/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.2489e-05 - val_loss: 0.0061\n",
      "Epoch 1734/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.0578e-05 - val_loss: 0.0065\n",
      "Epoch 1735/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.6661e-05 - val_loss: 0.0061\n",
      "Epoch 1736/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.4414e-05 - val_loss: 0.0061\n",
      "Epoch 1737/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.7899e-05 - val_loss: 0.0063\n",
      "Epoch 1738/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.7128e-05 - val_loss: 0.0058\n",
      "Epoch 1739/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 7.9025e-05 - val_loss: 0.0061\n",
      "Epoch 1740/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.4898e-05 - val_loss: 0.0060\n",
      "Epoch 1741/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.4022e-05 - val_loss: 0.0061\n",
      "Epoch 1742/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.5485e-05 - val_loss: 0.0063\n",
      "Epoch 1743/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.5008e-05 - val_loss: 0.0061\n",
      "Epoch 1744/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.4088e-05 - val_loss: 0.0060\n",
      "Epoch 1745/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.0287e-05 - val_loss: 0.0063\n",
      "Epoch 1746/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.9828e-05 - val_loss: 0.0063\n",
      "Epoch 1747/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.4563e-05 - val_loss: 0.0061\n",
      "Epoch 1748/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.1851e-05 - val_loss: 0.0063\n",
      "Epoch 1749/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.6200e-05 - val_loss: 0.0063\n",
      "Epoch 1750/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.6314e-05 - val_loss: 0.0060\n",
      "Epoch 1751/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.3654e-05 - val_loss: 0.0062\n",
      "Epoch 1752/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.4142e-05 - val_loss: 0.0063\n",
      "Epoch 1753/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.1237e-05 - val_loss: 0.0060\n",
      "Epoch 1754/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.9854e-05 - val_loss: 0.0063\n",
      "Epoch 1755/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.9253e-05 - val_loss: 0.0066\n",
      "Epoch 1756/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.8079e-05 - val_loss: 0.0061\n",
      "Epoch 1757/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.9544e-05 - val_loss: 0.0065\n",
      "Epoch 1758/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.8041e-05 - val_loss: 0.0063\n",
      "Epoch 1759/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.9168e-05 - val_loss: 0.0063\n",
      "Epoch 1760/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.0664e-05 - val_loss: 0.0061\n",
      "Epoch 1761/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.3585e-05 - val_loss: 0.0061\n",
      "Epoch 1762/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.0902e-05 - val_loss: 0.0064\n",
      "Epoch 1763/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.8711e-05 - val_loss: 0.0058\n",
      "Epoch 1764/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.0419e-05 - val_loss: 0.0062\n",
      "Epoch 1765/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.7112e-05 - val_loss: 0.0060\n",
      "Epoch 1766/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.6860e-05 - val_loss: 0.0061\n",
      "Epoch 1767/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.2129e-05 - val_loss: 0.0062\n",
      "Epoch 1768/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.6921e-05 - val_loss: 0.0061\n",
      "Epoch 1769/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.7241e-05 - val_loss: 0.0062\n",
      "Epoch 1770/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.4104e-05 - val_loss: 0.0060\n",
      "Epoch 1771/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.3959e-05 - val_loss: 0.0063\n",
      "Epoch 1772/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.6529e-05 - val_loss: 0.0065\n",
      "Epoch 1773/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.8077e-05 - val_loss: 0.0065\n",
      "Epoch 1774/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.1131e-05 - val_loss: 0.0064\n",
      "Epoch 1775/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.3976e-05 - val_loss: 0.0062\n",
      "Epoch 1776/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.9070e-05 - val_loss: 0.0060\n",
      "Epoch 1777/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.0369e-05 - val_loss: 0.0063\n",
      "Epoch 1778/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.1490e-05 - val_loss: 0.0060\n",
      "Epoch 1779/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 8.7809e-05 - val_loss: 0.0063\n",
      "Epoch 1780/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.6183e-05 - val_loss: 0.0064\n",
      "Epoch 1781/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.5699e-05 - val_loss: 0.0061\n",
      "Epoch 1782/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.1664e-05 - val_loss: 0.0063\n",
      "Epoch 1783/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 7.3615e-05 - val_loss: 0.0064\n",
      "Epoch 1784/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.8840e-05 - val_loss: 0.0063\n",
      "Epoch 1785/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.3647e-05 - val_loss: 0.0065\n",
      "Epoch 1786/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.3476e-05 - val_loss: 0.0061\n",
      "Epoch 1787/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.8886e-05 - val_loss: 0.0061\n",
      "Epoch 1788/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.9252e-05 - val_loss: 0.0062\n",
      "Epoch 1789/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.1545e-05 - val_loss: 0.0061\n",
      "Epoch 1790/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.1613e-05 - val_loss: 0.0059\n",
      "Epoch 1791/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.2895e-05 - val_loss: 0.0062\n",
      "Epoch 1792/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.6760e-05 - val_loss: 0.0062\n",
      "Epoch 1793/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.0362e-05 - val_loss: 0.0061\n",
      "Epoch 1794/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.3921e-05 - val_loss: 0.0062\n",
      "Epoch 1795/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.8285e-05 - val_loss: 0.0062\n",
      "Epoch 1796/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.7931e-05 - val_loss: 0.0064\n",
      "Epoch 1797/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.0014e-05 - val_loss: 0.0064\n",
      "Epoch 1798/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.3636e-05 - val_loss: 0.0063\n",
      "Epoch 1799/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.9059e-05 - val_loss: 0.0059\n",
      "Epoch 1800/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.4756e-05 - val_loss: 0.0060\n",
      "Epoch 1801/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.7260e-05 - val_loss: 0.0059\n",
      "Epoch 1802/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.1823e-05 - val_loss: 0.0055\n",
      "Epoch 1803/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.8892e-05 - val_loss: 0.0060\n",
      "Epoch 1804/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.5003e-05 - val_loss: 0.0061\n",
      "Epoch 1805/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.1125e-05 - val_loss: 0.0063\n",
      "Epoch 1806/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.1328e-05 - val_loss: 0.0059\n",
      "Epoch 1807/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.6648e-05 - val_loss: 0.0064\n",
      "Epoch 1808/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.1743e-05 - val_loss: 0.0060\n",
      "Epoch 1809/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.2314e-05 - val_loss: 0.0060\n",
      "Epoch 1810/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.6757e-05 - val_loss: 0.0062\n",
      "Epoch 1811/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.3833e-05 - val_loss: 0.0058\n",
      "Epoch 1812/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.1343e-05 - val_loss: 0.0059\n",
      "Epoch 1813/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.8473e-05 - val_loss: 0.0061\n",
      "Epoch 1814/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.5384e-05 - val_loss: 0.0060\n",
      "Epoch 1815/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.9034e-05 - val_loss: 0.0061\n",
      "Epoch 1816/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.9890e-05 - val_loss: 0.0057\n",
      "Epoch 1817/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.0938e-05 - val_loss: 0.0061\n",
      "Epoch 1818/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.2370e-05 - val_loss: 0.0062\n",
      "Epoch 1819/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.9670e-05 - val_loss: 0.0060\n",
      "Epoch 1820/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 1.0190e-04 - val_loss: 0.0058\n",
      "Epoch 1821/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.8452e-05 - val_loss: 0.0061\n",
      "Epoch 1822/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.6144e-05 - val_loss: 0.0062\n",
      "Epoch 1823/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.0246e-05 - val_loss: 0.0065\n",
      "Epoch 1824/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.0602e-05 - val_loss: 0.0061\n",
      "Epoch 1825/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.9663e-05 - val_loss: 0.0060\n",
      "Epoch 1826/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.1274e-04 - val_loss: 0.0063\n",
      "Epoch 1827/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.2513e-04 - val_loss: 0.0056\n",
      "Epoch 1828/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.1694e-04 - val_loss: 0.0061\n",
      "Epoch 1829/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0507e-04 - val_loss: 0.0057\n",
      "Epoch 1830/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 1.0732e-04 - val_loss: 0.0063\n",
      "Epoch 1831/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 1.0215e-04 - val_loss: 0.0058\n",
      "Epoch 1832/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 9.1434e-05 - val_loss: 0.0062\n",
      "Epoch 1833/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.8394e-05 - val_loss: 0.0063\n",
      "Epoch 1834/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.0605e-05 - val_loss: 0.0059\n",
      "Epoch 1835/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.8886e-05 - val_loss: 0.0062\n",
      "Epoch 1836/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 1.0137e-04 - val_loss: 0.0059\n",
      "Epoch 1837/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.7886e-05 - val_loss: 0.0058\n",
      "Epoch 1838/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.9945e-05 - val_loss: 0.0058\n",
      "Epoch 1839/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.5227e-05 - val_loss: 0.0059\n",
      "Epoch 1840/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 8.6119e-05 - val_loss: 0.0060\n",
      "Epoch 1841/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.2615e-05 - val_loss: 0.0059\n",
      "Epoch 1842/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.8170e-05 - val_loss: 0.0056\n",
      "Epoch 1843/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.7227e-05 - val_loss: 0.0055\n",
      "Epoch 1844/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.2814e-05 - val_loss: 0.0059\n",
      "Epoch 1845/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.8019e-05 - val_loss: 0.0058\n",
      "Epoch 1846/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.2756e-05 - val_loss: 0.0060\n",
      "Epoch 1847/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.6218e-05 - val_loss: 0.0058\n",
      "Epoch 1848/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.0316e-05 - val_loss: 0.0058\n",
      "Epoch 1849/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.9637e-05 - val_loss: 0.0058\n",
      "Epoch 1850/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.5069e-05 - val_loss: 0.0058\n",
      "Epoch 1851/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.4358e-05 - val_loss: 0.0060\n",
      "Epoch 1852/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.2896e-05 - val_loss: 0.0057\n",
      "Epoch 1853/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.9457e-05 - val_loss: 0.0059\n",
      "Epoch 1854/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 9.1255e-05 - val_loss: 0.0057\n",
      "Epoch 1855/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.4541e-05 - val_loss: 0.0059\n",
      "Epoch 1856/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.3709e-05 - val_loss: 0.0059\n",
      "Epoch 1857/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.8029e-05 - val_loss: 0.0059\n",
      "Epoch 1858/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.5386e-05 - val_loss: 0.0061\n",
      "Epoch 1859/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.2283e-05 - val_loss: 0.0058\n",
      "Epoch 1860/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.2310e-05 - val_loss: 0.0059\n",
      "Epoch 1861/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.0905e-05 - val_loss: 0.0058\n",
      "Epoch 1862/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.9191e-05 - val_loss: 0.0062\n",
      "Epoch 1863/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.2003e-05 - val_loss: 0.0063\n",
      "Epoch 1864/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.0773e-05 - val_loss: 0.0061\n",
      "Epoch 1865/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.7588e-05 - val_loss: 0.0063\n",
      "Epoch 1866/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.8069e-05 - val_loss: 0.0062\n",
      "Epoch 1867/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 8.1470e-05 - val_loss: 0.0060\n",
      "Epoch 1868/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.4898e-05 - val_loss: 0.0061\n",
      "Epoch 1869/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.2047e-05 - val_loss: 0.0062\n",
      "Epoch 1870/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.3808e-05 - val_loss: 0.0059\n",
      "Epoch 1871/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.2701e-05 - val_loss: 0.0060\n",
      "Epoch 1872/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.6566e-05 - val_loss: 0.0060\n",
      "Epoch 1873/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.8484e-05 - val_loss: 0.0060\n",
      "Epoch 1874/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.6036e-05 - val_loss: 0.0062\n",
      "Epoch 1875/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.6459e-05 - val_loss: 0.0061\n",
      "Epoch 1876/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.7368e-05 - val_loss: 0.0062\n",
      "Epoch 1877/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.4606e-05 - val_loss: 0.0064\n",
      "Epoch 1878/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.0735e-05 - val_loss: 0.0064\n",
      "Epoch 1879/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.6117e-05 - val_loss: 0.0064\n",
      "Epoch 1880/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.9846e-05 - val_loss: 0.0060\n",
      "Epoch 1881/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.3012e-05 - val_loss: 0.0061\n",
      "Epoch 1882/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.4551e-05 - val_loss: 0.0061\n",
      "Epoch 1883/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.9016e-05 - val_loss: 0.0063\n",
      "Epoch 1884/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.6232e-05 - val_loss: 0.0059\n",
      "Epoch 1885/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.1496e-05 - val_loss: 0.0063\n",
      "Epoch 1886/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.3322e-05 - val_loss: 0.0060\n",
      "Epoch 1887/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.7422e-05 - val_loss: 0.0061\n",
      "Epoch 1888/2000\n",
      "3811/3811 [==============================] - 1s 205us/step - loss: 7.3515e-05 - val_loss: 0.0062\n",
      "Epoch 1889/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.9652e-05 - val_loss: 0.0060\n",
      "Epoch 1890/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.3917e-05 - val_loss: 0.0060\n",
      "Epoch 1891/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.8399e-05 - val_loss: 0.0063\n",
      "Epoch 1892/2000\n",
      "3811/3811 [==============================] - 1s 213us/step - loss: 9.1611e-05 - val_loss: 0.0061\n",
      "Epoch 1893/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 8.9200e-05 - val_loss: 0.0061\n",
      "Epoch 1894/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 7.9771e-05 - val_loss: 0.0061\n",
      "Epoch 1895/2000\n",
      "3811/3811 [==============================] - 1s 218us/step - loss: 7.5829e-05 - val_loss: 0.0064\n",
      "Epoch 1896/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.2056e-05 - val_loss: 0.0062\n",
      "Epoch 1897/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 6.8971e-05 - val_loss: 0.0060\n",
      "Epoch 1898/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 6.8799e-05 - val_loss: 0.0060\n",
      "Epoch 1899/2000\n",
      "3811/3811 [==============================] - 1s 211us/step - loss: 6.5443e-05 - val_loss: 0.0058\n",
      "Epoch 1900/2000\n",
      "3811/3811 [==============================] - 1s 215us/step - loss: 6.7648e-05 - val_loss: 0.0059\n",
      "Epoch 1901/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.2799e-05 - val_loss: 0.0058\n",
      "Epoch 1902/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.3191e-05 - val_loss: 0.0058\n",
      "Epoch 1903/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.0791e-05 - val_loss: 0.0060\n",
      "Epoch 1904/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.5979e-05 - val_loss: 0.0058\n",
      "Epoch 1905/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.8202e-05 - val_loss: 0.0061\n",
      "Epoch 1906/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.6172e-05 - val_loss: 0.0058\n",
      "Epoch 1907/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.8197e-05 - val_loss: 0.0060\n",
      "Epoch 1908/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.0191e-05 - val_loss: 0.0058\n",
      "Epoch 1909/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.7755e-05 - val_loss: 0.0059\n",
      "Epoch 1910/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.9362e-05 - val_loss: 0.0060\n",
      "Epoch 1911/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.7897e-05 - val_loss: 0.0058\n",
      "Epoch 1912/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.5408e-05 - val_loss: 0.0057\n",
      "Epoch 1913/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.5964e-05 - val_loss: 0.0058\n",
      "Epoch 1914/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.2139e-05 - val_loss: 0.0058\n",
      "Epoch 1915/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.0899e-05 - val_loss: 0.0056\n",
      "Epoch 1916/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.4721e-05 - val_loss: 0.0057\n",
      "Epoch 1917/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.2381e-05 - val_loss: 0.0060\n",
      "Epoch 1918/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.8754e-05 - val_loss: 0.0057\n",
      "Epoch 1919/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.4407e-05 - val_loss: 0.0060\n",
      "Epoch 1920/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 7.3212e-05 - val_loss: 0.0058\n",
      "Epoch 1921/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.7269e-05 - val_loss: 0.0055\n",
      "Epoch 1922/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.7145e-05 - val_loss: 0.0061\n",
      "Epoch 1923/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.2361e-05 - val_loss: 0.0058\n",
      "Epoch 1924/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.5441e-05 - val_loss: 0.0059\n",
      "Epoch 1925/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.5799e-05 - val_loss: 0.0058\n",
      "Epoch 1926/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.5625e-05 - val_loss: 0.0060\n",
      "Epoch 1927/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.7755e-05 - val_loss: 0.0057\n",
      "Epoch 1928/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.8693e-05 - val_loss: 0.0059\n",
      "Epoch 1929/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.1043e-05 - val_loss: 0.0058\n",
      "Epoch 1930/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2116e-05 - val_loss: 0.0058\n",
      "Epoch 1931/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.4098e-05 - val_loss: 0.0056\n",
      "Epoch 1932/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.0804e-05 - val_loss: 0.0059\n",
      "Epoch 1933/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 5.9258e-05 - val_loss: 0.0057\n",
      "Epoch 1934/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.2169e-05 - val_loss: 0.0060\n",
      "Epoch 1935/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.3980e-05 - val_loss: 0.0059\n",
      "Epoch 1936/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 6.6461e-05 - val_loss: 0.0060\n",
      "Epoch 1937/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.0121e-05 - val_loss: 0.0058\n",
      "Epoch 1938/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.5171e-05 - val_loss: 0.0060\n",
      "Epoch 1939/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.2695e-05 - val_loss: 0.0057\n",
      "Epoch 1940/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 7.0150e-05 - val_loss: 0.0061\n",
      "Epoch 1941/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.4169e-05 - val_loss: 0.0059\n",
      "Epoch 1942/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.9774e-05 - val_loss: 0.0058\n",
      "Epoch 1943/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.7665e-05 - val_loss: 0.0060\n",
      "Epoch 1944/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.4580e-05 - val_loss: 0.0062\n",
      "Epoch 1945/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.1620e-05 - val_loss: 0.0060\n",
      "Epoch 1946/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.2180e-05 - val_loss: 0.0057\n",
      "Epoch 1947/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.0547e-05 - val_loss: 0.0062\n",
      "Epoch 1948/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.3072e-05 - val_loss: 0.0057\n",
      "Epoch 1949/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.0548e-05 - val_loss: 0.0057\n",
      "Epoch 1950/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.7894e-05 - val_loss: 0.0059\n",
      "Epoch 1951/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.4861e-05 - val_loss: 0.0059\n",
      "Epoch 1952/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.1407e-05 - val_loss: 0.0059\n",
      "Epoch 1953/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.9863e-05 - val_loss: 0.0059\n",
      "Epoch 1954/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.9347e-05 - val_loss: 0.0057\n",
      "Epoch 1955/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 6.6936e-05 - val_loss: 0.0059\n",
      "Epoch 1956/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.7425e-05 - val_loss: 0.0058\n",
      "Epoch 1957/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3009e-05 - val_loss: 0.0056\n",
      "Epoch 1958/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.7610e-05 - val_loss: 0.0059\n",
      "Epoch 1959/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.9320e-05 - val_loss: 0.0057\n",
      "Epoch 1960/2000\n",
      "3811/3811 [==============================] - 1s 214us/step - loss: 6.5872e-05 - val_loss: 0.0056\n",
      "Epoch 1961/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.7272e-05 - val_loss: 0.0059\n",
      "Epoch 1962/2000\n",
      "3811/3811 [==============================] - 1s 216us/step - loss: 7.2471e-05 - val_loss: 0.0058\n",
      "Epoch 1963/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 7.5577e-05 - val_loss: 0.0061\n",
      "Epoch 1964/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.7138e-05 - val_loss: 0.0057\n",
      "Epoch 1965/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.4858e-05 - val_loss: 0.0060\n",
      "Epoch 1966/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.4165e-05 - val_loss: 0.0060\n",
      "Epoch 1967/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.2090e-05 - val_loss: 0.0057\n",
      "Epoch 1968/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.4360e-05 - val_loss: 0.0057\n",
      "Epoch 1969/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 6.1565e-05 - val_loss: 0.0059\n",
      "Epoch 1970/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 5.8401e-05 - val_loss: 0.0061\n",
      "Epoch 1971/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 6.3161e-05 - val_loss: 0.0056\n",
      "Epoch 1972/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.5913e-05 - val_loss: 0.0058\n",
      "Epoch 1973/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 5.8000e-05 - val_loss: 0.0058\n",
      "Epoch 1974/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 6.7145e-05 - val_loss: 0.0056\n",
      "Epoch 1975/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 6.6927e-05 - val_loss: 0.0058\n",
      "Epoch 1976/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.3265e-05 - val_loss: 0.0057\n",
      "Epoch 1977/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.5298e-05 - val_loss: 0.0057\n",
      "Epoch 1978/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.7786e-05 - val_loss: 0.0057\n",
      "Epoch 1979/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 8.8744e-05 - val_loss: 0.0059\n",
      "Epoch 1980/2000\n",
      "3811/3811 [==============================] - 1s 212us/step - loss: 9.1792e-05 - val_loss: 0.0056\n",
      "Epoch 1981/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 9.3765e-05 - val_loss: 0.0060\n",
      "Epoch 1982/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.1578e-05 - val_loss: 0.0056\n",
      "Epoch 1983/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.3211e-05 - val_loss: 0.0059\n",
      "Epoch 1984/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.5279e-05 - val_loss: 0.0057\n",
      "Epoch 1985/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 9.0547e-05 - val_loss: 0.0056\n",
      "Epoch 1986/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 8.2778e-05 - val_loss: 0.0055\n",
      "Epoch 1987/2000\n",
      "3811/3811 [==============================] - 1s 209us/step - loss: 8.4460e-05 - val_loss: 0.0055\n",
      "Epoch 1988/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.4441e-05 - val_loss: 0.0056\n",
      "Epoch 1989/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.6198e-05 - val_loss: 0.0058\n",
      "Epoch 1990/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.1520e-05 - val_loss: 0.0058\n",
      "Epoch 1991/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.4453e-05 - val_loss: 0.0060\n",
      "Epoch 1992/2000\n",
      "3811/3811 [==============================] - 1s 207us/step - loss: 7.4693e-05 - val_loss: 0.0058\n",
      "Epoch 1993/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.3990e-05 - val_loss: 0.0059\n",
      "Epoch 1994/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.5427e-05 - val_loss: 0.0058\n",
      "Epoch 1995/2000\n",
      "3811/3811 [==============================] - 1s 208us/step - loss: 7.2809e-05 - val_loss: 0.0059\n",
      "Epoch 1996/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.4742e-05 - val_loss: 0.0058\n",
      "Epoch 1997/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 7.6317e-05 - val_loss: 0.0061\n",
      "Epoch 1998/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.4973e-05 - val_loss: 0.0055\n",
      "Epoch 1999/2000\n",
      "3811/3811 [==============================] - 1s 206us/step - loss: 8.6857e-05 - val_loss: 0.0056\n",
      "Epoch 2000/2000\n",
      "3811/3811 [==============================] - 1s 210us/step - loss: 7.6760e-05 - val_loss: 0.0058\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'softsign',\n",
       " 'shuffle': True,\n",
       " 'lstmsize': 104,\n",
       " 'full_density': True,\n",
       " 'twice': False,\n",
       " 'optimizer': 'adam',\n",
       " 'density': 180,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x25663168448>]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_315 (LSTM)              (None, 104)               45760     \n",
      "_________________________________________________________________\n",
      "dense_918 (Dense)            (None, 180)               18900     \n",
      "_________________________________________________________________\n",
      "dense_919 (Dense)            (None, 90)                16290     \n",
      "_________________________________________________________________\n",
      "dense_920 (Dense)            (None, 45)                4095      \n",
      "_________________________________________________________________\n",
      "dense_921 (Dense)            (None, 22)                1012      \n",
      "_________________________________________________________________\n",
      "dense_922 (Dense)            (None, 1)                 23        \n",
      "=================================================================\n",
      "Total params: 86,080\n",
      "Trainable params: 86,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_5days/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 29.14\n",
      "Medium error is 4.44\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 56.67%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 33.33%\n",
      "Accuracy for downward trend is: 80.00%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 60 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(60), true_y_test)\n",
    "plt.plot(range(60), predicted_y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last 20 days + prediction of last 10 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(20), true_y_test[-20:])\n",
    "plt.plot(range(20), np.append(true_y_test[-20:-10], predicted_y_test[-10:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
