{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 5\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(data),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(len(index)):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "normaliser = preprocessing.MinMaxScaler()\n",
    "data_norm = normaliser.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised chunks\n",
    "historical_sequences_norm = np.array([data_norm[ix].copy() for ix in ordered_index])\n",
    "next_day_open_values_norm = np.array([data_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "next_day_open_values_norm = np.expand_dims(next_day_open_values_norm, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "historical_sequences_norm = historical_sequences_norm[:next_day_open_values_norm.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4755, 92, 5)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "historical_sequences_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4755, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_day_open_values_norm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.32507933],\n",
       "       [0.31792447],\n",
       "       [0.29925963],\n",
       "       ...,\n",
       "       [0.47601568],\n",
       "       [0.44328999],\n",
       "       [0.46319915]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y raw data\n",
    "next_day_open_values = np.array([data.to_numpy()[ordered_index[i+days][-1],0] for i in range(len(ordered_index) - days)])\n",
    "next_day_open_values = np.expand_dims(next_day_open_values, -1)\n",
    "\n",
    "# Y normaliser\n",
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "y_normaliser.fit_transform(next_day_open_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(historical_sequences_norm.shape[0] * train_size)\n",
    "\n",
    "X_train = historical_sequences_norm[:split]\n",
    "Y_train = next_day_open_values_norm[:split]\n",
    "\n",
    "X_test = historical_sequences_norm[split:]\n",
    "Y_test = next_day_open_values_norm[split:]\n",
    "unscaled_y_test = next_day_open_values[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0557 - val_loss: 0.0053\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 158us/step - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 158us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 157us/step - loss: 0.0022 - val_loss: 0.0178\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 163us/step - loss: 0.0037 - val_loss: 0.0565\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 159us/step - loss: 0.0038 - val_loss: 0.0342\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 157us/step - loss: 0.0118 - val_loss: 0.0439\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 157us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 168us/step - loss: 0.0016 - val_loss: 0.0188\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 158us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 159us/step - loss: 0.0130 - val_loss: 0.0189\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 158us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 170us/step - loss: 0.0016 - val_loss: 0.0209\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 157us/step - loss: 0.0020 - val_loss: 0.0141\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 158us/step - loss: 0.0072 - val_loss: 0.0315\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 158us/step - loss: 0.0029 - val_loss: 0.0092\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 159us/step - loss: 0.0022 - val_loss: 0.0202\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 159us/step - loss: 0.0022 - val_loss: 0.0061\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 160us/step - loss: 0.0056 - val_loss: 0.0309\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 178us/step - loss: 0.0031 - val_loss: 0.0136\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 177us/step - loss: 0.0027 - val_loss: 0.0224\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 165us/step - loss: 0.0026 - val_loss: 0.0080\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 168us/step - loss: 0.0028 - val_loss: 0.0311\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 164us/step - loss: 0.0033 - val_loss: 0.0194\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 1s 288us/step - loss: 0.0482 - val_loss: 0.1258\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 163us/step - loss: 0.0297 - val_loss: 0.0132\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 159us/step - loss: 0.0102 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 159us/step - loss: 0.0091 - val_loss: 0.0100\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 160us/step - loss: 0.0090 - val_loss: 0.0121\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 163us/step - loss: 0.0078 - val_loss: 0.0079\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 163us/step - loss: 0.0085 - val_loss: 0.0136\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 166us/step - loss: 0.0077 - val_loss: 0.0098\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 160us/step - loss: 0.0079 - val_loss: 0.0101\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 158us/step - loss: 0.0069 - val_loss: 0.0085\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 159us/step - loss: 0.0068 - val_loss: 0.0092\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 161us/step - loss: 0.0064 - val_loss: 0.0078\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 161us/step - loss: 0.0065 - val_loss: 0.0082\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 160us/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 159us/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 158us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 161us/step - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 172us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 162us/step - loss: 0.0061 - val_loss: 0.0053\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 164us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 163us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 161us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 162us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 160us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.2556 - val_loss: 0.1718\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0576 - val_loss: 0.0091\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 332us/step - loss: 0.0197 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 342us/step - loss: 0.0125 - val_loss: 0.0258\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 334us/step - loss: 0.0110 - val_loss: 0.0180\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 334us/step - loss: 0.0114 - val_loss: 0.0290\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 334us/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0111 - val_loss: 0.0265\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0094 - val_loss: 0.0227\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0069 - val_loss: 0.0124\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 332us/step - loss: 0.0097 - val_loss: 0.0197\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 333us/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 334us/step - loss: 0.0086 - val_loss: 0.0239\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 333us/step - loss: 0.0061 - val_loss: 0.0081\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 337us/step - loss: 0.0070 - val_loss: 0.0269\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0079 - val_loss: 0.0056\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 344us/step - loss: 0.0058 - val_loss: 0.0194\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 332us/step - loss: 0.0056 - val_loss: 0.0071\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 334us/step - loss: 0.0061 - val_loss: 0.0216\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 334us/step - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 336us/step - loss: 0.0053 - val_loss: 0.0134\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 332us/step - loss: 0.0050 - val_loss: 0.0082\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 335us/step - loss: 0.0061 - val_loss: 0.0149\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 793us/step - loss: 3.4461 - val_loss: 0.0320\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0350 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0053 - val_loss: 0.0118\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 868us/step - loss: 0.1712 - val_loss: 0.0311\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0310 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0079 - val_loss: 0.0095\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0040 - val_loss: 0.0070\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 614us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 869us/step - loss: 0.2321 - val_loss: 0.0742\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0409 - val_loss: 0.0293\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0146 - val_loss: 0.0136\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0049 - val_loss: 0.0072\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0033 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 930us/step - loss: 0.1258 - val_loss: 0.0061\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0240 - val_loss: 0.0117\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0112 - val_loss: 0.0100\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0074 - val_loss: 0.0144\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0038 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 612us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 908us/step - loss: 0.0956 - val_loss: 0.0408\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0204 - val_loss: 0.0202\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0096 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0020 - val_loss: 0.0045\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 936us/step - loss: 0.1316 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0153 - val_loss: 0.0108\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0104 - val_loss: 0.0119\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0062 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0049 - val_loss: 0.0074\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 911us/step - loss: 0.1058 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0151 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0098 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0086 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0079 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0078 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0077 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0075 - val_loss: 0.0034\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0075 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0073 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0072 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0060 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0060 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0057 - val_loss: 0.0034\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 817us/step - loss: 0.2406 - val_loss: 0.1527\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0596 - val_loss: 0.0091\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0258 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0118 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0086 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 398us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 400us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 3s 1ms/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 3s 782us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 674us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0027 - val_loss: 0.0046\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.1205 - val_loss: 0.0489\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0424 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0146 - val_loss: 0.0097\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0097 - val_loss: 0.0083\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0053 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0039 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 937us/step - loss: 2.4251 - val_loss: 0.0232\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.1760 - val_loss: 0.0783\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.1001 - val_loss: 0.0112\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0824 - val_loss: 0.0805\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0778 - val_loss: 0.0179\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0772 - val_loss: 0.0221\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0737 - val_loss: 0.0429\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0733 - val_loss: 0.0287\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0721 - val_loss: 0.0246\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0718 - val_loss: 0.0309\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0701 - val_loss: 0.0282\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0677 - val_loss: 0.0233\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0654 - val_loss: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0549 - val_loss: 0.0092\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0457 - val_loss: 0.0112\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0215 - val_loss: 0.0289\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0125 - val_loss: 0.0607\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0108 - val_loss: 0.0145\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0086 - val_loss: 0.0222\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0073 - val_loss: 0.0183\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0067 - val_loss: 0.0167\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0063 - val_loss: 0.0223\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0060 - val_loss: 0.0178\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0055 - val_loss: 0.0124\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 962us/step - loss: 0.1114 - val_loss: 0.0466\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0397 - val_loss: 0.0112\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0125 - val_loss: 0.0219\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0083 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0061 - val_loss: 0.0059\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 994us/step - loss: 0.1504 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0855 - val_loss: 0.0493\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0408 - val_loss: 0.0106\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0104 - val_loss: 0.0172\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0075 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0052 - val_loss: 0.0076\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0048 - val_loss: 0.0095\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0040 - val_loss: 0.0067\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0034 - val_loss: 0.0057\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0032 - val_loss: 0.0060\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.0924 - val_loss: 0.0183\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0350 - val_loss: 0.0116\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0134 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0102 - val_loss: 0.0102\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0076 - val_loss: 0.0378\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0064 - val_loss: 0.0187\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0052 - val_loss: 0.0107\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0051 - val_loss: 0.0143\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0047 - val_loss: 0.0163\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0043 - val_loss: 0.0149\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0041 - val_loss: 0.0113\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0033 - val_loss: 0.0066\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 487us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 488us/step - loss: 0.0030 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0029 - val_loss: 0.0057\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 3s 912us/step - loss: 0.1405 - val_loss: 0.0101\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0752 - val_loss: 0.0315\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 357us/step - loss: 0.0307 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0107 - val_loss: 0.0113\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0069 - val_loss: 0.0120\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0057 - val_loss: 0.0151\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0051 - val_loss: 0.0130\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0041 - val_loss: 0.0081\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0038 - val_loss: 0.0078\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0039 - val_loss: 0.0075\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0036 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 358us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 354us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 353us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 350us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 352us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 351us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.1375 - val_loss: 0.0064\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0181 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0078 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0056 - val_loss: 0.0123\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.1339 - val_loss: 0.0097\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0334 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0118 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0077 - val_loss: 0.0120\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0039 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.2151 - val_loss: 0.0156\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0486 - val_loss: 0.0362\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0206 - val_loss: 0.0103\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0070 - val_loss: 0.0110\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0043 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.1095 - val_loss: 0.0446\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0295 - val_loss: 0.0223\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0121 - val_loss: 0.0105\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0072 - val_loss: 0.0105\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.1740 - val_loss: 0.0743\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0313 - val_loss: 0.0067\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0114 - val_loss: 0.0103\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0080 - val_loss: 0.0119\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0059 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0027 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0025 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0022 - val_loss: 0.0057\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.1069 - val_loss: 0.0156\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0207 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0067 - val_loss: 0.0086\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.2830 - val_loss: 0.0217\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0081 - val_loss: 0.0099\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0044 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0044 - val_loss: 0.0137\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0033 - val_loss: 0.0088\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0045 - val_loss: 0.0095\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0098 - val_loss: 0.0054\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0035 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0038 - val_loss: 0.0046\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.1084 - val_loss: 0.0061\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0058 - val_loss: 0.0167\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0094 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0047 - val_loss: 0.0083\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0052 - val_loss: 0.0109\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0055 - val_loss: 0.0105\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0031 - val_loss: 0.0065\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0055 - val_loss: 0.0069\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0032 - val_loss: 0.0073\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 4s 1ms/step - loss: 0.1587 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0045 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0077 - val_loss: 0.0186\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0113 - val_loss: 0.0099\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0122 - val_loss: 0.0067\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0108 - val_loss: 0.0148\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0107 - val_loss: 0.0094\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0080 - val_loss: 0.0090\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0080 - val_loss: 0.0142\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0077 - val_loss: 0.0093\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0078 - val_loss: 0.0071\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0070 - val_loss: 0.0112\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0067 - val_loss: 0.0098\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0063 - val_loss: 0.0130\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0062 - val_loss: 0.0076\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0064 - val_loss: 0.0074\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0047 - val_loss: 0.0105\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.0920 - val_loss: 0.0227\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0202 - val_loss: 0.0213\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 400us/step - loss: 0.0109 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0055 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0021 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.1188 - val_loss: 0.0111\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0164 - val_loss: 0.0262\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0041 - val_loss: 0.0075\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.4125 - val_loss: 0.0158\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0367 - val_loss: 0.0068\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0097 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0058 - val_loss: 0.0081\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0032 - val_loss: 0.0067\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 2ms/step - loss: 0.2616 - val_loss: 0.0092\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0405 - val_loss: 0.0453\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0240 - val_loss: 0.0113\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0048 - val_loss: 0.0103\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0037 - val_loss: 0.0157\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0035 - val_loss: 0.0120\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0032 - val_loss: 0.0126\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0031 - val_loss: 0.0139\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0031 - val_loss: 0.0088\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0028 - val_loss: 0.0077\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0028 - val_loss: 0.0089\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0027 - val_loss: 0.0093\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0026 - val_loss: 0.0092\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0026 - val_loss: 0.0084\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0082\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0025 - val_loss: 0.0088\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0024 - val_loss: 0.0054\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0024 - val_loss: 0.0078\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0022 - val_loss: 0.0060\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0023 - val_loss: 0.0072\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0029 - val_loss: 0.0101\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0022 - val_loss: 0.0064\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.4837 - val_loss: 0.0372\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0676 - val_loss: 0.0133\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 398us/step - loss: 0.0604 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0649 - val_loss: 0.0138\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 401us/step - loss: 0.0144 - val_loss: 0.0220\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 398us/step - loss: 0.0062 - val_loss: 0.0434\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0084 - val_loss: 0.0150\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0069 - val_loss: 0.0351\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0058 - val_loss: 0.0106\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0064 - val_loss: 0.0254\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0061 - val_loss: 0.0074\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0066 - val_loss: 0.0244\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 420us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 400us/step - loss: 0.0049 - val_loss: 0.0151\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0048 - val_loss: 0.0138\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0062 - val_loss: 0.0187\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0042 - val_loss: 0.0078\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0051 - val_loss: 0.0149\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0040 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0035 - val_loss: 0.0093\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.9173 - val_loss: 0.0313\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0732 - val_loss: 0.0271\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0666 - val_loss: 0.0236\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0515 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0352 - val_loss: 0.0076\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0127 - val_loss: 0.0390\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0097 - val_loss: 0.0356\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 0.0375 - val_loss: 0.0053\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0074 - val_loss: 0.0142\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0055 - val_loss: 0.0138\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0053 - val_loss: 0.0109\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0050 - val_loss: 0.0101\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0048 - val_loss: 0.0100\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0046 - val_loss: 0.0091\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0044 - val_loss: 0.0093\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0045 - val_loss: 0.0066\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 401us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0040 - val_loss: 0.0068\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0038 - val_loss: 0.0089\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0047 - val_loss: 0.0144\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0059 - val_loss: 0.0045\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.3089 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0126 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0069 - val_loss: 0.0223\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0028 - val_loss: 0.0046\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 398us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0029 - val_loss: 0.0064\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: 0.0028 - val_loss: 0.0074\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 1ms/step - loss: 0.4749 - val_loss: 0.0098\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0124 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 398us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0033 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 398us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 400us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 401us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 5s 2ms/step - loss: 1.2987 - val_loss: 0.0083\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0173 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0075 - val_loss: 0.0176\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0035 - val_loss: 0.0052\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0028 - val_loss: 0.0050\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 503us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 0.5090 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0208 - val_loss: 0.0185\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0147 - val_loss: 0.0111\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0088 - val_loss: 0.0145\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0068 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0053 - val_loss: 0.0069\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0046 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0032 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 0.0983 - val_loss: 0.0352\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0183 - val_loss: 0.0071\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0071 - val_loss: 0.0100\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0031 - val_loss: 0.0048\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 0.2815 - val_loss: 0.0091\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0317 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0150 - val_loss: 0.0152\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0032 - val_loss: 0.0087\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0034 - val_loss: 0.0178\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0030 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0033 - val_loss: 0.0109\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0027 - val_loss: 0.0067\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0031 - val_loss: 0.0145\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0028 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0023 - val_loss: 0.0056\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0024 - val_loss: 0.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0023 - val_loss: 0.0151\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0026 - val_loss: 0.0075\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0020 - val_loss: 0.0078\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0020 - val_loss: 0.0078\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 0.3445 - val_loss: 0.0134\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0348 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0122 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0055 - val_loss: 0.0130\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0038 - val_loss: 0.0142\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.0036 - val_loss: 0.0075\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0037 - val_loss: 0.0114\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0034 - val_loss: 0.0095\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0034 - val_loss: 0.0078\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0032 - val_loss: 0.0080\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0032 - val_loss: 0.0116\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.0032 - val_loss: 0.0059\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: 0.0032 - val_loss: 0.0102\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0030 - val_loss: 0.0096\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: 0.0030 - val_loss: 0.0068\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.0029 - val_loss: 0.0081\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0029 - val_loss: 0.0095\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0029 - val_loss: 0.0082\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0027 - val_loss: 0.0086\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: 0.0028 - val_loss: 0.0090\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0026 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0026 - val_loss: 0.0071\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 7s 2ms/step - loss: 0.2282 - val_loss: 0.0068\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.0696 - val_loss: 0.0099\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0209 - val_loss: 0.0098\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0260 - val_loss: 0.0092\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0045 - val_loss: 0.0101\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0037 - val_loss: 0.0089\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0035 - val_loss: 0.0075\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0033 - val_loss: 0.0058\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0032 - val_loss: 0.0076\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0030 - val_loss: 0.0099\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0033 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0030 - val_loss: 0.0081\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0037 - val_loss: 0.0126\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0026 - val_loss: 0.0067\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0028 - val_loss: 0.0074\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0025 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0025 - val_loss: 0.0099\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0025 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0025 - val_loss: 0.0066\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 7s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 6s 2ms/step - loss: 1.3427 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0106 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0081 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 370us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0042 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: 0.0041 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 370us/step - loss: 0.0039 - val_loss: 0.0032\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 7s 2ms/step - loss: 0.2546 - val_loss: 0.2290\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0883 - val_loss: 0.0223\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0374 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0091 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 7s 2ms/step - loss: 0.1082 - val_loss: 0.0141\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0132 - val_loss: 0.0134\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0060 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.0777 - val_loss: 0.0983\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0484 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0092 - val_loss: 0.0142\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0072 - val_loss: 0.0140\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0083 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0043 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0047 - val_loss: 0.0056\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0060 - val_loss: 0.0060\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0037 - val_loss: 0.0064\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0056 - val_loss: 0.0108\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0071 - val_loss: 0.0071\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0042 - val_loss: 0.0046\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0048 - val_loss: 0.0123\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0038 - val_loss: 0.0056\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.1127 - val_loss: 0.0410\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0138 - val_loss: 0.0261\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0141 - val_loss: 0.0092\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0126 - val_loss: 0.0111\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0051 - val_loss: 0.0119\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0092 - val_loss: 0.0148\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0093 - val_loss: 0.0059\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0043 - val_loss: 0.0099\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0079 - val_loss: 0.0092\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0047 - val_loss: 0.0089\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0049 - val_loss: 0.0089\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.1070 - val_loss: 0.0325\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0224 - val_loss: 0.0240\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0097 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0058 - val_loss: 0.0075\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 520us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 520us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.1471 - val_loss: 0.0767\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0267 - val_loss: 0.0123\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0103 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 7s 2ms/step - loss: 0.1126 - val_loss: 0.0486\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 329us/step - loss: 0.0218 - val_loss: 0.0096\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0117 - val_loss: 0.0059\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0074 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 341us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 325us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 325us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 325us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 333us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 325us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 325us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 7s 2ms/step - loss: 0.1491 - val_loss: 0.0455\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0347 - val_loss: 0.0217\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 329us/step - loss: 0.0146 - val_loss: 0.0239\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0081 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0066 - val_loss: 0.0089\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 325us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 334us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0037 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 331us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 332us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 329us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.1067 - val_loss: 0.0212\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 325us/step - loss: 0.0198 - val_loss: 0.0101\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 325us/step - loss: 0.0110 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 329us/step - loss: 0.0072 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0058 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0051 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 329us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 332us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0044 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0040 - val_loss: 0.0045\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 334us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0036 - val_loss: 0.0067\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0035 - val_loss: 0.0055\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0035 - val_loss: 0.0046\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 324us/step - loss: 0.0035 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0032 - val_loss: 0.0058\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 328us/step - loss: 0.0031 - val_loss: 0.0062\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0029 - val_loss: 0.0074\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 326us/step - loss: 0.0029 - val_loss: 0.0088\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 327us/step - loss: 0.0027 - val_loss: 0.0071\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 8s 2ms/step - loss: 0.1078 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: 0.0191 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0099 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 407us/step - loss: 0.0070 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0043 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0022 - val_loss: 0.0049\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 410us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 9s 3ms/step - loss: 0.1453 - val_loss: 0.0047\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0216 - val_loss: 0.0203\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0113 - val_loss: 0.0091\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0062 - val_loss: 0.0118\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0031 - val_loss: 0.0055\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 9s 3ms/step - loss: 0.2314 - val_loss: 0.2349\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.1545 - val_loss: 0.1596\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.1142 - val_loss: 0.1120\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0918 - val_loss: 0.0820\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0793 - val_loss: 0.0627\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0722 - val_loss: 0.0500\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0679 - val_loss: 0.0418\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0651 - val_loss: 0.0362\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0632 - val_loss: 0.0325\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0619 - val_loss: 0.0299\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0608 - val_loss: 0.0280\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0598 - val_loss: 0.0265\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0589 - val_loss: 0.0254\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0581 - val_loss: 0.0243\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0572 - val_loss: 0.0235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0563 - val_loss: 0.0227\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0555 - val_loss: 0.0220\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0545 - val_loss: 0.0214\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0537 - val_loss: 0.0209\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0527 - val_loss: 0.0203\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0517 - val_loss: 0.0196\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0507 - val_loss: 0.0190\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0497 - val_loss: 0.0185\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0486 - val_loss: 0.0180\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 9s 3ms/step - loss: 0.1795 - val_loss: 0.1480\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0950 - val_loss: 0.0656\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0635 - val_loss: 0.0342\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0530 - val_loss: 0.0221\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0483 - val_loss: 0.0166\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0457 - val_loss: 0.0139\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0430 - val_loss: 0.0123\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0409 - val_loss: 0.0107\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0381 - val_loss: 0.0098\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0354 - val_loss: 0.0091\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0328 - val_loss: 0.0082\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0300 - val_loss: 0.0075\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0280 - val_loss: 0.0066\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0258 - val_loss: 0.0058\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0234 - val_loss: 0.0052\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0213 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0190 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0170 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0152 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0133 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0127 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0110 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0099 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0094 - val_loss: 0.0040\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 9s 3ms/step - loss: 0.7630 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0169 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0103 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0078 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0068 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0065 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0057 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 524us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0050 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 529us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 527us/step - loss: 0.0047 - val_loss: 0.0037\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 9s 3ms/step - loss: 1.4122 - val_loss: 0.0142\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0325 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.0178 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0113 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0082 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0071 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.0069 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0061 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0062 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0058 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0056 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0056 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0055 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0052 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 9s 3ms/step - loss: 0.1104 - val_loss: 0.0198\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0404 - val_loss: 0.0097\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0319 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0260 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0209 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0172 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0137 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0116 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0098 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0072 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0067 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0060 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0055 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0050 - val_loss: 0.0050\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 9s 3ms/step - loss: 0.3860 - val_loss: 0.0119\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0983 - val_loss: 0.0145\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0757 - val_loss: 0.0266\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0737 - val_loss: 0.0300\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0737 - val_loss: 0.0307\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0736 - val_loss: 0.0307\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0736 - val_loss: 0.0319\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0736 - val_loss: 0.0324\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0736 - val_loss: 0.0315\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0736 - val_loss: 0.0316\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0736 - val_loss: 0.0304\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0736 - val_loss: 0.0316\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0736 - val_loss: 0.0313\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0736 - val_loss: 0.0318\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0736 - val_loss: 0.0322\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0736 - val_loss: 0.0319\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0736 - val_loss: 0.0310\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0736 - val_loss: 0.0319\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0736 - val_loss: 0.0324\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0736 - val_loss: 0.0318\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0736 - val_loss: 0.0317\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: 0.0736 - val_loss: 0.0325\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0736 - val_loss: 0.0322\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0736 - val_loss: 0.0317\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 10s 3ms/step - loss: 0.1174 - val_loss: 0.0128\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0616 - val_loss: 0.0192\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0474 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: 0.0311 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0214 - val_loss: 0.0086\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0158 - val_loss: 0.0154\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0115 - val_loss: 0.0250\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: 0.0088 - val_loss: 0.0344\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0072 - val_loss: 0.0353\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0062 - val_loss: 0.0259\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0056 - val_loss: 0.0154\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0051 - val_loss: 0.0103\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: 0.0041 - val_loss: 0.0070\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0036 - val_loss: 0.0068\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0032 - val_loss: 0.0074\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0031 - val_loss: 0.0064\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0029 - val_loss: 0.0075\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: 0.0028 - val_loss: 0.0063\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: 0.0027 - val_loss: 0.0072\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 10s 3ms/step - loss: 0.1437 - val_loss: 0.0066\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0149 - val_loss: 0.0208\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0048 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0039 - val_loss: 0.0083\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 11s 3ms/step - loss: 0.1224 - val_loss: 0.0433\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0303 - val_loss: 0.0265\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0131 - val_loss: 0.0116\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 10s 3ms/step - loss: 0.1049 - val_loss: 0.0130\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0153 - val_loss: 0.0127\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0082 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 485us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 483us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 484us/step - loss: 0.0021 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 482us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 486us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 11s 3ms/step - loss: 0.0617 - val_loss: 0.0226\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0105 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0036 - val_loss: 0.0064\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 11s 3ms/step - loss: 0.0718 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0096 - val_loss: 0.0076\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0070 - val_loss: 0.0125\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0032 - val_loss: 0.0066\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 12s 3ms/step - loss: 0.1308 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0181 - val_loss: 0.0250\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0115 - val_loss: 0.0169\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0063 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0030 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 11s 3ms/step - loss: 17629762926785444136567701504.0000 - val_loss: 84121919403002429440.0000\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 14752194253568724705476608.0000 - val_loss: 83853286722104197120.0000\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 5850471016357858392408064.0000 - val_loss: 83721468472073388032.0000\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 56333999302099538425151488.0000 - val_loss: 83598683809576386560.0000\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 95148424548719211969511424.0000 - val_loss: 83594452888832704512.0000\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 509us/step - loss: 121790157555744545508950016.0000 - val_loss: 83589333562693779456.0000\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 1571287508420951575363584.0000 - val_loss: 83588981718972891136.0000\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 511us/step - loss: 1471547108208941820589113344.0000 - val_loss: 83588278031531114496.0000\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 55887388430194577380474880.0000 - val_loss: 83587697489391648768.0000\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 3864357354433746260346273792.0000 - val_loss: 83587037782414983168.0000\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 9057541831613643620612046848.0000 - val_loss: 83586835472275472384.0000\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 26816290609893505341849600.0000 - val_loss: 83586826676182450176.0000\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 7236175927800047270363136.0000 - val_loss: 83586817880089427968.0000\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 11510663017870225286627328.0000 - val_loss: 83586809083996405760.0000\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 680189360121201037578076160.0000 - val_loss: 83586721123066183680.0000\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 41562174130870869194440704.0000 - val_loss: 83586712326973161472.0000\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 64313940164436997286395904.0000 - val_loss: 83586712326973161472.0000\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 5149942824274414972960768.0000 - val_loss: 83586694734787117056.0000\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 66633361951704915181043712.0000 - val_loss: 83586677142601072640.0000\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 4732147857968206148796416.0000 - val_loss: 83586641958228983808.0000\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 508us/step - loss: 1046487621572750143662325760.0000 - val_loss: 83584566080275742720.0000\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 507us/step - loss: 325735368057791120588931072.0000 - val_loss: 83584566080275742720.0000\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 506us/step - loss: 50625812550051063230627840.0000 - val_loss: 83584566080275742720.0000\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 1749268412546484000522240.0000 - val_loss: 83584548488089698304.0000\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 12s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 12s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 12s 3ms/step - loss: 0.2075 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0330 - val_loss: 0.0339\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0171 - val_loss: 0.0281\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0082 - val_loss: 0.0067\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 469us/step - loss: 0.0053 - val_loss: 0.0098\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0036 - val_loss: 0.0043\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 465us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 470us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 467us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 471us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 464us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 466us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 468us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: 0.0798 - val_loss: 0.0217\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0094 - val_loss: 0.0050\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: 0.0871 - val_loss: 0.0403\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0156 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0064 - val_loss: 0.0082\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0044 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: 0.2093 - val_loss: 0.0137\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0337 - val_loss: 0.0256\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0134 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0049 - val_loss: 0.0071\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0027 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 12s 4ms/step - loss: 0.3071 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0044 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0169 - val_loss: 0.0256\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0107 - val_loss: 0.0159\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0197 - val_loss: 0.0139\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0127 - val_loss: 0.0265\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0151 - val_loss: 0.0182\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0201 - val_loss: 0.0209\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0147 - val_loss: 0.0246\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0169 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0041 - val_loss: 0.0159\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0150 - val_loss: 0.0377\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0150 - val_loss: 0.0088\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0111 - val_loss: 0.0241\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0080 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0078 - val_loss: 0.0256\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0108 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0042 - val_loss: 0.0161\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0093 - val_loss: 0.0064\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0076 - val_loss: 0.0105\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 12s 4ms/step - loss: 0.1486 - val_loss: 0.0425\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0207 - val_loss: 0.0170\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0125 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0085 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0050 - val_loss: 0.0094\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0044 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0035 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: 0.0732 - val_loss: 0.0381\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0598 - val_loss: 0.0648\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0750 - val_loss: 0.0302\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0718 - val_loss: 0.0682\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0691 - val_loss: 0.0299\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0678 - val_loss: 0.0141\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0401 - val_loss: 0.0159\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0142 - val_loss: 0.0404\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0071 - val_loss: 0.0550\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0074 - val_loss: 0.0479\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0070 - val_loss: 0.0614\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0063 - val_loss: 0.0503\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0055 - val_loss: 0.0623\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0054 - val_loss: 0.0529\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0050 - val_loss: 0.0609\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0048 - val_loss: 0.0478\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0042 - val_loss: 0.0377\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0044 - val_loss: 0.0505\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0044 - val_loss: 0.0617\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0042 - val_loss: 0.0090\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0052 - val_loss: 0.0248\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0053 - val_loss: 0.0152\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 13s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 419us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 420us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 418us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 14s 4ms/step - loss: 0.1083 - val_loss: 0.0536\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0112 - val_loss: 0.0172\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0142 - val_loss: 0.0151\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0100 - val_loss: 0.0140\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0075 - val_loss: 0.0124\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0075 - val_loss: 0.0109\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0069 - val_loss: 0.0107\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0038 - val_loss: 0.0079\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0050 - val_loss: 0.0077\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0047 - val_loss: 0.0098\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0064 - val_loss: 0.0062\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0044 - val_loss: 0.0076\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0038 - val_loss: 0.0064\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0049 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0043 - val_loss: 0.0066\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0038 - val_loss: 0.0085\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 15s 4ms/step - loss: 0.1001 - val_loss: 0.0466\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0246 - val_loss: 0.0269\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 15s 4ms/step - loss: 0.0912 - val_loss: 0.0504\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0189 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0068 - val_loss: 0.0100\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 16s 5ms/step - loss: 0.1590 - val_loss: 0.0643\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0312 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0128 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0080 - val_loss: 0.0087\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0053 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0043 - val_loss: 0.0088\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 16s 5ms/step - loss: 0.0963 - val_loss: 0.0727\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0311 - val_loss: 0.0259\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0116 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 16s 5ms/step - loss: 0.4256 - val_loss: 0.3551\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.1909 - val_loss: 0.1447\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0968 - val_loss: 0.0540\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0745 - val_loss: 0.0226\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0761 - val_loss: 0.0148\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0780 - val_loss: 0.0156\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0764 - val_loss: 0.0206\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0744 - val_loss: 0.0278\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0735 - val_loss: 0.0336\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0735 - val_loss: 0.0355\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0736 - val_loss: 0.0351\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0736 - val_loss: 0.0335\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0735 - val_loss: 0.0316\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0735 - val_loss: 0.0307\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0735 - val_loss: 0.0308\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0735 - val_loss: 0.0310\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0735 - val_loss: 0.0319\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0735 - val_loss: 0.0320\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0735 - val_loss: 0.0315\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0735 - val_loss: 0.0308\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0735 - val_loss: 0.0313\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0735 - val_loss: 0.0321\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 16s 5ms/step - loss: 0.2190 - val_loss: 0.0356\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0746 - val_loss: 0.0197\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0741 - val_loss: 0.0271\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0726 - val_loss: 0.0260\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0725 - val_loss: 0.0269\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0734 - val_loss: 0.0329\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0732 - val_loss: 0.0296\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0724 - val_loss: 0.0336\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0716 - val_loss: 0.0867\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0712 - val_loss: 0.0493\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0667 - val_loss: 0.0076\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0559 - val_loss: 0.0086\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0771 - val_loss: 0.0232\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0649 - val_loss: 0.0112\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0581 - val_loss: 0.1762\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0596 - val_loss: 0.0150\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0102 - val_loss: 0.0440\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0068 - val_loss: 0.0449\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0050 - val_loss: 0.0340\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0042 - val_loss: 0.0342\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0062 - val_loss: 0.0228\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0086 - val_loss: 0.0118\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0031 - val_loss: 0.0079\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 17s 5ms/step - loss: 0.5649 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0063 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0111 - val_loss: 0.0395\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0038 - val_loss: 0.0060\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0049 - val_loss: 0.0130\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0052 - val_loss: 0.0024\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0024 - val_loss: 0.0051\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 17s 5ms/step - loss: 0.3967 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0067 - val_loss: 0.0236\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0108 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0042 - val_loss: 0.0060\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0041 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0051 - val_loss: 0.0058\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 17s 5ms/step - loss: 0.1570 - val_loss: 0.0917\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0285 - val_loss: 0.0252\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0144 - val_loss: 0.0150\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0076 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0036 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 387us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 17s 5ms/step - loss: 0.1902 - val_loss: 0.0598\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0399 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0084 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0020 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 18s 5ms/step - loss: 0.1059 - val_loss: 0.0337\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0241 - val_loss: 0.0258\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0096 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0047 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 18s 5ms/step - loss: 0.1414 - val_loss: 0.1855\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0447 - val_loss: 0.0122\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0161 - val_loss: 0.0166\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0138 - val_loss: 0.0127\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0161 - val_loss: 0.0143\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0132 - val_loss: 0.0185\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0126 - val_loss: 0.0172\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0134 - val_loss: 0.0138\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0108 - val_loss: 0.0164\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0139 - val_loss: 0.0132\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0093 - val_loss: 0.0081\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0109 - val_loss: 0.0127\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0084 - val_loss: 0.0056\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0091 - val_loss: 0.0154\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0094 - val_loss: 0.0048\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0069 - val_loss: 0.0164\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0077 - val_loss: 0.0115\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0078 - val_loss: 0.0084\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0087 - val_loss: 0.0109\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0048 - val_loss: 0.0086\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0065 - val_loss: 0.0154\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 18s 5ms/step - loss: 0.1613 - val_loss: 0.0069\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0085 - val_loss: 0.0202\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 0.0096 - val_loss: 0.0174\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 477us/step - loss: 0.0122 - val_loss: 0.0325\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0110 - val_loss: 0.0265\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0135 - val_loss: 0.0256\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0125 - val_loss: 0.0250\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 0.0128 - val_loss: 0.0078\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0113 - val_loss: 0.0164\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 0.0099 - val_loss: 0.0194\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0106 - val_loss: 0.0115\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0090 - val_loss: 0.0113\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0099 - val_loss: 0.0137\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0070 - val_loss: 0.0096\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 0.0096 - val_loss: 0.0101\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0074 - val_loss: 0.0081\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 476us/step - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 475us/step - loss: 0.0064 - val_loss: 0.0146\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 474us/step - loss: 0.0085 - val_loss: 0.0070\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 481us/step - loss: 0.0048 - val_loss: 0.0117\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 472us/step - loss: 0.0088 - val_loss: 0.0092\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0050 - val_loss: 0.0081\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 473us/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 480us/step - loss: 0.0050 - val_loss: 0.0073\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 18s 5ms/step - loss: 0.3173 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0074 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0070 - val_loss: 0.0234\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0102 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0122 - val_loss: 0.0203\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0152 - val_loss: 0.0141\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0134 - val_loss: 0.0263\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 550us/step - loss: 0.0180 - val_loss: 0.0088\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0148 - val_loss: 0.0423\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0217 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0062 - val_loss: 0.0156\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0129 - val_loss: 0.0179\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0158 - val_loss: 0.0279\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0078 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0112 - val_loss: 0.0175\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0167 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0090 - val_loss: 0.0150\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0148 - val_loss: 0.0147\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0086 - val_loss: 0.0175\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0124 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0040 - val_loss: 0.0082\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0074 - val_loss: 0.0051\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 18s 5ms/step - loss: 0.2398 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0048 - val_loss: 0.0217\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0120 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0127 - val_loss: 0.0126\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0099 - val_loss: 0.0179\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0135 - val_loss: 0.0160\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0139 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0131 - val_loss: 0.0158\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0128 - val_loss: 0.0088\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0157 - val_loss: 0.0364\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0149 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0044 - val_loss: 0.0150\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0123 - val_loss: 0.0140\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0116 - val_loss: 0.0224\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0109 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0054 - val_loss: 0.0131\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0082 - val_loss: 0.0151\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0160 - val_loss: 0.0078\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0081 - val_loss: 0.0177\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0053 - val_loss: 0.0112\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0066 - val_loss: 0.0156\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0111 - val_loss: 0.0051\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 19s 5ms/step - loss: 0.3088 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0085 - val_loss: 0.0049\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0088 - val_loss: 0.0320\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0096 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0134 - val_loss: 0.0259\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0109 - val_loss: 0.0163\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0141 - val_loss: 0.0158\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0154 - val_loss: 0.0218\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0165 - val_loss: 0.0151\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0128 - val_loss: 0.0178\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0120 - val_loss: 0.0113\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0139 - val_loss: 0.0219\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0089 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0124 - val_loss: 0.0414\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0153 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0148 - val_loss: 0.0131\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0063 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0055 - val_loss: 0.0204\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0111 - val_loss: 0.0098\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0060 - val_loss: 0.0069\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0075 - val_loss: 0.0122\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0105 - val_loss: 0.0083\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0039 - val_loss: 0.0050\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 19s 6ms/step - loss: 0.1768 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0064 - val_loss: 0.0127\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 549us/step - loss: 0.0119 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0052 - val_loss: 0.0083\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0065 - val_loss: 0.0063\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0062 - val_loss: 0.0088\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0055 - val_loss: 0.0108\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0049 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 553us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 552us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0061 - val_loss: 0.0097\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 546us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0061 - val_loss: 0.0109\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 20s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 19s 6ms/step - loss: 0.1434 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0145 - val_loss: 0.0160\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0061 - val_loss: 0.0144\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 20s 6ms/step - loss: 0.0670 - val_loss: 0.0299\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0143 - val_loss: 0.0078\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0036 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0028 - val_loss: 0.0057\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 385us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 380us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 386us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 19s 6ms/step - loss: 0.9182 - val_loss: 0.1568\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0457 - val_loss: 0.0588\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0467 - val_loss: 0.0220\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0295 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0296 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0230 - val_loss: 0.0057\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0168 - val_loss: 0.0046\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 377us/step - loss: 0.0101 - val_loss: 0.0058\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 382us/step - loss: 0.0068 - val_loss: 0.0049\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 384us/step - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0053 - val_loss: 0.0052\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0050 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 377us/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 378us/step - loss: 0.0047 - val_loss: 0.0055\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 379us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 377us/step - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 376us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 381us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 21s 6ms/step - loss: 0.0944 - val_loss: 0.0135\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0305 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0242 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0189 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0157 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0130 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0110 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0095 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 505us/step - loss: 0.0087 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0080 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0073 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 502us/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0067 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0061 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0063 - val_loss: 0.0047\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0062 - val_loss: 0.0049\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0061 - val_loss: 0.0050\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0060 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0060 - val_loss: 0.0051\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 20s 6ms/step - loss: 0.1126 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 500us/step - loss: 0.0250 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0172 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0143 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0124 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0122 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 501us/step - loss: 0.0109 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0109 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0101 - val_loss: 0.0045\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0099 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0091 - val_loss: 0.0046\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0089 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0090 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0085 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0080 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0079 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0076 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0074 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0071 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0070 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0069 - val_loss: 0.0037\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 21s 6ms/step - loss: 0.4574 - val_loss: 0.2583\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.1371 - val_loss: 0.0954\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0837 - val_loss: 0.0528\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0749 - val_loss: 0.0394\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0734 - val_loss: 0.0335\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0732 - val_loss: 0.0326\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0731 - val_loss: 0.0325\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0731 - val_loss: 0.0315\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0731 - val_loss: 0.0317\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0731 - val_loss: 0.0313\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 548us/step - loss: 0.0731 - val_loss: 0.0315\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0731 - val_loss: 0.0313\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0731 - val_loss: 0.0311\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0730 - val_loss: 0.0314\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0730 - val_loss: 0.0317\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0730 - val_loss: 0.0317\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0730 - val_loss: 0.0315\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0730 - val_loss: 0.0307\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0730 - val_loss: 0.0309\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 551us/step - loss: 0.0730 - val_loss: 0.0312\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0730 - val_loss: 0.0316\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0730 - val_loss: 0.0315\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0730 - val_loss: 0.0317\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0730 - val_loss: 0.0319\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 21s 6ms/step - loss: 0.0680 - val_loss: 0.0159\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0412 - val_loss: 0.0078\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0122 - val_loss: 0.0545\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0086 - val_loss: 0.0809\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0057 - val_loss: 0.0561\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0047 - val_loss: 0.0551\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0041 - val_loss: 0.0573\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0038 - val_loss: 0.0604\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 0.0036 - val_loss: 0.0613\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0035 - val_loss: 0.0621\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0034 - val_loss: 0.0599\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0033 - val_loss: 0.0635\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0033 - val_loss: 0.0619\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 0.0032 - val_loss: 0.0611\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0031 - val_loss: 0.0610\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 0.0031 - val_loss: 0.0626\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0031 - val_loss: 0.0606\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 408us/step - loss: 0.0031 - val_loss: 0.0615\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0030 - val_loss: 0.0608\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 0.0031 - val_loss: 0.0586\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0030 - val_loss: 0.0615\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 409us/step - loss: 0.0029 - val_loss: 0.0621\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0029 - val_loss: 0.0587\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0029 - val_loss: 0.0625\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 21s 6ms/step - loss: 0.0741 - val_loss: 0.0219\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0689 - val_loss: 0.0295\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0518 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0259 - val_loss: 0.0261\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0200 - val_loss: 0.0590\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0110 - val_loss: 0.0523\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0080 - val_loss: 0.0597\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0055 - val_loss: 0.0432\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0047 - val_loss: 0.0504\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0042 - val_loss: 0.0571\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0040 - val_loss: 0.0481\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0038 - val_loss: 0.0362\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0037 - val_loss: 0.0328\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0035 - val_loss: 0.0358\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0034 - val_loss: 0.0365\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 422us/step - loss: 0.0033 - val_loss: 0.0161\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 418us/step - loss: 0.0031 - val_loss: 0.0074\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 406us/step - loss: 0.0026 - val_loss: 0.0075\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.0019 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 23s 7ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 23s 7ms/step - loss: 0.0893 - val_loss: 0.0528\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0222 - val_loss: 0.0195\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0101 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 23s 7ms/step - loss: 0.1439 - val_loss: 0.0486\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0273 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0096 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0057 - val_loss: 0.0116\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0036 - val_loss: 0.0072\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 24s 7ms/step - loss: 0.2489 - val_loss: 0.1973\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0537 - val_loss: 0.0751\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0209 - val_loss: 0.0352\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0231 - val_loss: 0.0192\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0177 - val_loss: 0.0291\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0159 - val_loss: 0.0171\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0107 - val_loss: 0.0197\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0093 - val_loss: 0.0065\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0053 - val_loss: 0.0116\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0054 - val_loss: 0.0057\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0055 - val_loss: 0.0136\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0080 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0058 - val_loss: 0.0092\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0038 - val_loss: 0.0097\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0084 - val_loss: 0.0162\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0081 - val_loss: 0.0047\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0045 - val_loss: 0.0093\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0049 - val_loss: 0.0066\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0054 - val_loss: 0.0093\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0046 - val_loss: 0.0052\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 24s 7ms/step - loss: 0.0912 - val_loss: 0.0385\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0126 - val_loss: 0.0128\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0095 - val_loss: 0.0159\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0073 - val_loss: 0.0088\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0085 - val_loss: 0.0091\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0066 - val_loss: 0.0082\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0083 - val_loss: 0.0136\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0112 - val_loss: 0.0062\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0072 - val_loss: 0.0094\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0067 - val_loss: 0.0102\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0081 - val_loss: 0.0168\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0101 - val_loss: 0.0116\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0085 - val_loss: 0.0097\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0048 - val_loss: 0.0073\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0062 - val_loss: 0.0119\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0081 - val_loss: 0.0145\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0066 - val_loss: 0.0086\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0077 - val_loss: 0.0086\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0059 - val_loss: 0.0135\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0068 - val_loss: 0.0077\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0074 - val_loss: 0.0109\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 25s 7ms/step - loss: 0.0984 - val_loss: 0.0221\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0110 - val_loss: 0.0051\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0052 - val_loss: 0.0091\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 25s 7ms/step - loss: 0.1127 - val_loss: 0.0132\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0208 - val_loss: 0.0074\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0092 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0057 - val_loss: 0.0091\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 25s 7ms/step - loss: 0.1142 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0140 - val_loss: 0.0089\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0090 - val_loss: 0.0078\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0032 - val_loss: 0.0047\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 25s 7ms/step - loss: 0.5200 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0059 - val_loss: 0.0222\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0097 - val_loss: 0.0153\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0119 - val_loss: 0.0110\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0101 - val_loss: 0.0153\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 663us/step - loss: 0.0123 - val_loss: 0.0160\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 620us/step - loss: 0.0124 - val_loss: 0.0173\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0157 - val_loss: 0.0121\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0187 - val_loss: 0.0434\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0189 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0037 - val_loss: 0.0219\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0131 - val_loss: 0.0186\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0158 - val_loss: 0.0271\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 0.0155 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 0.0031 - val_loss: 0.0122\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 610us/step - loss: 0.0115 - val_loss: 0.0127\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 609us/step - loss: 0.0184 - val_loss: 0.0074\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0080 - val_loss: 0.0152\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 0.0068 - val_loss: 0.0093\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0123 - val_loss: 0.0164\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 610us/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0054 - val_loss: 0.0192\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 26s 8ms/step - loss: 0.1176 - val_loss: 0.0343\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0294 - val_loss: 0.0219\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0122 - val_loss: 0.0106\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0075 - val_loss: 0.0126\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0032 - val_loss: 0.0041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 27s 8ms/step - loss: 0.1760 - val_loss: 0.0534\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0344 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0098 - val_loss: 0.0093\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0068 - val_loss: 0.0099\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0046 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 27s 8ms/step - loss: 0.2142 - val_loss: 0.2034\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.1287 - val_loss: 0.1109\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0856 - val_loss: 0.0635\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0655 - val_loss: 0.0405\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0568 - val_loss: 0.0287\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0524 - val_loss: 0.0221\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0496 - val_loss: 0.0185\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0471 - val_loss: 0.0163\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0448 - val_loss: 0.0145\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0424 - val_loss: 0.0134\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0400 - val_loss: 0.0127\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0376 - val_loss: 0.0117\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0353 - val_loss: 0.0107\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0325 - val_loss: 0.0097\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0303 - val_loss: 0.0089\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0282 - val_loss: 0.0080\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0259 - val_loss: 0.0073\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0237 - val_loss: 0.0066\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0216 - val_loss: 0.0060\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0196 - val_loss: 0.0056\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0177 - val_loss: 0.0052\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0160 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0145 - val_loss: 0.0045\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0131 - val_loss: 0.0043\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 26s 8ms/step - loss: 0.1199 - val_loss: 0.0270\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0558 - val_loss: 0.0163\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0472 - val_loss: 0.0134\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0405 - val_loss: 0.0117\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0341 - val_loss: 0.0098\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 398us/step - loss: 0.0293 - val_loss: 0.0080\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0244 - val_loss: 0.0068\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0207 - val_loss: 0.0057\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0175 - val_loss: 0.0048\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0149 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0123 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0108 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0095 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0090 - val_loss: 0.0044\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0070 - val_loss: 0.0060\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 388us/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 390us/step - loss: 0.0065 - val_loss: 0.0068\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0064 - val_loss: 0.0071\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0063 - val_loss: 0.0072\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: 0.0063 - val_loss: 0.0073\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 27s 8ms/step - loss: 0.1299 - val_loss: 0.0387\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0587 - val_loss: 0.0209\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0510 - val_loss: 0.0166\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0450 - val_loss: 0.0146\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0399 - val_loss: 0.0135\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0347 - val_loss: 0.0117\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0307 - val_loss: 0.0102\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0265 - val_loss: 0.0087\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0229 - val_loss: 0.0076\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0195 - val_loss: 0.0062\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0165 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0144 - val_loss: 0.0046\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0121 - val_loss: 0.0042\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0109 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0094 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0084 - val_loss: 0.0042\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0078 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0064 - val_loss: 0.0055\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0060 - val_loss: 0.0061\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0060 - val_loss: 0.0063\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 27s 8ms/step - loss: 0.1488 - val_loss: 0.0985\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0843 - val_loss: 0.0517\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0750 - val_loss: 0.0383\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0737 - val_loss: 0.0341\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0735 - val_loss: 0.0332\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0735 - val_loss: 0.0315\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0735 - val_loss: 0.0316\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0735 - val_loss: 0.0315\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0735 - val_loss: 0.0319\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0735 - val_loss: 0.0320\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0735 - val_loss: 0.0316\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0735 - val_loss: 0.0315\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0735 - val_loss: 0.0316\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0735 - val_loss: 0.0312\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0735 - val_loss: 0.0313\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 28s 8ms/step - loss: 0.3006 - val_loss: 0.1751\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.1066 - val_loss: 0.0712\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0780 - val_loss: 0.0446\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0738 - val_loss: 0.0359\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0732 - val_loss: 0.0329\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0730 - val_loss: 0.0322\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0730 - val_loss: 0.0308\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0730 - val_loss: 0.0313\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0730 - val_loss: 0.0311\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0730 - val_loss: 0.0314\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0730 - val_loss: 0.0311\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0730 - val_loss: 0.0309\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0730 - val_loss: 0.0309\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0729 - val_loss: 0.0308\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0729 - val_loss: 0.0315\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0729 - val_loss: 0.0311\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0729 - val_loss: 0.0307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0729 - val_loss: 0.0312\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0729 - val_loss: 0.0312\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0729 - val_loss: 0.0314\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0728 - val_loss: 0.0311\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0728 - val_loss: 0.0307\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0728 - val_loss: 0.0312\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0728 - val_loss: 0.0310\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 28s 8ms/step - loss: 0.9029 - val_loss: 0.3196\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.1319 - val_loss: 0.0350\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0794 - val_loss: 0.0072\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0926 - val_loss: 0.0067\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0887 - val_loss: 0.0103\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0788 - val_loss: 0.0198\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0741 - val_loss: 0.0307\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0736 - val_loss: 0.0373\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0739 - val_loss: 0.0381\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0738 - val_loss: 0.0360\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0736 - val_loss: 0.0331\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0735 - val_loss: 0.0309\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0735 - val_loss: 0.0300\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0735 - val_loss: 0.0299\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0735 - val_loss: 0.0298\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0735 - val_loss: 0.0306\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0735 - val_loss: 0.0311\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0735 - val_loss: 0.0315\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0735 - val_loss: 0.0312\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0735 - val_loss: 0.0308\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0735 - val_loss: 0.0306\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0735 - val_loss: 0.0305\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0734 - val_loss: 0.0305\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0735 - val_loss: 0.0307\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 29s 8ms/step - loss: 0.0583 - val_loss: 0.0147\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0195 - val_loss: 0.0294\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0081 - val_loss: 0.0742\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0064 - val_loss: 0.0676\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0047 - val_loss: 0.0483\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0041 - val_loss: 0.0521\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0038 - val_loss: 0.0561\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0037 - val_loss: 0.0509\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0036 - val_loss: 0.0535\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0035 - val_loss: 0.0518\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0034 - val_loss: 0.0493\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0034 - val_loss: 0.0491\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0033 - val_loss: 0.0535\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0032 - val_loss: 0.0560\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0032 - val_loss: 0.0569\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0032 - val_loss: 0.0579\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0032 - val_loss: 0.0561\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0031 - val_loss: 0.0539\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0031 - val_loss: 0.0534\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0031 - val_loss: 0.0496\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0031 - val_loss: 0.0479\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0030 - val_loss: 0.0487\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0030 - val_loss: 0.0399\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0027 - val_loss: 0.0260\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 28s 8ms/step - loss: 0.1713 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 525us/step - loss: 0.0054 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0155 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0037 - val_loss: 0.0104\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0175 - val_loss: 0.0103\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0116 - val_loss: 0.0107\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0105 - val_loss: 0.0178\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0103 - val_loss: 0.0157\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0089 - val_loss: 0.0121\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0095 - val_loss: 0.0122\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 521us/step - loss: 0.0100 - val_loss: 0.0281\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 518us/step - loss: 0.0089 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 519us/step - loss: 0.0024 - val_loss: 0.0058\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0115 - val_loss: 0.0097\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0046 - val_loss: 0.0042\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0076 - val_loss: 0.0182\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0080 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0036 - val_loss: 0.0102\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0063 - val_loss: 0.0097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0088 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 517us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 29s 9ms/step - loss: 0.1035 - val_loss: 0.0465\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0324 - val_loss: 0.0212\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0134 - val_loss: 0.0108\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0078 - val_loss: 0.0100\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0045 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 29s 8ms/step - loss: 0.3556 - val_loss: 0.2555\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.1330 - val_loss: 0.0727\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0764 - val_loss: 0.0198\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0786 - val_loss: 0.0109\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0814 - val_loss: 0.0131\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0772 - val_loss: 0.0218\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0740 - val_loss: 0.0328\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0736 - val_loss: 0.0382\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0739 - val_loss: 0.0376\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0737 - val_loss: 0.0339\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0735 - val_loss: 0.0311\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0735 - val_loss: 0.0300\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0735 - val_loss: 0.0300\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0735 - val_loss: 0.0311\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0735 - val_loss: 0.0324\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0735 - val_loss: 0.0323\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0735 - val_loss: 0.0312\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0735 - val_loss: 0.0312\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 30s 9ms/step - loss: 0.1133 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0130 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0089 - val_loss: 0.0127\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0055 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0044 - val_loss: 0.0090\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 30s 9ms/step - loss: 0.0793 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0123 - val_loss: 0.0125\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0092 - val_loss: 0.0147\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0060 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 31s 9ms/step - loss: 0.1867 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0160 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0097 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0045 - val_loss: 0.0122\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0030 - val_loss: 0.0056\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 31s 9ms/step - loss: 0.1180 - val_loss: 0.0081\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0136 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0079 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0028 - val_loss: 0.0056\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 535us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 534us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 536us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 532us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 530us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 533us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 531us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 32s 9ms/step - loss: 0.3860 - val_loss: 0.0522\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 542us/step - loss: 0.0219 - val_loss: 0.0109\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0101 - val_loss: 0.0120\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0064 - val_loss: 0.0117\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 547us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 541us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 543us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 540us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 544us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 538us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 537us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 545us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 539us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 31s 9ms/step - loss: 0.0336 - val_loss: 0.0064\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 417us/step - loss: 0.0155 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0116 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0096 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 420us/step - loss: 0.0076 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 421us/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0045 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 416us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 420us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 412us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 415us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 414us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 413us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 32s 9ms/step - loss: 0.3205 - val_loss: 0.1823\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0978 - val_loss: 0.0252\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0805 - val_loss: 0.0073\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0892 - val_loss: 0.0095\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0791 - val_loss: 0.0239\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0736 - val_loss: 0.0415\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 497us/step - loss: 0.0748 - val_loss: 0.0444\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0742 - val_loss: 0.0356\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0734 - val_loss: 0.0288\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0735 - val_loss: 0.0275\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0734 - val_loss: 0.0304\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0731 - val_loss: 0.0329\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0727 - val_loss: 0.0316\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0717 - val_loss: 0.0305\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0716 - val_loss: 0.0282\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0734 - val_loss: 0.0306\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0731 - val_loss: 0.0363\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0718 - val_loss: 0.0302\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0674 - val_loss: 0.0230\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0620 - val_loss: 0.0151\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0662 - val_loss: 0.0467\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0739 - val_loss: 0.0268\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0739 - val_loss: 0.0251\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0730 - val_loss: 0.0325\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 33s 10ms/step - loss: 0.1135 - val_loss: 0.0301\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0141 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0061 - val_loss: 0.0114\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0023 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 33s 10ms/step - loss: 0.0968 - val_loss: 0.0287\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0205 - val_loss: 0.0175\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0094 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 34s 10ms/step - loss: 0.1293 - val_loss: 0.0179\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0193 - val_loss: 0.0158\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0117 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0106 - val_loss: 0.0214\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0100 - val_loss: 0.0061\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0054 - val_loss: 0.0111\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0091 - val_loss: 0.0092\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0052 - val_loss: 0.0140\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0086 - val_loss: 0.0114\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0076 - val_loss: 0.0119\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0040 - val_loss: 0.0061\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0064 - val_loss: 0.0098\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0066 - val_loss: 0.0068\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0053 - val_loss: 0.0130\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0075 - val_loss: 0.0059\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0048 - val_loss: 0.0043\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0047 - val_loss: 0.0075\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 35s 10ms/step - loss: 0.0982 - val_loss: 0.0083\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0108 - val_loss: 0.0106\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0093 - val_loss: 0.0151\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0081 - val_loss: 0.0111\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0069 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0050 - val_loss: 0.0083\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0067 - val_loss: 0.0064\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0075 - val_loss: 0.0099\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0068 - val_loss: 0.0066\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0063 - val_loss: 0.0094\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0052 - val_loss: 0.0112\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0053 - val_loss: 0.0044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0045 - val_loss: 0.0071\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0060 - val_loss: 0.0077\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0076 - val_loss: 0.0088\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0045 - val_loss: 0.0047\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0046 - val_loss: 0.0065\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 35s 10ms/step - loss: 0.0842 - val_loss: 0.0079\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0095 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0084 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0065 - val_loss: 0.0075\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0087 - val_loss: 0.0093\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0064 - val_loss: 0.0073\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0065 - val_loss: 0.0080\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0052 - val_loss: 0.0085\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0069 - val_loss: 0.0080\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0067 - val_loss: 0.0063\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0067 - val_loss: 0.0075\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0070 - val_loss: 0.0057\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0050 - val_loss: 0.0069\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0051 - val_loss: 0.0062\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0065 - val_loss: 0.0079\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0050 - val_loss: 0.0087\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0052 - val_loss: 0.0075\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 35s 10ms/step - loss: 0.0881 - val_loss: 0.0112\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0176 - val_loss: 0.0253\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0159 - val_loss: 0.0139\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0104 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0083 - val_loss: 0.0154\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0089 - val_loss: 0.0089\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0080 - val_loss: 0.0111\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0064 - val_loss: 0.0096\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0064 - val_loss: 0.0108\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0065 - val_loss: 0.0077\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0079 - val_loss: 0.0090\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0055 - val_loss: 0.0120\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0068 - val_loss: 0.0059\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0072 - val_loss: 0.0113\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0052 - val_loss: 0.0058\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0053 - val_loss: 0.0076\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0065 - val_loss: 0.0067\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0043 - val_loss: 0.0071\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 36s 10ms/step - loss: 0.0986 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0152 - val_loss: 0.0170\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0088 - val_loss: 0.0134\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0141 - val_loss: 0.0125\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0090 - val_loss: 0.0117\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0093 - val_loss: 0.0167\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0094 - val_loss: 0.0058\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0070 - val_loss: 0.0087\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0077 - val_loss: 0.0088\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0061 - val_loss: 0.0060\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0054 - val_loss: 0.0105\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0068 - val_loss: 0.0114\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0066 - val_loss: 0.0085\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0064 - val_loss: 0.0052\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0056 - val_loss: 0.0081\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0049 - val_loss: 0.0073\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 559us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0070 - val_loss: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0063 - val_loss: 0.0071\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 36s 11ms/step - loss: 0.1013 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0231 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0154 - val_loss: 0.0161\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 554us/step - loss: 0.0108 - val_loss: 0.0081\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0094 - val_loss: 0.0198\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 563us/step - loss: 0.0108 - val_loss: 0.0075\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0059 - val_loss: 0.0086\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0085 - val_loss: 0.0140\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0081 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0068 - val_loss: 0.0069\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 560us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0056 - val_loss: 0.0074\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 555us/step - loss: 0.0061 - val_loss: 0.0052\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0069 - val_loss: 0.0104\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 561us/step - loss: 0.0079 - val_loss: 0.0040\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0063 - val_loss: 0.0076\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0056 - val_loss: 0.0062\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 556us/step - loss: 0.0066 - val_loss: 0.0114\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 558us/step - loss: 0.0073 - val_loss: 0.0043\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 557us/step - loss: 0.0040 - val_loss: 0.0042\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 562us/step - loss: 0.0041 - val_loss: 0.0058\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 37s 11ms/step - loss: 0.1861 - val_loss: 0.0665\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0438 - val_loss: 0.0190\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0136 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0073 - val_loss: 0.0121\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0054 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0041 - val_loss: 0.0076\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 37s 11ms/step - loss: 0.1389 - val_loss: 0.0054\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0288 - val_loss: 0.0070\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0124 - val_loss: 0.0099\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0076 - val_loss: 0.0149\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 38s 11ms/step - loss: 0.1538 - val_loss: 0.0164\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0291 - val_loss: 0.0192\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0113 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 38s 11ms/step - loss: 0.1870 - val_loss: 0.0115\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0115 - val_loss: 0.0072\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 577us/step - loss: 0.0134 - val_loss: 0.0153\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0118 - val_loss: 0.0099\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0132 - val_loss: 0.0184\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0117 - val_loss: 0.0127\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0137 - val_loss: 0.0139\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0108 - val_loss: 0.0089\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0108 - val_loss: 0.0225\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0105 - val_loss: 0.0071\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0110 - val_loss: 0.0046\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 573us/step - loss: 0.0072 - val_loss: 0.0224\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0076 - val_loss: 0.0089\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0094 - val_loss: 0.0086\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0093 - val_loss: 0.0149\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0055 - val_loss: 0.0066\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0047 - val_loss: 0.0086\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 574us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0049 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 575us/step - loss: 0.0060 - val_loss: 0.0032\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 38s 11ms/step - loss: 0.1782 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0112 - val_loss: 0.0099\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0123 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0108 - val_loss: 0.0242\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0129 - val_loss: 0.0173\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0142 - val_loss: 0.0246\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0107 - val_loss: 0.0187\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0138 - val_loss: 0.0287\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 400us/step - loss: 0.0117 - val_loss: 0.0122\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0112 - val_loss: 0.0187\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0100 - val_loss: 0.0147\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0110 - val_loss: 0.0223\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0093 - val_loss: 0.0163\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0083 - val_loss: 0.0104\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0085 - val_loss: 0.0128\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 403us/step - loss: 0.0072 - val_loss: 0.0096\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 400us/step - loss: 0.0088 - val_loss: 0.0152\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0053 - val_loss: 0.0056\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 400us/step - loss: 0.0091 - val_loss: 0.0144\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0087 - val_loss: 0.0100\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0046 - val_loss: 0.0108\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0079 - val_loss: 0.0122\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 38s 11ms/step - loss: 0.1912 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0072 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 401us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 398us/step - loss: 0.0094 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0068 - val_loss: 0.0303\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0145 - val_loss: 0.0060\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0113 - val_loss: 0.0148\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0139 - val_loss: 0.0246\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0126 - val_loss: 0.0076\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0104 - val_loss: 0.0193\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.0120 - val_loss: 0.0100\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0116 - val_loss: 0.0083\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0080 - val_loss: 0.0130\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0096 - val_loss: 0.0131\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 401us/step - loss: 0.0097 - val_loss: 0.0071\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.0077 - val_loss: 0.0130\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0076 - val_loss: 0.0072\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 404us/step - loss: 0.0105 - val_loss: 0.0172\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0055 - val_loss: 0.0082\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0062 - val_loss: 0.0168\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 0.0081 - val_loss: 0.0058\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 411us/step - loss: 0.0062 - val_loss: 0.0074\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 38s 11ms/step - loss: 2091.3509 - val_loss: 24.2251\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 18.0544 - val_loss: 16.1875\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 11.7249 - val_loss: 10.2349\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 6.9830 - val_loss: 5.8743\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 3.6127 - val_loss: 2.8346\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 1.5175 - val_loss: 1.0097\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.5068 - val_loss: 0.2343\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 401us/step - loss: 0.2171 - val_loss: 0.0487\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 405us/step - loss: 0.1526 - val_loss: 0.0235\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 401us/step - loss: 0.1328 - val_loss: 0.0114\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.1150 - val_loss: 0.0076\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.1031 - val_loss: 0.0083\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.0893 - val_loss: 0.0080\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.0807 - val_loss: 0.0400\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.1329 - val_loss: 0.0376\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 0.1341 - val_loss: 0.2034\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 401us/step - loss: 0.3001 - val_loss: 0.1645\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.2279 - val_loss: 0.1427\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.3114 - val_loss: 0.2517\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 402us/step - loss: 0.1804 - val_loss: 0.0765\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 0.2549 - val_loss: 0.1247\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.1021 - val_loss: 0.0634\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.2148 - val_loss: 0.0812\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.0562 - val_loss: 0.0251\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 39s 11ms/step - loss: 296335.8554 - val_loss: 650.2905\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 399us/step - loss: 1690.5233 - val_loss: 279.4687\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 1025.9348 - val_loss: 65.1047\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 581.5074 - val_loss: 11.3936\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 314.1965 - val_loss: 1.3996\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 153.7039 - val_loss: 0.3522\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 79.3703 - val_loss: 0.0784\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 36.5042 - val_loss: 0.0308\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 19.1162 - val_loss: 0.0923\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 12.6108 - val_loss: 0.1807\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 395us/step - loss: 9.1091 - val_loss: 0.0400\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 6.9084 - val_loss: 0.0158\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 5.3159 - val_loss: 0.0119\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 397us/step - loss: 3.8925 - val_loss: 0.0090\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 3.0568 - val_loss: 0.0155\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 2.3278 - val_loss: 0.0171\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 398us/step - loss: 1.8511 - val_loss: 0.0239\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 1.4537 - val_loss: 0.0081\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 1.2356 - val_loss: 0.0480\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 392us/step - loss: 0.8591 - val_loss: 0.0054\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 394us/step - loss: 0.6373 - val_loss: 0.1324\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 393us/step - loss: 0.6257 - val_loss: 0.0529\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 391us/step - loss: 0.4594 - val_loss: 0.0349\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 396us/step - loss: 0.3544 - val_loss: 0.0082\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 40s 12ms/step - loss: 425558.0357 - val_loss: 152.1662\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 338.1573 - val_loss: 30.3048\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 178.4026 - val_loss: 2.0104\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 105.1981 - val_loss: 4.3643\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 65.5124 - val_loss: 9.2296\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 40.7089 - val_loss: 10.7735\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 22.8668 - val_loss: 8.0835\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 14.2262 - val_loss: 6.5712\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.2561 - val_loss: 4.0299\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 608us/step - loss: 6.5690 - val_loss: 2.4157\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 5.3484 - val_loss: 1.4308\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.9756 - val_loss: 0.6312\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.3030 - val_loss: 0.4212\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.8197 - val_loss: 0.4285\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.1061 - val_loss: 0.2046\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8076 - val_loss: 0.1173\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.2752 - val_loss: 0.0713\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0538 - val_loss: 0.1894\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.9652 - val_loss: 0.1298\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 0.6497 - val_loss: 0.0051\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.5161 - val_loss: 0.4219\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.4582 - val_loss: 0.0259\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.2966 - val_loss: 0.1457\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.3909 - val_loss: 0.0384\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 40s 12ms/step - loss: 0.1106 - val_loss: 0.0642\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0406 - val_loss: 0.0197\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0149 - val_loss: 0.0131\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0092 - val_loss: 0.0107\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0043 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 578us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 41s 12ms/step - loss: 0.1624 - val_loss: 0.0588\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 580us/step - loss: 0.0279 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0093 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0059 - val_loss: 0.0121\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 42s 12ms/step - loss: 0.2190 - val_loss: 0.0047\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0099 - val_loss: 0.0083\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0091 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 0.0073 - val_loss: 0.0129\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 0.0049 - val_loss: 0.0095\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 614us/step - loss: 0.0060 - val_loss: 0.0161\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 618us/step - loss: 0.0066 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 0.0036 - val_loss: 0.0069\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 0.0056 - val_loss: 0.0083\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 0.0038 - val_loss: 0.0051\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 614us/step - loss: 0.0036 - val_loss: 0.0060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 608us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 0.0035 - val_loss: 0.0062\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 609us/step - loss: 0.0049 - val_loss: 0.0101\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 616us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 615us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 44s 13ms/step - loss: 0.1261 - val_loss: 0.1071\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0245 - val_loss: 0.0130\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0120 - val_loss: 0.0129\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0079 - val_loss: 0.0145\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0062 - val_loss: 0.0125\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0071 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0056 - val_loss: 0.0159\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0066 - val_loss: 0.0092\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0058 - val_loss: 0.0089\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0053 - val_loss: 0.0057\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0066 - val_loss: 0.0125\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0060 - val_loss: 0.0086\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0035 - val_loss: 0.0121\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0040 - val_loss: 0.0074\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0031 - val_loss: 0.0073\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0040 - val_loss: 0.0083\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 41s 12ms/step - loss: 0.1038 - val_loss: 0.0633\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0288 - val_loss: 0.0250\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0202 - val_loss: 0.0362\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0157 - val_loss: 0.0121\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0109 - val_loss: 0.0079\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0071 - val_loss: 0.0119\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0071 - val_loss: 0.0107\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0065 - val_loss: 0.0118\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0082 - val_loss: 0.0114\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0068 - val_loss: 0.0097\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0077 - val_loss: 0.0058\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0068 - val_loss: 0.0105\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0077 - val_loss: 0.0088\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0058 - val_loss: 0.0077\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0065 - val_loss: 0.0105\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0055 - val_loss: 0.0084\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0052 - val_loss: 0.0096\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 43s 13ms/step - loss: 0.0771 - val_loss: 0.0330\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0736 - val_loss: 0.0301\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0735 - val_loss: 0.0308\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0736 - val_loss: 0.0302\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0735 - val_loss: 0.0302\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0735 - val_loss: 0.0283\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0735 - val_loss: 0.0290\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0736 - val_loss: 0.0335\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0736 - val_loss: 0.0334\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0736 - val_loss: 0.0323\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0737 - val_loss: 0.0319\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0736 - val_loss: 0.0307\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0736 - val_loss: 0.0321\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0735 - val_loss: 0.0311\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0734 - val_loss: 0.0219\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0736 - val_loss: 0.0366\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0737 - val_loss: 0.0319\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0736 - val_loss: 0.0344\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0735 - val_loss: 0.0278\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 581us/step - loss: 0.0735 - val_loss: 0.0257\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: 0.0735 - val_loss: 0.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: 0.0735 - val_loss: 0.0246\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: 0.0736 - val_loss: 0.0317\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0735 - val_loss: 0.0346\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 42s 12ms/step - loss: 0.2873 - val_loss: 0.2375\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.1405 - val_loss: 0.1178\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0928 - val_loss: 0.0690\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0787 - val_loss: 0.0482\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0748 - val_loss: 0.0395\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0738 - val_loss: 0.0347\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0735 - val_loss: 0.0333\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0735 - val_loss: 0.0324\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0313\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0735 - val_loss: 0.0319\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0735 - val_loss: 0.0313\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0324\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0322\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 496us/step - loss: 0.0735 - val_loss: 0.0313\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0735 - val_loss: 0.0281\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0322\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0310\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0736 - val_loss: 0.0310\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0735 - val_loss: 0.0298\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0343\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0279\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 44s 13ms/step - loss: 0.1051 - val_loss: 0.0463\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0740 - val_loss: 0.0325\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0735 - val_loss: 0.0349\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 504us/step - loss: 0.0735 - val_loss: 0.0324\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0324\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0735 - val_loss: 0.0336\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0328\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0300\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0734 - val_loss: 0.0293\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0735 - val_loss: 0.0334\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0736 - val_loss: 0.0310\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0321\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0735 - val_loss: 0.0338\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0735 - val_loss: 0.0347\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 493us/step - loss: 0.0734 - val_loss: 0.0334\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0735 - val_loss: 0.0294\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0735 - val_loss: 0.0350\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0738 - val_loss: 0.0277\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0734 - val_loss: 0.0277\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0737 - val_loss: 0.0319\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 499us/step - loss: 0.0735 - val_loss: 0.0324\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 495us/step - loss: 0.0738 - val_loss: 0.0383\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0397\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 43s 13ms/step - loss: 0.0955 - val_loss: 0.0104\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0789 - val_loss: 0.0188\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0748 - val_loss: 0.0245\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0738 - val_loss: 0.0279\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0736 - val_loss: 0.0295\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0304\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 494us/step - loss: 0.0735 - val_loss: 0.0308\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0735 - val_loss: 0.0318\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0735 - val_loss: 0.0316\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0735 - val_loss: 0.0312\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 498us/step - loss: 0.0735 - val_loss: 0.0312\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0735 - val_loss: 0.0310\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0735 - val_loss: 0.0314\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 490us/step - loss: 0.0735 - val_loss: 0.0313\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 489us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 491us/step - loss: 0.0735 - val_loss: 0.0312\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0316\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 492us/step - loss: 0.0735 - val_loss: 0.0317\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 46s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 586us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 45s 13ms/step - loss: 0.1089 - val_loss: 0.0334\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0331 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0130 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0089 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 585us/step - loss: 0.0052 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0038 - val_loss: 0.0064\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 47s 14ms/step - loss: 0.0619 - val_loss: 0.0131\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0107 - val_loss: 0.0141\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0070 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0025 - val_loss: 0.0066\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0026 - val_loss: 0.0048\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0025 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0023 - val_loss: 0.0068\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0021 - val_loss: 0.0053\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0020 - val_loss: 0.0042\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0020 - val_loss: 0.0058\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 0.0019 - val_loss: 0.0048\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0019 - val_loss: 0.0052\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 47s 14ms/step - loss: 0.1453 - val_loss: 0.0359\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0201 - val_loss: 0.0219\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0087 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0043 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0034 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 48s 14ms/step - loss: 0.1029 - val_loss: 0.0216\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 0.0161 - val_loss: 0.0120\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0087 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0047 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0041 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 49s 14ms/step - loss: 0.0834 - val_loss: 0.0177\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0116 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0055 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0036 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 50s 15ms/step - loss: 0.1144 - val_loss: 0.0175\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0153 - val_loss: 0.0086\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0069 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0034 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 49s 14ms/step - loss: 0.2375 - val_loss: 0.2956\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.1475 - val_loss: 0.0738\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0243 - val_loss: 0.0140\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0093 - val_loss: 0.0093\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0039 - val_loss: 0.0057\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0032 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0037 - val_loss: 0.0059\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0039 - val_loss: 0.0076\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 50s 15ms/step - loss: 1.0213 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0069 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0050 - val_loss: 0.0092\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0061 - val_loss: 0.0075\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 510us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 516us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 511us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 520us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 515us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 512us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 514us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 513us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 51s 15ms/step - loss: 2.6073 - val_loss: 0.0263\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.1009 - val_loss: 0.0315\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0284 - val_loss: 0.0093\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0135 - val_loss: 0.0217\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0134 - val_loss: 0.0156\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0056 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0056 - val_loss: 0.0093\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0039 - val_loss: 0.0141\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0035 - val_loss: 0.0080\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0031 - val_loss: 0.0065\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0029 - val_loss: 0.0086\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0029 - val_loss: 0.0088\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0026 - val_loss: 0.0072\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0026 - val_loss: 0.0075\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0026 - val_loss: 0.0078\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0026 - val_loss: 0.0074\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 586us/step - loss: 0.0025 - val_loss: 0.0069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 587us/step - loss: 0.0025 - val_loss: 0.0071\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0026 - val_loss: 0.0068\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0025 - val_loss: 0.0071\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 588us/step - loss: 0.0025 - val_loss: 0.0067\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0024 - val_loss: 0.0065\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 589us/step - loss: 0.0024 - val_loss: 0.0067\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0024 - val_loss: 0.0064\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 51s 15ms/step - loss: 0.1654 - val_loss: 0.0391\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0412 - val_loss: 0.0179\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0153 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0084 - val_loss: 0.0104\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0043 - val_loss: 0.0047\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 52s 15ms/step - loss: 0.1198 - val_loss: 0.0172\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0745 - val_loss: 0.0284\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0735 - val_loss: 0.0307\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0734 - val_loss: 0.0338\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0730 - val_loss: 0.0343\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0653 - val_loss: 0.0083\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0437 - val_loss: 0.0082\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0316 - val_loss: 0.0090\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0130 - val_loss: 0.0137\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 572us/step - loss: 0.0107 - val_loss: 0.0274\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0090 - val_loss: 0.0133\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0128 - val_loss: 0.0678\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0084 - val_loss: 0.0328\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0047 - val_loss: 0.0291\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0077 - val_loss: 0.0171\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0053 - val_loss: 0.0805\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0108 - val_loss: 0.0208\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0038 - val_loss: 0.0148\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0074 - val_loss: 0.0094\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0041 - val_loss: 0.0841\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0100 - val_loss: 0.0074\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0030 - val_loss: 0.0212\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0083 - val_loss: 0.0110\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0035 - val_loss: 0.0320\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 53s 15ms/step - loss: 1.7832 - val_loss: 1.1459\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.7002 - val_loss: 0.6296\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.3763 - val_loss: 0.3576\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.2129 - val_loss: 0.2029\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.1305 - val_loss: 0.1153\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0925 - val_loss: 0.0679\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0781 - val_loss: 0.0440\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 576us/step - loss: 0.0741 - val_loss: 0.0347\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0736 - val_loss: 0.0315\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0735 - val_loss: 0.0310\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0735 - val_loss: 0.0343\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0737 - val_loss: 0.0276\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0737 - val_loss: 0.0381\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0736 - val_loss: 0.0338\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 564us/step - loss: 0.0736 - val_loss: 0.0232\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0719 - val_loss: 0.0299\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0736 - val_loss: 0.0211\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0739 - val_loss: 0.0157\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0705 - val_loss: 0.0153\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0575 - val_loss: 0.0068\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0366 - val_loss: 0.0069\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0182 - val_loss: 0.0207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0123 - val_loss: 0.0296\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0128 - val_loss: 0.0252\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 53s 16ms/step - loss: 0.2995 - val_loss: 0.0276\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0861 - val_loss: 0.0169\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0765 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0508 - val_loss: 0.0431\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 2s 571us/step - loss: 0.0067 - val_loss: 0.0390\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0341 - val_loss: 0.0686\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0103 - val_loss: 0.0347\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 2s 566us/step - loss: 0.0294 - val_loss: 0.0630\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0123 - val_loss: 0.0181\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0186 - val_loss: 0.0805\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0195 - val_loss: 0.0261\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0093 - val_loss: 0.0933\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0206 - val_loss: 0.0442\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 2s 569us/step - loss: 0.0095 - val_loss: 0.0901\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0182 - val_loss: 0.0411\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 2s 568us/step - loss: 0.0067 - val_loss: 0.0914\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0159 - val_loss: 0.0228\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0082 - val_loss: 0.0815\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0124 - val_loss: 0.0277\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 2s 579us/step - loss: 0.0083 - val_loss: 0.0699\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 2s 570us/step - loss: 0.0122 - val_loss: 0.0301\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 2s 567us/step - loss: 0.0073 - val_loss: 0.0706\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 565us/step - loss: 0.0107 - val_loss: 0.0265\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 52s 15ms/step - loss: 0.0492 - val_loss: 0.0117\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 0.0142 - val_loss: 0.0182\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0054 - val_loss: 0.0103\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 359us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 359us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 359us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 358us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 371us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 358us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 358us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 53s 15ms/step - loss: 33260.9564 - val_loss: 742.1245\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 1204.6123 - val_loss: 102.4822\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 340.1934 - val_loss: 10.2741\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: 59.5786 - val_loss: 3.3040\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 25.3975 - val_loss: 0.6474\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 17.5975 - val_loss: 0.1557\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 13.5017 - val_loss: 0.0975\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 11.4179 - val_loss: 0.1111\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: 9.3805 - val_loss: 0.0898\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 359us/step - loss: 8.1469 - val_loss: 0.0693\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 6.9546 - val_loss: 0.0782\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 5.8227 - val_loss: 0.0803\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 4.4150 - val_loss: 0.0698\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 4.0254 - val_loss: 0.0806\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 361us/step - loss: 3.3142 - val_loss: 0.0532\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 2.7879 - val_loss: 0.0481\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 370us/step - loss: 2.2860 - val_loss: 0.0250\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 359us/step - loss: 1.9113 - val_loss: 0.0280\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 362us/step - loss: 1.7502 - val_loss: 0.0366\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: 1.5612 - val_loss: 0.0634\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 364us/step - loss: 1.3066 - val_loss: 0.0648\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 365us/step - loss: 1.1778 - val_loss: 0.0446\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.9196 - val_loss: 0.0227\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 360us/step - loss: 0.8646 - val_loss: 0.0748\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 54s 16ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 363us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 1s 364us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 2s 453us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 1s 370us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 373us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 373us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 374us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 369us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 368us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 366us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 367us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/24\n",
      "3423/3423 [==============================] - 55s 16ms/step - loss: 0.0844 - val_loss: 0.0390\n",
      "Epoch 2/24\n",
      "3423/3423 [==============================] - 1s 437us/step - loss: 0.0226 - val_loss: 0.0274\n",
      "Epoch 3/24\n",
      "3423/3423 [==============================] - 1s 436us/step - loss: 0.0163 - val_loss: 0.0119\n",
      "Epoch 4/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 5/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0116 - val_loss: 0.0173\n",
      "Epoch 6/24\n",
      "3423/3423 [==============================] - 1s 435us/step - loss: 0.0079 - val_loss: 0.0091\n",
      "Epoch 7/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0079 - val_loss: 0.0100\n",
      "Epoch 8/24\n",
      "3423/3423 [==============================] - 2s 444us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0059 - val_loss: 0.0125\n",
      "Epoch 10/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0072 - val_loss: 0.0062\n",
      "Epoch 11/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0051 - val_loss: 0.0106\n",
      "Epoch 12/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0067 - val_loss: 0.0122\n",
      "Epoch 13/24\n",
      "3423/3423 [==============================] - 1s 436us/step - loss: 0.0076 - val_loss: 0.0109\n",
      "Epoch 14/24\n",
      "3423/3423 [==============================] - 1s 434us/step - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 15/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0049 - val_loss: 0.0089\n",
      "Epoch 16/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0061 - val_loss: 0.0073\n",
      "Epoch 17/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0071 - val_loss: 0.0137\n",
      "Epoch 18/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 19/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0070 - val_loss: 0.0089\n",
      "Epoch 20/24\n",
      "3423/3423 [==============================] - 1s 435us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0048 - val_loss: 0.0096\n",
      "Epoch 22/24\n",
      "3423/3423 [==============================] - 1s 432us/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 23/24\n",
      "3423/3423 [==============================] - 1s 433us/step - loss: 0.0068 - val_loss: 0.0098\n",
      "Epoch 24/24\n",
      "3423/3423 [==============================] - 2s 439us/step - loss: 0.0043 - val_loss: 0.0039\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03517590090632439,\n",
       " 0.00708832498639822,\n",
       " 0.010037644766271114,\n",
       " 0.004291078075766563,\n",
       " 0.0035012061707675457,\n",
       " 0.004761275835335255,\n",
       " 0.003289292799308896,\n",
       " 0.0030249804258346558,\n",
       " 0.0028761415742337704,\n",
       " 0.0028448367957025766,\n",
       " 0.002631708048284054,\n",
       " 0.0024961272720247507,\n",
       " 0.0023273280821740627,\n",
       " 0.002243820345029235,\n",
       " 0.0021181132178753614,\n",
       " 0.0022076014429330826,\n",
       " 0.0019467637175694108,\n",
       " 0.002220721449702978,\n",
       " 0.0018840301781892776,\n",
       " 0.001855815527960658,\n",
       " 0.0018388425232842565,\n",
       " 0.0022802238818258047,\n",
       " 0.0016680756816640496,\n",
       " 0.0015784644056111574]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "activation: relu\n",
      "optimizer: adam\n",
      "dropout: 0.1\n",
      "full_density: True\n",
      "twice: True\n",
      "shuffle: True\n",
      "lstmsize: 176\n",
      "density: 204\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_39\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_75 (LSTM)               (None, 92, 176)           128128    \n",
      "_________________________________________________________________\n",
      "dropout_74 (Dropout)         (None, 92, 176)           0         \n",
      "_________________________________________________________________\n",
      "lstm_76 (LSTM)               (None, 176)               248512    \n",
      "_________________________________________________________________\n",
      "dropout_75 (Dropout)         (None, 176)               0         \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 204)               36108     \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 102)               20910     \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 51)                5253      \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 25)                1300      \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 12)                312       \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 440,536\n",
      "Trainable params: 440,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3423 samples, validate on 381 samples\n",
      "Epoch 1/2000\n",
      "3423/3423 [==============================] - 56s 16ms/step - loss: 0.1454 - val_loss: 0.0051\n",
      "Epoch 2/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 0.0366 - val_loss: 0.0065\n",
      "Epoch 3/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0146 - val_loss: 0.0039\n",
      "Epoch 4/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0090 - val_loss: 0.0072\n",
      "Epoch 5/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 6/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0041 - val_loss: 0.0080\n",
      "Epoch 7/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0035 - val_loss: 0.0035\n",
      "Epoch 8/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 9/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 10/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 11/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 12/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 13/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 14/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 15/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 16/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 17/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 18/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 19/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 20/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 21/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 22/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 23/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 24/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 25/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 26/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 27/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 28/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 29/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 30/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 31/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 32/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 33/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 34/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 35/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 36/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 37/2000\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 38/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 39/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 40/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 41/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 42/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 43/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 44/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 45/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 46/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 47/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 48/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 49/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 50/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 51/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 52/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 53/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 54/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 55/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 56/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 57/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 58/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 59/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 60/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 61/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 62/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 63/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 64/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 65/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 66/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 67/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 68/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 69/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 70/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 71/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 72/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 73/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 74/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 75/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 76/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0010 - val_loss: 0.0020\n",
      "Epoch 77/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 78/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 79/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.9330e-04 - val_loss: 0.0012\n",
      "Epoch 80/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 81/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 82/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 83/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 84/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 85/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 86/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 87/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 88/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 89/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 90/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 91/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 92/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.5971e-04 - val_loss: 0.0012\n",
      "Epoch 93/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.5268e-04 - val_loss: 0.0020\n",
      "Epoch 94/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.2676e-04 - val_loss: 0.0011\n",
      "Epoch 95/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.1586e-04 - val_loss: 0.0017\n",
      "Epoch 96/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.3878e-04 - val_loss: 0.0011\n",
      "Epoch 97/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 9.2356e-04 - val_loss: 0.0016\n",
      "Epoch 98/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.1734e-04 - val_loss: 0.0015\n",
      "Epoch 99/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.4308e-04 - val_loss: 8.7345e-04\n",
      "Epoch 100/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.9422e-04 - val_loss: 0.0014\n",
      "Epoch 101/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.5699e-04 - val_loss: 0.0012\n",
      "Epoch 102/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.6239e-04 - val_loss: 0.0021\n",
      "Epoch 103/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 9.6294e-04 - val_loss: 0.0015\n",
      "Epoch 104/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.0560e-04 - val_loss: 0.0011\n",
      "Epoch 105/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.6446e-04 - val_loss: 0.0019\n",
      "Epoch 106/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 8.6160e-04 - val_loss: 0.0016\n",
      "Epoch 107/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.8501e-04 - val_loss: 9.2424e-04\n",
      "Epoch 108/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.1231e-04 - val_loss: 0.0015\n",
      "Epoch 109/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.5825e-04 - val_loss: 0.0017\n",
      "Epoch 110/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.7438e-04 - val_loss: 8.8553e-04\n",
      "Epoch 111/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 8.7198e-04 - val_loss: 0.0014\n",
      "Epoch 112/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.3290e-04 - val_loss: 9.1411e-04\n",
      "Epoch 113/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.8119e-04 - val_loss: 0.0014\n",
      "Epoch 114/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.6610e-04 - val_loss: 0.0011\n",
      "Epoch 115/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.3379e-04 - val_loss: 0.0012\n",
      "Epoch 116/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.4066e-04 - val_loss: 0.0018\n",
      "Epoch 117/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 7.9825e-04 - val_loss: 0.0011\n",
      "Epoch 118/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.1955e-04 - val_loss: 0.0020\n",
      "Epoch 119/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 8.9043e-04 - val_loss: 0.0012\n",
      "Epoch 120/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.3687e-04 - val_loss: 0.0011\n",
      "Epoch 121/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.3990e-04 - val_loss: 0.0016\n",
      "Epoch 122/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.0522e-04 - val_loss: 8.3024e-04\n",
      "Epoch 123/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.2947e-04 - val_loss: 0.0024\n",
      "Epoch 124/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.0400e-04 - val_loss: 7.7696e-04\n",
      "Epoch 125/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.6843e-04 - val_loss: 0.0016\n",
      "Epoch 126/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.7817e-04 - val_loss: 0.0012\n",
      "Epoch 127/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.8703e-04 - val_loss: 0.0011\n",
      "Epoch 128/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.6563e-04 - val_loss: 0.0014\n",
      "Epoch 129/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.9460e-04 - val_loss: 0.0012\n",
      "Epoch 130/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.5984e-04 - val_loss: 0.0011\n",
      "Epoch 131/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 7.3913e-04 - val_loss: 0.0011\n",
      "Epoch 132/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 7.3077e-04 - val_loss: 0.0015\n",
      "Epoch 133/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.4318e-04 - val_loss: 8.8865e-04\n",
      "Epoch 134/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.6831e-04 - val_loss: 0.0014\n",
      "Epoch 135/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.5260e-04 - val_loss: 0.0018\n",
      "Epoch 136/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.3916e-04 - val_loss: 0.0013\n",
      "Epoch 137/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 7.2535e-04 - val_loss: 0.0020\n",
      "Epoch 138/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 7.0155e-04 - val_loss: 0.0014\n",
      "Epoch 139/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 7.0402e-04 - val_loss: 0.0012\n",
      "Epoch 140/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.1677e-04 - val_loss: 0.0012\n",
      "Epoch 141/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.9866e-04 - val_loss: 0.0017\n",
      "Epoch 142/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 7.0651e-04 - val_loss: 0.0019\n",
      "Epoch 143/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 7.2836e-04 - val_loss: 0.0018\n",
      "Epoch 144/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.0010e-04 - val_loss: 0.0019\n",
      "Epoch 145/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.0238e-04 - val_loss: 0.0013\n",
      "Epoch 146/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.1597e-04 - val_loss: 0.0012\n",
      "Epoch 147/2000\n",
      "3423/3423 [==============================] - 2s 608us/step - loss: 6.6517e-04 - val_loss: 0.0011\n",
      "Epoch 148/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.8388e-04 - val_loss: 0.0012\n",
      "Epoch 149/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.0058e-04 - val_loss: 0.0019\n",
      "Epoch 150/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.2579e-04 - val_loss: 0.0017\n",
      "Epoch 151/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.9731e-04 - val_loss: 0.0015\n",
      "Epoch 152/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.8750e-04 - val_loss: 0.0012\n",
      "Epoch 153/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.7345e-04 - val_loss: 0.0010\n",
      "Epoch 154/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 7.2529e-04 - val_loss: 7.8494e-04\n",
      "Epoch 155/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.4588e-04 - val_loss: 0.0012\n",
      "Epoch 156/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.7120e-04 - val_loss: 0.0023\n",
      "Epoch 157/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 7.6318e-04 - val_loss: 0.0018\n",
      "Epoch 158/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.1995e-04 - val_loss: 0.0015\n",
      "Epoch 159/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.6498e-04 - val_loss: 0.0011\n",
      "Epoch 160/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.1724e-04 - val_loss: 9.9902e-04\n",
      "Epoch 161/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 6.8513e-04 - val_loss: 0.0014\n",
      "Epoch 162/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 6.6717e-04 - val_loss: 0.0014\n",
      "Epoch 163/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.4422e-04 - val_loss: 0.0011\n",
      "Epoch 164/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 6.9232e-04 - val_loss: 8.2567e-04\n",
      "Epoch 165/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.3019e-04 - val_loss: 0.0012\n",
      "Epoch 166/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.0975e-04 - val_loss: 0.0012\n",
      "Epoch 167/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.5021e-04 - val_loss: 0.0019\n",
      "Epoch 168/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.8154e-04 - val_loss: 0.0017\n",
      "Epoch 169/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.5136e-04 - val_loss: 0.0014\n",
      "Epoch 170/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.7894e-04 - val_loss: 0.0028\n",
      "Epoch 171/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.6343e-04 - val_loss: 0.0015\n",
      "Epoch 172/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.1489e-04 - val_loss: 7.8048e-04\n",
      "Epoch 173/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.2370e-04 - val_loss: 9.1953e-04\n",
      "Epoch 174/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.7507e-04 - val_loss: 0.0015\n",
      "Epoch 175/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.0245e-04 - val_loss: 0.0020\n",
      "Epoch 176/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 6.4724e-04 - val_loss: 0.0011\n",
      "Epoch 177/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.5617e-04 - val_loss: 0.0016\n",
      "Epoch 178/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.6744e-04 - val_loss: 0.0013\n",
      "Epoch 179/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.5779e-04 - val_loss: 0.0014\n",
      "Epoch 180/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.4796e-04 - val_loss: 0.0012\n",
      "Epoch 181/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.4856e-04 - val_loss: 0.0010\n",
      "Epoch 182/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.2563e-04 - val_loss: 0.0016\n",
      "Epoch 183/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.5032e-04 - val_loss: 0.0015\n",
      "Epoch 184/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.3742e-04 - val_loss: 0.0012\n",
      "Epoch 185/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.6538e-04 - val_loss: 0.0020\n",
      "Epoch 186/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.0890e-04 - val_loss: 0.0011\n",
      "Epoch 187/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.6501e-04 - val_loss: 7.7265e-04\n",
      "Epoch 188/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 6.4062e-04 - val_loss: 0.0015\n",
      "Epoch 189/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 6.2291e-04 - val_loss: 0.0016\n",
      "Epoch 190/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.3362e-04 - val_loss: 0.0016\n",
      "Epoch 191/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.2987e-04 - val_loss: 0.0011\n",
      "Epoch 192/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.2535e-04 - val_loss: 0.0014\n",
      "Epoch 193/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.1608e-04 - val_loss: 0.0021\n",
      "Epoch 194/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.6664e-04 - val_loss: 0.0024\n",
      "Epoch 195/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.5070e-04 - val_loss: 0.0023\n",
      "Epoch 196/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.0384e-04 - val_loss: 0.0018\n",
      "Epoch 197/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.0963e-04 - val_loss: 6.8738e-04\n",
      "Epoch 198/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.0719e-04 - val_loss: 7.3514e-04\n",
      "Epoch 199/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.7309e-04 - val_loss: 0.0022\n",
      "Epoch 200/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 6.7880e-04 - val_loss: 0.0013\n",
      "Epoch 201/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.5254e-04 - val_loss: 6.2753e-04\n",
      "Epoch 202/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.6015e-04 - val_loss: 0.0018\n",
      "Epoch 203/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.9471e-04 - val_loss: 0.0010\n",
      "Epoch 204/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.7215e-04 - val_loss: 9.6396e-04\n",
      "Epoch 205/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.1872e-04 - val_loss: 0.0012\n",
      "Epoch 206/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 6.3945e-04 - val_loss: 0.0014\n",
      "Epoch 207/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.4549e-04 - val_loss: 9.3634e-04\n",
      "Epoch 208/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.4343e-04 - val_loss: 0.0015\n",
      "Epoch 209/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 5.9353e-04 - val_loss: 0.0018\n",
      "Epoch 210/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.4605e-04 - val_loss: 0.0019\n",
      "Epoch 211/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.1255e-04 - val_loss: 0.0010\n",
      "Epoch 212/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 6.2285e-04 - val_loss: 8.7113e-04\n",
      "Epoch 213/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.1453e-04 - val_loss: 0.0011\n",
      "Epoch 214/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.3080e-04 - val_loss: 0.0019\n",
      "Epoch 215/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.3956e-04 - val_loss: 0.0017\n",
      "Epoch 216/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.3030e-04 - val_loss: 0.0011\n",
      "Epoch 217/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.0472e-04 - val_loss: 0.0012\n",
      "Epoch 218/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.8882e-04 - val_loss: 0.0011\n",
      "Epoch 219/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.9403e-04 - val_loss: 0.0014\n",
      "Epoch 220/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.0205e-04 - val_loss: 0.0012\n",
      "Epoch 221/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.2651e-04 - val_loss: 0.0013\n",
      "Epoch 222/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 6.0688e-04 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.7775e-04 - val_loss: 0.0019\n",
      "Epoch 224/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 6.7927e-04 - val_loss: 0.0021\n",
      "Epoch 225/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.1969e-04 - val_loss: 8.4203e-04\n",
      "Epoch 226/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.4098e-04 - val_loss: 7.1585e-04\n",
      "Epoch 227/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.1004e-04 - val_loss: 0.0020\n",
      "Epoch 228/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.9632e-04 - val_loss: 0.0012\n",
      "Epoch 229/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.5207e-04 - val_loss: 8.4896e-04\n",
      "Epoch 230/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 6.0996e-04 - val_loss: 0.0021\n",
      "Epoch 231/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.2742e-04 - val_loss: 0.0021\n",
      "Epoch 232/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.1559e-04 - val_loss: 0.0015\n",
      "Epoch 233/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.8431e-04 - val_loss: 0.0016\n",
      "Epoch 234/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.8328e-04 - val_loss: 0.0020\n",
      "Epoch 235/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.2355e-04 - val_loss: 0.0016\n",
      "Epoch 236/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.4304e-04 - val_loss: 0.0010\n",
      "Epoch 237/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.8992e-04 - val_loss: 0.0012\n",
      "Epoch 238/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 6.2516e-04 - val_loss: 0.0017\n",
      "Epoch 239/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.3902e-04 - val_loss: 0.0025\n",
      "Epoch 240/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 6.4615e-04 - val_loss: 0.0018\n",
      "Epoch 241/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.8184e-04 - val_loss: 9.7688e-04\n",
      "Epoch 242/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.0204e-04 - val_loss: 0.0014\n",
      "Epoch 243/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.8480e-04 - val_loss: 0.0025\n",
      "Epoch 244/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.9757e-04 - val_loss: 0.0019\n",
      "Epoch 245/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.4108e-04 - val_loss: 9.1491e-04\n",
      "Epoch 246/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.7572e-04 - val_loss: 9.8112e-04\n",
      "Epoch 247/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 6.1025e-04 - val_loss: 0.0011\n",
      "Epoch 248/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.7606e-04 - val_loss: 0.0011\n",
      "Epoch 249/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 5.6794e-04 - val_loss: 0.0014\n",
      "Epoch 250/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.6427e-04 - val_loss: 0.0019\n",
      "Epoch 251/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.8313e-04 - val_loss: 0.0017\n",
      "Epoch 252/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.7437e-04 - val_loss: 0.0015\n",
      "Epoch 253/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.7967e-04 - val_loss: 0.0012\n",
      "Epoch 254/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.3545e-04 - val_loss: 6.6504e-04\n",
      "Epoch 255/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 7.2030e-04 - val_loss: 0.0020\n",
      "Epoch 256/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.4211e-04 - val_loss: 0.0017\n",
      "Epoch 257/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.7556e-04 - val_loss: 9.9374e-04\n",
      "Epoch 258/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.5146e-04 - val_loss: 0.0017\n",
      "Epoch 259/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.1226e-04 - val_loss: 0.0019\n",
      "Epoch 260/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.2852e-04 - val_loss: 0.0026\n",
      "Epoch 261/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.3364e-04 - val_loss: 0.0012\n",
      "Epoch 262/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.8320e-04 - val_loss: 0.0012\n",
      "Epoch 263/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.8528e-04 - val_loss: 0.0012\n",
      "Epoch 264/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 5.7300e-04 - val_loss: 0.0014\n",
      "Epoch 265/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.8176e-04 - val_loss: 0.0018\n",
      "Epoch 266/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.7955e-04 - val_loss: 0.0017\n",
      "Epoch 267/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.0140e-04 - val_loss: 0.0013\n",
      "Epoch 268/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.5571e-04 - val_loss: 0.0012\n",
      "Epoch 269/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.8374e-04 - val_loss: 0.0015\n",
      "Epoch 270/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.8247e-04 - val_loss: 0.0013\n",
      "Epoch 271/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.8435e-04 - val_loss: 0.0018\n",
      "Epoch 272/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 5.5513e-04 - val_loss: 0.0015\n",
      "Epoch 273/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.7556e-04 - val_loss: 0.0013\n",
      "Epoch 274/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.5663e-04 - val_loss: 0.0011\n",
      "Epoch 275/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.6286e-04 - val_loss: 0.0016\n",
      "Epoch 276/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 5.5268e-04 - val_loss: 0.0013\n",
      "Epoch 277/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.4388e-04 - val_loss: 0.0016\n",
      "Epoch 278/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.4448e-04 - val_loss: 0.0010\n",
      "Epoch 279/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.0254e-04 - val_loss: 0.0011\n",
      "Epoch 280/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.8959e-04 - val_loss: 0.0016\n",
      "Epoch 281/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.0426e-04 - val_loss: 0.0021\n",
      "Epoch 282/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.7713e-04 - val_loss: 0.0021\n",
      "Epoch 283/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.1187e-04 - val_loss: 0.0012\n",
      "Epoch 284/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.3081e-04 - val_loss: 6.3624e-04\n",
      "Epoch 285/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.9399e-04 - val_loss: 0.0020\n",
      "Epoch 286/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.3057e-04 - val_loss: 0.0020\n",
      "Epoch 287/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.7971e-04 - val_loss: 0.0013\n",
      "Epoch 288/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 5.5303e-04 - val_loss: 0.0012\n",
      "Epoch 289/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.6227e-04 - val_loss: 0.0018\n",
      "Epoch 290/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.8502e-04 - val_loss: 9.3315e-04\n",
      "Epoch 291/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.0768e-04 - val_loss: 0.0011\n",
      "Epoch 292/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.4482e-04 - val_loss: 0.0020\n",
      "Epoch 293/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.8112e-04 - val_loss: 0.0014\n",
      "Epoch 294/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.8631e-04 - val_loss: 0.0014\n",
      "Epoch 295/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 5.4102e-04 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.4646e-04 - val_loss: 0.0012\n",
      "Epoch 297/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.6956e-04 - val_loss: 0.0021\n",
      "Epoch 298/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.1974e-04 - val_loss: 0.0023\n",
      "Epoch 299/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.0211e-04 - val_loss: 0.0013\n",
      "Epoch 300/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.2926e-04 - val_loss: 6.4891e-04\n",
      "Epoch 301/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 6.8340e-04 - val_loss: 0.0011\n",
      "Epoch 302/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.5035e-04 - val_loss: 0.0016\n",
      "Epoch 303/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.7104e-04 - val_loss: 0.0014\n",
      "Epoch 304/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.0669e-04 - val_loss: 7.5109e-04\n",
      "Epoch 305/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.4860e-04 - val_loss: 8.9032e-04\n",
      "Epoch 306/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.9414e-04 - val_loss: 0.0019\n",
      "Epoch 307/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.0360e-04 - val_loss: 0.0017\n",
      "Epoch 308/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 5.5584e-04 - val_loss: 8.6985e-04\n",
      "Epoch 309/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.9357e-04 - val_loss: 0.0011\n",
      "Epoch 310/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.8026e-04 - val_loss: 0.0014\n",
      "Epoch 311/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 5.3160e-04 - val_loss: 0.0013\n",
      "Epoch 312/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.3953e-04 - val_loss: 9.4855e-04\n",
      "Epoch 313/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.7288e-04 - val_loss: 0.0016\n",
      "Epoch 314/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.5141e-04 - val_loss: 0.0019\n",
      "Epoch 315/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.6789e-04 - val_loss: 0.0011\n",
      "Epoch 316/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 5.5803e-04 - val_loss: 0.0012\n",
      "Epoch 317/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.4157e-04 - val_loss: 0.0013\n",
      "Epoch 318/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 5.8238e-04 - val_loss: 8.2948e-04\n",
      "Epoch 319/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.0121e-04 - val_loss: 0.0016\n",
      "Epoch 320/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.2396e-04 - val_loss: 0.0013\n",
      "Epoch 321/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.6656e-04 - val_loss: 0.0020\n",
      "Epoch 322/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.4803e-04 - val_loss: 0.0019\n",
      "Epoch 323/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 5.4455e-04 - val_loss: 0.0014\n",
      "Epoch 324/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.2088e-04 - val_loss: 0.0017\n",
      "Epoch 325/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.3667e-04 - val_loss: 9.8402e-04\n",
      "Epoch 326/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.6593e-04 - val_loss: 0.0010\n",
      "Epoch 327/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.6135e-04 - val_loss: 0.0011\n",
      "Epoch 328/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.2549e-04 - val_loss: 0.0014\n",
      "Epoch 329/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.2554e-04 - val_loss: 0.0013\n",
      "Epoch 330/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.3640e-04 - val_loss: 0.0014\n",
      "Epoch 331/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.1224e-04 - val_loss: 0.0013\n",
      "Epoch 332/2000\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 5.3538e-04 - val_loss: 0.0017\n",
      "Epoch 333/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.7354e-04 - val_loss: 0.0020\n",
      "Epoch 334/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.5616e-04 - val_loss: 0.0015\n",
      "Epoch 335/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.3895e-04 - val_loss: 0.0011\n",
      "Epoch 336/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.3127e-04 - val_loss: 0.0011\n",
      "Epoch 337/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 5.1690e-04 - val_loss: 0.0021\n",
      "Epoch 338/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.6142e-04 - val_loss: 0.0017\n",
      "Epoch 339/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.2282e-04 - val_loss: 8.6969e-04\n",
      "Epoch 340/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.9243e-04 - val_loss: 0.0012\n",
      "Epoch 341/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.3252e-04 - val_loss: 0.0014\n",
      "Epoch 342/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 5.2243e-04 - val_loss: 0.0010\n",
      "Epoch 343/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.7391e-04 - val_loss: 8.4499e-04\n",
      "Epoch 344/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.4741e-04 - val_loss: 9.5205e-04\n",
      "Epoch 345/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.1801e-04 - val_loss: 0.0017\n",
      "Epoch 346/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.3601e-04 - val_loss: 0.0015\n",
      "Epoch 347/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.2873e-04 - val_loss: 0.0014\n",
      "Epoch 348/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.3476e-04 - val_loss: 0.0019\n",
      "Epoch 349/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.2500e-04 - val_loss: 0.0020\n",
      "Epoch 350/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.4293e-04 - val_loss: 0.0016\n",
      "Epoch 351/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.2531e-04 - val_loss: 0.0018\n",
      "Epoch 352/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.0062e-04 - val_loss: 0.0017\n",
      "Epoch 353/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 5.1261e-04 - val_loss: 0.0014\n",
      "Epoch 354/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 5.1199e-04 - val_loss: 0.0010\n",
      "Epoch 355/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.3778e-04 - val_loss: 0.0015\n",
      "Epoch 356/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 6.0884e-04 - val_loss: 0.0013\n",
      "Epoch 357/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.2610e-04 - val_loss: 0.0019\n",
      "Epoch 358/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.2412e-04 - val_loss: 0.0018\n",
      "Epoch 359/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.4141e-04 - val_loss: 0.0019\n",
      "Epoch 360/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.4165e-04 - val_loss: 0.0017\n",
      "Epoch 361/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.3526e-04 - val_loss: 0.0014\n",
      "Epoch 362/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.0533e-04 - val_loss: 0.0011\n",
      "Epoch 363/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.9340e-04 - val_loss: 9.2929e-04\n",
      "Epoch 364/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.7644e-04 - val_loss: 0.0012\n",
      "Epoch 365/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.3854e-04 - val_loss: 0.0014\n",
      "Epoch 366/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.3266e-04 - val_loss: 0.0013\n",
      "Epoch 367/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.3034e-04 - val_loss: 9.1972e-04\n",
      "Epoch 368/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.4767e-04 - val_loss: 0.0013\n",
      "Epoch 369/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.2619e-04 - val_loss: 0.0014\n",
      "Epoch 370/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.2014e-04 - val_loss: 0.0010\n",
      "Epoch 371/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.5801e-04 - val_loss: 0.0010\n",
      "Epoch 372/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.4370e-04 - val_loss: 0.0016\n",
      "Epoch 373/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.2056e-04 - val_loss: 0.0017\n",
      "Epoch 374/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.0872e-04 - val_loss: 0.0021\n",
      "Epoch 375/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.4484e-04 - val_loss: 0.0021\n",
      "Epoch 376/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.5408e-04 - val_loss: 0.0019\n",
      "Epoch 377/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.3532e-04 - val_loss: 0.0020\n",
      "Epoch 378/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.2478e-04 - val_loss: 0.0016\n",
      "Epoch 379/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.0086e-04 - val_loss: 0.0013\n",
      "Epoch 380/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.1402e-04 - val_loss: 0.0013\n",
      "Epoch 381/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.1246e-04 - val_loss: 0.0013\n",
      "Epoch 382/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 5.1632e-04 - val_loss: 0.0011\n",
      "Epoch 383/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.2065e-04 - val_loss: 0.0011\n",
      "Epoch 384/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.1114e-04 - val_loss: 0.0012\n",
      "Epoch 385/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.2080e-04 - val_loss: 0.0012\n",
      "Epoch 386/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 5.1832e-04 - val_loss: 0.0017\n",
      "Epoch 387/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.2465e-04 - val_loss: 0.0016\n",
      "Epoch 388/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.9531e-04 - val_loss: 0.0019\n",
      "Epoch 389/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.8035e-04 - val_loss: 0.0015\n",
      "Epoch 390/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 5.8175e-04 - val_loss: 0.0012\n",
      "Epoch 391/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.2285e-04 - val_loss: 0.0015\n",
      "Epoch 392/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.2213e-04 - val_loss: 7.8143e-04\n",
      "Epoch 393/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.5934e-04 - val_loss: 9.4998e-04\n",
      "Epoch 394/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.5968e-04 - val_loss: 9.5250e-04\n",
      "Epoch 395/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.1975e-04 - val_loss: 0.0019\n",
      "Epoch 396/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.5719e-04 - val_loss: 0.0018\n",
      "Epoch 397/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.3627e-04 - val_loss: 0.0019\n",
      "Epoch 398/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.3200e-04 - val_loss: 0.0014\n",
      "Epoch 399/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.0565e-04 - val_loss: 0.0024\n",
      "Epoch 400/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.7109e-04 - val_loss: 0.0021\n",
      "Epoch 401/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.4739e-04 - val_loss: 0.0014\n",
      "Epoch 402/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.2222e-04 - val_loss: 0.0018\n",
      "Epoch 403/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.2461e-04 - val_loss: 0.0016\n",
      "Epoch 404/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.0109e-04 - val_loss: 0.0020\n",
      "Epoch 405/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.1931e-04 - val_loss: 0.0016\n",
      "Epoch 406/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.9813e-04 - val_loss: 0.0017\n",
      "Epoch 407/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.9860e-04 - val_loss: 0.0018\n",
      "Epoch 408/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.9589e-04 - val_loss: 0.0035\n",
      "Epoch 409/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.1138e-04 - val_loss: 0.0022\n",
      "Epoch 410/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.6308e-04 - val_loss: 6.6131e-04\n",
      "Epoch 411/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.3121e-04 - val_loss: 0.0016\n",
      "Epoch 412/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.8256e-04 - val_loss: 0.0026\n",
      "Epoch 413/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.4197e-04 - val_loss: 0.0013\n",
      "Epoch 414/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.6566e-04 - val_loss: 6.9785e-04\n",
      "Epoch 415/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.1838e-04 - val_loss: 0.0018\n",
      "Epoch 416/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.2009e-04 - val_loss: 0.0016\n",
      "Epoch 417/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.3245e-04 - val_loss: 0.0011\n",
      "Epoch 418/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.3218e-04 - val_loss: 8.3723e-04\n",
      "Epoch 419/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.5143e-04 - val_loss: 0.0015\n",
      "Epoch 420/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.1205e-04 - val_loss: 0.0012\n",
      "Epoch 421/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 4.9771e-04 - val_loss: 0.0015\n",
      "Epoch 422/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.8760e-04 - val_loss: 0.0012\n",
      "Epoch 423/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.0620e-04 - val_loss: 0.0017\n",
      "Epoch 424/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.0006e-04 - val_loss: 0.0020\n",
      "Epoch 425/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.4664e-04 - val_loss: 9.0663e-04\n",
      "Epoch 426/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 5.3355e-04 - val_loss: 0.0013\n",
      "Epoch 427/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.3723e-04 - val_loss: 0.0020\n",
      "Epoch 428/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.3089e-04 - val_loss: 9.8758e-04\n",
      "Epoch 429/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 5.2842e-04 - val_loss: 0.0011\n",
      "Epoch 430/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.0312e-04 - val_loss: 0.0016\n",
      "Epoch 431/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.1508e-04 - val_loss: 0.0019\n",
      "Epoch 432/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.3075e-04 - val_loss: 8.8130e-04\n",
      "Epoch 433/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 5.4974e-04 - val_loss: 0.0010\n",
      "Epoch 434/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 5.2408e-04 - val_loss: 0.0019\n",
      "Epoch 435/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.6226e-04 - val_loss: 0.0016\n",
      "Epoch 436/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.2752e-04 - val_loss: 0.0011\n",
      "Epoch 437/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.9888e-04 - val_loss: 0.0012\n",
      "Epoch 438/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.9276e-04 - val_loss: 0.0012\n",
      "Epoch 439/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.1592e-04 - val_loss: 0.0019\n",
      "Epoch 440/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.1656e-04 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 441/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.1148e-04 - val_loss: 9.5011e-04\n",
      "Epoch 442/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.9517e-04 - val_loss: 0.0018\n",
      "Epoch 443/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.2487e-04 - val_loss: 0.0022\n",
      "Epoch 444/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.3588e-04 - val_loss: 0.0011\n",
      "Epoch 445/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.1946e-04 - val_loss: 0.0014\n",
      "Epoch 446/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.2502e-04 - val_loss: 0.0018\n",
      "Epoch 447/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.1525e-04 - val_loss: 0.0014\n",
      "Epoch 448/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.9849e-04 - val_loss: 0.0011\n",
      "Epoch 449/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.0652e-04 - val_loss: 0.0015\n",
      "Epoch 450/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.8509e-04 - val_loss: 0.0014\n",
      "Epoch 451/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.9250e-04 - val_loss: 8.8483e-04\n",
      "Epoch 452/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 5.1348e-04 - val_loss: 0.0012\n",
      "Epoch 453/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.4803e-04 - val_loss: 0.0015\n",
      "Epoch 454/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.1544e-04 - val_loss: 0.0023\n",
      "Epoch 455/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 5.2134e-04 - val_loss: 0.0011\n",
      "Epoch 456/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.4639e-04 - val_loss: 0.0011\n",
      "Epoch 457/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.2489e-04 - val_loss: 8.0152e-04\n",
      "Epoch 458/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.0834e-04 - val_loss: 0.0014\n",
      "Epoch 459/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 4.8370e-04 - val_loss: 0.0014\n",
      "Epoch 460/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.3539e-04 - val_loss: 0.0014\n",
      "Epoch 461/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.7677e-04 - val_loss: 0.0018\n",
      "Epoch 462/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.9192e-04 - val_loss: 0.0014\n",
      "Epoch 463/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.8236e-04 - val_loss: 0.0017\n",
      "Epoch 464/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.8817e-04 - val_loss: 0.0012\n",
      "Epoch 465/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.9869e-04 - val_loss: 0.0013\n",
      "Epoch 466/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.8770e-04 - val_loss: 9.7814e-04\n",
      "Epoch 467/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.9369e-04 - val_loss: 0.0016\n",
      "Epoch 468/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 5.1275e-04 - val_loss: 0.0017\n",
      "Epoch 469/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.0152e-04 - val_loss: 0.0019\n",
      "Epoch 470/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.2519e-04 - val_loss: 0.0019\n",
      "Epoch 471/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.3891e-04 - val_loss: 0.0010\n",
      "Epoch 472/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.5310e-04 - val_loss: 6.7613e-04\n",
      "Epoch 473/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 5.9374e-04 - val_loss: 9.3761e-04\n",
      "Epoch 474/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 5.2689e-04 - val_loss: 0.0013\n",
      "Epoch 475/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.9540e-04 - val_loss: 0.0018\n",
      "Epoch 476/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.9307e-04 - val_loss: 0.0016\n",
      "Epoch 477/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.6847e-04 - val_loss: 0.0014\n",
      "Epoch 478/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.7154e-04 - val_loss: 9.3268e-04\n",
      "Epoch 479/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.5924e-04 - val_loss: 8.7604e-04\n",
      "Epoch 480/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.2740e-04 - val_loss: 0.0018\n",
      "Epoch 481/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.8514e-04 - val_loss: 0.0012\n",
      "Epoch 482/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.9007e-04 - val_loss: 0.0016\n",
      "Epoch 483/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.1924e-04 - val_loss: 0.0011\n",
      "Epoch 484/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 4.8900e-04 - val_loss: 0.0014\n",
      "Epoch 485/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.8896e-04 - val_loss: 0.0017\n",
      "Epoch 486/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.9272e-04 - val_loss: 0.0015\n",
      "Epoch 487/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.9835e-04 - val_loss: 9.5762e-04\n",
      "Epoch 488/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.2609e-04 - val_loss: 8.2652e-04\n",
      "Epoch 489/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.3570e-04 - val_loss: 0.0015\n",
      "Epoch 490/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.7856e-04 - val_loss: 0.0012\n",
      "Epoch 491/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 4.8178e-04 - val_loss: 0.0010\n",
      "Epoch 492/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.7723e-04 - val_loss: 0.0011\n",
      "Epoch 493/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.6100e-04 - val_loss: 0.0013\n",
      "Epoch 494/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.7041e-04 - val_loss: 9.9707e-04\n",
      "Epoch 495/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.0045e-04 - val_loss: 0.0015\n",
      "Epoch 496/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.3331e-04 - val_loss: 0.0023\n",
      "Epoch 497/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.1705e-04 - val_loss: 7.9646e-04\n",
      "Epoch 498/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.3130e-04 - val_loss: 0.0011\n",
      "Epoch 499/2000\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 4.7341e-04 - val_loss: 0.0015\n",
      "Epoch 500/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.6206e-04 - val_loss: 0.0012\n",
      "Epoch 501/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 4.5734e-04 - val_loss: 0.0013\n",
      "Epoch 502/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.7504e-04 - val_loss: 0.0012\n",
      "Epoch 503/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.6833e-04 - val_loss: 0.0014\n",
      "Epoch 504/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.6177e-04 - val_loss: 0.0014\n",
      "Epoch 505/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.8794e-04 - val_loss: 0.0016\n",
      "Epoch 506/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.5356e-04 - val_loss: 0.0012\n",
      "Epoch 507/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 4.5863e-04 - val_loss: 0.0011\n",
      "Epoch 508/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.2818e-04 - val_loss: 9.3905e-04\n",
      "Epoch 509/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.2757e-04 - val_loss: 0.0015\n",
      "Epoch 510/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.1811e-04 - val_loss: 0.0013\n",
      "Epoch 511/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.8753e-04 - val_loss: 0.0021\n",
      "Epoch 512/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.8297e-04 - val_loss: 0.0012\n",
      "Epoch 513/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.6703e-04 - val_loss: 0.0014\n",
      "Epoch 514/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.6662e-04 - val_loss: 0.0013\n",
      "Epoch 515/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.6986e-04 - val_loss: 9.6373e-04\n",
      "Epoch 516/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.9397e-04 - val_loss: 0.0014\n",
      "Epoch 517/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.6722e-04 - val_loss: 0.0013\n",
      "Epoch 518/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.6438e-04 - val_loss: 0.0018\n",
      "Epoch 519/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.7244e-04 - val_loss: 0.0013\n",
      "Epoch 520/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.6045e-04 - val_loss: 0.0011\n",
      "Epoch 521/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.8318e-04 - val_loss: 0.0012\n",
      "Epoch 522/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.6527e-04 - val_loss: 0.0019\n",
      "Epoch 523/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.1591e-04 - val_loss: 0.0016\n",
      "Epoch 524/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.7742e-04 - val_loss: 9.9323e-04\n",
      "Epoch 525/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.6291e-04 - val_loss: 0.0010\n",
      "Epoch 526/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.6686e-04 - val_loss: 0.0016\n",
      "Epoch 527/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.5981e-04 - val_loss: 0.0011\n",
      "Epoch 528/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.5689e-04 - val_loss: 0.0012\n",
      "Epoch 529/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.7473e-04 - val_loss: 9.5237e-04\n",
      "Epoch 530/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.5968e-04 - val_loss: 9.3749e-04\n",
      "Epoch 531/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.4263e-04 - val_loss: 0.0014\n",
      "Epoch 532/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.5597e-04 - val_loss: 0.0021\n",
      "Epoch 533/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.9890e-04 - val_loss: 0.0013\n",
      "Epoch 534/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.7002e-04 - val_loss: 7.2975e-04\n",
      "Epoch 535/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.2644e-04 - val_loss: 6.6103e-04\n",
      "Epoch 536/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.5717e-04 - val_loss: 0.0013\n",
      "Epoch 537/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.1059e-04 - val_loss: 0.0012\n",
      "Epoch 538/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 4.7248e-04 - val_loss: 0.0018\n",
      "Epoch 539/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.8039e-04 - val_loss: 9.8302e-04\n",
      "Epoch 540/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.8128e-04 - val_loss: 0.0010\n",
      "Epoch 541/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.8453e-04 - val_loss: 0.0010\n",
      "Epoch 542/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.5388e-04 - val_loss: 0.0012\n",
      "Epoch 543/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.5075e-04 - val_loss: 0.0017\n",
      "Epoch 544/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.5141e-04 - val_loss: 0.0015\n",
      "Epoch 545/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.7976e-04 - val_loss: 0.0015\n",
      "Epoch 546/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 4.8782e-04 - val_loss: 0.0020\n",
      "Epoch 547/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 5.0541e-04 - val_loss: 0.0012\n",
      "Epoch 548/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.8315e-04 - val_loss: 0.0010\n",
      "Epoch 549/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.4990e-04 - val_loss: 0.0011\n",
      "Epoch 550/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.5630e-04 - val_loss: 0.0013\n",
      "Epoch 551/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.5589e-04 - val_loss: 0.0015\n",
      "Epoch 552/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.6066e-04 - val_loss: 0.0013\n",
      "Epoch 553/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.4928e-04 - val_loss: 0.0012\n",
      "Epoch 554/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.4801e-04 - val_loss: 0.0014\n",
      "Epoch 555/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.4664e-04 - val_loss: 8.8273e-04\n",
      "Epoch 556/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.1049e-04 - val_loss: 6.7002e-04\n",
      "Epoch 557/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.8766e-04 - val_loss: 7.7619e-04\n",
      "Epoch 558/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 4.8878e-04 - val_loss: 0.0011\n",
      "Epoch 559/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.2261e-04 - val_loss: 0.0023\n",
      "Epoch 560/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.2428e-04 - val_loss: 0.0014\n",
      "Epoch 561/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.9713e-04 - val_loss: 9.2618e-04\n",
      "Epoch 562/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 4.6408e-04 - val_loss: 0.0012\n",
      "Epoch 563/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.6882e-04 - val_loss: 0.0015\n",
      "Epoch 564/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 4.8666e-04 - val_loss: 0.0012\n",
      "Epoch 565/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.9660e-04 - val_loss: 7.5900e-04\n",
      "Epoch 566/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.7633e-04 - val_loss: 0.0013\n",
      "Epoch 567/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.7973e-04 - val_loss: 0.0018\n",
      "Epoch 568/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.1201e-04 - val_loss: 9.9344e-04\n",
      "Epoch 569/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.4093e-04 - val_loss: 0.0012\n",
      "Epoch 570/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.3632e-04 - val_loss: 9.8787e-04\n",
      "Epoch 571/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.5674e-04 - val_loss: 9.3186e-04\n",
      "Epoch 572/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.4158e-04 - val_loss: 0.0012\n",
      "Epoch 573/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.3898e-04 - val_loss: 0.0011\n",
      "Epoch 574/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.5040e-04 - val_loss: 0.0010\n",
      "Epoch 575/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.4593e-04 - val_loss: 9.2533e-04\n",
      "Epoch 576/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.4087e-04 - val_loss: 0.0013\n",
      "Epoch 577/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.4434e-04 - val_loss: 7.0056e-04\n",
      "Epoch 578/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.1538e-04 - val_loss: 9.4711e-04\n",
      "Epoch 579/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.7319e-04 - val_loss: 0.0021\n",
      "Epoch 580/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.9646e-04 - val_loss: 0.0012\n",
      "Epoch 581/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.4442e-04 - val_loss: 0.0011\n",
      "Epoch 582/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.4027e-04 - val_loss: 0.0015\n",
      "Epoch 583/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.7454e-04 - val_loss: 0.0014\n",
      "Epoch 584/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.5613e-04 - val_loss: 8.6873e-04\n",
      "Epoch 585/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 599us/step - loss: 4.5068e-04 - val_loss: 7.5592e-04\n",
      "Epoch 586/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 5.2278e-04 - val_loss: 0.0010\n",
      "Epoch 587/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.8785e-04 - val_loss: 0.0016\n",
      "Epoch 588/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.6704e-04 - val_loss: 0.0013\n",
      "Epoch 589/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.6816e-04 - val_loss: 7.1873e-04\n",
      "Epoch 590/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.4879e-04 - val_loss: 9.6736e-04\n",
      "Epoch 591/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 4.2600e-04 - val_loss: 0.0012\n",
      "Epoch 592/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.3879e-04 - val_loss: 0.0014\n",
      "Epoch 593/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.3443e-04 - val_loss: 9.6113e-04\n",
      "Epoch 594/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.3709e-04 - val_loss: 8.8816e-04\n",
      "Epoch 595/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.4310e-04 - val_loss: 0.0018\n",
      "Epoch 596/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.3922e-04 - val_loss: 0.0015\n",
      "Epoch 597/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.4991e-04 - val_loss: 0.0011\n",
      "Epoch 598/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.2737e-04 - val_loss: 0.0013\n",
      "Epoch 599/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.4669e-04 - val_loss: 0.0015\n",
      "Epoch 600/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.8379e-04 - val_loss: 8.4172e-04\n",
      "Epoch 601/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.6816e-04 - val_loss: 9.0859e-04\n",
      "Epoch 602/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 4.2557e-04 - val_loss: 0.0012\n",
      "Epoch 603/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.3214e-04 - val_loss: 0.0010\n",
      "Epoch 604/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.3074e-04 - val_loss: 9.6184e-04\n",
      "Epoch 605/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.4943e-04 - val_loss: 0.0010\n",
      "Epoch 606/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.2801e-04 - val_loss: 0.0011\n",
      "Epoch 607/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.3662e-04 - val_loss: 9.3762e-04\n",
      "Epoch 608/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.3812e-04 - val_loss: 0.0018\n",
      "Epoch 609/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 4.8050e-04 - val_loss: 0.0015\n",
      "Epoch 610/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.2035e-04 - val_loss: 0.0011\n",
      "Epoch 611/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.1271e-04 - val_loss: 0.0010\n",
      "Epoch 612/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.2985e-04 - val_loss: 0.0021\n",
      "Epoch 613/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.6466e-04 - val_loss: 0.0014\n",
      "Epoch 614/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.1867e-04 - val_loss: 0.0011\n",
      "Epoch 615/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.3561e-04 - val_loss: 9.1110e-04\n",
      "Epoch 616/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 4.4586e-04 - val_loss: 0.0014\n",
      "Epoch 617/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 4.4866e-04 - val_loss: 0.0012\n",
      "Epoch 618/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.1408e-04 - val_loss: 9.3476e-04\n",
      "Epoch 619/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 4.2549e-04 - val_loss: 0.0012\n",
      "Epoch 620/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.7930e-04 - val_loss: 0.0017\n",
      "Epoch 621/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.4798e-04 - val_loss: 0.0018\n",
      "Epoch 622/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 5.1619e-04 - val_loss: 0.0012\n",
      "Epoch 623/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 4.8585e-04 - val_loss: 9.0727e-04\n",
      "Epoch 624/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 4.3122e-04 - val_loss: 0.0014\n",
      "Epoch 625/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.4963e-04 - val_loss: 9.4134e-04\n",
      "Epoch 626/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.5050e-04 - val_loss: 7.8600e-04\n",
      "Epoch 627/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.3807e-04 - val_loss: 0.0010\n",
      "Epoch 628/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.3211e-04 - val_loss: 0.0013\n",
      "Epoch 629/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.3147e-04 - val_loss: 0.0014\n",
      "Epoch 630/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.4275e-04 - val_loss: 0.0012\n",
      "Epoch 631/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.1082e-04 - val_loss: 8.3728e-04\n",
      "Epoch 632/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 4.2152e-04 - val_loss: 0.0012\n",
      "Epoch 633/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.1861e-04 - val_loss: 0.0014\n",
      "Epoch 634/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.0224e-04 - val_loss: 0.0013\n",
      "Epoch 635/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.0465e-04 - val_loss: 9.7116e-04\n",
      "Epoch 636/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.1865e-04 - val_loss: 0.0010\n",
      "Epoch 637/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.2454e-04 - val_loss: 0.0016\n",
      "Epoch 638/2000\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 4.5131e-04 - val_loss: 8.5695e-04\n",
      "Epoch 639/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 4.6908e-04 - val_loss: 6.9155e-04\n",
      "Epoch 640/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 4.1618e-04 - val_loss: 0.0013\n",
      "Epoch 641/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.1486e-04 - val_loss: 9.6707e-04\n",
      "Epoch 642/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.0068e-04 - val_loss: 0.0014\n",
      "Epoch 643/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 4.2713e-04 - val_loss: 0.0012\n",
      "Epoch 644/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.0692e-04 - val_loss: 0.0013\n",
      "Epoch 645/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.2360e-04 - val_loss: 9.7810e-04\n",
      "Epoch 646/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 4.2145e-04 - val_loss: 8.6285e-04\n",
      "Epoch 647/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.1925e-04 - val_loss: 8.2409e-04\n",
      "Epoch 648/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.0511e-04 - val_loss: 9.3379e-04\n",
      "Epoch 649/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.9329e-04 - val_loss: 0.0011\n",
      "Epoch 650/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 4.1438e-04 - val_loss: 7.2260e-04\n",
      "Epoch 651/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.4123e-04 - val_loss: 9.4903e-04\n",
      "Epoch 652/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.0211e-04 - val_loss: 0.0011\n",
      "Epoch 653/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.3344e-04 - val_loss: 0.0012\n",
      "Epoch 654/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.0507e-04 - val_loss: 0.0015\n",
      "Epoch 655/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.2303e-04 - val_loss: 8.6086e-04\n",
      "Epoch 656/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 4.3062e-04 - val_loss: 7.4670e-04\n",
      "Epoch 657/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.1291e-04 - val_loss: 9.8721e-04\n",
      "Epoch 658/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.9996e-04 - val_loss: 7.4328e-04\n",
      "Epoch 659/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.1370e-04 - val_loss: 8.2998e-04\n",
      "Epoch 660/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.5222e-04 - val_loss: 8.9285e-04\n",
      "Epoch 661/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.1114e-04 - val_loss: 0.0010\n",
      "Epoch 662/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.1667e-04 - val_loss: 8.6115e-04\n",
      "Epoch 663/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.6442e-04 - val_loss: 7.9650e-04\n",
      "Epoch 664/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 4.1799e-04 - val_loss: 8.9292e-04\n",
      "Epoch 665/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.9127e-04 - val_loss: 0.0010\n",
      "Epoch 666/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.7663e-04 - val_loss: 0.0013\n",
      "Epoch 667/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.0366e-04 - val_loss: 0.0010\n",
      "Epoch 668/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.0483e-04 - val_loss: 0.0012\n",
      "Epoch 669/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.8523e-04 - val_loss: 8.5934e-04\n",
      "Epoch 670/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.8936e-04 - val_loss: 9.0714e-04\n",
      "Epoch 671/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 4.1796e-04 - val_loss: 7.1744e-04\n",
      "Epoch 672/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.2728e-04 - val_loss: 0.0012\n",
      "Epoch 673/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 3.8013e-04 - val_loss: 9.9268e-04\n",
      "Epoch 674/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.0176e-04 - val_loss: 7.3593e-04\n",
      "Epoch 675/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 4.4385e-04 - val_loss: 7.1504e-04\n",
      "Epoch 676/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.9231e-04 - val_loss: 9.6846e-04\n",
      "Epoch 677/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.7623e-04 - val_loss: 0.0011\n",
      "Epoch 678/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.8364e-04 - val_loss: 8.0228e-04\n",
      "Epoch 679/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.0745e-04 - val_loss: 7.9994e-04\n",
      "Epoch 680/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.0419e-04 - val_loss: 8.2946e-04\n",
      "Epoch 681/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.7455e-04 - val_loss: 0.0011\n",
      "Epoch 682/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.7802e-04 - val_loss: 0.0011\n",
      "Epoch 683/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.3541e-04 - val_loss: 8.2551e-04\n",
      "Epoch 684/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.4773e-04 - val_loss: 7.0271e-04\n",
      "Epoch 685/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.6172e-04 - val_loss: 8.2307e-04\n",
      "Epoch 686/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.1268e-04 - val_loss: 8.4400e-04\n",
      "Epoch 687/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.9365e-04 - val_loss: 8.9174e-04\n",
      "Epoch 688/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.0952e-04 - val_loss: 8.6056e-04\n",
      "Epoch 689/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.8855e-04 - val_loss: 8.5648e-04\n",
      "Epoch 690/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 3.7131e-04 - val_loss: 0.0011\n",
      "Epoch 691/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.0878e-04 - val_loss: 0.0019\n",
      "Epoch 692/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 4.7441e-04 - val_loss: 0.0010\n",
      "Epoch 693/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.7647e-04 - val_loss: 7.3818e-04\n",
      "Epoch 694/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.6687e-04 - val_loss: 7.4972e-04\n",
      "Epoch 695/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 4.0915e-04 - val_loss: 9.8551e-04\n",
      "Epoch 696/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 4.3576e-04 - val_loss: 0.0013\n",
      "Epoch 697/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 3.9836e-04 - val_loss: 0.0012\n",
      "Epoch 698/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.7372e-04 - val_loss: 0.0011\n",
      "Epoch 699/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.6365e-04 - val_loss: 7.6275e-04\n",
      "Epoch 700/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 3.8011e-04 - val_loss: 9.2698e-04\n",
      "Epoch 701/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.6639e-04 - val_loss: 8.2139e-04\n",
      "Epoch 702/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 4.1262e-04 - val_loss: 7.6212e-04\n",
      "Epoch 703/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 4.0114e-04 - val_loss: 0.0013\n",
      "Epoch 704/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.9431e-04 - val_loss: 0.0011\n",
      "Epoch 705/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 3.9909e-04 - val_loss: 0.0017\n",
      "Epoch 706/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.2129e-04 - val_loss: 0.0012\n",
      "Epoch 707/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.7765e-04 - val_loss: 0.0011\n",
      "Epoch 708/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.6361e-04 - val_loss: 9.4949e-04\n",
      "Epoch 709/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.8555e-04 - val_loss: 8.8047e-04\n",
      "Epoch 710/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.7281e-04 - val_loss: 7.4992e-04\n",
      "Epoch 711/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.8387e-04 - val_loss: 0.0012\n",
      "Epoch 712/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 3.6638e-04 - val_loss: 0.0011\n",
      "Epoch 713/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.5763e-04 - val_loss: 0.0012\n",
      "Epoch 714/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.4804e-04 - val_loss: 0.0010\n",
      "Epoch 715/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.8202e-04 - val_loss: 0.0013\n",
      "Epoch 716/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.1047e-04 - val_loss: 0.0013\n",
      "Epoch 717/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.7022e-04 - val_loss: 9.7533e-04\n",
      "Epoch 718/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.6589e-04 - val_loss: 7.8455e-04\n",
      "Epoch 719/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 4.0189e-04 - val_loss: 8.9332e-04\n",
      "Epoch 720/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.6384e-04 - val_loss: 0.0011\n",
      "Epoch 721/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.5867e-04 - val_loss: 9.6024e-04\n",
      "Epoch 722/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 3.5066e-04 - val_loss: 0.0015\n",
      "Epoch 723/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.6237e-04 - val_loss: 9.2927e-04\n",
      "Epoch 724/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.3916e-04 - val_loss: 8.0887e-04\n",
      "Epoch 725/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 3.8235e-04 - val_loss: 9.3369e-04\n",
      "Epoch 726/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.9248e-04 - val_loss: 0.0011\n",
      "Epoch 727/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 3.9117e-04 - val_loss: 0.0013\n",
      "Epoch 728/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.0867e-04 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 729/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 4.2029e-04 - val_loss: 0.0011\n",
      "Epoch 730/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.8280e-04 - val_loss: 7.6856e-04\n",
      "Epoch 731/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 4.0757e-04 - val_loss: 8.1402e-04\n",
      "Epoch 732/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 4.0471e-04 - val_loss: 0.0013\n",
      "Epoch 733/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 4.0595e-04 - val_loss: 0.0013\n",
      "Epoch 734/2000\n",
      "3423/3423 [==============================] - 2s 608us/step - loss: 3.7826e-04 - val_loss: 0.0013\n",
      "Epoch 735/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.9856e-04 - val_loss: 8.3614e-04\n",
      "Epoch 736/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.9091e-04 - val_loss: 8.3959e-04\n",
      "Epoch 737/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.5711e-04 - val_loss: 9.6025e-04\n",
      "Epoch 738/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.7637e-04 - val_loss: 0.0010\n",
      "Epoch 739/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.5508e-04 - val_loss: 0.0012\n",
      "Epoch 740/2000\n",
      "3423/3423 [==============================] - 2s 590us/step - loss: 4.1865e-04 - val_loss: 9.3107e-04\n",
      "Epoch 741/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.2229e-04 - val_loss: 8.0224e-04\n",
      "Epoch 742/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 4.1285e-04 - val_loss: 7.1655e-04\n",
      "Epoch 743/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.9612e-04 - val_loss: 0.0011\n",
      "Epoch 744/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 4.1656e-04 - val_loss: 0.0011\n",
      "Epoch 745/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.7497e-04 - val_loss: 8.6988e-04\n",
      "Epoch 746/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.5769e-04 - val_loss: 8.5987e-04\n",
      "Epoch 747/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.5083e-04 - val_loss: 9.4274e-04\n",
      "Epoch 748/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.3894e-04 - val_loss: 8.8086e-04\n",
      "Epoch 749/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 3.4926e-04 - val_loss: 0.0010\n",
      "Epoch 750/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.3428e-04 - val_loss: 0.0012\n",
      "Epoch 751/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 4.0493e-04 - val_loss: 8.9272e-04\n",
      "Epoch 752/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.6191e-04 - val_loss: 7.7748e-04\n",
      "Epoch 753/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.7567e-04 - val_loss: 9.5299e-04\n",
      "Epoch 754/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.4347e-04 - val_loss: 8.8100e-04\n",
      "Epoch 755/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 3.2587e-04 - val_loss: 9.5173e-04\n",
      "Epoch 756/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.3015e-04 - val_loss: 8.3938e-04\n",
      "Epoch 757/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 3.4203e-04 - val_loss: 9.0077e-04\n",
      "Epoch 758/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.2986e-04 - val_loss: 8.9172e-04\n",
      "Epoch 759/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.3983e-04 - val_loss: 0.0012\n",
      "Epoch 760/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.5846e-04 - val_loss: 0.0012\n",
      "Epoch 761/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.5957e-04 - val_loss: 9.7088e-04\n",
      "Epoch 762/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 3.7978e-04 - val_loss: 9.6168e-04\n",
      "Epoch 763/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 3.8377e-04 - val_loss: 0.0012\n",
      "Epoch 764/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.8969e-04 - val_loss: 0.0011\n",
      "Epoch 765/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.6990e-04 - val_loss: 0.0012\n",
      "Epoch 766/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 3.5032e-04 - val_loss: 8.6103e-04\n",
      "Epoch 767/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.2272e-04 - val_loss: 8.5121e-04\n",
      "Epoch 768/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.2971e-04 - val_loss: 0.0012\n",
      "Epoch 769/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.4123e-04 - val_loss: 0.0010\n",
      "Epoch 770/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.2945e-04 - val_loss: 0.0012\n",
      "Epoch 771/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.1740e-04 - val_loss: 0.0010\n",
      "Epoch 772/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.1518e-04 - val_loss: 0.0011\n",
      "Epoch 773/2000\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 3.1557e-04 - val_loss: 0.0010\n",
      "Epoch 774/2000\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 3.4228e-04 - val_loss: 0.0011\n",
      "Epoch 775/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.7167e-04 - val_loss: 9.7325e-04\n",
      "Epoch 776/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.3806e-04 - val_loss: 0.0010\n",
      "Epoch 777/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.0695e-04 - val_loss: 0.0011\n",
      "Epoch 778/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 2.9785e-04 - val_loss: 9.6283e-04\n",
      "Epoch 779/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.0834e-04 - val_loss: 0.0012\n",
      "Epoch 780/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.5621e-04 - val_loss: 0.0010\n",
      "Epoch 781/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 3.3340e-04 - val_loss: 0.0011\n",
      "Epoch 782/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 3.4070e-04 - val_loss: 0.0011\n",
      "Epoch 783/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.2148e-04 - val_loss: 0.0011\n",
      "Epoch 784/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 3.0042e-04 - val_loss: 0.0011\n",
      "Epoch 785/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.0584e-04 - val_loss: 0.0012\n",
      "Epoch 786/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.9394e-04 - val_loss: 0.0012\n",
      "Epoch 787/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.9932e-04 - val_loss: 0.0011\n",
      "Epoch 788/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.8945e-04 - val_loss: 0.0014\n",
      "Epoch 789/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 2.8871e-04 - val_loss: 0.0012\n",
      "Epoch 790/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.8768e-04 - val_loss: 0.0014\n",
      "Epoch 791/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.0679e-04 - val_loss: 0.0011\n",
      "Epoch 792/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.3017e-04 - val_loss: 0.0012\n",
      "Epoch 793/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 3.2416e-04 - val_loss: 0.0012\n",
      "Epoch 794/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.0834e-04 - val_loss: 0.0011\n",
      "Epoch 795/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.1616e-04 - val_loss: 0.0012\n",
      "Epoch 796/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.0597e-04 - val_loss: 0.0011\n",
      "Epoch 797/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.1045e-04 - val_loss: 0.0012\n",
      "Epoch 798/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.2292e-04 - val_loss: 0.0013\n",
      "Epoch 799/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.3153e-04 - val_loss: 0.0012\n",
      "Epoch 800/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.1330e-04 - val_loss: 0.0014\n",
      "Epoch 801/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.0976e-04 - val_loss: 0.0012\n",
      "Epoch 802/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.0127e-04 - val_loss: 0.0013\n",
      "Epoch 803/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.0677e-04 - val_loss: 0.0014\n",
      "Epoch 804/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.1165e-04 - val_loss: 0.0013\n",
      "Epoch 805/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.1041e-04 - val_loss: 0.0013\n",
      "Epoch 806/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.0056e-04 - val_loss: 0.0013\n",
      "Epoch 807/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 2.9436e-04 - val_loss: 0.0014\n",
      "Epoch 808/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.8156e-04 - val_loss: 0.0016\n",
      "Epoch 809/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 2.9720e-04 - val_loss: 0.0012\n",
      "Epoch 810/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.9676e-04 - val_loss: 0.0017\n",
      "Epoch 811/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.0265e-04 - val_loss: 0.0015\n",
      "Epoch 812/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 3.1866e-04 - val_loss: 0.0014\n",
      "Epoch 813/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.9685e-04 - val_loss: 0.0014\n",
      "Epoch 814/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.9836e-04 - val_loss: 0.0014\n",
      "Epoch 815/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.1407e-04 - val_loss: 0.0013\n",
      "Epoch 816/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.0653e-04 - val_loss: 0.0013\n",
      "Epoch 817/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.1188e-04 - val_loss: 0.0013\n",
      "Epoch 818/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.1792e-04 - val_loss: 0.0015\n",
      "Epoch 819/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.2161e-04 - val_loss: 0.0012\n",
      "Epoch 820/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 2.9937e-04 - val_loss: 0.0014\n",
      "Epoch 821/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.0842e-04 - val_loss: 0.0013\n",
      "Epoch 822/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 3.4411e-04 - val_loss: 0.0014\n",
      "Epoch 823/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.3689e-04 - val_loss: 0.0012\n",
      "Epoch 824/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 2.8511e-04 - val_loss: 0.0014\n",
      "Epoch 825/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.9167e-04 - val_loss: 0.0013\n",
      "Epoch 826/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.7252e-04 - val_loss: 0.0013\n",
      "Epoch 827/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.9108e-04 - val_loss: 0.0016\n",
      "Epoch 828/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 2.6617e-04 - val_loss: 0.0012\n",
      "Epoch 829/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.6485e-04 - val_loss: 0.0015\n",
      "Epoch 830/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.0018e-04 - val_loss: 0.0013\n",
      "Epoch 831/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.9500e-04 - val_loss: 0.0016\n",
      "Epoch 832/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.0370e-04 - val_loss: 0.0014\n",
      "Epoch 833/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.1625e-04 - val_loss: 0.0013\n",
      "Epoch 834/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 3.1121e-04 - val_loss: 0.0016\n",
      "Epoch 835/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.9823e-04 - val_loss: 0.0012\n",
      "Epoch 836/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 3.0250e-04 - val_loss: 0.0012\n",
      "Epoch 837/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 2.9472e-04 - val_loss: 0.0013\n",
      "Epoch 838/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 2.9154e-04 - val_loss: 0.0015\n",
      "Epoch 839/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.9312e-04 - val_loss: 0.0013\n",
      "Epoch 840/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.7587e-04 - val_loss: 0.0015\n",
      "Epoch 841/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.0568e-04 - val_loss: 0.0020\n",
      "Epoch 842/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.9958e-04 - val_loss: 0.0012\n",
      "Epoch 843/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.1504e-04 - val_loss: 0.0015\n",
      "Epoch 844/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 3.3366e-04 - val_loss: 0.0014\n",
      "Epoch 845/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 3.5665e-04 - val_loss: 0.0014\n",
      "Epoch 846/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.9113e-04 - val_loss: 0.0014\n",
      "Epoch 847/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 2.8971e-04 - val_loss: 0.0015\n",
      "Epoch 848/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.9777e-04 - val_loss: 0.0015\n",
      "Epoch 849/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 3.0600e-04 - val_loss: 0.0016\n",
      "Epoch 850/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.8857e-04 - val_loss: 0.0016\n",
      "Epoch 851/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 2.7377e-04 - val_loss: 0.0012\n",
      "Epoch 852/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.6636e-04 - val_loss: 0.0015\n",
      "Epoch 853/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.5559e-04 - val_loss: 0.0015\n",
      "Epoch 854/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.6049e-04 - val_loss: 0.0016\n",
      "Epoch 855/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.7284e-04 - val_loss: 0.0013\n",
      "Epoch 856/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 2.5836e-04 - val_loss: 0.0017\n",
      "Epoch 857/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.7024e-04 - val_loss: 0.0014\n",
      "Epoch 858/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.8329e-04 - val_loss: 0.0014\n",
      "Epoch 859/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 2.7658e-04 - val_loss: 0.0015\n",
      "Epoch 860/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.8400e-04 - val_loss: 0.0017\n",
      "Epoch 861/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.8634e-04 - val_loss: 0.0014\n",
      "Epoch 862/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.8153e-04 - val_loss: 0.0017\n",
      "Epoch 863/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.6621e-04 - val_loss: 0.0014\n",
      "Epoch 864/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.8201e-04 - val_loss: 0.0016\n",
      "Epoch 865/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.9540e-04 - val_loss: 0.0016\n",
      "Epoch 866/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.9875e-04 - val_loss: 0.0018\n",
      "Epoch 867/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 3.0645e-04 - val_loss: 0.0016\n",
      "Epoch 868/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.8836e-04 - val_loss: 0.0016\n",
      "Epoch 869/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.7320e-04 - val_loss: 0.0015\n",
      "Epoch 870/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.6624e-04 - val_loss: 0.0015\n",
      "Epoch 871/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.3622e-04 - val_loss: 0.0016\n",
      "Epoch 872/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.5058e-04 - val_loss: 0.0017\n",
      "Epoch 873/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.5812e-04 - val_loss: 0.0016\n",
      "Epoch 874/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 593us/step - loss: 2.6079e-04 - val_loss: 0.0015\n",
      "Epoch 875/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.7445e-04 - val_loss: 0.0015\n",
      "Epoch 876/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.5543e-04 - val_loss: 0.0016\n",
      "Epoch 877/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.4843e-04 - val_loss: 0.0018\n",
      "Epoch 878/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.7026e-04 - val_loss: 0.0017\n",
      "Epoch 879/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.6805e-04 - val_loss: 0.0016\n",
      "Epoch 880/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.7099e-04 - val_loss: 0.0025\n",
      "Epoch 881/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 2.9578e-04 - val_loss: 0.0020\n",
      "Epoch 882/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 3.2099e-04 - val_loss: 0.0018\n",
      "Epoch 883/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 3.0926e-04 - val_loss: 0.0017\n",
      "Epoch 884/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.9715e-04 - val_loss: 0.0016\n",
      "Epoch 885/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.7187e-04 - val_loss: 0.0015\n",
      "Epoch 886/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.5204e-04 - val_loss: 0.0018\n",
      "Epoch 887/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.5534e-04 - val_loss: 0.0015\n",
      "Epoch 888/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.3120e-04 - val_loss: 0.0018\n",
      "Epoch 889/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.2657e-04 - val_loss: 0.0017\n",
      "Epoch 890/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 2.4802e-04 - val_loss: 0.0016\n",
      "Epoch 891/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.5365e-04 - val_loss: 0.0017\n",
      "Epoch 892/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.6726e-04 - val_loss: 0.0017\n",
      "Epoch 893/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.6803e-04 - val_loss: 0.0022\n",
      "Epoch 894/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 2.7119e-04 - val_loss: 0.0016\n",
      "Epoch 895/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 2.6746e-04 - val_loss: 0.0016\n",
      "Epoch 896/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 2.7286e-04 - val_loss: 0.0017\n",
      "Epoch 897/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 3.0551e-04 - val_loss: 0.0015\n",
      "Epoch 898/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 3.2143e-04 - val_loss: 0.0022\n",
      "Epoch 899/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.2363e-04 - val_loss: 0.0017\n",
      "Epoch 900/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.5897e-04 - val_loss: 0.0018\n",
      "Epoch 901/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.7403e-04 - val_loss: 0.0020\n",
      "Epoch 902/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.7414e-04 - val_loss: 0.0023\n",
      "Epoch 903/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.7308e-04 - val_loss: 0.0018\n",
      "Epoch 904/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.6331e-04 - val_loss: 0.0024\n",
      "Epoch 905/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.6122e-04 - val_loss: 0.0020\n",
      "Epoch 906/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 2.3524e-04 - val_loss: 0.0018\n",
      "Epoch 907/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.2586e-04 - val_loss: 0.0021\n",
      "Epoch 908/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.4853e-04 - val_loss: 0.0025\n",
      "Epoch 909/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.4167e-04 - val_loss: 0.0020\n",
      "Epoch 910/2000\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 2.3673e-04 - val_loss: 0.0021\n",
      "Epoch 911/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.2507e-04 - val_loss: 0.0019\n",
      "Epoch 912/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.6260e-04 - val_loss: 0.0022\n",
      "Epoch 913/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 2.6897e-04 - val_loss: 0.0022\n",
      "Epoch 914/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 2.6944e-04 - val_loss: 0.0024\n",
      "Epoch 915/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.5406e-04 - val_loss: 0.0020\n",
      "Epoch 916/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.5790e-04 - val_loss: 0.0019\n",
      "Epoch 917/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.2871e-04 - val_loss: 0.0022\n",
      "Epoch 918/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.4433e-04 - val_loss: 0.0019\n",
      "Epoch 919/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 2.2771e-04 - val_loss: 0.0019\n",
      "Epoch 920/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.1912e-04 - val_loss: 0.0021\n",
      "Epoch 921/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.2701e-04 - val_loss: 0.0020\n",
      "Epoch 922/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.6230e-04 - val_loss: 0.0018\n",
      "Epoch 923/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.0732e-04 - val_loss: 0.0022\n",
      "Epoch 924/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 3.0238e-04 - val_loss: 0.0019\n",
      "Epoch 925/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 2.5823e-04 - val_loss: 0.0022\n",
      "Epoch 926/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.3168e-04 - val_loss: 0.0023\n",
      "Epoch 927/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.1059e-04 - val_loss: 0.0024\n",
      "Epoch 928/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.2928e-04 - val_loss: 0.0021\n",
      "Epoch 929/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.4586e-04 - val_loss: 0.0020\n",
      "Epoch 930/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 2.6211e-04 - val_loss: 0.0018\n",
      "Epoch 931/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 2.3929e-04 - val_loss: 0.0020\n",
      "Epoch 932/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.1884e-04 - val_loss: 0.0021\n",
      "Epoch 933/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.2841e-04 - val_loss: 0.0019\n",
      "Epoch 934/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.6821e-04 - val_loss: 0.0020\n",
      "Epoch 935/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.6696e-04 - val_loss: 0.0027\n",
      "Epoch 936/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.7156e-04 - val_loss: 0.0021\n",
      "Epoch 937/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.4907e-04 - val_loss: 0.0018\n",
      "Epoch 938/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.6606e-04 - val_loss: 0.0023\n",
      "Epoch 939/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 2.6049e-04 - val_loss: 0.0024\n",
      "Epoch 940/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.6773e-04 - val_loss: 0.0030\n",
      "Epoch 941/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.7453e-04 - val_loss: 0.0019\n",
      "Epoch 942/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.4748e-04 - val_loss: 0.0020\n",
      "Epoch 943/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.6156e-04 - val_loss: 0.0027\n",
      "Epoch 944/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.6147e-04 - val_loss: 0.0029\n",
      "Epoch 945/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 2.5207e-04 - val_loss: 0.0020\n",
      "Epoch 946/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.4676e-04 - val_loss: 0.0019\n",
      "Epoch 947/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.3613e-04 - val_loss: 0.0023\n",
      "Epoch 948/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.2509e-04 - val_loss: 0.0027\n",
      "Epoch 949/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.3205e-04 - val_loss: 0.0026\n",
      "Epoch 950/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.2939e-04 - val_loss: 0.0020\n",
      "Epoch 951/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 2.4375e-04 - val_loss: 0.0022\n",
      "Epoch 952/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.3209e-04 - val_loss: 0.0023\n",
      "Epoch 953/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 2.1270e-04 - val_loss: 0.0024\n",
      "Epoch 954/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 2.1567e-04 - val_loss: 0.0026\n",
      "Epoch 955/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.2031e-04 - val_loss: 0.0028\n",
      "Epoch 956/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.1634e-04 - val_loss: 0.0026\n",
      "Epoch 957/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.2784e-04 - val_loss: 0.0029\n",
      "Epoch 958/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.4914e-04 - val_loss: 0.0026\n",
      "Epoch 959/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.3393e-04 - val_loss: 0.0025\n",
      "Epoch 960/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 2.1045e-04 - val_loss: 0.0027\n",
      "Epoch 961/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.1018e-04 - val_loss: 0.0021\n",
      "Epoch 962/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.9661e-04 - val_loss: 0.0024\n",
      "Epoch 963/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.2712e-04 - val_loss: 0.0022\n",
      "Epoch 964/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.1439e-04 - val_loss: 0.0028\n",
      "Epoch 965/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.1645e-04 - val_loss: 0.0028\n",
      "Epoch 966/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.1333e-04 - val_loss: 0.0029\n",
      "Epoch 967/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.9782e-04 - val_loss: 0.0026\n",
      "Epoch 968/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.9129e-04 - val_loss: 0.0029\n",
      "Epoch 969/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 2.0724e-04 - val_loss: 0.0025\n",
      "Epoch 970/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.1362e-04 - val_loss: 0.0028\n",
      "Epoch 971/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.0668e-04 - val_loss: 0.0033\n",
      "Epoch 972/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.1145e-04 - val_loss: 0.0027\n",
      "Epoch 973/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.3021e-04 - val_loss: 0.0029\n",
      "Epoch 974/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.2239e-04 - val_loss: 0.0025\n",
      "Epoch 975/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.3109e-04 - val_loss: 0.0029\n",
      "Epoch 976/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.1176e-04 - val_loss: 0.0030\n",
      "Epoch 977/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.3059e-04 - val_loss: 0.0026\n",
      "Epoch 978/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.1844e-04 - val_loss: 0.0032\n",
      "Epoch 979/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.1678e-04 - val_loss: 0.0026\n",
      "Epoch 980/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.1927e-04 - val_loss: 0.0028\n",
      "Epoch 981/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.0802e-04 - val_loss: 0.0027\n",
      "Epoch 982/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 2.0132e-04 - val_loss: 0.0026\n",
      "Epoch 983/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 2.2397e-04 - val_loss: 0.0027\n",
      "Epoch 984/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 2.1643e-04 - val_loss: 0.0034\n",
      "Epoch 985/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 2.1574e-04 - val_loss: 0.0031\n",
      "Epoch 986/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.0256e-04 - val_loss: 0.0028\n",
      "Epoch 987/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.9738e-04 - val_loss: 0.0024\n",
      "Epoch 988/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.1864e-04 - val_loss: 0.0031\n",
      "Epoch 989/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.1201e-04 - val_loss: 0.0030\n",
      "Epoch 990/2000\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 2.0125e-04 - val_loss: 0.0030\n",
      "Epoch 991/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.9798e-04 - val_loss: 0.0036\n",
      "Epoch 992/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 2.0813e-04 - val_loss: 0.0035\n",
      "Epoch 993/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.0801e-04 - val_loss: 0.0028\n",
      "Epoch 994/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.9872e-04 - val_loss: 0.0027\n",
      "Epoch 995/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 2.1325e-04 - val_loss: 0.0036\n",
      "Epoch 996/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.0930e-04 - val_loss: 0.0049\n",
      "Epoch 997/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.2239e-04 - val_loss: 0.0033\n",
      "Epoch 998/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 2.3938e-04 - val_loss: 0.0023\n",
      "Epoch 999/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.3074e-04 - val_loss: 0.0032\n",
      "Epoch 1000/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 2.1410e-04 - val_loss: 0.0029\n",
      "Epoch 1001/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.1524e-04 - val_loss: 0.0031\n",
      "Epoch 1002/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.4535e-04 - val_loss: 0.0028\n",
      "Epoch 1003/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.1745e-04 - val_loss: 0.0027\n",
      "Epoch 1004/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.1302e-04 - val_loss: 0.0034\n",
      "Epoch 1005/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.0667e-04 - val_loss: 0.0034\n",
      "Epoch 1006/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.0787e-04 - val_loss: 0.0033\n",
      "Epoch 1007/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.1099e-04 - val_loss: 0.0040\n",
      "Epoch 1008/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 1.9440e-04 - val_loss: 0.0036\n",
      "Epoch 1009/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8991e-04 - val_loss: 0.0032\n",
      "Epoch 1010/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 1.9024e-04 - val_loss: 0.0041\n",
      "Epoch 1011/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8828e-04 - val_loss: 0.0037\n",
      "Epoch 1012/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.8547e-04 - val_loss: 0.0037\n",
      "Epoch 1013/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.9154e-04 - val_loss: 0.0033\n",
      "Epoch 1014/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.9624e-04 - val_loss: 0.0037\n",
      "Epoch 1015/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.8902e-04 - val_loss: 0.0035\n",
      "Epoch 1016/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.9182e-04 - val_loss: 0.0036\n",
      "Epoch 1017/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.0273e-04 - val_loss: 0.0036\n",
      "Epoch 1018/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8953e-04 - val_loss: 0.0039\n",
      "Epoch 1019/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8469e-04 - val_loss: 0.0039\n",
      "Epoch 1020/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.8907e-04 - val_loss: 0.0048\n",
      "Epoch 1021/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.1717e-04 - val_loss: 0.0036\n",
      "Epoch 1022/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.0393e-04 - val_loss: 0.0027\n",
      "Epoch 1023/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.9107e-04 - val_loss: 0.0035\n",
      "Epoch 1024/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.8458e-04 - val_loss: 0.0026\n",
      "Epoch 1025/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8048e-04 - val_loss: 0.0030\n",
      "Epoch 1026/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.8036e-04 - val_loss: 0.0030\n",
      "Epoch 1027/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 1.9802e-04 - val_loss: 0.0028\n",
      "Epoch 1028/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.9677e-04 - val_loss: 0.0040\n",
      "Epoch 1029/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.8424e-04 - val_loss: 0.0031\n",
      "Epoch 1030/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.9584e-04 - val_loss: 0.0031\n",
      "Epoch 1031/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 2.1199e-04 - val_loss: 0.0028\n",
      "Epoch 1032/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.0809e-04 - val_loss: 0.0042\n",
      "Epoch 1033/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.0602e-04 - val_loss: 0.0036\n",
      "Epoch 1034/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.1053e-04 - val_loss: 0.0040\n",
      "Epoch 1035/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.9438e-04 - val_loss: 0.0029\n",
      "Epoch 1036/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 1.9057e-04 - val_loss: 0.0039\n",
      "Epoch 1037/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.9801e-04 - val_loss: 0.0041\n",
      "Epoch 1038/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.3474e-04 - val_loss: 0.0031\n",
      "Epoch 1039/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 2.4035e-04 - val_loss: 0.0040\n",
      "Epoch 1040/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.6565e-04 - val_loss: 0.0030\n",
      "Epoch 1041/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.6017e-04 - val_loss: 0.0026\n",
      "Epoch 1042/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 1.9408e-04 - val_loss: 0.0040\n",
      "Epoch 1043/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.9197e-04 - val_loss: 0.0030\n",
      "Epoch 1044/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.1489e-04 - val_loss: 0.0025\n",
      "Epoch 1045/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.1375e-04 - val_loss: 0.0038\n",
      "Epoch 1046/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.9795e-04 - val_loss: 0.0043\n",
      "Epoch 1047/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.9189e-04 - val_loss: 0.0038\n",
      "Epoch 1048/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.8503e-04 - val_loss: 0.0034\n",
      "Epoch 1049/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.6892e-04 - val_loss: 0.0032\n",
      "Epoch 1050/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.9368e-04 - val_loss: 0.0036\n",
      "Epoch 1051/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.9162e-04 - val_loss: 0.0033\n",
      "Epoch 1052/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.8186e-04 - val_loss: 0.0037\n",
      "Epoch 1053/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.7979e-04 - val_loss: 0.0033\n",
      "Epoch 1054/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.9096e-04 - val_loss: 0.0033\n",
      "Epoch 1055/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.9040e-04 - val_loss: 0.0040\n",
      "Epoch 1056/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.8403e-04 - val_loss: 0.0041\n",
      "Epoch 1057/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.8206e-04 - val_loss: 0.0035\n",
      "Epoch 1058/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.8062e-04 - val_loss: 0.0036\n",
      "Epoch 1059/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8464e-04 - val_loss: 0.0033\n",
      "Epoch 1060/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.7972e-04 - val_loss: 0.0033\n",
      "Epoch 1061/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.7657e-04 - val_loss: 0.0035\n",
      "Epoch 1062/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.8760e-04 - val_loss: 0.0035\n",
      "Epoch 1063/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.7935e-04 - val_loss: 0.0040\n",
      "Epoch 1064/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.7868e-04 - val_loss: 0.0033\n",
      "Epoch 1065/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.7374e-04 - val_loss: 0.0033\n",
      "Epoch 1066/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.7853e-04 - val_loss: 0.0035\n",
      "Epoch 1067/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8856e-04 - val_loss: 0.0029\n",
      "Epoch 1068/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8085e-04 - val_loss: 0.0031\n",
      "Epoch 1069/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.6757e-04 - val_loss: 0.0031\n",
      "Epoch 1070/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.7221e-04 - val_loss: 0.0037\n",
      "Epoch 1071/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 1.6120e-04 - val_loss: 0.0032\n",
      "Epoch 1072/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.7393e-04 - val_loss: 0.0037\n",
      "Epoch 1073/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.8107e-04 - val_loss: 0.0045\n",
      "Epoch 1074/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.4642e-04 - val_loss: 0.0045\n",
      "Epoch 1075/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 2.2919e-04 - val_loss: 0.0032\n",
      "Epoch 1076/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 2.8673e-04 - val_loss: 0.0029\n",
      "Epoch 1077/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 2.2746e-04 - val_loss: 0.0049\n",
      "Epoch 1078/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 2.0515e-04 - val_loss: 0.0035\n",
      "Epoch 1079/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.9586e-04 - val_loss: 0.0035\n",
      "Epoch 1080/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8511e-04 - val_loss: 0.0034\n",
      "Epoch 1081/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.9117e-04 - val_loss: 0.0041\n",
      "Epoch 1082/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.9679e-04 - val_loss: 0.0041\n",
      "Epoch 1083/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8192e-04 - val_loss: 0.0034\n",
      "Epoch 1084/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.6976e-04 - val_loss: 0.0042\n",
      "Epoch 1085/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.8250e-04 - val_loss: 0.0040\n",
      "Epoch 1086/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 1.9170e-04 - val_loss: 0.0043\n",
      "Epoch 1087/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 1.9298e-04 - val_loss: 0.0043\n",
      "Epoch 1088/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 1.9896e-04 - val_loss: 0.0044\n",
      "Epoch 1089/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.0391e-04 - val_loss: 0.0035\n",
      "Epoch 1090/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 2.3244e-04 - val_loss: 0.0038\n",
      "Epoch 1091/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 2.1303e-04 - val_loss: 0.0051\n",
      "Epoch 1092/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.7630e-04 - val_loss: 0.0039\n",
      "Epoch 1093/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 1.6929e-04 - val_loss: 0.0034\n",
      "Epoch 1094/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.6838e-04 - val_loss: 0.0037\n",
      "Epoch 1095/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.7898e-04 - val_loss: 0.0051\n",
      "Epoch 1096/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.7518e-04 - val_loss: 0.0040\n",
      "Epoch 1097/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.6783e-04 - val_loss: 0.0036\n",
      "Epoch 1098/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.8275e-04 - val_loss: 0.0056\n",
      "Epoch 1099/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.6626e-04 - val_loss: 0.0039\n",
      "Epoch 1100/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.7160e-04 - val_loss: 0.0036\n",
      "Epoch 1101/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.7125e-04 - val_loss: 0.0051\n",
      "Epoch 1102/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.8951e-04 - val_loss: 0.0037\n",
      "Epoch 1103/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.7435e-04 - val_loss: 0.0046\n",
      "Epoch 1104/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.9932e-04 - val_loss: 0.0050\n",
      "Epoch 1105/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.9570e-04 - val_loss: 0.0039\n",
      "Epoch 1106/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.7561e-04 - val_loss: 0.0045\n",
      "Epoch 1107/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.5375e-04 - val_loss: 0.0040\n",
      "Epoch 1108/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.5691e-04 - val_loss: 0.0039\n",
      "Epoch 1109/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.6627e-04 - val_loss: 0.0041\n",
      "Epoch 1110/2000\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 1.5990e-04 - val_loss: 0.0051\n",
      "Epoch 1111/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.6126e-04 - val_loss: 0.0039\n",
      "Epoch 1112/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 1.5325e-04 - val_loss: 0.0040\n",
      "Epoch 1113/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.5919e-04 - val_loss: 0.0042\n",
      "Epoch 1114/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.6617e-04 - val_loss: 0.0045\n",
      "Epoch 1115/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.6937e-04 - val_loss: 0.0037\n",
      "Epoch 1116/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.6358e-04 - val_loss: 0.0037\n",
      "Epoch 1117/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 1.5599e-04 - val_loss: 0.0039\n",
      "Epoch 1118/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.6330e-04 - val_loss: 0.0042\n",
      "Epoch 1119/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.6580e-04 - val_loss: 0.0040\n",
      "Epoch 1120/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.5863e-04 - val_loss: 0.0041\n",
      "Epoch 1121/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.5452e-04 - val_loss: 0.0045\n",
      "Epoch 1122/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.4626e-04 - val_loss: 0.0048\n",
      "Epoch 1123/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.5732e-04 - val_loss: 0.0041\n",
      "Epoch 1124/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.5519e-04 - val_loss: 0.0043\n",
      "Epoch 1125/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 1.5895e-04 - val_loss: 0.0042\n",
      "Epoch 1126/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.4588e-04 - val_loss: 0.0039\n",
      "Epoch 1127/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 1.4746e-04 - val_loss: 0.0036\n",
      "Epoch 1128/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.4983e-04 - val_loss: 0.0039\n",
      "Epoch 1129/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.4767e-04 - val_loss: 0.0036\n",
      "Epoch 1130/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.5416e-04 - val_loss: 0.0040\n",
      "Epoch 1131/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.5807e-04 - val_loss: 0.0035\n",
      "Epoch 1132/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.4719e-04 - val_loss: 0.0049\n",
      "Epoch 1133/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.5709e-04 - val_loss: 0.0042\n",
      "Epoch 1134/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.5645e-04 - val_loss: 0.0050\n",
      "Epoch 1135/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.7424e-04 - val_loss: 0.0037\n",
      "Epoch 1136/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.5477e-04 - val_loss: 0.0039\n",
      "Epoch 1137/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.6184e-04 - val_loss: 0.0043\n",
      "Epoch 1138/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.5406e-04 - val_loss: 0.0042\n",
      "Epoch 1139/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.7056e-04 - val_loss: 0.0035\n",
      "Epoch 1140/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.8341e-04 - val_loss: 0.0035\n",
      "Epoch 1141/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 1.6498e-04 - val_loss: 0.0028\n",
      "Epoch 1142/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.4435e-04 - val_loss: 0.0044\n",
      "Epoch 1143/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.4518e-04 - val_loss: 0.0034\n",
      "Epoch 1144/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.4796e-04 - val_loss: 0.0037\n",
      "Epoch 1145/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.7256e-04 - val_loss: 0.0032\n",
      "Epoch 1146/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.5596e-04 - val_loss: 0.0037\n",
      "Epoch 1147/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.6761e-04 - val_loss: 0.0032\n",
      "Epoch 1148/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.4474e-04 - val_loss: 0.0042\n",
      "Epoch 1149/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.5702e-04 - val_loss: 0.0042\n",
      "Epoch 1150/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.4427e-04 - val_loss: 0.0039\n",
      "Epoch 1151/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.4220e-04 - val_loss: 0.0037\n",
      "Epoch 1152/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.6811e-04 - val_loss: 0.0040\n",
      "Epoch 1153/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.6100e-04 - val_loss: 0.0033\n",
      "Epoch 1154/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.4713e-04 - val_loss: 0.0037\n",
      "Epoch 1155/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.4773e-04 - val_loss: 0.0037\n",
      "Epoch 1156/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.4409e-04 - val_loss: 0.0036\n",
      "Epoch 1157/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.6590e-04 - val_loss: 0.0042\n",
      "Epoch 1158/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.6115e-04 - val_loss: 0.0043\n",
      "Epoch 1159/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.4532e-04 - val_loss: 0.0036\n",
      "Epoch 1160/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.4443e-04 - val_loss: 0.0044\n",
      "Epoch 1161/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.5178e-04 - val_loss: 0.0035\n",
      "Epoch 1162/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.7219e-04 - val_loss: 0.0035\n",
      "Epoch 1163/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.5965e-04 - val_loss: 0.0036\n",
      "Epoch 1164/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 603us/step - loss: 1.5776e-04 - val_loss: 0.0037\n",
      "Epoch 1165/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.5132e-04 - val_loss: 0.0034\n",
      "Epoch 1166/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.5287e-04 - val_loss: 0.0032\n",
      "Epoch 1167/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.5360e-04 - val_loss: 0.0044\n",
      "Epoch 1168/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.4196e-04 - val_loss: 0.0043\n",
      "Epoch 1169/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.3761e-04 - val_loss: 0.0041\n",
      "Epoch 1170/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.4586e-04 - val_loss: 0.0038\n",
      "Epoch 1171/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.5445e-04 - val_loss: 0.0044\n",
      "Epoch 1172/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.6085e-04 - val_loss: 0.0051\n",
      "Epoch 1173/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.4788e-04 - val_loss: 0.0040\n",
      "Epoch 1174/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.5509e-04 - val_loss: 0.0035\n",
      "Epoch 1175/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.4068e-04 - val_loss: 0.0035\n",
      "Epoch 1176/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.4339e-04 - val_loss: 0.0038\n",
      "Epoch 1177/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.5070e-04 - val_loss: 0.0036\n",
      "Epoch 1178/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.5530e-04 - val_loss: 0.0038\n",
      "Epoch 1179/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 1.6100e-04 - val_loss: 0.0037\n",
      "Epoch 1180/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.5904e-04 - val_loss: 0.0046\n",
      "Epoch 1181/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.4209e-04 - val_loss: 0.0048\n",
      "Epoch 1182/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.3636e-04 - val_loss: 0.0051\n",
      "Epoch 1183/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.3334e-04 - val_loss: 0.0044\n",
      "Epoch 1184/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.3561e-04 - val_loss: 0.0045\n",
      "Epoch 1185/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.3377e-04 - val_loss: 0.0047\n",
      "Epoch 1186/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.3622e-04 - val_loss: 0.0049\n",
      "Epoch 1187/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.4285e-04 - val_loss: 0.0045\n",
      "Epoch 1188/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 1.3682e-04 - val_loss: 0.0040\n",
      "Epoch 1189/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.3515e-04 - val_loss: 0.0040\n",
      "Epoch 1190/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.3149e-04 - val_loss: 0.0040\n",
      "Epoch 1191/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.6538e-04 - val_loss: 0.0043\n",
      "Epoch 1192/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.7013e-04 - val_loss: 0.0039\n",
      "Epoch 1193/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.4659e-04 - val_loss: 0.0038\n",
      "Epoch 1194/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.5838e-04 - val_loss: 0.0041\n",
      "Epoch 1195/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.5569e-04 - val_loss: 0.0046\n",
      "Epoch 1196/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 1.4761e-04 - val_loss: 0.0044\n",
      "Epoch 1197/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.5314e-04 - val_loss: 0.0039\n",
      "Epoch 1198/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.3961e-04 - val_loss: 0.0039\n",
      "Epoch 1199/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.6905e-04 - val_loss: 0.0038\n",
      "Epoch 1200/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.8014e-04 - val_loss: 0.0035\n",
      "Epoch 1201/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.6289e-04 - val_loss: 0.0044\n",
      "Epoch 1202/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.5032e-04 - val_loss: 0.0041\n",
      "Epoch 1203/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 1.3810e-04 - val_loss: 0.0033\n",
      "Epoch 1204/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.3042e-04 - val_loss: 0.0042\n",
      "Epoch 1205/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.5002e-04 - val_loss: 0.0042\n",
      "Epoch 1206/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2858e-04 - val_loss: 0.0040\n",
      "Epoch 1207/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.4825e-04 - val_loss: 0.0043\n",
      "Epoch 1208/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.4697e-04 - val_loss: 0.0043\n",
      "Epoch 1209/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.5231e-04 - val_loss: 0.0054\n",
      "Epoch 1210/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.6677e-04 - val_loss: 0.0045\n",
      "Epoch 1211/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.7866e-04 - val_loss: 0.0033\n",
      "Epoch 1212/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.6067e-04 - val_loss: 0.0036\n",
      "Epoch 1213/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.7057e-04 - val_loss: 0.0041\n",
      "Epoch 1214/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.7445e-04 - val_loss: 0.0034\n",
      "Epoch 1215/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 1.6823e-04 - val_loss: 0.0044\n",
      "Epoch 1216/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.9406e-04 - val_loss: 0.0042\n",
      "Epoch 1217/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.7919e-04 - val_loss: 0.0032\n",
      "Epoch 1218/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 1.6727e-04 - val_loss: 0.0039\n",
      "Epoch 1219/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.4039e-04 - val_loss: 0.0037\n",
      "Epoch 1220/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.2442e-04 - val_loss: 0.0039\n",
      "Epoch 1221/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.3085e-04 - val_loss: 0.0037\n",
      "Epoch 1222/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2096e-04 - val_loss: 0.0036\n",
      "Epoch 1223/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1961e-04 - val_loss: 0.0046\n",
      "Epoch 1224/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.2461e-04 - val_loss: 0.0039\n",
      "Epoch 1225/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.2496e-04 - val_loss: 0.0040\n",
      "Epoch 1226/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.4503e-04 - val_loss: 0.0044\n",
      "Epoch 1227/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 1.5076e-04 - val_loss: 0.0038\n",
      "Epoch 1228/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.5167e-04 - val_loss: 0.0041\n",
      "Epoch 1229/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2919e-04 - val_loss: 0.0043\n",
      "Epoch 1230/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.3078e-04 - val_loss: 0.0045\n",
      "Epoch 1231/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.2689e-04 - val_loss: 0.0040\n",
      "Epoch 1232/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.3301e-04 - val_loss: 0.0037\n",
      "Epoch 1233/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 1.4110e-04 - val_loss: 0.0044\n",
      "Epoch 1234/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.5016e-04 - val_loss: 0.0038\n",
      "Epoch 1235/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.4726e-04 - val_loss: 0.0037\n",
      "Epoch 1236/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.3575e-04 - val_loss: 0.0044\n",
      "Epoch 1237/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2192e-04 - val_loss: 0.0036\n",
      "Epoch 1238/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.2124e-04 - val_loss: 0.0035\n",
      "Epoch 1239/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2387e-04 - val_loss: 0.0053\n",
      "Epoch 1240/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.3389e-04 - val_loss: 0.0038\n",
      "Epoch 1241/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.2821e-04 - val_loss: 0.0044\n",
      "Epoch 1242/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.2513e-04 - val_loss: 0.0049\n",
      "Epoch 1243/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 1.3078e-04 - val_loss: 0.0039\n",
      "Epoch 1244/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.3382e-04 - val_loss: 0.0045\n",
      "Epoch 1245/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.3172e-04 - val_loss: 0.0046\n",
      "Epoch 1246/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.2762e-04 - val_loss: 0.0036\n",
      "Epoch 1247/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 1.2793e-04 - val_loss: 0.0045\n",
      "Epoch 1248/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2585e-04 - val_loss: 0.0039\n",
      "Epoch 1249/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.3594e-04 - val_loss: 0.0044\n",
      "Epoch 1250/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.4286e-04 - val_loss: 0.0047\n",
      "Epoch 1251/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.3714e-04 - val_loss: 0.0044\n",
      "Epoch 1252/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1511e-04 - val_loss: 0.0042\n",
      "Epoch 1253/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1381e-04 - val_loss: 0.0039\n",
      "Epoch 1254/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.1454e-04 - val_loss: 0.0045\n",
      "Epoch 1255/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.1587e-04 - val_loss: 0.0045\n",
      "Epoch 1256/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.2249e-04 - val_loss: 0.0039\n",
      "Epoch 1257/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.1936e-04 - val_loss: 0.0036\n",
      "Epoch 1258/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.2614e-04 - val_loss: 0.0039\n",
      "Epoch 1259/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.2678e-04 - val_loss: 0.0038\n",
      "Epoch 1260/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1421e-04 - val_loss: 0.0037\n",
      "Epoch 1261/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 1.3050e-04 - val_loss: 0.0040\n",
      "Epoch 1262/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 1.2663e-04 - val_loss: 0.0037\n",
      "Epoch 1263/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.3374e-04 - val_loss: 0.0043\n",
      "Epoch 1264/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.1888e-04 - val_loss: 0.0041\n",
      "Epoch 1265/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.3748e-04 - val_loss: 0.0036\n",
      "Epoch 1266/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.4443e-04 - val_loss: 0.0044\n",
      "Epoch 1267/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.4681e-04 - val_loss: 0.0040\n",
      "Epoch 1268/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.2508e-04 - val_loss: 0.0037\n",
      "Epoch 1269/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.3465e-04 - val_loss: 0.0039\n",
      "Epoch 1270/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.3726e-04 - val_loss: 0.0042\n",
      "Epoch 1271/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.4643e-04 - val_loss: 0.0040\n",
      "Epoch 1272/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.5020e-04 - val_loss: 0.0033\n",
      "Epoch 1273/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.3968e-04 - val_loss: 0.0043\n",
      "Epoch 1274/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.4576e-04 - val_loss: 0.0047\n",
      "Epoch 1275/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.4361e-04 - val_loss: 0.0037\n",
      "Epoch 1276/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.3565e-04 - val_loss: 0.0037\n",
      "Epoch 1277/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.1378e-04 - val_loss: 0.0044\n",
      "Epoch 1278/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.1832e-04 - val_loss: 0.0042\n",
      "Epoch 1279/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.1382e-04 - val_loss: 0.0043\n",
      "Epoch 1280/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0706e-04 - val_loss: 0.0040\n",
      "Epoch 1281/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.1494e-04 - val_loss: 0.0042\n",
      "Epoch 1282/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.2694e-04 - val_loss: 0.0046\n",
      "Epoch 1283/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2482e-04 - val_loss: 0.0040\n",
      "Epoch 1284/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.3143e-04 - val_loss: 0.0041\n",
      "Epoch 1285/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.4846e-04 - val_loss: 0.0042\n",
      "Epoch 1286/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.3335e-04 - val_loss: 0.0038\n",
      "Epoch 1287/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.2318e-04 - val_loss: 0.0039\n",
      "Epoch 1288/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.1676e-04 - val_loss: 0.0041\n",
      "Epoch 1289/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.1571e-04 - val_loss: 0.0046\n",
      "Epoch 1290/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.3084e-04 - val_loss: 0.0045\n",
      "Epoch 1291/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.2873e-04 - val_loss: 0.0037\n",
      "Epoch 1292/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1732e-04 - val_loss: 0.0039\n",
      "Epoch 1293/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.1239e-04 - val_loss: 0.0043\n",
      "Epoch 1294/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.2831e-04 - val_loss: 0.0038\n",
      "Epoch 1295/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.2175e-04 - val_loss: 0.0038\n",
      "Epoch 1296/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.3864e-04 - val_loss: 0.0050\n",
      "Epoch 1297/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 1.4709e-04 - val_loss: 0.0041\n",
      "Epoch 1298/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.1474e-04 - val_loss: 0.0040\n",
      "Epoch 1299/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.2018e-04 - val_loss: 0.0042\n",
      "Epoch 1300/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1680e-04 - val_loss: 0.0042\n",
      "Epoch 1301/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1144e-04 - val_loss: 0.0047\n",
      "Epoch 1302/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.1578e-04 - val_loss: 0.0046\n",
      "Epoch 1303/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.2501e-04 - val_loss: 0.0047\n",
      "Epoch 1304/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.2813e-04 - val_loss: 0.0042\n",
      "Epoch 1305/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.1655e-04 - val_loss: 0.0044\n",
      "Epoch 1306/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 1.2806e-04 - val_loss: 0.0048\n",
      "Epoch 1307/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.4173e-04 - val_loss: 0.0037\n",
      "Epoch 1308/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.5696e-04 - val_loss: 0.0038\n",
      "Epoch 1309/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.4540e-04 - val_loss: 0.0042\n",
      "Epoch 1310/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.2645e-04 - val_loss: 0.0044\n",
      "Epoch 1311/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.2005e-04 - val_loss: 0.0050\n",
      "Epoch 1312/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.1377e-04 - val_loss: 0.0050\n",
      "Epoch 1313/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.0907e-04 - val_loss: 0.0050\n",
      "Epoch 1314/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.0625e-04 - val_loss: 0.0046\n",
      "Epoch 1315/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.9375e-05 - val_loss: 0.0047\n",
      "Epoch 1316/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.0754e-04 - val_loss: 0.0048\n",
      "Epoch 1317/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0535e-04 - val_loss: 0.0041\n",
      "Epoch 1318/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.1960e-04 - val_loss: 0.0044\n",
      "Epoch 1319/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2663e-04 - val_loss: 0.0042\n",
      "Epoch 1320/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.2193e-04 - val_loss: 0.0047\n",
      "Epoch 1321/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 1.4172e-04 - val_loss: 0.0050\n",
      "Epoch 1322/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.5379e-04 - val_loss: 0.0050\n",
      "Epoch 1323/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.5619e-04 - val_loss: 0.0040\n",
      "Epoch 1324/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.2618e-04 - val_loss: 0.0050\n",
      "Epoch 1325/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2689e-04 - val_loss: 0.0045\n",
      "Epoch 1326/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.1560e-04 - val_loss: 0.0043\n",
      "Epoch 1327/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.1409e-04 - val_loss: 0.0039\n",
      "Epoch 1328/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.1771e-04 - val_loss: 0.0045\n",
      "Epoch 1329/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.1135e-04 - val_loss: 0.0048\n",
      "Epoch 1330/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.2188e-04 - val_loss: 0.0045\n",
      "Epoch 1331/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.1879e-04 - val_loss: 0.0042\n",
      "Epoch 1332/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.1882e-04 - val_loss: 0.0043\n",
      "Epoch 1333/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.2638e-04 - val_loss: 0.0043\n",
      "Epoch 1334/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.1397e-04 - val_loss: 0.0037\n",
      "Epoch 1335/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 1.1210e-04 - val_loss: 0.0036\n",
      "Epoch 1336/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 1.0980e-04 - val_loss: 0.0040\n",
      "Epoch 1337/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.1905e-04 - val_loss: 0.0042\n",
      "Epoch 1338/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.2331e-04 - val_loss: 0.0050\n",
      "Epoch 1339/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.3470e-04 - val_loss: 0.0034\n",
      "Epoch 1340/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.3297e-04 - val_loss: 0.0042\n",
      "Epoch 1341/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.1741e-04 - val_loss: 0.0043\n",
      "Epoch 1342/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0695e-04 - val_loss: 0.0043\n",
      "Epoch 1343/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2567e-04 - val_loss: 0.0040\n",
      "Epoch 1344/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 1.1762e-04 - val_loss: 0.0042\n",
      "Epoch 1345/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.2087e-04 - val_loss: 0.0039\n",
      "Epoch 1346/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2811e-04 - val_loss: 0.0040\n",
      "Epoch 1347/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 1.2901e-04 - val_loss: 0.0041\n",
      "Epoch 1348/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2517e-04 - val_loss: 0.0038\n",
      "Epoch 1349/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1309e-04 - val_loss: 0.0034\n",
      "Epoch 1350/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.1352e-04 - val_loss: 0.0039\n",
      "Epoch 1351/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0856e-04 - val_loss: 0.0041\n",
      "Epoch 1352/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.1268e-04 - val_loss: 0.0042\n",
      "Epoch 1353/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0723e-04 - val_loss: 0.0045\n",
      "Epoch 1354/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0531e-04 - val_loss: 0.0041\n",
      "Epoch 1355/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0319e-04 - val_loss: 0.0040\n",
      "Epoch 1356/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.1516e-04 - val_loss: 0.0048\n",
      "Epoch 1357/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.3830e-04 - val_loss: 0.0038\n",
      "Epoch 1358/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.1389e-04 - val_loss: 0.0044\n",
      "Epoch 1359/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2234e-04 - val_loss: 0.0046\n",
      "Epoch 1360/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.4275e-04 - val_loss: 0.0035\n",
      "Epoch 1361/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.3522e-04 - val_loss: 0.0037\n",
      "Epoch 1362/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1098e-04 - val_loss: 0.0034\n",
      "Epoch 1363/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0898e-04 - val_loss: 0.0037\n",
      "Epoch 1364/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.1318e-04 - val_loss: 0.0041\n",
      "Epoch 1365/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.1196e-04 - val_loss: 0.0046\n",
      "Epoch 1366/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.1512e-04 - val_loss: 0.0045\n",
      "Epoch 1367/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0880e-04 - val_loss: 0.0044\n",
      "Epoch 1368/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.1137e-04 - val_loss: 0.0045\n",
      "Epoch 1369/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.0687e-04 - val_loss: 0.0039\n",
      "Epoch 1370/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.3216e-04 - val_loss: 0.0044\n",
      "Epoch 1371/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1526e-04 - val_loss: 0.0040\n",
      "Epoch 1372/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2770e-04 - val_loss: 0.0035\n",
      "Epoch 1373/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0880e-04 - val_loss: 0.0045\n",
      "Epoch 1374/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.9362e-05 - val_loss: 0.0044\n",
      "Epoch 1375/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0052e-04 - val_loss: 0.0049\n",
      "Epoch 1376/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.0829e-04 - val_loss: 0.0041\n",
      "Epoch 1377/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.1403e-04 - val_loss: 0.0042\n",
      "Epoch 1378/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.0704e-04 - val_loss: 0.0046\n",
      "Epoch 1379/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.0642e-04 - val_loss: 0.0044\n",
      "Epoch 1380/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0180e-04 - val_loss: 0.0036\n",
      "Epoch 1381/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0990e-04 - val_loss: 0.0041\n",
      "Epoch 1382/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.0388e-04 - val_loss: 0.0039\n",
      "Epoch 1383/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 1.1010e-04 - val_loss: 0.0041\n",
      "Epoch 1384/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0775e-04 - val_loss: 0.0043\n",
      "Epoch 1385/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.2787e-04 - val_loss: 0.0038\n",
      "Epoch 1386/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.1192e-04 - val_loss: 0.0046\n",
      "Epoch 1387/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.1844e-04 - val_loss: 0.0043\n",
      "Epoch 1388/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0738e-04 - val_loss: 0.0038\n",
      "Epoch 1389/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.0949e-04 - val_loss: 0.0039\n",
      "Epoch 1390/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.9994e-05 - val_loss: 0.0041\n",
      "Epoch 1391/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 1.0338e-04 - val_loss: 0.0041\n",
      "Epoch 1392/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0391e-04 - val_loss: 0.0043\n",
      "Epoch 1393/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1057e-04 - val_loss: 0.0040\n",
      "Epoch 1394/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.3916e-05 - val_loss: 0.0038\n",
      "Epoch 1395/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0415e-04 - val_loss: 0.0036\n",
      "Epoch 1396/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.1675e-04 - val_loss: 0.0039\n",
      "Epoch 1397/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.2768e-04 - val_loss: 0.0043\n",
      "Epoch 1398/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.4641e-05 - val_loss: 0.0041\n",
      "Epoch 1399/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.0023e-04 - val_loss: 0.0045\n",
      "Epoch 1400/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0585e-04 - val_loss: 0.0041\n",
      "Epoch 1401/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0780e-04 - val_loss: 0.0045\n",
      "Epoch 1402/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.1005e-04 - val_loss: 0.0048\n",
      "Epoch 1403/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0915e-04 - val_loss: 0.0042\n",
      "Epoch 1404/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0470e-04 - val_loss: 0.0051\n",
      "Epoch 1405/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0507e-04 - val_loss: 0.0046\n",
      "Epoch 1406/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.5341e-05 - val_loss: 0.0046\n",
      "Epoch 1407/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 9.7265e-05 - val_loss: 0.0046\n",
      "Epoch 1408/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.7066e-05 - val_loss: 0.0040\n",
      "Epoch 1409/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.0374e-04 - val_loss: 0.0040\n",
      "Epoch 1410/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 9.6405e-05 - val_loss: 0.0044\n",
      "Epoch 1411/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0084e-04 - val_loss: 0.0044\n",
      "Epoch 1412/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.2030e-05 - val_loss: 0.0045\n",
      "Epoch 1413/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.5320e-05 - val_loss: 0.0045\n",
      "Epoch 1414/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0597e-04 - val_loss: 0.0041\n",
      "Epoch 1415/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 1.0529e-04 - val_loss: 0.0039\n",
      "Epoch 1416/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 9.4497e-05 - val_loss: 0.0044\n",
      "Epoch 1417/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.6106e-05 - val_loss: 0.0039\n",
      "Epoch 1418/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.5291e-05 - val_loss: 0.0042\n",
      "Epoch 1419/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 9.0591e-05 - val_loss: 0.0049\n",
      "Epoch 1420/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.9408e-05 - val_loss: 0.0046\n",
      "Epoch 1421/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0579e-04 - val_loss: 0.0049\n",
      "Epoch 1422/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.2351e-04 - val_loss: 0.0052\n",
      "Epoch 1423/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.2051e-04 - val_loss: 0.0044\n",
      "Epoch 1424/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.0251e-04 - val_loss: 0.0043\n",
      "Epoch 1425/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0148e-04 - val_loss: 0.0044\n",
      "Epoch 1426/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0349e-04 - val_loss: 0.0040\n",
      "Epoch 1427/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0049e-04 - val_loss: 0.0041\n",
      "Epoch 1428/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.7315e-05 - val_loss: 0.0038\n",
      "Epoch 1429/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0517e-04 - val_loss: 0.0038\n",
      "Epoch 1430/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.0374e-04 - val_loss: 0.0046\n",
      "Epoch 1431/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.6596e-05 - val_loss: 0.0046\n",
      "Epoch 1432/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.8230e-05 - val_loss: 0.0045\n",
      "Epoch 1433/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.2677e-04 - val_loss: 0.0052\n",
      "Epoch 1434/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.3413e-04 - val_loss: 0.0040\n",
      "Epoch 1435/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.3942e-04 - val_loss: 0.0049\n",
      "Epoch 1436/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.0762e-04 - val_loss: 0.0048\n",
      "Epoch 1437/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.0103e-04 - val_loss: 0.0044\n",
      "Epoch 1438/2000\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 9.3291e-05 - val_loss: 0.0046\n",
      "Epoch 1439/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.1554e-04 - val_loss: 0.0044\n",
      "Epoch 1440/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.9801e-05 - val_loss: 0.0042\n",
      "Epoch 1441/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.7442e-05 - val_loss: 0.0039\n",
      "Epoch 1442/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.5072e-05 - val_loss: 0.0042\n",
      "Epoch 1443/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0349e-04 - val_loss: 0.0040\n",
      "Epoch 1444/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0777e-04 - val_loss: 0.0041\n",
      "Epoch 1445/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.1653e-04 - val_loss: 0.0047\n",
      "Epoch 1446/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.0985e-04 - val_loss: 0.0037\n",
      "Epoch 1447/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 9.7469e-05 - val_loss: 0.0042\n",
      "Epoch 1448/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0654e-04 - val_loss: 0.0045\n",
      "Epoch 1449/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.1437e-04 - val_loss: 0.0039\n",
      "Epoch 1450/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.1057e-04 - val_loss: 0.0041\n",
      "Epoch 1451/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.7106e-05 - val_loss: 0.0044\n",
      "Epoch 1452/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.8999e-05 - val_loss: 0.0043\n",
      "Epoch 1453/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 9.0426e-05 - val_loss: 0.0043\n",
      "Epoch 1454/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 9.3420e-05 - val_loss: 0.0039\n",
      "Epoch 1455/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 9.7482e-05 - val_loss: 0.0041\n",
      "Epoch 1456/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.4466e-05 - val_loss: 0.0044\n",
      "Epoch 1457/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.4364e-05 - val_loss: 0.0041\n",
      "Epoch 1458/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0370e-04 - val_loss: 0.0043\n",
      "Epoch 1459/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.1725e-05 - val_loss: 0.0043\n",
      "Epoch 1460/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 1.0178e-04 - val_loss: 0.0040\n",
      "Epoch 1461/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.2145e-04 - val_loss: 0.0043\n",
      "Epoch 1462/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.0963e-04 - val_loss: 0.0043\n",
      "Epoch 1463/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0546e-04 - val_loss: 0.0043\n",
      "Epoch 1464/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.9893e-05 - val_loss: 0.0044\n",
      "Epoch 1465/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0497e-04 - val_loss: 0.0042\n",
      "Epoch 1466/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.9538e-05 - val_loss: 0.0043\n",
      "Epoch 1467/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.3055e-04 - val_loss: 0.0044\n",
      "Epoch 1468/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.0962e-04 - val_loss: 0.0042\n",
      "Epoch 1469/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.0776e-04 - val_loss: 0.0036\n",
      "Epoch 1470/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 1.1889e-04 - val_loss: 0.0037\n",
      "Epoch 1471/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.3351e-05 - val_loss: 0.0040\n",
      "Epoch 1472/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.9447e-05 - val_loss: 0.0041\n",
      "Epoch 1473/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.0209e-05 - val_loss: 0.0041\n",
      "Epoch 1474/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.1682e-05 - val_loss: 0.0046\n",
      "Epoch 1475/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.0378e-05 - val_loss: 0.0045\n",
      "Epoch 1476/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0012e-04 - val_loss: 0.0043\n",
      "Epoch 1477/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 1.0554e-04 - val_loss: 0.0045\n",
      "Epoch 1478/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.3207e-05 - val_loss: 0.0042\n",
      "Epoch 1479/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.6475e-05 - val_loss: 0.0040\n",
      "Epoch 1480/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.2690e-05 - val_loss: 0.0044\n",
      "Epoch 1481/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.5568e-05 - val_loss: 0.0041\n",
      "Epoch 1482/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 9.3683e-05 - val_loss: 0.0041\n",
      "Epoch 1483/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.8993e-05 - val_loss: 0.0041\n",
      "Epoch 1484/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.8854e-05 - val_loss: 0.0045\n",
      "Epoch 1485/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 8.5034e-05 - val_loss: 0.0047\n",
      "Epoch 1486/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.8358e-05 - val_loss: 0.0040\n",
      "Epoch 1487/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.5516e-05 - val_loss: 0.0044\n",
      "Epoch 1488/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.2695e-05 - val_loss: 0.0049\n",
      "Epoch 1489/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.7799e-05 - val_loss: 0.0050\n",
      "Epoch 1490/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.4012e-05 - val_loss: 0.0048\n",
      "Epoch 1491/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.2709e-05 - val_loss: 0.0050\n",
      "Epoch 1492/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.7515e-05 - val_loss: 0.0044\n",
      "Epoch 1493/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.6581e-05 - val_loss: 0.0039\n",
      "Epoch 1494/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 8.9665e-05 - val_loss: 0.0043\n",
      "Epoch 1495/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.4095e-05 - val_loss: 0.0046\n",
      "Epoch 1496/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0619e-04 - val_loss: 0.0046\n",
      "Epoch 1497/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.0124e-04 - val_loss: 0.0048\n",
      "Epoch 1498/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1965e-04 - val_loss: 0.0041\n",
      "Epoch 1499/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.7099e-05 - val_loss: 0.0044\n",
      "Epoch 1500/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.9840e-05 - val_loss: 0.0041\n",
      "Epoch 1501/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.8614e-05 - val_loss: 0.0039\n",
      "Epoch 1502/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.1999e-05 - val_loss: 0.0044\n",
      "Epoch 1503/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.7671e-05 - val_loss: 0.0045\n",
      "Epoch 1504/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.4221e-05 - val_loss: 0.0040\n",
      "Epoch 1505/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.8194e-05 - val_loss: 0.0044\n",
      "Epoch 1506/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.6228e-05 - val_loss: 0.0040\n",
      "Epoch 1507/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 9.9942e-05 - val_loss: 0.0045\n",
      "Epoch 1508/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.3417e-05 - val_loss: 0.0044\n",
      "Epoch 1509/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 9.0353e-05 - val_loss: 0.0041\n",
      "Epoch 1510/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0504e-04 - val_loss: 0.0041\n",
      "Epoch 1511/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.8121e-05 - val_loss: 0.0045\n",
      "Epoch 1512/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 9.7609e-05 - val_loss: 0.0041\n",
      "Epoch 1513/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0562e-04 - val_loss: 0.0037\n",
      "Epoch 1514/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0784e-04 - val_loss: 0.0042\n",
      "Epoch 1515/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 9.7086e-05 - val_loss: 0.0045\n",
      "Epoch 1516/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.9905e-05 - val_loss: 0.0049\n",
      "Epoch 1517/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 8.8094e-05 - val_loss: 0.0043\n",
      "Epoch 1518/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.9317e-05 - val_loss: 0.0049\n",
      "Epoch 1519/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.1576e-05 - val_loss: 0.0047\n",
      "Epoch 1520/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0793e-04 - val_loss: 0.0049\n",
      "Epoch 1521/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0233e-04 - val_loss: 0.0045\n",
      "Epoch 1522/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.7010e-05 - val_loss: 0.0051\n",
      "Epoch 1523/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.2952e-05 - val_loss: 0.0044\n",
      "Epoch 1524/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.2247e-05 - val_loss: 0.0043\n",
      "Epoch 1525/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 8.4842e-05 - val_loss: 0.0047\n",
      "Epoch 1526/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.6560e-05 - val_loss: 0.0048\n",
      "Epoch 1527/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.6352e-05 - val_loss: 0.0048\n",
      "Epoch 1528/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.4655e-05 - val_loss: 0.0042\n",
      "Epoch 1529/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0545e-04 - val_loss: 0.0036\n",
      "Epoch 1530/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.1503e-05 - val_loss: 0.0040\n",
      "Epoch 1531/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.6560e-05 - val_loss: 0.0040\n",
      "Epoch 1532/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.4455e-05 - val_loss: 0.0040\n",
      "Epoch 1533/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.7296e-05 - val_loss: 0.0045\n",
      "Epoch 1534/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 7.8874e-05 - val_loss: 0.0041\n",
      "Epoch 1535/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 8.1518e-05 - val_loss: 0.0040\n",
      "Epoch 1536/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.3796e-05 - val_loss: 0.0042\n",
      "Epoch 1537/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.7637e-05 - val_loss: 0.0042\n",
      "Epoch 1538/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.2772e-05 - val_loss: 0.0048\n",
      "Epoch 1539/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0440e-04 - val_loss: 0.0049\n",
      "Epoch 1540/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 1.1742e-04 - val_loss: 0.0050\n",
      "Epoch 1541/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2901e-04 - val_loss: 0.0041\n",
      "Epoch 1542/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.1074e-04 - val_loss: 0.0049\n",
      "Epoch 1543/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.0525e-04 - val_loss: 0.0054\n",
      "Epoch 1544/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 1.1440e-04 - val_loss: 0.0043\n",
      "Epoch 1545/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.9385e-05 - val_loss: 0.0046\n",
      "Epoch 1546/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.8633e-05 - val_loss: 0.0046\n",
      "Epoch 1547/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.1765e-05 - val_loss: 0.0040\n",
      "Epoch 1548/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.5297e-05 - val_loss: 0.0045\n",
      "Epoch 1549/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.0241e-04 - val_loss: 0.0043\n",
      "Epoch 1550/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.0036e-04 - val_loss: 0.0047\n",
      "Epoch 1551/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.0177e-05 - val_loss: 0.0037\n",
      "Epoch 1552/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.5532e-05 - val_loss: 0.0041\n",
      "Epoch 1553/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 8.6013e-05 - val_loss: 0.0042\n",
      "Epoch 1554/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.7671e-05 - val_loss: 0.0047\n",
      "Epoch 1555/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.5512e-05 - val_loss: 0.0042\n",
      "Epoch 1556/2000\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 9.5306e-05 - val_loss: 0.0044\n",
      "Epoch 1557/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.1783e-05 - val_loss: 0.0042\n",
      "Epoch 1558/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.0395e-05 - val_loss: 0.0044\n",
      "Epoch 1559/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.6881e-05 - val_loss: 0.0040\n",
      "Epoch 1560/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.7787e-05 - val_loss: 0.0037\n",
      "Epoch 1561/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.1429e-05 - val_loss: 0.0038\n",
      "Epoch 1562/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.5710e-05 - val_loss: 0.0038\n",
      "Epoch 1563/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.6921e-05 - val_loss: 0.0038\n",
      "Epoch 1564/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.6061e-05 - val_loss: 0.0037\n",
      "Epoch 1565/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.9366e-05 - val_loss: 0.0036\n",
      "Epoch 1566/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 9.7079e-05 - val_loss: 0.0037\n",
      "Epoch 1567/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0018e-04 - val_loss: 0.0039\n",
      "Epoch 1568/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.1155e-04 - val_loss: 0.0037\n",
      "Epoch 1569/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.0840e-04 - val_loss: 0.0039\n",
      "Epoch 1570/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 9.3287e-05 - val_loss: 0.0037\n",
      "Epoch 1571/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 9.3087e-05 - val_loss: 0.0036\n",
      "Epoch 1572/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.9291e-05 - val_loss: 0.0040\n",
      "Epoch 1573/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.0346e-05 - val_loss: 0.0038\n",
      "Epoch 1574/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.4927e-05 - val_loss: 0.0037\n",
      "Epoch 1575/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.3446e-05 - val_loss: 0.0039\n",
      "Epoch 1576/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.8425e-05 - val_loss: 0.0039\n",
      "Epoch 1577/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.9838e-05 - val_loss: 0.0036\n",
      "Epoch 1578/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 7.7488e-05 - val_loss: 0.0040\n",
      "Epoch 1579/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.8199e-05 - val_loss: 0.0044\n",
      "Epoch 1580/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.8963e-05 - val_loss: 0.0038\n",
      "Epoch 1581/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.0400e-05 - val_loss: 0.0039\n",
      "Epoch 1582/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.3803e-05 - val_loss: 0.0040\n",
      "Epoch 1583/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 7.7042e-05 - val_loss: 0.0042\n",
      "Epoch 1584/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.8443e-05 - val_loss: 0.0041\n",
      "Epoch 1585/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 7.8014e-05 - val_loss: 0.0041\n",
      "Epoch 1586/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.5309e-05 - val_loss: 0.0041\n",
      "Epoch 1587/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 7.7549e-05 - val_loss: 0.0042\n",
      "Epoch 1588/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.0596e-05 - val_loss: 0.0040\n",
      "Epoch 1589/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.9003e-05 - val_loss: 0.0044\n",
      "Epoch 1590/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.9824e-05 - val_loss: 0.0046\n",
      "Epoch 1591/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.2377e-05 - val_loss: 0.0047\n",
      "Epoch 1592/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.7826e-05 - val_loss: 0.0047\n",
      "Epoch 1593/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.8809e-05 - val_loss: 0.0043\n",
      "Epoch 1594/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.0330e-04 - val_loss: 0.0042\n",
      "Epoch 1595/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.7358e-05 - val_loss: 0.0039\n",
      "Epoch 1596/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 593us/step - loss: 9.0379e-05 - val_loss: 0.0040\n",
      "Epoch 1597/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.7747e-05 - val_loss: 0.0041\n",
      "Epoch 1598/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.3017e-05 - val_loss: 0.0041\n",
      "Epoch 1599/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.9688e-05 - val_loss: 0.0046\n",
      "Epoch 1600/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 8.6007e-05 - val_loss: 0.0041\n",
      "Epoch 1601/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 8.8546e-05 - val_loss: 0.0049\n",
      "Epoch 1602/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.6144e-05 - val_loss: 0.0047\n",
      "Epoch 1603/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 8.7327e-05 - val_loss: 0.0043\n",
      "Epoch 1604/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 7.9670e-05 - val_loss: 0.0039\n",
      "Epoch 1605/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.4649e-05 - val_loss: 0.0044\n",
      "Epoch 1606/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 8.2754e-05 - val_loss: 0.0045\n",
      "Epoch 1607/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.5717e-05 - val_loss: 0.0040\n",
      "Epoch 1608/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 1.0553e-04 - val_loss: 0.0037\n",
      "Epoch 1609/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 9.2990e-05 - val_loss: 0.0040\n",
      "Epoch 1610/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.8651e-05 - val_loss: 0.0043\n",
      "Epoch 1611/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.1106e-05 - val_loss: 0.0041\n",
      "Epoch 1612/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.3588e-05 - val_loss: 0.0041\n",
      "Epoch 1613/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.5553e-05 - val_loss: 0.0042\n",
      "Epoch 1614/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.0484e-05 - val_loss: 0.0043\n",
      "Epoch 1615/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.6119e-05 - val_loss: 0.0043\n",
      "Epoch 1616/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.8731e-05 - val_loss: 0.0042\n",
      "Epoch 1617/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 8.1176e-05 - val_loss: 0.0043\n",
      "Epoch 1618/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 8.1554e-05 - val_loss: 0.0041\n",
      "Epoch 1619/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.7296e-05 - val_loss: 0.0042\n",
      "Epoch 1620/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.3903e-05 - val_loss: 0.0041\n",
      "Epoch 1621/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 9.8369e-05 - val_loss: 0.0043\n",
      "Epoch 1622/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.0454e-04 - val_loss: 0.0042\n",
      "Epoch 1623/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 1.2448e-04 - val_loss: 0.0039\n",
      "Epoch 1624/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.1574e-04 - val_loss: 0.0041\n",
      "Epoch 1625/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.3552e-05 - val_loss: 0.0044\n",
      "Epoch 1626/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 8.5891e-05 - val_loss: 0.0043\n",
      "Epoch 1627/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.2272e-05 - val_loss: 0.0040\n",
      "Epoch 1628/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.5596e-05 - val_loss: 0.0042\n",
      "Epoch 1629/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.6573e-05 - val_loss: 0.0044\n",
      "Epoch 1630/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 8.1302e-05 - val_loss: 0.0049\n",
      "Epoch 1631/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.1282e-05 - val_loss: 0.0045\n",
      "Epoch 1632/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.6267e-05 - val_loss: 0.0047\n",
      "Epoch 1633/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 7.6973e-05 - val_loss: 0.0044\n",
      "Epoch 1634/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 8.8659e-05 - val_loss: 0.0045\n",
      "Epoch 1635/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.6781e-05 - val_loss: 0.0043\n",
      "Epoch 1636/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.7852e-05 - val_loss: 0.0047\n",
      "Epoch 1637/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.1945e-05 - val_loss: 0.0039\n",
      "Epoch 1638/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.6898e-05 - val_loss: 0.0040\n",
      "Epoch 1639/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.2338e-05 - val_loss: 0.0041\n",
      "Epoch 1640/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 9.0607e-05 - val_loss: 0.0044\n",
      "Epoch 1641/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 8.4573e-05 - val_loss: 0.0043\n",
      "Epoch 1642/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 8.4143e-05 - val_loss: 0.0044\n",
      "Epoch 1643/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.1614e-05 - val_loss: 0.0048\n",
      "Epoch 1644/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 1.0542e-04 - val_loss: 0.0037\n",
      "Epoch 1645/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.8043e-05 - val_loss: 0.0043\n",
      "Epoch 1646/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 1.1952e-04 - val_loss: 0.0045\n",
      "Epoch 1647/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.2143e-05 - val_loss: 0.0047\n",
      "Epoch 1648/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 9.0327e-05 - val_loss: 0.0050\n",
      "Epoch 1649/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 8.4677e-05 - val_loss: 0.0049\n",
      "Epoch 1650/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.5347e-05 - val_loss: 0.0048\n",
      "Epoch 1651/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.4041e-05 - val_loss: 0.0047\n",
      "Epoch 1652/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.2454e-05 - val_loss: 0.0044\n",
      "Epoch 1653/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.7847e-05 - val_loss: 0.0043\n",
      "Epoch 1654/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.1811e-05 - val_loss: 0.0043\n",
      "Epoch 1655/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.4932e-05 - val_loss: 0.0041\n",
      "Epoch 1656/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.0611e-05 - val_loss: 0.0039\n",
      "Epoch 1657/2000\n",
      "3423/3423 [==============================] - 2s 612us/step - loss: 8.6548e-05 - val_loss: 0.0044\n",
      "Epoch 1658/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 8.4077e-05 - val_loss: 0.0043\n",
      "Epoch 1659/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.0960e-05 - val_loss: 0.0045\n",
      "Epoch 1660/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.2061e-05 - val_loss: 0.0043\n",
      "Epoch 1661/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.8318e-05 - val_loss: 0.0043\n",
      "Epoch 1662/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.3151e-05 - val_loss: 0.0040\n",
      "Epoch 1663/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 8.4021e-05 - val_loss: 0.0040\n",
      "Epoch 1664/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 8.3892e-05 - val_loss: 0.0041\n",
      "Epoch 1665/2000\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 8.2699e-05 - val_loss: 0.0040\n",
      "Epoch 1666/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.5360e-05 - val_loss: 0.0041\n",
      "Epoch 1667/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.2292e-05 - val_loss: 0.0044\n",
      "Epoch 1668/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 593us/step - loss: 7.9781e-05 - val_loss: 0.0042\n",
      "Epoch 1669/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.0029e-04 - val_loss: 0.0046\n",
      "Epoch 1670/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.3513e-05 - val_loss: 0.0039\n",
      "Epoch 1671/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.5025e-05 - val_loss: 0.0042\n",
      "Epoch 1672/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.6227e-05 - val_loss: 0.0045\n",
      "Epoch 1673/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 8.7266e-05 - val_loss: 0.0037\n",
      "Epoch 1674/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 7.7291e-05 - val_loss: 0.0036\n",
      "Epoch 1675/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 7.1427e-05 - val_loss: 0.0039\n",
      "Epoch 1676/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.6750e-05 - val_loss: 0.0041\n",
      "Epoch 1677/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 7.6948e-05 - val_loss: 0.0044\n",
      "Epoch 1678/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 9.2053e-05 - val_loss: 0.0045\n",
      "Epoch 1679/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.6782e-05 - val_loss: 0.0042\n",
      "Epoch 1680/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.7299e-05 - val_loss: 0.0048\n",
      "Epoch 1681/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 1.2190e-04 - val_loss: 0.0052\n",
      "Epoch 1682/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 1.2295e-04 - val_loss: 0.0044\n",
      "Epoch 1683/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.5650e-05 - val_loss: 0.0037\n",
      "Epoch 1684/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 7.9573e-05 - val_loss: 0.0039\n",
      "Epoch 1685/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.6971e-05 - val_loss: 0.0038\n",
      "Epoch 1686/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.4776e-05 - val_loss: 0.0036\n",
      "Epoch 1687/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.4338e-05 - val_loss: 0.0044\n",
      "Epoch 1688/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.6983e-05 - val_loss: 0.0042\n",
      "Epoch 1689/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 7.9911e-05 - val_loss: 0.0038\n",
      "Epoch 1690/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.8321e-05 - val_loss: 0.0037\n",
      "Epoch 1691/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.3002e-05 - val_loss: 0.0037\n",
      "Epoch 1692/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.3416e-05 - val_loss: 0.0038\n",
      "Epoch 1693/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 7.7402e-05 - val_loss: 0.0044\n",
      "Epoch 1694/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.1647e-05 - val_loss: 0.0043\n",
      "Epoch 1695/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.9468e-05 - val_loss: 0.0037\n",
      "Epoch 1696/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.2949e-05 - val_loss: 0.0038\n",
      "Epoch 1697/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.3626e-05 - val_loss: 0.0039\n",
      "Epoch 1698/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 7.3938e-05 - val_loss: 0.0039\n",
      "Epoch 1699/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.7246e-05 - val_loss: 0.0042\n",
      "Epoch 1700/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.0832e-05 - val_loss: 0.0039\n",
      "Epoch 1701/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 8.4558e-05 - val_loss: 0.0044\n",
      "Epoch 1702/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 8.4677e-05 - val_loss: 0.0042\n",
      "Epoch 1703/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 8.3475e-05 - val_loss: 0.0041\n",
      "Epoch 1704/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 7.4147e-05 - val_loss: 0.0043\n",
      "Epoch 1705/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 6.9845e-05 - val_loss: 0.0040\n",
      "Epoch 1706/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 6.9554e-05 - val_loss: 0.0042\n",
      "Epoch 1707/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 7.0728e-05 - val_loss: 0.0038\n",
      "Epoch 1708/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.5913e-05 - val_loss: 0.0043\n",
      "Epoch 1709/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.7579e-05 - val_loss: 0.0044\n",
      "Epoch 1710/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.1406e-05 - val_loss: 0.0044\n",
      "Epoch 1711/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 7.8130e-05 - val_loss: 0.0042\n",
      "Epoch 1712/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.6830e-05 - val_loss: 0.0046\n",
      "Epoch 1713/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 7.7114e-05 - val_loss: 0.0049\n",
      "Epoch 1714/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 8.6304e-05 - val_loss: 0.0041\n",
      "Epoch 1715/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 9.5557e-05 - val_loss: 0.0040\n",
      "Epoch 1716/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.2667e-05 - val_loss: 0.0041\n",
      "Epoch 1717/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.9164e-05 - val_loss: 0.0043\n",
      "Epoch 1718/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.7003e-05 - val_loss: 0.0043\n",
      "Epoch 1719/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.0389e-05 - val_loss: 0.0039\n",
      "Epoch 1720/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 7.3037e-05 - val_loss: 0.0042\n",
      "Epoch 1721/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.9989e-05 - val_loss: 0.0039\n",
      "Epoch 1722/2000\n",
      "3423/3423 [==============================] - 2s 591us/step - loss: 7.6085e-05 - val_loss: 0.0042\n",
      "Epoch 1723/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 7.9315e-05 - val_loss: 0.0041\n",
      "Epoch 1724/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 8.2840e-05 - val_loss: 0.0036\n",
      "Epoch 1725/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.6479e-05 - val_loss: 0.0042\n",
      "Epoch 1726/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.5757e-05 - val_loss: 0.0045\n",
      "Epoch 1727/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.8446e-05 - val_loss: 0.0045\n",
      "Epoch 1728/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.6445e-05 - val_loss: 0.0046\n",
      "Epoch 1729/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 1.0352e-04 - val_loss: 0.0045\n",
      "Epoch 1730/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 9.5402e-05 - val_loss: 0.0040\n",
      "Epoch 1731/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.7174e-05 - val_loss: 0.0043\n",
      "Epoch 1732/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 9.2735e-05 - val_loss: 0.0045\n",
      "Epoch 1733/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 7.1272e-05 - val_loss: 0.0043\n",
      "Epoch 1734/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 7.0000e-05 - val_loss: 0.0041\n",
      "Epoch 1735/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 7.3040e-05 - val_loss: 0.0041\n",
      "Epoch 1736/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.5430e-05 - val_loss: 0.0041\n",
      "Epoch 1737/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.6166e-05 - val_loss: 0.0040\n",
      "Epoch 1738/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.8334e-05 - val_loss: 0.0048\n",
      "Epoch 1739/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.1636e-05 - val_loss: 0.0046\n",
      "Epoch 1740/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.7055e-05 - val_loss: 0.0044\n",
      "Epoch 1741/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.6329e-05 - val_loss: 0.0042\n",
      "Epoch 1742/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.9006e-05 - val_loss: 0.0043\n",
      "Epoch 1743/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.8933e-05 - val_loss: 0.0045\n",
      "Epoch 1744/2000\n",
      "3423/3423 [==============================] - 2s 594us/step - loss: 8.1376e-05 - val_loss: 0.0042\n",
      "Epoch 1745/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.1919e-05 - val_loss: 0.0043\n",
      "Epoch 1746/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 7.0245e-05 - val_loss: 0.0045\n",
      "Epoch 1747/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.5698e-05 - val_loss: 0.0050\n",
      "Epoch 1748/2000\n",
      "3423/3423 [==============================] - 2s 592us/step - loss: 8.0254e-05 - val_loss: 0.0041\n",
      "Epoch 1749/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.9357e-05 - val_loss: 0.0043\n",
      "Epoch 1750/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.8361e-05 - val_loss: 0.0044\n",
      "Epoch 1751/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 7.6204e-05 - val_loss: 0.0044\n",
      "Epoch 1752/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 7.9268e-05 - val_loss: 0.0036\n",
      "Epoch 1753/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 6.7830e-05 - val_loss: 0.0046\n",
      "Epoch 1754/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.4963e-05 - val_loss: 0.0041\n",
      "Epoch 1755/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.5279e-05 - val_loss: 0.0039\n",
      "Epoch 1756/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 7.0081e-05 - val_loss: 0.0040\n",
      "Epoch 1757/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 6.8643e-05 - val_loss: 0.0040\n",
      "Epoch 1758/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 6.6761e-05 - val_loss: 0.0043\n",
      "Epoch 1759/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.9864e-05 - val_loss: 0.0044\n",
      "Epoch 1760/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.0462e-05 - val_loss: 0.0040\n",
      "Epoch 1761/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.9438e-05 - val_loss: 0.0046\n",
      "Epoch 1762/2000\n",
      "3423/3423 [==============================] - 2s 593us/step - loss: 8.3046e-05 - val_loss: 0.0048\n",
      "Epoch 1763/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.3744e-05 - val_loss: 0.0042\n",
      "Epoch 1764/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.0883e-05 - val_loss: 0.0040\n",
      "Epoch 1765/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 7.9373e-05 - val_loss: 0.0044\n",
      "Epoch 1766/2000\n",
      "3423/3423 [==============================] - 2s 595us/step - loss: 6.9309e-05 - val_loss: 0.0041\n",
      "Epoch 1767/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.9149e-05 - val_loss: 0.0045\n",
      "Epoch 1768/2000\n",
      "3423/3423 [==============================] - 2s 707us/step - loss: 6.5810e-05 - val_loss: 0.0043\n",
      "Epoch 1769/2000\n",
      "3423/3423 [==============================] - 2s 608us/step - loss: 7.1685e-05 - val_loss: 0.0044\n",
      "Epoch 1770/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 8.6596e-05 - val_loss: 0.0042\n",
      "Epoch 1771/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.8675e-05 - val_loss: 0.0044\n",
      "Epoch 1772/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.6683e-05 - val_loss: 0.0042\n",
      "Epoch 1773/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 7.6053e-05 - val_loss: 0.0047\n",
      "Epoch 1774/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.0402e-05 - val_loss: 0.0047\n",
      "Epoch 1775/2000\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 6.4454e-05 - val_loss: 0.0049\n",
      "Epoch 1776/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.6592e-05 - val_loss: 0.0044\n",
      "Epoch 1777/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.1873e-05 - val_loss: 0.0042\n",
      "Epoch 1778/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.3704e-05 - val_loss: 0.0041\n",
      "Epoch 1779/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.5587e-05 - val_loss: 0.0043\n",
      "Epoch 1780/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.1528e-05 - val_loss: 0.0045\n",
      "Epoch 1781/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 8.9930e-05 - val_loss: 0.0043\n",
      "Epoch 1782/2000\n",
      "3423/3423 [==============================] - 2s 610us/step - loss: 9.1651e-05 - val_loss: 0.0045\n",
      "Epoch 1783/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 9.0691e-05 - val_loss: 0.0048\n",
      "Epoch 1784/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 8.4036e-05 - val_loss: 0.0046\n",
      "Epoch 1785/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.3565e-05 - val_loss: 0.0043\n",
      "Epoch 1786/2000\n",
      "3423/3423 [==============================] - 2s 596us/step - loss: 7.1068e-05 - val_loss: 0.0050\n",
      "Epoch 1787/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.7378e-05 - val_loss: 0.0043\n",
      "Epoch 1788/2000\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 7.4815e-05 - val_loss: 0.0044\n",
      "Epoch 1789/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.2453e-05 - val_loss: 0.0037\n",
      "Epoch 1790/2000\n",
      "3423/3423 [==============================] - 2s 613us/step - loss: 6.8176e-05 - val_loss: 0.0045\n",
      "Epoch 1791/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 7.2123e-05 - val_loss: 0.0039\n",
      "Epoch 1792/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.5380e-05 - val_loss: 0.0046\n",
      "Epoch 1793/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 9.6607e-05 - val_loss: 0.0039\n",
      "Epoch 1794/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 8.0157e-05 - val_loss: 0.0038\n",
      "Epoch 1795/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 8.1144e-05 - val_loss: 0.0045\n",
      "Epoch 1796/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 8.8591e-05 - val_loss: 0.0041\n",
      "Epoch 1797/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.4882e-05 - val_loss: 0.0042\n",
      "Epoch 1798/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 7.6312e-05 - val_loss: 0.0042\n",
      "Epoch 1799/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 8.4892e-05 - val_loss: 0.0046\n",
      "Epoch 1800/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.2469e-05 - val_loss: 0.0040\n",
      "Epoch 1801/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.0201e-05 - val_loss: 0.0043\n",
      "Epoch 1802/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.5376e-05 - val_loss: 0.0035\n",
      "Epoch 1803/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.4690e-05 - val_loss: 0.0034\n",
      "Epoch 1804/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.3490e-05 - val_loss: 0.0038\n",
      "Epoch 1805/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 6.6263e-05 - val_loss: 0.0044\n",
      "Epoch 1806/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 6.3027e-05 - val_loss: 0.0038\n",
      "Epoch 1807/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.4458e-05 - val_loss: 0.0039\n",
      "Epoch 1808/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.2849e-05 - val_loss: 0.0042\n",
      "Epoch 1809/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 6.8149e-05 - val_loss: 0.0043\n",
      "Epoch 1810/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.4615e-05 - val_loss: 0.0041\n",
      "Epoch 1811/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 7.0522e-05 - val_loss: 0.0039\n",
      "Epoch 1812/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 601us/step - loss: 7.4927e-05 - val_loss: 0.0038\n",
      "Epoch 1813/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 7.1831e-05 - val_loss: 0.0037\n",
      "Epoch 1814/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 7.2542e-05 - val_loss: 0.0039\n",
      "Epoch 1815/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.7860e-05 - val_loss: 0.0038\n",
      "Epoch 1816/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.4017e-05 - val_loss: 0.0041\n",
      "Epoch 1817/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 8.9778e-05 - val_loss: 0.0038\n",
      "Epoch 1818/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 9.7491e-05 - val_loss: 0.0038\n",
      "Epoch 1819/2000\n",
      "3423/3423 [==============================] - 2s 608us/step - loss: 8.3145e-05 - val_loss: 0.0039\n",
      "Epoch 1820/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 7.5996e-05 - val_loss: 0.0037\n",
      "Epoch 1821/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 8.1998e-05 - val_loss: 0.0038\n",
      "Epoch 1822/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 7.5954e-05 - val_loss: 0.0041\n",
      "Epoch 1823/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.2118e-05 - val_loss: 0.0040\n",
      "Epoch 1824/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 6.4555e-05 - val_loss: 0.0042\n",
      "Epoch 1825/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.1513e-05 - val_loss: 0.0037\n",
      "Epoch 1826/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.4362e-05 - val_loss: 0.0037\n",
      "Epoch 1827/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 7.6787e-05 - val_loss: 0.0040\n",
      "Epoch 1828/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 8.4436e-05 - val_loss: 0.0040\n",
      "Epoch 1829/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 8.1983e-05 - val_loss: 0.0037\n",
      "Epoch 1830/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 8.9491e-05 - val_loss: 0.0041\n",
      "Epoch 1831/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 8.3620e-05 - val_loss: 0.0038\n",
      "Epoch 1832/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 8.4856e-05 - val_loss: 0.0040\n",
      "Epoch 1833/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 8.5618e-05 - val_loss: 0.0034\n",
      "Epoch 1834/2000\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 7.8475e-05 - val_loss: 0.0037\n",
      "Epoch 1835/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 7.5286e-05 - val_loss: 0.0038\n",
      "Epoch 1836/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 6.9031e-05 - val_loss: 0.0035\n",
      "Epoch 1837/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 7.0002e-05 - val_loss: 0.0038\n",
      "Epoch 1838/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.8884e-05 - val_loss: 0.0039\n",
      "Epoch 1839/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.4030e-05 - val_loss: 0.0043\n",
      "Epoch 1840/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.1204e-05 - val_loss: 0.0040\n",
      "Epoch 1841/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.7844e-05 - val_loss: 0.0042\n",
      "Epoch 1842/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.7322e-05 - val_loss: 0.0043\n",
      "Epoch 1843/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.7625e-05 - val_loss: 0.0038\n",
      "Epoch 1844/2000\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 7.4531e-05 - val_loss: 0.0038\n",
      "Epoch 1845/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 7.5440e-05 - val_loss: 0.0038\n",
      "Epoch 1846/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 7.5681e-05 - val_loss: 0.0040\n",
      "Epoch 1847/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.8558e-05 - val_loss: 0.0036\n",
      "Epoch 1848/2000\n",
      "3423/3423 [==============================] - 2s 609us/step - loss: 7.9591e-05 - val_loss: 0.0043\n",
      "Epoch 1849/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.6459e-05 - val_loss: 0.0042\n",
      "Epoch 1850/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.3418e-05 - val_loss: 0.0041\n",
      "Epoch 1851/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.0987e-05 - val_loss: 0.0040\n",
      "Epoch 1852/2000\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 6.4038e-05 - val_loss: 0.0041\n",
      "Epoch 1853/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.4503e-05 - val_loss: 0.0040\n",
      "Epoch 1854/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.4730e-05 - val_loss: 0.0038\n",
      "Epoch 1855/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.8653e-05 - val_loss: 0.0040\n",
      "Epoch 1856/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.1423e-05 - val_loss: 0.0039\n",
      "Epoch 1857/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.1087e-05 - val_loss: 0.0038\n",
      "Epoch 1858/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.2861e-05 - val_loss: 0.0040\n",
      "Epoch 1859/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.7477e-05 - val_loss: 0.0040\n",
      "Epoch 1860/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 7.2846e-05 - val_loss: 0.0038\n",
      "Epoch 1861/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.9056e-05 - val_loss: 0.0038\n",
      "Epoch 1862/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.2684e-05 - val_loss: 0.0044\n",
      "Epoch 1863/2000\n",
      "3423/3423 [==============================] - 2s 606us/step - loss: 6.3354e-05 - val_loss: 0.0040\n",
      "Epoch 1864/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 6.6948e-05 - val_loss: 0.0037\n",
      "Epoch 1865/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.0031e-05 - val_loss: 0.0039\n",
      "Epoch 1866/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.2451e-05 - val_loss: 0.0039\n",
      "Epoch 1867/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 5.8736e-05 - val_loss: 0.0038\n",
      "Epoch 1868/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 6.1420e-05 - val_loss: 0.0043\n",
      "Epoch 1869/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.7879e-05 - val_loss: 0.0040\n",
      "Epoch 1870/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.2212e-05 - val_loss: 0.0039\n",
      "Epoch 1871/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 5.9455e-05 - val_loss: 0.0040\n",
      "Epoch 1872/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.1586e-05 - val_loss: 0.0039\n",
      "Epoch 1873/2000\n",
      "3423/3423 [==============================] - 2s 611us/step - loss: 6.6419e-05 - val_loss: 0.0038\n",
      "Epoch 1874/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 7.7784e-05 - val_loss: 0.0039\n",
      "Epoch 1875/2000\n",
      "3423/3423 [==============================] - 2s 609us/step - loss: 9.3713e-05 - val_loss: 0.0042\n",
      "Epoch 1876/2000\n",
      "3423/3423 [==============================] - 2s 611us/step - loss: 8.2015e-05 - val_loss: 0.0047\n",
      "Epoch 1877/2000\n",
      "3423/3423 [==============================] - 2s 614us/step - loss: 7.1979e-05 - val_loss: 0.0037\n",
      "Epoch 1878/2000\n",
      "3423/3423 [==============================] - 2s 608us/step - loss: 7.3723e-05 - val_loss: 0.0039\n",
      "Epoch 1879/2000\n",
      "3423/3423 [==============================] - 2s 608us/step - loss: 7.4825e-05 - val_loss: 0.0039\n",
      "Epoch 1880/2000\n",
      "3423/3423 [==============================] - 2s 610us/step - loss: 7.0767e-05 - val_loss: 0.0040\n",
      "Epoch 1881/2000\n",
      "3423/3423 [==============================] - 2s 609us/step - loss: 6.3418e-05 - val_loss: 0.0039\n",
      "Epoch 1882/2000\n",
      "3423/3423 [==============================] - 2s 609us/step - loss: 6.0543e-05 - val_loss: 0.0038\n",
      "Epoch 1883/2000\n",
      "3423/3423 [==============================] - 2s 612us/step - loss: 6.2932e-05 - val_loss: 0.0035\n",
      "Epoch 1884/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 607us/step - loss: 6.9148e-05 - val_loss: 0.0036\n",
      "Epoch 1885/2000\n",
      "3423/3423 [==============================] - 2s 615us/step - loss: 7.0600e-05 - val_loss: 0.0033\n",
      "Epoch 1886/2000\n",
      "3423/3423 [==============================] - 2s 620us/step - loss: 6.6758e-05 - val_loss: 0.0036\n",
      "Epoch 1887/2000\n",
      "3423/3423 [==============================] - 2s 610us/step - loss: 6.0582e-05 - val_loss: 0.0036\n",
      "Epoch 1888/2000\n",
      "3423/3423 [==============================] - 2s 609us/step - loss: 6.5177e-05 - val_loss: 0.0037\n",
      "Epoch 1889/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.1936e-05 - val_loss: 0.0037\n",
      "Epoch 1890/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 5.9832e-05 - val_loss: 0.0036\n",
      "Epoch 1891/2000\n",
      "3423/3423 [==============================] - 2s 609us/step - loss: 6.3977e-05 - val_loss: 0.0035\n",
      "Epoch 1892/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.3589e-05 - val_loss: 0.0041\n",
      "Epoch 1893/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 5.9176e-05 - val_loss: 0.0038\n",
      "Epoch 1894/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.7607e-05 - val_loss: 0.0039\n",
      "Epoch 1895/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 5.9316e-05 - val_loss: 0.0038\n",
      "Epoch 1896/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.1459e-05 - val_loss: 0.0042\n",
      "Epoch 1897/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 5.7226e-05 - val_loss: 0.0039\n",
      "Epoch 1898/2000\n",
      "3423/3423 [==============================] - 2s 610us/step - loss: 6.2852e-05 - val_loss: 0.0038\n",
      "Epoch 1899/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 6.9014e-05 - val_loss: 0.0043\n",
      "Epoch 1900/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.2716e-05 - val_loss: 0.0038\n",
      "Epoch 1901/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.5372e-05 - val_loss: 0.0036\n",
      "Epoch 1902/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.9164e-05 - val_loss: 0.0038\n",
      "Epoch 1903/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.8125e-05 - val_loss: 0.0039\n",
      "Epoch 1904/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.3409e-05 - val_loss: 0.0040\n",
      "Epoch 1905/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.4310e-05 - val_loss: 0.0045\n",
      "Epoch 1906/2000\n",
      "3423/3423 [==============================] - 2s 609us/step - loss: 6.7375e-05 - val_loss: 0.0038\n",
      "Epoch 1907/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 8.8102e-05 - val_loss: 0.0039\n",
      "Epoch 1908/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 7.3191e-05 - val_loss: 0.0039\n",
      "Epoch 1909/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 7.9047e-05 - val_loss: 0.0040\n",
      "Epoch 1910/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 9.1772e-05 - val_loss: 0.0043\n",
      "Epoch 1911/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 9.0660e-05 - val_loss: 0.0044\n",
      "Epoch 1912/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 7.7565e-05 - val_loss: 0.0043\n",
      "Epoch 1913/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 7.9849e-05 - val_loss: 0.0035\n",
      "Epoch 1914/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 7.4397e-05 - val_loss: 0.0035\n",
      "Epoch 1915/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 7.2461e-05 - val_loss: 0.0037\n",
      "Epoch 1916/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.9579e-05 - val_loss: 0.0034\n",
      "Epoch 1917/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.4694e-05 - val_loss: 0.0037\n",
      "Epoch 1918/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.1514e-05 - val_loss: 0.0039\n",
      "Epoch 1919/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.8757e-05 - val_loss: 0.0037\n",
      "Epoch 1920/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 5.8710e-05 - val_loss: 0.0037\n",
      "Epoch 1921/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 6.1622e-05 - val_loss: 0.0040\n",
      "Epoch 1922/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 6.3626e-05 - val_loss: 0.0035\n",
      "Epoch 1923/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 7.3945e-05 - val_loss: 0.0038\n",
      "Epoch 1924/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 6.4663e-05 - val_loss: 0.0039\n",
      "Epoch 1925/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.7880e-05 - val_loss: 0.0038\n",
      "Epoch 1926/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 6.1820e-05 - val_loss: 0.0038\n",
      "Epoch 1927/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.8092e-05 - val_loss: 0.0038\n",
      "Epoch 1928/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.2066e-05 - val_loss: 0.0040\n",
      "Epoch 1929/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.1606e-05 - val_loss: 0.0040\n",
      "Epoch 1930/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 6.0335e-05 - val_loss: 0.0041\n",
      "Epoch 1931/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 5.9618e-05 - val_loss: 0.0042\n",
      "Epoch 1932/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 5.6791e-05 - val_loss: 0.0043\n",
      "Epoch 1933/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 5.7490e-05 - val_loss: 0.0036\n",
      "Epoch 1934/2000\n",
      "3423/3423 [==============================] - 2s 620us/step - loss: 6.0133e-05 - val_loss: 0.0037\n",
      "Epoch 1935/2000\n",
      "3423/3423 [==============================] - 2s 637us/step - loss: 5.3377e-05 - val_loss: 0.0038\n",
      "Epoch 1936/2000\n",
      "3423/3423 [==============================] - 2s 628us/step - loss: 5.3356e-05 - val_loss: 0.0037\n",
      "Epoch 1937/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 5.3323e-05 - val_loss: 0.0036\n",
      "Epoch 1938/2000\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 6.0370e-05 - val_loss: 0.0037\n",
      "Epoch 1939/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 8.0975e-05 - val_loss: 0.0036\n",
      "Epoch 1940/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 7.4845e-05 - val_loss: 0.0036\n",
      "Epoch 1941/2000\n",
      "3423/3423 [==============================] - 2s 620us/step - loss: 5.9543e-05 - val_loss: 0.0037\n",
      "Epoch 1942/2000\n",
      "3423/3423 [==============================] - 2s 635us/step - loss: 6.4609e-05 - val_loss: 0.0038\n",
      "Epoch 1943/2000\n",
      "3423/3423 [==============================] - 2s 644us/step - loss: 6.4135e-05 - val_loss: 0.0040\n",
      "Epoch 1944/2000\n",
      "3423/3423 [==============================] - 2s 619us/step - loss: 6.9224e-05 - val_loss: 0.0037\n",
      "Epoch 1945/2000\n",
      "3423/3423 [==============================] - 2s 623us/step - loss: 6.6524e-05 - val_loss: 0.0037\n",
      "Epoch 1946/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 6.2571e-05 - val_loss: 0.0037\n",
      "Epoch 1947/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 5.8970e-05 - val_loss: 0.0040\n",
      "Epoch 1948/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 5.6350e-05 - val_loss: 0.0036\n",
      "Epoch 1949/2000\n",
      "3423/3423 [==============================] - 2s 608us/step - loss: 5.5250e-05 - val_loss: 0.0035\n",
      "Epoch 1950/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 6.0713e-05 - val_loss: 0.0037\n",
      "Epoch 1951/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.6703e-05 - val_loss: 0.0037\n",
      "Epoch 1952/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 7.1069e-05 - val_loss: 0.0037\n",
      "Epoch 1953/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 7.1943e-05 - val_loss: 0.0036\n",
      "Epoch 1954/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.8438e-05 - val_loss: 0.0035\n",
      "Epoch 1955/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.5015e-05 - val_loss: 0.0038\n",
      "Epoch 1956/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3423/3423 [==============================] - 2s 599us/step - loss: 5.7534e-05 - val_loss: 0.0036\n",
      "Epoch 1957/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.0285e-05 - val_loss: 0.0036\n",
      "Epoch 1958/2000\n",
      "3423/3423 [==============================] - 2s 600us/step - loss: 5.5125e-05 - val_loss: 0.0039\n",
      "Epoch 1959/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 5.8342e-05 - val_loss: 0.0036\n",
      "Epoch 1960/2000\n",
      "3423/3423 [==============================] - 2s 608us/step - loss: 5.5145e-05 - val_loss: 0.0039\n",
      "Epoch 1961/2000\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 5.6709e-05 - val_loss: 0.0037\n",
      "Epoch 1962/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 6.6306e-05 - val_loss: 0.0038\n",
      "Epoch 1963/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 5.8676e-05 - val_loss: 0.0036\n",
      "Epoch 1964/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 5.6950e-05 - val_loss: 0.0039\n",
      "Epoch 1965/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 5.9041e-05 - val_loss: 0.0036\n",
      "Epoch 1966/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.0442e-05 - val_loss: 0.0039\n",
      "Epoch 1967/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.0910e-05 - val_loss: 0.0036\n",
      "Epoch 1968/2000\n",
      "3423/3423 [==============================] - 2s 613us/step - loss: 6.4226e-05 - val_loss: 0.0037\n",
      "Epoch 1969/2000\n",
      "3423/3423 [==============================] - 2s 615us/step - loss: 6.3863e-05 - val_loss: 0.0040\n",
      "Epoch 1970/2000\n",
      "3423/3423 [==============================] - 2s 597us/step - loss: 6.9764e-05 - val_loss: 0.0037\n",
      "Epoch 1971/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 7.1007e-05 - val_loss: 0.0038\n",
      "Epoch 1972/2000\n",
      "3423/3423 [==============================] - 2s 610us/step - loss: 6.4071e-05 - val_loss: 0.0035\n",
      "Epoch 1973/2000\n",
      "3423/3423 [==============================] - 2s 614us/step - loss: 6.1022e-05 - val_loss: 0.0036\n",
      "Epoch 1974/2000\n",
      "3423/3423 [==============================] - 2s 615us/step - loss: 5.9665e-05 - val_loss: 0.0037\n",
      "Epoch 1975/2000\n",
      "3423/3423 [==============================] - 2s 620us/step - loss: 6.5314e-05 - val_loss: 0.0037\n",
      "Epoch 1976/2000\n",
      "3423/3423 [==============================] - 2s 616us/step - loss: 5.9250e-05 - val_loss: 0.0037\n",
      "Epoch 1977/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.5165e-05 - val_loss: 0.0038\n",
      "Epoch 1978/2000\n",
      "3423/3423 [==============================] - 2s 614us/step - loss: 5.7328e-05 - val_loss: 0.0038\n",
      "Epoch 1979/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 5.6959e-05 - val_loss: 0.0037\n",
      "Epoch 1980/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 6.5513e-05 - val_loss: 0.0034\n",
      "Epoch 1981/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 5.8736e-05 - val_loss: 0.0037\n",
      "Epoch 1982/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 7.0757e-05 - val_loss: 0.0038\n",
      "Epoch 1983/2000\n",
      "3423/3423 [==============================] - 2s 608us/step - loss: 6.3844e-05 - val_loss: 0.0037\n",
      "Epoch 1984/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 5.6691e-05 - val_loss: 0.0036\n",
      "Epoch 1985/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 5.9085e-05 - val_loss: 0.0039\n",
      "Epoch 1986/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 6.6919e-05 - val_loss: 0.0034\n",
      "Epoch 1987/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 7.3445e-05 - val_loss: 0.0038\n",
      "Epoch 1988/2000\n",
      "3423/3423 [==============================] - 2s 598us/step - loss: 6.3505e-05 - val_loss: 0.0037\n",
      "Epoch 1989/2000\n",
      "3423/3423 [==============================] - 2s 607us/step - loss: 6.0021e-05 - val_loss: 0.0037\n",
      "Epoch 1990/2000\n",
      "3423/3423 [==============================] - 2s 599us/step - loss: 6.4178e-05 - val_loss: 0.0038\n",
      "Epoch 1991/2000\n",
      "3423/3423 [==============================] - 2s 604us/step - loss: 6.6982e-05 - val_loss: 0.0038\n",
      "Epoch 1992/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 5.9957e-05 - val_loss: 0.0038\n",
      "Epoch 1993/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 5.4874e-05 - val_loss: 0.0039\n",
      "Epoch 1994/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 5.5092e-05 - val_loss: 0.0035\n",
      "Epoch 1995/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 5.4556e-05 - val_loss: 0.0038\n",
      "Epoch 1996/2000\n",
      "3423/3423 [==============================] - 2s 603us/step - loss: 5.4010e-05 - val_loss: 0.0034\n",
      "Epoch 1997/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 6.0316e-05 - val_loss: 0.0034\n",
      "Epoch 1998/2000\n",
      "3423/3423 [==============================] - 2s 605us/step - loss: 5.6096e-05 - val_loss: 0.0036\n",
      "Epoch 1999/2000\n",
      "3423/3423 [==============================] - 2s 601us/step - loss: 6.2715e-05 - val_loss: 0.0034\n",
      "Epoch 2000/2000\n",
      "3423/3423 [==============================] - 2s 602us/step - loss: 6.5662e-05 - val_loss: 0.0037\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'relu',\n",
       " 'optimizer': 'adam',\n",
       " 'dropout': 0.1,\n",
       " 'full_density': True,\n",
       " 'twice': True,\n",
       " 'shuffle': True,\n",
       " 'lstmsize': 176,\n",
       " 'density': 204,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x1d5c5a84f08>]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_361 (LSTM)              (None, 92, 176)           128128    \n",
      "_________________________________________________________________\n",
      "dropout_360 (Dropout)        (None, 92, 176)           0         \n",
      "_________________________________________________________________\n",
      "lstm_362 (LSTM)              (None, 176)               248512    \n",
      "_________________________________________________________________\n",
      "dropout_361 (Dropout)        (None, 176)               0         \n",
      "_________________________________________________________________\n",
      "dense_952 (Dense)            (None, 204)               36108     \n",
      "_________________________________________________________________\n",
      "dense_953 (Dense)            (None, 102)               20910     \n",
      "_________________________________________________________________\n",
      "dense_954 (Dense)            (None, 51)                5253      \n",
      "_________________________________________________________________\n",
      "dense_955 (Dense)            (None, 25)                1300      \n",
      "_________________________________________________________________\n",
      "dense_956 (Dense)            (None, 12)                312       \n",
      "_________________________________________________________________\n",
      "dense_957 (Dense)            (None, 1)                 13        \n",
      "=================================================================\n",
      "Total params: 440,536\n",
      "Trainable params: 440,536\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_5days/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 26.45\n",
      "Medium error is 3.55\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((unscaled_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(unscaled_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 56.68%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 65.99%\n",
      "Accuracy for downward trend is: 46.71%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACdwAAAc1CAYAAACU+4XAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzde5RcB30n+G91t7pbUndLslRlvWzLNuHhYGObpx+ASZwwkAQwJgkJITieZJKQ2SSzOZM5O8lOHnsy7Mwk7OScCZPXBBzCgvOwICGEDRAbjLGBxMIxxED8kG09q2VZ6lJLXf2q/aO75BhLVlmqqlvq/nzO0Wn3rVv3ftXWH93nfvv3KzUajUYAAAAAAAAAAACAZ9VXdAAAAAAAAAAAAAA4GyjcAQAAAAAAAAAAQAsU7gAAAAAAAAAAAKAFCncAAAAAAAAAAADQAoU7AAAAAAAAAAAAaIHCHQAAAAAAAAAAALRgoOgAJzI0NJRyuVx0DAAAAAAAAAAAAJaZ8fHx1Ov1E77Wk4W7crmcXbt2FR0DAAAAAAAAAACAZWbr1q0nfc1KWQAAAAAAAAAAAGiBwh0AAAAAAAAAAAC0QOEOAAAAAAAAAAAAWqBwBwAAAAAAAAAAAC1QuAMAAAAAAAAAAIAWKNwBAAAAAAAAAABACxTuAAAAAAAAAAAAoAUKdwAAAAAAAAAAANAChTsAAAAAAAAAAABogcIdAAAAAAAAAAAAtEDhDgAAAAAAAAAAAFqgcAcAAAAAAAAAAAAtULgDAAAAAAAAAACAFijcAQAAAAAAAAAAQAsU7gAAAAAAAAAAAKAFCncAAAAAAAAAAADQAoU7AAAAAAAAAAAAaIHCHQAAAAAAAAAAALRA4Q4AAAAAAAAAAABaoHAHAAAAAAAAAAAALVC4AwAAAAAAAAAAgBYo3AEAAAAAAAAAAEALFO4AAAAAAAAAAACgBQp3AAAAAAAAAAAA0AKFOwAAAAAAAAAAAGiBwh0AAAAAAAAAAAC0QOEOAAAAAAAAAAAAWqBwBwAAAAAAAAAAAC1QuAMAAAAAAAAAAIAWKNwBAAAAAAAAAABACxTuAAAAAAAAAAAAoAUtFe5+9md/Ntu2bUupVMpXv/rV48e/+7u/O5dddlkuv/zyvPrVr85XvvKV469t27YtL3zhC3P55Zfn8ssvz6233tr+9AAAAAAAAAAAANAlA62c9La3vS2/+Iu/mGuvvfZpx//0T/80a9euTZJ89KMfzc0335x77733+Ot//ud/nhe/+MVtjAsAAAAAAAAAAADFaKlw95rXvOaEx5tluyQ5fPhw+vpsqAUAAAAAAAAAAGBpaqlw92x+9Ed/NLfffnuS5JOf/OTTXnvHO96R+fn5vPKVr8x73vOelMvlE17jve99b9773vce//zIkSNnGgsAAAAAAAAAAADaqtRoNBqtnrxt27Z8/OMfP+Ga2FtuuSW33nprPvGJTyRJHnvssZx//vmZmZnJL//yL+f+++8//tqpbN26Nbt27Wo1FgAAAAAAAAAAALTFs/XX2rYD9l3velduv/32PPHEE0mS888/P0myYsWK/PzP/3zuvPPOdt0KAAAAAAAAAAAAuu60C3cTExPZs2fP8c+3b9+e9evX55xzzsnk5GQOHTp0/LUPf/jDueKKK84sKQAAAAAAAAAAABRooJWTfuZnfiYf+9jHsm/fvlx//fUZGRnJ7bffnhtvvDHHjh1LX19fyuVyPv7xj6dUKmX//v258cYbMzc3l0ajkYsuuih//Md/3Om/CwAAAAAAAAAAAHRMqdFoNIoO8a2ebQcuAAAAAAAAAAAAdMqz9ddOe6UsAAAAAAAAAAAALCcKdwAAAAAAAAAAANAChTsAAAAAAAAAAABogcIdAAAAAAAAAAAAtEDhDgAAAAAAAAAAAFqgcAcAAAAAAAAAAAAtULgDAAAAAAAAAACAFijcAQAAAAAAAAAAQAsU7gAAAAAAAAAAAKAFCncAAAAAAAAAAADQAoU7AAAAAAAAAAAAaIHCHQAAAAAAAAAAALRA4Q4AAAAAAAAAAABaoHAHAAAAAAAAAAAALVC4AwAAAAAAAAAAgBYo3AEAAAAAAAAAAEALFO4AAAAAAAAAAACgBQp3AAAAAAAAAAAA0AKFOwAAAAAAAAAAAGiBwh0AAAAAAAAAAAC0QOEOAAAAAAAAAAAAWqBwBwAAAAAAAAAAAC1QuAMAAAAAAAAAAIAWKNwBAAAAAAAAAABACxTuAAAAAAAAAAAAoAUKdwAAAAAAAAAAANAChTsAAAAAAAAAAABogcIdAAAAAAAAAAAAtEDhDgAAAAAAAAAAAFqgcAcAAAAAAAAAAAAtULgDAAAAAAAAAACAFijcAQAAAAAAAAAAQAsU7gAAAAAAAAAAAKAFCncAAAAAAAAAAADQAoU7AAAAAAAAAAAAaIHCHQAAAAAAAAAAALRA4Q4AAAAAAAAAAABaoHAHAAAAAAAAAAAALVC4AwAAAAAAAAAAgBYo3AEAAAAAAD3r0Scm02g0io4BAAAASRTuAAAAAACAHvXA3om89r/dkQ/e82jRUQAAACCJwh0AAAAAANCjHqweSZJ8+EuPF5wEAAAAFijcAQAAAAAAPWm8Vk+yMOnugb0TBacBAAAAhTsAAAAAAKBHVRcLd0myfcfuApMAAADAAoU7AAAAAACgJ1VrU0mSjWPD2b5jd2bn5gtOBAAAwHKncAcAAAAAAPSk8Vo9qwb78/ZXnJfxWj13PfRE0ZEAAABY5hTuAAAAAACAnjReq6c8OpQbrtiSJNl+766CEwEAALDcKdwBAAAAAAA9qVqrpzI6lAvWr87LLliXT35tX47UZ4uOBQAAwDKmcAcAAAAAAPSc6dn5HJycTmV0OEny1iu3ZmpmPn9z/96CkwEAALCcKdwBAAAAAAA958CRepKkPDqUJPmeSzdlsL8v23fsLjIWAAAAy5zCHQAAAAAA0HOqtacX7tasWpHrL6nk7oefyO5Dx4qMBgAAwDKmcAcAAAAAAPSc8cXCXWWxcJckN1yxNY1G8lFT7gAAACiIwh0AAAAAANBzqrWpJEllbPj4sdc+v5xzVg9m+47daTQaRUUDAABgGVO4AwAAAAAAek514pkT7gYH+vKml2zOg9UjuX/34aKiAQAAsIwp3AEAAAAAAD2neoKVsklywxVbkiS33WutLAAAAN2ncAcAAAAAAPSc8Vo9A32lrFs1+LTjl21dk4vLq/OX9+3JzNx8Qemem//+6W/mHX94T+bmrcEFAAA42yncAQAAAAAAPWe8NpUNI0Pp6ys97XipVMpbr9yag5PT+ew3xgtK17r9E1N53+0P5a4Hn8inH9hfdBwAAADOkMIdAAAAAADQc6q1eipjQyd87S2La2W37+j9tbL/6/OPZHpxEt/773qk4DQAAACcKYU7AAAAAACgp8zPNzJeq6cyeuLC3Za1K3PVRevzqQf25/DRmS6na93hozP50D2P5vnnjuRNL9mcex4+mAf2ThQdCwAAgDOgcAcAAAAAAPSUQ8dmMjvfSPkkhbskeeuVWzI9O5+/vn9vF5M9N7fcvTOT03P56esuzs3XXrhw7As7C80EAADAmVG4AwAAAAAAekq1NpUkKY8On/ScN1y6KcMr+rJ9x65uxXpOjk7P5v13PZKt61bm+y7bnMvPW5srzl+b7Tt25+DkdNHxAAAAOE0KdwAAAAAAQE+pTtST5KQrZZNkZGggr//2jfnyzifz6BOT3YrWso986fE8eXQmP/maizLQv/A45qart6U+O5+PfPmxgtMBAABwuhTuAAAAAACAnlKtnbpwlyRvvXJrkmT7jt0dz/RcTM/O5w/ufDgbRgbz/S877/jxN166KeeODeWDdz+ambn5AhMCAABwuhTuAAAAAACAnvLUStlnL9xdc/H6lEeHsn3H7jQajW5Ea8lHv7I7ew9P5eZrL8zwiv7jx1f09+VHXnlB9h6eyt9+bX+BCQEAADhdCncAAAAAAEBPGW9OuBsbftbzBvr78pbLN+fRJ47m3see7Ea0U5qbb+R3P/tQRocG8iOvuuAZr//QK8/PYH9fPvCFRwpIBwAAwJlSuAMAAAAAAHpKc6VseeTZJ9wlT62V/Yt7e2Ot7N9+bV8eHp/MO6+6IGPDK57x+oaRobzp8s358s4n89XdhwtICAAAwJlQuAMAAAAAAHrK+EQ961atyODAqR9jvGjTWF64cTQfv29P6rNzXUh3co1GI++746EMDfTl5msvPOl5N129LUny/rt2dicYAAAAbaNwBwAAAAAA9JRqbSqV0WdfJ/sv3Xjl1kxMzebvHqh2MNWpff7BA7l/9+H84MvPy4Znmc734i1r8opt5+Sv7ttzfH0uAAAAZweFOwAAAAAAoKeM1+opj556nWzTmy/fnL5S8Wtl33f7Q+nvK+UnXn3RKc+96ZptmZ6bz4e/9FgXkgEAANAuCncAAAAAAEDPmKzPZnJ6LpXnULirjA3n2m8r545vVHNwcrqD6U5ux2NP5u6Hn8ibX7I5552z6pTnf/cl52bzmuH8yT2PZnp2vgsJAQAAaAeFOwAAAAAAoGdUF1eslsdaL9wlyY1XbsnsfCN/dd+eTsQ6pffd8VCS5Keuu7il8wf6+/LOq7alWqvnb766t5PRAAAAaCOFOwAAAAAAoGdUJ6aSJJXR4ef0vu++ZGNWD/bntnt3dSLWs/rm/lo+9U/7812XnJvnnzva8vve/vLzMryiL++/a2fnwgEAANBWCncAAAAAAEDPOD7h7jmslE2SlYP9ecOlm3LfrsN5sHqkE9FO6ncXp9u9u8Xpdk3rVg/mhiu25CuPH8qOx57sRDQAAADaTOEOAAAAAADoGeOLhbvKcyzcJclbr9ySJNm+o3tT7h4/eDQfu29Prrpofa44f91zfv+7rt6WJPnAF3a2NxgAAAAdoXAHAAAAAAD0jOoZFO5edeH6bF4znI/u2JP5+Ua7o53QH9z5cObmG3n3657bdLumF24cy1UXrc9f/+Pe7F9cpwsAAEDvUrgDAAAAAAB6RrW2UDqrjA0/5/f29ZXyliu2ZPehY/niIwfbHe0Zxmv13Prlx3PpljW59nkbTvs6P3bNtszON/Khex5tYzoAAAA6QeEOAAAAAADoGeO1elYN9mdkaOC03t9cK3vbvZ1fK/v+ux5JfXY+777u4pRKpdO+zne+6Nycd87KfOiLj6U+O9fGhAAAALSbwh0AAAAAANAzxmv1lE9jnWzT8yqjecnWNfnE/XtzbLpz5bWJqZl88O5Hc1F5dV7/7RvP6Fr9faW866pteWJyOn913942JQQAAKATFO4AAAAAAICeUa3VUzmDwl2S3HDFlkxOz+Vv/2lfm1I905/c82hq9dn81GsvTl/f6U+3a/r+l52XlSv68/67Hkmj0WhDQgAAADpB4Q4AAAAAAOgJ07PzOTg5ncro8Bld5/tesjkDfaXcdu/uNiV7uqmZufzR5x/JpjXDecvlW9pyzTUrV+TGl27J1/ZM5B8efbIt1wQAAKD9FO4AAAAAAICecOBIPUnOaKVskqwfGcp1L6jkzn8eT3Viqh3RnubP/v7xHDgynZ949UUZHGjfo5abrt6WJHn/XTvbdk0AAADaS+EOAAAAAADoCdVaewp3SfLWK7dkvpH85X17zvha/9Ls3Hx+73MPZ92qFXn7K85r67WfVxnNq79tQz75tX3Zc+hYW68NAABAeyjcAQAAAAAAPWF8sXBXaUPh7jteWMnY8ED+os1rZf/qH/dk15PH8mPXXJhVgwNtvXaS3HzNhZmbb+SD9zza9msDAABw5hTuAAAAAACAnlCtLax/rYwNn/G1hlf053su25wH9k7kgb0TZ3y9JJmfb+R/3vFQVg/2511XbWvLNb/Va59fzrb1q/LhLz2WqZm5jtwDAACA06dwBwAAAAAA9ITqRPsm3CXJjVduSZJs39GeKXef+Xo139x/JO941QVZs2pFW675rfr6SnnX1dty6OhMPvaV9k7nAwAA4Mwp3AEAAAAAAD2h2saVskny0gvW5fxzVuWjO3Znbr5xRtdqNBp53x0PZrC/L//62gvbku9k3vbSrRkZGsj779qZRuPMcgMAANBeCncAAAAAAEBPGK/VM9BXyrpVg225XqlUyg1XbEm1Vs9dDx44o2vd8/DB7HjsUG586dac24aVt89mdHhF3vbSrfn6vlruefhgR+8FAADAc6NwBwAAAAAA9ITx2lQ2jAylr6/Utmu+dXGt7G337jqj67zvjgfTV0p+6rUXtSPWKd109baUSsn773qkK/cDAACgNQp3AAAAAABAT6jW6qmMtWedbNMF61fnZResyye/ti9H6rOndY37dx3Onf98IN9z2eZcsH51W/OdzLYNq/O6F1Ty6Qf25/GDR7tyTwAAAE5N4Q4AAAAAACjc/Hwj47V6KqPtLdwlyQ1XbsnUzHw++dV9p/X+//nZB5MkP/3ai9sZ65Ruunpb5hvJB+95tKv3BQAA4OQU7gAAAAAAgMIdOjaT2flGyh0o3H3vpZsz2N93WmtlHxo/kr/56r687gXlXLJ5rO3Zns2rv21DnlcZyUe+9FiOTp/edD4AAADaS+EOAAAAAAAoXLU2lSQpjw63/dprVq3I9ZdUcvfDT2TPoWPP6b2/99mH0mgk737d89qe61RKpVLedfW2TEzN5rZ7d3f9/gAAADyTwh0AAAAAAFC46kQ9STqyUjZJbrhiaxqN5KNfab24tvfwsWzfsTsv37YuL992TkdyncqNV27J6PBAPvCFnWk0GoVkAAAA4CkKdwAAAAAAQOGqtc4W7l77/HLOWT2Y2+7d3XJx7Q8+90hm5hp593Xdn27XtGpwIG9/+Xl5sHokn3/wQGE5AAAAWKBwBwAAAAAAFK65UrYy1v6VskkyONCXN71kcx6sHsn9uw+f8vyDk9P58Jcey4s2jeW6F5Q7kqlVP3rVtvSVkg/ctbPQHAAAACjcAQAAAAAAPWB8ccJduUMT7pLkhiu2JEluu/fUa2U/8IWdOTYzl5++7uKUSqWOZWrFeeesyvUvOjd/941qdh6YLDQLAADAcqdwBwAAAAAAFK65UrY80rnC3WVb1+Ti8ur85X17MjM3f9LzjtRnc8sXduaC9avyxhdv7Fie5+Kma7al0UhuuXtn0VEAAACWNYU7AAAAAACgcOMT9axbtSKDA517dFEqlfLWK7fm4OR0PvuN8ZOe9+EvPpbDx2byk6+5OAP9vfEo5aqL1ueFG0fzZ3+/K7WpmaLjAAAALFu98VMiAAAAAACwrFVrU6mMDnf8Pm9ZXCu7fceJ18rWZ+fyh59/OJXRodz40i0dz9OqUqmUm67eliP12fzFP+wqOg4AAMCypXAHAAAAAAAUbrxWT3m0c+tkm7asXZmrLlqfTz2wP4ePPnNS3G337s7+iXp+/NUXZmigv+N5nos3X74la1etyC13P5r5+UbRcQAAAJYlhTsAAAAAAKBQk/XZTE7PpdKFwl2SvPXKLZmenc9f37/3acfn5hv5vc8+lDUrV+SHX3lBV7I8FysH+/NDrzg/jxyYzGe/efKVuAAAAHSOwh0AAAAAAFCoaq2eJCmPdadw94ZLN2V4RV+273j6atZP3L83O584mnddvS0jQwNdyfJcvfNVF6S/r5T3f2Fn0VEAAACWJYU7AAAAAACgUNWJqSRJZXS4K/cbGRrI6799Y76888k8+sRkkqTRaOR9dzyUlSv682NXb+tKjtOxee3K/Ktv35jPfXM8D1aPFB0HAABg2VG4AwAAAAAACtWccNetlbJJ8tYrtyZJtu/YnSS545vjeWDvRH7oFedn3erBruU4HTddsy1JcospdwAAAF2ncAcAAAAAABRqvLlStouFu2suXp/y6FC279i9MN3u9gezor+Un3jNhV3LcLpedsG6vHjLWP7i3l05fGym6DgAAADLisIdAAAAAABQqCIm3A309+Utl2/Oo08cze997uF8eeeTueGKLdm0ZmXXMpyuUqmUm66+MEen5/Jnf/940XEAAACWFYU7AAAAAACgUNXaVJKkMjbc1fs218r+l09+PaVS8pOvvbir9z8T33vZpqxfPZhb7t6ZuflG0XEAAACWDYU7AAAAAACgUOO1elYN9mdkaKCr933RprG8cONoGo3kDS/emIvLI129/5kYXtGfd7zy/Dx+8Fg+88D+ouMAAAAsGwp3AAAAAABAocZr9ZS7uE72X3rnVRdksL8v777ueYXc/0y841UXZKCvlA98YWfRUQAAAJaN7v6qGAAAAAAAwLeo1uq5uLy6kHv/8CvOz5tesjmjwysKuf+ZOHdsON9z2aZ87Ct78o19tbxg42jRkQAAAJY8E+4AAAAAAIDCTM/O5+DkdCqjw4Xcv1QqnZVlu6abrt6WJPnAFx4pNggAAMAyoXAHAAAAAAAU5sCRepIUtlL2bHfF+evykvPWZvuO3XlycrroOAAAAEuewh0AAAAAAFCYam2hcFcZU7g7XTdfsy1TM/P5yJcfLzoKAADAkqdwBwAAAAAAFGZ8sXBXHlG4O11vePGmjA0P5NMP7C86CgAAwJKncAcAAAAAABSmWptKklTGhgtOcvYaHOjL1nWrsn9iqugoAAAAS57CHQAAAAAAUJjqxOJK2VET7s5EeXQo47V6Go1G0VEAAACWNIU7AAAAAACgMNWawl07VEaHUp+dz8TUbNFRAAAAljSFOwAAAAAAoDDjtXoG+kpZt2qw6ChntcrYQmFxvGatLAAAQCcp3AEAAAAAAIUZr01lw8hQ+vpKRUc5q1VGh5M8NTEQAACAzlC4AwAAAAAAClOt1Y9PZ+P0lUebE+4U7gAAADpJ4Q4AAAAAACjE/Hwj47V6KqMKd2eq+TWsTijcAQAAdJLCHQAAAAAAUIhDx2YyO984Pp2N0/fUStmpgpMAAAAsbQp3AAAAAABAIZrlsPJiWYzTZ6UsAABAdyjcAQAAAAAAhWiuP7VS9sytHOzP6NBAqgp3AAAAHaVwBwAAAAAAFKJZDlO4a4/y2JDCHQAAQIcp3AEAAAAAAIVorpStjFkp2w6V0SErZQEAADpM4Q4AAAAAAChEsxxWNuGuLcqjwzl8bCZTM3NFRwEAAFiyFO4AAAAAAIBCNNeflkcU7tqhuZrXlDsAAIDOUbgDAAAAAAAKMT5Rz7pVKzI44HFFOzQLd1WFOwAAgI7xEywAAAAAAFCIam0qldHhomMsGWUT7gAAADpO4Q4AAAAAACjEeK1+vCTGmWuWF8drUwUnAQAAWLoU7gAAAAAAgK6brM9mcnru+BpUzlxlzEpZAACATlO4AwAAAAAAuq5ZCiuPKdy1S8VKWQAAgI5TuAMAAAAAALquOrGw9rS5BpUzt2bligz295lwBwAA0EEKdwAAAAAAQNc1S2FWyrZPqVRKeXQo1dpU0VEAAACWLIU7AAAAAACg65prT8sKd21VHh1KdcKEOwAAgE5RuAMAAAAAALrOhLvOKI8O5YnJ6czNN4qOAgAAsCQp3AEAAAAAAF3XXHtaGRsuOMnSUhkdytx8Iwcnp4uOAgAAsCQp3AEAAAAAAF03Xqtn1WB/RoYGio6ypFRGFwqMzUIjAAAA7aVwBwAAAAAAdN14rZ6ydbJtVxlb+JqOL67sBQAAoL0U7gAAAAAAgK6r1uqpKNy1XXlk4WtaVbgDAADoCIU7AAAAAACgq6Zn53Nwcvr4+lPax4Q7AACAzlK4AwAAAAAAuurAkYUymJWy7dcsMVYnpgpOAgAAsDQp3AEAAAAAAF3VXHfanMZG+6wfGUyplIwfMeEOAACgExTuAAAAAACArmquOy2PKNy124r+vpyzajDVCYU7AACATlC4AwAAAAAAuqpaW1h3WhkbLjjJ0lQeHTo+RRAAAID2UrgDAAAAAAC6qjl9rTJqwl0nVMaGM16rp9FoFB0FAABgyVG4AwAAAAAAuqo5fU3hrjPKI0M5NjOXI/XZoqMAAAAsOQp3AAAAAABAV43X6hnoK2XdqsGioyxJlbGFIqO1sgAAAO2ncAcAAAAAAHTVeG0qG0aG0tdXKjrKktScHNhc3QsAAED7KNwBAAAAAABdVa3Vj09ho/0qo8NJkvEjCncAAADtpnAHAAAAAAB0zfx8I+O1+vEpbLRf+fiEu6mCk/SgoweTR+4sOgUAAHAWU7gDAAAAAAC65tCxmczON1JenMJG+zXLjOM1E+6eptFIbn1ncsv3Jjs+VHQaAADgLKVwBwAAAAAAdE21tjB1rWzCXceUFe5O7J//Nnn08wv//fF/l+y+t9g8AADAWUnhDgAAAAAA6JrqxEIJzErZzlk9NJDVg/2pKtw9ZX4u+fSvJgMrk7d/eOHYre9MJg8UGgsAgKccOFLP637zjnz+n32PRm9TuAMAAAAAALqmWQJTuOusytjw8WmCJLnvw0n1n5Kr3p288I3J9743mdiV/NlNydxs0ekAAEjyj7sO5ZEDk7nzwfGio8CzUrgDAAAAAAC6plkCq4wNF5xkaSuPDplw1zRzLLn9Pycrz0mu+bmFY1f8SPLyH0923pl8+leKzQcAQJJk96GFnxX2HvKLI/Q2hTsAAAAAAKBrxhdLYGUT7jqqMjqUQ0dnUp+dKzpK8b74u8nE7uS1v5gMr3nq+Ovfk5z3quTu/5Hc/+fF5QMAIEmy99CxhY+HjxWcBJ6dwh0AAAAAANA1zalr5RGFu05qFhoPHJkuOEnBjh5M7vx/krXnJy+7+emvDQwmP3BLMrIx+di/TfbdX0xGAACSJHsWC3d7TLijxyncAQAAAAAAXTM+Uc+6VSsyOOARRSdVRhdW9lYnlvnDyjt/K6kfTr7jPyUDJyh5jm5MfuCPk/nZ5CPvWCjoAQBQiGbRbv/EVObnGwWngZPz0ywAAAAAANA11drU8TIYnVNZnHDXXOG7LD35aPKl3082vSR58Y0nP+/8VyZv+C/JoUeTv/jxZN4aXgCAIuxZXCU7O9/IgSPL+PtYep7CHQAAAAAA0DXjtXoqY9bJdlpzpWx1ORfubv/Pydx0cv2vJX2neCT2spuTK34keegzye2/0Z18AAAcNzffyL7DT01n3nN4mU9qpqcp3AEAAAAAAF0xWZ/N5PRcyvQSbL4AACAASURBVCMKd53WLDUu28LdvvuTf7w1ufg7kotfd+rzS6Xkjb+VbL5yYQ3tP/1l5zMCAHDceK2e2flG1q5akSTZe+hYwYng5BTuAAAAAACArmiWv8om3HVcc23veG2ZTgb51K8sfLz+11p/z4rh5Ac/mKzakHz0p5Pq1zuTDQCAZ9i9WLB76fnrkiR7TbijhyncAQAAAAAAXVGdWHho1iyD0TlrV67Iiv5SxpfjhLuH71hYDXvZDySbLntu712zNfmBW5KZY8mt70imDnckIgAAT7f38ELh7soL1j3tc+hFCncAAAAAAEBXNCfcVUZNuOu0vr5SNowMLb+VsvPzyaf+U9I/mLzul07vGtuuTV7/G8kTDya3/eTCNQEA6Kg9ixPurjh/7cLnJtzRwxTuAAAAAACArmhOWysr3HVFZXQo1YllVrj72m3J3vuSV/ybZN0Fp3+dV/5UcukPJN/8m+Rz/619+QAAOKE9hxYKdtvWr86GkaHsPWTCHb1L4Q4AAAAAAOgKE+66qzw6nANH6pmfbxQdpTtm68lnfj0ZWpO8+hfO7FqlUvJ9v51svDS54z3JNz7ZnowAAJzQnkPH0t9XSmV0KJvXDmefCXf0MIU7AAAAAACgK6q1hYdmlbHhgpMsD+XRoczON/Lk0emio3TH3/9RcujR5NX/Lll1zplfb3BV8oMfSlauTW77N8kTD535NQEAOKE9h49l49hwBvr7smnNcPbX6plbLr84wllH4Q4AAAAAAOiK8Vo9qwb7MzI0UHSUZaE5SbA5WXBJmzqcfPa/JqObF9bBtsu6C5K3/VEyXUs+8sNJ/Uj7rg0AwHF7Dk1l89qFX8zZtGZl5uYbx39hB3qNwh0AAAAAANAV47V6ytbJdk1lbBkV7u767eTYweR1/zFZsbK91774O5Lv/JVk/OvJx96dNExaAQBop2PTczk4OZ1Naxa+j9u0ZqF4t+eQwh29SeEOAAAAAADoimqtfnzqGp1XGV14UDm+1At3E3uSu9+XlF+UXP7DnbnHNT+XXPKW5J8+ltz13ztzDwCAZWrv4WNJks1rFwt3ix/3HVa4ozcp3AEAAAAAAB03PTufg5PTx0tgdF75+ErZJf6g8o73JLPHkut/Nenr78w9SqXkzb+zUOr7zK8nD/1dZ+4DALAMNSfZbVlcKbt5ccJds4gHvUbhDgAAAAAA6LgDRxamrFkp2z3NaYLViSU84W78G8mOP0kuuCZ5/us7e6+hkeTtH0oGR5M/vzl5cmdn7wcAsEzsObRQrGuulN1opSw9TuEOAAAAAADouOriWtPKmMJdt2wYWfhajx9ZwoW7T/9a0phPvuvXF6bQddr6i5Mb/yA5dij5yI8k00c7f08AgCVuz7eslD13bDilkgl39C6FOwAAAAAAoOPGFwt35RGFu24ZHOjLulUrMr5UJ9w9dk/yjb9OLnlzsvVl3bvv81+fXPd/JPvvT/7q55JGo3v3BgBYgpoT7rYsFu5W9PelMjqUvYdNuKM3KdwBAAAAAAAdV60tPCyrjA0XnGR5qYwOH//aLymNRvK3/2fSN5B85690//6v+ffJC96Y3P+nyRd/t/v3BwBYQvYcmsrqwf6MrRw4fmzTmpUm3NGzFO4AAAAAAICOqy5OWauMmnDXTZWxoePrfJeUr3882fWl5KU3Lax57ba+vuSG303WPy/5/34peeTO7mcAAFgi9hw6lk1rV6ZUKh0/tmnNcKq1embm5gtMBiemcAcAAAAAAHRcs/SlcNdd5dGhHJ2ey2R9tugo7TM3m3z615LBkeS1/6G4HMNrkrf/v8mKlcmf3ZQc3lVcFgCAs1Sj0ciew8eyeXGdbNOmNSvTaCT7J5bgtGbOegp3AAAAAABAx43X6hnoK2XdqsGioywr5cWC45Kacrfjj5Mn/jm5+n9LRirFZim/YGHS3dEDya3vTGY8EAYAeC6ePDqTqZn5bFk7/LTjmxc/33fY91f0noFTnwIAAAAAAHBmxmtT2TAylL6+0qlPpm0qowsPKqsTU7lww+qC07TB9GRyx/+drC4nV/3botMseNH3Ja/+heTO30o+8QvJm/5HUjrDf+eNRlKfSCb2JrU9SW1fMrEnqe1dODY5vlA4vORN7fk7AAAUZM+hY0mSzWueOeEuSfYo3NGDFO4AAAAAAICOq9bqqYxZJ9ttzRW+40eWyIS7u38nObI/eeNvJkMjRad5yut+Kdl7X7LjT5LNVyYv/9cnP3duZqFAV9u7WKLbt1Cqm9i7cKxZqpuZPPH7S/1JYy65/08V7gCAs16zcLfpW1bKblyz8Isjexdfh16icAcAAAAAAHTU/Hwj47V6vn3zWNFRlp3jK2UnlkDh7sh4ctdvJ+dcnLz0pqLTPF1ff3LjHya/f13yN/8h6R9M0viWyXSLHycPLLx2IsNrktHNyfmvTEY3LfwZ27RwbHRjMrZ5Ybrfbz5/4esBAHCWOz7h7iQrZfeacEcPUrgDAAAAAAA66tCxmczON1IeHT71ybRVc8JdtbYECnef+6/J9JHkO38n6V9RdJpnWrku+cEPJf/ru5K//JZ1t30rFspz51yUXHDNQnFudONCkW5s01PlusFVrd1rpJJMVtv/dwAA6LLmytgt3zLhrjI6nP6+0vFCHvQShTsAAAAAAKCjqrWFh2jNaWt0T2VsoeTY/H9w1nrioeTv/yjZ8rLkkjcXnebkNr44+fHPJLu+9C8m1G1OVp6T9PW17z6ry8nue9t3PQCAguxeLNQ1V8g29feVcu7oUPZNnOXfx7IkKdwBAAAAAAAd1VxnWlG467qRoYGsGuzP+Nk+4e7v/q9kfjb5rl9PSqWi0zy7cy9Z+NNJI5VkupbMHEtWrDz1+QAAPWrvoWPZMDKUoYH+Z7y2cc1wHjtowh29p42/SgMAAAAAAPBMzXWmCnfFKI8Ond2Fu93/kHxte/L8f5Vsu6boNL1hdWXh4xFrZQGAs9ueQ1PZsnb4hK9tWrsyB47UU5+d63IqeHYKdwAAAAAAQEc115k215vSXZXRoeOlx7NOo5F86leSUl9y/a8WnaZ3jJQXPk6OF5sDAOAMzMzNZ39tKpvXnnhi7+bFNbP7D5+l38uyZCncAQAAAAAAHdWcrlY24a4QldHhHJyczszcfNFRnrsHP53svDO5/IeTyouKTtM7TLgDAJaAfYen0mgkm9acuHDXPL73sLWy9BaFOwAAAAAAoKOa09XKIwp3RWgWHQ8cOcsmg8zPLUy3GxhOrvuPRafpLSOLhbtJhTsA4Oy19/DCJOzNJ1spuzjhrnke9AqFOwAAAAAAoKPGJ+pZt2pFBgc8lihCs3BXnTjLCnf/eGtS/Vryqp9O1mwpOk1vaRbujlgpCwCcvfYcWphct+UkK2U3LR7fY8IdPcZPtgAAAAAAQEdVa1OpjJ54agWdV2kW7mpnUeFuZir5u99IVq5Lrvn5otP0ntUm3AEAZ7/di4W7TScp3G1uTrg7ZMIdvUXhDgAAAAAA6KjxWj2VMetki1IZW3hQOX42Fe6+9HvJxK7kNf8+Wbm26DS9Z/WGhY9H9hebAwDgDOxdnFx3spWyG0aGMtBXslKWnqNwBwAAAAAAdMxkfTaT03MpjyjcFaX5ta/WzpIHlUcPJnf+VrLm/OTlP150mt7UvyJZeY6VsgDAWW3PoakM9vdlw+oT/6zQ11fKuWPDx4t50CsU7gAAAAAAgI5prjEtm3BXmOZ0wbNmpezn35tMHU6+45eTAf9uTmqkYqUsAHBW23PoWDatHU5fX+mk52xeO2zCHT1H4Q4AAAAAAOiY6sTCw7HK6InXRNF556wazEBf6exYKXvo8eSLv59svDS59PuLTtPbVpdNuAMAzmq7Dx3LpjXP/nPCpjUrc3ByOlMzc11KBaemcAcAAAAAAHRMc6paZdSksqL09ZWyYWTo7Jhwd/tvJHP15PpfS/o8xnpWI5WkfjiZMfEFADj71KZmUpuazea1K5/1vE1rFwp5+0y5o4f4SQUAAAAAAOiY5lS1ssJdocqjQxmf6PGHlNUHkvs+klx0XfK87yw6Te9bXVn4OGnKHQBw9mmuid1yqsLd2ELhbs/hYx3PBK1SuAMAAAAAADrGhLveUBkdyviRehqNRtFRTu4bn0jSSK7934tOcnYYKS98nKwWmwMA4DTsPrRQoNu05lQT7hZe33uox395hGVF4Q4AAAAAAOiYam3hwVhlcTIFxaiMDWVmrpFDR2eKjnJyu+9NSn3J1pcVneTs0Jxwd8SEOwDg/2fv3sPjuut733/WjKQZaW6ypBlrRopjy+RiJyROiB0BBXqhdPewD2zKpRcoodCHUtrN2QVK293yUAql3bu74ZzuA233KaW0nHICBcou3S3Qkl6gcWxHcS5YjpPYTqyZkWckeW66jKSZOX+sGYWQ2NZl1vqtkd6v58nzS2zNWl9Q8jwerc98vp2nFaBL9V/5fUKqGcjL0nAHD1lX4O4973mP9u7dK8uy9Oijj679+qte9SrdcsstOnTokF72spfp5MmTa7/3+OOP6yUveYmuv/56HTlyRKdOnWr/9AAAAAAAAAAAwNPy5ar6evwKB7pMj7KjxcN2w2CrcdCT0hNS/IDUEzI9SWcIt1bK0nAHAAA6T6bZcHfVlbLNQF5rBS3gBesK3L3hDW/Qt771LV177bXP+vXPf/7zevjhh3Xy5Em9733v09vf/va13/u5n/s5vfOd79SZM2f0gQ98QO94xzvaOzkAAAAAAAAAAPC8fLnKOlkPiDcbBluNg55TnpbKGWnkNtOTdI5Qc6VshcAdAADoPK3AXfIqgbuBvh71+H0E7uAp6wrcvfzlL9fo6Ohzfr2/v3/t74vFonw++3K5XE4TExN6y1veIkl6/etfr3Pnzun8+fNtGBkAAAAAAAAAAHSKXLmqOIE741qhx7xXG+7SE/aZut3sHJ1kreGOlbIAAKDzpAuLiga7rtqE7fNZGo4F1wJ6gBdsub/9rW99q+69915J0t///d9Lki5cuKBUKqWuLvvylmVpz549evrpp7V3797nXOPuu+/W3XffvfbPlUplq2MBAAAAAAAAAADDllfrmptf1ovHBk2PsuO1AneeXSmbaQbuRl5kdo5OQsMdAADoYNniklJXabdrScaCOj1ddngiYP3W1XB3JX/+53+uCxcu6KMf/ah++Zd/ee3XLct61tc1Go3LXuO9732vpqam1v4Kh8NbHQsAAAAAAAAAABg2U7HDXTTcmdf6HuRKHg3cpSckf0DafZPpSTpHV0AKxmi4AwAAHadebyhbXNTIOgN3qf5eFRdXtLC86vBkwPpsOXDXctddd+nee+/V7OysrrnmGk1NTWl11f4XvdFo6MKFC9qzZ0+7bgcAAAAAAAAAADyu1aaWiBK4M20tcFdeMjzJ82g07Ia74RdK/m7T03SW8G4a7gAAQMeZqVS1Umusu+FuOBaUZLfiAV6w6cBdqVRSJpNZ++cvf/nLGhwc1MDAgBKJhG677TZ99rOflSR98Ytf1N69e593nSwAAAAAAAAAANie8s3AXTxM4M60QJdf/X3da98TT7l0Xlq8JI3cbnqSzhNKSPME7gAAQGfJNINzyf7gur4+1QrcFQjcwRu61vNFv/ALv6CvfOUrmp6e1itf+UqFw2Hde++9ev3rX6/FxUX5fD7F43F99atfXVsl+8d//Md629vepo997GOKRqP6zGc+4+j/EAAAAAAAAAAA4C2tNrVEdH0P0uCseDjgzcBdZsI+UwTuNiwcl566JK0uS109pqcBAABYl0xhUZLWvVI2GbO/LlNcdGwmYCPWFbj7xCc+oU984hPP+fVjx45d9jU33HCD7rvvvs1PBgAAAAAAAAAAOlqu1FwpG6HhzgsS0YAeulA0PcZzpZuBOxruNi6UsM/5vBQbMTsLAADAOrUCd+tdKdtqwptmpSw8YtMrZQEAAAAAAAAAAK4kVyZw5yWJSFCV6qoWlldNj/JsmQelnog0eJ3pSTpPOG6frJUFAAAdJN0M3CVj62vCbjXcZWm4g0cQuAMAAAAAAAAAAI7Il6vq8lna1ceqSy9oBR89tVa2XpMyJ6XUIcnHY6sNazXcVfJm5wAAANiAbGFJPkvaHV1f4G5XX7cCXT5lCjTcwRt45wIAAAAAAAAAAByRLy9pKByQz2eZHgWS4s3AXc5LgbuZM9LKvJS6zfQknSncWilLwx0AAOgcmeKidkeD6vavL7ZkWZZS/b003MEzCNwBAAAAAAAAAABH5MpVJaKsk/WKtcBdyUOBu/SEfY7cbnaOTrXWcEfgDgAAdI5MYVGp/t4NvSYZCypbpOEO3kDgDgAAAAAAAAAAtF293lC+XF1bYwrzEhF7ZVe+7KEHlZlm4C5F4G5TwnH7nGelLAAA6AxLKzXNVJaVjK1vnWzLcCyo8tKqKtVVhyYD1o/AHdprYU469RUpf8b0JAAAAAAAAAAAgwqLK1qtNxSPbOxBGpzjyZWy6Qmpb1Dq32N6ks5Ewx0AAOgw082WupENNtylYvbXZwuslYV5BO7QXnNnpc+/VTr9VdOTAAAAAAAAAAAMyjVb1OI03HlGa72vZwJ3q8vSxUftdjvLMj1NZ+oOSoGoNE/gDgAAdIZMMzC34ZWy/fYHeTKslYUHELhDe8VG7bOUNjsHAAAAAAAAAMCoXMkOdbFS1jsigS4Fu33KeyVwd/FRqbYsjbBOdktCcanCSlkAANAZ0s3A3UZXyrYa7qaLNNzBPAJ3aK9QQvJ1S0UCdwAAAAAAAACwk7Va1AjceYdlWUpEgt5puMtM2GeKwN2WhBM03AEAgI6RbTbUbbThbrgZ0MsUaLiDeQTu0F4+nxRNSqUp05MAAAAAAAAAAAxqrZRNRDfWXAFnxSMB5cseeUiZftA+abjbmlBcWpiTaqumJwEAALiq1krZkQ0G7loNd1ka7uABBO7QftFRGu4AAAAAAAAAYIfL03DnSYlIQLPzy1qt1U2PYjfcRUfthjZsXjghqSEtzJieBAAA4KrShUX1dvvV39e9oddFe7vU1+Nfa8gDTCJwh/aLjUiLc9LygulJAAAAAAAAAACGtNaWDoUJ3HlJIhJQoyHNzi+bHaRakfKnpZHbzM6xHYR322eFtbIAAMD7MoVFJfuDsixrQ6+zLEvJWHCtIQ8wicAd2i86Yp8lWu4AAAAAAAAAYKfKl6ra1detni4eRXhJvNk4mCtVzQ6SfUhq1KUU62S3LBS3z3kCdwAAwNsajYayxaUNr5NtScZ6lS0uqdFotHkyYGN4l4v2i43aZ3HK7BwAAAAAAAAAAGNy5SUlIkHTY+B7tL4nubLhVVyZCfscIXC3Za2VvDTcAQAAjysurmhhuaZUbLOBu6AWlmsqLa22eTJgYwjcof1agTsa7gAAAAAAAABgx8qXq0pEWSfrNfHm9yRfNtxwl24G7pKHzM6xHYQI3AEAgM6Qbq6DTW224a75umyRtbIwi8Ad2q+1UrZI4A4AAAAAAAAAdqL56qrml2uKhwnceU2itVLWdOAuMyENvkDq7Tc7x3YQbq2UzZudAwAA4CqyBbtlOdm/uSbsVCz4rOsAphC4Q/utNdyxUhYAAAAAAAAAdqJWmCtOw53nxNcCdwYfUi7MSZfOSyMvMjfDdkLDHQAA6BCZZjPdyCYb7oZbgbsigTuYReAO7de7S+rqlYoE7gAAAAAAAABgJ8qV7AdgicjmmivgnMFQQD5LypUMNtxlmutkU7ebm2E76emTesLSPIE7AADgbVtdKZtipSw8gsAd2s+ypNgIK2UBAAAAAAAAYIdqNdy11pfCO/w+S0PhgPIVg4G79IP2OULgrm1CcanCSlkAAOBtmdZK2djmPpjTel2GlbIwjMAdnBEblUppqdEwPQkAAAAAAAAAwGX51kpZAneeFI8EzDfc+bqk4Ream2G7CSdouAMAAJ6XLSxqMNSjYLd/U6+PBLsVCXTRcAfjCNzBGdFRabkiLRVNTwIAAAAAAAAAcBkNd96WiASUL1fVMPWh+fSElDggdW9ulRieRyguLcxK9ZrpSQAAAC4rU1jc9DrZluFYUNNFGu5gFoE7OCM2Yp8l1soCAAAAAAAAwE6TK9sPwBLRza2KgrMSkaCWa3WVFlfdv3kpI1WmpRTrZNsqnJAadTt0BwAA4EGrtbqmS0tK9W/tPUKyv1eZ4qK5D48AInAHp0SbgbsigTsAAAAAAAAA2Gny5ar6evwKB7pMj4LnkYjazYOtYKSr0hP2OULgrq1CCfussFYWAAB4U65cVb0hJWNba7hLxYJaWqmrsLDSpsmAjSNwB2e0Gu6KF8zOAQAAAAAAAABwXb5cZZ2sh8UjrcBd1f2bZ5qBOxru2isct895AncAAMCbMoVFSdLIFlfKtgJ7meLilmcCNovAHZwRHbVPVsoCAAAAAAAAwI6TK1fXQl3wnkTEcMNdV1BKHHD/3tvZWsNd3uwcAAAAl5FuBu5SWw7c2Stpp4sG/iwLNBG4gzNirJQFAAAAAAAAgJ1oebWuufllJSJB06PgMuLN703e7Ya7RkPKPCgN3yL5u92993YXbgbuaLgDAAAelSnYAblk/9beJ7RenyFwB4MI3MEZgYgUjNFwBwAAAAAAAAA7zEzFDnHRcOddaw13JZcDd3NnpaWCNMI62bYLNVfKVgjcAQAAb8oW27tSNltgpSzMIXAH50RHpeKU6SkAAAAAAAAAAC7KNVvTElECd14VX1sp63LgLvOgfaYI3LVdeLd9zrNSFgAAeFOmsKhuv6V4eGvvE1orZbM03MEgAndwTmxEKmWket30JAAAAAAAAAAAl7TWlG71QRqcE+z2Kxrscn+lbHrCPmm4a79AWOrukyoXTU8CAADwvNKFJQ3HgvL5rC1dJxToUjTYtdaYB5hA4A7OiY5Itaq0MGN6EgAAAAAAAACAS3Jlu2kiEQ0angRXkogG175XrslMSIGoNLDf3fvuFKG4VKHhDgAAeFO2uLi2DnarUv29NNzBKAJ3cE5sxD5ZKwsAAAAAAAAAO0au1FwpG6Hhzsvi4YC7K2Vrq1L2ISl1SPLxeMoR4YQ0nzM9BQAAwHPMV1dVWFjRSH97AnfJWFDZ4pIajUZbrgdsFO9o4JzYNfZZSpudAwAAAAAAAADgmlaIi8CdtyWiAZWXVrW0UnPnhjOPSSsLUop1so4JJaT5GaleNz0JAADAs7TWv6b629OCnezv1fJqXbPzy225Xrv95f1P68N/8x1VqqumR4FDCNzBOdFWwx2BOwAAAAAAAADYKfLlqrp8lnb19ZgeBVfQCkTm3Wq5S0/Y5wiBO8eE41KjJi3OmZ4EAADgWdIFe/1ru1bKJqN2cG/ao2tl/+7RrD537Gn1dvtNjwKHELiDc1orZUuslAUAAAAAAACAnSJfXtJQOCCfzzI9Cq4gEbEfUubKLj2kzDQDdzTcOSeUsM8Ka2UBAIC3ZAt2w13bVso2r5NpXtdrJrMl3TAclZ/3RNsWgTs4h4Y7AAAAAAAAANhxcuWqElHWyXpdvNlwlyu51XD3gBSKS7FRd+63E4Wbgbt5AncAAMBbWsG4VJsCd6mY/eGRrAcb7nLlJc1UlnUwGTE9ChxE4A7O6QrYb56LNNwBAAAAAAAAwE5QrzeUL1fX1pXCu9ZWylZcCNytLEkXv2O321m0fDgmFLfPSt7sHAAAAN+jtVI21R9sy/XWGu6K3mu4m8yWJUkHklHDk8BJBO7grOiIVKLhDgAAAAAAAAB2gsLiilbrDcUj7XmQBue0Wghdabi7+KhUX5VGWCfrKBruAACAR2WLi4oEuhQJdrflesNR+/3GtAcb7k5lSpKkgwTutjUCd3BWbFQqZ6XaqulJAAAAAAAAAAAOy5XtB15xGu48Lx62H1K2vmeOSk/Y58iLnL/XThZqBu4qBO4AAIC3ZAqLbVsnK0m9PX7t6utWtuC9wN1k1g7c3UjgblsjcAdnxUalRl2qTJueBAAAAAAAAADgsFZbGitlvS/a26WeLp9yZRca7jLNwF2KhjtHhZsrZedZKQsAALyjXm8oU1xq2zrZlmSs16MrZUvaM9CncKDL9ChwEIE7OCs6Yp9F1soCAAAAAAAAwHbXCm8RuPM+y7KUiASUdyNwl56Q+vdIoUHn77WTBaKSP0DDHQAA8JTZ+WUtr9bb2nAnSan+oC6WllSvN9p63a1YWqnp7My8DiQjpkeBwwjcwVmxZuCuNGV2DgAAAAAdqbpa072P5dRoeOeHJgAAALi81nrSRLS97RVwRiIScL7hrlqWZs7QbucGy5LCCWmewB0AAPCObLOFrt2Bu+FYUCu1hmbmXfgAyTqduVhWrd7QwWTM9ChwGIE7OCs6ap803AEAAADYhA/+9aP6mU8f1zdP88AIAACgE+RpuOso8UhAs5Wqak62gmROSmpIIwTuXBGKSxVWygIAAO/IFFqBu/avlJWkbGGprdfdislsSZJouNsBCNzBWa2GuyINdwAAAAA25mvfmdbnT9jvJb79xKzhaQAAALAerba0oTCBu06QiARVb0izTraCZCbsk4Y7d4R3S/N5qV43PQkAAIAkKd0MxKVi7V8pKz3ToOcFk9myJOlAMmp4EjiNwB2cFR6WLJ9UouEOAAAAwPrly1X92pceUay3W/193Tp6lsAdAABAJ8iXqtrV162eLh4/dIJWE2Gu5GDgLj0hyZJSh5y7B54Rjkv1FWmpYHoSAAAASVK24MxK2VbDXcZDDXenMiVFgl0a3dXe/63wHt7xwln+LimSouEOAAAAwLo1Gg396hcf1tz8sj72uhfqpS8Y0uR0SYWFZdOjAQAA4Cpy5SUlIu1dFQXnxJuBu9YqYEdkJqSh66UAa7VcEUrYZyVndg4AAICmTHFRliXtjrZ7pax9vemSNwJ3jUZDk9MlHUhGZVmW6XHgMAJ3cF5shIY7AAAAAOv2/x2/oH88ndPrbhvRq29JoXx4ogAAIABJREFUanxsUI2GdOzcnOnRAAAAcBX5clWJKOtkO0Xre5UrO/SQcn5GKjwtjbBO1jXhZuBunsAdAADwhnRhSYlIoO0t2MPNwF2m4I2VslOXFlVeWtVB1snuCATu4LzoiDSfl1Yd/IQcAAAAgG3hqdl5feSrp5SKBfWbr7lJkvTisQFJ0tGzBO4AAAC8bL66qvnlmuJhAnedotVG6FjDXeZB+0wRuHNNKG6fNNwBAACPyBQW275OVpICXX4NhXuULXqj4W4yW5IkHUjS7LwTELiD82Ij9knLHQAAAIArWK3V9Uv3nNTCck3/7U23KtbbLUnaHw9rKNyjo2dnDU8IAACAK8k1Q1txGu46RiLSarhzKHCXnrBPGu7cs9Zwlzc7BwAAgKTqak35clWpWPsDd5KUjPUq65GGu1PNwN3BZMzwJHADgTs4Lzpqn8Ups3MAAAAA8LQ//pezmni6oJ/9vn16yf6htV+3LEt3jg1qcrqkwsKywQkBAABwJbmS3SzRak2D9w2EemRZUq7kVMPdhOTrknbf7Mz18VyhZuCOhjsAAOABF4v2nzNT/c68RxiOBXWxXFWt3nDk+hsxmS3J77N03e6w6VHgAgJ3cF6r4a5Iwx0AAACA5/douqiPf+OMrt8d1vt/5Ibn/P742KAaDenYOdbKAgAAeFWrJa3Vmgbv6/L7NBgKKF9xIHDXaNgNd7tvkroJYbom3FwpO0/gDgAAmJduts85sVJWklKxoGr1hvJONTZvwGS2rLGhkILdftOjwAUE7uC8WLPhrkTDHQAAAIDnWlqp6T/dc1KWJX38xw897w8kXjw2IEk6epbAHQAAgFflCdx1pEQkoFx5qf0XLqXt0FeKdbKuCvZL/h6pwkpZAABgXqYZuEs6tVK2GeTLFM2ulS0vrejpuQUdSEaNzgH3ELiD89ZWytJwBwAAAOC5/svfn9YTuYre+8M36KZU7Hm/Zn88rKFwQEfPzro8HQAAANar1XAXJ3DXUeKRgHKlqhqNNq/hSk/Y5wiBO1dZlhSK03AHAAA8IdsMwo041HCXjNlNytmCAx8g2YDT02VJ0sEUgbudgsAdnBcakvwB+9NsAAAAAPBdvvX4jD797fM6vHeX3vnysct+nWVZGh8b0OR0SYWFZRcnBAAAwHq1WtISUdaHdpJEJKDqal2lpdX2XjjTDNzRcOe+UJyGOwAA4AnpZhAu1e/Me4RWc17WcMPdZLYkSTTc7SAE7uA8y5KiKRruAAAAADxLcWFF7//CQwr1+HX3mw7J77Ou+PXjY4NqNKT7z7FWFgAAwIvy5ar6evwKB7pMj4INSETtRsLWSuC2SU9IXb1S/Mb2XhdXF07YDXftbi0EAADYoExhUYEunwZCPY5cf63hrmi24e6ZwF3E6BxwD4E7uCM2KhWnTE8BAAAAwEM++JVHNV1a0odec5OuGei76tePjw1KEmtlAQAAPCpfrirBOtmOk4jYDylbDYVtUa9LmZNS8lbJTwDTdaGEVFuWloqmJwEAADtctrioVH+vLOvKH7berOFYUJZlvuHuVLasoXDP2p+tsf0RuIM7oiNStShVy6YnAQAAAOABXzmZ1v98KKMfPrhbb3zR6Lpesz8e0lA4oKNnabgDAADwoly5qjiBu47T+p61teFu7qz9TGCEdbJGhOP2Oc9aWQAAYE6j0VD60qJj62QlqdvvUzwcUKZgruGuVm/osekS62R3GAJ3cEes+QCNtbIAAADAjpctLuqDf/2ohsI9+p0fe+G6P91oWZbGxwZ0erqkwsKyw1MCAABgI5ZX65qbX6bRoQMlnAjcpR+wzxSBOyNCCfus5MzOAQAAdrTS0qrml2tKxXodvU8yFjTacHduZl5LK3UdJHC3oxC4gztiI/ZZYq0sAAAAsJPV6w29/wsPqbS0qt/9sVs0FN5YA8r42KAaDen+c7TcAQAAeMlMxQ5r0XDXeZ5ZKdvGwF1mwj5puDMj3ArcXTQ7BwAA2NEyBTsEl+p3OnDXq1y5qpVa3dH7XM5ktiRJNNztMATu4I4oDXcAAAAApM/cd17ffmJWP3nkGr3y4O4Nv358bFCSdPTsbJsnAwAAwFa0wlqJKIG7TtMKSeZKbVzDlZ6QgjFpYKx918T6tQJ3rJQFAAAGtVrnnFwpK0nJ/qAajTZ/gGQDTjUDdwdTBO52EgJ3cMdawx2BOwAAAGCnevxiWb/7d6e1Z6BPv/Hqg5u6xv54SEPhgI6epeEOAADAS1rrSFkp23l6e/yKBLra94CytiJNP2yvk7Ws9lwTG8NKWQAA4AHpgv2BDqcb7lora7MFM2tlJ7Ml9XT5NDYUMnJ/mEHgDu6INgN3RVbKAgAAADvR8mpdv/T5k1qp1fXxH79VoUDXpq5jWZbGxwZ0erqkwsJym6cEAADAZuXK9sM0Vsp2png0sBaa3LLcpLS6xDpZk9Ya7gjcAQAAc9xaKTscsz/0kym2sbF5AyazJV2/O6wuPxGsnYTvNtwRjEk9YQJ3AAAAwA71B//4uB5Nl/Tu73+BXnTtwJauNT42qEZDuv8cLXcAAABekSu1Gu4I3HWiRCTQvoa7zIR9pgjcGRPsl3xdUoWVsgAAwJxW41yrgc4prZW100X3G+5mK1VdLFV1YJh1sjsNgTu4w7Kk2CgrZQEAAIAd6IGn5vTJf3pCN49E9Z4fum7L13vx/kFJ0tGzs1u+FgAAANojVyZw18nikaCKiytaWqlt/WLpZuCOhjtzfD4pFKfhDgAAGJUpLGlXX7d6e/yO3ifZDPRlCu433E1my5KkgykCdzsNgTu4JzoiFdNSo2F6EgAAAAAuma+u6pfueUjdfp8+/qZD6una+tvQsaGQ4pGA7nuSwB0AAIBX5MtVdfks7errMT0KNqEVlJyptKHlLjMhhYelaGrr18LmheI03AEAAKPShUXH18lK9p9lfZaUNdBwN5ktSZIOJAnc7TQE7uCe2Ii0uigtXjI9CQAAAACXfPRvT+npuQX96o/eqOt2R9pyTcuyND42qNPTZV2aX27LNQEAALA1+fKShsIB+XyW6VGwCa3A3ZbXyq4sShdP0W7nBeGE3XBHCQIAADCgVm9ourTkSuCuy+9TIhJUtmii4a4ZuGOl7I5D4A7uiY7aZ3HK7BwAAAAAXPEPpy7qc8cu6PteMKS7Xry3rdceHxuQJN1/bq6t1wUAAMDm5MpVJaKsk+1U8VbgrrTFwN30I1KjJqUI3BkXSkirS1K1bHoSAACwA+XLVdXqDaViQVful+w3E7g7lS1ppL9Xsb5u1+8NswjcwT2xEfskcAcAAABsezOVqn71Sw8rGuzS773xlrY3nYyPDUqSjp5lrSwAAIBp9XpD+XJ1rSUNnScRsR+E5stbfEiZnrDPkdu2OBG2LBy3z3nWygIAAPelC/Z6Vzca7iQpFevVTKWq5dW6K/eTpOpqTU/kKqyT3aEI3ME90WbgrpQ2OwcAAAAARzUaDf3alx7RTGVZH33dC5WMtf+HKmNDIcUjAQJ3AAAAHlBYXNFqvaF4xJ32CrRfq50wv9WVsplm4I6GO/NCCfus5MzOAQAAdqSMy4G7ZCyoRkO6WHKv5e6JXEWr9YYOJiOu3RPeQeAO7oldY5803AEAAADb2hdOTOkbpy7qNbem9JpbU47cw7IsjY8N6vR0WZfmlx25BwAAANYn12xFo+Guc7W+d7mtBu7SE9KuvVLfwNaHwtaEm4G7eQJ3AADAfdliK3Dnzodyhpura1tBPzdMZsuSRMPdDkXgDu6JNh+00XAHAAAAbFtPzy7ow3/zHQ1Hg/rIa2929F7jY/ZDvPvPzTl6HwAAAFxZrmSHtOIE7jpWrLdbPX7f1gJ3S0Vp9nHa7bwi1FwpS8MdAAAwIFOwP5Tj2krZ5n2mXWy4O5UpSSJwt1MRuIN7evqk3gGpSOAOAAAA2I5q9Ybe+/mTml+u6ffeeItifd2O3m98bFCSWCsLAABgWCukRcNd57IsS/FIYGsrZTMn7XOEwJ0nrDXc5c3OAQAAdqR0YVF+n6VExJ2Gu+Raw517gbvJbEmhHr/2DPS5dk94B4E7uCs2IpVYKQsAAABsR3/8L0/qxFOX9LaX7NXLros7fr+xoZDikQCBOwAAAMPWVspG3XmYBmfEI4G17+WmZCbsk4Y7bwg1A3c03AEAAAMyhUUNR4Py+yxX7tdquGutsnVao9HQ5HRJNyaj8rn0vxHeQuAO7oqOSqWMVK+ZngQAAABAGz2aLurj3zij/fGQfvVHb3TlnpZlaXxsUKeny7o0v+zKPQEAAPBceRrutoV4JKCZyrJq9cbmLpCekCyflLy1vYNhc/oGJMtP4A4AABiRLS4p1e/eB3KGwgF1+SzXGu6mS0sqLKzoQDLiyv3gPQTu4K7YiFRf5Q0eAAAAsI0srdT0S/ecVKMh/Z8/fpuC3X7X7v3i5lrZ+8/NuXZPAAAAPFtrpexQmMBdJ0tEAqrVG5rb7IdZMg9KQzdIgXB7B8Pm+PxSaEia53kMAABw1+JyTXPzy2utc27w+yztjgY1XXKn4e5UpiRJOpiMuXI/eA+BO7grNmqfpbTZOQAAAAC0ze997TE9nqvoP73yOr1w1N0fMIyPDUgSa2UBAAAMypeq2tXXrZ4uHjl0skTEbiBpNRZuSCUvFS9II6yT9ZRQggIEAADgukxzraubgTtJSsaCyrrUcDeZtQN3NNztXLz7hbuizcBdccrsHAAAAADa4ttPzOhT3zqn2/f0612v2O/6/fcNhZSIBAjcAQAAGJQrL62FtdC5ElG7oTBX3sRDysyEfaZua+NE2LJwXJrPm54CAADsMK3Qm+uBu/5ezc4va2ml5vi9JrNlWZZ0wzCBu52KwB3cFRuxTxruAAAAgI63sLyq93/hIfX1+HX3mw6py+/+W0zLsjQ+NqjT0+XNr74CAADAluTL1bWwFjpXPNwK3G2i4S7dDNzRcOctoYS0siBVK6YnAQAAO0im0Gy4i7n7oZxk837TRedb7iazJe0bDKmvp8vxe8GbCNzBXdFm4K5I4A4AAADodPc9OatscUm/+IMv0N6hkLE5xscGJUnHztFyBwAA4Lb56qrml2trYS10rlZoclMrZTMTkq9b2n1zm6fCloTj9jnPWlkAAOCedMHcSllJyjocuFtYXtW52XkdSEUdvQ+8jcAd3BVNSbKk4gXTkwAAAADYomPn5yRJ3399wugc42MDkqSjZ+eMzgEAALATtdrQ4jTcdbzWWuANB+4aDSn9gDR8s9TFvweeEmq+V6uwVhYAALgnYyxwZ98vW1x09D6np8tqNKSDSQJ3OxmBO7jL3y2Fd7NSFgAAANgGjp+bUyTYpRuGI0bn2DcUUiIS0NGzNNwBAAC4LVey2yNaYS10rsFwjyxLypU32AhSeFpamJVSrJP1nHAzcEfDnbPu+6T9V23V9CQAAHhCtrikUI9f0aC761ZT/e403E1mS5KkA0mzPxeHWQTu4L7YKCtlAQAAgA63uFzTI+mi7rh2l/w+y+gslmVpfGxQp6fLmptfNjoLAADATtNquEtEaDbrdN1+nwb6epQrbbDhLjNhnyMvav9Q2JpQc6VshcCdY5ZK0tf+s/S1X5P+9FVS/jHTEwEAYFymsKhUf68sy92fGw83V8q2Gvac8kzgjoa7nYzAHdwXG5EqF6VVHoQBAAAAnerBC5e0UmvoyL5B06NIksbH7DmOnaPlDgAAwE15AnfbSjwSUL6ywcBduhW4o+HOc9Ya7lgp65jMg5IaUvJW++//6GXSt/9AqtdMTwYAgBGNRkPpZuDObUOhgLr9lqYdbrg7lSlpV1+3hqO0fO9kBO7gvuiopIZUzpqeBAAAAMAmHT93SZJ0ZN8uw5PYxscGJElHz84ZngQAAGBnaTXcxQncbQuJaFC5UlWNRmP9L8o8KHWHpKHrnRsMmxNqBu5ouHPO1HH7/NH/Kr39a/aWp298UPr0/ybNPml2NgAADJibX1Z1tW4kcOfzWRqOBZVxMHBXrzd0erqsA8mo6w1+8BYCd3BfbMQ+S6yVBQAAADrV8fNzCnT59MKRftOjSJL2DYW0OxrQ0bM03AEAALgpV7YfZiVod9gW4uGAFldqqlRX1/eCel3KnJRShySf39nhsHF9g5IsaZ7AnWOmTki+Lrvh7poj0ru+JY2/W7pwv/SHL5WO/pH93wkAADtEthl2S8XMvD9IxnqVLTq3UvbpuQUtLNdYJwsCdzAg2gzcFafMzgEAAABgU1ZqdU08fUmHrulXT5c33lZalqXxsUGdni5rbn7Z9DgAAAA7Rr5cVV+PX+FAl+lR0AaJqN1U2FoVfFWzj0vLZSl1m4NTYdP8XXborsJKWUc0GnbD3fALpe5mi09Pn/Tvfkd6299Kkd3S3/+K9Jn/Xbp03uioAAC4JV2ww24mGu4kKRkLqrCwosVlZ9a7n8qWJInAHQjcwYDYqH0SuAMAAAA60ncyJS0s13TnvgHTozzL+NigJOl+Wu4AAABcky9XlWCd7LbR+l7m1hu4S0/Y58jtDk2ELQsnaLhzyqXz0sKMNHr4ub+396XSu74tHf5Z6alvSZ98iXT8U3ZIDwCAbSxjPHBn3zfjUMvdZDNwd5DA3Y5H4A7uawXuWCkLAAAAdKTj5+YkSYc9GrhjrSwAAIB7cuWq4gTuto1ExF79te7AXaYZuEsRuPOsUJyGO6dMnbDP5wvcSVIgLL3696Wf/mupb0D62/dKf/E6CikAANva2krZfjMrZVv3nW7O0W6T2ZK6/ZZekAg7cn10DgJ3cF8oIfm6pSKBOwAAAKATHTs/J7/P0u17dpke5Vn2DvZpdzSgo2fnTI8CAACwI/zTYznNzS8ba69A+7XCk7nSOh9Qpiek3gFp117nhsLWhHfba3+XF0xPsv1MHbfP0Tuu/HX7f0D6+X+Tbn+rdPZe6ZMvlib+grY7AMC21FopOxwzE7hba7grONVwV9b+eFg9XcStdjr+DYD7fD4pmpRKfIIHAAAA6DT1ekMnzs/pplRUoUCX6XGexbIsjY8N6rGLZc1W1tnIAQAAgE05fn5O7/rsA+rv69Yv/sALTI+DNmmtlM2v58/Tq8vS9CNS6jbJshyeDJsWTtgna2Xbb+q41Dco7dp39a8NRqXX/HfpzX8l9YSk//mL0l++SSplnZ8TAAAXZQqLikcCCnT5jdw/2Qz6ZR1ouCssLCtdWNTBFOtkQeAOpkRHabgDAAAAOtAT+YouLazoyF5vrZNtaa2VPXaOljsAAACnPJou6u2fPi6/ZenPfuaIrtsdMT0S2qTVcJcvrSNwlzsl1arSCOtkPS0Ut0/WyrbXyqI0/bC9TnYjgdPrflh6933SrT8pPf516ZN3Sg/dQ9sdAGDbyBQWjTZgPxO4a3/D3WS2LEk6mCRwBwJ3MCU2Ii3OUWEOAAAAdJhWkO3wPm8H7o6enTU8CQAAwPb0RK6it/7pMVVrdf0/d92hQ9f0mx4JbRQKdCnU41euvI7AXWbCPlME7jyNhjtnZB+W6qtXXyf7fHp3Sa/7I+kn/lLyB6Qvv1O65y1She8RAKCzrdTqypWrShlaJytJA6EeBbp8jjTcTWZLkqQDBO4gAncwJTpinyVa7gAAAIBOcvx8M3Dn0Ya7vYN92h0N6OhZGu4AAADaberSgn76U/eruLiiT/7U7XrJ/iHTI8EBiWhQ+fUE7tLNwB0Nd94WagbuCHO119Rx+xw9vPlr3Phq6Rful25+vXT6q9In7pQe/VJ75gMAwIDp4pIaDRltuLMsS8lYUNkCgTs4i8AdzIiN2mdxyuwcAAAAANat0Wjo2Lk5vSAR1kCox/Q4z8uyLI2PDeqxi2XNVtbxkBAAAADrkisv6S1/cr+mS0u6+0236pUHd5seCQ6JRwLKldfxgDLzoBRJSZFh54fC5oWbK2XnWSnbVlPHJVlbb3jsG5De8KfSG//MXk37Vz8jfeFt0jyt7QCAzpMp2GtcTQbuJGk4FlTGgZWyp7IlDUeDnv3ZONxF4A5mtAJ3NNwBAAAAHWPq0qKyxSUd8eg62ZbWWtnW+lsAAABsTXFhRW/91DGdn13QR157s157aMT0SHBQIhLQpYUVLa/WL/9FywtSbpJ2u05Aw50zpk5IiQNSsE0NNze9Tnr3/dKN/176zpelT94pTX61PdcGAMAlrTWuJlfK2vfvVXlpVZXqatuuuVKr6/GLFR1IRtp2TXQ2Ancwo7VStkjgDgAAAOgUrXWyRzy6Trblxc3A3dGzNAIAAABs1Xx1VW/7s2M6PV3Wr/y7G/WW8WtNjwSHxSMBSVL+So3R0w9LjZqUus2lqbBpoebq53kCd21TykilKWn0jvZeNxyXfvyz0o/9iVRbke55s/Sld0qLl9p7HwAAHJL2SMNdst8O/E23seXubH5ey7U662SxhsAdzFhruGOlLAAAANApWoG7wx5vuLt2sE/D0aCOnqXhDgAAYCuWVmp651+c0INPF/Tz379fP//9+02PBBckIvYDynz5CoG79IR90nDnff5uqXdAqrBStm2mTtjn6OH2X9uypFveKL37qHTdj0gP3yN98sXSma+3/14AALSZV1bKJmP2/TOFpbZd81S2KEkE7rCGwB3M6N0ldfVKRQJ3AAAAQKc4dm5OI/29GjH8A5OrsSxL42MDeuxiWbNXauUAAADAZa3W6nrP5x7Ut5+Y1Zvv3KMP/MgNpkeCSxLNhrtc6QoPKDPNwB0Nd50hnKDhrp2mjtunE4G7lmhS+ql7pNd+Qlqel/7yjdKjX3LufgAAtEGmsKieLp8GQz1G50g1G+6ybWy4m8yWJUkHUwTuYCNwBzMsS4qNsFIWAAAA6BAzlaqezM/r8N5dpkdZl/HmWtn7z9Fy11Fqq1LhgukpAADY8er1hj7wxYf19VMX9dpDKX3ktTfLsizTY8ElrZWyuas13A2M2R+uh/eF4jTctVP6AaknIg1d7+x9LEu67S3SO//J/ucn/sHZ+wEAsEXZ4pKSsaB8PrPvHYaj7W+4m8yWFOz2ae9gqG3XRGcjcAdzYqNSKS01GqYnAQAAAHAVJ5rrZI/sGzQ8yfq0AndHz84angQb8vXfkP6vW6XMSdOTAACwYzUaDf3WV0/pSxNp/dCNCf23N95q/IEZ3JWI2oG7y66UXSxIc09KKdbJdoxwQqoWpZX2PXTesWqrduB05HbJ53fnnoP77dBk/jF37gcAwCalC4tKxcxvR2k13E0X2/Nnn0ajoVOZkm4YjsrPeyM0EbiDOdFRabkiLRVNTwIAAADgKo6duyRJOrKvMxosrh3s03A0SOCuk8w8Lh37H1KjJn3zo6anAQBgx7r7G2f0Z/92XuNjA/rEm29Xt5/HCDtNImI/oLxsw13mQfscIXDXMUIJ+5yn5W7Lct+RVhedXSf7fIZukGbOUGIBAPCs8tKKykurSvWbD9zFervV2+1Xpk0rZfPlqmbnl3UwGWnL9bA98E4Z5sRG7LPEWlkAAADA646fn9NAqEf742HTo6yLZVkaHxvQmYsVzVSusAoL3vGND9lhu+Qh6YlvSE/dZ3oiAAB2nP/xL0/qv3/zCd06GtOf3HVYwW6X2pvgKf293er2W8qXL9MIkn7APmm46xzhuH3O58zOsR1MHbdPtwN38eulakkqT7t7XwAA1inbbJMbabbLmWRZlpL9wbWZtupUtiRJOpiMtuV62B4I3MGcaDNwVyRwBwAAAHhZpbqq72SKuuPaXbKszqnMb62VPXZuzvAkuKrz35Ie+1vp4H+Q3vCnkuWXvvkR2hsAAHDR5449rY/9r9O6LhHWn/3MEYUDXaZHgiE+n6WhcODKDXeWX0re4u5g2LxWw12Fhrstmzphn6N3uHvfoRvsc4a1sgAAb0oX7Da5pAca7iQpGQsqW1hUow0/X5zMliVJBwjc4bsQuIM5rYa74gWzcwAAAAC4ogeeuqR6Qzqyb8D0KBvSCtyxVtbj6nXpa78u+bqlV/6mNLhfuu3N0lPflp78punpAADYEf7moYz+85cf0TUDvfrsz96pXaEe0yPBsEQkoPzlAnfpCSlxQOoJuTsUNi/cCtxdNDvHdjB1XNq1TwoNuXvf+PX2mT/j7n0BAFinTDNw54WVspKUjPVqfrmmcnV1y9eabDbc3UjgDt+FwB3MiY7aJytlAQAAAE873myI67TA3bWDfRqOBgnced2jfyVlT0p3/pw0sM/+tZd/QPL30HIHAIAL7j2d0y/dc1KJSED/7zvGtTtqfgUUzItHgsqXq6rXv+fPYuVpqZyRUreZGQyb0wrcsVJ2axbmpNkn3F8nK9FwBwDwvFbgzgsrZSUpFbPnyBa2vlb2VLakawf7aAHHsxC4gzkxVsoCAAAAneDY+TmFevw62GGf4LMsSy/eP6gzFyuaqVymnQNmrSxK//BhKdgvvex9z/x6/zXSHW+315Wd/qq5+QAA2ObuPzurd332AUWCXfrsO+7UnsE+0yPBI+KRgFbrDV1aWH72b6Qn7HPkdveHwuaxUrY90g/Yp4nAXTQl9USkPIE7AIA3tYJtyZhHGu6aTXuZ4uKWrrO0UtPZfEUHhjvrZ+NwHoE7mBOISMEYDXcAAACAh1VXazp5oaDbr92lLn/nvYUcH7Nb+Y41W/rgMUf/UCpNSa/4FanvexoUX/Y+qbtP+uZHpXrNzHwAAGxjj0wV9Y7PnFC336fPvP2IrtsdMT0SPCQRCUiS8t/7wZVMM3CXInDXUUJx+6Thbmumjtvn6B3u39uypKHrpJnH3b83AADrkC4sKtbbrZBHWuCG29Rwd+ZiWfWGdKDDPowO53Xe0xJsL9FRqThlegoAAAAAl/HwVFHLq3Ud2dtZ62RbxscGJYm1sl40PyP9693Srn3S4Z997u+HE9Kd75Lyp6VH/sr9+QAA2MaeyJV116ePaaVW15/cdYduGe03PRI8JhG1A3e50vcE7tITkj8g7b7JwFTYtK7wdw/kAAAgAElEQVQeu1WahrutmToudQWl3TebuX/8BqkyLS0VzdwfAIAryBQXler3RrudJKWaTXvTW2y4m8yWJEkHknxACc9G4A5mxUakUkaq101PAgAAAOB5tJrhDu/rzMDdnoE+JWNB3fckgTvP+affkZbL0it/034A+Hxe+h4pEJP+6WNSbcXN6QAA2LYuzC3oLX9yTKXFFf3hW25f+4AC8N0SEbsRJFf+rsDdyqKUeVAafqHk7zY0GTYtnKDhbivqdWnqASl56PLvX5w2dL195s+YuT8AAJdRrzc0XVzSSH/Q9Chrks1ZMsWtNdydytiBu4MpGu7wbATuYFZ0RKpVpYUZ05MAAAAAeB7Hz8+p22/p0DWd2XpiWZbGxwb1eK6ime9dhwVz8mekE5+WrrlTOvjay39d7y7ppf9RunReevAvXBsPAIDtKlda0ls+db8ulpf0+2+6VT94427TI8Fr6jXp0lMaKx7VXf6v6YYHPiz9+Wulj98s/fawtDgnjbzI9JTYjFBCqhC427TZx6Vq0cw62Zb4DfY585i5GQAAeB4zlapWag0lY95puIsGuxUOdCm75Ya7sqLBLo14qL0P3uCN5cnYuWIj9lmcsj9dBQAAAMAzavWGHjh/SbeM9ivY7Tc9zqaNjw3oyw+mdf/ZOb36lqTpcSBJ//AhqVGTXvXbkmVd+Wvv/Hnp6B9J//x70q0/KXXzwy0AADajsLCsn/7UMT01u6Dfft3Neu2hEdMjwaSFOWn2Cfuvmcef+fvZJ6VaVfslfbhbUkZSd0ga3C+NHrYbtu74GcPDY1PCcempgrS6bK6hrZNNHbfP0cPmZhhqBu7yBO4AAN6SLtihNi+tlJWk4VhQ2cLmG+4ajYYmsyUdSEVlXe1nmNhxCNzBrNg19llKSyO3m50FAAAAwLNMZksqV1d1pEPXyba01qQdPTtL4M4Lzv2r9Nj/km56nXTNOh5WBcLSy94nfe3XpOOfkl7yi87PCADANlOpruquTx/XYxfL+tUfvVFvvvNa0yPBDatVae7sd4XqnrRbumYet5vqvpvlk/r3SPteLg1dp9VdY/rpr1zSvhtu1cfe+qqrf0gC3hdqlh7M558pQ8D6eSFwt2uv5O+RZlgpCwDwlkwz1Jby0EpZSUrGgjpx/pIajcamAnNTlxZVrq7qYJJ1snguAncwK9pquEubnQMAAADAcxw/bz+EO7K3swN3ewb6lIwFdfTsrOlRUK9LX/91+yHRD31o/a+74+3Sff+39K27pRfdJQUizs0IAMA2s7RS0zv//IQeulDQu79/v971iv2mR4JTnvymdObrdqhu9gmp8LTUqD/7a/oG7Za6wRdIQy+wz8HrpIF9Uldg7cu6JJ3+2tdVW4wQttsuwnH7nM8RuNuMqRNSJGX2/zt/lzSwn4Y7AIDntNa2eq3hLhXr1eLKjIqLK+rv23jD76lsSZII3OF5EbiDWa03JqUps3MAAAAAeI7j5+dkWdLt1+4yPcqWWJal8bFBffnBtGYqVQ2FA1d/EZzxyBek7EPSi3/Rfqi7Xt1B6RUfkP7m/7DXy77il52bEQCAbWSlVtd//NyD+rcnZ/XT49fql3/kBtMjwSn1mnTPW6XlsuQP2Ctgb/z3zWDddXaobnC/1Lf+D9MkIkHlK1UHh4arWg13lbzZOTpRtSLlTtn/TZkWv16a/BtpZcl+nwQAgAd4daVsstm4lyksbSpwN9kM3B0gcIfn4TM9AHY4Gu4AAAAAT2o0Gjp27pJuHI4q1tttepwtGx+zHyzef3buKl8Jx6wsSv/4W1KwX3r5+zf++kNvlnbtk/7tD6QFvo8AAKzHR756St84dVGvu21EH37NTZtao4QOkZu0w3bj75Z+PSu9+z7px/9CeuWHpEM/JV1zeENhO0lKRAPKlZYcGhiuC7dWyubMztGJMg/abZGjd5ieRBq6wZ5l9gnTkwAAsCZTWJTPknZHvPVB52TMDty1Gvg2ajJbkt9n6brd4XaOhW2CwB3M6gpIobhUpOEOAAAA8JJzM/OaqVR1577OXifbMj42KEmslTXp6CftdvNX/IrUu4nWRH+39AO/LlVLdugOAABc0Uylqs8de1q37enXf33DLfL5CNtta+kT9nntSyWfvy2XjEcCml+uab662pbrwbC1hjsCdxs2ddw+Rw+bnUOS4s2m0hnWygIAvCNTWNJwNKguv7ciSMmY3biXLW7uQySnsiWNDYUU7G7Pn6+xvXjr33bsTNERqUTDHQAAAOAlx8/bDWKH926PwN2egT6lYkECd6ZU8tK/ftxuqDv8s5u/zs2vlxIH7bWy5Yvtmw8AgG3oiw9MaaXW0Du+b5+6PfbgCw6Yagbu2tjAFW82lOTKrJXdFsJx+5xnpeyGTZ2QLL+UPGR6EmnoevvMnzE7BwAA3yVbXFTSY+tkJSnVv/mGu/LSii7MLepginWyeH68y4Z5sVGpnJVqfEoOAAAA8Ipj5y5Jkg7v20QTmQdZlqXxsUE9nqtopsIDQ9f98+/aK85++MNSV8/mr+Pz2S13q4vSv/5+++YDAGCbaTQa+tyxpzUY6tGrDg6bHgdumDohRUelSPu+34mI/YAyT+Bue6DhbnMaDbvhbvhmqafP9DTS0HWSLBruAACesbRS00xlWSkPBu6GWw13hY033J2eLkuSDiQJ3OH5EbiDebFRqVGXKtOmJwEAAADQdPz8nPYO9q09ZNsOWmtl7z87Z3iSHSb/mHTi09I149KB12z9eje+WkrdLj3waanw9NavBwDANnTfk7M6P7ugN7xoVD1dPAbY9pZKUv50W9vtJCmx1nC3uRVc8JjuoBSIShWaojek8LQ0n/PGOllJ6u6V+vfQcAcA8IzWutZWm5yXhANdigS7lNlEw91ktiSJwB0uj3faMC86Yp9F1soCAAAAXjBdXNLTcwvbZp1sSytwd9/ZGcOT7DDf+JDUqEk/8tuSZW39epYl/dAHpdqy9M//ZevXAwBgG/rLY3Yo/SeO7DE8CVyReVBSo+2Bu7WVsiUa7raNcIKVshs1ddw+vRK4k6T4DdLsE1K9ZnoSAACULdhhthEPNtxJUirWq+nixj9AcipjB+4OErjDZRC4g3mxZuCuNGV2DgAAAACSpGPn7Qa4I/u2V+DumoFepWJBHaXhzj3n/kU683fSTT/W3gfAYz8g7X2ZdPJz0szj7bsuAADbwGylqq99Z1ov2T+ofUMh0+PADekT9jniTMNdvkLgbtsIJVgpu1FTzf++vBS4G7peqlWlS+dNTwIAgNLNwF0y5s3AXbI/qGxxSY1GY0Ovm8yWNBQOrH0IBfheBO5gXnTUPosE7gAAAAAvOH5uewbuLMvS+NignshVlC/z0NBx9br09d+Q/D3SKz/U3mtblvSDH7Sb8+79WHuvDQBAh/vixJRWag39JO12O8fUCcnyS8lb23rZRNReC0bD3TYSjkuLc1JtxfQknWPquNS7SxoYMz3JM+I32OcMa2UBAOZlCt5dKSvZQcDqal1z88vrfk2t3tBjF8s6kIw4OBk6HYE7mBdjpSwAAADgJcfPzykRCWjPQJ/pUdqutVb2/nOzhifZAR75vJR9SDryTmnX3vZff8+d0nWvkr7zJWn6kfZfHwCADtRoNPS5Yxc0EOrRq27abXocuKHRsAN3wzdLPe3983s40KW+Hr9y5Y2v4IJHhRL2OT9jdo5OsVqVph+22+0sy/Q0zxhqBu7yj5mdAwAASRmPr5RNxuwgYHYDa2XPzcxraaXOOllcEYE7mBcetj99VyJwBwAAAJhWWFjWYxfLOrxvQJaXHii0SStwd/QsgTtHrSxK//hbdhPEy9/v3H1+8Dfs85u/7dw9AADoIPedndW5mXm94UWjCnT5TY8DNxQvSPO5tq+TbYlHArRDbyfhVuCOtbLrkn1Yqi17a52sJMWvt08a7gAAHpApLqq3269Yb7fpUZ7XZgJ3p7IlSdLBFIE7XB6BO5jn75IiSVbKAgAAAB5w4vwlNRrSndtsnWzLNQO9SsWCOnp2zvQo29vRT9ofqnrFr9ihO6ckb5UO/gfpzN9JF447dx8AADrE545dkCT9xOFrDE8C10ydsM9RZwJ3CQJ320sobp+VvNk5OsVU8z2GQ/99bVrvLrutkIY7AIAHZAqLSvUHPfvh7VSzeS9bXFz3ayabgbsDNNzhCgjcwRtiIzTcAQAAAB5w/LwdRDu8d3sG7izL0vjYoJ7IVXhw6JRKXvrXj0sDY9Id73D+fj/w65Llk775W87fCwCwLvV6Q/8/e3ce39Z9n/n+A4A7CICkuIOSqMXctEuWbMfZmzZu4sSJkzZ12pu0nWna6XSSZtqmmabT3u7LnTZLl9ve6dy5dRO76eLUiZM4W+M2VhItliVRIrVZIiUs3Elw34Bz//gBlLVzAXAOwOf9evn1cyUC5+tUpAieB8/Xsiy7x1h3hifn+NqZPh7auoGtNeV2jyPZkgrcZajhrtZXwvDUPAvxREaeX7JMDXcrEzoGuCB4wO5JblXTahru9PetiIjYyLIsImOzS6E2J0o13EXGlt9w1x0dp6jAzdZqb6bGkjygwJ04gz8IU4OwsPwvciIiIiIikn5He0bwlxTQWueze5SMeXCbWSt75IrWymbEC38A8xPwlt+CgqLMX6+mBfY8AVf+HS6/kPnriYjIPb33r77Lh//+pN1jrDvPnAgzH0/wxAOb7B5Fsil8HEoCsGF7Rp6+xlcMwNCk3qySF7zJwN2kAnfLEjpugm0lAbsnuVV1C8yNw0Sf3ZOIiMg6FptZYGYhTtDRgbuVN9x1RcZpqSunwKNIldyZ/nSIMwSC5lTLnYiIiIiIbWbm43SGYtzfXIXb7cwVAOnw0FYTuPv+ZQXu0m7wPLz0/8HGB6H9Hdm77ht+FdyF8K3fUcODiIjNxqbnOXF1jH+/MKiWuyyyLIunj16lsqyQt+6os3scyZb4AkRPmfYtd2Zu96QCd2qHzhPlyZWyU1ope08T/RC76rx1sik1reYc0lpZERGxT3jMhNhSoTYnKi3yUFFWSHSZDXfDk3MMTMzRoXWycg8K3Ikz+JvMqcCdiIiIiIhtXr46ymLC4tCW/Fwnm9JUWUqwopTvXx6xe5T8843fACsOb/09cGUxtFm5GQ78pGl4Of/V7F1XRERucSY8Dpimg0hM2yyy5fuXR7g8NMV7DzRRXOCxexzJlv4zsDibsXWyALXJwN3AuAJ3eUENd8sXTq5rbjpo7xx3Ut1izsEL9s4hIiLrWmpNa2NFic2T3F1DoJTo+PIa7rqjEwC0K3An96DAnThDIBm4iylwJyIiIiJil6M9JoB2sDm/A3cul4sHtlZxaWBSTR3pdPnf4MLzsPM99rRAvP6XoaAUvv17kEhk//oiIgLA6fDY0r93R8ZtnGR9efroVQB+7JDWya4roVQgKIOBO7+5eTqg75vzQ1EZFJXDlAJ39xQ6Zk6nBu7UcCciIg4QSTbcOXmlLEBjoIS+2CyJxL1b2Luj5nWsAndyLwrciTMsrZQN2TuHiIiIiMg6dqxnhJJCN7uCAbtHybgH822trGXB9/4CzvyzPWGzRAK+/uvgKYIf+I3sXx/AVw8PfMg0vZx9xp4ZRESEzlBs6d9TNyoks0am5nn+TB8Pbq1iW0253eNINqUCdxlsuKspTzbcTaixMm94a2BSK2XvKXTchBNr2uye5PZ8DVDkg0EF7kRExD6RWHKlrMMDd/WBEhbiFkNT934TSVcqcFevwJ3cnQJ34gx+NdyJiIiIiNhpIZ7gRO8YezdWUFSQ/y8VH8q3wN1AN3zt1+Cffhr++nVw/nkTwsuW05+HvtPwwM9CZXP2rnuzh38Riv3w7d+H+KJ9c4iIrGOd4Rgbq0pxu6C7T4G7bHjmRIj5eIIn1G63/oSPQ+UW8G7I2CVq/SZwp2boPFJeq4a7e4kvQvgENO4Dt0PXdLtcUNMCQ1opKyIi9kmtlG0IOHulbGMyEBgdu/ebSLqj4wQrSgmUFWZ6LMlx+X8XRXKDtxo8xTCuwJ2IiIiIiB3OhGPMLMQ5tCVzN+ucpKmylGBFaf4E7noPm/O+t8LwJXj6ffC/fgiufCfz156fhn/9HSithNf9UuavdzdlVfDQf4aRV+DUU/bOIiKyDo1OzRManeFgcxXN1V66tFI24yzL4qmjV6ksK+StO+rtHkeyaXrEfN+XwXWyAFVlRRS4XVopm0+8NTA1pDeo3M1gNyxMOXedbEp1C0z2w8zYvT9WREQkAyJjM1SXF1FS6NCAelIqEBiN3T1wN7cY59LApNbJyrIocCfO4HKBvxFiWikrIiIiImKHYz0jABxqrrJ5kuxwuVw8sLWKVwan8mM9Vu9hwAWP/zV8+CQc/I8QOQF/+yg8+S4Iv5S5a3//L82bp97wcRO6s9uDPw+lVfDCH8GibgyLiGRTZ9isk90dDNDe4Kd3ZJqpOQU6MunIlREuD07xnv1Njr/JJWkWPmHODK6TBXC7XVSXFytwl0/KawELpvPkzUeZEDpmzlwI3IFa7kRExDbRsZml9jgnawgkG+6SK3Dv5NLAJIsJi44GXzbGkhynwJ04R6BJK2VFRERERGxy9MooHreLfZsq7B4lax5MrpU9cnnE5knWyLKg5zDU7TCBN38DvP1P4BeOw54n4PIL8D/fDJ//CRg4l95rTw7Ai5+Eqq1w/0+n97lXq8QPr/0ojIfg+P+2exoRkXUlFbjb1RSgo8GPZcG5vgmbp8pvTx+9CsCPaZ3s+hM+bs4MN9wB1PiKGVLgLn+U15lTa2XvLJS9z681qWk15+B5e+cQEZF1aTGeoG981vHrZGH5DXeplvaORjXcyb0pcCfOEWiCuRjM6YdwIiIiIiLZlEhYHO8dYWejH29xgd3jZM1DycBdzq+VHb5kbpZtfvjGX6/aAu/+K/j570H7O6D7S/CXD8IXfg5Ge9Jz7Rf+AOYn4S2/BQVF6XnOdDj0M+BrgO/8D5ifsnsaEZF143RoDLcLOhpM4A6gO6q1spkyOjXPVzv7eGBLFdtry+0eR7ItdBw8RVC/K+OXqvUVMzgxh2VZGb+WZIG3xpyTCtzdUegYVGxOtgE6WHUycDekwJ2IiGRf/8QcCYucaLirTwbuImN3b7jrjpqsilbKynIocCfO4Q+aUy13IiIiIiJZdXFgkrHpBQ5tWR/rZFOaKksJVpTmfuCu50VzNj98+9+vbYf3fRZ+5l9h6xvh1NPwZ/fDl38JJvpWf92Bc/DS38Kmh0ygz0kKS+H1vwxTg3Dkr+yeRkRk3TgTHqelzkdpkWfpBkWXAncZ888nQszHE7z/AbXbrTuWZRru6ndDQXHGL1frL2Y+nmBseiHj15IsSIXIpgbtncOpZkbNilanr5MFqGw2wdtBrZQVEZHsS4XXgjkQuCsp9LDBW0TfPRruuqPjeIs8bKwsy9JkkssUuBPnCCQDd+Mhe+cQEREREVlnjvaYlaoHm9dX4M7lcvHg1g28MjjFwMTdf9jiaL2HzXlzw93NggfgA/8CH/wSNO6DY38Dn94L3/gNmF7FWt1v/iZYcfih3wWXa+WPz7R9H4CKTXD40zAzZvc0IiJ5b2hyjvDYDDuDAQDq/MVUlhWq4S5DLMviqaNXqSgr5K076u0eR7Jt5LIJBWVp3WVNuQn1DWitbH7wJgN3ari7vfBL5syFwJ2nAKq2qeFORERskQrcNQScH7gDaKgouetKWcuy6IqO09bgx+124M86xXEUuBPn8DeZUw13IiIiIiJZdezK+gzcATy41fw3H7m8isCZE1gW9ByGmjbwVi/vMVteD//h6/DE52HDNhNI+/Qe+Lc/hrmJ5T3H5X+DC8/Dzvdk7UbvihUUwRt/DWZj8N0/s3saEZG81xmOAbC7yQTuXC4XHY1+zvdNkEhoDWW6Hb0ywuXBKd6zv4mSQo/d40i2hY6bM5ilwJ3frOAaVOAuP5QnV8pOKXB3W6nPr1wI3AHUtMBoLyzcfUWeiIhIukXGTHitsaLE5kmWp95fSt/4LPE7vD6NxmaJzSzQoXWyskwK3IlzpBruYmq4ExERERHJFsuyOHplhPtqy6n0Ftk9TtY9uHUDQO6ulR3tgYnIvdvtbuZyQesj8LPfgff8LxPW+/bvmca77/0lLNyl8S+RgK9/wqwu+oHfXNP4Gbf7R6G6Fb7/f8OkVmaJiGTSmZAJ3KUa7gDa6/1Mz8fpHZm2a6y89fTRqwA8cWijzZOILcKpQFB2Ane1vlTDXQ63Qst1Sw13+v74tkLHwFMM9bvsnmR5qlsBC4Yv2T2JiIisM7m0UhZMMDCesO74JpJUO3u7AneyTArciXP4Uytl1XAnIiIiIpItodEZ+sZnObRl/bXbAWysKiNYUZq7gbuldbKvWd3j3W7Y9V74z0fhHZ82Ibqv/Tf4s/3w0t9CfPHWx5z+PPR1wgM/B5WbVz97Nrg98OZPwMIUvPhJu6cREclrp8MxPG7XDW0AqRsVXRGtlU2n0al5vnKmj0Nbqthe67N7HLFD6DiUbYDK5qxc7nrgTg13eaG4HArL1HB3O4mE+fxq2GMas3NBTas5B7VWVkREsisam6HQ46K6vNjuUZYltfo2Grt9K+z1wJ1eY8nyKHAnzlESgCKfGu5ERERERLLoaHKd7HoN3AE8sKWKVwanGJ2at3uUletJBu6aX7u25/EUwoGfhA+/DG/9fVichS99GP7iEHT+k7nxBDA/Dd/6bSithNf90tqumS3t7zQ3zI79DcT0Bi8RkUw5E47RUue7Yb1pKnCXunEh6fHMy2HmFxO8/9Amu0cROyzMmjc/BO83rcVZUJMM3GmlbB7x1qjh7nZGXoHZsdxZJwtQ3WLOoQv2ziEiIutOeGyW+kAJbnd2viddq9Tq22js9q3NXdFxsxSkXoE7WR4F7sQ5XC6zVlYNdyIiIiIiWXOsxwTuDjav38BdR6MJA5zrm7B5klXofRGqtoGvPj3PV1gCD/1n+MgpeNMnYGoQ/vk/wF+/Ds4/D9/7C7PC9g0fh9KK9Fwz01wuePN/h/gc/Psf2z2NiEheGpiYJRqbZVfwxtU722vLKfS4FLhLI8uyeOpIL4HSQh7Zmaa//yW39J2GxELW1snC9cCdGu7ySHmtGu5uJ3TMnFn8/Fqz6vsAlxruREQk6yJjMzQGcmOdLEC93wTuUqtwb9YdnWBLtZeyooJsjiU5TIE7cRZ/0DQOWJbdk4iIiIiIrAtHe0YIVpTSWJE7PxxJt7b6VOAux8IAY9dg7Co0P5z+5y72wRs+ZoJ3D38Ehi/B0++Db/+uCfjd/9Ppv2YmbX8LbHoITvwdDL9i9zQiInnnTDgGwK6mG8PYRQVuttf66FLgLm2O9YzyyuAU79nfdEOboKwjoePmzGIgqLjAQ0VZIQPjt28DkRzkrYWpoetN1mIsBe5yqOGusBQqNqnhTkREsmpqbpHYzALBHPqZcurn37druJueX6RneGqppV1kORS4E2cJBGFxBmZG7Z5ERERERCTvDU7McXlwal2vkwVoazBrAs7nWsNd73fNuXmN62TvpqwKfvC34cMn4eB/hJIA/PAfQUFR5q6ZCamWOysOL/yh3dOIiOSdzpAJ1O0OBm75vfYGH9HYLGPTObi63YGePnoVgCcObbR5ErFNOBm4a9yf1cvWlBdrpWw+Ka8x3xvPjNg9ibOEjkN5PQSa7J5kZWpazZuk4ot2TyIiIutENGZa4nLpTdx1/hJcLui7TeDuXN8ElgUdCtzJCihwJ87iT76IiV2zdw4RERERkXXgeHKd7HoP3FWXF1NdXkR3zgXuXjRnJhrubuZvgLf/CXz8Ktz3g5m/XiY0PwzbfgA6/xH6u+yeRkQkr3SGxyhwu2it993ye6kbFmq5W7ux6Xm+3BnlYHMl99Xd+r+1rBOh41DdAqUV9/7YNKr1K3CXV7y15pzUWtkl81PQf9a0R7pcdk+zMtUtEJ+HsV67JxERkXUiPGZCaw0VJTZPsnxFBW6qy4uJxG5dKdsVMa9X2xv0OkuWT4E7cZZA0JyxsL1ziIiIiIisA0eTgbuDzes7cAfQWu/jYv8EiYRl9yjL13MYKjbnXvuCnd7864AF3/49uycREckrp0MxWut9t11xmgrcdUdzLNjuQM+cCDO/mOD9D2yyexSxy+SgCdQEs7dONqXWV8LE3CIz8/GsX1syoDwZuJtS4G5J5KRp/culdbIpNa3mHDxv7xwiIrJuRMZyr+EOoCFQQnTs1oa77uQbxDoabm1tF7kTBe7EWVI3isYVuBMRERERybRjPSNs8BaxrcZr9yi2a6v3Mz0f59rotN2jLM9EH4y8Apuz0G6XT4L7Yeub4MLzsHDrD9dERGTl+sdnGZiYY3fT7W9MtKca7iJquFsLy7J46uhVAqWF/PDOBrvHEbuk1sk22RG4KwZgYELfQ+UFb4051XB3XeiYOW34/Fqz6mTgbkiBOxERyY5oMnAXzMHA3cDELIvxxA2/3h0dp7KskDp/sU2TSS5S4E6cZWmlbMjeOURERERE8tzE7AJdkXHub67ElWvrcjIgtQIvZ9p3erK4TjbfbH4NJBahr9PuSURE8kJnKAbAzuDtA3eV3iLq/SVLjQGyOsd7R7k0MMnj+4O3bRKUdSJkX+CuJhm401rZPFGulbK3CB0Dlxsa99k9ycrVtJhz8IK9c4iIyLqxtFI2kDsrZQEaAqUkLBh41fe0iYTFub4J2hv8+jm5rIgCd+Is/kZzquFORERERCSjXuodJWHBoS0b7B7FEdrrTfvO+b4cCdz1HjanGu5WLrjfnOGX7J1DRCRPdIZN4G53sOKOH9PR6OfSwCQLN7UIyPI9feQqAE8c0jrZdS18HApKoXZH1i9ds9Rwp8BdXiivM6dWyhqWZQJ3dTugKAcb4EsrwVurhjsREcmayNgMvpICfCWFdo+yIo0VJiAYjc0s/VrvyDTT83E6kpqYO0YAACAASURBVO3sIsulwJ04S1EZlFZBTIE7EREREZFMOtYzAsCh5iqbJ3GG++rKcbvgXF+OtO/0HAZ/ECqb7Z4k9zQmA3eRE/bOISKSJzrDMQo9Llrqy+/4Me0NPubjCV4ZnMziZPljbHqe5zqj3L+5kpY6n93jiF0SCQifgMa94CnI+uVrfebm5MC4VsrmhaWVsoP2zuEUsRBM9kPTQbsnWb2aVtNwZ1l2TyIiIutAJDaTc+tkAeoDZubI2PXvaVNt7O0K3MkKKXAnzhMIaqWsiIiIiEiGHbsyirfIQ3uDbtoClBR6aK725kbD3eSgaS7Y/DBozcHKlVVB5RZzw1pERNbEsixOh2K01fspLrjzmtPUjYuuSI4E2x3mCy+HmV9M8P4H1G63rg1dgLlxW9bJghru8k6xDwpK1HCXEjpmzlwO3FW3wPwETETtnkRERPJcImERjc3SmIOBu8bArQ13CtzJailwJ87jb4KJCCTidk8iIiIiIpKXZhfinAyNsX9zJQUevSxMaav3cWV4ipl5h78WufpdczZrneyqBffD8EWYGbN7EhGRnNY/PsfQ5By7mgJ3/bjUjYvUjQxZPsuyeOrIVfwlBbxtV4Pd44idwsfNGbQncFfrN4G7QQXu8oPLZVaQTipwB0Ao+fmVy4G7mlZzDmqtrIiIZNbw1DzziwkakuG1XNKQDAlGY9cb7roi4xR6XGyvvXNru8jt6M6KOE8gCIlFvdATEREREcmQ06EY84sJHtiidbKv1lrnx7Lg4oDDW+56DptzswJ3q5ZaKxs9ae8cIiI57nTIBJd3Be8euGve4KW00EN31OF/xzrQS72jXByY5PH9TZQU3rlFUNaBpUCQPYE7X3EBJYVuNdzlk/IamNJKWcA03JVUQNU2uydZveoWcw5dsHcOERHJe5Ex0w6Xiw13tb5i3C6I3rRSdnutj6ICxadkZfQnRpwn0GTO8bC9c4iIiIiI5KljPSMAHGxW4O7V2pLrdc85fa1s72HTRrFhu92T5K7gAXOGX7J3DhGRHNcZjgH3Dtx53C5a6310R8exLCsbo+WNp45eBeCJQ1onu+6FjkN5PfiDtlze5XJR6ytR4C6feGtN4C6RsHsSey3OQfSUCbO6c/i2qRruREQkS1KBu2AOBu4KPW5qfMVLK2XHpueJxGZpT/5cWGQlcvg7R8lb/mTgLhaydw4RERERkTx19MoIRR43ezZW2D2Ko7TVJwN3Tm7fmR6B/rNmnazLZfc0uathN7jcED5h9yQiIjmtMxyjqMBNS929b060N/gZnppXWGcFYtMLfPl0lAObK2mt1w2gdW1+CgbOmkCQjd8D1viKtVI2n5TXmG1Ds2O2jdAdHedX/+k0c4tx22ag7wzE53J7nSyArwGKfGq4ExGRjIsk17Hm4kpZgIZA6dJ/Q6qFvaPBb+dIkqMUuBPnCSTfoaeGOxERERGRtIsnLF7qHWV3U0BryW6ysbKMsiIP5/vH7R7lzq5+D7C0TnatirxQ0w6Rl+2eREQkZ1mWRWcoRnv98lbvdCQbA7qiDv571mG+8HKIucUE71e7nUROgpWwbZ1sSq2vmOGpORbj67wRLV94a805OWDbCE8ducrnj1/jRK99oT9Cx8xp8+fXmrlcUNOiwJ2IiGRcLq+UBWisKGFoco75xcTS69N2Be5kFRS4E+dJVeKr4U5EREREJO26o+NMzi1yaIvWyd7M7XbRUudzdsNd73fN2fxae+fIB8H95o1eE312TyIikpOisVmGp+bZ1XT3dbIpHY3mBka3AnfLYlkWTx29ir+kgLfvbrB7HLFb+Lg5g/YH7iwLhqfmbZ1D0qQ8Gbibsi9wl/o7oWd4yrYZlgJ3wQP2zZAu1a0w2Q8zNgYYRUQk70XGZnC5oD6HG+4sC/rHZ5e+F1HgTlZDgTtxHn8j4FLgTkREREQkA45eGQHgoAJ3t9VW72N4at65q7J6XoSyDVDTZvckuS+435xaKysisiqnQzEAdgWXF7hrrTc3MLoiCtwtx4mro1zon+Tx/U1qJRYTCHK5oXGfrWPU+IoBGBh36PfKsjLeGnPa1HCXSFhLN7mvDNkcuKtugdJK+2ZIl5oWc6rlTkREMigSm6XOV0KhJzfjRqlVuNGYCdzV+0uo8hbZPJXkotz8DJD85imE8jqtlBURERERyYBjPSO4XHBgcx7cTMiAtnqz7u5cnwPDALMx6DsNmx4y64JkbVINFhEF7kREVqMzbNpzdgUrlvXx5cUFbN5Qpoa7ZXrqyDUAfuzQRpsnEUcIvQQ17VBcbusYtT5zc3JwctbWOSRNlhruBm25/NWRaabm44CNgbvJQRjrhaaD9lw/3apbzTl43t45REQkr0XGZmioyM12OzANd2C+F7nYP0l7g8/miSRXKXAnzhRogpgCdyIiIiIi6WRZFsd6Rmiv9+MvKbR7HEdKte+c73PgWtmrR8BKaJ1sutR2QEEJhF+yexIRkZzUGR6nuMDNfXXLDwC11/u5MjTF7EI8g5Plvtj0As+djrB/UwVt9VpttO6NR2AiAk32rpMFqPGr4S6veJOBO5sa7rpeFcDusStwl1rX7IDPr7SoSQbuhhS4ExGRzAiNTjM4MceWaq/do6xaKix4+NIQ8/GE1snKqilwJ84UCMJkPyzO23P9f/1d+MuH7Lu+iIiIiEgGXB6aYmhynkNaJ3tH1xvuHBi4633RnJsftneOfOEphPpdEHkZLMvuaUREcoplWXSGxmhv8K9ojVBHo5+E5dBgu4P8y8kwc4sJ3v/AZrtHEScIOScQVJtaKTuhwF1eKE+ulJ2yJ3CXajyt95fQOzxNPGHD9+ShY+bMl4a7is3gKYJBrZQVEZHM+NKpKABv29lg8ySr15hsuHvhvPkeqKNRgTtZHQXuxJn8TYAFE9HsX3t+Cr7/VzDQBZe/nf3ri4iIiIhkyLErIwAK3N1FpbeIOn+xM1fK9hyGkgDU7bB7kvwRPAAzozB6xe5JRERySmh0htHpBXY3BVb0uFRzQJfWyt6RZVk8deQqvpIC3r4rd29iSRqlAkFB+wN3qfVb0diMzZNIWpRUmHCWXQ13kXEKPS7e0lHLfDxBZMyGP1ehY1DoNSub84GnADZsV8OdiIhkzLMnwwRKC3l9S43do6xaja8Yj9vF6PQCgBruZNUUuBNnCgTNGQtl/9pnvwDzE9f/XUREREQkTxztMYG7g80K3N1NW72fi/2TLMYTdo9y3dwkRE/CpteA22P3NPmjcb85wyfsnUNEJMecCccA2BVcaeDONMl2K3B3RyeujnG+f4LH9wUpLdLf+QKEX4Ki8uurIm1UWVZIaaGH0KgCd3nB5QJvja0rZbfX+mipM3839Axnea1sIm5eBzTuM0G1fFHdAqO9sKDPUxERSa/zfROc65vgbbsaKCrI3aiRx+2iLtncXFLopnlD7q7HFXvl7meB5Dd/MnA3Hs7+tU88CQWl5h1N574MC7PZn0FEREREJAOO9YywpdpLTfIHCnJ7bfU+5hYT9AxP2z3KdaGjkFiEZq2TTaugAnciIqtxOhW4W2HDXbCiFH9JgQJ3d/H00asAPPHAJpsnEUeIL0LkZfM9iwPedOFyuWiqLCWswF3+KK+FqcGsX3Z0ap5obJaOBv/STe4rQ1kO3A2eg/lJR6xrTquaVsCC4Ut2TyIiInnm2ZMmu/HY3kabJ1m7hgrT3NxW78fjdtk8jeQqBe7EmQJN5sx2w91AN1w7AjveBft+HObG4ZVvZXcGEREREZEMiMZmuDYyw8HmSrtHcbzWetOwcL5vwuZJXqXnsDk3v8beOfJN1TYoDpjmGBERWbYz4RglhW6215Sv6HEul4v2Bj/d0QkSCStD0+Wu2MwCz52OsG9TBW31WmskwGA3LEw7Yp1sSlNlKaGxGX0O5wtvMnBnZff/n6ngdUejny3VNgXuUuuamw5m97qZVt1izkGtlRURkfSxLItnT0ao95dwKA+2pzQESgCtk5W1UeBOnCkVuMt2w92JvzPn/g9Ax7vMv595JrsziIiIiIhkwNErZp3soS0bbJ7E+VI3uM/1Oah9p/cwFPmgfo/dk+QXtxsa90L0lGmQERGRe7Isi9OhGB0Nfgo8K//xcnuDn8m5Ra2kvI1nT4aZXUjw/kNqt5OkpUCQcwJ3wcpS5hcTDE3N2T2KpEN5DcTnYXYsq5ftSgXuGvw0VpRS5HHTY1vgzjmfX2mRWj89dMHeOUREJK+cuDpKeGyGd+5txJ0HjXCpwF1Hg8/mSSSXKXAnzuStBXchxLIYuFucg1NPw4b7YNNDULERmg7B+a/CvINWSYmIiIiIrMKxnmTgLg/egZhp22q9eNwuzjml4W5hxjSwbXoAPAV2T5N/ggdgccaslBIRkXu6NjJDbGaB3U0Vq3p8R7JBoEtrZW9gWRZPHbmKr6SAR3fn/oomSZNQsoXXUQ13ZQAKzeYLb605J7O7VrYrcj1w53G72LyhzIaGu+MQ2AS++uxeN9M2bAdcargTEZG0evZkBIB37smP1yrtDX5cLjiwWT8rl9VT4E6cye0GfwOMZ3Gl7LnnYGbEtNu5kqnsnY/DwhRc/Hr25hARERERyYBjV0ap8xezsarU7lEcr7jAw7Yar3NWyoaOmdaJzQ/bPUl+Cu43p9bKiogsS2c4BsCuYGBVj+9oNIG7bgXubvDytTHO9U3w7n1BSos8do8jThFOBYLq7J5kSbDCvJ5Q4C5PlCcDd1MDWb1sV3ScYEUpgbJCAJqrvVwbnWEhnsjOADNj5g03+dZuB1BYCpWb1XAnIiJpsxBP8OXTUbbVeNnRmB8rWN+1N8i//8qbll6fiqyGAnfiXP4miGUxcHfiSdOqt+eJ67/W8S7ABWe/kL05RERERETSbGx6nvP9ExxsrsLlyv3K/2xorfdzdWSayTkHrBnt/a45m19r7xz5qjEZuIucsHcOEZEccTps1g7ualpd4G57bTket0sNdzd5+shVAH7soNbJStJszDRUNR2we5IbNFWawF1YgTvbfaUzuvY1rN4ac05mL3A3txjn0sAk7Q3Xb3BvqfYST1jZC3KmvvdvOpid62VbdSsMX4K4A17PiohIzjt8aYjhqXke2xvMm58tu90uNlaV2T2G5DgF7sS5AkGYGc3OOteRK3D5BWh7G5TXXP91fwNsfg1c+BrMTWZ+DhERERGRDDjWMwrAA1tUkb9cbfU+AC70O6DlrudFKCyDhr12T5Kf/I1QXg9hBe5ERJajMxSjtNDDtpryVT2+pNA0yarh7rrx2QW+dDrC3o0ValiQ68InAMtR62Th1Stls/Bze7mjL56K8POfO8EfPX9ubU+01HCXvZWyF/snWUxYdDT4ln5tS7UXgCtDWboPEzpuznwN3NW0mJb0sV67JxERkTzwxTxbJyuSLgrciXP5g+YcD2f+Wi9/1pz7P3Dr7+14NyzOwIXnMz+HiIiIiEgGHOsZAeCgAnfLlgrcnYvaHLhbnDMrZZsOQkGRvbPkK5fLrJXtPwsLamoREbkby7LoDMfYGfTjca++2aC9wU9odIbx2YU0Tpe7nn05zOxCgvc/oHY7eZVwKhDkrMBddXkRxQVuwmP6vskuodFpPvGFTgBOXhtb25N5k4G7LDbcpQLXrw4YN29IBe6yFOQMHQNPETTszs71sq261ZyD5+2dQ0REct7MfJyvne1jz8YKmpMBeRExFLgT5wo0mTPTa2Xji3DycxDYBFvffOvvdzwGLrfWyoqIiIhIzjp6ZYRAaSEttb57f7AA0JoM3J3vs7l9J3wCFme1TjbTGveDFYe+TrsnERFxtN7haSZmF9kZXN062ZSO5BpB24PtDmBZFp87chVfcQGP7m6wexxxktBL4C6Ahj12T3IDl8tFsLI0e6s/5QbxhMV//fwpJmYXaakrJxqbZWB8dvVPuNRwl73AXWqleEfD9b9LUg13a16RuxyWZQJ39buhoDjz17NDTTJwN6TAnYiIrM23zvUzNR/nMbXbidxCgTtxrlTgLtMNd5e+ARNR2PcT4L7Np0R5rbm5dfEbMKtVFyIiIiKSW6bnFzkTjnH/5krca2iiWW+CFaX4igs412dzEKD3RXNuftjeOfJdcL85wy/ZO4eIiMN1hmMA7G5aW+CuPRm464rE1jxTrjt5bYxzfRO8a1+QsqICu8cRp7As03BXtxMKS+2e5hZNlWWERqexLMvuUdadv/q3VzjaM8JPvqaZD76mGYBToTV8LS2pMMHOyeytlO2KjOMrLqCp8vqf7Tp/MaWFHq5kI3A3chlmRvN3nSxAdYs5By/YO4eIiOS8Z09GcLvQm4NEbkOBO3Gu1ErZWIYDdyeeNA12+378zh+z43GIz8H5r2R2FhERERGRNHv56hiLCYtDWie7Ii6Xi9Z6H+f6Juy9kdhzGDzFEDxg3wzrQeM+c4ZP2DuHiIjDpQJ3u9bYcJcK3HWr4Y6nj14F4IlDWicrrzJ2FaYGHbdONiVYUcrsQoKRqXm7R1lXTl4b45PfuEBrnY+P/3Abe5oqADgdWsNaWbcbvDVZa7izLIuu6DhtDb4b3hDmcrlorvZmJ3AXcua65rQqrYDyOjXciYjImsSmF3jh/ACv2VZNrb/E7nFEHEeBO3GupZWy1zJ3jfEoXPgabH/L9evdTvs7weXRWlkRERERyTlHr4wAcFCBuxVra/ARm1mgf3zOngHiC3DtqGleKNQPtTKqrAqqtkJEgTsRkbs5HRrDW+RhS3X5mp6nxldMja+YbrtXt9tsfHaBL52KsmdjBR2NfrvHEScJHTNn0JmBoFQzmdbKZs/U3CK/+Pcv43a7+PQTeykp9NBa76O4wM3Ja2sI3IEJ3GWp4S48NsPE7OLSavFX21JdRiQ2w+xCPLNDpD6/8rnhDkzL3eAF05gpIiKyCl89E2UhbvHOvVonK3I7CtyJc5VWQkFpZlfKnvwcWHHY/4G7f5x3A2x9A1z6lqkaFxERERHJEcd6RigpdLOzcW1NNOtRa32yfceuMED0FCxMQbPWyWZF434YvgQza7xhKSKSpxIJi7PhcXYEA3jSsKa+vcHP+b4JFuOJNEyXm75wIszMQpwfV7ud3Cy15t6hgSAF7rLvt750lp7haT7+SBttydcphR43HY1+OsOxtbVyl9eahrssBLO6Iua11e1CxluqvVgWXB2ZzuwQoWPgrYWKPP/aW9MK8xMwEbV7EhERyVHPnoxQVODmkZ31do8i4kgK3IlzuVwQCGZupWwiAS//nXlh1fLIvT9+x+OQWIBzX87MPCIiIiIiaTa/mODE1VH2baykqEAv/1aqrd4HwPk+m9bd9bxozs0K3GVFcL85Iy/bO4eIiEP1DE8xMbe45nWyKe0NPuYWE9lZH+hAk3OL/Pm3L7HBW8SjexrsHkecJnQcSipgwza7J7mtVOAuPJbhYJQA8JXOKP9wPMQbWmr4qYebb/i9PU0VjE0vrC2k5q2FxVmYy/wbjbqi5hrtt2m4a97gBcjs3wvz09B/xoRZXWsPjztadas5B7VWVkREVq4vNsv3rwzz5tZa/CWFdo8j4ki64yLOFmgyDXeZeGdVz7/DaA/sfT94lvGXRPuj4C6EM8+kfxYRERERkQw4E4kxu5DgkNbJrkprMnB3LmpTw13vYfMaxKHNJnkneMCcWisrInJbneEYALub0hO4S60T7LLr71mb/cW3LzE4Mccv/VArZUUFdo8jTrI4b5qOgwccGwhqqiwD1HCXDdHYDP/tmU6qvEX8Xz+yG9dNfyb2bDRfk9e0Vra8xpxZWCvbHR3H43bRUue75fe2VJvAXU8mA3fRU5BYhCZnrmtOq5oWcw5dsHcOERHJSc+djmBZ8JjWyYrckQJ34mz+JpifhNlY+p/7xJPmvNc62ZTSStj2Zrj8AkwNp38eEREREZE0O3ZlBECBu1XylxQSrCjlnB0Nd4k4XP2+aV0rKsv+9dej+t3g8kBYgTsRkdvpDJmfz6Wr4S4VuOuO2tQka6Orw9P8r+9cob3Bz/sObrR7HHGa/k6Izzk6EFRTXkyRx63AXYbFExb/9fOniM0s8Mfv2U2tr+SWj9nTVAHA6dAa7qF4a805NbD651imrug422q8lBR6bvm9VOAuow13oWPmdPDnV9pUJwN3argTEZFVePZkBF9xAW9qq7V7FBHHUuBOnC0QNOd4mtfKTo9A95eg+XUrq+Xf+ThYcej+YnrnERERERHJgGM9IxS4XezbVGH3KDmrrd7HK4OTLMQT2b1w32mz0knrZLOnqAxq2xW4ExG5g9PhGOXFBUsr/9ZqS7WXogI33euw4e73v9LNfDzBbzzagcftzAYzsVHoJXM6uOXY7XbRWFFCWIG7jPqf37nM9y4P8xMPbuItHXW3/ZjmDV58JQWcWlPDXfK5JzMbuIvNLHBtZGYpcH2zKm8RvpKCzAfuXG5o3Je5aziFrwGKfGq4ExGRFXtlcJLOcIy37qy/bUheRAwF7sTZ/MnAXSyU3uc99fcQn4f9H1zZ41p/GDxFcPYL6Z1HRERERCTNLMvieO8oO4IBrSlbg9Z6Hwtxi8uDGbzpczs9h83ZrMBdVgX3w0QExqN2TyIi4iiJhMXZcIydQT/uNAXECjxuWut8626l7PdeGeb5s308sqOeh7ZtsHsccaLwcXOm1t07VFNlGaHRaSzLsnuUvNQZivEnXz/P9tpyPvG2jjt+nNvtYk9TBWciMRZX+yah1ErZqcyulD2X/HrffofAncvlYku1l57hTAbujkNtBxTfutI277hcZq2sGu5ERGSFvngyAmidrMi9KHAnzhbIQODOssw62ZIKaH/Hyh5bEoDtPwg938n4u71ERERERNYiPDbD2PQCe5rSs/ZtvWpL3gw615flMEDvd816040PZPe6613jfnNG1HInIvJql4emmJqPs7spva257Q0+BifmGJqcS+vzOlU8YfHbz3VR5HHza29rt3sccarQcajaCmVVdk9yV8GKUqbm44xNL9g9St6Znl/kI59/GYBP/9heSovu3iyzuynA7EKCC/2Tq7tgaqVshu95pBpNOxpvH7gD037aPz7H1Nxi+geIhc2ba9bDOtmU6lazKnhm1O5JREQkR1iWxRdPRaguL+ahrXqDkMjdKHAnzuZvMmc6V8qGjsFgN+x+HxSWrPzxOx8HKwFdz6ZvJhERERGRNOuKJG9m3KE9QJanrd40H5zrm8jeRRMJuPpdaNy7PpoXnCSYDNxprayIyA06w2ZV4c5geoP8qe9T1sta2X84fo3u6Dg//dotbNpQZvc44kTTIzDyCgSdHwhqqiwFzBt9JL1+57luLg9O8bG3trGj8d5fd/dsNGHo06FVrpUtTwbupjIbuOu6R8MdsLS2PCMtd6Fj5nTwuua0q2kx56DWyoqIyPJ0hmNcGZri0d0NFHgUJxK5G32GiLMtNdylMXB34m/Nuf8Dq3t8yyNQUKq1siIiIiLiaF3LaA+Qe9tS7aXQ4+J8NgN3A12mgWDza7J3TTFqO6CgBMIv2T2JiIijdIbM9xW70xy4S4UuUm8UyGfjswv8j6+dp7q8mF9483a7xxGnSn0PkgMNXE1VJnAXGp22eZL88rWzfTx99CoPb9/Af3jtlmU9Zk+yffTUagN3pVWmXXsysytlu6Lj1PqKqS4vvuPHbKlOBu6GMvDnaj0G7qpbzTmktbIiIrI8z2qdrMiyKXAnzlbsM2tc09VwNzsOZ56B4AGo37nKmcqh5YfMiqfxaHrmEhERERFJs67IOB63i5Y6NaStRaHHzfZaH+ey2bzTe9icm1+bvWuK4SmE+t0QeRksy+5pREQcozM8hq+kgM1pbmVrW0cNd3/+r5cYnprnY29tpby4wO5xxKlCx82ZA4G7YIX5ehAaVcNduvSPz/Lxfz5NRVkhf/Ije3G7Xct6XH2ghDp/MaeuxVZ3YbcbvNUZbbhbiJuVt/d6Q1gqcHdlaJXrce8mdByKA7DhvvQ/t1PVJAN3gwrciYjIvcUTFl86FWFTVRl7kw26InJnCtyJ8/mbIBZKz3Od+WdYmIb9H1zb8+x4N2BprayIiIiIOFZXdJxtNV5KCj12j5Lz2up9RGKzxGYWsnPBnhcBF2x6MDvXkxsFD8DsGIxctnsSERFHiCcszoTH2RUM4HItL/yxXIHSQoIVpXRHs9gka4MrQ1P878NX2Bn0894DTXaPI04WPg6eYqjbZfck95RaKavAXXokEha//I+nGJ1e4A8f3019oGRFj9/dVMH5/glmF+KrG8BbC5OZC9xdHpxifjGxtEr8TpqXAndpbrhbnIfoSWg6YAKG60XFZvAUwZBWyoqIyL0duTzMwMQcj+1tTPtrP5F8tI6+q5ScFQiahrtEYu3PdeJJKPTCzsfX9jz3vdU8z9ln1j6TiIiIiEiaxWYWCI3O3PNmhixPW71pCbzQn4UwgGWZNu36XVCqd5LaIrjfnOET9s4hIuIQlwcnmVmIs6spvetkUzoa/bwyOLn6kEgO+L0vd7MQt/iNR3csu7FK1iHLMg1cDbuhoMjuae6pzl9CgdulwF2a/L+Hr/Cdi0M8cWgjj+ysX/Hj9zQFiCcszkZW2XJXXgNTmVsp2xU1c92r4S5QWkiVt4ie4an0DtB/BhZn19c6WQBPAWzYroY7ERFZFq2TFVkZBe7E+fxBiM/D9NDanqevEyInTNiueI1rtYrKoPURuHYkfe17IiIiIiJpklrLdq+bGbI8rcnAXVbWyg5dMK99mrVO1jaNycBdRIE7ERGA0yETktgVzEzgrr3Bz2LC4tJABtYHOsCLF4f4Znc/b9/dwKEtVXaPI042/Ipp2Q06f50sgMftoqGihPCYAndrdTYS44+fP8/Wai///dGOVT3HnuTat1WvlfXWmu1Ac5n5WtwVMa+l2pfxprAt1V6uDKU5cLe0rnmdBe4Aqltg7Cos6HNVRETubG4xzlfOROlo8LO9AK/9ygAAIABJREFUdo1ZCpF1QoE7cb5A0JxrDbadeNKcB35ybc+TsiPZknf2C+l5PhERERGRNEndzOhoyMyN8fWmrd7cFDrXl4WGu54Xzbn54cxfS26vaiuUBNRwJyKS1Bk24Y3dwcw0r3Y0mJs5XdkItmfZYjzBbz93lqICNx9/pM3uccTpwqlAUG4E7gCaKsoIjaZ59ec6MzMf5yN/f5KEZfGpH9tLWVHBqp4n9TX6VGhsdYOU15hzKjNrZbujE5QWemje4L3xN64dg8/9KHz143Di7yB8gvsqPYxMzRObXkjfAKFj5gweSN9z5oqaVsCCoYt2TyIiIg72wvlBJmYX1W4nsgKr+85dJJsCG805Hr6+2melFmbg9OehtiN9L6i2vwWKfHDmGXjNf0nPc4qIiIiIpEHqhnV7g96NmA51/mIqygqzE7jrPWzOTQ9l/lpye243NO6Dq0cgvmjWMImIrGOd4RiB0kI2VpVm5PlTbxDozsPA3dPHrnGhf5JfeNN2NlaV2T2OOF0oBwN3laV87/IwsZkFAqWFdo+Tk/7gq91cGpjkY4+0srtp9cHmQFkhW6q9S62kK+atNefkoHkDShpZlkVXdJy2Bh+em9dqf+u3oOc7N/zS7+PmZ4rqsP5hH2zZB3U7zD+BTeZ79dUIHzerVcvWYdNodYs5hy6YldUiIiK38cXkOtl37FHgTmS59FNjcT5/quEuvPrn6PoizMbgjb8GLte9P345Ckug7W0myDdyBaq2pOd5RURERETWqCsyTr2/hA3lxXaPkhdcLhetdT7ORsaxLAtXul5T3MyyoOeweaOQd0NmriHL07gfLr8Ag91Qv8vuaUREbLMYT3A2EuP+zVUZ+/uvqbKU8uKCvAvcxaYX+NOvn6fWV8x/euM2u8eRXBA6BmXVULHZ7kmWLVhpgrjh0RkF7lbhW939PPm9Xh7cWsXPvn7tXyd2NwV49mSE2PQCgbIV/v+jPBm4y0DDXf/4HCNT8zyys/6m3zhrwnY73ws/8N/N/91/lv4Lx+HaaQI9X4Wer1z/+CIf1HVcD+DV7YTadtNOfTdTwzByGfY8kfb/tpxQ02rOwfP2ziEiIo41MbvAN7v7ObSlisaKzLzRSiQfKXAnzpdaKTu+hpWyJ54ETzHs/tH0zJSy43ETuOv6F3jtR9P73CIiIiIiqzC/mODiwASvu6/G7lHySnuDnyNXRgiNzmSuoWbkMkz2Qfs7MvP8snypZvTwSwrcici69srgFLMLCXY1ZW5Nvdvtoq3eR1emg+1Z9ulvXWR0eoE/+ZE9eIv1Y3i5h4UZ6D9jtqrk0OdAU6X5vjg0Ok1Ho9/maXLLwMQsH/un0/hLCvjTH917a/PbKuxpquDZkxFOh8dW/nrQm/z4yf41z3Gzrqhp3etouOnPyJG/NueD/wkqm80/bW9n5L4Yb//Mi/zSGzfyX3YtLAXxzD9n4NqRG58nsOlVIbxkEK9q6/Wm6hxc15xWG7YDLhhS4E5ERG7v62f7mVtMaJ2syArplb4431LD3SoDd0OXoPdF8y6pdNeFb3uzeffUmWcUuBMRERERR7g0MMlC3Lr1ZoasSWu9Wc97vm8ic4G7nhfN2fxwZp5fli+435zhE3DgJ20dRUTETqdDYwDsCmYucAcm2H68d5RIbJZgHjQqXBqY5Mnv9bBnYwXv3he0exzJBdHTkFjMuUBQ6vM1NDpj8yS5xbIsfuUfTzM8Nc9fvH9/2ppk9mw0X6tPXVtF4K78VStl06w7OgFwYyhzegRO/4Nplr7pz33zBi8AF0fj5o0wqTfDgGkFn+i7Hr5LBfEufQMufPX6xxWUQE2bCd9NmBV5NB1M+39bTigshcrNMHjB7klERMShnj0VocDt4m07G+weRSSnKHAnzldQbN5dtdqVsi8/ac4DH0zfTCkFRdD2Djj5WRh+BTZoPYSIiIiI2KsruY5NDRPp1ZYK3PVP8JaOusxcpPe75tyswJ3t/I3ga4DICbsnERGxVWfYtBJlOnCX+r6lOzKeF4G73/tyF4sJi994tAN3GlqrZB1INXAFcytw15RaKTumwN1K/O13e/i3C4O890ATb9+dvhvbOxoDeNwuToViK3+wN3MrZbsi47hc119TAfDy38HiDDzwc7eOUlxAnb+YnuGpW5/M5QJ/g/nnvrdc//XFeRi6YMJ3A69qxIueNL9fHIDajjT/l+WQ6lZ45V8hvni9+U9ERAQYnJjj8KUh3thSQ6W3yO5xRHKKvquS3OAPwvgqAnfxBTj5FFRugc2vTf9cADvfbQJ3Z56BN/xKZq4hIiIiIrJMXZFk4E4Nd2nVUmduDnUnA40Z0XsYqluut0uIvRr3w4XnYX4aijLUaigi4nCd4RiVZYVLoZpMaU9+39IdHc9csD1LXjg/wLfPD/LY3kYObK60exzJFaFjgOt6y26OaAiU4HG7CI1O2z1KzjjXN87vf/UcmzeU8X++c0dan7uk0ENrnY9T18ZW/mBvNbjcMJmBwF10nC0bvJQVJW9JJuJw9G9M0cKOd932Mc0bvHRFV7BqvKAI6neaf15tatg04XmrwVO4xv+SHFbTAhe/BqM9UL3d7mlERMRBvtIZJZ6weEzN3CIr5rZ7AJFlCTTBRNS8+2Ylzn8VpgZh/wfAnaE/7lveAKVVcPaZzDy/iIiIiMgKdEVjeIs8bMrU2tN1yltcwKaqMs73TWTmAqO9ELsGm1+TmeeXlQvuAysOfZ12T5J/pobhu38Of34IPrUb5m/TXiIitluMJ+iKjLMzGFhe2GENWut8uF3Xm3pz1UI8we8810VJoZtffaTN7nEkl4ReMm+8KMlsm2S6FXjc1PtLtFJ2mWYX4nzk6ZPEExafet9eyovT34mxZ2OAgYk5+mKzK3ug2wNlG8z9lDSamlukZ3iK9lc3sJ//KsSuwv0/bTYc3cbWGi8Ts4sMT82vbQDvBtj6BqhLb7gx51S3mnPovL1ziIiI4zx7MkxZkYe3tOsNwCIrpcCd5IZAE1gJmOxb2eNOPAkuD+x9f2bmAvOuqPZ3wEAXDJzL3HVERERERO7Bsiy6IuO0N/i1viwD2up9XB6aYm4xnv4n7z1szkw1c8vKBQ+YU2tl0yORgMsvwD/+FPxpG3z9EzB6BcZ6TTO9iDjOxYFJ5hYT7G7KfACotMhDc7U3s02yWfC57/fyyuAUP/v6bTTmwWpcyZLJARM+ajpo9ySrEqws1UrZZfqj589xvn+CX/yB+9i3KTMNmHuaKgA4FVpNy11t2hvuzvVNYFk3NbAf/WtwF8CBn7rj45o3eAHoGdIbM9KiJhm4G1TgTkRErrs6PM2Jq2P8UEfd9SZaEVk2Be4kN/iTFaaxFayVHbsGl74JLY+Arz4zc6XsfNycZ7+Q2euIiIiIiNxFeGyG8dlFdjRqnWwmtNX7iCcsLg1Mpv/Je5KBu+aH0//csjqN+8wZfsneOXLdRD9850/gz/bDk4+ZdviND8DjfwO/dB5KK+H7f2kCeSLiKJ2hGAC7ghVZuV5Hg5/ekWkm51a44cIhRqfm+eQ3L9IQKOHn3rDN7nEkl4SOm7PpgL1zrFJTZSlj0wtMzC7YPYqjvXB+gP99uIeDzZX8/Jsyt9Jzdypwt5q1suU1aW+4SzWXLgXu+rvgyr9Dx7vA33DHxzVXm8DdFQXu0qO6xZxDF+ydQ0REHOVLpyMAPLZX62RFVkOBO8kNgVTg7tryH3Pyc4AFBz6YkZFusPm14K0xNw4sK/PXExERERG5ja5I8maGAncZ0Za8SXQumoG1sr0vQuUW8Dem/7lldUoroWorhNVwt2KJOFz8Bvz9j8MnO+Bbvw3zk/DwR+C/nICffA52/wiUVZlVYiOX4cLzdk8tIjc5HTZhjV1ZaLgDaG/wY1lwvi83W+4+9c0LxGYW+PgPt1Fa5LF7HMkloWPmDN5v7xyr1JRsc1TL3Z0NT87xy/94Gl9xAX/6o3vxZLCNvKWunJJCN6eToekV8daa79nmp9M2zy2vUY/+P+Z84Ofu+ritCtylV2kFlNep4U5ERJZYlsW/vBymsqyQ195Xbfc4IjlJgTvJDf4mc44vs+EuEYeXPwu+Rtj2A5mbK8VTAB2PmXcH9Z/N/PVERERERG7jentAdm6Mrzet9T4AzvenOXAXC8Noj9rtnCh4AEZegZlRuyfJDbEQvPCH8Ok98Ln3wrkvw5Y3wI8+CR/tgh/8bdhwU+vTwZ8Bd6FpuRMRR+kMj7PBW0RjoCQr10u1H3VlItieYRf6J/jskavs31TBO/coPC8rFD4OhWVQ22H3JKvSVFkGQHhUgbvbsSyLj/3TaYYm5/jdd+9kY1VZRq9X4HGzszHAqdAYicQKywHKa805lb61st1R83dJra/YfE99+vOmSbrp7gHTjVVluFzQM6zAXdpUt8DQRZVGiIgIYNa+XxyY5O27Gyj0KDYkshr6zJHcEFjhStlXvm3a8Pb9hAnDZcOO1FrZZ7JzPRERERGRm3RFxvG4XdxXV273KHmpeYOX4gI35/rSHATo/a45N782vc8ra9e435yRl+2dw8niC9D9HHzuR+BTu+CFPzBvgnv9x+Ajp+D/eMa8Qa2g6PaP9zfArvdCz3cgcjK7s4vIHc0vJuiOjrMzGMDlylwT06u1JwN33dHcarizLIvfea6LeMLiN9+xI2v/e0meSMQh/LIJIGXr59hp1lRpGu5CCtzd1mePXOVb5wZ4975g1ta17dlYwcTs4srDat4ac06mZ61sPGFxrm+cjka/+dr48mdhYdq0293ja2VJoYfGQClXhtLXtrfu1bTC/ASMR+yeREREHODZk1onK7JWywrcffjDH6a5uRmXy8WZM2cAmJ2d5V3vehctLS3s3buXRx55hJ6enqXHvPGNb2Tr1q3s3buXvXv38slPfjIj/wGyTpTXg8uz/Ia7E38LuEzgLls2PWjmPKO1siIiIiJij67oONtryikp1BqzTPC4XbTU+TiX7iBA74vm3Pya9D6vrF3wgDm1VvZWI1fgm78Fn9wBn/9xuPQtaHkEnvg8/GInvPkTULl5ec/14M+bUy13Io5xoX+C+cUEu7O0Thagzl9Mlbco5wJ3/3pugO9cHOLx/UH2bKywexzJNUMXTAAm9T1HDgpWaqXsnVwamOB3n+uiqbKU33psR9aum/rafSo0trIHprnh7srQFLMLCROoTsTNOllvDex497Iev7XGS8/QFJbut6RHdas5h7RWVkRkvUskLL50KkKwopQDmyrtHkckZy0rcPfe976XF198kc2bb/xB6Yc+9CHOnz/PyZMnefTRR/nQhz50w+9/5jOf4eTJk5w8eZKPfvSj6Zta1h9PAfgazHqae5kcgPNfga1vXP4P99PB7YEd74LRKxDVu/JFREREJLtiMwuERmfoaPTbPUpea633MTAxx8jUfPqetOcwBDZm9/WLLE/9LvPmLwXujMU58yazJx+Dz+yFF/8UCorhTb8OHz0DTzwNrY+svKGnYTc0vw7O/LMaN0Qc4kw4BsCuYPYCdy6Xi/YGH+eiE8RXugbRJvOLCX73y92UFnr42Fvb7B5HclHomDnvsV7TyRoCpbhcEBpVE9mrzS3G+fDTJ1mIJ/jU+/biLynM2rX3JsO/p67FVvZAbzJwN5mewF0qQN3R4IcLX4Oxq3Dgp8z3j8vQvMHLzEKc/vG5tMyz7tW0mHPwgr1ziIiI7V66Okp4bIZ37GnE7VZDt8hqLStw9/rXv56mpqYbfq2kpIS3ve1tSxX5Dz74IJcvX07/hCIpgeDyGu5OPQ2JRTjwwczPdLOltbJfyP61RURERGRdu+FmhmRMW70PgHN9aWrfmeiH4Yuw+eH0PJ+kV1EZ1HZAZJ0H7oYuwtc+AX/aDv/0UyYk2vEY/MQz8OFT8IZfAX/j2q7x0C+Y1/JH/2d6ZhaRNTmdCtxlseEOoL3ez8xCnN6VrkG0yZPf6+HK0BQ//8Zt1AdK7B5HclHouDmDuRu4KypwU+8v0UrZm3zqmxfpio7zC2++j/ubq7J67U1VZVSUFa6i4S65UnYqPStlu1KvURv9cOSvwF0A9//0sh/fXO0FTFOepMFSw50CdyIi692zJ03m4rG9a/xZjsg6t6zA3XJ85jOf4R3v+P/Zu/PwOO/y7PvfGe0ajfZdY1teYluyJTl2VkIggUBCiB0gJAHaUqDsS5+2dH3pQwstPPR9W9pSkrakD5TQEpKQlNgJIQmQhGyQ2I4lO5JXedO+a7SORjPz/vHTeEm8aJmZ3yzn5zhy3I40mrkS29LM3Nd9nlvP+tif/Mmf0NDQwJ133nnBZbxvfvObeDyeU/+Mj49HaixJJvk15oWef/r8twmFYPe9kFsC626O3Wxhnssh32MW7hRzLiIiIiIx1Np1xskMiZr1leb/74Gescjc4fEXzLFWC3dxq2YzjHWnXvJaMAgtD8B33wXfvgxe+jZkF8I7vgp/1AZ33Atr3g7OCL21dMk7oWQN7PwuzOikqoht+zpHKc3LojI/tktk4ecxbd0R+jkbRYPjPv75F4eoKczhE29ZZXscSVSdu8BdbS42T2A1hTl0auHuLI/v7cZTlMPvv21NzB/b4XDQ6CmktcuLPxCc/xdGOOGutctLZrqTVaGTcPRZc8FGftW8v36VFu4iy10JWflauBMRSXH+QJDHWrpZW5F36sJiEVmciLwr+vWvf51Dhw7xta997dTHfvCDH9DW1kZLSwvXXnstt9xyy3m//o/+6I/o6Og49U9eXl4kxpJkE37T4UIpd8dfhMHD0PTBeceSR5TTaWplR06YN0tERERERGIknB5Qp4S7qFpfNZdwF6lFgOMvmqMS7uJXzWZzTLVa2VfugYc/YV7bNtwBH3kMvrALrvlfp9NPIsnphKs+A9MjsOeHkb9/EZk332yAtm4vjZ6CU+0msRJ+HhNO7o1n33zqIGPTs/zFzevJzkizPY4kIt849LWCZ4vtSZbMU5TD4MQMkzOztkeJC6FQiF6vj1VleaSnRSz3YkGaPAX4ZoMLu1DIVWqO470RmaG128u6CjfpO+cSjK/41IK+PpxwdyxBUk/jnsMBpWuh/4DtSURExKLnDvUzPOnn1k01MX+9J5JslvxM/+///u95+OGHefzxx8nNzT318WXLlgHmSprPf/7ztLe3Mzg4uNSHk1SWP1drfKGFu933muPmD0d/nvMJ18rue9jeDCIiIiKSclq7vFQVZFPsyrQ9SlIrzcuiNC+T/b0RTLhzV0GxknHiVvXcwl2q1cq++gPIKjBpdrfdA7VvNifpoqnpg5BTBL/+V5OwJyJWHOwZxx8IsbEmtnWyAKvL8shIc5y6kCBetXV7ue/lE1xRW8y7G+af1iRylu49EAomdJ1sWE1RDoBS7uaM+WaZ8geocFsIBZjT6CkEWFitbFoG5BRHpFK2f8xH/5iPzeUOaP4RVG2CZVcs6D48RTmkOR1KuIuksnUw0QdTw7YnERERSx7ZYxoctjWpTlZkqZa0cPfNb36T++67j6eeeorCwsJTH5+dnaW39/QVMA899BAVFRWUlJQs5eEk1RXMLdyNnmfhbmoYWn8Cy682LxpsqdkMhStMraxOEIiIiIhIDMzMBjnUN0a90u1iYl2lm4M9YwSDoaXd0cSgSTVZcU30F5lk8crrID0ntRLueluhZy9suBVcMXwvJ9MFl30Mho7AoSdi97gicpa9naMANFpYuMtMd7Km3B3XCXehUIi/ebSVEPDlrfVKhZDF63jFHD2Jv3DnKTJhDB0jWrgD6PNOA1AR41ruMzV5zPfwlpOjC/vCvPKIVMqGv4/fEvgF+Cfhyk8t+DVPRpqT5cW5WriLpNK15tivWlkRkVQ0OTPLk6/1snl5IcuKcy/+BSJyQfNauPvc5z6Hx+Oho6ODG264gTVr1tDR0cEXv/hFRkZGuP7669m0aRNXXnklAD6fj3e/+900NDTQ1NTE3Xffzfbt26P6HyIp4FSlbMe5P7/3xzA7bTfdDsyLxg3vhbEu6HjZ7iwiIiIikhIO95kkmvpqLdzFwvrKfKb8AU4MTS7tjk6E62TftPShJHrSMqCq0STchZa4ZJko9j5gjo13xv6xL/8EODPgpbti/9giAsDeTpOG1OCJ/cIdQH1VPt2j04xMzlh5/It5srWXF48McvsWj5UUQEkiHTvB4TTJXwnOM5dw16GEOwB6vT4AKvLtJdyV52dTVZC9sIQ7AFdZRBLuWru9OAnS0PUg5JaebgZaoNqSXE4MThJY6sVOYoTDKgZUKysikoqeau1lyh/g1k01tkcRSQrp87nRXXfdxV13vfGNztB53mh2uVzs3LlzaZOJvF7+BRLuQiHY9X3Iyof6W2M717lsfB+88E+mVnb5VbanEREREZEkF65dU8JdbKyrdAOwv2eM2lLX4u/o2AvmWPvmCEwlUVWzBU7+BobaoWS17WmiKxiElgfNa/DlFpZB86tg423Q8iPo2gPVib+EIJJoWjpGKXdnWUtmqqsyP2dbu728aXWplRnOxzcb4Os/bcOVmcYf32ixYUOSQ+cuKN8AWXm2J1mymsLwwt0SL0hJEr1zCXflFhPuAJo8hTzZ2sPkzCy5mfM6HQh5FeDzgn8aMhY/f1u3l+udr5I9fgKu/eNF31dtqYunD/TTNTKlJJ5IOJVwp4U7EZFUtH1PF2lOBzc3VNkeRSQpLKlSViSmXKWQlgWj50i463oVevdCw+2mgsa2ykYoXm0qboMB29OIiIiISJJr7ZpbuFPCXUzUVZr/z/t7llh3d/x5kyARPukh8at6szl27rI7RyyceNEkyzfeDk5Lbxtd/Vlz/PXddh5fJIVN+wMc7B2j0VK6HZy+gCD8/CaefO+FYxwfnORzb1tDudvuIo0kuNFOGOsGzxbbk0RE9dzCXacS7oAzE+7sfp9oXFZAMAT7Ohfw/TSv3BwnllYr29rl5dPZPwdHGlz+e4u+n1VzFzipVjZCimrNebYBVcqKiKSa4YkZnj3YzzVrSilz20vhFUkmWriTxOFwQH41eM+RcLf7XnO0XScbFq6VHe+F4y/ankZEREREklxr9yh5WeksK9IV/7FwSUUeTgcc6Blb/J1MDUPPPlMn63BEbjiJjprwwt1uu3PEQsv95mijTjasqglqr4V9D4G3y94cIinoQM8Y/kDIalVq3dzCXVv3En7ORkH/mI9v//Iwy4pz+Ng1K22PI4mu4xVzrLnM7hwRkp2RRrk7S5Wyc8IJdzYrZQE2eQoBaFlIrayrzBzHF18rO+0PwMABLg82Q/02c15nkcKJ4scGtXAXEc40KFmjhDsRkRT0033dzAZD3Nq0+J/LInI2LdxJYinwvLFS1jcOe39s3pCPp6qZje8zx9cetjuHiIiIiCS1UChEa5eXuio3TqcWt2IhOyON2lIX+5eycHfiN0AIVqhONiEUr4LsAuhK8oU7/zS89ghUNkB5nd1Zrv4cBGfh5XvsziGSYvZ2jgJYTbgrcmVSVZBNW3d8Jdz9w5MHGPfN8qWb68jOSLM9jiS6zp3m6EmOhTuAmqIcLdzN6RubxuGA0jy7C3cb576X7zm5gIW7CCTcHegZ43ecT5p/ufLTi74fgJVKuIu8srUwcgL8+vsqIpJKHtnTRVa6k3duqLA9ikjS0MKdJJYCD/hGwXfGia3Wn8DMWPyk24WV10PpOmjdDoFZ29OIiIiISJLqGJ7COz17qn5NYmN9pZtjgxNMzQQWdwfHnzfH2msiN5REj8NhamW7myHgtz1N9Bx6wrzmtpluF3bJjVC8GnZ+F2Z0glUkVvZ2mIU7mwl3YFLuDvWNMTMbtDpH2L7OUe7feZKrVhVz44ZK2+NIMujYBVn55v3jJOEpymVg3GfSzVJcr9dHiSuLjDS7p+DyszNYXeaiZe57+7y45hbuxhe/cHf4RCe3pf0Kb2E9LLty0fcDUF2QQ2a6Uwt3kVS6DgjBwCHbk4iISIx0jUzx8tEhbqirwJ2dYXsckaShhTtJLPk15nhmyt3ueyE9BxputzPT+TgcJuVucgCOPWd7GhERERFJUq1z6S/11Vq4i6V1FfmEQnCob5Epd8degJwiKLOcIibzV7MZZqehr832JNHT8gDggI3vtz0JOJ1w9WdhegT2/ND2NCIpo6VzlMr8bMrd2VbnqKty4w+EONI/bnUOMGnCX320FQfw5Vs24FAVvCxVYBa6XoXqS83PuyThKcoBoHNEqVm93mnrdbJhTZ5CTgxNMjQxM78vyJurlF1Cwl1u649wOXwELv+kOU+yBE6ngxXFuRzTwl3klK01x4GDducQEZGY2dHcBcC2TaqTFYmk5Hk1J6mhYG7hztthjn1tcPI3sOG9pt4n3mx4rzmqVlZEREREoqS1a27hrioOnw8nsfVVbgD2dy9i4c43ZpLSlr8pqU6yJr2aLeaYrLWyk0Nw8AlY9VbIr7I9jdH0QbOY+ut/hWB8pFyJJLNpf4BDvWM0WKyTDQs/r4mHWtnH9/Xw8tEh7rx8uS5wkMjoew1mp5KqThagpnBu4S7Fa2VDoRB9Xh8V+XYXl8PCFeEtHfOslT2VcNe/uAcMBtnU8yBDuCm84gOLu4/XWVnq4uTwFP6Ang9GRDhZs/+A3TlERCRmHtnThTs7nevWldkeRSSp6J19SSz5HnMcnVu42/0Dc4y3OtmwsnVQvgHadiR37ZCIiIiIWNPa7SXN6eCSijzbo6SU9ZVzC3c9i1i4O/EbCAVUJ5toqjebY+cuu3NES+tPIOiPjzrZsEwXbPkoDB0xdbciElVt3V5mgyEaLNfJgkm4A/sLd9P+AF//aRvurHS++M61VmeRJNKx0xxrkmvhLpxw15HiC3cjk35mAsH4SbhbVggw/1pZ19IS7oIHn6Qq0M2zee/GkZGzqPt4vZWlLgLBECeHJiNyfymvZA04nDCghTsRkVRwqHeM1m4vN2+sIis9zfY4IklX6jrDAAAgAElEQVRFC3eSWArOqJSd9UHzfVC6FpZfZXeuC9n4XpgahvZnbE8iIiIiIkmotcvLmrI8sjP0hkksLSvKJTczjf09i1gEOP68Oa7Qwl1Cya8CdxV0vmp7kuhoeQDSc2D9LbYnOdsVnwRnBrx0l+1JRJLe3k6zjBEPCXcrSlzkZKTRannh7v8+f5SO4Sm+8PY1lObFx/KMJIHw8n6SJdydXrhL7aWo3rFpAOvV3GF1VfmkOx00n5xnwl16JmQXLjrhzvfi3cyGnBxb+cFFff251Ja6ADg2qFrZiMjIhsIV0K9KWRGRVLB9rk72VtXJikScFu4kseSHK2U7Yf+jMDVk0u0cDrtzXciG95njPtXKioiIiEhkjU766RyZUr2ZBU6ng7UVbvb3jBEKhRb2xcdfhKwCqGyIznASPTVboK8VZpLsRPLwMTjxEqy/GbLj7PtJfhVsvA2OPWeqmEUkavbOpR/FQ8JdmtPBuko3bd2L+DkbIX3eae56+jC1Jbl85E0rrcwgSapjJxQuh7xy25NEVE1hLgCdI6mdcNfr9QHETaVsdkYadVX5NHeMzv/7aV754hLu+g+Sc+JZfha8nGW1axb+9eexcm7hrr1fC3cRU7YOBg9DYNb2JCIiEkWhUIhH9nRR7s7iylUltscRSTpauJPEkl0AmW5TKbv7XnOVe1PkrpSKipLVUNUE+x8zqXwiIiIiIhESTn2pr4qzBZkUUVflZmhihv7xBTzPn5mEzt0mpdupVMKEU32pqQPuabE9SWTtfdAc46lO9kxXf9YcX7rb7hwiSW5v5yjVBdlxk+RWX53P0MQMfWN23k/72k/bmJwJ8KV315OZrrfRJUKmRkyNY5LVyQLkZKZRmpeZ8pWyvV6TcBcvlbIAjZ4CBsZ9dI1Oz+8LXOUwvoiFu5e/A8B/zt54qho8ElYq4S7yStdC0G8uvBERkaS15+QIJ4Ym2dpUTZozjgOMRBKU3imQxOJwmFrZ7mZT0br+3eAqtT3VxW14H/hG4cgvbU8iIiIiIknk1MKdEu6sWFdhTiId6Bmb/xd1vGxObKx4U5Smkqiq2WKOnbvtzhFJoZCpk80tgdVvsz3NuVU1Qe21sO/H4O2yPY1IUpqaCXCobzwu6mTD6uYuKLBRK/vi4QEe2dPF29eXc0NdcqWQiWVdc88hkqxONqymMCflK2X7Ti3cxUfCHUDTskIAWuZbK5tXBtMjCwsQmB6F5vs4kbmaZud6LimP3MJduTuL3Mw0jg2k9p+tiCpbZ44DB2L7uM//I3z3Jpidie3jioikqEf2qE5WJJq0cCeJJ7/GvNgDUyebCDa8xxxVKysiIiIiEdTaZU5A1ynhzop1leb/+4IW7o69YI61b47CRBJ11ZeaY+cuu3NEUvceGDhoalvTMmxPc35Xfw6Cs/DyPbYnEUlKrd1eAsEQjZ5C26OcUj+XjhR+vhMrM7NB/vKRfWSlO/nrbRtwOJQEIRHUMfccwnO53TmixFOUS9+YD99swPYo1vTMLdyVx1HCXdPc9/Y9HfNcuHPNLRpP9M//Qfb8EGbG+UHwJtaU50c0GdThcFBb4uLogBLuIqZ0buGuP4YLd6/9BH7+13DiJTj6q9g9rohIipoNBHm0pZuVpS4aauLnwiqRZKKFO0k8BTVzx+Ww6nq7s8xXUa1JQjjwU/CndqS+iIiIiEROa7eXqoJsil2ZtkdJSesrzSJAW/cCFu6OvwAZLpPYJYknpxCKV59Op0kGLQ+YY7zWyYZdcqP5f7/rezCjk60ikbZ3bgljYxydiAkvtrfFOOHunufaae+f4AtvW8Oy4tyYPrakgM6d4MyAykbbk0SFpyiHUAi6R+ZZXZqEer0+0pwOSlzxs3C3pjyP3Mw0Wk6Ozu8L8srMcb61ssEgvPwdgjnF3Dt+eUTrZMNWlrroGp1i2p+6y5wRVbbWHAcOxubxevbBTz4D2XOL/W3bY/O4IiIp7KX2QQbGfWxrqtZFRCJRooU7STz5HnPc/DvgTKA/whveBzPjcOgp25OIiIiISBKYmQ1yuG+MeqXbWVPkyqQiP4sDvfNcBPBPQ8dOWH5lfCeJyYXVbIGhdpgcsj3J0gVmYd9DULzqdF1uvHI64arPwNQwNN9nexqRpLO30/wsi6fkg7ysdGpLcmO6cHdyaJJ/+eUhVpW6+MRbVsXscSVFhELQ8QpUboSM+KkbjaSaohwAOoZT96LzPu80ZXlZpDnj58R2mtPBxpoC9naOEgyGLv4FC024O/xzGGqna/Wd+MiMymvU2tJcQiE4MaRa2YjILoC8ytgk3E0OwY8+BAE/fOh+KKuD/Y9BUMuTIiLRFK6T3aY6WZGoSaBtJZE5dbfA2nfBlo/anmRhwrWyr6lWVkRERESW7lDfGP5AiPpqLdzZtL4yn4O948wGghe/cecuCPhgxTXRH0yip2azOXa9aneOSDj6LIz3mnS7RLjaedOHTCrGS3ebJBURiZi9nSN4inLiLjW3riqfowMTTM3E5qT8V3a0Mu0P8tVbN5KVnhaTx5QUMnwMJgeh5jLbk0SNZ27hrnMkdZeier0+Kgrib6Fy07JCxn2ztA+MX/zGeRXmON+Eu5f/HRxpPFewDSAqr1FXluYB0N6vpOOIKVsLA4fMMnC0BGbhwY/AyHG4+f+D5VdB3VaYHIATv47e44qIpLhpf4Cf7euhoaaA1WV5tscRSVpauJPEU7EBPvSj07HmiaLAA8uugoNPqP5GRERERJastcukvSjhzq71lW5mZoMcG5zHScXjL5hj7ZujO5REV3V44S4JamXDdbINt9udY74yXXDZx2DoCBx6wvY0IkljcmaWw33jcZVuF1ZXlU8wBAd6F1DfvkhPtfby87Zebmms4s2XlEb98SQFde4yR8/ldueIIk+RqWFO1YS7QDBE/7iPCnf81MmGNXrM9/jm+dTKhs+9TMxj4W7gkEm4q7uFV4bN7380XqOuLDX3fWxQ51YipnQtzIyBtyt6j/HUl81FPpd9DC6bC9Go22qObTui97giIinu6f19jPtmuVXpdiJRpYU7kVja8F7wT5qlOxERERGRJWidq1dTwp1d6yrdAOzvmUfd3bHnIT0bqi+N8lQSVVWN4EiDzgRPuJuZMCe5PJdDyWrb08zfFZ8EZwa8dJftSUSSRmuXl2AIGjzxuXAHRL1WdmomwF9vf428rHT+9y31UX0sSWEdO83Rk7wJdzWFqV0pOzjhIxAMUZEffwl3TZ5CAJo7Ri5+43Cl7Pg8KmVf/o45XvEpWru8VBdkU5gb+bTU2hIXAMcGtHAXMaXrzHEgSrWyzT+CX98Fy6+Gm/7u9McrG6BwhXktEs10PRGRFPbIni4cDrilUQt3ItGkhTuRWKq/FXCoVlZERERElqy1y0teVjrL5lIkxI71lWYR4EDPRZJ3Zmfg5MtmuSk9/hIvZAEycqCi/nRKTaLa/1PwT5g62USSXwUb3wfHnoPuZtvTiCSFlg6TdhSPCXfhCwuivXD37acP0TkyxR++Y21cLspIkmh/GlxlULzK9iRR48pKpyg3g84UXbjr8/oAqMiPv+f74drw5o55JNy55plwN+2FPT+EigZmaq7iSP941C4IK3Zlkp+dTrsW7iKnbK059h+M/H137obtvw/5NXDHvZB+xhKmw2FS7rwdyZEaLiISZ0an/PzyQB9XrSyhMg5r7kWSiRbuRGIpvwpWXAOHngJf9KswRERERCQ5hUIhWru91FW5cTodtsdJaavLXaQ5Hey/2MJd16swO6U62WRRswXGe6JbvxRtLfeDM90ksSeaqz5rji/dbXcOkSSxrzN+F+6qC7LJz06ntSt6C3dH+sf5zq/aWV/p5nevXhG1x5EU138Q+vfD+nebZZMk5inKpWN40vYYVvR6pwEoj8PFXYfDQaOngLYuLzOzwQvfOCMbsgpg/CILd3t+CDPjcOUnOdQ/jj8QikqdLJj5V5a6lHAXSdFKuBvvg/t/2/z6zv+CvPI33qZumzmqVlZEJOKeeK2Hmdmg6mRFYkALdyKxtvG9MDsNBx63PYmIiIiIJKiO4SnGpmejdjJD5i8rPY3VZa6LV8oef94cV1wT/aEk+qo3m2OiptyN98GRX8KaG8BVanuahaveBLXXwr4fg7fb9jQiCa+lc5TlxblRqQBcKofDQV1VPvt7xggGI187FwqF+PIj+/AHQnztvRtJT9Pb5RIlbdvNsW6r3TlioKYwhx7vNP7ARZa6klDvqYS7+Fu4A1MrOxMIXvy1C0BeGUxcoFI2GDR1sjlF0HD7qcXouii+Rq0tddE35mPCNxu1x0gp7krIyo9swt3sDDzwYfB2wrZvQc3mc9/OcznkVUDrdtXKiohE2PY9XWSkOXjXxirbo4gkPb2DIBJrdbeCwwn7VCsrIiIiIovTOlerFq26HlmYdZX5nByaYvxCJ36OvwhpmeC5LHaDSfSETxx1JmgF0r6HIRSAxjtsT7J4V30WgrPwyj22JxFJaOO+WY70j8dlul1YfXU+475ZOqJQUbmjpZsXDg9y52XL2LKiOOL3L3JK2w6TGFb7FtuTRJ2nKIdgCHpGp22PEnPhhLt4rJQFaFpmvtc3nxy5+I1d5RdOuDvyCxg6Apt/FzJyYvIadWWpC4CjSrmLDIcDStdGNuHuZ38GJ16Cqz4HTR84/+2cTlh/i/kz1L8/co8vIpLi+samefHIAG9dW05BbobtcUSSnhbuRGItr8xciX/kFzA1jxe2IiIiIiKvE04PqK+K35PjqWR9pRuAA+erlZ2dgeMvmav4M3JiOJlETVkdpOdAV4Iu3LXcD5luWPsu25Ms3tqboHgV7PwuzOikq8hitXZ5CYWgwRO/zynCaUnhZY5I8U77+ZtHWynMzeDP3rU+ovctcpbh49C9B9bdBOnxlyQZaTVF5vnuyRSsle0bm1u4c8dnwl2jpxCA5o7Ri984rwymhiDgP/fnf/PvJljg8o8D0NbtJS8rnWVFuZEa9w3CC3fHBvXcL2LK1pkkw8mhpd/Xzu+Z5+Yr3wrv+OrFbx9O/FStrIhIxDy+t4dgCLapTlYkJrRwJ2LDxvdBYAYO/NT2JCIiIiKSgFq7vaQ5HVxSkWd7FGEeC3edO8E/Aauui9lMEmVp6VDVBJ2vmjqtRDJwyCwK1m+DzOidEI06p9Ok3E0NQ/N9tqcRSVgtHeZi0MZ4TriL0sLdPz51kP4xH39+03qKXcm/BCUW7X/UHOu22Z0jRjxzC1edUUiljHe9Xh+ZaU4K4zRRpjQvi5rCnPkn3AFMDLzxcwOH4fBTsP7dULiMUChEa5eXuio3TqcjskOfobZkbuFOCXeRU7rWHAeWWCt74tfw0z+BwhVw+3+a10sXU/tmyC48XbktIiJLtr25i5yMNG6oK7c9ikhK0MKdiA1128CZDq2P2J5ERERERBJQa5eXNWV5ZGek2R5FgHWnFu7OswjQ/ow5rrouFuNIrNRsBt8oDLXbnmRhWh4wx0Sukw3b9CFzku6luxNv8VEkTuztNClHG+J44W5NeR5pTgdtEVy4e61rlO+/eIxLlxdyx2XLIna/IufUtgMycmH122xPEhOeuYS7aNRAx7te7zTl+Vk4HNFbOluqTcsKOdw/zrhv9sI3zAsv3J2jVvaVe8zxyk8D0DkyhXd69lQiabTUziXctWvhLnLK1plj/xJqZb1dcP/vQFoGfOCHkDvPiva0DFh3M/TshaGji398EREBoGN4kl3Hh7mhvoLczHksPovIkmnhTsSG3GIoqjV1AiIiIiIiCzA66adzZIr66uiezJD5qynMwZ2VTtv5Eu7anzH1ndWbYzqXRFnNFnNMpFrZUMjUybqroPZa29MsXaYLLvsoDB2BQ0/ankYkIe3tHKW2JJeCnPhMYwLIzkhjTVlexBbugsEQf/mTfQD87Xs2RjWNSYSxXpP8tOaGxE6WXYCalF6481GRH591smGNngJCIdjXeZFaWVeZOY73n/1x3xi8+t9QsRFWXANAW7d5HVQf5YW7gpwMSlyZSriLpKUm3Pmn4Ue/ZRYz33M3VG5c2NeHa2XDSaAiIrJoj7Z0A7C1scryJCKpQwt3IrZk5ZsXpyIiIiIiCxCuU4v2yQyZP4fDwbpKNwd6xgiFQmd/ctoLHTth5bXzq9WRxFF9qTl27rI7x0KcfBlGjkPD+8GZJAmZV3zSJMi/9G3bk4gknLFpP+39E2yM43S7sLoqNx3DU4xO+Zd8Xw/sPMmrJ0b43TfVsqE6/v/bJcHtfxQIQf2ttieJmfzsDPKz0+kcmbQ9Skz5A0EGJ3xU5GfZHuWCGj2FABevlQ0n3I33nv3xPffBzJh5DjaX5NfaNfcaNQYXha0sdXFsMLX+bEVVUS2kZS0u4S4Ugkf/0FyAdO0XYcN7F34fq6+HDJdJAhURkSXZ0dyFOzudt64rsz2KSMrQwp2ILVluLdyJiIiIyIKdWrhTwl1cWV/lZnTKT493+uxPHH8BQgHVySaj4lWmzrQzgRLuWu43x8Y77c4RSfnVsPE2OPYcdDfbnkYkobw2tyDR6In/pbNwTeH+JabcDU3M8I2f7afcncUfvWNtJEYTubC2HZCWCZe80/YkMeUpyk25hLuBcR+hEJS74zvhrsFTgMMBLR0XS7g7R6VsMAgv/zvkFEHD7ac+3No9itMBayvcUZj4bLWlLoYmZhidXPoCtmAuwilZAwOLWLj7zb9D8w/hkhvh+i8t7vEzcuCSd8DJ38BYz+LuQ0REONI/zmtdXm7aUElWepJcYCmSALRwJ2JLlht8XvMiVURERERknsLpAXVKuIsr6yrnFgFeXyvb/ow5rrouluNILDgcULMZelogkAAn/GZn4LWHobzeVIAlk6s+a44v3W13DpEEs3du2aKhptDyJBcXft6z1FrZv3t8PyOTfv7ylnrc2fFboytJYnLILISvug6yU+u5e01RDt2j08wGUue9716vDyDuK2XzstJZU5bHnosm3J2jUrb9lzB4GDZ/+KyK5NZuL6vL8sjOiP4J/pWlLgCODqpWNmLK1sLISZhZQHJg+7PwxP9jlvVuu2dp6dmqlRURWbIdzV0AbNtUbXkSkdSihTsRW7ILgBD49cJQREREROavtdtLVUE2xa5M26PIGeoqTZrD/u5zLNy5q6BUKTpJqXozzE5DX6vtSS7u8M9hahga7zhV/5U0qjfBijfDvofA2217GpGE0dJpFu421MT/ItDphbvFt0XsOj7E/TtPcs2aErY2VkVqNJHzO/gzCM5C3Tbbk8ScpyiHQDBE75jP9igx0zuXdB3vlbIATcsK6RyZYmD8Ar8/50q4+82/g8MJl3/81Ie8035ODk3FLIE9vHB3bEDnVSKmdB0QgsFD87v98DF48COQkQsfuG/uXNcSXPJOkwSqWlkRkUUJhULsaO6iNC+Tq1eV2B5HJKVo4U7Elqy5ePXppV2ZKyIiIiKpY2Y2yOG+MeqVbhd31s4t3B3oOeP5vbcb+vebVJNkW3ASo2aLOSZCrWy4TvaM+q+kcvXnIOiHV+6xPYlIwtjXOcqqUhf5CZD0VubOosydResiE+5mA0G+9D/7yEhz8NVbN+LQz2WJhbYdZjlp3c22J4k5T5FJP+sYWkBiVoLrO7VwF98JdwBNc1XiLR0XSLnLzIVMN4zPLdwNHoFDT5o/z4XLT90sfMFRrF6j1paYhbt2LdxFTtncxWH9By9+25kJ+NFvmwt5brvn9NcuRXY+rLoejj5nkkFFRGRBWru9HOmf4OaGKtLTtP4jEkv6GydiS9bcC1Df4q/MFREREZHUcqhvDH8gFLP0AJm//OwMagpzzq6UPfqsOa66zsZIEgs1m82xc5fdOS5mehQOPA6110KBx/Y00bH2JiheBTu/a04EisgFjU75OTowQYNniak0MVRXlc+B3rFFVVR+/6Xj7O8Z41NvWc3qsrwoTCfyOr5xOPwLWHENuFIvaaSmMAeAjuEpy5PEzulK2cRIuANoPjl64RvmlcHEXKXsy3MXNVz56bNu0tpl7qMuVgt3pWaZUwl3EVS6zhwHDlz4dqEQPPJ56N0L138J1r0rcjPUbYVQwCSDiojIguxoNkn/W5tUJysSa1q4E7ElnHDnU8KdiIiIiMxPa5d57qiEu/i0vtLNkf5x/OFFgPZnzHHlW63NJFHmrgR3NXS9anuSC2vdDgGfqZNNVk4nXPVZk7bRfJ/taUTi3mtzdbINNYmzcFdflc/MbJCjC1yy6PVO849PHaSmMIfPXb8mStOJvM6hJ83P3vpbbU9ihafILNx1jqTSwp1JuCtPgIS79ZX5ZKY5ab5Qwh2YWtnxPhMasOe/obweat981k3CVd+xWrjLzUynMj+bY4NauIuYkjUmjbP/Igt3L/wTvPawqcl+yx9HdoZ1N5sZVCsrIrIg4TrZ6oJstiwvsj2OSMrRwp2ILdnhhDst3ImIiIjI/IRr1JRwF5/WVbrxB0K090+Yq//bn4Gy9ZBfZXs0iaaazdDXFt+pai33Q1qWOTmWzDZ9CLIL4df/CsGFJ2CJpJK9CbhwV1dlLl5daK3s3z7Wxrhvlq9s20BOZlo0RhN5o/DSyPp3253DkvDCXcdw6lTK9o75yMlIw52VbnuUi8pMd1JXnU9LxyihUOj8N8wrg8lBePW/zXmMKz8Fr6vkbu32Uj5X+x0rtaW5HO2fuPDsMn8Z2VC4AgYuUCl76Cn4+VfM0uV7/vUNfw6WzFViEkEP/8IkhIqIyLzsPjFC58gUtzRV43RG+HuziFyUFu5EbAkn3E1r4U5ERERE5qe1y0teVjrLinJtjyLnsH4u1WF/j9ekA4x1w6rrLU8lUVez2dQfdbfYnuTcRjvg2POw7ibIKbQ9TXRluuCyj8LgYZMsJCLn1dI5isMBGxJo4S6c8LuQhbvnDw2wo7mLG+oquKG+IlqjiZzNP21+Dnkuh/zUrPYqyMkgLys9pRLu+rzTVORn4Yj0IlKUNHkKGJqYuXDtr6scCMHz3zQXNTScnZbsDwQ50DsWs3S7sJWlLsZ8swxOzMT0cZNa2ToYPAKB2Td+buAw/Pj3ILsAPvDfkBWlava6bSYZ9PBT0bl/EZEktKO5C4BtqpMVsUILdyK2ZM29oekbszuHiIiIiCSEUChEa7eXuiq3rliMU+srzUU1+3vGTtfJrrrO1jgSKzVbzLFrt905zmfvj4EQNN5pe5LYuOKT4EyHl75texKRuLavc5RVpS7yEiCJKWxlqYvMdOep+sKL8c0G+PIj+8jOcPJXW+ujPJ3IGdqfhpnx5E+WvQCHw4GnKOfCy1xJptc7nRB1smFNHnMhxgVrZfPKzXG8FzZ/GDLPvvCrvX+CmdlgzBPYV5a6ADi2wIpxuYDStRD0w/DRsz8+7YUffQhmxuD270HxqujNUHeLOapWVkRkXgLBEI+2dLOy1MUGtaGIWKGFOxFbwgl3qpQVERERkXnoGJ5ibHr2VLqLxJ+VpS4y0hzs7/aahTtHGtReY3ssibaqTebYGacLdy0PQE4RrHmH7UliI78aNrwPjj0Xv6mDIpaNTvo5PjhJoyexUi/T05ysr3TTNs+Eu3t+1U77wARfeNslLCtWOrDEUHhZJLw8kqJqCnPoGpkiGEz+2k/fbIDhST8VibRwt8wEArR0jJ7/Rq4yc3Q44fKPv+HT4e/HsX6NWltiFu7atXAXOWXrzLH/wOmPBYPwP5+CgQPwjq/C6rdFd4b8apMMevAJkxQqIiIX9Ov2QQbGfWxtqk6YhF2RZKOFOxFbsudehCrhTkRERETmIVyfFuv0AJm/jDQna8rdHO4eNhWenstPX2gjySunEErWQOcu25O8Uc8+6HsNNrwX0jNtTxM7V3/WHH99t905ROLU3k6zXLExgepkw+oq8+kf89E/5rvg7U4OTfIvvzzM6jIXn7g2imk8Iq8X8MOBn0JFQ3SToBKApygHfyBE30X+viaDPq/5b6xwZ1meZP5WleaRl5XOnpPzSLhbdzMUrXjDp229RlXCXRSUzi3cDZyxcPfsN8z3s4Y74OrPx2aOuq0mIfTos7F5PBGRBBauk93aWGV5EpHUpYU7EVvCJ96mlXAnIiIiIhfX2mWeN26oTryT46lkfaWbsrFWU7mz6jrb40is1Gwx9UuTQ7YnOVvL/eaYKnWyYdWXwoo3mzpdb7ftaUTiTnjhrtGTeM8p6qrM+2kXSrkLhUL81fbX8M0G+ZtbN5KZrrfAJYaOvwBTw1CfunWyYZ4ikyzZMTxpeZLo6xszaVyJlHDndDpoqClgX+cogfOlEC5/E6y5Aa77i3N+urXLS3aG81TiXKwsL8nF4YCjWriLnLK15th/0BzbdsCzfwdVTbDtWxCr5KT14VrZ7bF5PBGRBDUzG+TxfT2sr3RzSYUu9hWxRe82iNiSpYQ7EREREZm/1m4v6U4Ha8rzbI8iF7C+0s2bnfvMv6y6zuYoEkvVm82xK45qZYMBs3BWuByWXWl7mti7+rMQ9MMr99ieRCTutHSM4HTEvgIwEurmZr7Qwt1Trb38cn8ft26q5k1rSmM1Wurq2Qv/8+nTNaqprnVuSaRuq9054kBNUQ4AHcNTlieJvp5Rk3BXnp84CXcAjcsKmJwJcLhv/Nw3cJXAbz8ElRvf8KlQKERbt5f1lfmkOWNbY5eVnkZNYY4W7iIpuwDyKk3CXV+b+b6eWwp3/jdk5MRujpLVULER9v8UArOxe1wRkQTz3KF+Rqf8bNtUbXsUkZSmhTsRWzLzAAf4Rm1PIiIiIiIJoLXLy5ryPLIz0myPIhewrtLNNWn78Kflgucy2+NIrNTMLdx1vmp3jjMdex7Guky6XawSKeLJ2ptMld/O78JM8ifriMxXKBRi94lh1la4cWWl2x5nweqqL7xwNzkzy1d2tOLOSudLN9fFcrTUM3QUHvo4/Nu10HwfPPVlCJ0nJStVBIOw/1FTNV+23vY01jKXcXgAACAASURBVHnmFu46R5J/4a7Xm3gJdwCbPIUANHdcoFb2PPrGfAxOzMS8TjZsZamL44OTBM+XzicLV7bWJNzd90GYnYY77oXCZbGfo24rTA3BiRdj/9giIgnidJ2sFu5EbNLCnYgtTqeplVXCnYiIiIhcxOikn86RqYRMokk19SVpbHYc4kjuJkjLsD2OxEplAzjT4yvhruUBc2y4w+4ctjjT4KrPmlq/5vtsTyMSN7pGp+n1+tiyosj2KIuSn52BpyiHtu5zv5/2L788TOfIFF9851rKE2zxJWGM9cJjfwzfvgz2Pghr3m6WI4ba4+vnoA0dr8B4L9RtS81l99dJpUrZ3gSslAVoXDa3cHdy4Qt3rV1m8bnO0mvUlaUupvyBU//vJQJK14F/AoaPwk3fgNpr7MwRTghVcqqIyDlNzQR4srWXS5cXsqw41/Y4IilNC3ciNmW5Yfr8FRgiIiIiImDqZAFr6QEyf2VDO8lwBHgx9MbaJUliGTlQXg+du+Ij3cc/Ba2PQPWlJqkiVW36EGQXwq/+HiaHbE8jEhd2Hx8GYPPyxFy4A7Pccbh/nGl/4KyPH+od455ftbOhOp/fvmqFpemS2PQo/OJv4FubTF139aXwu4+auslr/tDcpuVBuzPa1qY62TMV5WaQk5GWEpWyfd65Sll3YlXKVhdkU5qXRUvHwlt4Tr1GtbRwV1viAlCtbCRV1Jvj5g/D5R+3N0d5vUmqbnvUJIeKiMhZfrm/j8mZgNLtROKAFu5EbMrKV8KdiIiIiFyU7ZMZMn+O9mcB2D62llA8LF5J7NRsNqk23i7bk8CBx2FmzNTJprJMF9z4NVOt+8jn42MZUsSyXeGFuwRNuAOzcBcIhjjcN37qY6FQiP/9yD4CoRB/+56NpKfpbe+I8U/BC9+Cf26C5/4eCpfDB34Iv/cUrLzW3KZms1mO2PcQBAMXvr9kFQqZhbt8j1lGFBwOB56iHDpTYOGu1zuNOys94aq6HQ4HTZ4C2rq9b1hivpjWbi8OB6yvdEdpugtbWWoW7o4NJH+CYsw0fgBu+79w8z/YTel0OMzi8liXklNFRM5he3MnDgfc0lhlexSRlKd3HkRsynKDTwl3IiIiInJhtut6ZAHan2E8vZg9vqqUSPOQM9RsMcd4OCnU8gA40mDjbbYnsW/Tb8HG98OBx+Dle2xPI2LdqyeGKXZlUluSuNVD4QsQwhckADyyp4tftw/xgcuXc2kCp/fFlcAs7L4X/mULPPW/ITMP3vOv8JkXYf27z17GcDig4XaY6IOjz9qb2aaeFhg5YZZEVCd7Sk1RDh0jUwSDyb303uudpqIgsepkw5qWFTIbDNHWvbDzFG1dXlaWuKwtGYYX7o4OjF/kljJvmbnQ8H5Iz7Q9ianmhtPJoSIiAoB32s/TB/q5amUJ5QlWZS+SjLRwJ2JTthLuREREROTiWru9VBdkU+SKgze+5fzGeqHvNQbKrwYcHOjRc/2UUr3ZHDt32Z1jYhAOPwWrr4e8cruzxAOHA275RyiqhSe/BN0tticSsWbaH+C1Li+blxfiSOCFoFMLd3MXJHin/fztY20UuzL50xvX2RwtOYRCppb87qtg+xdgdhpu/D/w+Z2mqtuZdu6va7jdHPf+OHazxpPWuaWQ+m1254gznqIcZmaDDIz7bI8SVX1eHxX5iVUnG9boKQBYUK3s5MwsRwcnrF4Q5inKId3p4KgS7pJT9WZwV0PbDqVUi4ic4cnXepmZDbJtk+pkReKBFu5EbMpyg38SAn7bk4iIiIhInJqZDXK4b4z6aqXbxb2jvwLAsfo6APb3KM06pZSth4xc6LSccPfawxCcVZ3smbLz4f3fMyfrfvwx8CkJRVJTS8cos8FQwifAeYpyyMtKP5XG9M0nDzIw7uPP37VeFycsVfuzcM/b4IEPw1g3vPXP4ff3wNWfhYyLJGiUXgJVm8zimT8FU37bdoCrDJZdaXuSuOIpMmmaHSPJ+2diwjfLmG+WCndipsw0egoBaD45Mu+v2d8zRiiE1deo6WlOlhXncmxwwtoMEkVOJ9TdAkPt0NdqexoRkbixo7mLdKeDmzZU2h5FRNDCnYhdWXMvSJVyJyIiIiLncahvDH8gdCrNReJY+zMAlDXeCJgTUZJC0tKhqgm6XoVg0N4cLQ9AhsvU/clpNZvhhr+CwUPw+J/ankbEit0nhgHYnOALd06ng7oqN23dXvZ1jnLvS8fYsqKI92/22B4tcXW9Cve+B+7dBj174crPmEW76//CLC3PV+MdMDMGB5+I3qzxqP8ADBwwP3vPlwCYomoKcwDoGE7ehbu+MZPel6i1bsWuTJYX59LcMf+Fu3DCqO3XqCtLXZwYnCSQ5JXFKatuqzm27bA7h4hInBgc9/H84QHesrZMFxqJxAkt3InYlOU2Ry3ciYiIiMh5nDqZoYS7+BYKmYW7kkvILVvB8uJcLdylourN4PPC0BE7jz/UDh0vmzSITJedGeLZVZ+DNe+APf9tFhNFUszu48OkOR00LSuwPcqS1VXl452e5Qv3vYrD4eBv37MRpzNxa3KtGTgMD/wufOc68zym6YPwhV3wrm9AXtnC72/D+wAH7H0wwoPGufAySJ3qZF/PUxReuEve2s9e7zRAwlbKgqmVPdI/gXd6fk08rXMJozYrZQFqS1zMBIJ0JXGCYkpb/ibIKdbCnYjInMf39RAIhtjaVGV7FBGZo4U7EZuy597g9KlqSkRERJJEMAj/82m9IRpB4ZMZ9VWJf3I8qQ0eAW8HrLoOgPWVbo4OTDDtD1gdS2KsZrM52qqVbZlbcGi8w87jxzunE97zr5BXCY/+ofl7K5IiQqEQu0+MUFflJjcz3fY4SxZe8jg6MMFH3lRrfekj4Xi7YMf/gruugNafwLqb4TMvwnv/DYpWLP5+86tg5Vvg0JMwNRy5eeNd23bzPm/ttbYniTvhStnOJE64O71wl5gJdwCblpla2X0do/O6fWuXl2JXpvUlw5Vl5gKTowOqlU1Kaemw/mbo3afn7SIiwPbmLrLSnbyjXnWyIvFCC3ciNinhTkRERJLNeA803wev/pftSZJGa5cXd1b6qXQIiVPtT5vjqusAs3AXCIY43DdubSSx4NTC3a7YP3YoBC33g6scVl4X+8dPFHll8L7vwMwE/PijMOuzPZFITJwcmmJg3JfwdbJh4QW7ivws/uCGSyxPk0Amh+CpL8O3LoVd/wnLroSPPQkfvA8q6iPzGA23Q2AGWrdH5v7i3fBx6G6Gte+CdFV7vV5pXiZZ6c7krpT1mucStpfPlqLRYxbu9syjVjYQDHGgZ4z6qnwcDrvJoitLtHCX9MLJofsftTuHiIhl3aNTvHJsiLfXlZOXlfgXUIkkCy3cidgUXribVsKdiIiIJImxHnMcOmp3jiQRCoVo7fZSV5WvmrR41/4MOJyw0iSbrJ9bBDigWtnUUrQScoqgy0LCXeduU2Xb8H6TBiHnt+qtcO0XzYLEz79iexqRmNh9wqSNJcvC3cbqfD5w+TL+8c5NuLMzbI8T/2Ym4blvwrc2wQv/DCVr4EMPwkd/CsuvjOxj1W+DtKzUqZUNL4HUq072XBwOBzVFOXQmceVnOOGu3J24CXcba/JxOqDl5MUT7o4NTjDlD1BfbT9ZtLbUJChq4S6JrXwrZLrVoiAiKe+xlm5CIdjWVG17FBE5g96BFbEpa+5FqRLuREREJFmEF+6Gj5l6Waeu8VmKjuEpxqZn4+JkhlxAYBaOPgc1W0ydGLCu0lxcc6BXz/VTisMB1Zvh2PMQ8ENaDJdAWu43R9XJzs91fwHHnoNf32UW8NbeaHsikagKL9xtWZEcC3fpaU6+cVuj7TESw4HHYccfmCTqolq4+R9g423Re56eXWC+p7btMNW1+Ul+UrB1O2Tkwuq32Z4kbnmKcnn56CChUMh6Ilo09I6ZhLvyBE64y81MZ22Fm+Z5JNy1dpnwgLoqd7THuqjqghwy050cG9TCXdLKyIa174R9D6XGzxQRkfPY0dxFXlY6160rtz2KiJxBZ79EbDpVKXvxK8dEREREEsJYtzkGfKd/LYvW2m1OZtRXaeEurnXvMc/pV1136kO1JS6y0p20dSvNOuXUbDbfA3tfi91jBvzmJFTpWqjaFLvHTWRp6XDbf5jFkJ98xpzAE0liu44PU5qXpYr6VBMKmWW72Sm4+e/hc69A4+3Rvyim4XYgZH42JbOxHjj5G7jkHZChv1vnU1OYw7Q/yODEjO1RoqLXO01RbgZZ6Wm2R1mSJk8h3aPT9M0l9p1P26nXqAWxGOuCnE4HtSW5SrhLdnVbzXH/Y3bnEBGx5PjgBM0do7yzvoLsjMR+viGSbLRwJ2JTthLuREREJMmEE+4AhlUru1Th9AAl3MW59qfNcdV1pz6U5nSwtsKtStlUVLPFHGNZK3vkaZgcMOl2SZgcEzWFy2Hbt2FyEB7+JAQDticSiYrJmVn294yxeXlhUqZLyQV0N5tku80fhis+AemZsXncS94JWQXQ8kBsHs+W/Y8BIahTneyFhBd9O4eTs1a2zztNRX7i1smGNS4zC3TNHRcOB2jt9pKZ7mRVmSsWY11UbYmLjuEp/IGg7VEkWta8w1SVt223PYmIiBU7ms0Fgls3KeVTJN5o4U7EpnCl7LRSL0RERCRJjJ+xcDekhbulau32ku50sKY8z/YociHtz5oqMc/lZ314XaWbvjEfQ0ma5iHnUb3ZHHf9Jxz+eWyWuPbOLTQ03B79x0o29dvgst8z9bLPfdP2NCJR0XxylEAwlDR1srIAB58wx0tiXJudkQ31W6GnBfoPxPaxY6ltO6RlmgVDOa/wwl1HEi7chUIher0+ypNg4a7JUwhAy0VqZVu7vKytyCMjLT5OL64scxEIhjg5NGl7FImWrDxY83Y49gJMDNqeRkQk5nY0d1OUm8Gb15TaHkVEXic+nhGLpKosJdyJiIhIklHCXUS1dnlZU56nuoB4NjNhqsRWvAnSs8761PpKNwD7e3SBTUpxV8Clv21Shf7rNvinRnj66zB8LDqP5xuDtkdh+dVQVBudx0h2N34NyjfAM1+H4y/ankYk4nafGAZgsxbuUs+hJ0zS3PKrYv/YDXeY494HY//YsTA5BEefg1XXn24xkXM6vXCXfAtRY75ZpvwBKtxZF79xnFtX6SYr3XnBhLuBcR99Yz7qq+Lnz/zKEpO0p1rZJFe3FUIBOPi47UlERGLqQM8YB3rHeFdDVdwsu4vIafpbKWJTljkBh08n4ERERCRJjHVDXoX5tRLulmRkcobOkam4Opkh53DiJQjMnFUnG7a+0vze7e/WBTYp59a74Pf3wFv+FAjBs38H/9wE398KLQ+CP4IJL/sfg9kpUycri5ORA7d/D9Kz4aFPmCUKkSSy+/gw6U4HDTUFtkeRWBrvh87dsOZtkJYR+8evfTPkVZqFu1Ao9o8fbQd/ZpY/6lUnezGeolwAOkeSL+GuzzsNkBSVshlpTuqr82npGCF0nr+zbd3mPEY8vUatLdXCXUpYexM40qBth+1JRERi6lSdbKPqZEXikRbuRGzKyAFnuhLuREQk6fkDQYLBJDzJIm801msSltxVSrhbotbwyYzq+DmZIefQ/ow5rrruDZ9aX2UusDnQo+f7Kal4JbztS/AHe+G3H4L698Dxl+Dhj8M/rIPHvghdry59CaHlfnBmmPuXxStbB+/6O/B2wPYvJOdyiKSkUCjEqydH2FCdr8TcVHP4KSAU+zrZMGcaNLzfJLx27LQzQzS17TDLH2vfZXuSuFeWl0VmmjMpK2V7vT4AKvITP+EOTK3syKSfE+epZ23tCr9GjZ8F7lVzC3fHBrVwl9Ryi2HltXDklzqfJiIpIxQKsb25i4r8LK5YWWx7HBE5By3cidjkcJiUu2kl3ImISPIKBkPc8q3n+ZMft9geRaIt4IeJfnBXQvEqJdwt0amTGXGUHiDn0P4M5JaaOsrXKc3LojQvk/29OiGQ0pxpsOYGuOP78MUDcNM3IN8Dr/wHfOc6+Ldr4df/trhUtbEe82dw7Y3mJJQszaW/Axtvg/2Pmt8fkSRwbHCSoYkZ1cmmooNPAA645B32Zmh4vznufcDeDNHgG4PDv4Daa8BVYnuauOd0OqguzE7KStneuYS78iRIuANoWmYW6facHDnn58MXhYUvLIoHZe4sXJlpSrhLBXVbTbr8oSdtTyIiEhMtHaOcGJrk3Q3VpDkdtscRkXPQwp2IbVn5qpQVEZGktqdjhAO9Y+w6rnq2pDfeB4RMul3RSpgeUS3fEoRPZtRp4S5+TQxAz15Y9VZwnvvl9frKfA72jCnlUwxXCVz1GfjMC/CJp+Gy34ORE/CzPzOpdw9+xJzADwbmd3/7HoJQUHWykeJwwC3/aJJan/iS+fstkuB2HR8GYPNyLdyllIDfpADVbAFXqb05qjZBySWw72EIzNqbI9IOPQUBH9SpTna+PEW5dA5PnbeqNFGdTrhLkoU7TyFgTvCfS2uXl2XFOeRnW6ipPg+Hw8GKEhfHBpJvoVNeZ/0tgMN+rWwoBHt+CINH7M4hIklv+1yd7LZNqpMViVdauBOxTQt3IiKS5H62rweAjuEpZgNBy9NIVI2Z32vyKqC41vxatbKL1trlpbogmyJXpu1R5HyOPmuOq647703WVbqZ8gfOW8uUaHq90/peHgkOB9Rshlu+CV/cD++7B5ZdCa/9D/zX++CfGuHpr5savgtpuR+yCuzVBSaj7AK47bsQCsCDH4UZpaVIYtt9Ym7hTgl3qeXES+b9xrWWfz44HNBwO0wOmETWZBFe9lh/i905EkhNYQ4TMwFGJv22R4mocMJdslTK1pa4cGen03yOhLtpf4D2gYm4TGBfWeaia3SKaf88L1qRxOSuhGVXwMEnwT9tb46nvw4/+Qz88m/szSAiSS8YDPFoSxfLi3Np8sRPlbuInE0LdyK2ZeebGgIREZEkFAqFeHxfNwCzwRDdoxbfEJPoG59buAsn3IFqZRfJNxvgcN849dXxdzJDzhA+cbzquvPeZF2lqVva35P4F9m8cmyIK7/+C5q+8iQf+d7L/PuzR2jpGCGg9L6lycw1CXUfeRR+fw+85U+AEDz7d/DPTfD9bdDyIPinzv66vv3Q3QwbboWM5EhViRueLfD2v4LBQ/DTP7U9jciS7D4+TGV+NtUF+j6RUg4+YY62F+7gjFrZB+3OESn+aVNn6LkC8qtsT5MwPEU5gLkQL5n0jU3jcEBpXnIs3DmdDpo8hezrGn3DRTYHe8cIBENxmcC+ssRFKATHB5PjIie5gLqt4J+A9qftPP7O78Gv/l/z65Mv25lBRFLCy8eG6PX62NpUhcOhOlmReKWFOxHbstww7TUx1CIiIkmmtdvLyaEp3NnpgN78THpjZrkSdyUUzy3cKeFuUQ71jjMbDMVleoDMCYXgyDNQvAoKl5/3ZnWV5vdwf0/iX2Tz7IF+wCRIvHB4gP/z+H62ffsFNn31ST7+/Vf4j+faea1rVPW5S1G8Et72l/AHe+G3HoL698DxF+Hhj5vK2ce+CF17zJ+/vQ+Yr2m80+7Myerqz8OaG2DPf5mFR5EENDbt50DvGJtXFOokTao59KS5CKay0fYkULLaVNvufxRmkuD1YPvTMDMO9aqTXQhPsVm46xxJgj8DZ+j1+ihxZZGRljyn2ho9BUz7gxzsHT/r461d5gKieHyNWlvqAuDogJKJk144WdRGreyBn8FjfwSFK8wc3k4Y7Yz9HCKSEnbM1clubVKdrEg8S7c9gEjKy8qHoB9mfUolEBGRpBOuk/2dq1Zw9zNHkqZSUc5j7IyEu7xy8+uhY9bGSWSt3XMnM5RwF7+Gj8LoCbjsYxe82SUVeTgdsL878Rfudh0fJjczjZ989hr8gRC7jg/zUvsALx0Z5JkD/fy8rQ+AwtwMrlxZzNWrSrh6dSlrK/K06LFQzjS45Abzz8SgWa7b/QN45T/MPxUNJlU03wPL32R72uTkdMJ7/g3+7Rp49A9NBXDJattTiSxI88lRQiHYvFx1sill6CgMHITNHzaVrvGg4Q742Z/Bwcdh4222p1ka1ckuSk1hLpB8CXe93umkqZMNa/r/2bvv6LjqO+/j7ynSSKNerN5dsC1ZNnLHgAvV1FBDCilAOmlsNtkkz57nSXaz6ckmkJBCSCGQhJpgwBgwNt1V7pKreu8atRlpyvPHTyNTbKwyM/feme/rnD33rC3N/QaMPHPv536++ckAHGzqe8fn0Wodf0YtHg/c1XVL4C7spRZD1iI49hx4xsASFZrzNu2Fxz8JsSlw+1NqdfvRZ6BpNyTlhmYGIUTEGPN4ee5QK/My45mfpb+/d4UQp0ngTgit2dSKKVwOCdwJIYQIO5sPt5EeH82NFXn8evsp6nvk4mdYmwjcZaqLkDFJ0nA3TafbA5I0nkSc1STWyQLERFkoSo/jWLuxA3djHi/7G/s4vyAZq8WM1QIXzk3nwrnpAAy53Oyu6+Gtmm52nOrmxap2thxpByAtLppVJWmsmp3G6pI0Zs+KkwDeVMSlwarPwcrPQss+2PcQHHpcfYa86N9UMEwER/wsuOG38NAN8PgdcOeLYI3WeiohJq2yoReA8yVwF1lOvKCOc3WwTtav9AbY8k3VGGrkwJ1nDI4+q8Ie/kZvMSnhuFLW5/PR4XAxLzNB61ECanGeCtwdaOrnthWnf72q1UFijJXc5FiNJjs7f+CutlOuOUWEBdfBtu9B/Rvn/DweEN2n4JFbVMv4hx9VD+F4Per3mnZD6QeCP4MQIqK8cbKL3uEx7lgj7zeF0DsJ3AmhtZjxZLpr4HQTjBBCCBEGTnYMcLJjkA+tKKAg1Y7ZBA2yUja8DbSBNQZi1AV6UopVw4aYsqpWBwk268SNKaFDNdsBExRddM4vnZ+VwObDbYyMeoiNtgR9tGCobnUwMuZhWeGZQxtxNivrzstg3XnqM43DOcbu2h7eOtXNWzXdPHe4lWcPqbXTGQk2VpWksXo8gFeYZpcA3mSYTKplLbcCLv8eNO6QdrtQmL0eLroHXvspbP0OXPE9rScSYtIqG3qJtpgpy5VWhIhyfAtYokMTQpishEw1z8kXYbgH7KlaTzQ9da+Dsw8WfEHrSQwnMzEGq9kUVoG73uExRj3esGu4y0qKISPBxoHGvolf83p9VLcOUJqTqMv37Sn2KBJjrNRKw11kWHCtCtxVbwr+33WDnfDXm2CkF257BPKWqV9Pm6MeMm3cFdzzCyEi0qYD6vqZrJMVQv8kcCeE1vwNd85+becQQgghAsy/TnZjWRbRVjPZSbHUS+AuvA20QULW6dVVqcXQuh/GRiBKgmOT5fP5qG5xsCA7EbNZfzczBOpp9tpXIWfJpG4Yn5eZyHOH2jjePjCxoslo9tSplqSKswTu3i0xJopLFmRyyYJMAPqGR9k5HsDbUdPN0wdaePpACwDZSTGsflsDXn6qPTj/I8JJtB1mb9B6isix7ptQ+xq8dR8Ur4V5l2s9UeCd2gbHn1dhTotcLgwHXq+PyvpeynITsVmNGfYW0+AahLrXoHAN2OK1nuadFt0Cp16Gqn/Csju0nmZ6/OtkF1yn7RwGZDGbyE6Ooak3fK4JtDucAGQkhN/WmsX5ybx8tAPnmIeYKAuNvcMMuty6XCcLYDKZKJ4VT22XBO4iwqz5KvBW/Qxs/HHwGr9Hh+CRW9Xmhmt+DudtPP17ZjPkLVefEdwusIZX8FYIoR3nmIcXjrRRnpdE0XiDqxBCv2TviBBas72t4U4IIYQII5sPt5EYY2X17DQACtPsNPQM4/P5NJ5MBM1gG8Rnnf7/U8Zr73vrtZnHoJp6RxjQ8c0MAbQdVE+4l6yf1JfPz1YP2RxrM+57/r31vZhMkw/cvVuyPZorSrP4f9eV8vxXLmbv/7mUX3+kgttXFRJns/Lkvma+/vhBLvrRNtb/ZDsPvFaDwzkW4P8VQkyTJQpuekC1WPzzs+Bo1XqiwDr8BDx8M+z8DbQd0HoaESA1XYM4nG4qZJ1sZKl9BTyjMO9KrSd5r/nXqDbsQ49rPcn0eL1w9BlImwuzztN6GkPKS7bT3Bc+DXf+wF1mYhgG7vKS8Hh9HGlRJQHVrQ4AFmbr9zNqcZqdzgEXgy631qOIYDOZVMvdYBs07wnOOTxueOwT0FIJF33tzEHxvBXgcUHboeDMIISISNuPdTLgcnNtubTbCWEEErgTQmsSuBNCCBGGGnuGOdLi4NKFmURZ1FvOwjQ7gy43PUOjGk8ngsIzBkOdquHOL7VEHXtlrexUHGnR/82MiHdqmzqWrJvUl8/PUoG76jZHcOYJMp/Px576Hs7LTCAxJiogr5kWb+OqRdn81wfKeOmetez69iX88kPn86EVBQw4x/jvZ6u54Psv851NR6iX1VBCD1IK4bp7YbgbnvyUaroMB5V/gcfvBNP4JcLWg9rOIwKmsl6tAlw6zaC0MKjjW9RRj02cMYkqCFj/BvQ1aj3N1DXtgsF2FfLQ4UpNI8hNiWXA6aZ/JDwequhwuADCbqUsMNHKfaBRBe6qxj+jLtDxZ1R/C1CdtNxFhgXXqmP104F/bZ8Pnv0qnHgBFn8YNvyfM3+df72srJUVQgTQpvFtENcsztZ4EiHEZEjgTgitxfgDd8a8+SaEEEKcyel1sqc/GPpXBNb3hM8KGfE2g+3qmPC2iwGp4w13PRK4m4oqf3uANNzpV8121dCSv3JSX56fYscebeFoqzEfsmnqHaHd4QpqaCMjIYbrFufw/RsX8fo3NvDjm8vJS4nlj2/Use4n2/n0X/aws6ZbWlKFthZer9ot6l6D13+m9TQz99av4OkvQnIBfOxf6tfaJHAXLvbWT20VuAgDPh+ceFE1sPkffNGb8lvV8fAT2s4xHf51sgtlnex05aXEAoTNWtlwbrgrzx0P3DWp8HZVqwOrhOcW3AAAIABJREFU2cTcTJ2tqn6b4vHAnayVjRA5FZCYq342B/oz4is/Ug+lzN4A1/3y7CHrvGWASQWyhRAiAAZdbrYebWdFUSrZSbFajyOEmAQJ3AmhNZtqu5CGOyGEEOFk8+FW7NEWLpqbPvFrhanq4mejBO7C04AKWb6j4c6/UranJvTzGFhVi7qZMSdDvzczItrYCDTsgILVEDW5m2tms4mynCQONvXh9niDPGDgVTao0MayotCENmKiLNyyLJ/NX76IR+5aySXzM3ixup0P/m4H19z7Ok9WNjHqNt4/RxEmrvgfyFgI276vfhYYkc+n5t/yLUg/D+54Xv1Ms6dJw10YqWzoJTc5NiyDIOIs2g7BQAvMu0LrSc5uzqVqPfehx7SeZGp8PtWilJQP2Uu0nsaw8lLUQ3jNveGxVrZ9QAXuMsKw4S7JHkVxehwHm/wrZQeYkxGPzWrReLKzK5aGu8jiXyvbWxfYla6VD8H2/4Gscrj1L2B5n4b3mCSYNR+agrTWVggRcV6qasc55uXaJbJOVgijkMCdEFrzr5R1SsOdEEKI8NDucFLZ0Mf6+RnERJ2+GFuYNt5w1y2Bu7B0psBdQjZYbLJSdoqqWx3MyYh/x38/QkcadoDHNel1sn4rS1IZGvVwuMV47/v31I0H7gpTQ3pek8nEBXPSeeDjy3n539bxsdWF1HQOcc+jB1jzw5e5d+sJWVMuQi8qFm7+I1ii4Ym7YLhH64mmxudTQbtXfqBCI5/cDIk56qZlVjm0HwmfdbkRrH9kjBMdg5xfkKz1KCKUToyvk52rw3WyflYbLPwAtB+G9iqtp5m81gPQ1yDrZGcoN9nfcBcmgTuHC4vZRHpc+AXuAMrzkqjtGqK+e4jmvhHdN7D7V8rWdkvgLmJMrJXdFJjXO/EibPqyan/+yOOnyzLeT/5y6G8ER2tgZhBCRLRNB1qwmE1cVZZ17i8WQuiCBO6E0NpEw53xbrwJIYQQZ7LliH+d7Ds/GBZI4C68DYxfXHx74M5shpQiWSk7BX3Do+pmRra+b2ZEtJrt6liybkrftqokDYAdNd0BHScU9tT3kpFgm1gDpoXi9Di+e30ZO755Cd/cOJ8os4mfvnic1d/fyjefPMjxdmkMFyGUMR82/lDdXHv6i4FfYxUsXo+ad8evoeAC+PjTEJd2+vezy8E9Al0ntJtRBMT+RrUCMJirwIUOHd8C0QmqsVLPFt2ijkZqufOHORbIOtmZOL1SNjwCdx0OJxkJNszm8AxhLs5Toe1/7G4E0P1n1MSYKNLjo2WlbCQpWA329MAE7por4dGPQUwifPRJSMic3PflLVdHWSsrhJihvuFRXj3RyZo56aTFh2eYX4hwJIE7IbTmb7iTwJ0QQogwsflQG9FWM+vPy3jHryfGRJFij6KhRy5+hqWJhrvsd/56arFqg5C2nEmpalXvCfXeHhDRarZDbIpqgpqCioIUoiwmdhoscDfgHONYm4OlhSmYdNDokmSP4jNrZ/Pq19dz34fPZ2FOIn/b1cjlP3+V2/+wk+3HOvB6DRJ+EsZW8TEovRGOPgO7H9B6mnNzj8ITd8K+h9RKx48+odZgvZ3/51qbrJU1ur31qpm0okACdxFjqEuttJuzAazRWk/z/grXQEIOHHrcOIHl6k0QlwH5K7SexNCyk2KwmE0094XHQ3jtDhcZYby2e3G+ep/w2N4mQP+BO4CitDhZKRtJzBaYfxV0Vs/sgZGeWnjkVvB54UP/gPS5k//evPG/F5p2T//8QggBPH+4jTGPj2vLs8/9xUII3ZDAnRBam2i4k0YGIYQQxtczNMrO2m4unjuLOJv1Pb9fkBYnDXfhanA8cBf/rqeAU4rBOwb9TaGfyYCqxteNGuFmRkQa7lErxYrXqgbHKYiNtrAkP5nddb24Pd4gDRh4+xr68Pr015JktZi5pjyHpz6/hic/fwHXlGfz5qluPvHH3Vz281d4eGc9I6MS9BVBZDLBtf8LyYWw5dsq6KJXo8Pw9w/Dkadg4fVw298g2v7er8terI6tB0I7nwi4fQ292KxmFsj7ichx8iXAB3Ov0HqSczObYdFN0N8AjTu1nubcOo9B1zGYf7UKd4hps1rMZCXGhEXDncfro3PQRWZC+DbQlOYkYTGb6BxwARji75Ti9Dh6h8foGx7VehQRKv7m0em23A11wV9vUsebHoCClVP7/vR5YEuCRgncCSFm5ukDLURbzFwh62SFMBQJ3AmhNWs0WGPAKQ13QgghjO/Fqja8vveuk/UrTLXTMeCSEEQ4GmgDa+x723JSi9WxV9bKToa/4c4INzMiUu2rgG/K62T9VpWkMehyc6TFOO/994y3JC0rStV4krOrKEjhvg9X8OrX1/OZtSV0Drj49lOHWf2Drfzo+aO09Tu1HlGEq5gkuPmPqg3jD5er4J3eHqZzOuDhm+Hki7Dko3DTg2dvv0qdDVFx0nBncB6vj/0NfSzOSybaKpd+I8bxLeo49zJt55isRbeqoxHWylY/rY4LZZ1sIOSmxIZF4K57yIXH6yMzjBvuYqIsnJepygKyk2JIidN5eyZQlB4HIGtlI0nxxWqL1HQCd6PD8MgHoecUXPVjWHDt1F/DbIa8pdCyTzVKCyHENHQ4nLxV082682aRGBOl9ThCiCmQqy5C6IEtUX8X5YUQQohp2Hy4DavZxKULMs/4+wWpqk2lsVda7sLOQBskZKnGn7dLGQ/c9UjgbjKqWhzkGORmRkSq2a6OJeum9e2rStIA2GGgtbJ763uIiTJTaoA1x7nJsXxz4wLe+uYlfPf6UlLs0fx6+yku/OHLfOXv+zjY1Kf1iIbi8/lkJddk5C2Fu15S7XBv3Qf3rYAj/9THmsShbvjLdVD/Bqz8HFx3L1je20A8wWyGrDJoPaiP+cW0nOgYYMDl5vzCZK1HEaHiccOprZBTAfEZWk8zOVmLYNZ81bzpGdN6mvdXvUkFrIsu0nqSsJCXEkv/yBgDTp3/ez+HDodqfctMDN+GOzi9VtYoDezF44G7um55DxsxrDaYdyW0VEJf4+S/z+OGJ+6E5j1w4VdhxaemP0PeCvC4oO3Q9F9DCBHRnj3Uis8H1y3J0XoUIcQUSeBOCD2wJYDLOC0XQgghxJk4nGO8cbKL1bPTSLKf+UmsgjQVuJO1smFooFUF7t5NGu4mzeX2cLJjkIUGCDZFrJrtan2k/8/1FFUUpBBlMRkmcOf2eCdakqIsxrl8EGez8rHVRWy9Zy1/+PgyVhSn8s/9LVx33xvc8ps32XyoFY9XwkTn8vvXalj3k+0caJSg4jnlLFGhu6t/BmND8NjHVatc9yntZnK0wp+uUm0ba78BV35/cquws8rB2Qf9U7hhKXSlsl79N1tRoK9V4CKIGneCsx/mGWCdrJ/JBItuhuFuOLVN62nOrrderdk+7yqwSNtIIOQlxwLQ3Gfslrt2h2pQzgjjhjuAxXkqvG2Uz6jFEw13cs0povib6Y4+O7mv9/lg87/Dseeg/INwyf+d2fnzl6tjk6yVFUJMz6YDLdijLVwy/8wlBkII/TLOFXMhwlmMNNwJIYQwvperOxjz+NhYln3WrylM9Qfu5GnjsOIeVTfLzhS4Sy4ATNJwNwkn2gdxe32GaQ+IOL11Kjhasm7aLxEbbWFxXjK763pxe7yBmixojrYNMDTqYVmRMUMbZrOJSxZk8sinVvHcly7ilqV5HGjs53MPV7Lhp9v51/5mvBK8O6Mhl5v7t6uw2O66Ho2nMQizBZbfCXfvhcUfhpMvwa9Xw/YfwFiI1xr31sEfr4TOo3D5f8P6b723gfZsssvVsVXWyhpVZYNaBS6Buwhy/Hl1nHu5tnNM1aJb1PHQo9rO8X78KwoXyDrZQMlLUdcEmg2+VrZ9ouEuvAN3ly7M5KK56Vy72BiNO0VpslI2Is25BKyxk18r+9pPYc+D6rP9dfdN/n3y2eQuU8emXTN7HSFERGrsGaayoY/LFmYSG23RehwhxBRJ4E4IPbAlgFMa7oQQQhjb84fbMJng8tKzP4lVOH7xs6FHnjYOK4Pt6phwhrCl1QZJ+dJwNwlVrer9oFHaAyJOzSvqWLJuRi+zqiSNQZd74t+3nu2tV6GNZYWpGk8ycwtzEvnxLYt54z828KVL5tIzNMqX/76fq375Gi9WteOT9Znv8Ncd9fQOq1VvVS36/7OqK/Gz4Ib74RPPQWoJbP8+/HqVCuCFQsdRePBK1cp07S/ggi9O7fuzxgN3bRK4M6rK+l4KUu3MSgjvNYfibU68APGZkL1E60mmJqVIreE7+iyM6jQcU70JouJg9nqtJwkbeSmq4a7J8IE7FaYP95Wy6fE2HrpzJfMyE7QeZVJioy1kJcZQJ4G7yBIdp0J3DW/CYOf7f+3+R+Dl/4LMRXDrQ2CNnvn5Y5Mh/TxolIY7IcTUPXOwFYBry40RbhdCvJME7oTQA1uiWikrN3mEEEIY1PCom+3HO1helEp6/NkvOGck2LBZzbJSNtwMtKnjmRruAFKLVMOdvNd5X/5Qy8LsJI0nEWdUs10di9fO6GVWlaQBGGKt7J7xwN35BckaTxI4sxJs3HPZPF77+no+t242dd1DfOove7jx/jd581SX1uPpwsioh9+9WkN2UgzZSTEcbunXeiRjKloDn30NLvuuCqb/9SZ49GPgaAneOVv2wR83wlAn3PQALP3E1F8jYwGYrdJwZ1C9Q6PUdA1REUY/t8U59NarNsu5l01ubbTelN8KY8Nw9DmtJ3mvgTa1rnfuZRAVq/U0YSN3InBn7GsCHQPjgbuE8G64M6Li9DjquobkgZpIs+A68HnVmtizObkVnv6ieij0I4+pzVOBkr8c+htOXx8TQohJ2nSghcQYKxfPm6X1KEKIaTDgp3AhwpAtEfDB6KDWkwghhBDT8sqxTpxjXjaWnSVwNc5sNlGQapeGu3AzOH5BMf4s//5TitX7nCEJs7yfqlYHCTbrROuD0BGvF2pfUc1PcWkzeqmKwmSiLCZ21Oh/Tefeuh7mZsSTbA/AU/86k2yP5htXzufVf1/Px1YXcri5nw//ficffWAn+xv7tB5PUw/vrKd7aJTPrZvNotwkTnUO4RzzaD2WMVmiYM2X4Qu7YMG1UPUvuG85vHkfeMYCe676N+HP16mWqNsegUU3T+91rDaYtUAa7gxqX+P4OtlCWScbMU68oI5zr9B2jula+AEwWeDQY1pP8l5HnwF8sFDWyQZSdlIsJhM09xm94c5FtMVMsj1K61HEuxSlxzHgctM1OKr1KCKU5l2hHho521rZlv3q4ZfoOPjI45B4hg0NM5G3Qh2bpOVOCDF5JzsGqWp1sLEsm2irxHaEMCL5L1cIPfA/SeMa0HYOIYQQYpqeP6ICV1eUvn/gDqAg1U5T7zAerzxtHDbO2XBXrI6yVvasfD4f1S0OFmQnYjabtB5HvFv7YRjunvE6WQB7tJXyvGR21/bg9nhn/HrB0tI3Qku/k2VF4R3ayEiM4bvXl/Hyv63jxopc3jjVxQd+9QafeWgPx9sj7/OZc8zDb1+tITPRxq3L8inLTcLj9XG0LfL+WQRUcj588K/w4cfAngYvfBt+uxYadgTm9U++BA/dqFo9Pvq4uuE4E9nl4GiGIf03cYp3qqxXgeGKgvD+2S3e5vgWMEcZd+Vp/CyYvQFObdXfz5zqTWCJhrmXaz1JWIm2mslMiAmLlbIZiTZMJvnspjfF6XYA6rplrWxEiU1WbfQ128H5robu3np45Fb1wMuH/g4Z8wN//rzl6ti4K/CvLYQIW5sOqAb8axfLOlkhjEoCd0LogS1BHZ0ObecQQgghpsHl9vBydQeL85PJST53M1dBmp0xj4/WfmNfYBdvM9CqjglneUI4ZTxw1yOBu7Np6h1hwOVmYU4AV5qIwPGvky1ZF5CXW1WSyoDLTVWrft//+9fJLi1M1XiS0MhPtfOzW5ew5SsXc2VpFluOtHPF/77KPf/YT2MEtbL+fVcDnQMuPrt2NjFRFkrHfyYdbpa1sgEx73L4wk64+OvQfQIevAL+9YWZhUyq/gWP3Kaa6T72NBRfPPM5s8rVse3AzF9LhNTe+l7s0RbmZyVoPYoIhdFhqHsNCi84fW3RiBbdAl43VD2l9SSnDfdA7WsqDGjkf7Y6lZcSGwaBOxeZibJOVo+K0+MBqO2SwF3EWXAteMfg+Aunf224B/56Ewx2wE2/V39nBsOs+WqTlTTcCSEmyefzselAC+nxNlbPntk2DSGEdiRwJ4Qe2KThTgghhHG9cbKLAZf7nOtk/QpT1dPGDd2RE2AIexMNd5ln/n1puDunIy0qeLUwWwJ3ulSzHSy2gF2cX1WiLqTt1PFa2crxwN2yCFtLOC8zgd/cvpR/fWENF85J58l9zWz46Xb+85+H6XA4tR4vqJxjHu5/5RTp8TY+tKIAgLLcJOD0zygRAFGxsOHb8Lk3VYh331/hvqWw989qffVU7HsYHvsE2FPhk5shb2lgZsweD9y1ylpZI3F7vBxo6qM8LwmrRS75RoTaV8HtnHmrpdbmXw3WWDioo7WyxzaDzwMLZJ1sMOSlxNIzNMrwqFvrUaZlzOOle8hFZqJN61HEGfgb7iRwF4HmXw2YoPpp9f+PjcDfblMPulz5A1h4ffDObTZD7lJo2aea9IQQ4hyOtDio6Rri6kVZWGTbiRCGJVdfhNAD/5OSLmkNEEIIYTzPH1ZhqysnsU4WoDAtDoD6CGoMCnsDbRBlP/0QwbtJw905+ZvOpOFOh9wuqH8TClaqoEwALC1MwWo2saNGZ6vT3mZPfQ/p8dEUptm1HkUTi/OTeejOlTzyqZWU5Sbx0I56Lv7xNn6w+Sh9w6NajxcUj+1tot3h4rNrS4iJsgCQkWAjPT6aIy3yWTXg0ufC7f+Emx9Ugd5NX4IHL598yG3Hb+Bfn4fEPBW2y1wYuNkyy9SxTQJ3RnKsfYDhUY+sk40kx59Xx3lXajvHTNniYf5V0LhDrf3Tg+pNYLLAeRu1niQs5aao99TNBm256xp04fNBRoI03OlRfqodswnqJHAXeeIzoGA1nHwJXIPwxF3QuBMu+CKs+mzwz5+/QgXh2w4F/1xCCMPzr5O9bomskxXCyCRwJ4QexEjDnRBCCGNye7y8WNXO/KwEitLjJvU9BePhjXppuAsfA22QkAWmszyNF5MI9jRpuHsfVS0OrGYTczLitR5FvFvjTnCPBGydLIA92sri/GR21fbg8foC9rqBMuRyU906wNLCFExn++86QlwwO50nP3cBD3xsGUVpcfzmlVNc9KNt3PfyCYZcxmxlOZNRt5f7t50kLS6aD68smPh1k8nEwpwkjrYNMOaZYvuaODeTCcpugrt3w6rPQ/Ne+N1a2Pwf4DxLq6DPB6/8GJ7/BqTNhTs2Q9rswM4VkwipJdJwZzCVE6vAJXAXEXw+OPECpM4O/M8ALSy6VR0PP67tHKCuz556GYouVA2iIuDyUtQ1AaOulW13uABkpaxO2awWclNipeEuUi24FsaG4c/XwtFn1HvtS78bmnPnLVdHWSsrhDgHr9fHMwdbyU2O5fx8+fwmhJFJ4E4IPfC3wZztgroQQgihUztre+gdHmNjWfakvycvJRaTCRp65OJn2BhohYRz/BlIKZaGu/dR3epgTkb8RKuU0JGa7epYsi6gL7uqJJUBl5sqHa7q3N/Yh8frk9DGOJPJxKULM3nuSxfxi9uWkBoXzU9eOM7FP9rGg6/X4hzzaD3ijD1R2URLv5NPXVyCPdr6jt8ry0lk1O3lZMegRtNFgJhEuPL78OlX1CqqnffDfcvh8BMqVOPn88GL/wnb/huyFqlmu6S84MyUVQ7dJ1U7iDCEyoY+AM6XhrvI0H4EHM3GXyfrN3sDxKbAIR0E7k68CB6XCm2IoMgbb7hr6jNq4M4JICtldawoLY667iG8Ony4SQTZgmvUsaUSii6CD9yv1r2GQt4ydZTAnRDiHCobemnuG+GaxdmYZZ2sEIYmgTsh9MAmDXdCCCGMyb9OduOiya2TBfW0cU5SrDTchQu3C0Z6ID7z/b8utRiGOuTG/Rn0DY/S3Dci62T1qmY7xCRB9pKAvuzK4jQAXa6V3VPnb0mSVpe3M5tNXL8kl5fuWcv/3LCIKIuZ7z5TxYafbOfR3Y24DdoAN+bx8qttJ0mxR3H7qsL3/H5pThIAR3QYDg072eVwxwtw7S9V2OPxO+ChD0DXSfB64JmvwJv3Qv5K+PgzED8ruLPgU6EeYQiVDb0Up8eRGhet9SgiFE5sUce5l2s7R6BYo6H0BuiogrbD2s5S/TRgksBdEOUmjwfueo15TaBjInAnDXd6VZweh3PMS/uAU+tRRKglF0DxWsheDB/8K1hDGIyNTYH0edC4K3TnFEIYkn+d7LXlsk5WCKOTwJ0QemBLUEcJ3AkhhDAQr9fHliNtlKTHMXeKazDzU2Np6B7G55OnjQ1vsF0dz9Vwl1qijr11QR3HiKpaVYhlYbYE7nRnpBda9kHxxWAObPvg0sIUrGaTPgN39T1EW82U5cqfyTOJspj58MoCtv/7Or591QJGxjx8/YmDXP7zV3nmYIvhmjSe2tdMU+8Id11UQpzN+p7f9/85ONLSH+rRIpPZDEs/DnfvhfM/qkK/96+GB6+AvX+CkvVw+1MQmxzcObIWq2PrgeCeRwRE16CL+u5hKqTdLnIcfwGi46FwjdaTBM6iW9Tx0GPazTDmVP9s81dAwuQfKhNTkzMRuDNqw51/paw03OlVcXocgKyVjVS3/xM+tS3475fPJG859NXDYEfozy2EMAS3x8uzh1opmRVHqTx8LYThSeBOCD2I8TfcSWOAEEII46hs6KVjwMWVZVmYTFOrPi9MjWPA5aZveCxI04mQGVAth+e8IZVSrI69slb23fwrRaXhTofqXgefN+DrZAHibFbK85LYVdeDR0cBLY/Xx76GPhbnJWGzyorj9xMTZeFTF5fw6tfX8+VL5tLucHL3I/u49r7X2XaswxChcvd4u11ijJWPrX5vux1AfoqdBJuVI83yeTWk4tLg+l/BHVsgba5aTTX/GvjwPyA6Lvjnzy5XxzYJ3BlBZb1qJq0o1ODGsgi94R5o2qXen1jDqNEwfxUk5au1sl6NWmNrtsHYkLTbBVlMlIWMBBvNhg3cqda0DGm4060iCdxFNrM54A/MTVrecnWUtbJCiLN49UQnXYOjXFueM+V7KkII/ZHAnRB6MNFwJzcwhBBCGMfEOtmyczSbnUFBmh2A+h5jrpARbzPZwF3qeOCupya48xiQNNzpWM12dSxZH5SXX1WSxoDTTXWrfj4HHG8fYNDllnWyU5AQE8VXL5vHa9/YwKcuKuZExyCf/ONuvvXUIa1HO6enD7RQ3z3MnReWkBATdcavMZtNLMxJpKrVYbj2vrBQsAo+86paNXvLn0O3Fis+A+KzoPVgaM4nZqSyoQ9AGu4ixcmX1AMB867UepLAMpuh7CZwNEHjDm1mqHpaHSVwF3S5KbHGbbgbcBEbZSHhDM3AQh+K01Tgrk4CdyLU8leoo6yVFUK8S3Wrgy/9bR93/XkPFrOJ65fIOlkhwoEE7oTQg+jxwJ1TPzfahBBCiPfj8/nYfLiN3OTYaa0cLPQH7rrl4qfhTbXhrkca7t6tqsVBbnIsyfYwaigJFzXbVdOKfyVygK0qSQPQ1VrZPeMtScsKJbQxValx0Xz76oW88u/ruGB2Gn/b1cjmQ61aj3VWHq+P+14+SYLNyifWFL3v15bmJDHocktQXisWKxSsVMdQyi6Hjmpwj4b2vGLKKht6ibdZmZeZoPUoIhSOb1HHuZdrO0cwlN+qjgcfDf25PWNw7DnIKoeUotCfP8LkpdjpGnThHPNoPcqUtfc7yUy0SSuNjuWlxGI1m6jtkveuIsRmzVf3+6ThTggxbm99D3f+aTcbf/EaTx9oYc2cdP7+6VWUzIrXejQhRABI4E4IPTCb1Ztw14DWkwghhBCTcrjZQXPfyLTWyYJaKQvQ0C0XPw1vYDxMknCOpsP4DIiKk5Wy7+JyezjZMcgCabfTn75G6D4JJWshSDfTlhamYDGbdBW421vXA0CFBO6mLTsplv+9bQkp9ii+9dQhOgacWo90Rs8cbKGma4hPrikiKfbM7XZ+peMrr4+09IdiNKEXWeXgHYPOo1pPIt7HmMfLwaY+luQnYzFL+CPsedyq4S57CSRkaj1N4GWWQsZCqPpn6MO+R58FZx8suC60541QucmxADT3Ga/lrn3AKetkdc5qMVOQaqe2a1DrUUSkMVsgtwKaK1WQWwgRkXw+H68c7+SDv32Lm+5/i5ePdbCxLIun717DQ3euZHmRbJUQIlxI4E4IvYhJlJWyQgghDOP5IypktbHsHK1mZyErZcPIZBvuTCbVFCENd+9won0Qt9fHwhwJ3OlO7SvqGKR1sgBxNivleUnsrO3Bo5NVnXvqeymZFUdqnDQuzkRGQgzfu2ERvcNjfOvJQ/h8+vj36+fx+rj35ZPERVu448Lic359WW4SoAL3IoJkl6tjm6yV1bPqVgfOMS8VBclajyJCoWm3CoXNu0LrSYJn0S0w0guntobmfEPd8PSX4LFPgMUGZTeG5rwRLi9FBe6MtlbWOeahb3iMTAnc6V5xehwNPcO6+ZwlIkj+CnCPQPsRrScRQoSYx+vjuUOtXHvf63z8wV3sre/l5qV5vPjVtdz/0aWU58lnNiHCjQTuhNALmzTcCSGEMAb/OtlZCTYqCqbXgJQUG0WyPUoa7sLBYJtqrrNNYoVZajH0N8lTvm9T1arCKwul4U5/ararY/HFQT3NqpI0Bpxuqlu1DzK1O5w09Y7IOtkAuWpRNh9YksNL1R08tqdJ63HeYfPhVk52DPLxC4omtc569qw4bFazNNxFmqzxwF2rBO70rHJ8Ffj58rM7Mpzwr5MN58DdzeoY7LWQ5H7EAAAgAElEQVSyXg/s+SPctxQq/wxFF8JnXoG02cE9rwBOB+6aDRa46xxwAZCZYNN4EnEuRelxjHl8hvszJsJA3gp1lLWyQkSMUbeXR3c3ctnPXuHzD1dysmOQT1xQxCtfX89PblnMnAxZHytEuJLAnRB6YUsAp/Y32YQQQohzOdExSE3nEFeUZmKewdqqglQ79T1DAZxMaGKg7dztdn4pReDzQF9DUEcykqoW9f6vVBru9MXnU4G7zDK1DjmIVpWkAehireyeOhXaWFYoqy0C5TvXlZGVGMN3Nh2hUSetrl6vj3u3nsQebeGui0om9T1Wi5n52YlUtTh019YngiilCGxJ0nCnc3sb+gCoyJfAXUQ4/gLEzYKc87WeJHiSC6BgNRzbHLyHk5v3wgOXwjNfUa12N/0BPr4JMhYE53ziPU433Onj/dFktTucANJwZwBF6XEA1HbLdScRYnnL1LFxl7ZzCCGCbnjUzYOv17L2x9v4+hMH6Rx0cff6Obz+jQ38v+tKyU2O1XpEIUSQSeBOCL2wJUrDnRBCCEN4/rBaIbqxLHtGr1OQaqfd4cI55gnEWEIrA62QMMk/C6njawt7Za2sX1WrgwSbdeKGk9CJjioY6oSSdUE/1bLCFCxmEztqeoJ+rnPZU69mWFokoY1ASbJH8eNbyhka9fBvjx3Aq4OVVi9UtXGsfYDbVxVOaXVwaU4i3UOjtI3faBYRwGSCrEXQdgi8Xq2nEWdRWd/LnIx4kuxRWo8igq2vETqOwNzLwRzml/UX3azW8R19NrCvO9wDm74Mv78EWg/A6rvh7t3qfKbpP0wmpi432Q4Yb6Vsu0M13GUkSsOd3pWMB+7quiRwJ0LMngppc6ThTogw1j88xi+3nmDND17mu89UMebx8Y0r5/Pmf2zga1ecR3q8vE8QIlKE+SdzIQzElgBjQ+Bxaz2JEEII8b42H24j2R7FiuKZNSAVpqkL7Hpp/BHT4HbBSC8kZE7u61PGA3c9ErgDtZ65usXBgpxETHKDT1/862RL1gX9VHE2K+V5Seyq7cajcRirsr6X1LjoiZtTIjAumjuLj60uZFdtDw++oe3PP5/Pxy+2niQmyjzpdju/spwkAI40SzN7RMkuh9FBCcvrVIfDSXPfCBUFyVqPIkJhYp3s5drOEQoLbwCzFQ49FpjX83ph75/g3gp1LFwDn30drvgexEjTtBZioy2kx0fT3Ge0wJ003BnFRMOdBO6EFvJWqPfPg51aTyKECKAOh5PvP1fNBT/Yys9ePE6czcp/XV/K699Yz+fWzSYhRh6CEiLSSOBOCL3wX9wZlZY7IYQQ+lXfPUR1q4PLFmQSZZnZW8nC1Ljx15TAnWENqLbDqTfc1QVlHKNp6h1hwOVmYbbc5NOdmu1gjlLrzEJgZXEaDqeb6lbtgkwjox6OtDioKEiRAGgQ/MfG+RSnx/GjLcc43q7dZ76XqjuobnXwkZWFzEqY2hPX/tXXh1v6gzGa0KuscnVsPaDtHOKMKhvUKvClhdJMGhGOv6BCaLPXaz1J8MWlwexL4NS2mYcVmivhD5eqZjtLNNz4AHziGchcGJhZxbTlJscab6XsgATujCI7MQab1SyBO6GN/OXqKC13QoSFhu5hvv3UIS780TZ++2oNOcmx/PyDi9n2tXXcvrqImCiL1iMKITQigTsh9MI2fqPVKW0BQggh9GtineyirBm/VsF4w129NNwZ10TgbpJ/HpIK1E1CabgD4EiLet+3MEcCd7riHoW6NyB/BdjiQ3LKVSWqMXRHTXdIzncm+xv7cHt9LJN1skFhj7by01sX4/Z4uefR/Yx5Qr+e0+fz8cutJ7BZzXzm4qm12wGcl5WAxWya+NklIkT2eOCu7aC2c4gz2luvAncVBfKzO+yNjUDtq+phgJgkracJjfJbweeBI09N7/uHe+CZr8LvN0DL/vH1sXug/BZZH6sTeSl22h0uXG6P1qNMWsf4StlMWSmre2aziaK0OOq6JXAnNJDnD9zt0nYOIcSMHG1z8OW/72P9T7fz8M4GFmQn8rvbl7LlKxdzw/l5My4kEEIYn/wUEEIv/IE7lzTcCSGE0K/Nh9uIt1lZMyd9xq/lXynbIBc/jWugVR3jJxm4s1ghKR96aoI3k4FUjbeZBbXhzudTK7TE5DXvgbEhKAlde8yyolQsZhM7a3tCds5321uvzi0tScFTUZDC59fN4XCzg3tfPhny828/1smh5n4+tKKAjGm0ssREWZibEc+RZmm4iyjp88Big1YJ3OlRZUMfiTFWZs8KTUBcaKj2NXCPwLwrtJ4kdM7bCFFxcOjRqX2f1wt7/wz3LoU9D0LhBbI+VqfyUmIBaO1zajzJ5LU7nCTEWLFHW7UeRUxCUbqdxp5hRt3ymViEWMZCiI6Hpj1aTyKEmIa99b3c9efdXPm/r/Gv/S2sLknjkbtW8s/PX8DlpVmYzfLwhhBCkcCdEHphS1BHl7QFCCGE0KfW/hH2N/axYX4GNuvMa9IzE2KItpql4c7IBtvVcbINd6DWyvbWqSBYhKtq6cdqNjE3M0g3yRt2ws9L4bmvBef1w1XNdnUsWReyU8bbrCzKTWJXbQ9erzb/beyp7yXaYmZRboS05mjkS5fMZWF2Ir/adpL9jX0hO6/P5+MXW08QbTHz2bWzp/06C3MSael30js0GsDphK5ZotTaxbaD8ne3zrjcHg4197OkIEVu+ESCE1vUcW4EBe6i42D+1Wod32Qbslv2wR8ug01fUj+/bvw9fOJZWR+rU7njgbum3hGNJ5m8dodT1skaSFF6HF4fNBpsdbEIA2YL5FZA817wuLWeRggxSYMuNx95YAc33f8mL1V3cGVpFv/6whr+etdKLpiTjklakoUQ7yKBOyH0IkYa7oQQQujbFv862bKZr5MFtd4jPyWWhm658GlY/oa7hOzJf09KsWrn8K+jjVA+n48DTf2cl5UQkADre1Q+BH+6GhzNUPUvCUlMxaltqn065/yQnnZVSRr9I2NUt4X+ARyv10dlfS9luYnERAXhz6OYEG0187MPLsZiMnHPo/sZGQ3NCrXXTnSxv7GPDy7PJytp+jeJy3JUIFPWykaYrHIY6oz4v7v15kiLg1G3l6WyTjb8+XxwfIt6H50+V+tpQqv8VnU89Pj7f91wDzxzD/xuvQrdrfo83L1bfb/cGNWtvInAnXGuCXQ4XLJO1kBK0uMAqOuSzQpCA3nLYWwYOo5oPYkQYpI2H2rljZPdXFGayUv3XMxvbl/K4vxkrccSQuiYBO6E0At/w51TblwIIYTQp82H24iJMrP2vFkBe83CtDiaekfwaNToJGbIf+M9IXPy35NarI69k2ypCFNtDiedAy7K8wJ80cbjhs3fgKfvVkHIuZfDcBd0nwrsecKVs189gV50kVqBHEIrS1IB2FET+rWyJzoGcTjdLCtKDfm5I9H8rET+7fJ51HQO8cPnjwb9fP52uyiLic+um367HUBpjnpQ7HCLrJWNKNnl6tgma2X1pLK+F4CKQrkBFPY6qqG/Ua2TjbTwWMk6sKeptbJneoDE64XKv8B9y2DPH6BgNXz2Nbjy+xAjrb16l5diB6C5zxgNd0MuNwMuN5kJ0nBnFEVpKnBXK4E7oYW8FerYtFvbOYQQk3aqU/198e9XnMecjASNpxFCGIEE7oTQC5u/4U4Cd0IIIfSna9DF7roe1s6bhT06cCGUglQ7ox4vbQ5nwF5ThNBAG0THn35wYDJSxgN3k10LFaYONKqwyuK8AN4IHO6Bh2+Cnb+BwjXw6W2w+EPq9xp3BO484azuDfB5QrpO1m9ZYQoWs4kdNd0hP/fe8dDG0kJpSQqVuy4qYXlRCn96s443TnYF9Vxvnepmb30vNy/NJzc5dkavtXA8cCcNdxEma7E6tkrgTk/2NfRhMsESaVwIfxPrZC/Xdg4tWKKg9EboOv7e0G/LfrU+9ukvgskCN/wOPvkcZJZqM6uYMv/7EqOslO0YcAGQIStlDaM4XQJ3QkN5y9WxUQJ3QhjFqc5BLGYTBalxWo8ihDAICdwJoRcSuBNCCKFjL1a14/XBxrIprA6dhMI09UR7fbdc/DSkgTZImOKKYWm4A+BgUx9A4BruOo7C7zdAzXZYdgfc/k+IS4eCVer3GyRwNyk129WxZF3IT50QE0VZbhK7anvwhrj1c0+9atWTwF3oWMwmfnrLEuzRFr722AH6R8aCdq5fbD2B1Wzi8zNstwP157Qozc6RZmm4iyiZpWAyQ9sBrScRb1PZ0Mt5mQkkxERpPYoItuMvQFQcFF2o9STaWHSLOh56TB0n1seug5ZKWPk5+OIeWPzByGsANLg4m5UUexTNBgnctY8/KCgrZY1jVoKNuGgLdXLNSWghLg1SS6Bpl9aTCCEm6VTnIIWpdqKtEqERQkyO/LQQQi9i/IG7AW3nEEIIIc5g8+E2oiwm1s/PCOjr+gN3Dd3DAX1dESIDrWpt6VSkFKljpDfcNfURE2VmXmb8zF/s2PPwwKVq1djVP4Vrfg7WaPV7iTmQVACNO2d+nkhQsx0SciB9rianX1WSSv/IGEfbQvuZYG99L8XpcaTHy83DUCpIs/Of1yyktd/JdzYdCco5dtR0s7O2hxsrcslPtQfkNUtzkqjtHmLQ5Q7I6wkDiLZD2lxpuNORlr4RWvudnF8gQemwN9Kr3seVrANrhP49nb8Ckgvg0BPvWh+7Cj7zGmz8gayPNbDclFiaeo1xPeB04E4a7ozCZDJRlB5HbacE7oRG8lZATw0MBbfVXAgxc2MeLw3dw5TMCsC1WiFExJDAnRB64V/F5pSGOyGEEPrSPzLGmye7WDMnnaTYwDZo+OvZ63uMcYFdvM3YCDj7ID5zat8XHae+J4Ib7rxeHweb+inLScJqmcFHMp8PXvsZ/O02tW7r9n/C8rve+3UFK9UarqHQryo1FEcLdB1TN7Q1akdZVZIGENK1sp0DLuq7h6mQ0IYmbluez/rzZvFkZTPPH24L+Ovf+/IJLGYTX1g/J2CvWZqbiM8H1a3y2TWiZJdDXz2M9Gk9iUC12wFUFMg62bB3cqtadz8vAtfJ+plMquVuoGV8fawZbvgtfHIzZJVpPZ2YobxkO20OJ2Mer9ajnFOHQ62UlYY7YylKj6Ol34lzzKP1KCIS5Y+vlW3ao+0cQohzqu8exu31MTtD1skKISZPAndC6IVNGu6EEELo09bqdtxeHxvLprg6dBLyUmIxmaThzpAG29VxqitlAVKKI7rhrq57iAGne2brZMdG4Im7YOt3IGMBfHobFF905q/NX6mO0nL3/mpeUceSdZqNsKwwBYvZFNLA3d7xdbLLiiRwpwWTycQPbyon2R7Ft586RNegK2CvvaeuhzdOdnP9khwK0wJ3wbg0R7UIyVrZCJNVro5th7SdQwBQWa+CjxWyCjz8Hd+ijnMjOHAHcP7tai3fis/A3Xtg8W2yPjZM5KXE4vVBW79T61HOyd9wl5EgDXdGUpI+/qCnXHcSWshboY6yVlYI3TvVOQjAbGm4E0JMgQTuhNCLqFgwWSRwJ4QQQnc2H27DbIJLF0yxyWwSYqIsZCXGUN8j6z0MZ2C8iWmqK2UBUothpAeckRnWONik/ncvzp/m6qv+ZnjwSjj8OMy/Bu584fSq3jMpWKWOjTumd75IUbNdHUvWajZCQkwUZTmJ7Kztwev1heSce+pUS9IyCW1oJiMxhu99YBHdQ6N888lD+HyB+Xf/i60nMJsIaLsdQGmOeljsSIs03EWUbH/gTtbK6sHehl6S7VETIQIRprweOPmSCrwm5mg9jbZSi+FL++CqH0GsNDuGk9yUWAAaDbBWtn1APRiRIQ13hlI0/uBJbdegxpOIiJSxEKLioFECd0LonQTuhBDTIYE7IfTCZIKYRHDJTQshhBD6MeRy8+rxTlYWp5EWH5yLygWpdmm4M6KBVnWcTsNdaok6RmjL3f5G1UqzeDoNd4274HfroHU/rP0G3PoQ2BLe/3syFqo25QZpuDsrn08F7mYtmN6f6QBaVZJG/8gYR9tC8yDOnvpekmKj5IKixq4uz+b6JTm8WNXO43ubZvx6lQ29vHaii2sX5wT83216vI2sxBgOS+Ausvgb7lolcKc155iHqpZ+KgpSMEnDV3hr2qMeUpl3hdaTCBE0eSl2AJp6RzSe5NzaHU5S7FHYrBatRxFTUJTuD9zJdSehAYsVciuguVIF6YUQunWqQxUCzJ4lDzUJISZPAndC6IktQQJ3QgghdGX7sU5cbi8bFwUvgFKYZsfhdNM3PBq0c4ggGJjhSlmAnprAzWMgB5v6SIqNojDNPrVv3Pcw/OlqGB2EW/4E678F5kl8pDNbIG85tOwDd+DWVYaVzmMw2KbpOlm/VSVpAOysDf5aWeeYhyMt/SwtTMFsltCG1r57XRmZiTa+s6mKphm2vNy79QQmE9wd4HY7v7LcRE60D+Byy02jiGFPhaR8abjTgcPN/Yx5fFQUSMtX2DvhXycrgTsRvvLGG+6aDRC463A4yUyUdbJG42+DreuSzQpCI3nLYWwIOqq0nkQI8T5OdQ6SHh9Nsj1a61GEEAYigTsh9MSWBE4J3AkhhNCPzYdVi9nlC4MZuFMXP+ul5c5YJhruprlSFqA38hruxjxejrQ4KM9LmnwrjccNz38L/vV5iM+EO7ZA6Q1TO3HBKvC4oGX/1IeOBBPrZNdpOISyrCgFswl21AQ/cHewSYU2lso6WV1Iskfxo5sXM+hy87XHDkx7rfDBpj62HevkqkXZzM08RwPmNC3MScLt9XG8TVZzRZSschVQHtN/KCKcVTaoVeAV8rM7/B1/AexpqhlHiDDlXymr94Y7n89Hu8NFhgTuDCclLpqk2ChqJXAntJK3XB1lrawQuuXz+TjVOUiJbH8QQkyRBO6E0BNbArhCszpKCCGEOBfnmIdtRzuoKEgmKyl4F5ULUlXLV32PBO4MZaBNHeMzp/69Ew13kRe4O94+gMvtpTwvaXLfMNILj9wCO34FBavhU9sgu3zqJ85fqY6NO6b+veHO54MDj4A1BorWaD0NCTFRLMpNYmdtz7QDV5O1p74HgGUS2tCNtfNm8dFVBeyo6eGPb9ZN6zV+ufUkAF/cEJx2O4DSnEQAjrT0B+0cQoeyy8HnkXYOje2t78VsmuZqemEc/c3QfgjmXKbaioUIU4kxUSTGWGfc7htsAy43I2MeMhNsWo8ipqEoPY79TX18+i97+N+XjrPlSBuNPcP4fMH9vCUEcDpw17Rb2zmEEGfVOehiwOlmtgTuhBBTZNV6ACHE28QkykpZIYQQuvH6iS6GRj1cWRa8djtgYq1mQ7c8bWwoA60QnQC2aVyIsKeCLRF66wI+lt4daFThlEndJO88Dn+7DXpOQcXH4aqfgHWaaw3yloHJAg07QftMmb4c3wKtB2Dl59QDMDqwsiSNA039HGsfYEF2YtDOs7euF6vZRLmENnTlW1ct4LUTXfzw+aNcPDd9Si11h5v7eam6nStLs5ifFbw/O2W5KjR8WAJ3kSVrPPDdehByl2o7S4Ty+XxUNvQxPyuROJtc1g1rJ15Qx3myTlaEv7wUO819+m6463A4AWSlrEF98oIi7t9+iq1HO3ihqn3i1xNirCzITmRhdiILc9RxbmY8NqsEnUUAxc9SD55K4E4I3TrVoe5LzJ4Vp/EkQgijkSszQuiJLQE8o+B2gVWelhNCCKGtzYdVg9nGsmmsDJ2CiYY7WSlrLIPtkDDNMKbJBClFEdlwd7CpD4DF+ecIOB1/AZ64E0aHVNBu+V3qn9t0RcdB1iJo3Kka3WbyWuHE54NXfgAWG6z5stbTTFhVksrvXq1hR0130AJ3Xq+PvQ29lOYmERstN5T0xB5t5We3LuaW37zFPY8e4MnPX0CUZXILCu57ebzd7pLgtdsB5CTFkGyP4kiLPDAWUfwNq20HtZ0jgjX1jtA54OKK0mk0DAtjOb5FPSwxe4PWkwgRdLkpsRw7OoDb48U6yfc8odbucAGQmSjX7I3oA+fn8oHzc3GOeTjZMUhVi4OqVvV/1S0OdtX2THyt1WxiTkb8O4J4C7ITSY2b5sNvQgDkr4CD/4DhHvUQqhBCV051DgIwO0Ma7oQQUyOBOyH0xDZ+M83pUE+9CCGEEBoZ83h5qbqd0pxE8scDccGSbI8mMcYqK2WNZqD1dNPNdKQWQ9uhiHvQ4EBTP5mJtrM3I/h88OYv4cX/C7HJcPtTULI2MCcvWAU7fwPdpyA9uGEcwzj5ErTsgxWfhsTghounYllRKmYT7Kzp4ZNrioNyjpquQfqGx7ipQtbJ6tHSwlQ+u3Y2v95+ivtePslXL5t3zu852ubg+SNtXLogk9KcSa6tniaTyURZThJ76nvweH1YzBLijQiJuRCbqhruhCYqG3oBWCqrwMPbmBNqX4GC1er9oBBhLi8lFo/XR5vDSV5KcK8/TFf7eMNdhjTcGVpMlIWy3KSJtmZQ7bFNvSMqgDcexKtudfDUvmae2tc88XVZiTHj4bsEFmYnsTAnkcJUO2Z5HywmI2+5Ctw17Zb2WiF0yB+4myMrZYUQUySBOyH0xL/CyiWBOyGEENraUdNN/8gYd10YnKDHuxWmxdEogTvjGBsBZz8kzCCglFIM+KC3HmadO0gSDkZGPRxvH2DD/Iwzf8HYCGz6sroIO2sBfOhvKpgYKPkrVeCu4S0J3IEKN27/AViiYc1XtJ7mHRJjoijLTWJnbTdery8oN3H21KnQxjIJbejWVy6dx7Zjndy37SSXLMg45+rfe8fb7b58ydxQjEdpTiKvn+yipnNwSmtvhYGZTJC9GBp2gNcDZmnHDLXKevWzu6JAfnaHtbrXYWwY5l2u9SRChERuciwAzb0jOg7c+RvuJHAXbkwmE/mpdvJT7VxRerrFv39kjOrx8J0/iPf6iS5ePtox8TX2aAvzsxImWvAuW5ApoUxxZnnL1VECd0Lo0qnOIWxWMznj70mEEGKyJHAnhJ7EjDfcuWQtjxBCCG1NrJNdNM2VoVNUkGbncEs/zjEPMVFy81b3BtSfDxJmsM7MHyTrrY2YwN2Rln48Xh9LzrRO1tECf/8ItFTCeVfBjb87/TBGoBSsUsfGHVBxe2Bf24hOvQzNe2DZnZCUq/U077GqJI2DTf0c7xhgflbg18ruHQ9tLC2S0IZeRVvN/OzWxVx/3xt89R/7efZLF53178gT7QM8d6iVDfMzWJQX3HY7v9LxZpAjLQ4J3EWS7HKo2QZdJyBjvtbTRJzKhj7S4qIpCHIDtdDYiS3qOFduyIvI4A/ZNfWOsFLjWc7G33AnK2UjR1JsFKtK0lhVkjbxa2MeL6c61Ura6vGVtFUtDiob+gB4saqdP31yhVYjCz3LLANrLDTu0noSIcQZnOoYpGRWvLT3CyGmzKz1AEKIt/GvlHUNaDuHEEKIiObx+njhSDtzMuKZkxGaG+iFqXZ8PmjqlZY7Q5gI3M204Q7oqZ35PAZxoKkfgPJ3h2Ga9sDv1quw3UVfgw8+HPiwHUBiDiQXQMPOwL+20fh88MoPwRwFF35V62nOaFVJKgA7TnUH5fX31vdSkGonI0EaGPRsQXYi91w+j1OdQ/zo+WNn/br7tp3E54Mvbghde2Vpjvr8eri5P2TnFDrgXyffJmtlQ2141E1Vq4OKwhRMJrkRFLZ8Pji+Rb1nm3We1tMIERJ5KeMNd30jGk9ydu0OJyYTpMdL4C6SRVnMzM9K5MaKPL599UIevmsVlf95GTu+eQnzMuOpbpUiBXEWFivkVkDzXtUULYTQjZFRD819I8yeFaf1KEIIA5LAnRB64r+x6pQPZkIIIbSzt76XrkEXV5aGpt0OoDBNPdFe3y2BO0MYaFXHhBn8GUktUcfeyAncHWxST72X576t4e7A3+GPV6kVvTc/CJf8J5iD+DEtfxV0n4Ch4IS4DKP2FWjcCed/BJLztZ7mjJYVpWI2wY6anoC/dvegi5quIVknaxCfuqiEZYUpPPhGLW+e6nrP75/qHGTTgRYunjeL80O4ZrI4LQ57tIUjLfL5NaJkL1bH1gPazhGBDjapplxZJxvmuo5DXz3Mu1KtcRYiAvgDd3p+AK/d4SQtzkaURW6piXcymUxkJcVQmpNEu8OFwzmm9UhCr/KWw+ggdB7VehIhxNvUdA0CMHtWvMaTCCGMSD4dCKEn0nAnhBBCBzYfVmGqK8tCF7grSFVPkEngziAG29UxfgZ/RhJzwBINPTWBmckADjb1U5RmJ8kepX5hx2/gqc9AXDrc8TyU3RT8IQrGlzQ1RnDLnc8H238I/5+9+45v8zzv/f/BIECCBEiCJLhJcWhSorZEW94rbkaTuFmtm2b0ZJ22mU26zq85TU9H2sSJM5o2aZqmWU3dOM5qvOSlLWtSoixSJCXuAW5wgSTw/P64CUmWNSgSwP2AuN6vl1+3I4l4LjsyBALf53tZ7XDbJ3VPc02e1BRqijI5fGGIcNiI6mNH1slukcBdQrBZLXzxHRtxOWx8+rH613yI9/Xnmwkb8LF749duB2C1WlhX6KGhexTDiO7vUWFi3ipISZeGOw2Otc8/d5ddZTW9WD6anlSnrJMVSSQzLYUMp53OYTM33AVlnay4rmqfCmq09I9rnkSYVun8umFZKyuEqbT4JwCo8kngTghx8yRwJ4SZRBrugtIQIIQQQg/DMHjqdC+l3rSLq+LioWy+4a59SAJ3CSEaDXdWG2SVJ81K2dHJWc4PTLCx9LIPyU98H1y58MEXoGhTfAYprVNnx8H4XM+MLuyF9v2w8bchu1z3NNdVV+llaGKGc1H+0CYSuNu2QgJ3iaI8J52/eMNaukam+Nwvzlz88QsDE/zsRDe7qnPYWu6N+1w1RR7GpudM/QG5iDKrFQrWQ0+9CjCLuDnWNoLdaqG2RAJ3y1rT05DighW36Z5EiLixWCyUZNix3FAAACAASURBVKeZdqWsYRj0B6bJ96TqHkWYWKQZqVkCd+JaSrars/NlvXMIIV4lEpSWlbJCiMWQwJ0QZpIaabiTwJ0QQgg96jtH6R6d5sGaAixxXGFU4EnFYbPSNjgRt2uKJQj0qnMpgTsAb4VamRUOLX0mk6vvml8nG/mQPByGgWa1mi/DF79BfGtVq3J7Ejfcvfh5sNjg9k/pnuSG6ipzADjYGt0VwEfahnGn2lnlc0f1cUVs/c6OMu5clcd/H+3kqQb1PPxPLzQTCht89J6VWmaqKc4EoKF7VMv1hSYFtTA9AqMduidJGoZhcKx9mHVFHtIcNt3jiFiZGoH2A1BxJ6RIsEckl+KsNLpHpghFudk5GoYnZ5kNGdJwJ64r0nDX7JfAnbiGDJ+68VQa7oQwlZb55+3KXGm4E0LcPAncCWEmkYa7aQncCSGE0OPXp9UH+A+uL4zrdW1WCyXeNGm4SxSBHhXacizxzr/sCgjNwFh3dOYysfpOFUbZWKLCKYy2w9wU5K2O7yBWm7qruvsYzE7H99pmcGEfXNgDG9+lAp8mt22FF6sluoG74FyIU52jbCnLxmqNX7BaLJ3FYuEf3lZLZloKf/74KU50jPD4sS52VnjZOR/OjLdIG+7pLvkeNqkU1qqzR9bKxkvb4CRDEzNsKZNm0mWt5TkwQrDqAd2TCBF3JdlpzIZUk5zZ9I2pmXxuCcKKayvPcWG3WmSlrLi+0h0weA4mh3RPIoSY1+KfoDgrTW5sEkIsigTuhDAT5/wHsMGA3jmEEEIkJcMwePJ0D/keJ5tL47+qqtzromN4irAJ72gXVwj0Lb3dDi4FnoaX/1rZkx0j2KwWaormX+/5m9SZuyr+w5TVqaBjz4n4X1u3Fz8PFmtCtNsBZKalsK7Iw6HzQ1F7bjzdNcpMKMy2cgltJKJ8Tyr/7y3rGZyY4V3fPMBc2OBj9+pptwNY6XPjsFml4S7ZFMwH7nolcBcvx9rVKvDNZbJOdlk797Q6V0rgTiSfkmwXAF0mXFMfCdzJSllxPSk2Kyty02WlrLi+kh3q7Dqqdw4hBADhsEGrf5wqn7TbCSEWRwJ3QphJpOFOVsoKIYTQoLEvwIXBSV5XU6Cl9ag8J52ZuTC9Y+a7o11cIdAbncBd9nzgbigJAnedI6zKd1+6W9J/Vp3xbrgDKN2pzvaD8b+2Tu0H4fyLsOEdkFOle5oFq6vIYWhihnNR+uDmyAUV2ti6QgJ3iepNG4t408YipmdVcPKWKj3tdgAOu5VVBRmc7pbvYZOKby1Y7dJwF0dH2+afuyUsvXyFQ3DuGcjfAJkluqcRIu6Ks9MA6DRh4K5/LAggK2XFDVXnZdA+NMn0bEj3KMKsSrapU9bKCmEKXSNTBOfCVOUtcYuLECJpSeBOCDOxO8CeKg13QgghtPj1qcg62SgEqRahzKvuaG8blLWypjYzCcFRcEdh7XCSNNz1jU3TNxa8tE4WYKBRnbkaAncl28Big45D8b+2TpF2uzv+WPckN6VuflXoofPRWSt7pG0Ym9XCJg1NpiJ6/vrNNbx1czGffVMNFove1cA1hZn4A0H6JTCfPOxOyFsrDXdxdKx9BJ/bSXFW2tIfbLAFDn0Tjn536Y8loqfrGEwOyDpZkbRKLgbuzPd+gDTciYWq9mUQNuDC4ITuUYRZFWwAexp0vqx7EiEE0OJXN7dW5UnDnRBicSRwJ4TZON0wLe0AQggh4u+phl686Q52rPBquX55jgrctQ/JG5OmNq6CmWTkL/2xssoBy7JvuDvZMQJAbcllASd/E7hyIF1DM5UjHQprVeDOSJIVzh0vQ8tzsP63IFff+s3F2F7hxWKBg61LD9wZhsGxtmFqijy4HPYoTCd0yXI5+NI7N7Hh8iCvJuuLPQA0SMtdcimshbEumIhOGFhc23hwjsbeMbaUZS8uYBsch8Yn4Vd/DI9ugq9ugV9/Gn7xURXyEuZw7il1rnyd3jmE0CQSKO4aMV/DXV9AAndiYarnVxLKWllxTbYUKNqsVsqGw7qnESLptfjV5xASuBNCLJYE7oQwG6dHGu6EEELE3fmBCc72Brh/bT52m56XiNJwlyAC84G7aDTcpaSCp2jZN9yd7FSBu42l88EYw1ANdzra7SJK62ByEAab9c0QTy9+HrDAHZ/WPclNy0xLoabIw8HWIYwlBiTPD0wwODHDljJZSSiiZ12Rem5r6B7VPImIq4Jadfae1DtHEqjvGCFswJbyBTaTGgb0NcC+r8B3fxP+oQJ+9E54+VtghGDb++ENX1S/du8jsRtc3JympyDNe2nVnBBJxpvuIC3FZsqVsn1jQWxWCznpDt2jCJOTwJ1YkNLtEBwD/1ndkwiR9C423PlkpawQYnHklnYhzMbphskh3VMIIYRIMr8+3QPAgxv0rJMFKPVGGu4kcGdqAfV7BXeUfq9kV0DvKfXhsOa1iLFS3zmK025lVb5b/cB4P0yPQt4qfUOV7YRD34D2gwnX+HbTuo5C8zNQ8xDkaQw5LkFdRQ7/uvc85/rHL/0+WoQjbcMAbFshgTsRPWsL3Vgt0nCXdArnA3c99VB1j95Zlrmj88/dW8uv89w9NQytL0Dzs9C8+9LrNXsqVNwB1fepv3KqL73eOvcsvPJL1bqr8zWJgLEetaJ5wzvAatM9jRBaWCwWSrLTTBm46x+bxud2YrUuz+9XRfRU5qnAhgTuxHWVbFdn52HIX6d3FiGSXEv/OO5UO3kZTt2jCCESlATuhDCbVM+yb3kRQghhPk+d7sXttLOrKlfbDKkpNgo8qRK4M7uLDXdRCtx5K6Btr/qg2KVnnXEsGYZBfecoNUUeUiLtkQON6tTdcAfQcRC2vFvfHPHw4j+o887P6J1jCXZWqsDdwdbBJQXujkUCd+XL7781oY/LYacyL4PT0nCXXPLXq7O3Xu8cSeBY+zApNgs1RZetkA6Hoee4Ctc1PwudL4Mxv5YsdxXUvBWq74XyXZCSdvUHvv2T0PRr2PdleMs/xf4fRFzbuafVuUrWyYrkVpydxv6WQcJhw1Thtr6xIPmZsk5W3JjLYac4K00Cd+L6Snaos/Nl2PperaMIkexa/BNU5WVgWaY3gQshYk8Cd0KYTWSl7DJueRFCCGEuXSNTnOwc5S2binDY9ayTjSjLcdHYK6vVTS0WgTuAodZlGbhrG5xkdGqW2pLL1sD55wN3OttkPIWQVQbth/TNEA/dJ6DpSVj3ZvCt1T3Nou1Y4cVigUOtQ/zeLSsW/ThH2oYpzkqjQD4wFFG2vsjDEye6GZ2cJdOVonscEQ+pHvBWqoY7ETPhsMHxjhFqijJJDQ7CmedUwK7lObUaHsDhhtWvn2+xu1f9+b4QpTug/Dao/zHc9WeQVRq7fxBxfeeeBotN2iJF0ivJTmNmLszAeBCfxxyvV0NhA/94kNqSzBv/YiFQa2UPtA4SChvYTBQcFSbizlev1zpe1j2JEEltdHKWgfEgd67K0z2KECKB6f1EVQjxWk6Puit5ZkL3JEIIIZLEk6dVgOrB9YWaJ4Fyr4vRqVlGJ2d1jyKuJRK4y4jiSlmAoeXZ8HuycwSATaWXBe4GmtSps+EOVMvd4DmYGNA7RyxF2u3uSNx2O4BMVwrrCj0cbB3EMIxFPcbI5AzN/eOyTlbERKR5q6FHWu6SSkEtDDZDUFpcYiI0S3f9bj4w8z2+MfEJ+MJK+OmH4NRj4CmG2z4J7/0f+JPz8K4fwLb3LTxsF3H7JyA8Bwe+Fpt/BnFjc0FoeR5Kdy7Lm0+EuBkl2S4AOky0VnZwIkgobJBvkgCgML9qXwYzc2E6h2V7g7iOku1q+8HUsO5JhEhaLQPq+9gqX7rmSYQQiUwCd0KYjXN+RVRQ2n2EEELEXjhs8F8vd+By2ExxN1d5jnqDvW1IguemFeiB1ExwuKLzeJGGu+FlGrjrUOGTVzUi+BshJR0ySzRNNa9spzo7lmnLXU89NP4K1rwRCtbrnmbJ6ipzGJyYWfR6oqMX18lK4E5EX02RB4Az3WOaJxFxVVgLGNDXoHuS5WW4DX78u/D5Ckqe+C3+wP5zcub6YP3b4C3/DJ9qgg/vgfs+Cyt2gW0JrZJV96rg5NHvLu8Avpld2AuzE7DqAd2TCKFdcZZagd01Yp7AXf9YEIB8j1PzJCJRVPsyAGStrLi+yFrZrqN65xAiibXMP09X5WVonkQIkcgkcCeE2aSqDyoIygcVQgghYu+Xp3po7Avwe7esIM1h0z0Opd75wN2g3AlsWuN90Wu3g2XfcFffOYI71c6KnMvulhxogtyVYNG8XqbsFnW2H9Q7R6y8NN9ud+ef6J0jSuoqcwA42Dq4qK8/Mh+421ou7Tki+iINd6e7pOEuqRRsVGevrJWNqmPfhVd+AXmreCb//bw5+DkGP9IAb/s2bPpttYYsWiwWuP1TMDcFB78RvccVC9fynDpXSuBOiJJsFbgzUzNY39g0gGlW3Arzk8CdWJDS7eqUtbJCaNPiVzf8S+BOCLEUErgTwmyk4U4IIUSczIXCfPnZJjKcdj50R6XucQAonw8ltQ+Z5w12cYVAL7ijGLhLy4K07GXZcDcXCnO6e5Takkys1vlw3fSoagnM07xOFiBvLTgzl2fDXV+DCiusfv18A1Pi27HCi8UCB1uHFvX1Ry8Mk+G0s7rAHeXJhFBrj0uy02iQhrvkEnl+7Tmpd47lpvs42FPh/U/xj9Nvod+znsLsGH4ItPZNkFMNh78F0/LfcNz11qvm47y1uicRQrvIStkuE62U7bvYcCeBO7Ew1XkSuBMLkL9Bvd7rPKx7EiGSVot/HLvVcnHjjhBCLIYE7oQwG+d8w920NAMIIYSIrSdOdNPqn+D9t1WQne7QPQ4A5fMNd+3ScGdOwXHVwusujO7jZlcsy4a7pr5xpmfDbCzJuvSDA+fUmbtKz1CXs1rVXdXdx2F2Wvc00fVipN3uM3rniKJMVwprCzwcOj+IYRg39bUzc2FOdo6wuSwLm1Vzs6JYttYXZdLiH2dqJqR7FBEvGT7VeisNd9FjGOrP5YJaxmbhXP84W2K9Ctxqg10fh+AoHPm32F5LvJoxv5LZt1a9LhMiyeVmOHDarXSaKnCnvk+SlbJiobLTHeSkO2j2S+BOXIfdAYWboPMohMO6pxEiKbX4xynLcZFik9fhQojFk2cQIcxGGu6EEELEwWwozKO7m/Ck2vn92yp0j3NRlisFd6qdtqEJ3aOIqxnvU2c0V5kBeCtgvBdmllfQsr5zBIDaywN3/kZ1mqHhDqC0DkIz0HNC9yTR0/8KnPkZrHwdFG3WPU1U1VXmMDA+Q8tNfnjT0D1KcC7M1liHNkRSqynyEDbglV5pyEoqhbXqeTc0q3uS5WGkDaaGoWgzJ9pHMAzYUhaH5+7ad4KnGA58ffmF8M1svB8mByG/RvckQpiCxWKhODvNVCtl+wPzgTu3NNyJhavyZdDcP37TN0qJJFO6Xd3wMNCkexIhks5sKEz74KSskxVCLJkE7oQwm9RMdQblQwohhBCx89iRTjqGpvjQnVVkpqXoHucii0XVuEvDnUkFetUZi4Y7gOEL0X1czU52qsbijaWZl35wYD5wl2uSwF3ZTnW2H9Q7RzS99I+AAXf+ie5Joq6u0gvAgZtcK3u0bRiAbeXeqM8kRMT6YvVcJ2tlk0xBrQpu+8/qnmR56DqmzqLNHGtXz91byrKu8wVRYnfALX8IE/1w4vuxv55Q+hvUKYE7IS4qyXbRNTJlmqBS31gQh81Klss875sI86v2ZRCYnsMfCOoeRZhZyQ51ylpZIeKubXCSubAhgbtk1/oCfGE1/NMt8IO3wy8/AXu+CPWPQdsBGOmA0JzuKYXJ2XUPIIS4gjTcCSGEiLHp2RBffe4c3nQH7711he5xXqPcm05D9xjBuRBOu033OOJygR51ugui+7jeSODuPOSvi+5ja1TfOUKe20mB57I2BH8TWFMu/TPrVrwVLDboOKR7kujwN8Hpx6H6PijZqnuaqNtR4cVigYOtg7y7rnzBX3fkwjBWC2yKR2hDJK2aIg8ADV2jmicRcVVYq86eeijYoHeW5aD7uDqLNnP06DAOu5Waoszrf020bH2PCq3v+wpseS/Y5G3jmOs7o07f8nn9K8RSFWelMT0bZnBihtwM/Wtc+8am8XmcWCwW3aOIBFI9H+Bo7h/H55F2RHENJdvV2XEYtvye3lmESDKRzRFVeemaJxFanfih2rrjcEHrixC6SlDeYgNPEWSWzP9V+uozq/RStkMkJXnnRAizcaoPKZiWVgAhhBCx8Z+H2+kZneYvXr+WdKf5Xg6W5bgwDOgYmqLaJ3eZmUqsG+6Gzkf3cTWang1xtjfA3at9r/5wZqARcqrAZpKGBEe6Cku0HwTDgET/IOliu92f6p4kJrJcDtYWeDjUOohhGAv64M8wDI60DbO20EOGCZ/zxfLh86SSm+GUhrtkUzAfuOutBx7WOsqy0H0cUtIJe6s50bGb2uJMHPY4LShxpEPdR+D5v4GGx6H2HfG5bjLrk4Y7Ia5Ukp0GQOfwlEkCd0HKc1y6xxAJJvJeVrN/nFurczVPI0zLU6gCG51HdE8iRNK5GLiTzx6SVzgMzbshfz18ZJ/635MDMNqhmu1GO+f/6lB/DTRB+4GrP1Zq5nwAr/SyYF4JZJWpMyMfrFIssVzJu+1CmI003AkhhIihqZkQX3+hhTy3k9+9iXakeCrzqjez24cmJHBnNuPzgbuM/Og+rrdSncPLJ3DX0D1GKGywseSyVprZabU2d80btc11VaV16gP+gXOQt0r3NIs30Ayn/xuq7oHS7bqniZmdlV6+s+8CLf5xqn03voOyfWiSgfEgb9gQ5WZKIa5ifbGH/c2DzIbCpNjiFBISemWvAGemargTSxMOQ89JKNxI8+AUgek5tpRnx3eGHR+AfY/C3i/B+reBVf47jqn+BnUji0tWvgsREQncdQ1PsalUbzvzbCjM4ESQHRVxfi4WCe9i4K5/XPMkwvRKtkPDT2F6VAU2hBBx0dI/AUBVrnz2kLR661XAbtPvqP9ttUKGT/1VfI2tKTOTl4XwOq/4+w5ofhbCs6/9Oqsd/qQNnPL7bTmSwJ0QZnMxcCdreIQQQkTf9w5ewB8I8le/WUOaw5x31ZTPB+7aBic1TyJe42LDXZSDO+4CsKfBUGt0H1ej+s4RAGov/5BoqAWMMOSt1jTVNZTVwaFvQMfBxA7c7fmC+vd755/oniSm6ipz+M6+CxxsHVpQ4O7IhWGA+Ic2RFKqKfLwQqOfc33jrJtfMSuWOYtFrZLtOakCYxLQWryhVgiOQfEWjrbNP3fHexV4WjZsex/s/yqcewpW/0Z8r59MQnPgb4TyXbonEcJULjXc6X8/YGA8iGGAzy0rQcXNKcxMJd1hk8CduLHSHapZuPMIVN+rexohkkaLf5zcDCeZLpNsIBHx17JbnTfz3OtwqffOr/X+eTgE4/2vbsYb7YSJAQnbLWPyLpgQZiMNd0IIIWJkPDjHP7/YSlFmKu/aUap7nGsqy4k03Ol/g11cIdALqVmQkhbdx7VYVEPOMlopW9+pbp6oLb7sDmV/ozpzTRi4A2g/pHeOpRhsgfr/goo7L/3zLFM7K7xYLHCwdXBBv/7IfGhj2wppzxGxt75IPec1dMsNZEmlsBZmAsuqqVaL7uPqLNrMsYuBOw1h6bo/AJsD9nxRrZsXsTHUCnPTsk5WiCuUZKv3AzqHpzRPotbJAuR7JHAnbo7FYqHKlyGBO3FjJfPt/LJWVoi4MQyDFv84VXnpukcROjU/BykuKLsleo9ptal14aXbYf1DsOtj8Pp/hLd/J3rXEKYjgTshzMZqA0cGTI/pnkQIIcQy8+/7zjM0McMf3bsSp92c7XYAhZlppNgstEvDnfkEeqPfbhfhrVB3fYXmYvP4cXayY4TyHBfZ6Y5LPzjQpE6ztci5CyCrXDXcJao9j4ARWvbtdgBZLgdrCjwcbB3CWEAQ4ljbMIWZqRRnRTkoK8RV1FwM3Mn3s0mloFadvbJWdkm6j6mzaDPH2ocpyU7DpyPk4SmETQ9D58twYW/8r58s+hvUKYE7IV4lL8OJw2ala8QMgbtpAPI9Ts2TiERUnZdBfyDI2PRVVssJEVFQCzYndB7WPYkQScM/HiQwPUeVTxrHklYwoN4HX3E72OV1nlgaCdwJYUZOjzTcCSGEiKrRqVm++VIrZV4Xb9taonuc67JZLZRmu2iThjvziWXgLrsCwnMqdJfgRqdmaR2YoLbkijVw/kbAAjkrtcx1XWV1MNisKu4TzfAFOPkj9SbJiuRYy1ZX6WVgPEiLf+K6v250apam/gBbZZ2siJNSbxruVLs03CWbwvnAXY8E7pak+zg4MxlJLabFP6Gn3S5i10fBYoW9j+ibYbnrO6NO3zq9cwhhMlarhaKsVFOslL0UuJOGO3HzIkEOabkT12V3QNEmdaNDOKx7GiGSQku/ei+tKk8Cd0nr/B71OYSs8hZRIIE7IczI6YagNAIIIYSInm/vaWVseo6P3buSFJv5XwKW5bhoH5okHJY1VqYRDKh1ce7C2Dy+t0Kdy2Ad3ekuFTTZWJL56p8YaIKsUnC4NEx1A6U71dmRgGtl93xxvt3uM7oniZudFTnAjdfKHmsfxjBgmwTuRJxYLBZqijyc6R6TP8OTSe4q1cwhDXeLFw5Bz0ko2sjxDvV+kNawtLcSah6ClucurboV0dXXABYb5K3WPYkQplOS7aJzeGpBbc6xJA13YimqJXAnFqpkO0yPwuA53ZMIkRRa/Op5WVbKJrGW3eqsksCdWDrzf9oqRDJKlYY7IYQQ0TM0McO3956nKi+dt2wu1j3OgpR7XczMhekLTOseRUQE+tSZkR+bx8+eD9wNJX7g7mTnCAAbSy9ruAuHYOAc5Jr0Q9WyOnW2J9ha2ZF2OPFDKLtVNdwliZ0VXuDGgbujF4YB2LbCG/OZhIioKcpkYibEhcHrNzCKZcSWAvnrpOFuKQaaYHYSirawv0W1zWpvJ73tE+rc+yW9cyxX/Q2Qu1JWGAlxFcVZaUzOhBiZ1LuKs28sCKBnvbdIeJHAXYsE7sSNlGxXZ+fLeucQIklcCtxJw13Sat4NWWWQU6V7ErEMSOBOCDNyumFaGu6EEEJEx7+81MLETIiP37cKm9Wie5wFKfWqBrC2Qf1rZMS88V51SsPdDZ3sGMFqgZoiz6UfHL4AoaB5W0zy1oIzM/Ea7vY8olYA3PkZsCTG81s0ZKc7WFPg5tD5oes2fxxpG8LlsLGmwB3H6USyW1+snvtOd8v3tEmloBYm+tX6eXHz5lvkjKLNPHOmjwJP6qtfR+hQsB5WPQhnfg7+Jr2zLDfBcfXaUNbJCnFVJdlpAHQOT2mdo29smrQUG26nXescIjGVe12k2CzScCdurHSHOjsO650jBpr7xznaNqR7DCFepcU/gdNupTgrTfcoQofBFvX5Q9W9SfVesogdCdwJYUZOD8xOqCYUIYQQYgn6A9N8d/8F1hS4ecOGGAWlYqA8R1W6t0vgzjwiH6C7C2Lz+JmlYLEui4a7+s5RVuW7cTku+2BmYP6D6txVeoa6EasVSrerD/xnE6RZcrQTjn9frcOtvEv3NHFXV5mDPxCkdeDqLWKzoTAnOkbYVJqFPQFWiYvlo6ZIrdNu6B7VPImIq8JadUrL3eJ0HQOgzbmKC4OT3LfOh8UMb/7f9knAgH2P6p5keel/RZ35NXrnEMKkynPV+wFne/WG9/vHguR7nOZ4PhYJx26zsiInnWa/BO7EDXiKwFOy7BruDMPgw98/yru/fZjgnHzWKcyjpX+cyrwMrAlSTCCirOU5dVbLOlkRHfKuuxBm5JxvoJC1skIIIZboGy+0MD0b5hP3r0qobyLLc1TDXfuQBO5MI9Cjzlg13NkdkFmi2j4SWH9gmp7RaWpLMl/9E/5GdZq14Q7UWtnQzMWWHdPb+yUIzyZdu11EXWUOcO21sme6x5ieDbNN90pCkXQqc9NJTbFyRhrukkvBRnX2ntQ7R6LqPg5pXn7d4QDgvrX5mgeaV7YTyndB/X+qoLuIjv4GdUrgToirumX+de6LTX6tc/QFpmWdrFiSal8GHUOTTM9K2EjcQMk2FchfRpuvjneM0Nw/zuRMiGNtI7rHEQKAqZkQXSNTVOWl6x5F6NK8Gyw2qLhD9yRimZDAnRBmlDr/AW1w+by4FkIIEX89o1P84GA7G4ozeWCdST60W6CyyEpZCdyZx8WGuxj+XvJWqoa766zINLv6DtXotLE069U/YfaGO4DSOnV2HNQ7x0KMdsGx/4DibWoFQBLaWeEF4GDr1dezHG0bBmDrCm/cZhICVJvHmgIPp7tGr7vyWJjLE8e7uO+RF/n6880MT8zc/APk16imWmm4u3mhWeg9BUWbefZsP+kOG7dU5eie6pLbPqnWt+//mu5Jlo++M+qUlbJCXFWe28mG4kz2nBtgLhTWMsP0bIiRyVnyJXAnlqDal0HYgPPXaCUX4qLSHYABXUd1TxI1jx25dLPG/pYBjZMIcUnrgGodrcrL0DyJ0GJuBi7sUc+5qZk3/vVCLIAE7oQwI2m4E0IIEQVfe66ZmVCYTz6wKuFWoKSm2Mj3OGkflDclTSMSuMuI0UpZgOwKmJ2A8f7YXSPGTnaqu3Y3llwRuPM3QnoeuEwcfireClY7tB/SPcmN7XtUtfHd+SdJ2W4HkJ3uYE2Bm4Otg1cNNR1tG8Zigc1lWVf5aiFia32xh+HJWXpGE2RFdZKbC4X5x6caae4f5x+fauSWv9/Nnz1+iub+m3hPwuGCnJXQK4G7m9b/CoSCTOTWcqx9mDtX5+G023RPdUn1vVBQC8e+CxPyYWlU9DWAww1ZZbonEcK07l6dx+jU7MXvr+LNHwgCkO92arm+WB6qfSrQ0dwva2XFDZTsUOcyWSs7NRPi/fUqSAAAIABJREFUlye7WVPgxp1qZ19zAr+GDAbg5x9VN8iIhBd5Pq7ySeAuKXUcgpnxpL15W8SGBO6EMCOnR53LqD5aCCFEfHUMTfLjlzvYWp7NXavydI+zKOXedGm4M5NAL6RlQ0oM7/D3Vqhz+HzsrhFjJztHcditrC5wX/pBw1ANd7kmXicLKixRUKvefDBzK9VYDxz9dyjaDCvv1z2NVnWVOfgDwdc0JhiGwZG2IVbnu/GkpmiaTiSzmiJ1p/DprlHNk4iF+J/TvXSNTPHRe1fy6Ls2sTrfzY8Ot3PfIy/xnn87zItN/oW1FRbWqtXw0/L/+02ZX+V+fK4CwzDROtkIiwVu/yTMTsKhf9Y9TeIzDLVSNn9d0t40IMRC3LnaB8DzZ/Wsle0bUzcNSMOdWIpIg5IE7sQNFdaCzQEdh3VPEhVPNfQSCM7xzu2l1FXmcLJzlMD0rO6xFuelL6gbT174e92TiCho8av3z2SlbJJq2a3OagncieiRwJ0QZiQNd0IIIZboK7vPMRc2+NT9idduF1HqdTEyOcvoVIK+IbPcBHpi224HquEO1FrZBGQYBvWdI6wr9JBiu+xbrUAvBMcgz8TrZCPK6mBqCAbO6Z7k2vZ/BULBpG63i6irvPpa2c7hKfrGgmxbka1jLCGoKVI3kTV0y01kZmcYBt96qZXUFCvvu3UFb95UzBN/sIuffOQWXr+hgD3n/Lzn3w7zwJde4keH25meDV37wQpq1SntDzdnPnD3M78Pm9XCPWt8mge6irW/CTnVcPibcnPoUgV6YWpY1skKcQObSrPIcqXwQpOe9vO+MdVw5/NIw51YvKq8DCwWaPZL4E7cgN0JhRtVw52Zb4BcoMeOdpBis/DmTcXsqsohFDY4dMX7Fglh6Dwc/Cf1901PwrieELiInpb55+PKXGm4S0rNu8GVA4WbdE8ilhEJ3AlhRqnzDXdBeRNTCCHEzWv1j/OTY53cUpnDrdW5usdZtPIcFwDtg9JyZwrjfeCOceAuwRvuOoamGJmcZVPpFSs8BxrVafaGO4DSnersOKh3jmsJ9MGRf1NvRK96UPc02u2oyAHgYOvgq378aNswANvKTbzCWCxrq/Ld2K0WGrql6czsDp0f4lTXKG/fWkp2ugMAi8XC1nIv//TwVl789N184PYKeken+bPHT3HL3+3mC0810j92lXXBhfOBux5ZK3tTuo9hpOfzi/MG28qzyXI5dE/0WlYb7PqYai88+h3d0yS2vgZ15tfonUMIk7NZLdyxMo/TXWP0B+K/oj7ScFcgDXdiCdIcNoqz0miRhjuxECU7YHoEBpt1T7IkncOT7G8Z5L61+XjTHeyaf296X0sCrpV95i8hNANb3wfhOTj1X7onEkvU0j9OcVYaaQ6b7lFEvI33Q289VN4NVolIieiR301CmNHFhjsJ3AkhhLh5j+4+R9iATz2QAG1a1xEJ3LUNTdzgV4qYCwZgZhzchbG9TvYKdSZow92JzhEAaksyX/0T/iZ1JkrDHUD7Ib1zXMv+r8DctLTbzfOmO1hT4OZg6+Cr1j0eaVN3jm8tl4Y7oUdqio1qX4Y03CWAb73UisUCv39bxVV/vtTr4i/esI4Df34vn33TOtypKXzt+WZ2ff45PvHjE69eG3yx4U4Cdws2Ow19ZxjwrGN61uD+dSZbJ3u52neBuwgOfF3NLRanXwJ3QizU3WvyAHixMf6NQn0BWSkroqPal0HrwAShcOK3lokYK9mmzgRfK/uTo10YBrx9Wwmg/hvwuZ3sbx68wVeazIW98MrPYc0b4cG/h9RMOP6DZdFAmKxCYYPzAxNU+aTdLim1PKdOWScrokwCd0KYkXP+Q1pZ0yGEEOImNfYG+PnJbu5clce2FYndbFTmnW+4G5KGO+0CveqMdcOd0w3peQnbcFffEQncJXDDnbsAssrN2XA37oeXvw35G2D163VPYxo7K7z0B4KcH7gUTj5yYRif20lJdprGyUSyW1+cSc/oNIPjQd2jiGto7h9n99l+HliXz4rc9Ov+2gynnfftquD5P76Lb757K1vKsvnp8S7e+NW9vONfDvBUQy+h1GzILJWGu5vR3wDhWU6EVODR1IE7uwNu/UPVenzyh7qnSVx9Z9TpW6t3DiESwB0r87BY4AUNgbt+WSkroqQ6L4OZuTAd8t6WuJHSHersfFnvHEsQDhv897EO8txO7lipQtMWi4Vd1bk09gW0NJYuSjgET/4Z2BzwwF9DSiqsf5t67d5zQvd0YpG6R6YIzoWpyrv+975imWrerc6qe/TOIZYdCdwJYUYXG+4CeucQQgiRcL70TBOGAZ+8PwGatG6gPEd98ysrZU0gXoE7gOyKhG24q+8cxe20U3llaMHfCA43eIr0DHazym5RK0zG4//B1nUd+CrMTcGdn5F2u8vUVUbWyqpWu8D0LI19AbatyMYi/56ERjVFHgBpuTOxb+9tBeADt1cu+GtsVgsP1BTw4w/dwi//6DYe2lLM8fZhPvS9o9z9hRdoc1Rh+M9KA9pCdR8H4JcDBaz0ZVx8/WtaW94DaV7Y+2UIzemeJjH1NYCnBNKkhVaIG8nJcFJbksWec37mQuG4XrtvbBp3qh2Xwx7X64rlp3q+SalZ1sqKG8ksUW3CCRy4O3R+iI6hKR7aXIzddimCcGuVet/iQEuCtNyd+KFq7a77CHjnv1fa/LA6j/9A31xiSZr96nm4Kk8a7pJOOKwa7vLXx+fzDZFUJHAnhBmlqg8mZKWsEEKIm3G6a5QnG3q5f10+G0uzbvwFJpftSsHttNMmgTv94hm481bA5EDC3XgwFwpzqmuUDSWZWK1XhJwGmiB3ZeKExMp2qrPDRGtlJwbh8L+Cb51a5yEu2lGh2kwPnVdvXB9vH8EwYGt5YrecisS3vlg1t0vgzpwGxoP85FgXm8uyFr1+en1xJo+8YxP7/vQePnpPNePBOR7vzsFihPjXx38V8yaX2VCYntEpTnSM8FRDL987cIFHnm7kVOfoDb/WNOYDd/smS7nPzO12Ec4M2PlhGGmDhp/qnibxhGZV83H+Ot2TCJEw7lqVx9j0HMfn28TjpW9sWtbJiqi4GLjzS+BOLEDpdug/k3DviUU8drQDuLRONmJXdS4A+5oH4j7TTZseg92fUxs4bv/jSz9etAXy1sKpx+TmogTV0i+Bu6TVW68+b5B2OxEDcnuOEGYkDXdCCCEW4ZFnmoDl0W4HauVAWY5LVsqaQaBHne7C2F8rW61UY+g8FNbG/npR0uwfZ2o29Np1slMjavVaIn1DX1qnzo6DsNYk4bYDX4PZCdVuZ5X7xi6Xk+Fkdb6bg62DGIbBkbZhALYtMkAjRLSsLfRgscDp7gQKPyWR/zjQxsxcmA/cXrnkNkyfO5VPPrCa/313NS8/1Q1HfkJz/X7+9kQqr6sp4P23VbCtfOGtm6GwweBEkP6xIH1j0/TNn/2BS3/fNxZkcCKIYbz263ef7edXH719Sf9McdN1nDFHPgPTmeZeJ3u5HR+A/V+BvV+CDW9LnBsKzGCwBUIz6gYCIcSC3LU6j0d3n+P5s/1sXxG/G0r6x4LUlmbG7Xpi+ZKGO3FTSrbDmZ9B11GovEv3NDdlPDjHr0/1sqk0i2qf+1U/V5SVRkVuOvua1fsWpm7j3/sITPTDmx69VI4C6jXv5ofh6f8Djf8D6x/SN6NYlBb/BABVPpO3iovoa5lfJ1t9r945xLIkgTshzCjFBRabupNCCCGEWIBj7cM8d7afN9QWsrbQc+MvSBBlXhdnenoJzoVw2m26x0lekYa7jDh8EOydD9wNJ1bgrr5DBUo2llzxocyACsKSm0BB2Lw1kJoJ7SZpuJscgsPfVHOtfbPuaUyprtLLdw+0cWFwkqNtQ6Sl2FhXtHz+LBCJKcNpZ0VOOmek4c50pmZCfP9gG6XeNF5XE7322tQUG7fffi8cgY+um6RvJo9fn+7l16d7qS3J5P27KrhtZS4D48FLIbqxy0N06u/940FC4ask6QCHzYrP46Q8x8WOimx87lTyPanke5zke1L50eF2flnfQ2NvgNUF7qs+hmnMTIL/FeptO8jNcLLpytC+Wbm8sPW9Kgzf9BSsflD3RImj77Q689frnUOIBFJbkoU33cELjX4+8+CauFxzIjhHIDhHvlsa7sTSZbkc5GY4JHAnFqZkhzo7X064wN2v6ruZmg29pt0uYld1Dt8/2E770CTlOSYNPA1fgANfh/wNsPndr/352nfCM5+FEz+QwF0CavGP4061k5fh1D2KiLfm51T2ouwW3ZOIZUgCd0KYkcWiWu5kpawQQogFeuTpJqwW+MR9K3WPElVlOS4MAzqHp6TuXafxeK6UrVTn0PnYXyuKTnaqFUe1V65z9jeqM291nCdaAqtVvcl7/kW1JiNF8wdN+74MM+Nwx6el3e4a6ipz+O6BNvY2D3C8fYSNpZmk2OTfldCvpsjDL+t7CEzP4k5N0T2OmPeTY50MTczw0XvWYbtyDfpSeYohzUvR1Dm+87920Nw/znf2necnxzr5+I9PXPPLbFYLPreT/MxUaksyL4bofJ7LAnXuVLJcKddtxLBbLfyyvofHj3fyZ7+xNrr/bNHWewqMMPunyrhvi++1K+nN7JY/VGH4PV+EVa+TlruF6j+jTlkpK8SC2awW7liZyxMnuuO25rU/EATAJytlRZRU5WVwpnvM/M1eQr/CjWBNgY6XdU9y0x470onTbuVNG4uu+vO7qnL5/sF29jYPmDdw98xfqjbiB/8WrFe58TvDB6seVA13o12QWRz/GcWitfrHqcrLkOfhZBMMqC0uVfeCXcKWIvokcCeEWaV6JHAnhBBiQQ62DrK3eYCHNhe/prI/0ZV71Rsw7YOTErjTKdALad74fFN6caVsa+yvFUUnO0fIzXBSlHnFhzID84G73AQK3AGU7YTmZ6D7OJRrvPtvtBMO/rO6u7hG7h6+lh0Var3Wf+y/wORMiK2yTlaYRE1RJr+s7+GVnsDF36dCr3DY4Nt7z5OZlsLbt5VG/wIWi2qo7TgM4RDVvgz+5q0b+PTrVvOfL3fQNjh5sY0u3+O82FDnTXdEJfy3fYWX4qw0fna8m8+8bk30A4XR1H0cgFNGJe9ZmyDrZCM8hbDpd+Dov0PbPlhxm+6JEkPfGfUhes7yuklKiFi7e42PJ05082Kjn3dsj8GfXVfoG5sGIN8jH8qK6Kj2ZXDo/BD9gWBcQqMigaWkqtfSnS+DYSTMTQ2t/nGOtA3z5k1FeK5xo9UtVTlYLLC/eZCHd5bHecIFuLBPrfNd80aouOPav27zw9D4Kzj5I7jjj+M3n1iSkckZBsZnuHOVT/coIt7O74HwnKyTFTEjt7wLYVZOj0pdCyGEENdhGAaPPN2EzWrhY8us3Q6gPMcFQPvQpOZJklygB9yF8blWei44MtRK2QQxPRvibE+AjSWZr71L0t8ENgdkr9Ay26KV1qmz46DeOZ7/WwgF4f6/kna768jJcLIqP4Nz82uKtpVLsEmYw/pitdr4dNeo5klExLOv9HF+YIKHd5aR7ozRfbgFtTA7CYPNF38oy+Xgw3dW8XcPbeDj963it3eUcc+afNYXZ5LndkYtGGe1WnhoSzG9Y9McaBmMymPGzHzgrslWza7qXM3DLMKuj4HFCnse0T1J4uhrgNxVYHfonkSIhHL7yjwsFnihqT8u17sUuJNglIiOap+6gVTWyooFKdkBU0MJdSPqfx/tBODtW68dis5yOagp8rC/ZYBw2IjXaAsTDsGTf6pujHjgr6//a1c+AOl5aq2sYbJ/DnFNLf4JAKp8Jm1XFLHT/Kw6qyRwJ2JDPrEQwqycbpiWhjshhBDXt7d5gMMXhnj71hLz1vEvQZlXBe7aBiVwp41hQKAP3HFqXrFYVMvd0IX4XC8KXukZYy5sUFuS9dqfHGiEnGqwJVi5ePFWsNqh/ZC+Gfoa4MQPofIuuQtxAeoqcy7+/ZYyabgT5lBTlAlAQ7d8b2sW/7rnPCk2C++9dUXsLlK4UZ099bG7xnW8dbNa7fT48U4t11+oUNcx2gwftSsrSHNcZWWV2Xkroeat0LIbuq+9LljMmx6D0XZZJyvEInjTHWwqzWJP0wCzoXDMr9c/plbKSsOdiBYJ3ImbUrpdnR2H9c6xQKGwwePHuijOSuPWqpzr/tpd1bkMT87ySq/Jvj888UPorYe6j6jXuNdjS4Had6pAZLvmm1TFgrX41fOvbNBJQi27IasMcqp0TyKWKQncCWFW0nAnhBDiBgzD4AtPN+GwWfmje5dfux1AUVYaKTYL7UMTukdJXsEAzE7Er+EOwLsCxjphbiZ+11yC+k7V3FRbmvnqn5idguE21WSSaBwuFZjoOAjh2H+odVXP/l/AgPv+Ss/1E0wkcLcqP4NM19VXuAgRb950B0WZqTR0S8OdGZzoGOHwhSHevKkYXyxbewpq1dl7MnbXuI7KvAw2lWbx5OleJmfmtMxwQ8EA1sFznApXcn+irZO93G2fUOfeL+mdIxH0v6LO/Bq9cwiRoO5a5SMQnONY23DMrxVpuPO5peFORIcE7sRNKdmhzs7ECNztOeend2ya39pSjPUGrdW7qlSr8/5mEzVRBwOw+3Pgyl34ithND6vzxPdjN5eIKgncJanBFhi+oNrtEmRFt0g8ErgTwqycbrU+ay6oexIhhBAm9dzZfk52jPCuHaUUZ6XpHicmbFYLJdkuabjTKdCrTndB/K6ZXQFGGEba43fNJTjZMQLAxisb7gabAQPyVsd/qGgorYOpYRg8F/9rn38Jzj0NG94ORZvif/0EtLPCS2qKldtX5ukeRYhXWVeUybn+caZnQ7pHSXrf2qPWUn3g9hu0NixVThWkuLQ13AE8tKWYyZkQTzX0apvhunpOYsHglFHB3Wt8uqdZvIINaq3WmZ/BQPONf30y6zutTp8E7oRYjLtWq9e4zzf6Y36tvoB6P94nDXciSgo8qWQ47RK4EwuTWQIZBdD5su5JFiSyTvZt11knG7F9hReHzcre5oFYj7Vwex6BiX645/9AauaNfz2oxuKizdDwBMzITeKJoKV/ArvVQnmOS/coIp5anlOnbE4RMSSBOyHMKtWjTmm5E0IIcRXhsMEXn27CabfyB3dX6x4npkq9LtqHJgmHDd2jJKdAjzoz4hi481aoc/h8/K65BCc7Ryj1puFNd7z6J/yN6kzEhjuAsp3qjPeKjHAYnvlLsDnUG55iQXIynOz+1F18+nUJGvAUy1ZNkYdQ2KCpT7631aljaJJfn+rhjlV5rC5wx/ZiVhvkr1drmQw9r9/eWFuE3Wrh8WNdWq5/I3OdRwGYzttInjvBAx23fwowYJ+03F1X/xl1ykpZIRZlQ3EmOekOXmjsj/m1+samyXal4LQn4LpvYUoWi4WqvHSa/RK4Ewtgsai1sn0NEDT375nRyVmePtPHzgovZQsIMqU5bGwuy+Lw+SFm5jRtU7jc8AU48HX1vcuW37u5r930MMyMqxtPhOm1+scpy3GRYpNoTFJp3g0WG1TcoXsSsYzJs4oQZuWcfwN8WlbvCCGEeK2nGno50zPGu+vKyY/lSjATKPe6CM6F6Q9I66sW433qjHfDHcCQ+QN3gelZWgcmqL2y3Q5goEmdidxwB9BxKL7XPfNT6D4O2/8XZK+I77UTXHFWGqkp8sGgMJf1xaol4HTXmOZJktu/7TtP2IAPxrrdLqKwVrWkjnbG53pX8KY7uHuNj33NAxdXA5rJYJP6s7W05lbNk0RBWR2U3Qonfwyj5gw4mkLfGdWa4inWPYkQCclqtXDnqjzO9gboGZ2K6bX6x6aX/fssIv6qfBn4A0FGp2Z1jyISQckOtfnB5Gtlf36yi5m5MG/fduN2u4hd1blMzYY4Mb8tQqtnPqs2jT34d+qmoZux4W1gc8LxH8RmNhE1M3Nh2oYmZZ1sspmbgQt7oHTHwtsrhVgECdwJYVZOabgTQghxdaGwwSPPNOFy2PjwXVW6x4m5SNV726BU9GsRabhzF8bvmgnUcHeqaxTDgE1XC9z5zwIWyEnQFkp3vgq8xbPhbm4Gdn8OnJlwx6fjd10hRMzUFKnvbRu65WYyXUYnZ/nxyx2sKXCzqzonPhctqFVnr8a1spuLCRvwsxPmC4HZek/SEi7krtpl8lr+9k9CeBYOfE33JOZkGKqlxlejWmuEEIty1/wK7hdjuFbWMAz6xoL4JHAnoqzap4IeslZWLEj1fWCxwv98xtSlHI8d7STdYeP1GxZ+k+6u6lwA9uleK3thH5x5Ata8cXHtV2nZsOYN0LYXhlqjP5+ImvahCUJhQwJ3yabjkGqhlHWyIsYkcCeEWUngTgghxDX84mQ35/rHee+tK8jNSPAVVAtQ5lWBu/ahSc2TJKlArzrd+fG7pqcErPaEaLg72aHe+Kwtucqdcv4myC6HlLQ4TxVFpXUw1ALjsftQ61WOfket9Ljt4+DyxueaQoiYKsxMxZvu4HS3NNzp8sPD7UzOhPjgHZVY4hX2KZwP3PXoC9zds9aHJ9VuurWyxuQwuTOdtDpWUZWXrnuc6Ki+Dwo2wNF/h4lB3dOYz1gXBEdlnawQS3THylysFnghhoG7QHCOqdkQ+Ym+7luYTvV80KNFAndiIfLXwQP/DwbPwU8+AOGQ7oleo7E3QH3nKG+oLcTlsC/46zaWZJLhtOsN3IVD8OSfgjUF7v/c4h9n8++q88QPozOXiInmfnUT/7L53kssTMtudVZJ4E7ElgTuhDCr1EjgTj6UEEIIcclcKMyXn23C7bTzwTvitBJMs/Ic9c2wBO40iQTuMuIYuLPZIassIRru6jtHsFourUy8KDQHg82Qm6DrZCPKdqozHmtlp8fgxc+DuwjqPhL76wkh4sJisVBT5OFszxhzobDucZLOzFyYf99/nnyPkzfWFsXvwr51KjyvseHOabfxxo1FnO0NcMZEgc/zp/YBYBRuil8AMtYsFrjtEzA7CYf/Rfc05tN3Rp35NXrnECLBZbkcbC7LZm/zADNzsXlN0Teq1pDLSlkRbRcb7vwSuBMLVPe/YeNvw7mn4Pm/0T3Nazx2pAPgptbJAthtVnZWeDnRMcJEcC4Wo93YyR+p71PqPgw5S2icrrwLPMVw4kemDEUKpWX+ebfKJw13SaX5WXDlQOEm3ZOIZU4Cd0KYldOtTmm4E0IIcZnHj3VxYXCS37+9giyXQ/c4cRFpuGsblMCdFoFe9c2pPc53+HsrVcNd2NzhjPrOUap9GaQ7r7ibd/iCWq2Wt0rLXFFTdos6O+KwVnbfozA5CHf/eWK3AgohXqOmKJPgXJjWAVkPH2+/ONlN31iQ9+2qwGGP49uAdifkrdHacAdqrSzAT493ap3jcl0N+wEoqdmleZIoW/cW9frt0D/Le1lX6jutTp8E7oRYqrtW5TEenONo23BMHr9vLAhAvkca7kR0lXldOGxWWSkrFs5igTd+GYq2wJ4vwunHdU900WwozBMnuqjITWdbefZNf/2t1bnMhQ0Onx+KwXQ3EAzA7s+BKxfu+PTSHstqU6HIsU44/2J05hNRdzFwlyuBu6Qx3g+9p6DybrBKHErElvwOE8KsIitlp81zF7YQQgi9ZubCPLr7HFmuFN5/W4XuceImzWHD53bSJg13egR6wF0Y/+tmV0AoqK5vUv5AkK6RKTaWZL32Jwca1ZnoDXe5qyE1E9pj3HA31gMHvg55a2HT78T2WkKIuKspUt/fnu4a1TxJcjEMg2/taSXdYeO3d5TFf4CCWvXh06SGD9LmbS3Ppszr4okT3aZpWLT0HCeEhVUbb9U9SnRZbbDr4zA9Cke+o3sac+mfb7jzrdU7hxDLwF2rfQC80Ngfk8fvG1MNdz5puBNRZrdZWZHrksCduDkpqfCuH6itEz/7AxUgMYHnz/YzMD7D27aWLKqx+bbqXAA9a2X3fgnG++Ce/6Pe71qqyHtYx3+w9McSMdHinyA3w0mmK0X3KCJeWp5TZ7WskxWxJ4E7IczqYsOdBO6EEEIoPz7SQdfIFB+6owpPanJ9g1jmddE+KK04cWcY6k2oeK6TjfDOh0pNvFa2vnMEgNrSqwTu/POBu7wED9xZrVC6E7qPw+xU7K7zwt/B3BTc/1fqA3shxLISCdw1mGitZzLY2zzA2d4A79xeRmaahteOhbXq7DkZ/2vPs1gsvHVzMf5AkH0tg9rmiOgcnmTFTBP9zhXY09y6x4m+je9SN2oc+DrMBXVPYx59ZyCrDFI9uicRIuHVFHnIzXDyQqM/Jo/fF5CVsiJ2qn0ZdAxPMj0rqyfFTfAUwTu+B6FZ+NHvwIT+17SPHe3EaoGHthQv6utX5WeQm+Fkb7wDd8MXYP/XIH89bPm96DxmThWU3QpnfwlTI9F5TBE1hmHQ2j9OVV667lFEPDXvVmfVPXrnEElBAndCmFXkTTgJ3AkhhACmZ0N87blz5GY4eM+t5brHibuyHBfDk7OMTc/qHiW5BMdgdlJfwx2otbImdbJTNTVtLLnKHbEDTerMTfCVsqACd+FZFbqLBX8jHP8elN8GKx+IzTWEEFqtyEkn3WGThrs4+9ae81gt8L5dK/QMUDAfuOvVu1b2rZG1ssf0r5Xdc+IVSiwDhAo26R4lNuxOuOUPYbwXTvxQ9zTmMDejmo9lnawQUWG1WrhzVR6NfQG6R6J/Q1C/rJQVMVSdl4FhQKtfbigVN6lsJ7zhizDaDo+9R4XvNBkYD/L82X5uW5lHYWbaoh7DYrFwa1UOZ3sDDIzH8SaNZz6rtmm87m+je7Pn5odhbhpO/yR6jymiwh8IEgjOUeWTdbJJIxxWDXf568FdoHsakQQkcCeEWUVWygYDeucQQghhCj841E7fWJCP3FWNy2HXPU7clXvVXWjtg7JWNq4CverU8c1pgjTcOWxW1hRcpa3E36iaAdOu0n6XaMrq1Nn14NXLAAAgAElEQVR+MDaP/+z/BSMM938OFrGKRAhhflarhXVFHs50jxEOG7rHSQpne8d4qcnPb2wopNTr0jNEwQZ19ugN3K3ITWdLWRZPNfQxHpzTOkvH6f0A5K2u0zpHTG19L6Rlw75HIaT337cpDJ6D8Bzkr9M9iRDLxt1r8gBi0nLXNzaNxQK5GRK4E9EXCXw0+2WtrFiEre+B7R+AC3vgqb/QNsYTx7uYCxu8fWvJkh5nV3UOAAfi1ULdth/OPAGr3wCVd0b3sde9BVLS4YSslTWbyPNtVZ4E7pJGbz1MDki7nYgbCdwJYVaRlbLT0nAnhBDJbnJmjm+80Ey+x8nDO8t0j6NFeY76oLh9SAJ3cRXoUaeOwF32CnWatOHOMAzqO0dZW+TBYbde+ZMwcG55tNsBFG0Bqx06DkX/sdsOQOP/qDcnS7ZG//GFEKZRU5RJIDhHx7D8WR4P/7pH/fn5wdsr9Q2R6lGNtZob7gAe2lLC1GyIJ0/3apthbHqWlD61XtdZtk3bHDHnzICdH1Y3TZx5Qvc0+vWdUWe+NNwJES23V+dhtcALjf1Rf+y+sWly0p2k2OSjMxF91ZHAXb8E7sQiPfh3ajvA4X+BY9+L++UNw+CxI514Uu3cvy5/SY91a1UuAPtb4rBWNhyGJ/8UrCnwwF9H//GdGVDzFug6Cv2vRP/xxaK1zDeKykrZJNIyv062+l69c4ikId81CGFWdifYnNJwJ4QQgu/ub2NgfIY/vGclqSlRrLtPIGXzgbs2abiLr0CfOnUE7lLS1CpbkzbcdQ5PMTQxc/V1smPdMBOAvNXxHywWHC4o3KgCd+Fw9B7XMOCZ/0+F+e79y+g9rhDClGqKVBtoQ7fcVBZrfWPT/OxEFztWeNlYqrlptbBWhdBn9K5Oe2NtIQ6blZ8e17dW9oVGP+strYQtdrXeZjnb8UHV8rH/q7on0a/vtDplpawQUZPpSmFreTb7mgeYmYvi9ydA31hQ1smKmKnKy8BigRYJ3InFsqXAO74LmaXwq09Cx8txvfyprlEa+wK8eVPxkt+jLvW6KM9xsa85Dg13J38EPSeh7sOQUxWba2x6WJ3Hvx+bxxeLEnm+lYa7JNL8HKS4oOwW3ZOIJCGBOyHMLNUDQfkwQgghkllgepZ/eamF4qw03rmtVPc42pR7Iw13ej+sTToXG+4K9Vw/u8K0DXcnO0cAqC25SpBhoFGducskcAdQWgdTw2otWrS88gvofBm2vi92b3gKIUyjpkgFlBu6RzVPsvx9d/8FZkMGH7hDY7tdREEtYEDvaa1jZLkc3LPGx/6WQXpGp7TM8OyZPjZYWwnlrYWUVC0zxI3LCxveBj0ntP9/r13/GbA55LWOEFF212ofEzMhjlwYitpjGoZBf2CafM8yf44W2qSm2CjJTpOGO7E06bnwrh+CxQY//l0Y64nbpR87om5eefu2pa2Tjbi1Kpf2oUk6YrnRJDgOu/8KXLlwx6djd53yW8FbCfU/htBs7K4jbkqLfxyn3UpxVpruUUQ8TI9Bx0FYcbsqNhIiDiRwJ4SZOd3ScCeEEEnuJ0c7+f/Zu+/wuMoz///vMzPqzSqjbnVbbtiyKDY2xTbG9G6qTUuAzYaUzeaXvt8ku2mbsoQNIYVAEpYWINQQDNjGprhRbLlbsnqXRl0alZFm5vfHo5FtLMkqM3NGM/frurgekGbOuS0Laeac+7k/Hb2DfOWSvNNjKwNIXEQwEcFGmXDnbd3DsWt6TLgDiMuG/g7V6OVjDtSqhpFRJ9xZStRq9pNIWYCM5Wqt3u2e49kH1QXP4Ei4+FvuOaYQwqfNSYok2GjgUJ1sKvMk68AQT++uIichgkvmJepdjpqQCj4RK3tDYRpOJ7y6r97r5x60OzhUfIxkrZ2g9EKvn18XSzeqtegZfevQW9MRNfXYGKR3JUL4lYvnmgHY5sZY2fbeQQbtTplwJzwqzxxJRYuVIbt7pzOKAJOyGK5/FHoaVdPdYL/HT9k/aOe1ojryk6I4K22Ua2FTsDIvHoAdpR6Mlf3wIehpgjXfg1D31D0qTYOCO8BqgeObPXceMSnlFis55kgMBk3vUoQ3VH4AjiGJkxVeFbh3bYWYCUKiVTe2EEKIgFXcpBqv185P0rkSfWmaRkZ8hDTceVvPcMNdhE437GOz1eqDU+7213QQGWIiZ7RIAn+ccOdquKvZ457j7X0SWkth5Vch0uyeYwohfFqQ0UB+chSH6ztxOp16l+O3Xvykhq7+IT5/YbZv3FRIXqzWhv361gGszk9kVngQr+yr9fr34EcVbeTYhqfEpi716rl1k34uJMyF/X+DIZve1eijrx26aiVOVggPWJgaTWJUCNuLLW47ZlOXalhJjJIJd8Jz8hIjsdkd1LTrM3FX+JFFN8EFX4O6T1S8rIdf324+0kRX/xDrz05H09zzPuP8nOGGuzIPxcq2V8HO36rXYkvv8sw5TrbkdkAL7A0nDt9pJu61DVHX0UeuOULvUoS3lG5Va6403AnvkYY7IXxZSJREygohRICrbOklKsREXESw3qXoLjMunIbOPmxDvvPG3e91N6rIBZNO339xww137b7VcGd3ODlY18mitGiMozUzWErUxgm9JgN6QmSiaoCs3jX9Yw30wPafQ2QSnP/g9I8nhJgxFqVF09Jjo7l7QO9S/JLd4eSJHRXERQRzU6F7Yp6mLSpJ/bz3gQl3wSYD1yxOpaSph8P13r3Wsnk4ThYInIY7TVNT7vraoGST3tXoo/moWpMW6FuHEH5I0zQunmvmeHMPte3u2ZjnarhLjpGGO+E5eYlq057Eygq3WPP/IO9S1eC1548ePdWLn9ZiNGhcvzTNbceMjwxhQUo0O0tbcDg80DC45QdgH4DLfwpGk/uP/1kx6ZC7Gkregh73NYTPCK1l8Lvz4YU79a5kRLnFCkDuaJulhX8q2wqzMiA+V+9KRACRhjshfFlojIqUld3/QggRsKparWQlRLht5+BMlhkfjsMJdR2yC9hruhsgKkW/87sa7trK9athFGWWHnptdpakzxr9AS3FaqKLv/1/m7Fc/V30TDO2addvwdoMq74NwbLLVIhAsiBVRfgcru/UuRL/9PbhRmra+rhzeSahQUa9yzkhebFqPLIP6l0JNxSqG4Qv763z2jmdTiebjzRxXnAVTmMwJAZQ89Xi20Azwr6n9a5EH02H1ZokE+6E8ITVw9Hp7ppy19ylNgRIpKzwJGm4E25lMMJNj0N8Hrz9XSjf7pHTNHT28cFxC6vzEzFHufdn5Mq8eFqttpGUF7ep2gWHX4H8qyBnlXuPPZ6CDSrS8uAL3jun3qp3w+NrofkIHHtDNd/5gDKL+jnr+rkr/FxrGbRXqul2/nZNXvg0abgTwpeFRIHTDoMSnyeEEIGof9BOfWc/mfHhepfiEzKGvw5VrVadKwkQTqeacBelY5zxSKRspX41jGJ/TQcAi0druOttA6sFzH4UJ+sye5lapxMr29MMO34D8XO8E+chhPApi1KjAThUJ5Pc3c3pdPLY++UEmwzceX6m3uWcKmUx2G1gOaZ3JSydPYvshAhe31/HkN07U5OPNXZT19HLYkM5WtIi/SYH6yEqCeasg9It0NWgdzXe52q4k0hZITxiZV4CRoPmtoY7iZQV3pBnjgKk4U64UdgsuO05taHxxXtUw4mbvby3DqcTbj7H/VO0V+QlALCjtMV9B3U44K1vgyEI1v3IfcediHlXq2Eq+54JjGEqh16GJ6+FoQFY+W/qYz4SqVsmE+4CS9m7as2TOFnhXdJwJ4QvC1E3I+iXmxFCCBGIqttUw3VWvEyAAsiMU18H19dFeFh/Jwz16xuLGh6nLlL5WKTsgVo1mWnJ7JjTP9lSotaEuV6syEsylqu1evfUj/Hez2HQCmt/6J04DyGET5mXHI1Bkwl3nvBpVTtFNR3cVJhOQqSPTeZJXqzWBv1jZTVN44alabT02PjguBtv6o1jy5EmUmklYqgD0gq9ck6fsnQjOB2w/zm9K/G+5iMQFqvv62kh/FhMWBBnZ8ays6yFgSH7tI/X1K0a7pKipeFOeE5MeBAJkSGUWqThTriReS7c+Cfo64C/bYAB931/OZ1OXvykhviIYNYMTxZ1p/Oy4jAZNHaWtbrvoPufg4YiWPYv3o+WDAqFReuh+bCqwV85nfDhr+Hv96rXu/e+CZf8AGJmQ9Fz4Jj+7+XpKrP0oGmQnSD3VgJC6VY1XT37Ir0rEQFGGu6E8GUharcTA24epSyEEGJGqGxRu7Bkwp2SOTLhThruvKK7Ua16RsqCmnLX5lsNd/trO4iPCCZtVtjpn7QUq9UfJ9wl5KsGyKlOuGsphU/+oiblzbvKvbUJIWaEsGAjueZIDtfLpjJ3e+x9Fb/++Quyda5kFCnDDXeN+jfcAdywdDhWdp93YmU3H23ivNAq9R+pS71yTp8y9zKIMKtY2UCY8uHidELTEUhaJJFGQnjQqnwzvTY7H1e0T/tYTV0DGA0a8REBNIlU6CIvMYKy5h6cgfR7UXhe/uWw5j+g6RC89kW3ve76tKqdytZerl+aRpDR/W0FESEmCjNi2VPeyqA7JlAP9MDW/4TweLjoG9M/3lQs3aDWfb4x6c3t7EPwxr/Blh9C4gK4fyukFoDBAEtuh+56j8UbT0ZZcw9ps8IICzbqXYrwtCEbVLyvrjmHjrJBXggPkoY7IXzZSMOd3IwQQohA5Gosk11YSkpMKCaDJg133tI9HPul90SOuGx1oWawT986hg0M2Tna0MXi9Bi00W6e+vOEO4NBXbioL5ra38fW/wSnHS79kdx4FiKALUqLoba9j45em96l+I2KFiubjzaxdn4ieYk+GJczK0tN8PeBCXcAs+PCOTcrlncON9LdP+jRczV29nOgtpOr4oZfVwViw50xCBbfCm1l05uSO9N0VIOtW92EFEJ4zKq5atrStuLmaR+ruaufxKgQDAZ5ryI8Ky8xkp6BIZq6BvQuRfibC78OC66HI6/BB79yyyFf/KQW8EycrMuKvHisNjsHajumf7APfw09TbD6eypuVw+phWCeDwdfgMF+fWrwlP4uePYW+PSvkLMaPvcWxJz0vVFwu1p1jpW1O5xUtFglTjZQ1OxWiSp5a/SuRAQgabgTwpeFDkfKSsOdEEIEpIpW14Q7abgDMBkNpMWGUd1m1buUwNDTpNZInRvuYocn9bRX6VvHsGMN3QzanSxOH+OinaUYjCEQm+XVurwmYzk4BqF+3+SeV/MxHH0d5l0NGcs8U5sQYkZYmKre5x6RKXdu88SH5TidcN+FOXqXMjqDAZLPgsaD4HDD1Ao3uLEwnYEhB5sONnr0PFuOqtdTBcYKMIWpabGBqGB4ykfR0/rW4U3NR9SaJA13QnjS/JQokqJD2O6GhrumrgESJU5WeEHecANIabPEyorROZ1OPqlsm3xctqbB9b9TE3bf/TEUb5pWHb22Id44UM9ZaTHMS46e1rHGszIvAYAPj08zVrajGnY+ojY8FN7thsqmSNNg6Ubo74Tif+pXh7t11sFfroCyrbD0Ttjw4unTxOJyIHMlHH0D+qY/fXaq6jv6GBhySMNdoCjdqtbcS/StQwQkabgTwpeFDL+A7ZcbEUIIEYiqWq1EBBtJiJQ4E5eMuHCq23oldsMbRibc6RwpG+dquPONWFnXbtuC2WM03LUUQ8IcMPhpXMHs5WqdzIQapxM2fx80I1zyA8/UJYSYMRamqgvyh+o7da7EP7RZbfz901oWp8ewLDtO73LGlrxYTfvykd/nV56VQrDJwMv7aj16ni1HmzAZIKHriIrWNZo8ej6flbQA0s6GQ6+omK9A0HRYrUmL9K1DCD+naRqr5iZSZrFS0zb1afh2hxNLzwBJUSFurE6I0eUlqmSj0uZunSsRvurpPdWs/8Mu7nvyE/oHJ9l0FxwBtz0LYXHw0v1qY+gUbTrYiNVm9+h0O4Al6bMIDzayo6xlegfa/AOwD8DlP9P/dffiW8Fg8p9Y2YYD8PglKrJ4zf+Dax9Rk6xHU7BB/T0cesm7NZ6k1KLec+QmyiCDgFC2VcVIpxToXYkIQNJwJ4QvczXcDcgbLyGECESVLb1kxkeMHlsZoDLjw+kfdGDpltgNj+senviid6Ssa8Jdm2/coC+qUQ0ii9NjTv+krRc6avwzTtYlrRAMQZNruCt5C6p3QuGdYPbjr40QYkIWDE+4OywT7tzi6d1V9A86uO/CHN9+zZiyWK2NvhErGxMWxKXzk9hd3kZt+9QbNMZjHRhiZ2kr12bY0AY6AzNO9mRLN6qYnyOv6l2Jd7ga7szz9K1DiACwep4ZYFpT7lqtA9gdTpJkwp3wgrzE4Ql3lgBpQheT0jMwxMObSzAaND443sLn/voxvbahyR0kNhNueRIGe+G526FvalGtL35aQ7DRwLVLUqf0/IkKNhk4LzuOfdXtk/+zulTvhsMvQ/6VkLPKneVNTaQZ5lwGZe+qyXAz2fHNarJdbyvc9ARc9P+pKX5jWXAdBEVA0bPeq/EzyoYniMqEuwDQ06ym6eesVtP1hfAy+a4TwpeFqJ1O0nAnhBCBp3/QTn1nH9kJsgvrZJlx6utRNY2d62KCuhsADSIT9a3DByfcpc0KIz5ylMkHrccBJ5j9OC4uKAxSlkDNnonFAtqH1A7joHBY9R3P1yeE8HkxYUFkxIVzqE4m3E1X/6Cd/9tVSdqsMK5cpHOD/JkkDzfcNfhGwx3ADUvTAHitqN4jx3+/xILN7uC6RBUrS2qhR84zYyy6CUyhsC9AYmWbj0BsFoTITT4hPG1lXgImg8b2YsuUj9HcpTb1JUXLhDvheUnRIUSGmCRSVozqsffKaLXa+NF1i9i4PIOdZa3c+5ePsQ5MshEt+yI16a2tDF76PDgmNymvurWX3eVtXLowiVnhnk9fuSAvgUG7k48rpxBD6nDApm+pDaLrfuz+4qZq6QbACfuf07uSqfvkz/DsrWqa3V2vwVnrz/yckEhYeD3UfQrNxzxf4yjKLFZAGu4CQtm7as2TOFmhD2m4E8KXhbom3MnOfyGECDS17b04nWqimzghY/jrUdUqDXce190EEQljxwN4S1QqGEN8YsJdz8AQpZaeseNkXTEd/jzhDiBjOfR3QEvJmR9b9IyK2T3/S/pPSxRC+IyFqdGUt1inPr1AAPBaUR0tPTbuXZmFyejjl/jM+er3uY9MuAO4ON9MXEQwL++txel0uv34m4+qRrtC0/BrmECfcBcaA/Ovhepd0FKqdzWeNTQALcclTlYIL4kKDeKcrFh2lLVMPnpxWFNXPwCJMuFOeIGmaeQmRlLabNW7FOFjmrr6+dMHFcxJjOSWc9L50XWLuGdFFnsq2rjnLx/RM9mmu/MegIKNULoFtv7XpJ769721ANx8tmfjZF1W5CYAsKN0CrGyB/4GDUWw7F8gPtfNlU3DnHUQYVbXxjzwfsOjHA7Y/H1442swKwM+vwUyV0z8+QUb1Fqkz2abMksP0aEmEiI93ywqdFa6Va25a/StQwQsH78aJ0SAkwl3QggRsCpbVENZVrxMuDuZqwGxulUuSnpcd4NvNEgZDGo6iA9MuDtU14nTOUacLJxouPPnCXcAs5epteYMsbK2Xtj+MwhPgJVf8XxdQogZY2FqNE4nHG2Q97pT5XA4+dMHFUSFmrjtvAy9yzkzYxAkLYC6vZOeruEpQcPxWGUWKwfdPHFxyO5g27Fm5qdEE9V6CIIjIT7PreeYkZZuVGvRM/rW4WmWYnDaIXGB3pUIETBW5SfSP+jgo4q2KT2/aWTCnTTcCe/IM0fS0jNAZ++g3qUIH/LwlhL6Bu18+4p5mIwGNE3jB9cs4P4Ls/m4sp07n9hDV/8kvmc0Da5+CNLPhR0Pw8G/T+hpDoeTlz6tJTk6lAvnmKf4p5mceclRxEUET77hbqAHtvwnhMfDRd/wTHFTZQyCxbdCW7mKvJ0pBvvg7/fCjv+F9PPgvi2QMMn3MpkrIDYb9j8Pdu//nCu39JCbGIk2XvStmJ7OOrDpfI/G4VAT7pIW+cZ9DBGQpOFOCF8WMjzhrl+idoQQItBUDjeUZUmk7Clmxw5PuJNIWc9yOqG7ESJ95I1qXDa0V+l+g35/TQcAi9PHmHDXUgyawf9vqGcsV2v1nvEft/t3qnHz4m+d2EgihBDAwjTVuHy4Xt7rTtV7JRZKm3u447wMIkNMepczMTmroa9NNd35CFes7Mt769x63E+r2mnvHeTS+WY1bSOlQG0iCHRZF6oJGfufU7Hz/qr5iFqTpOFOCG9Zla8aQrYVN0/p+a4JdxIpK7wlL1HFHJZaZAOKUI43dfP8xzUsy45jzbzEkY9rmsZ3r5zPFy7OZV91B3c+vmdyjZqmELjlKXWN77UvQX3RGZ+yq7yVuo4+bixMw2jwTsOSwaBxfm48Rxq6aLfazvwE+xC0lsGWH0JPI6z+HoSNcb1OTzpPeps0aws8eS0ceRUWXAd3v64SUCZL09Sf3dp8YgKZl3T02mjpsUmcrCfZeuH358NfroTBfv3qaDwAvS0y3U7oSq70COHLZMKdEEIErJGGO4mUPUVEiImEyBCJlPW0/g6wD/jOzrDYbHAMQmetrmUcqO1E0+CsMSfclahpfCY/v0kTmaj+TsabcGdtgQ8fVo87+x6vlSaEmBkWpqrNZYfrunSuZOZ67P1yTAaNe1Zm6V3KxOVfodaSt/St4ySL02PIMUfw+v56Bu0Otx13y3Cc7NWpVrD1QGqB2449oxkM6sZbd4OaROCvmg6rVSJlhfCa/KQoUmJCea/YMqXnN3cPN9xFyYQ74R0jDXfNPTpXInzFz986hsMJ37ly/mlTuTRN41uX5/PlNXnsr+1kwxO7J9aU5hKdArc9oybw/m0D9Iz/s/LFT2oAWO+lOFmXC/IScDpVwx+gmurayuH4FtjzR9j0LXh6PfymEH6SBI8Uwsd/UlOFC+/2aq0TlrQAUpfC4VfVND5f1lIKj6+F2o9g5Vdh/V8hKGzqx1tyG6B5vdmwzKLuq0jDnQdVvKeGBTUUwdvf1a+O0i1qzVurXw0i4EnDnRC+zGBUsSMDchNCCCECTVVrL2FBRsxRft64MwWZ8eFUy4Q7z+puVGtUir51uMRlq1XnWNn9tR3kmSNHnyRkH4S2Mkjw8zhZl4zz1UXPnjEmSLz/S7B1wyXfB1Owd2sTQvi8xKhQEqNCOCQT7qbkUF0nu8pbuWZJKikx07gB4m1pZ6uop5K39a5khKZp3FSYTpvVNuUmjc9yOp1sPtJEcnQoc+zH1QfTCt1ybL9QcAd63HjzqqbDYAqFuBy9KxEiYGiaxqp8M+UtVqpaJx9v1tQ1QLDRwKzwIA9UJ8Tpcs0q0UIa7gTA7vJWthxt5urFKRTMHn1Km6ZpfH1dPl9bO5dDdV3c8fge2ibTdJd+Dlz9MHTVwot3jxnz2dU/yKZDjZyTGUuONxqWTmqqu6zndX5gepLcd+490VT3m6XwzE2w6Zuw5w9Q8b6Kap1zGaz4Mlz9a7j7DTD68NTvgg1qE86R1/SuZGxVO+GJtdBRBVc9BJf+1/QndM+aDTkXQ/FbYG11T50TUGZRP1ddP2eFBxS/qdbkxfDJE3DgRX3qKHsXgsJPpLEIoQNpuBPC14VEyYQ7IYQIQJWtVjLjw0/b0SggMy6cNquN7v5JxCeIyeluUKsvTbgDaNOv4a61Z4Da9r6x42TbKsAxBOa53i1MLxnL1FozSqxsWwV8/ASkFsLCG7xblxBixliYGk1JUze2IfdNFQsUf/qgHID7LszWuZJJMhhhzjpoOggdNXpXM+K6glQAXtnnnljZMksPla29rF2QiOaK7Epd6pZj+4VZGerG27E3vXrjzauaj4A5X33PCyG8ZlW+imDcPoUG6qaufhKjQ+QajPCajLhwgo0GabgTOBxOfvrmUYKMGt+47MybOL+6dg7fuCyfow1d3PGn3bT0DEz8ZEs3wLIvQNUOeOvboz7kjf0NDAw5uPkcN063sw+pa0WlW2DPY7Dp2/DMzac11cW9/z3uNb1Ndvcnw0116+D8L6mmurteg387BN9rhAf3wO3Pwrofwzmfg4h499XqCWetB2MIFD2jdyWjO/h3+L/rVBPmHS/AuZ9337ELNqrUkoMvuO+YZzDScJcoE+48wuFQTZQJ+bDxZbVh/x9fBUuxd+vo71LXpbMu9P+0GeHTJtTu/ZWvfIXXX3+dqqoqDh48yKJFi+jv7+e2227jyJEjhIeHk5yczB/+8AeysrIAaG5u5q677qKsrIyQkBD+8Ic/cMEFF3jyzyKEfwqJVr80hBBCBAzbkIO69j4uW+gjzU4+JmM4Zre6rZeFqWNEe4rp6VYxaD7TcOcDE+4O1KopTEtmj/E91zJ8USFQJtzNHt45WL0b5l9z6ufe/ZG6mLbuRyA3rIQQY1iUFsO2YgslTd0sSpPf5xNV39HHGwcaWJkXPzNfB829HPY/B8ffhnPv07saANJjw1mWHcfmo0109g0SEza96Uabj6jpr2vnJ8GHeyE05sTmAaEUbITy7erG2/J/1bsa9+ptU5tXctfoXYkQAWdlXgJBRo3txc3cvSJrUs9t6hogc/hagxDeYDIayEoIp9QiDXeB7p8HGzhQ28m9K7PIjJ/YRK4HV+dhMmj8bNMxbn9sN8/cv4zEiUZir/ux2hzw8eOQMBfmXApDNrAPwJCNI7s+5ZKgTq4Nc8LhvWC3wdDAyOdPXQdO+vxn1+HH9bZAe5W6TnQyY7B6jTxnnZoKHJcD8bn8bLeNPx0Y4IMNa0mbNYOmeY8nLBbmXw2HXlLT/HxlCrLTCR/8j7qOF5Wimu1SFrv3HPOuUve5i57x2uv+smYrJoNGRpz8XveI+n1gbVaTyyPNsP4v8Ner4Pk74f53IcRLjY6VH6jN73mXeOd8QoxhQg1369ev55vf/OZpDchzKz8AACAASURBVHMPPPAAV1xxBZqm8dvf/pYHHniAd955B4Bvf/vbLF++nLfeeouPP/6Y9evXU1ZWhsnkwyNdhfBFIVHQVa93FUIIIbyopr0Xh5MJX2QJNK6L4NWt0nDnMb424W5WBqDpOuFuf20HwNgT7ly7+MwB0nCXMBdCZ6mGu5PV7VUXEOdcBlmy4UoIMbaFqdEAHKnvkoa7SfjLjgrsDif3X+gjN2kmK3cNGEwqVtZHGu4AbipMZ09FG28ebOD28zKmdazNRxqJCDZyfnYMvHhATYWVBvRTzb8aQmJg39Nqyoo/fX2aDqs1cYG+dQgRgCJDTJybFcfOslb6B+2EBk1syuSg3UGrdYDzsmM9XKEQp8pLjGTTocZJfb8K/zIwZOcXbx8jKsTEl9fMmdRz/+XiXIwGjR//8yi3Pbab5+5fTlL0BJrujEGw/q/wp1UqpnXTqZ/+MYAR+PukyjlBM4ApVDXUmULUtaO8tRCfe0pjHdFpo04DXtBVh+NAETtKW7jlnNlTLMIHFWxQ18uKnoU1/6F3NWqa3Rtfg31PQdIi1WwXk+b+8wSHw6Ib4dO/QsMB9zf0jaLc0kNmfDhBRgl69AhXnGz+FWrNPB/W/gA2f199T934mHfe35VuVWuuNNwJfU2o++2iiy467WOhoaFceeWVI/+9fPlyHn744ZH/fuGFF6ioUDfEzj33XJKSkvjwww9ZtWrVNEsWIsCERoPlmN5VCCGE8KKqVisAWbK7elQZcaoRsaqtV+dK/Fh3o1qjUvStw8UUAjHpuk+4CzJqzE+JGv0BLSVqTZjcBdIZy2CA2cug7F0Y7IOgMLUzdvP31cXVtT/Uu0IhhI9zNc0fru8E/OhGigd19Q/y3Ec1zE2K5OK5Zr3LmZrQaMhcCeXvgc0Kwb6xweSKs5L5f68d4pW9ddNquLN0D7CvpoMrFiUT0l4KQ30SJzuaoDAVrfXJE9CwH1IL9K7IfZqPqDVJGu6E0MOqfDM7y1rZXd46EjF7JpbuAZxOJj4dSgg3yTNH4nSq+EPZUBqYntldTU1bH9+8PJ+4iOBJP/++C3MwGTR++I8j3PrHXTz3wHJSYiYwFS4iHu58VTVBgbruZgzh3dIO3i/v4s4L8slNiTvRNGcMAVPwZ9aQkz5/0uOM0xu8syI3AYCd/tZwl7NKNRkWPQervjNqs6HX9HfCC3dD+TbVrHTzX9X7NE8p2Ki+14qe8XjDnW3IQVVbL5fMm9hrADEFxZsgPB7Szz3xsRVfgeo9aoJ55vkq6tnTyraqTfrxuZ4/lxDjcFtr729+8xuuuUZFCbW2tuJwODCbT1z8y8rKorq6etTnPvTQQ6Snp4/809MjI5SFGBESBbYecNj1rkQIIYSXVLaoRjKZcDc61zj4qlZpuPOY7gZAgwgfujgRmwVtlaqpy8ucTif7azqYnxJNiGmMC2KWYtWgGBpAF8kzlqlIkLq96r9Lt6hx/kvukJvMQogzSo8NIzrUxKH6Lr1LmTGe/6iGnoEh7rsgB20mTwSbe7mKmCp/T+9KRkSFBnHpgiQ+qmyjZhqbOrYda8bpHI6Trd+nPigNd6NbulGt+57Wtw53c024S1qkbx1CBKjVw01224stE35OU1c/wMQmQwnhRrmJKnavtFnuiQaizr5BHnn3OCkxoXxuZfaUj3PPymx+fP0iKlt7ufWPu6ltn+Br2fhcWPcj9c+a/2Dogq/zrcbVbI25gezLHlRxkWeth/nXwNx1qmEs83xIOxuSF6kNp7GZKh0jPE5tpJlmsx2AOSqEeclR7ChrxanDNUCPMRhhye3QVQsVOr4P6qiBP1+umu0K74Y7nvdssx1A+jkqKePACypm2IOq26zYHc6Rn6/Czdorofmwek9/ctOopsH1v4NZmbDpWyfeC3tKa5mqJfcS/5qWLmYktzTc/fSnP+X48eP85Cc/GfnYZy/8jfdL8d///d+pra0d+ScyUn4ICjEiZPiFzkC3vnUIIYTwmsrhCXfZCdJwN5qEyGDCg41Ut1n1LsV/9TRBhNktF8rcJi4bbN3Q2+r1U9d19NFqtbE4fYxmOocDWo6ri0eBZPZytdbsVptDNv9AxYas/q6+dQkhZgRN01iYGsPRhi4cDj+6keIhg3YHf9lRQUJkCNctTdW7nOnJv1ytJW/pW8dn3FSYDsAr++qmfIx3jjRhNGismZd4UsNdoTvK8z+pS1Xs6sEXYLBf72rcp+kwhCdApA9tXBEigOQlRpI2K4ztxc0Tfk5T1wAASdEhnipLiFHlDTeElEnDXUD6w3tltPcO8vV1+dOOFN64PJP/vvEsatpV091UNpC8f9yCpXuA9YWzMRj0bWBZkZuApXuA4/72/0bBHWrd94w+568vgsfXqonMa38I1/yvihj2NE1Tf/a+No+/ByxtVvcLcs3Sa+IRxcN/f6442ZOFzYJbnlT//sLd0NfuuTrK3lVrnsTJCv1Nu+HuV7/6FS+//DKbNm0iPFxNG4mPjwfAYjmxi6iqqoqMjKlHMggRsKThTgghAk5lay+hQQYSo+Ri72g0TSMjLlwm3HlSd4PaoepL4nLU2ub9WNkDtZ0ALE6fNfoDuupg0ArmfC9W5QPSCsEQpCIDDjyvdjgu/1eISdO7MiHEDJGbGEGvzU6LdUDvUnzemwcbqO/s554VmWNPW50p4nJUk3rJ27pMrh3LhXMSSIgM5pV9dVOaptFns/NhqYVzMmOZFR6sJsCGJ0BMugeq9QOapqbc9XdC8T/1rsY9HA5oPiqTfoXQkaZpXJxvprK1l4qWiW3Sa+6WCXdCH7nmSDQNSi1+1lQkzqi+o48/f1jBvOQobljqnmsot52XwS/XL6G+s49b/7iLygn+DHR58ZNaAG46W/9rOivzVJ/BjtIWnStxs/hcyFgBx96Avg7vndfhUFG2f7lSNUGt/zNc8DXvTgZbfBtoBhUr60Flwz9Pc80yyMAjit9U0dE5q0f/fOpSuOLn0FEFrz7ouff7pVvAYILsizxzfCEmYVoNdw899BDPPfccmzdvZtasU28+3XzzzTz66KMAfPzxxzQ2NnLBBRdM53RCBCbXKN8BidkRQohAUdVqJTMuQvfdhL4sMz6c+o4+Bu0OvUvxP04ndDeqeFRfEjscr9FW7vVT769VF8EKZo/RcNdSrNZAm3AXFAapBVCzB979CYTFwsp/07sqIcQMkhITBkBjpx9Nt/IAp9PJnz4oJyzIyIZlmXqX4x5zL4OeRmjYr3clI0xGA9cuSaOixUpRzeRvgH1Y2kL/oINLFySpqKSmQ+qGg0TcjG3xrepGib/EynZUqU0YEicrhK5OxMpObMrdiUhZ2fQovCs0yEh6bJhEygaghzaXMDDk4DtXzsfoxuu/689O56FbltDY1c+tj+2ifILNnG1WG1uONrEiN5702HC31TNVy3LiMRo0dpR6P+XC45ZugKF+OPSS58/ldELJO/DHC+HVL4ApBO5+HRbd5Plzf1Z0CuStheObobvJY6dxNdzlyIQ79+vvhKodkHMxhIzz9T37XjjrFrWpaucj7q9jyAYVH0D6eRA6RhqNEF40oYa7Bx98kPT0dGpra1m7di15eXnU1tby9a9/nY6ODlavXk1BQQHLli0bec7Pf/5zdu7cyZw5c7jnnnt46qmnMJl8KJJKiJkiJEqtMuFOCCECwqDdQW17H1kJ+l/c8GWZ8RE4nFDX3qd3Kf6nrx3sNohK0ruSU8UNN9y1VzBod/D77WXsn8LN8KnYX9NBeLBx7DgCS4laA23CHcDsZdDfAV21cNE3VHyAEEJMUPLwJJkGabgb197qdg7VdXHzOenERgTrXY57zPXNWNkbC9VEj5f3Tj5WdssRdePo0gVJKqbJblMNd2JsEQkqjqhsG3TU6F3N9DUdVmuiTLgTQk8rcuMJNhrYXmw584M5ESmbKBPuhA7yzJFUtFgZkg2lAeNoQxcv7a3lgrwELpqT4Pbj37A0nYdvW0pLj41bH9s9oYbO14rqGLQ7ufkc35jMHBliomD2LPaUt/rf/xsLroegCM9vOKn5CP56FTx7M7QchxVfgS9/ChnLPXve8RRsAKcdDvzNY6cos1gxR4UQE+aFqNxAU7oFHEMn3suPRdPg6l9DQj5s+SFU7XRvHTW71SanvDXuPa4QUzShhrtHH32U2tpahoaGaGxspLS0lPT0dJxOJ2VlZRQVFVFUVMSePXtGnpOUlMQ777zD8ePHOXz4MBdffLHH/hBC+DVXpGy/TLgTQohAUNveh93hJCtexp6PJyNONSRWtUmsrNt1N6rVZyfcVfB+iYWfv3WM6x7dwX1Pfsyhuk6PndbhcHKorotFaTFj7zoemXAXgA13rgt1szLg3Pv0rUUIMeOkxKgb2zLhbnyuaPPLF/pY3Pt0zF6udqP7WMPdwtRo5iRG8o8D9diGJn5zz+FwsvVYE3MSI8mMj4D6feoT0nB3ZgUbASfsf07vSqav+YhaJVJWCF1FhJg4LzuOXeWt9NnsZ3x8U1c/YUFGokJkYITwvrzESAbtTqrl+lbA+O9Nx3A64dtXzEPz0CTka5ek8sjtS2m32rjtsV2UNI0/0OPvn9YSFWLi8oW+cy1wZW483QNDHPDgNT9dhETCwuuhfi80H3X/8ZuPwnN3wBOXQvUuWHonfGUfrPsRhMe5/3yTkX+FSscoetYjUaNOp5Py5h6Jk/WU4k1qPVPDHajv81ufAlMo/P1z0DOxTRATUrpVrbmXuO+YQkzDtCJlhRBeMDLhThruhBAiEFS2WgE1wU2MzdVwVz389RJu1N2g1igfu6kfGg3h8dBeMTIJ6ay0GLYcbebqRz7kX576hKMN7n+9VN7SQ8/AEEvSxxlRbylRTQORiW4/v8/LvhiyLoSrfq2iKYQQYhKSY2TC3URUtKjXO34Vi2M0Qd6lqjHN1ezvAzRN48bCdDp6B9k2wShCgH01HbT02NR0O5CGu8nIWwuRSVD0DDhm+ASTpsOABub5elciRMBblW/GNuRgd/mZ4wibuwZIig7xWOOLEOPJS1Sv7yRWNjB8eLyF90os3LA0jUVpno1CvPKsFB7dUEhn3yC3PbZ7zGtmR+q7OFzfxdVLUggLNnq0pslYkaem/+0sbdG5Eg9YulGt7pxy11ENr34Rfr9CRXnOvwa+uAeu+y3EpLnvPNNhCoGzbgbLMajb6/bDW7oH6B4YGjuhREydfRCOvwMpBRP/fjLnwzX/q+41vPR5cJx5E8SElG1V9whSCtxzPCGmSRruhPB1ocMT7qThTgghAkLV8A3VrHiJlB1P5vDXp6pVdgC7neumd6SPNdyBmnLXVkFzl2rM+NXNS9j01Qu5bGESbx9u4or//YAHn9l7xp27k7G/Ru2kXTJ7nKjUlmI13S4Qb9CERsM9b8CctXpXIoSYgVJiwgBo6JSI+PFUtFgJDzaSFO1njc0jsbJv61vHZ1y/NBVNg1cmESu75aiKk117csNdVApE+86UEJ9lNMGS26G9Eqp26F3N9DQdhrgcCJb3ckLobVW+2gy1fQLN003d/RInK3Qz0nBnkYY7f+dwOPnZpqMEGw18fd1cr5zzsoXJ/GHj2fT0D3H7n3aPmhDx4qc1AKw/e7ZXapqopRmzCA0ysKP0zI3TM07G+eo144HnVSPTdFhb4a3vwiNnqw0smSvhvnfh1qfB7J3vs0kp2KDWIvdH6rp+jkrDnQdU74L+Tsi/cnLPW3wznPM5qHgPtv/39OvoaYbGg5CzGgzS5iR8g3wnCuHrXJGyA+67cSyEEMJ3VQ43kGUlyIS78aTOCsNo0CRS1hN6XJGyPthwF5cN1mY6OtoBSIoOYX5KNH+88xze+PIFrJ2fyD8PNnDZw+/zlef2uWWH+P7aDgCWpI/RcGdthd5W37yIJYQQPi4s2Mis8CCZcHcG5RYr2QkR/jd5J+8S0Iw+13CXEhPG+TnxvHusmY5e24Ses+VIEwmRIRSkz4LBfhUtKtPtJs4TUz68bbAP2sokTlYIH5FrjiA9NoxtxRac48TW9Q/a6egdJEka7oRO8swq4Ugm3Pm/1/fXc7i+i3tWZpEe673m/EvmJ/HHu86m12bnjj/t5sDwdS4A25CD14rqyTFHUJgxzkZTHYSYjJyXHc+nVe0TigefUTQNCu4AqwWOb57aMQZ64L1fwP8ugd2PgnkebHwZ7v4HpJ/t3non6JGtx3l0W+n4D0pZAkmL4OBL6n2TG5VZ1CCD3ERpuHO74rfUmn/F5J972c/UNLr3fwmlW6ZXR9m7as2TOFnhO6ThTghf54qU7ZcJd0IIEQgqW60Emwwky8XecQUZDaTNCqNaJty5n2vCXZQPTmSJzQbA2V5JsMlATFjQyKcWpcXw+N3n8tqDK1k118zr++tZ9+v3+NrzRSNRfFOxv7aT2PAg0mPDRn9AS7FaE/KnfA4hhAhkydGhNErD3Zj6B+3UdfSR7Y+bMcLjIGM5lG9z+82W6bqxMB2b3cEbBxrO+NjKFivHm3tYOz8Rg0GDpkPgGJKGu8lImAOzl8GR19TkhJnIUgxOh7qBKITQnaZprMo3U93WO+77QUv3AABJUX42RVbMGDHhQSREhlAmDXd+rX/Qzi/fLiYmLIgHV+V5/fyr8xN5/K5zGBhysOHxPeyrVhtZ3z3WRJvVxs1nz/bJzT0rc+Ox2R18UtWmdynut+R2QFNT6SZjyAZ7HoPfFMC2n0CkGdb/GR54b3hDkz5/j06nk8c+KOdX7xRT2jzOABlXs+FAJxx7w601uH6O5pr98L2znpxOKH4TotMh+azJPz8oFG55UqWkvHQ/dNZOvZbSrWrNXTP1YwjhZtJwJ4Svkwl3QggRUKpae8mMC1c368S4MuPDqW7rHXe3upiC7gbQDBBh1ruS08WphrvgrioSo0JGvRi4ZPYs/nLvebz8xRWszEvglX11rH3oPb7x4v5JN2jahhwcre9icfqssS88WoYb7szScCeEEFOREqMa7uT3+egqW1WTQI4/NtwBzL0MBnuh8kO9KznF5YuSCQ0y8Mq+M8fKjsTJzj8pThak4W6ylm6EoT44/IrelUxN02G1JsqEOyF8xerhWNltxZYxH9PUpRq+k2Nk06PQT15iBGUWq7we9mNP7aqirqOPL63OIyY86MxP8ICL5pr5yz3nMmR3cucTH/FpVRsvflKLQYMbC9N0qelMVuYlAPhnrGxMOuSuhpK3oGfs31MjHA448AL89hzY9A117faqh+DBj2DRTbrHa3b0DtLdP4TTCQ9vOT7+gxffCgbT5JsNz6DM0kNokIHUmDE2TYupsRRDewXkXz71hs7YLLj+D9DXBi/eoxpHJ8vhgLKtaoOTLybziIAlDXdC+DrXhDtpuBNCCL83ZHdQ09ZLZryf3lB1s4y4cPoG7Vh6BvQuxb90N6lmO6NJ70pONzzhLqqv5oyRP4UZsTz1+WW8+IXzWZYdx4uf1rLmf7bznZcPUNs+sca74sZubHYHS2aPE6vRUqLWBImUFUKIqUiOCcNmd9BmncIF1wBQPhyLk2P201icuZertWSTvnV8RmSIicsWJvNpVTtVreNPyn3nSBOhQQYumKNuCErD3RQtvAGCwmdurGzzEbUmLdS3DiHEiPNz4wk2Gthe3DzmY5q61PWEREkZEDrKS4ykZ2CIxi7fmvgr3KOj18Yj7x4nbVYYd56fqWstK/IS+Ou95+JwOrnriY/YXmLh4rlmn43VXpASzazwIHaWtehdimcUbFCTsQ++MPZjnE4oeQf+eCG8fD/0dcAl34ev7INzPw9GfRo4P6uqTV1rNRo03jjQwLHGcVLbIhLU+8CybdObdvYZ5RYrOQmRMsjA3YrfVOtU4mRPNu9KWPlVqP0Ytvxg8s9v3A+9rRInK3yONNwJ4euCI9ROhQGJlBVCCH9X39HPkMNJdkK43qXMCJnx6usksbJu1t3ou7vEhifcJQzWkxQ9scifc7PiePb+5Tx3/3IKM2J57qMaVv9qO//x6kEaOvvGfW5RbQcAS9Jjxn6QpRhMoTArY2J/BiGEEKdIGZ4o0yCxsqNyxeD5ZaQsqIb12GwoeVvdTPIhNxamA/Dy3rGn3LVbbXxS2caFc8yEBhnVB+v3QUyGupEkJi4kChZcr27ANB/Tu5rJazqsGgaHN4gIIfQXHmxiWU4ce8rb6LUNjfoY14Q7iZQVesob3lhRKrGyfunRbaV09Q/xjcvyT7xe1NGynHj+73PnoWkadoeTm8+ZrXdJYzIYNFbkxnOwrpPO3kG9y3G/eVdDaIzacDLae6Gaj+CvV8GzN0NrKaz4Cny1CC78urp37ENcm5TuvzAHgIc3n2HKXcEGwAn7/+aW8/fahqjr6CM30U83qumpeBMER0LWhdM/1prvQ8YK2P07OPLa5J47EicrDXfCt0jDnRC+TtPURUdpuBNCCL9XMfzGVCbcTUxGnGq4q5KGO/dxOlWkbFSK3pWMLjIJhymMDJpJjJrc7tvzc+N5/l+W88x9yzgrLYand1dz8S+284PXDo3cZPmsAzWq4W5x+jgT7izFED8HDPpfNBVCiJnIFeHWKA13o3JNuMvy14Y7TVPTDTprTkwI8xErc+MxR4XwalHdmBFv24qbcTjhUlecrM0KlmOQWuDFSv3I0o1qLZqBU+6aDoN5nu5xXkKIU63KT8Rmd7CrbPQ4wqbu4YY7H53uJAJDXqJKOZKGO/9T09bLkzurWJgazbVLUvUuZ8Q5WXH87YHlfOOyfC5dkKR3OeNakZuA0wm7yv0wVjYoFBatV++DXFOyAZqPwnN3wBOXQvUuKLwLvrwX1v0IwuP0q3ccruvzV52VwroFSbx1uJFDdZ1jP2HOpSphpegZt2y8cr1vzjX76ftmvfRY1IaovEvA5IbNCUYTrP+z+rt/9UFoLZv4c8veVRucMpZPvw4h3EiuAAgxE4TEQL803AkhhL9z7QTLkoa7CcmIU18n18h64Qa9beAYhEgfvdimaQxEZZKlNZI4wQl3pz5dY2VeAi/96wqe/Nx5zE+N5sldVVz0i2381z+O0Nx9arPHgdpO0maFYR5r2sFAD3TVgjl/Kn8aIYQQnDThTiK0RlXR0kNCZDAxYb4RFeQRcy9Ta8lb+tbxGSajgeuWpFLV2sve6vZRH7P5SBOaBmvmJ6oPNBwAp0PiZKcqcwXE5cD+58E+g6aYWFvA2ixxskL4oNX5ZgC2F1tG/XzzSKSsTLgT+slLlAl3/up/3inGZnfw3Svn+1zM5aK0GB5cnUeQ0bdbBVbmqanRO0r9NFZ26Qa1Fj0DHdXw6hfh9yug+J8w/1r44h649hGISdO3zjNwNdxlxIfztUvnAvDwlpKxn2AMgsW3Qls5VO+e9vnLLOrnZ65ZJty51fG3ASfkX+m+Y0anwE2Pg60HXrgLBsdPoAFUj0TNHjVlzx2Nf0K4kW//FhVCKCFRMNCtdxVCCCE8rLJFvTHNkkjZCckYiZS16lyJH+lpVKuvTrgDusLSSdVaSY6Y+kQ5TdO4eK6ZV7+4gj/fcw5zkiL5844KLvrFNn765lFaewawDgxxvLmbxePFybYMXziShjshhJiylJEJdxO4yBqAylus5CT4+U2DzJUQHAXFvtVwBydiZV8aJVa2f9DOeyUWCjNiSYgcvujvmkwhDXdTo2kqXsraDMc3613NxDUdVqs03Anhc7ITIsiIC2dbcfOo00qbuvqJCjURHmzSoTohlKToECJDTNJw52cO1XXyalE9F881jzSNicnLig8nNSaUHWV+2nCXWgiJC2DfM/DI2arxLnMl3Pcu3PoUmOfqXeGEVLVaiQ0PIiYsiPkp0Vx1Vgpbjjazfzg9ZFQFrmbD6U+3LhuZcOfn7529rXgTaAaYs869x81ZBau/B02H4M1vnPnxlR+AY0hN2hPCx0jDnRAzQWi0RMoKIUQAqGy1Emw0kBITpncpM0JkiImEyGCZcOdO3Q1qjUrWt45xtASnYtIcZBinHyWhaRpr5iXxjy9dwGN3nk12QiSPvV/Ohb/Yxjf/fgCH8wxxsq6Gu4SZcfFLCCF8UfLw656GDplw91ntVhsdvYNk+2ucrIspGPLWqKgaq2/dSFuQGs285Cje2F/PwJD9lM/tLm+l12Zn7fyTJgOPNNxJpOyULbld3dTZN4NiZV0Nd4kL9K1DCHEaTdNYlW+mtr1v5Gb8yZq6+iVOVuhO0zRyEyNHJjSJmc/pdPLTN4+iafCdK+fpXc6M5kqrKLdYaez0w/eMmgZn3wtDfWCeBxtfhrv/Aeln613ZpFS19ZJxUmrPV9fOQdPgoc3jTLlLWqA2Kh1+FWzT21BfZulB0/D/987eNNinYlxnL/dMlPGFX4e8tbDvKdVwOp7SrWrNlYY74Xuk4U6ImUAm3AkhRECobLUyOy4Mo49FDPiyjLhwaqThzn26XRPufLfhrsGgakuxN7jtmJqmsW5hMv/88gX8fkMh6bFh/POgOv6S8SbcWYrVKhPuhBBiyiJDTESFmmjwx5sn01Teom46ZJsD4KbB3MsBp09ONbuxMI2u/iHePdp8ysc3H2kC4NIFn2m4i8uBsFhvluhfYtIgd42KGO5pPvPjfUGzTLgTwpetzlex39uLT/+Z0tw1QJLEyQofkGeOpKXHRkevTe9ShBu8V2JhZ1kr6wvTmZccrXc5M57fx8qedz/860544D01wUubWfcGem1DWLoHyIo/kdozNymKaxan8l6JhU+r2sZ+csEGFS165PVp1VDW3EParDDCgqeeiCI+o+J9GOyF/Cs8c3yDAW54DKLT4J9fP7GJ6bOcTijdArMyID7XM7UIMQ3ScCfETBASDUP9MCRvtoQQwl/ZHU5q2nrJig+AG6pulBkfQUuPjZ6BIb1L8Q8zoOGuwq5ulsTZ6t1+bINB44qzUnjrqxfxyO1L+eKqXM7LHmcHX0sJaEaIkzf7QggxHSkxoTR2ScPdZ5UPTznJ/7ttbgAAIABJREFUCYRd+nmXAppqsvIx1xWkYdDg5X0nYmWdTidbjjaRnRBBrqshsr8LWo9LnKw7LN0ITjsceF7vSiam6QhEJkGExMUJ4YuW58QTbDKwvdhyysetA0N0DwyRFCUT7oT+8hJVDKLEys58doeT/950jBCTgX9fJ4kI7rAiNx7w44Y7TVMbNwwzs22jqlVths+MCz/l419dOweDBr/efHzsJy+6CYzBKkp3iuwOJxUtVomTdbfiN9Waf6XnzhERDzc/CY5BeP5O9Z76s9rKoaNKTbebYc2oIjDMzJ/cQgSakCi1ypQ7IYTwW/UdfQzanWQFwg1VN8oYfiNf3SpT7txipOEuRd86xlFiMwMQ2l3lsXMYDBrXLEnlm5fPw2Qc5y2TpRjislUUnhBCiClLjgmjobMPp9Opdyk+pWJ4wl1OIEy4izRD+rkqKsbHNhsmRYeyMi+B7cXNtFlVbQfrOmnqGmDt/EQ010X/hiK1SsPd9OVfqaYE7ntaTTTwZQ47NB+VOFkhfFhYsJHzc+L5qKIN60mb9Zq7BwBIlEhZ4QOk4c5/vLy3lmON3Xz+gmxSYsL0LscvJEaHMicxkh1lLfKe0Qe5Gu4yPjNIINccyfVL0/iwtIU95a2jPzk8DuZdBZUfQFvFlM5f39HHwJBDGu7cyeGAkrchfg4k5Hn2XLPPhXU/hrYyeP3Lp7//c8XJ5q31bB1CTJE03AkxE4QOj5we6NS3DiGEEB5T2apuqJ48el2c2UjDXZtV50r8RHcDaAaIMOtdyZiO9EYzhAGtvVLfQoZsaoddgsTJCiHEdKVEh9I/6KCzb1DvUnxKRYsVgwaz4wLk9eHcy8DWDdU79a7kNDcWpjFod/LGATVhd8tInOxJU4Hr96lVGu6mzxQCZ90ClmNQ96ne1YyvvRKG+iROVggftyrfjM3uYGfZiRv+TcPTdSVSVvgCabjzD/2Ddv7nnRJiw4P4wipJQ3CnlXkJNHUNUGaRa8C+xnVdfrT7Gl+9ZA5Gg8b/bC4Zu1myYINa9/9tSucvHZ4Mn5sYABvVvKWhSN0n8FSc7Gct+wLMvxaOvAofPXbq58q2gsEE2Rd5pxYhJkka7oSYCWTCnRBC+L1K1+h1iZSdlMzhN/JVMuHOPXqaICIRDEa9KxlTY4+dFmMitE9t16PbtJWrqDOzxIMIIcR0JceoyTINnRIre7Jyi5X02HBCTL77e9mt5l6u1pK39a1jFJctTCY82MjLe1Ws7OajzcSGB1GYMevEg+r3ARokL9anSH+zdKNa9z2lbx1n0nRYrdJwJ4RPW52fCMD24uaRj51ouJMJd0J/s2PDCDYaRhpHxMz05x0VNHb185VL5hAdGqR3OX5lZV4CADvL/DRWdgarHJlwd3rDXWZ8BOsL0/moou2UpvdT5K5RaStFz6rJapNUNtyoLBPu3Kh4k1o9GSd7Mk2D6x6FuFx4+3tQ+4n6+JANKj6A9PNODCcSwsdIw50QM0FIjFpHyy4XQgjhF6paXDvBpOFuMlxv5KvapOHOLbobISr5zI/TiW3IQavVRntIupomomeMREuxWmXCnRBCTFvKcMNdozTcjXA4nFS0WgMjTtYlaSFEp6uL+z4WFRUebOLyhckU1XTwwXELRxu6WDMv6dTo+fp9kDBHbgS4S8pi1bx46GWw+fBrfVfDnUTKCuHTshIiyIoPZ3uxZWTCTnOXipSVCXfCF5iMBrITImTC3QzWZrXx+21lZMSFs2FZpt7l+J1lOXEYNNhRKg13vqa6tZfwYCPmyNF/n35pTR5BRo2HxppyZzDCktugs1pFy06Sa+qhNNy5UfEmCIuD2ed575yh0XDL/6nvhxfuht42qNkNg1bIW+O9OoSYJGm4E2ImkAl3Qgjh9ypbewkyaqTOkp3Vk2GODCE82Ei1TLibPodjuOEuRe9KxmTpUTdErOGzYbBXTeTTrZgStcqEOyGEmDaZcHe6+s4+bEMOshMCqOFO0yD/cjXFtuW43tWc5sbCdAC+9fcDAFy6IPHEJ3vb1GaA1EIdKvNjSzfCQBcc/YfelYyt+TBoBjDP07sSIcQZrMpPpK6jb6ShyTXhLjFKrsMI35CXGEldRx99NrvepYgpeOTd43QPDPHNy/MJNsntd3eLDg1icfosdpW1Ynf41uacQFfVZiUjLhxN00b9/Oy4cG45ZzafVrXz/vExGiZdsbJFz0z6/GWWHqJDTSREBk/6uWIUHdXQdBDmXub9FJzkRXDlr6CrFl5+AEq3qI/nXuLdOoSYBPmNL8RM4NodPSAT7oQQwl9VtlqZHRt+6pQMcUaappERF061TLibvr42cAxCVJLelYzJdUPEFpOlPtBWrl8xIxPupOFOCCGmKyUmDIDGzj6dK/EdFcPTj3MCqeEOToqVfUvfOkZxfm48SdEh1Hf2E2wycOEc84lP1u9Ta+pSfYrzV2fdDMZg346VbToC8XkQJA07Qvi6Vfnq5/a24VjZpm61oStRJtwJH5GbGInTqZpHxMxS1Wrl6d1VLEmP4aqzfHcj60y3Mi+erv4hDtV16l2KGGYbclDX3kfmKHGyJ3twdR7BRgMPvVM8+pS7hDkqNvTI65NOeyu39JCbGDlmw5+YpJK31Zp/hT7nL7wTCjZC6WbY9TsIj4eUAn1qEWIC5I6uEDOBTLgTQgi/Znc4qW7tPeMbUzG6jLhw6jr6GLQ79C5lZutuVKsPT7hzRf4Y4nPUBxr261eMpRii0068ThNCCDFlKcMTfutlwt2I8uFYnJxAi8XJuhCCwk9c5PchRoPG9QVpAKzMjScixHTik9Jw5xnhcTDvKhUt1VahdzWns1nVBhCJkxViRlieE0+IycD2YgsATZ39xIYHEWLy8vQWIcaQl6he90nD3czzy7eLGbQ7+c6V86Xpx4NW5iUAsKNMYmV9RV1HHw4nZMaPv1EsdVYYdyzLYH9tJ+8eax79QUs3wFAfHH5lwufv6LXR0mOTOFl3Kn5TbXrK1THG9cpfQuJCNRwgZzUYpKVJ+C757hRiJggZnnDXL7s2hBDCHzV29WOzO874xlSMLjM+HLvDSX2HTMWZlpGGu2R96xhHc/dwI0b2RRAWBzt/C0MD3i/E4VBRdzLdTggh3CIqxEREsJFGabgb4ZpwF1CRsqCmhOWsgupd0NeudzWnufXc2USFmrjlnNmnfqJ+n4oVTT5Ln8L82dKNat3/nL51jMZyDHBC0iK9KxFCTEBokJEVufF8XNlGz8AQTd39JEXLdErhO/KGG0ZcscdiZiiq6eCNAw2snZ/I8px4vcvxa4UZsYSYDOwsbdW7FDGsqlW9b53IIIF/XZVLiMnAQ5tLRp9yt/BGMIVNKla2bHijmjTcuUl/F1R8oK6967nJPDgcbvk/SC2Ewrv0q0OICZCGOyFmAplwJ4QQfq0yUG+ouklGnHpDX9UqsbLT0t2gVh+ecOeKlE2Ij4cLvgZdtfDpX71fSGeN2nFpzvf+uYUQwg9pmkZyTCgNEik7orzFSmiQgeRAbASYezk47VC6Ve9KTpNjjuTgDy/jis9GhdUXgXm+ujEg3CtntZoqvO8ZcNj1ruZUTUfUmiQT7oSYKVblJzJod7KjtIWmrn4SA/H3rPBZOeYINE0a7mYSp9PJT988ikGDb10+T+9y/F5okJFzs+L4uLKN/kEfe10YoFzX4zPjznxfIyk6lI3LMzlc38Xbh5tOf0BoNCy4Fmr2qI3OE+CaCJprlvsqblG2VU2V0ytO9mQJefDANsi5WO9KhBiXNNwJMROExqh1YHK59UIIIWaGyknsBBOnyxieDFjVNrMb7voH7Ty1q5Jvv3SA5z+uprq1d/Tdfp7SMzzhLjLJe+ecpKbhSNnE6FA49z5V6/u/UnFe3tRSolaZcCeEEG6TEhNGQ2e/d3/3+bBySw/ZCZEYDAEYSTVnnVpL3tK3jonqaVabACRO1jMMRlhyu/oaV7yndzWnajqsVomUFWLGWJ2fCMDr++vpH3SQFBWic0VCnBAaZGR2bLg03M0gW48281FFG7eeO5s5STpOgwogK/LiGRhysLfK96ZhB6KRhrsJ3tf4wsW5hAUZeXhLCQ7HKO/9C+5Qa9GzEzreSMNdoky4c4viTWqde7m+dQgxg0jDnRAzgUy4E0IIv+Z6Y5olkbJTkvn/s3fn8VHV9/7HXzOTZCbrZN8gkI0AoggiqCgguGvrUmtdr93sclvr7d6qvbe/Xrva232vdtFq3Vtb9w1QFBVURBQlkBXIvk8mmUkmM78/TiaAJJBlZs5M8n4+HjwOzJyc80EhzDnn831/hhPu6tsj3HQVIv0DQ/zpxRpW37qB//7XO9y7dS/feGgHq3+8gdN+tIGv3L+dB1/fx/5wj8wdGSkbvQl3LS4vifE2Uu1xRoLM6q+BuwW23BbZQlp3GVsl3ImIhEy+00HfwBAur8/sUkznGRxif1c/pTM1/TitAAqWwO5nYCgG/jw0vGlsZ6nhLmyCD9623WVuHe/X8g4kpED6XLMrEZFxmpOVRGl2Ms8MJ+topKxEm/LcFGrb3fiG/GaXIkfhG/LzwyffIzHexhfP1ILMSDm1LBuAl6raTK5EAOo73MTbLBQ4x/fvaU6qnWtXzuW9JhePv914+A7Fq8E5B7bfO65066oWN3FWy8gEHJmCIR9UPgX5i8E52+xqRGKGGu5EYkGcHWx2Y3a6iIhMO7VtxoXh7IxEs0uJSbMyErFZLTE3Utbt9fHHF6pYdet6bnl0JwHgWxcsZNPX1/Lrq5Zy9UlzsMdbeeiNfXz1ge2c+sP1rL51A9948C0e3rZ/ZLxqyLiawGKD5OzQHjeEWno85KXZsViG035OuBacRfDSz8HTHblC2oYb7rLVcCciEirBG/RN3SH+9y0G1Xf0EQhAyUxtuANjhI2nyxgnFO0a3jC2SrgLn6wymHsavPso9EdJmkkgYCTc5S4Eq26xi8SSNfNzGBhuZspLU8KdRJfy3BQGhwIxP8VhJnjg9X3saenlU6tK1LwbQcfOcpLmiOOlPe1mlyJAbXsfszOSiLON//PwZ1aXkZxg4+fP7mbo/Sl3VissuRJcDVC14ajHqm7tZW5WEvETOL+MYe+rxjX4/PPNrkQkpui7j0issKcq4U5EZJqqbXczOyNxQhemckC8zUphuoP6GLkZ6fIM8psNe1h16wa+//h7xFmt/L8PHsOmr6/lulWlFGUm8YHFhXzvkuNY/5XTefWmM/jFFUu4YnkRFgvc99pevnjfm5z0/edY938buemfO3hkewOtLu8UC2uElFxjbFeUau7xkJt60E3MODus+Ybx4PWV30WukNZKSMyI6uZEEZFYkz/ccNeohjuqW43U3hndcFdxjrGNhbGyDdvAGg95x5pdyfS29GoY8sKOB82uxNDbAn3tGicrEoOCY2UBctUkI1GmPMcYi6ixstGtb8DHT5+pJDslgU+vKTO7nBnFZrVwSlkWb+3rosczaHY5M5rfH6C+o2/C6XKZyQl8/NQS9rT08sj2hsN3OP5KY/vmkdOtB3x+6jr6KMvRONmQ2PW4sZ1/nrl1iMSYOLMLEJFxUsOdiMi05PcHqGvv4+TSLLNLiWlzM5N5o76TQCBwIP0synT3D3LH5lr+9GIN3f2DzEpP5LsXH8tlJ87GHjd2k1temoOLlszioiWzAGjo6uflqnZerm7n5ap2/v5qPX9/tR6AebkpnFKWxSmlWZxUmkVmcsL4C3Q1Q2r+lH6P4eT1DdHZN0ju+xMIjr8SXvwZbP41rPg0JGWGt5BAwEi4y54PUfpnTUQkFh1IuAvzCPUYUN1mPGAtzZnBDXf5x0NKvjHS5uxbzK5mbIGA0XCXd4yxEEDC55iL4PGvGWNlV3zK7GqMcbKgRkuRGLSiJJPEeBv9g0NKpZKoU5Z7oOHunEUmFyNjun1TDa0uL7dcfCwpdj1qj7RTy7N56p1mXqlq5+xF0Xsvc7prdnkY8Pkpzpr4ONfrVpVwx+ZafvHcbj6wuODQIILMEiPd+r3HjEXWiRmjHqO+w82QPzDyfVOmIBAwGu5SC6HgeLOrEYkpilERiRWONPBGcFSaiIhERLPLg3eSF6ZyQFFmEn0DQ7T1DphdymG6+gb46dO7OO2H6/npM5U4E+P50aXHseGrp3PNyXOP2Gw3msL0RC5dNpv/u+x4XvrmOjZ9fS23XrqYS5bOwuXxcefLdfzn3W9wwi3PcO7PX+A7j7zD0+800d13hFWffj/0NkFqwRR/t+HT0mMk+B32QMQWB2tvggEXvPSL8BfibjNu9uRUhP9cIiIzSH5aIqCEO4AaJdwZo4Qqzjaa3Duqza5mbK5G6G3WONlISEiGYz8EjW9C09tmVwPNO41tnhLuRGKNI97GyjJj0WO+Gu4kypQPN45UKeEuanW4B/jD81WUZidzxfIis8uZkVaWGRMnNldprKyZatuMaTNzsiZ+3ZqelMAnV5VQ0+bm4TdHSblbejUMDRwx3XpPi3HdrIS7EGjbbVx3zz9PC8xFJkht9yKxwp4GXfVmVyEiIiEWvDAtnskPVENg7nDDYn2Hm5zU6EgXae/1cvuLNdy5uRb3wBAl2cn8vwsXcdGSwpCODy7KTKIoM4mPLC8iEAhQ2953SALeX16q5S8v1WKxwKLCNE4pzeLipbNYVOg8cJC+dvD7ojrhrsUVbLgb5f/vog/Bpp/Aq3+Akz8HqXnhK6Rtl7HNnh++c4iIzECF6cMjZbvUcFfT5iYzOYH0pAkk1U5HFefBG3caKXcn/6fZ1YyuYZuxLTzB3DpmiiXXGH8m3rwbzv2BubU0DyfcaaSsSEz6xnkLWDM/Z2SkvUi0cCbGk5NqZ0+rGu6i1Z9erMY9MMSXzqogPoT392T8ynKSyU9z8NKeNrNLmdHqO4yGt8kGCXzitBL+/GINv3xuNxctKTz071Mw3frNu8dMt64a/j5ZNpOT4UNF42RFJk2fBERihT0NPD1GrKuIiEwbte3BC1NdGE7F3Ezjwr6uvc/kSqDF5eF7j+3ktB9t4HcbqyhIT+QXVyzh2S+v4dJls0PabPd+FouFkuxkrjppDr+6cilbbz6DZ7+8mlsuWsT5xxbQ2OXhtk013HDPtkO/sLfJ2KZEccNdj9GAMerIH6sV1t4Mvn548afhLaR1uOEuRw13IiKh5EyMxxFvpbFHDXfVbW5KtRgDSteAzQ6VT5pdydhGGu6UcBcRRSsgax5svxd8Jidbt7xjjFxKyjS3DhGZlIq8VK49pdjsMkRGVZ6TQlVLLwE9C4o63X2D3LG5jtKcZM4/LnqnREx3FouFleVZ7G7pHblfKJEXvA8/d5INd2mOeD69upT6jj4een3foW8mJMOii43rrWCy9PsEG+5KlXA3dZVPQnwyFK8yuxKRmKOGO5FYYU+FwBAM9ptdiYiIhFCw4W6yF6ZiCCYEfuOhtzjvF5v4yv3b+dOLNWyuaqOrLzIP45q6PXznkXdY9aMN3LaphrlZSfzmqhN4+ouruWjJLGzWyMexWywWynNT+Y9TivnN1Sew9eYzWTUvm72d/YfeuHUNN9xFccJd8/ANtDETDBdcYDzsfu3P0LU3fIUEG+6yNVJWRCSULBYLBc5Emrpn9jVvV98AHe6BmT1ONighGUpWQ+1LxgLEaLT/DaMpMHeh2ZXMDBYLLL0G+jug8gnz6hjyQct7GicrIiJhUZ6bgntgiCY1EkWdv2yuodfr4/q15abc55MDTh0eK/tSlVLuzFLX3ofFArMzJv9c42OnlpCRFM+v1u/B6xs69M0lVxvbN+8e9WurWo1JN87E+EmfXwB3G+x9FcrXQbySf0UmSg13IrHCkWZsvVF6k1lERCalrq0P6xQvTAUW5KfyzfMWsHpeDl19Azz0xj5ueXQnV932Kkv+9xlO/eF6rrvjNX769C6efLuR+vY+/P7QrBTe39XPfz/8Nqtv3cBfXqqlPDeFP/zHMh6/YRUXLC7AGkU34KxWC0WZSQz4/LS7D2pEdDUa29ToXZ3bPDJSdowLf4sF1n0LhgbghR+Hr5C2XRCfBM6i8J1DRGSGyk9z0Ng9sx8s1rQZizFKNBbHUHEO+Aehar3ZlRwuEDASF/KPA5se8kTM8VeAxQbbRn/wFhEd1TDk1ThZEREJi/JcI61pT4vGykYTl2eQP79oLLC98PhCs8uZ8U4tH26429NuciUzV12Hm4I0B45426SPkWKP4zNrytjf1c/9r70v5W7OKZBZCm/dB0ODh7wVCASobunVONlQ2P00BPww/3yzKxGJSXFmFyAi42RPNbZeV1Snz4iIyMTUtruZnZFEQpzWQUyFxWLhs2vK+OyaMgA63QO829jDzuCPhh427mrh2XebR74mxR7HwoJUjilIY2FBGscUplGRlzrumwR7O/r47cY9PPj6PgaHAhxflM4N68pZtyAXiyV6muzer9BpNKw1dnnIThlOixtJuMszqaqja+k5SsMdQNkZMGclbLsLTv0vyCoLfSGtlZBVboyxFRGRkCpwOni5up1er48U+8y8ZRVsuNNI2WEV58LjX4XKp4yRQtGkq95IWiu81OxKZpbUfJh3lvFgqKcR0kxYMNLyjrHNOzby5xYRkWnv4Ia7VfNyTK5Ggu58uY4ej4+bL1hInE33hMyW73RQmpPM5j1tBAKBqL4XOx0FAgHq2vtYVJg25WNde8pcbt9UzW/W7+GyZbMP3Ju3WGDJVbD+u7D7GVhwoCGs1eXF5fVRpnGyU7frcbBYYd7ZZlciEpNm5t1LkVhkH/7QEq1jVEREZMICgQC17W6WF2eaXcq0k5GcwMrybFYOr3YE8PqG2NPSy84Gownv3eFGvK21nSP72KwWSrOTOaYw7ZBGvJHGNKC2zc1vNuzhH9v2M+QPsGxuBjecMY/V87Jj4uZOYXoiYCTzHTfbabw40nAXvQl3LS4PyQm2IzdgBFPu/no+PP8j+NAfQ1uEpwdcDVB8WmiPKyIigPHQBIwx7cEHjTNNdetww50eHBjSi4ympt1Pg38IrJNPTwi5hm3GtnCpuXXMREuvgconYfs9sOrLkT9/c7DhTgl3IiISekq4iz59Az7+9GINs9ITuWTpbLPLkWGnlWdz58t11Lb3UaIFSxHV2TeIy+NjbubU/7snJcTx2TVlfPexd7lnSz0fP7XkwJvHXwnrv2eMlT2o4W5Pq/H9UQ13UzTogT3roegkSM4++v4ichg13InEipGEOzXciYhMFy0uL55BP8VZuiEQCfY4G4sKnSwqdI68FggE2N/Vz7uNruFGvG7ebXTxrzcb+NebDSP75abaWViQRmK8jad3NuEPwEklmfzXGfM4pSwrJhrtggqcRsNdY3f/gRddTcZorqTovbBu7vGQe6R0u6DiU6FsHbx1P5z2JchdGLoi2nYb25yK0B1TRERGFKjhjpo2NxYLzMlMMruU6FFxDmz6Cex/A4qWm13NAcGGu1knmFvHTDTvHONz67a7jM97kf4s3rzT+Oycrc+EIiISermpdlLtcWq4iyJ3v1JPh3uAWy4+VlNKosjKMqPh7qU9bWq4i7C6dmOh2Nzs0Fy3XnPyXP74QjW/3VjFFcvnkJgwvNDKORtKTzcW27jbRprCqoa/P5bN0PsGIVO7CQbdRrK8iEyKGu5EYoVjuDlADXciItNG7fDIsGLdEDCNxWJhdkYSszOSOOuYA+NUezyDvNfoGknB29nYw8vV7Qz4/JxWns0X1pVzUmmWiZVPXmH68EjZbs+BF12NxniuKB6T2tzjZUF+6vh2XvstqFoPG74Pl/8tdEW07TK22fNDd0wRERmRP1pT+AxT3eZmVnriuEfczwgV5xoNd5VPRFnD3RsQn6SmKzPEJcDxV8DLv4a9r8KckyN7/pZ3jP/vcfaj7ysiIjJBFouFstwUqlrVcBcNPIND/OGFavLS7Fy2TOl20eSU0iysFnh8RyNXnzQnphZEx7r6jj6AkCTcATjibXx+bTnf/vc73PVKHZ9aXXrgzaXXQPUGY3H1KZ8DoGo4Gb4sR89VpmTXE8Z2/vlH3k9ExhS9T9RE5FAjCXcuc+sQEZGQqR1eCVacpQSTaJPmiGdFSSYfXVnMjz68mEe+cBo7v3MOW28+k7uuOylmm+3gwLi+/V0HNTP0NkNK3hhfYT7P4BDd/YPkjSfhDmD2Mph/Abz7b2h4M3SFtA433OWo4U5EJBwOTribifz+ADVtvRon+36zlhlpZpVPmV3JAX4/NGyHguOja8ztTLL0GmP71E3GKKRI8bqgs1bjZEVEJKzKc1No6x2gq2/A7FJmvHu31NPW6+Uzq8u0KCbKOJPiuXjpLDZXtfPYjkazy5lRatuGG+5C+Fzj8uVFFDgd/P75Ktxe34E3FlwAdqcxVjYQAKCqtRdHvJXC4UV7MgmBgNFwl1kG2fPMrkYkZqnhTiRW2NOMrUcJdyIi00Vte/DCVCuxYkGczUpOauynWNjjbGSn2GkMNtz5/cZI2dQCcws7glaXF4C8tAn89197E2CBDd8LXSFtlWCNg8zSo+8rIiITFmy4a5ihDXdNPR48g35KlX58KKsN5p0NzW9D116zqzF01oC3GwqXml3JzJW70Bgnu/91eOSGkYdvYdfy3vD51XAnIiLhUz48JlFjZc3l9Q3x++eryU5J4MoVc8wuR0Zx8/kLyUiK5zuP7KS7f9DscmaMug4jSGBOCBvuHPE2rl9XTrt7gDterj3wRnwiHPsh43qw6S3AGClbmp2C1apUw0lr3A6uBph/HigdUmTS1HAnEiuUcCciMu3UtbuxWqAoUyuxJLJmpTto6BpuZuhrg8CQMVI2SjX3GLXmpo4z4Q4g/1jjZszup6H+1dAU0rrLaLazxYfmeCIicojM5AQSbFaaZuhI2Zo246FFiRruDldxjrHdHSUpdw3bjK0a7sy17n+g4jx46z546ReROWfLO8Y279jInE9ERGak8hw13EU/26BeAAAgAElEQVSDB1/fR1OPh0+tKiUxQel20Sgrxc5N5y+k1eXlR0++Z3Y5M0Z9ex+ZyQmkOUJ7j/SyZUXMSk/kjy9U4/Ic1EAZTLfedjdur4+Gbg9luUqGnxKNkxUJCTXcicQKx3DCnVcJdyIi00VtWx+F6YnY43TDRiKrwJlIi8uDb8gPruGRC1HdcGck3OVOJOEO4PQbwWKF9bdMPfXE5zXSbLIrpnYcEREZk8ViId/poHGGJtxVtxoPVEtz1HB3mLJ1YI2HXU+aXYlhpOHuBHPrmOmsVrj0NiNt7tn/d+ChUTg1BxvulHAnIiLho4Q78w0O+fndxioykuK55uS5ZpcjR/DhZbM5pTSLv79az2u1HWaXMyPUtvcxJzN06XZBCXFWbjijnK6+Qf76Uu2BN2Ytg+z5sON+apuN/8dlum6eml2PQ2IGFJ1kdiUiMS3O7AJEZJxGEu7UcCciMh0EAgFq292cMCfD7FJkBipId+APQLPLyyxXs/FiVDfcGY0XeWkTSLgDyJ4Hx18Fb94FNc9D6emTL6K9CgJ+yJk/+WOIiMhR5TsdVDbPzGT3aiXcjc2RBsWnQs0LMOCGBJP/GzVsA3uaxsxHA3sqXHkP/HEtPHQdXPesMW42XJp3Gv/vnUXhO4eIiMx4RZlJJMRZ2dOqhjuz/HPbfvZ19vPVsytItutxejSzWCx875JjOfcXm7jxHzt47IZVJMQpcyhc3F4fbb1eTivPCsvxP3TCbH67sYrbNlVz7cpinInxxsjTpVfDM/9D6jNf48txcG5rPqxPPfCFYy62HuP1sfaPc8DJnwWHc0q/j6jWvd8Yz7v4crDp+5vIVOhvkEissA8n3HnUcCciMh209nrpGxhiblboV4KJHM2sdGOMcUNXP7NGEu4KTKzoyFpcRsLdhBvuANZ83Rgz9twtULLGuEEzGW27jG22Gu5ERMKpwOlgS00H/QNDM25sU02bm4Q4K4XORLNLiU4V50L1Rqh+HhaYOPbGPwQNb8KsE4yENTFfRjFc/je48yK45wr41AZIygz9eQIBY6Rs7jGT/0wpIiIyDjarhdLsZCXcmcQ35Oe3G/aQ5ojj2pXFZpcj41Cak8L1a8v56TOV/PGFKq5fN8/skqat+o4+AOZkhWcRVLzNyg3r5vGVB7bzpxdr+PJZw9NGFl8OG3/InL0Pc0McsGv4Rzh4uuDcH4Tp4FGgMjhO9jxz6xCZBtRwJxIrrDaITwbvzFzpLyIy3dS1GxemxWG6MBU5kgLngYY7XE3Giyl5JlZ0ZC3DCXe5qRMcKQuQMReWfRS23g6VT8H8cydXRGulsc3RSFkRkXDKdxrN1U09nhmX9FbT5qYkKxmrVY08o6o4B578JlQ+aW7DXdtuGHRD4VLzapDDFZ8G5/8YHv0S3H8t/Mc/wRYf2nO4GqG/U+NkRUQkIspyU3h8R+OMXIhitkffaqS2vY8bzphHmiPEnyckbD6zppR/b2/gl+v3cMHiwhl3PRkpde1GMvvcMIyUDbpoSSG/2biHP79Yw8dXFpORnGBMZ/niDv73/hd5fncLj12/Ckf8Qd8bx1wQM8brY+3/4Mdh65/glOvBOWtKv4+otesJsMZD2RlmVyIS87QMUySWONI0UlZEZAJ+/mwlL+1pM7uMUdUMjwwr1oW/mKAg3WhmaOz2QO9ww10UJ9w1uzyk2OMmP8Jj1VeNcQDrvwt+/+SOMZJwp4Y7EZFwKkgL/hvVb3IlkeX1DbG3o4/SHH02HFNmqZE0W/nU5P89D4WGbcZWDXfR58RPwPJPQe0meOLroT9+805jm6uGOxERCb/ynBQCAajSWNmI8vsD/HrDHpITbHzi1GKzy5EJsMfZ+P4lxzHg83PzP3cQGHPEqEzFSJBAdvga7uJsVv7rjHn0en3ctqn6wBvJ2WzuzsTrLMdRuNBYGB38kT1vjB/lo//IKhv9x9pvwZAXNv0kbL8/U3ldUPMClKwy+g5EZErUcCcSS+ypSrgTERknl2eQnz+7m188u9vsUkYVXAlWrJGyYoKDR8riagJrHCRlmVzV2Jp7vOSmTSLdLiitAJZfB8074N1/Te4YrZXgLIIENUKIiIRT/nAKa1O3x+RKImtvRx/+AEphOJqKc4zFAk3bzatBDXfR7dwfQMkaeO3PsOW20B675R1jm3dsaI8rIiIyivLcFEANd5H2xNtN7Gnp5dqVxaQnJZhdjkzQipJMrlhexOaqdv7xxn6zy5mW6oIjZTPDe+36gcWFzMtN4a+ba2nv9QIw5A9Q3eYe+f4YFvPOgtkr4I07obM2fOcxS9V6GBqA+SamxotMI2q4E4kl9jTwKOFORGQ8uvoGAXhzXxde35DJ1Ryutr0PiwWKwhi9LjKW7BQ7cVYLDV0eYzRWSj5Yo/fSoKXHQ16qY2oHOe1LkJACG74P/gl+T/APQftupduJiERA4cEprDNIdauxGEMNd0dRMTwavvIp82po2AaJGZBRbF4NMjZbPFz2VyMR8YlvQPXzoTt283DDXe7C0B1TRERkDMGGkj0tariLFL8/wK/W7yYx3sZ1p5WYXY5M0o3nLSQ7JYHvPraTDveA2eVMO3XtbpISbGSnhLch1Wa18KWzKugbGOIPLxgpd/s7+xnw+SnLCWPDncUC674F/kF4/sfhO49Zdj1hbIPX1iIyJdH7VE1EDqeEOxGRcevuNxruBnx+duzrNrmaw9W1uyl0JuKIt5ldisxANquFfKdjOOGuGVLzzC5pTP0DQ/R4fORNJeEOIDkbTv5PaKuEt+6f2Nd21YPPAznzp1aDiIgcVb5zZo6UrW4zGu5Kw/ngYDooOgkc6QceEkTa0CA0vWWk21ks5tQgR5eUCVfeayQT338ttFeF5rjNOyFtNiSmh+Z4IiIiR1CSnYzVooa7SHr23Wbea3Jx9UlzyEqZ4n0oMY0zKZ7//sAxdPYN8v3H3zW7nGmnrr2PuVnJWCJwPXTuonwW5Kdy58u1tLg8I4mfYW24AyhdA8WrYPvfoW1PeM8VSf4hY/Fa3nGQXmR2NSLTghruRGKJIw0GXOD3m12JiEjUCybcAWyp7TCxksMFAgFq2/qYq3GyYqJCZyLNXb3Q2wypBWaXM6YWl5FwlJs2xYQ7gFOuB4cTNv4AfBNY4dpWaWyVcCciEnbZyUYK60wbKVsznHBXqoS7I7PFGSN+Gt+EnsbIn//Nu40mfI2TjX458+HSP4GnG+650thOxdAgtO2CvEWhqU9EROQoHPE2ijKT1HAXIYFAgF+t30NCnJVPry41uxyZoguPL2R1RQ4Pvr6PzVVtZpczbQz4/DR09TM3QlN7rMMpd55BP7/bWHVQw10ErpvX3gwBPzz/w/CfK1L2boH+Dph/ntmViEwbargTiSX2VGM7oJQ7EZGj6eo/0EyztSa6Gu7a3QP0en3MzdIDVTFPQboDa38HBIYgNd/scsbU3OMFIDc1BCuLE9Nh5Q3QVQdv3jX+r2vdZWyVcCciEnZWq4W8NMeMGylb0+YmPSmejOTwjuWZFoKjb3Y/HblzBgLwwo/hkf8CZxEs+1jkzi2TV3E2nH2L0Sj30HVGosNkte+BoQHIOyZ09YmIiBxFeU4Kte1ufEMKYQi3jZWt7NjfzZXLi0Kz6FNMZbFY+N7Fx+KIt3LzP9/GMziFz4EyYl9nH/4AEQ0SOPuYPI6dlcbdr9bz0h6jebIsNwLJ8HNPgfIzYceDRtL1dLDrcWOrhjuRkFHDnUgssacZW42VFRE5qmDCXZzVwmt1nfj9AZMrOqCu3UgwKVbCnZioMD2RXEun8YuU6G24Cybc5YXqZudJn4WkbHj+xzA4zmaOtuGGu2w13ImIREKB0zHjEu6q29yUKN1ufMrPAIvNGIUTCUM+ePRLsP67xuidTz4D6XMic26ZulOuhyVXGw2az/6/yR+n+R1jm6uEOxERiZzy3BQGhwLUdfSZXcq0FggE+NVzu4m3WfjMmjKzy5EQKcpM4otnVlDT5ua3G6bRWFATBb8XRTJIwGKx8OWzKhjw+dmwqxVnYjxZkVqotvZmIAAbvx+Z84XbrieMSTcFS8yuRGTaUMOdSCwJNtx5esytQ0QkBnT3Gw13J5Vm4vL42NUcPc3KtW3GhWmxHqqKiQqdDnItXcYvYiDhLmQNd/YUWPVlcDXAa38e39e0VkJSFiRnhaYGERE5onyng3b3wIxJIejxDNLW66U0OwKr9KeDxAyYcwpUbxh/8/xkDbjhvmvg9b9A6Vr4+OOQVhDec0poWSzwgZ/B7BWw+Zfw5j2TO07LcKqFRsqKiEgEBVOcNFY2vDZXtfNGfRcfXlZEYXqi2eVICH3ytBIW5Kfyu+er2B1FzwdiVX17sOEuskECa+fnsqQoHTDGyVoslsiceNYJsOAD8O4j0LAtMucMl7Y90L7bSIy3qkVIJFT0t0kklgRHyirhTkTkqLr6jJGyZy3MA2BrbfSMla0dSbhTw52Yp8CZSF4w4S41eh8ct/QEE+5CMFI26MRPQmohbPoJeI9y0zoQMBLulG4nIhIxBU6jybpluOl6uqtpNT4blubos+G4VZwDg31Quyl853C3wR0fhMon4Pgr4ar7wZEWvvNJ+MTZ4fK7IG0WPHID7N0y8WM0vwPWeMieF/r6RERExlCuhruI+OVzu7FZLXzudKXbTTfxNis/+NBx+PwBbvrnjqiaghOLgs815mRGtuEumHIHMC83NaLn5vQbje2GGE+5q3zC2M4/39w6RKYZNdyJxJLgjV2vEu5ERI4mOFL2jOGGuy010dRwZ6wEi/SFqcjBCtMTySPYcBfNCXdGw11uaogS7gDiHbDma9DXBlv+cOR9e1vA0w05FaE7v4iIHFG+00iVaOzuN7mSyKhpMx5aaKTsBFSca2wrnwzP8Tuq4U9nwf7XYdVX4OLfQVyExhZJeKTmwZX3GOOI770auvdN7Oubd0LOfLDFh6c+ERGRUQQb7qrUcBc2W2o6eLWmg0uWzqJI92qnpaVzMviPk+eytbaT+17ba3Y5Ma2+vY94m8WUJMhV87L51ZVLuX5deWRPnH8sLPoQ7H56cgt3osWuJyA+CUpWm12JyLSihjuRWDKScKeGOxGRo+nuH8RmtTA7I5GKvBS21nYQCETHCra6djf5aQ4SE2xmlyIzWGF67IyUTXXEhf7vy5JrIH0uvPQL6O8ae7/W94ytEu5ERCKmcDjhrqknzONCo0R1q/EAVQl3E5A9DzJKoPIpI402lPa9DrefBZ21cMFP4Yz/McaSSuwrOB4u+R24W+Deq2Cgb3xf5+mG7nrIPSa89YmIiLxPmiOe3FQ7e1rVcBcuv1q/G6sFPr82wk08ElFfO2c+eWl2fvD4u7S4ZsZ1ZjjUdfRRlJGEzRr56yOLxcIHjy80pzH29BvBYoX13438uUOhrwPqX4aydcZCdBEJGTXcicQS+3DCnUcNdyIiR9PVP0h6YjwWi4XlxZk093jZ12l+SkogEKCmzU1xtlZMirmcifEU2LrwEQeJmWaXM6YWl4e8tDDcCIhLMG6WeLrh5d+MvV9bpbFVwp2ISMTkDzfcNXbPjAch1cMJd8VZargbN4sF5p8H3XuNUZ+hsutJuOMDMOCGy++G5Z8M3bElOiy6BNZ8Exq3w8P/Ob6GzZZ3jW2eGu5ERCTyynNTqGrpjZqFxNPJtvpONu1u44PHFypteppLdcTznQsX0ePxccuj75pdTkzy+wPUd/QxJ2sGPtfIqYDFV0DN81DzgtnVTNzupyHgN66hRSSk1HAnEkuCDXdel7l1iIjEgO6+QZxJxrifFSVGM1E0jJXt7BvE5fHpgaqYzmKxMMvWRbslA6zRe1nQ0uMlL80enoMv/ghkV8ArvwV32+j7tO4ytkq4ExGJmILgSNku8xdLREJNm5tZ6Yk44pV+PCEV5xjbUI2Vff2vcO+VEJ8IH30EFpwfmuNK9FnzDVh4Iex8GJ6/9ej7B5s6844Nb10iIiKjKM9NwT0wNGMWo0TSr9bvwWKB65VuNyOcsyifMxfm8cj2BjbuajG7nJjT1ONhwOefuc811nwdrHGw/nuhT1kPt12PAxaYd47ZlYhMO9H7ZE1EDucINtwp4U5E5Gi6+gdwJhoNd8uLjYa7rbXmN9zVthsJJnNn6oWpRJVcOmnyO6N2lbTb68Pl9ZGbGqaoe6sN1t4EA73w4s9G36dtF8Qng3N2eGoQEZHD5KTasVktM+KhYjD9WIkakzBnJSSkGmNlpyIQMB6aPPJfkD4HPvkMFC0PTY0SnaxWuOT3kH8cbPw+7PzXkfdv2WlsNVJWRERMUJ6bAsCeFo2VDaW393ez/r0Wzjs2n3l5qWaXIxFgsVj434sWkZxg41sPv03fgM/skmJK8LnGHDNGukaDzBJYeg3sfQWqnjO7mvHzeWHPc1C0AlJyzK5GZNpRw51ILLEPf+hXwp2IyFF19RkjZQEK0xOZlZ4YFQ13dcMXpiUaKStm8w/h9HfR6M+gu3/Q7GpG1eLyApAbroQ7gIUXQd5xsPV26Gk8/P3WSsieZ4yuExGRiLBZLeSm2mnqmf4Nd809XvoGhijNUcPdhMUlQPk62Ld17KTaoxkahIc/By/cCoVLjWa7rLLQ1inRKSEZrrgHknPgn5+FxrfG3rf5HXA4Ia0wcvWJiIgMK89Rw104/Gr9bgCuXzvP5EokkgrTE/nK2fPZ19nPL57bbXY5MaW+vQ+AuTNxpGzQ6q+BLQHWfzd2Uu5qXzQWm2ucrEhYqOFOJJYER8p6lHAnInIknsEhvD4/6UkJI68tL86gqtVNe6/XxMqgpi14YaqHqjIKT8+BkVXh5m7Fip/mQDoNXdHZ0NAy3GiRF66EOzASTtZ9C3we2PR/h77n6YbeJsjROFkRkUjLdzpmRMJddZvx4FQJd5NUcR4QgN1PT/xrvS74+0dg+99h3tnwsccgJTfkJUoUSy+Cy+8Gvw/uuRJ6RxktFghA805jnKwWYIiIiAlGEu5a1XAXKu819fDUO82cuTCPYwrTzC5HIuyjK4tZPNvJ7Ztq2Nmg563jVdeh5xo4Z8OJn4CGbcNjWmPArieMbYUa7kTCQQ13IrEkIRksVo2UFRE5iq4+I60rOFIWYHlJcKxspyk1BdWNjJSdwSvBZGwbvge/Wwlv3hP+c7mMNLfmQAaN3f3hP98kNA8n3OWlhbHhDqDiHJh1Irx+B3TWHXi9tdLYquFORCTiCpwO2nq9DPj8ZpcSVjVtwfTjGfzQYirmnQVYoPLJiX2dqwn+cj5UrYcTrjWSzhL0/2BGmnMSfODn0LMP7rvGGLl0sJ794O3WOFkRETFNTqqdVEecEu5C6Nfr9wBwwxnlJlciZrBZLXz/kuMAuPGfOxjyx0hSmcnq2t1YLFCUmWh2KeY67csQlwjrvwf+KL9fEQgYDXcZJbq/LRImargTiSUWizFWVg13IiJH1NU/AEB60oGGuxXFwYY7c8fK1rb3kZtqJykhztQ6JEq17DS2//oc7Px3eM/lagaglXQauqKz4S6YcBfWkbJgfMY647/BPwjP33rg9bZdxjZbNyRERCItPy2RQABaXNM75a661Wi4KxseFSYTlJwNs5fDnvXgGxjf17RWwu1nQdNbcPpN8MFfgk2fzWe0pVfDKdfD3lfh0S8fOh4qmD6dp4Y7ERExh8VioTw3hSo13IXEnpZeHtvRyJqKHBbPTje7HDHJsbOcfOLUYrbv7eKuV+qO/gVCXXsfBWkO7HE2s0sxV2oerPgUtLwDO/9pdjVH1rTDWFg0/3yldYuEiRruRGKNPc0YeyIiImMKJtylH5RwV5aTQnpSPK+Z3HBX1+6mWAkmMpbOWkibDck58OAnYM+z4TvXQQl3DVE6sq85EiNlg0rWQPEqY6xcm7HSmdbhhjutABQRibgCp/G9vylK/40KlZo2Nwk2K4XpMzwlYCrmnwsDLqh76ej71r8Cfz7bSC276Ddw+jf04EEMZ/0vlJ8Jb94Fr/z2wOsjDXfHmlOXiIgIUJ6TQrt7gE73OBcYyJh+u2EPgYDS7QS+eGYFs9IT+fFTu6b9dedUBQIB6tv7ZvY42YOd+kVISIENP4Ahn9nVjC04Tna+xsmKhIsa7kRijT0NPEq4ExE5kpGGu6SEkdesVgsnzs3k7YYe3F5zLoK6+gbo6hukWONkZTRDg9C9DwqXwH88DPYUuPcaqNscnvO5moDhkbLRmnA3PFI27Al3YDxsX/ffEPDDxu8br7VVgjXeiN0XEZGIKkg3Gu4ap/mDj5o2N3OzkrBZ1fQ1aRXnGtvKp468385/wx0XGkl4V90PS68Jf20SO6w2uPRPkDUPnv7WgYUvwQTq3IXm1SYiIjNeea6RhrynVSl3U1HX7uZf2xtYWZbFsrmZZpcjJku2x3HLxYvo9fr49r/fNrucqNbhHsDl9TFXzzUMyVlw8uegfTfseMDsasZW+QQ40mHOyWZXIjJtqeFOJNbYU5VwJyJyFD39RsOd86CRsgArSjIY8gfYVt9lRlnUtvcBaCWYjK57r9HslVFsjKy65iHjwd/dH4H9b4T+fMMJdwOOHBq6orOZobnHgzMxHkd8hEYVzDkJ5p0Nbz8ETW8bCXdZZRozJyJigpmQcDfg81Pf0Udpjj4bTknuMeAsMh4mHDwK9GCv/gHuvxYcTvj4YzDvzMjWKLEhMR2uus9Y7PrAJ4zxw83vQPoc436ciIiISUYa7jRWdkp+u6GKIX+AL6ybZ3YpEiXWLcjjguMKeOqdZp5+p8nscqJWXYeeaxzmlM8b15cbf2AspI82PQ3QsA3mnQW2+KPvLyKTooY7kVjjSAOvEu5ERI6kq98Yr3DwSFmA5cXGysWtJo2VrWt3A1CsC1MZTWetsc0oNrazlhkP/PyDcNel0PJuaM/X2wzWeBKduTR0R2nCXY+XvEik2x1s7c3G9tlvQ1cdZFdE9vwiIgJAvtMYsRqt/0aFwt7OPob8AUqyU8wuJbZZLFBxjvFZqm33oe/5/fD0f8MTXzea6K97BgqXmlKmxIisMrjsrzDQC/dcbiQea5ysiIiY7JjCNABe3NNmciWxa19nHw+9sY/lxRmcXKp0Ozng2x88hlRHHN/+9zv0mjQZJ9rVjwQJKOFuRGI6rLzBuH+87S6zqzlc5ZPGVuNkRcJKDXciscaeCj6PMQJFRERGNdpIWYBFhU4c8VbTGu5q2oYb7rJ1YSqjGGm4O2h8afFpcPndRrrtnRdBe1XozudqhNQCCjOSaO7xMOQfIxHGRM09HnJTHZE9aeESWHihMUYs4Iec+ZE9v4iIAJCbasdimd4JdzWtxmfD0mwtxpiyiuGHCJVPHHjN54V/fAo2/xJmr4BPPH1gYYPIkZSthXN/AB3V4PcZKYoiIiImKnAmclJJJs/sbKa7LwqTlMYpEAgQGCuROMx+/3wVvuF0O4vFYkoNEp1y0xx849wFNHZ7+L+ndpldTlSqHQ4SmJOp5xqHOOmzkJQFL/wYBqPs3sWuJ8AaB+VKdxcJJzXcicQau7GSSWNlRUTG1hUcKfu+hLuEOCtLizLYVt/F4JA/4nXVaaSsHMn7E+6C5p0Jl94O7la482Lo3h+a87maIDWPwnQHg0MB2nq9oTluiPR6fbgHhsiNdMIdwNqbgOGbr9lquBMRMUO8zUpOip3G6dxwN7wYo0QjZaeu+DSIT4LKp4xf93cZCcFvPwgLPgAf/TckZ5lbo8SWFZ+GEz5q/FypiCIiEgUuO7GIAZ+ff28P0X0hE/z0mUoWffspbnl0Z0QX1jR1e7h/6z6OL0pn1bzsiJ1XYsdVK+awbG4Gd7xcy/a9XWaXE3WUcDcGewqc9iXo2Q9v3GF2NQd4e6H6eeM62eE0uxqRaU0NdyKxxp5qbDVWVkRkTMGVnmmOuMPeW16SSf/gEG/v7450WdS2u8lOsZNiP7wuEaPhzgLpRYe/t+hiuPDX0F1vJN31tk7tXEM+o4EvNZ+C4Mi+ruga2dfSY9x4zUuLcMIdQO5CWPwR4+d5iyJ/fhERAaDA6ZjWCXfVbb2AEu5CIt4BpWuh/hVofgf+ch7UbjKapj5yJ8Qnml2hxBqLBS74KXzsMY1hEhGRqHD+cfkkJ9h44PV9ZpcyKZ7BIe7YXItncIg/vVjDqlvX882H3hpZhBJOf3ihioEhPzesK1e6nYzKarXw/UuOw2axcOM/duAzYbF+NKvr6CMrOYFUR/zRd55pTvwkpOTDC/8HA31mV2Oo3gBDXph/vtmViEx7argTiTUOJdyJiBxNV/8AqY444myHf9RZUZwJwGu1nZEui7r2Poq1CkzG0lkLabMgboxEt6VXw3k/hvbd8LdLoH8Kf4bdrca41NQCCtONhraGruhqaGjuMRL38lJNSLgD4wHrNQ9BnkaIiYiYJd/poMXlmbYPO6pb3aQ54shMTjC7lOmh4hwIDMEf10LLTjjzO3DerWC1mV2ZxCpbnJEKoT9DIiISBZIS4rhgcQFv7etmV1PsPR96fEcjPR4fN19wDH/+2IkcPzude7fu5YyfbOTzf3+DdxrCszi61eXl76/Ws6gwjXULcsNyDpke5uen8pk1pexs7OEvL9WaXU5UqWt3M0fPNUaXkASrvwruFth6m9nVgN8P2+81fl5xrrm1iMwAargTiTUjI2WVcCciMpauvkHSk0ZfbbV0Tjo2q4UttR0Rram7f5AO9wDFSjCRsXTWHj5O9v1O+jSc8T/QvAPuvsyIh58MV6OxTc2nMN1IfGnsjrKEO5fRAJhrRsIdGCMBys8059wiIgJAgTMRfwBao2zseajUtLkpyUlRykaoVJxjbAN++NDtcNoXjZQyERERkWnishONqQgPvLbX5Eom7t4te0mIs3LpCbNYtyCPB/9zJfd/5hRWV+Tw2FuNXPDLF/nYX7awpSa092xv31SN1+fnC0q3k3H4wrp5FGcl8dNnKtnbESVpZSbr9fpo6x2gOEvPNeh3Jo8AACAASURBVMZ0wrWQNhte/Lm5gTleF9x3Nbz3KJSdARlzzatFZIZQw51IrLEr4U5E5Gi6+gZJTxw9KSTZHseiwjReq+3A7w9ErKa6dmM8ghLuZFT9neDphszio++76itw2pdg31a490oYnEQyXW+zsU3Jp8AZrQl3wZGyJiXciYiI6fKH/41qnIZjZV2eQVpcXsq0GCN0UvPhir/DJ5+CxZeZXY2IiIhIyJ04N4OS7GQefnM/gzGUAr2npZcttR2cuyif9KQD92xXlGTy14+v4NEvnMYFiwt4vrKVj/zhZS77/WY2vNdCIDC1e7cd7gH+9kod8/NSOfuY/Kn+NmQGcMTb+O7Fx9E/OMT//OvtKf8ZnA7q243GwzmZeq4xpjg7rPk69HfAK783p4aOGrj9LNj1OCy+HK6425w6RGYYNdyJxBp7qrH1KOFORGQs3f1jJ9wBLC/OpLNvkKrWSaaDTULt8IXpXK0Ek9F01hrboyXcBZ3xbVj+Kah5AR74GAwNTux8ByXc5aU5sFqgoSvKEu6GR8rmppqUcCciIqYLNoU3TcOGu9o247NhiRruQmvBBTBrmdlViIiIiISFxWLhw8tm09Y7wIb3WswuZ9zuH07ku2JF0ajvHzvLyW+uOoHnvryGy08s4s29XXz8r1s5/5cv8u/tDQxNctH0n1+soW9giM+vK8dqVbqdjM9p87K5ZOksNuxq5bEdjWaXY7pgkMBcBQkc2ZKrIKMENv/KWFwfSTUvwG1rofU9OOt/4ZI/QHxiZGsQmaHUcCcSa4INdxopKyIyqsEhP71eH87EIzfcAWytjdyFT12bcWGqh6oyqpGGu5Lx7W+xwHm3wvFXQuUT8M/PgH9o/OdzNRnb1ALibVZyUx1RN1K22TXccKeEOxGRGavAGRx7Pv0a7qrbjIUfJTn6bCgiIiIi4/ehE2ZhtcADr+8zu5RxGfD5eej1fRRnJXFKadYR9y3NSeFHH17MC19fyydOLaG2zc0N92zjjJ9s5J4t9Xh947/31d0/yB2baynNSeaC4wqm+tuQGeZbFywkPSme7zyyk+7+CS50nmbqOhQkMC62eDj9RvB2w+ZfR+acgQBsuQ3uvNh4NnDV/XDqfxnPDkQkItRwJxJrHMGRsmq4ExEZTc/wBfCREu5OLM4AYGttR0RqAqgZXgk2RyvBZDQTTbgDsFrhwl/Dwg/C2w/Bo180LrLH46CEO4CCdAcNUdbM0NzjIT0pHnuczexSRETEJMGEu8YoS2ENhRotxhARERGRSShwJnLavBw2vNdCW6/X7HKO6pmdzbS7B7h8+Rws42wCKXAm8j8fPIaXvrmOG86YR4d7gBv/sYPVt27g9k3VuL2+ox7jry/V4vL6+Pzp5diUbicTlJVi56bzF9Lq8vKjJ98zuxxT1Y1M7tFzjaM67sOQPR9e+R2428J7Lt8APPolePyrkDEXrnsWKs4O7zlF5DBquBOJNfZgw53L3DpERKJUV7DhLjFhzH2yU+yU5iSzpSZyDXd17X1kJSeQ5hi7EVBmsMk03AHY4uDSP0HZGfDGnfDUzeNrunM1gy0BEo3m08L0RFpd3gmtFA63lh4PeRonKyIyowVTTht7oqspPBSqW9VwJyIiIiKTc9my2fj8AR7ett/sUo7q3q31xFmNUbgTlZmcwJfPqmDzjWdw0/kLCATgu4+9y6k/Ws/Pnqmk0z0w6te5PIP8+aUa5mQmcdGSwqn+FmSGumzZbE4uzeTvr9bztQe287NnKvn7q/U8924zb+/vpsXlmfS441hS1+4mOcFGVvLYz1tkmNUGa2+EQTe8+LPwncfdBn+7BF7/C5SeDtc9Bznzw3c+ERlTnNkFiMgEBRvuPEq4ExEZTVff0RPuAFYUZ3Lv1r00dPVTmJ4Y9rrq2t1aBSZj66yFhBRIOvJojVHF2eHyu+CuS+GV3xjj59feeOSvcTUa6XbDK4sLhxOEmru9UZHCGAgEaHF5WTY3w+xSRETERPY4G9kpCTRFWQprKNS0uSlwOkhK0K05EREREZmYs47JI80RxwOv7eOTp5WMOzku0vZ29LFpdxvnLsonJ9U+6eOk2OP49Ooyrj2lmH+8sZ/fP1/FL57bzW2bqrlqxRyuW1VKvvPAos2/vVJHd/8gN563gDibsmdkciwWC9+/5Diuvv3VMUc426wWclLs5KXZyU1zkJdmJy/VQV6ag9w0O3lpxs8zkuKj9u/p0dS19zE3Kzlm64+4hRdB3nGw9XZY+YWRCTMh0/Q23HsldNXDSZ+Fs79nLMoXEVPob59IrLGnGlsl3ImIjKq731jZmJZ45Ia75cMNd1trO7hoyayw1uTyDNLWO8DqipywnkdiWEeNkW432RsXCUlw1X1w54Xw/A/BnmJc0I/F1QSZJSO/DDad7u/qj4qGu16vj76BIfLSlHAnIjLT5Tsd067hLhAIUNPmZvFsp9mliIiIiEgMcsTbuHBJIXe9Us+O/d0snp1udkmjum/rXgAuX1EUkuM54m1cddIcPnLibB7b0cjvNlZx+4s13PlyHZcum8VnVpeRm2bn9k01zEpP5EMnTDxVT+RgpTkpbP7mOrr7B2nu8dLc46G5x0OL68DPm3u8tPR4eKehB98YiXfxNgu5qcNNeKmOgxr0jJ8XZyVTlGn+Pdn38/qGaOzu17XrRFitsO5muOcK2PQTOP/HoTv2u4/APz4DQwPwwV/Cso+G7tgiMilquBOJNfEOYwScVwl3IiKjGUm4G0fDHRCRhru69j4AirM0MkxGMTQI3ftg/nlTO44jDa75B/zlfHj6W0Zi3okfH+V8PnC3wpyTR14qcBoNd43d/VOrIUSae7wA5KVNfvWziIhMD/lpibzX6GLIH8BmnR4r6ltdXnq9Pkpz9NlQRERERCbnsmVF3PVKPQ+8ti8qG+58Q34eeH0vs9ITWT0vtIuQ42xWLloyiwuPL2T9ey38dmMV92zZy31b97IgP40O9wC3XLSIhDil28nUWSwW0pMSSE9KYH5+6pj7+f0BOvoGjIa8keY8L80uDy3DP9/f2c/2vV2M1pf37+tPjbq/y/s6+/EHiIoF2jGl4lyYtQxe+4uxKD59ztSOFwjACz+GDd+DpGy45iGYe0poahWRKVHDnUgssqcq4U5EZAwHRsomHHG/osxE8tLsbK3pDHtNte1uAI2UldF174PAkJFwN1VJmXDtw/Dnc+HRLxmfGY778KH7uFuAAKQWjLxUmG4kyTVGSYJQS49RR26qEu5ERGa6AqcDnz9Ae6+X3GmSfFrdZnw2LMlOMbkSEREREYlVi2c7qchL4V9v7ufmCxbiiLeZXdIhNu5qpbnHyxfPnBe2hTMWi4UzFuaxbkEuW2o6+M3GKl6obCUvzc5lJ4YmVU9kvKxWC9kpdrJT7CwqHHs/35CfdvfASEPeW/u6+NX6PWza3RZ1DXf1ChKYHIsF1n0L/naJ0Sh34a8mf6wBNzz8Odj5sDGq9sp7IF3f30SihVr7RWKRPQ08SrgTERlNV3+w4e7ICXcWi4XlxZnsanbR1TcQ1pqUcCdH1FlrbEPRcAeQmg/X/gvSCuEfn4b3Hj/0fVfjgf2GHTxSNhq0uJRwJyIihoIoawoPhZrhhrvSbH02FBEREZHJsVgsXLasiB6Pj2d2NptdzmHu3VqP1QIfiUDjm8Vi4aTSLO78xAqe/tJqHvzsyqhrQBQJirNZyUtzsHh2Omcdk8fn15aTYLOytbbD7NIOUxcMEojCcbdRr3QtzFkJ2+6G9qrJHaNrr7GwfufDsPBC+ORTarYTiTJquBOJRfZUjZQVERlD93Dz3NFGygKsKDHGyr5eF96Uu+BDVTXcyahC3XAHkDHXaLpLzIAHPgpVGw6852oytgc13GUlJ5AQZ6UxShrumoMJd9MkyUhERCavwDl9G+5K1HAnIiIiIlNw8dJZ2KwWHnh9n9mlHKKp28P691pYU5EzssgzUiryUilSc5DEEEe8jcWznbxe28nQaLNmTVQ7HCSgkbKTEEy5CwzB87dO/OvrX4Hb1kLTW3D6TXDZHZCgewgi0UYNdyKxyOFUw52IyBiCCXdp42i4O3Gu0XC3Jcyrx+ra3WQkxeM8SuqezFDhaLgDyJ5njJeNT4R7r4L6V43XR2m4s1gsFDgdUdPM0NwTTLhTw52IyEyXn2Y8oGvqjo6m8FCobu0l3mZhdkZkHz6KiIiIyPSSk2pn7fxcNu1upTGKPi8/8Npe/AG4YsUcs0sRiQnLSzJxeX3sanKZXcoh6jv6SLBZKXDq2nVSik81ku7eug9a3hv/173xN/jrB4xxsh+5E07/BljV1iMSjfQ3UyQW2VPB64JAdK10EBGJBl19gyTG28Y1NmB+fiqpjji21oS34a62vY+5SreTsXTWAhZwhiEOPv84uPpB4/h3XwaN2w9quCs4ZNdCZ2LUjJRtdhmNfzkpGikrIjLTTceEu+o2N3Myk4iz6baciIiIiEzNZSfOJhCAf7yx3+xSAPD7A9z32l5yUu2sW5BrdjkiMWF5cQZA1I2VrWt3MzszEZvVYnYpsWvdt4AAbPzB0fcd8sGTN8K/rzcWy3/yaTjmorCXKCKTpzt7IrHIngZ+HwxGx0NxEZFo0t0/SPo4k+RsVgsnzs1gx/5uPINDYanH7fXR6vJqZJiMrbMW0gohPkxpbkUr4Mp7wOeBv10C9S8brx+UcAdQkO7A5fHR6/WFp44JaOnxkDk85lZERGa2/GnWcOcb8lPf3kdJdorZpYiIiIjINLBuQS5ZyQk88NpeAlEQ0vBSVRv7Ovv58LLZxGuBici4LJuTicUSXQ13Q/4Aezv6masRzVMz+0SoOBd2PgyNb429X38n3P1heOW3MGclfGqDsZheRKKaPumIxCJ7qrH1Rle0sIhINOjuH8Q5jnGyQctLMhkcCvDm3q6w1FPb7gZgbpYuTGUMnbWhHyf7fqVr4CN3gKcbajeBzQ6O9EN2KRweDdAYBSl3LS4vualKtxMREXDE28hIiqdpmjTc7e3sx+cPUJajxRgiIiIiMnXxNisXL51FbXsfr9V1ml0O927ZC8AVy8MwyUFkmnImxTM/L5WttR1R0TgL0NTjYWDIr8k9obD2JmM7Vspd6y64bR1Ub4ATPgrX/gtSciJXn4hMmhruRGKRI83YenvMrUNEJAp19Q2MO+EOYHlxJkDYxsrWtfcBUKwLUxlNfyd4usLfcAcw/zy45A+AxUjUsxw6CqAw3Wi4M3usbCAQoLnHQ15amBL/REQk5uQ7E2nsMb8hPBRq2noBlH4sIiIiIiFz2YmzAXjgtb2m1tHe6+XpnU2sLMtSk47IBC0vzqS5x8u+zui49q1TkEDoFBxvjIbd9Tjse/3Q9yqfhtvPhM46OO/H8MFfQFyCOXWKyISp4U4kFo0k3KnhTkTkYH5/YMIJd4tnO0mIs7IlTHHtSriTI+qsM7YZJZE533EfhqsfgA/89LC3CtKjY2Rfj8eHZ9CvhDsRERlR4HTQ3O3F74+Olf5TUd1qfDZUw52IiIiIhMqC/DSOm+Xksbca6RvwmVbHQ2/sY3AowBUr5phWg0isOrE4A4AtYQoGmKhgkICea4TI6TcBFtjwXePXgQC89Ev4+0fAYoX/+Aec9OnDFsmLSHRTw51ILLIPJ9x51HAnInIwl9eHPwDpieNfAWSPs7Fkdjpv1HXiG/KHvKbaNj1UlSPorDW2kUi4C5p3FpStO+zlWf+fvTsNkvSw7/v+e/runuljjp2Znt2d6VmA4AkQx85KJGzRlGhJNm1LIgERisRISBTbFblUilKppMqVSl6kKpWUo1dm5ZUFmbJJUCBNSrFE23KoiCJIaXcBLAjwJnZ6Znfn7ulr+j6evHi6B1hgZneOp/vpfvr7qUI91GzP8/zFIraP59e/f6fhbt3hhrvtghX4o+EOANA1Fw+p3mprr1x3epQzu9l5bXjp3LjDkwAAAMBNnr58QaV6S199bdOR65umqeev3dJExK+fe/+sIzMAw+zKkrWJ5/rqoAXuuK9hi5n3SI/8svTG16x/vvxPpT//n6Vz75b+8V9Il/6O0xMCOAUCd8Aw6gbuakVn5wCAAZMvNyTpRCtlJWl5aUKlekvf37T/79V0pqx42K9EhBpwHMKJwN0RknEr4Laec7bhbrtYkyTNxmi4AwBY5jvPUZsOt7DaYWWnpGjQp+lxXhsCAADAPv/og/MKeD164SVn1speXdnTzZ2SPvH4BQV9XkdmAIZZMh7W+UR4YBru1vZKMgzpwkTY6VHc4yP/o2R4pX/zlPTt56WHfl76r/9cmrzk9GQATonAHTCMQgTuAOAwuYrVehI/YeDucsr69lgv3syuZkpKUbuOowxQ4C4a8isa9Gkj72zD3Van4W6GhjsAQMdc3PqA3+m153ZY2S1p6dyYDNbEAAAAwEaJSEB/9/2z+uube1rrNFP10xeuWUG/Z5Yv9v3agFtcWZrUGzslZfZrTo+i9G5Z8/EwAVo7TT0gPf5pyWxJf+u/k5753Jv3/AEMJQJ3wDAKRq1jjZWyAPBWuW7D3QlWykrSE4sTMgzpWtrewF253tRWoUbtOo6WTUv+MWls2ulJJEnzibDjK2W3Ct2GOwJ3AABL8qDhztnnqLMq1ZraLFS1NM1rQwAAANjv6ScuSJK++PLtvl43X27oT1/b0BOLE3rXbLSv1wbc5HJqQpJ0fTXr6BymaWptr6xFigTs9/f/hfTPXpI+9r9KHsKMwLAjcAcMI1bKAsChcpXTrZSNhfx671xM19J7Mk3TtnlWO98mTXFTFUfJpq12uwFpuUkmQtrIV2399+CkDhruoqyUBQBY5rprz4e84W5ltyRJujQ97vAkAAAAcKO//a5zmouF9KWXbqvd7t9nO1+5cUe1Zpt2O+CMrnQ28Vy3uRjgpPZKde3XmgTuesHrl6YfdHoKADYhcAcMo27DXTXv7BwAMGDyZWulbCJ8ssCdZNW17+7XlbZx5cJqxrqpykpZHKrVlPK3BmKdbFcyHlat2dZeqe7YDDtFq+HuHIE7AEDHXKzbcOeOwN3SOb6MAQAAAPt5PYY+8fh53clV9K2bmb5c0zRNff7qmqJBnz7+SLIv1wTc6oFz40pE/LqadrbhrnuPZGGS964AcC8E7oBhFKLhDgAOk+803MVP2HAnvVnXfm3Fvm+Pdd+YslIWhyrcltrNgQrcnU90GoRyzgUatgpVTY8H5PfyVgUAYBkL+hQL+bQx5Ctl32y447UhAAAAeuOpzlrZF67f6sv1Xr2d1/c3i/qFx+YVCfj6ck3ArTweQ5cXJ/WdO3mV603H5ljbo0gAAI6Du1jAMAp0Gu5qBWfnAIABkyt3V8oGTvy73br2qzbWtXcb7pa4qYrDZNPWcYACd8l4WJK07mCgYatY1Uw05Nj1AQCDKRkPD33D3c2dfUm8NgQAAEDvXDo3rsuLE/rq65sqVBs9v97zV9ckSc8sL/T8WsAoWE5NqNk2dWMt59gMq92GOwJ3AHBPBO6AYeT1Sf4IDXcA8Da5TsPdaVbKzsRCWpyK6JqNgbuV3ZKiIZ8mTtG4hxEwgIG7+UQncJdzJnBnmqa2CjXNxFgnCwC421w8pI18VaZpOj3Kqa3sljQbC2osSPMHAAAAeufpyxdUa7b171/d6Ol19mtN/cmr63r4fFwfOB/v6bWAUbG8ZBUDXHNwrewqm3sA4FgI3AHDKhiTqjTcAcBb5coN+TyGIgHvqX5/OTWp1UxZ2wV72lNWM2WlpsZkGIYt54PLDGTgzmqW23CoQShfaajebGuWhjsAwNvMJ0KqNdsHjcbDxjRN3dwt0W4HAACAnvv4I/MK+7164aXerpX996+uq1xv6VPLF3t6HWCUfGA+rpDfY2sxwEmtZkqaHg9onC+LAcA9EbgDhlUwSsMdALxNvlJXIuI/dcBtOTUhyZ5vj1UbLW3kq1qkdh1H6QbuEoOzcmMubgXdnGq42y7WJEmzNNwBAN5mLma1sDoVCj+rTKmuYrWppelxp0cBAACAy40Hffp7D8/plbWcfrzdu/tIn792S2G/V7/w6HzPrgGMmoDPo0cvJvTyWlbNVtuRGdb2ylqY5L4GANwPgTtgWIViUo2GOwB4q1y5ofgp1sl2Lae6de1n//ZYt3adFhMcKZuWovOSf3Da3II+r6bHg44F7rY67ZIzscH57wQAMBiSnVD4ZsGZ56izurlTkiQ9cI7XhgAAAOi9p5+wWudeeOl2T87/vY2CXr2V0z94JKlo6PSfxwJ4p+XUpMr1lr670f/7wPu1pnb360qxThYA7ovAHTCsaLgDgHfIVRpKRAKn/v2l6TFNjwd0deXsgbt0xrqpusgbUxwlmx6odbJd84mQY+1BW4Vuwx2BOwDA3botrMPacLeyuy+JL2MAAACgP35iaVIXJ8P6dy/f6UlL1vNX1yRJz1wZnM0NgFt0iwHsuE9xUqud+xoLbO4BgPsicAcMq2DMCty1nakTBoBBY5qm8uWGEmdouDMMQ8upSX1/s6BCtXGmebpvTFO8McVhKjmpkh3IwF0yHtJWoerIyoKDhrsoK2UBAHfrNtxt5IYzcHdz13ptSOAOAAAA/eDxGHrq8YvaKdb09R/t2HruaqOlL79yRw/NjuvxhYSt5wYgPbaQkMeQrqezfb/2WmdzzyL3NQDgvgjcAcMqGJNkSvV9pycBgIFQabRUb7UVj5xthcHl1KTapvTy6tnezKYP3phyUxWHyK1axwEM3M0nwmqb0lax1vdr7xRpuAMAHG7YG+5u7pTk8xi6OMlNCwAAAPTHJ584L8OQXrhu71rZP3ttQ4VqU88sL8gwDFvPDUCKhvx633xM19J7Mk2zr9fmvgYAHB+BO2BYhWLWsVZwdg4AGBC5stVIlwiffqWsJF3p1LVfS5+trj29W9J40Kfp8bPNA5fKpq3j5JKjYxxmPh6WJG3kKn2/9lahKsMQ/94AAN4hGvJrPOjTZqH/z092WNktaWEyIr+Xj+IAAADQHxcmIvrwA1P6z9/b0l6pbtt5n792SwGvR7/02HnbzgngbpcXJ5Up1bXSaUvvl7U963qLfFkMAO6LT/mAYRWMWsda0dk5AGBAHATuzthw995kVGMBr66tnK3hbjVT1uJUhG954nDdwN0ANtwlE1aD0LoDDUJbhaqmx4PyEUYAABxiLh4ayoa7VtvUaqbEOlkAAAD03dNPXFSjZeqPb9yx5Xxv7Ozr6sqefv4Dc5oY4wuTQK9cWbKnGOCkVjNljQd9muTfbwC4L+5kAcMq2Gm4q9JwBwCSlK/YE7jzeT16fHFCN27nVGu2TnWOaqOl9XxFKWrXcZQBDtzNJ6yGu3VHGu5qmokG+35dAMBwSMZD2sxX+75S56zuZCtqtExdOsdrQwAAAPTXz71/TtGgz7a1sl+4dkuS9MyVi7acD8DhLqcmJEnX0mcrBjgpigQA4PgI3AHDioY7ALhLvmKtRYiHzxa4k6Tl1KTqzbZeu50/1e/fzpZlmtLiFLXrOEI2Lfkj0tg5pyd5B6dWypqmqZ1iTbOxUF+vCwAYHsl4SOV6S4Vq0+lRTuSN3X1J0tL0uMOTAAAAYNSEA179gw8m9d2Ngr6zfrrPOrvqzba+9NJtpaYi+tClKZsmBHCYmWhIqalIXxvuak2rSID7GgBwPATugGEV6jTc1c72BgkA3KK7UtauwJ0kXT3lm9mV3bIkKcXaMBwlm7ba7Qbwm4LnokH5PIbu5Pq7si9Xbqjeams2RsMdAOBwc51Q+OaQrZVd2SlJEitlAQAA4IinnrDa6M7acvfn391SplTXp5YXaL8C+uByalKrmbK2C/15D3w7W5FpSguTvHcFgOMgcAcMKxruAOAuuYOVsoEzn+uxhYT8XkPXVk4XuFvNWDdVWSmLQ7VbUm5tINfJSpLXY2g2FtJGvr8Nd1tF64OjmSgNdwCAwyXj1nNEv5+jzmpl13ptyEpZAAAAOOHxhYQunRvTH9+4o3qzferzPH9tTT6PoU8+cd7G6QAc5UqnGKBfa2XfvK9Bwx0AHAeBO2BYBePWsVpwdg4AGBDdhruEDQ13Ib9XD5+P6/pqVu22eeLfT/PGFPeSvy21mwMbuJOk+URIG31uD9oq1CRJMzTcAQCOMNcJ3A1bw93N3X2NBbyaifIcBwAAgP4zDENPP3FR2XJD/+/3tk51jlt7Zf3Vj3b1M++d4cuSQJ9cTk1IUt/Wyq5mrM09C9zXAIBjIXAHDCsa7gDgLvlKXZKUiJw9cCdZa2WL1aZ+sHXyv2fTu2VFAl6d46YqDpNNW8eBDtyFtVeqq1Jv9e2aW53VCLN8aAsAOEK34W59yAJ3KzslLZ0bY+0WAAAAHPOJx8/LY0gvvHS6tbJ/dP2WJOmZKwt2jgXgHpamxzQ9Huh74G6RzT0AcCwE7oBhFYpZRwJ3ACDJargzDCkasi9wJ53u22PpTEmLU9xUxRGGIHCXjIcl9Xdl307RaribjRG4AwAcLhmznp82h2ilbKXe0nq+qqXpcadHAQAAwAibjYX0kYfO6S9/uKPtwsm+wNJstfVH12/pfCKsn3rXuR5NCODtDMPQ5cVJfW+joGK10fPrrWZKCvg8SvL5LAAcC4E7YFgdNNyxUhYAJCtwFwv55fXYE3Lr1rVfXTlZ4K7WbGk9V2GdLI42BIG7+YT1oUo/18oeNNyxUhYAcIRY2Kew39v3tednsbJbkiRdmqYhAAAAAM56+vJFtdqmvvzKnRP93v/3gx1tFWp6+vIF2z57BXA8y0uTapvSy2u5nl9rda+sixNhefj3HACOhcAdMKwC45IMAncA0JGrNGxbJytJiUhA756N6lp6T6ZpHvv3bmcrapvUruMeuoG7xOCu4JjvNNzdyfWvQWirUJXHkKbGCdwBAA5nGIaS8ZA2hzFwd47XhgAAAHDWz7x3RomIXy+8dPtEn3c+f21NHkP65csXezgdgMMsLJAgBwAAIABJREFUd4oBrvd4rWyrber2XoX7GgBwAgTugGFlGFIwJlUJ3AGAJOXLdSXC9gXuJKvlbqtQ0+3s8UNH6c5N1aVpGu5whGxaiiYlf9jpSY6U7Dbc5frZcFfT9HiQb0oDAO4pmRi2wN2+JGmJhjsAAAA4LOjz6hcfPa8fb+/rxq3jtWVt5qv62ve39ZGHzmk+MbifZQFu9b5kTJGA98SbeE5qI19RvdXWIpt7AODYCNwBwywUk2pFp6cAgIGQrzQUjwRsPeeVpUlJJ1srm86UJdFwh3vIpgd6nawkne98gLqR71/D3U6xptlYqG/XAwAMp7lYWMVaU8Vqw+lRjuXmwZcxeG0IAAAA5z31xAVJ0gsv3T7W47/40i21TemZK4O7qQFwM5/Xo8cXJnTjVk71Zrtn11nr3teYJHAHAMdF4A4YZsEoK2UBQFK92Vap3rK94W45ZQXurp2grn01Y91UTRG4w2GqeamyN/CBu3jYr7Df27eVsu22qe1iVbMx1skCAO4tGbfC2VuF4Wi5u7lT0rloUNGQva9TAQAAgNP4wPm43puM6f95dV3VRuuej223TX3h+i1Njwf10++Z6dOEAN5uOTWpWrOt1+7ke3YNigQA4OQI3AHDLEjDHQBIVrudZIWE7DSfCOt8InyiwF06U1bI79FMlOAQDpFdtY4DHrgzDEPJREgbfVrZly3X1WiZmqHhDgBwH3OdwF2/nqPOwjRN3dzZp90OAAAAA+XpJy6oWG3qP35n856Pe/GNXd3aq+jpyxfk93JLGXDKcmpCknT9BPcpTmp1zyoSYKUsABwfr46AYRaMSlUa7gAgX6lLkhIR+5tDllMTemOnpMx+7ViPT++WlJoak8dj2D4LXCCbto4DHriTrLWy67mKTNPs+bW2Cta/XwRVAQD3kxyiwF223FCh2tQlAncAAAAYIL/42Hn5vYZeuH7vtbLPX70lSXpm+WI/xgJwhEcXEvJ5jBMVA5zUWqYsjyFdmCBwBwDHReAOGGbBqNSsSK2G05MAgKNy5d403EnS8lJ3rWz2vo+tN9u6nS3zLTAc7SBwt+ToGMeRjIdUrrdUqDR7fq3tohWamKXhDgBwHwcNd7nBD9zd3NmXJF06R+AOAAAAg2NyLKCfec+sXnxjV3dylUMfk9mv6T99d1MffmCKFZOAwyIBn95/Pq7rq1m12735cnQ6U1YyHlbAR3wEAI6LvzGBYRaKWUfWygIYcd3AXSISsP3cV1LdwN39vz12J1dR25RSfAiFowxRw10yHpYkrecP/+DVTtudhrvZGA13AIB76z4/bRZ6//x0Vjd3rZU8S9PjDk8CAAAA3O3pyxdkmtKXXjq85e5LL99Wo2XqmSsLfZ4MwGGupCaUKzf0484Xu+xkmqbWMiWlpikSAICTIHAHDLNg1DrWWCsLYLTlKp3AXQ8a7h6cGddExK/rxwjcpTs3VVOsDcNRsmnJF5bGZ5ye5L7OJzqBuyO+6WynrYLVUjQTpeEOAHBvExG/Aj7PUKyUXTkI3PHaEAAAAIPlIw+d07loUF986fY7GrNM09Tz124pEfHr594/69CEAN7q8gmKAU4qU6qrVG9pYZL3rgBwEgTugGEWjFvHKoE7AKMtV65LkhIR+wN3hmHoicVJvb5eUKl279Wa6Yx1U5WVsjhSNm212xmG05PcVzJhhd/W+xBo2OqslJ2h4Q4AcB+GYSgZD2lzGAJ3OyV5PYYWJnltCAAAgMHi83r0icfOa22vrKtvC/BcS2d1c6ekTzx2QUGf16EJAbzV5cUJSdK1FfsDd6vc1wCAUyFwBwyzg4Y7VsoCGG35bsNdDwJ3knRlaUKttqlX1nL3fNxqpiyJlbI4Qrsl5daGYp2s9ObKvo2+NNzV5PUYmhojcAcAuL9kPDQUDXc3d/d1cSKsgI+P3wAAADB4nr58QZL0wvW718o+f3VNkvQrVy72fSYAh5saD+qBc2O6ls7afu4372sQuAOAk+ATP2CYhWLWkZWyAEZcrmwF7uLhQE/Ov9ypa3/7tz3fLp0pKejzaC7GWkwcorAutRtDE7ib7zbc9SFwt12s6dx4UF7P4Df/AQCcl4yHla80VK7fu33YSa22qXSmzDpZAAAADKwHZ6J69GJCf/bahvY7mz3y5Yb+9LUNPbE4oXfNRh2eEMBbXVma1J1cxfbPa7uBO1bKAsDJELgDhhkNdwAg6c2Gu3i4Nw13HzgfV8jv0fX7Be52S1qcishDaAiHya5YxyEJ3EUCPiUi/r6slN0uVDXLOlkAwDHNxa1Q+CCvlV3PVVRvtrU0Pe70KAAAAMCRnr58QZVGS3/27Q1J0ldu3FGt2dYzy7TbAYPm8qJVDHDtPvcpTqq7UnaBhjsAOBECd8AwC3Ya7qp5Z+cAAIflKg2NBbw9W9fl93r02MUJvbKWU6PVPvQxjVZbt7MVLbJOFkfJpq3jkATuJGk+Hu55w127bWq7WNMMzZAAgGNKDkHg7uaudcPi0jleGwIAAGBw/cMPzivo8+iFl27JNE19/uqaokGfPv5I0unRALzNlaUeBe72ypoeD2o86LP1vADgdgTugGFGwx0ASJLy5XrP2u26lpcmVWm09Pqdw0PO67mKmm1TKb4FhqMMY+AuEdJWoap22+zZNTKlulptUzNRGu4AAMcz1wlpbwxw4G5lZ1+SdImVsgAAABhgsZBfP/+BOV1LZ/Unr67r+5tF/cJj84oECN4Ag+bCRFizsaCup7O2nnctU9Yi9zUA4MQI3AHDLBS3jrWCs3MAgMNylYbikUBPr3Elde9vj6UzZUmi4Q5H6wbuEguOjnESyXhYjZap3f1az66xXbTCErM03AEAjikZD0uSNvK9bWE9i5VOw90SDXcAAAAYcE8/Ya2P/Z++9Jok6Znl4fnsChglhmFoOTWpH2wVlS83bDlnsdpQplTX4iSBOwA4KQJ3wDCj4Q4AJEm5ckOJHjfcPbaQkNdj6NoR3x5Ld2+q0mKCo2TT0vicFBieDy/mE1ag4U4P18puF6ww32yMhjsAwPHMxQe/4e7mbklhv/egjQ8AAAAYVB9+YErnE2FVGi194HxMHzgfd3okAEdYTk3KNKWX1uxZK7tKkQAAnBqBO2CYBWPWsUrDHYDR1WqbKlQbSkR6G7gbC/r0/vmYrqf3Dl2vmc5YgTuq13GkbHqo1slK1kpZqbeBhq2Cde4ZAgkAgGOaGgvI7zW0OciBu52SlqbHZBiG06MAAAAA9+TxGPrk4+cl0W4HDLrlziaeqyv2rJVd2+sG7rivAQAnReAOGGa+oOTx03AHYKQVqw2ZpnoeuJOsN7PZckNv7Oy/489WM2UFvJ6DFWfAXaoFqZwZusBd93/P6z1suNvqNNzNRGm4AwAcj8djaC4eGtiGu2qjpfV8hXWyAAAAGBr/5CMP6H//xMP61PJFp0cBcA/vnosqGvTpetqehrtukcACgTsAODECd8AwMwwpFCNwB2Ck5coNSVI8HOj5tQ6+PXbIm9n0bkkLUxF5PbSY4BC5Ves4ZIG7bsPdeq53gYbtonXuWRruAAAnkIyFtVkYzMDdaqYs05QuTRO4AwAAwHAYC/r0K1cW5Pdy6xgYZF6PoSdSE/r27byqjdaZz7fWWSmbYqUsAJwYr5qAYReMSrW801MAgGNyFStw15+GuwlJ0vX03XXtzVZbt7JlpfgWGI6STVvHIQvczcZCMgxpI9/bhjufx9BkpPehWQCAe8zFQ9or1W25wWC3m5025Es03AEAAAAAbLacmlS91da3b5/9/vBqpqxo0KeJPtxfAQC3IXAHDLsgDXcARluuXJckJcK9f0M4NR7UpXNjurpyd8PdRr6qRsvUIt8Cw1GGNHDn93o0Ew1qvYcr+7aLVc1Eg/LQDgkAOIFk3GpG3RrAlrubu9ZKnqXpcYcnAQAAAAC4TXcTzzUb1squZkpanI7IMPhsFgBOisAdMOyCMalacHoKAHBMvo8Nd5J0JTWpO7mK1nNvNn6lM9ZNVRrucKRu4G5yydExTmM+Eb7rf+922ypUNcM6WQDACc11AncbPQyFn9bKQeCOL2MAAAAAAOz1yIW4Al7PmQN3tWZLG4WqFid57woAp0HgDhh2oU7DnWk6PQkAOKIbuIuH+7OO8rBvj6U7N1VT3FTFUbJpyReSxmednuTE5uNh7RRrqjXtX9nXapva3a9rJhq0/dwAAHfrNtxtDmDg7ubOvqbHA4r3oYEZAAAAADBaQn6vHrkQ10vprFrt098fvrVXkWlKCxQJAMCpELgDhl0wKrUbUnPwbjIAQD/kyt3AXZ8a7pYOCdxlypKkFCtlcZRs2lonO4TV/POJzsq+fM32c2dKNbXapmZpuAMAnNBcPCxJWs/3roX1tFZ2S7TbAQAAAAB65nJqUsVaUz/YLJ76HKts7gGAMyFwBwy7YMw61k7/ggoAhlk3cNevlbIXJsKajQV1bSV78LPVTEl+r3HQtALcpd2ScmtW4G4IJXsYaNguWCG+2RgNdwCAkxnUhrtsqa5suUHgDgAAAADQM1eWJiTpTGtlVztFAguslAWAUyFwBwy7YNQ6VgvOzgEADslV6pL6F7gzDEPLqUn9YKuoXNm6djpT1sWJiHxeXlrhEMUNqVUf2sBdt+FuoweBu62CFZKYoeEOAHBC0+NB+TyGNgYscLfSaQhYmh53eBIAAAAAgFs9sTApwzhb4G5tzwrcLdJwBwCnwl1hYNiFug13BO4AjKZ8uaGA16Ow39u3a3bXyl5PZ9Vqm1rLlJWixQRHyaat49AG7joNdzn7Aw1bnYa7mSgNdwCAk/F6DM3GQgPXcHdzxwrcXTrHa0MAAAAAQG/EI369ezaqa+k9maZ5qnOkMyUFfB7N8WVoADgVAnfAsOs23BG4AzCicpWG4hG/DMPo2zWXU1bg7trqnjbyFdVbbb4FhqPtrVjHIQ3cHayUzfVgpWzRCknM8qEOAOAU5uKhwWu4292XJF3iyxgAAAAAgB66nJrQVqGm29nTfW67lilrYTIij6d/91YAwE0I3AHDLhi3jrWis3MAgENy5boS4f6sk+16aDaqaMinayt7Ws1YteupKW6q4ghD3nA3NRZQwOvpSaCh23BH4A4AcBpz8ZB292uqN9tOj3JgZbckjyEt8GUMAAAAAEAPdYsBrq6cfK1sq23qVrasxUneuwLAaRG4A4Zdt+GuSsMdgNGUrzSUiPQ3cOf1GLq8OKHX7uT1vQ3r718a7nCkbuAusejoGKfl8RhKJkK9abgrVOX3Gpro87/DAAB3SHYC21uFwWm5u7lT0oWJiII+r9OjAAAAAABcrBu4u7568sDdeq6iRsvUIkUCAHBqBO6AYXewUpaGOwCjxzRN5coNxcOBvl97eWlSjZapP76xLklaYm0YjpJNS+OzUmB4Q5nJeG8Cd1vFqmaiob6uhAYAuMdc3ArcbQ5I4K7dNrWyW+J1IQAAAACg5+YTYZ1PhE/VcLe2Z23uoUgAAE6PwB0w7EIx61ij4Q7A6CnXW2q2zb433EnSlc63x167k5fPY+h8Itz3GTAksumhXSfbNZ8Iq1Btar/WtPW824WaZmJBW88JABgdybj1+qsXa89PY6NQVa3ZJnAHAAAAAOiL5dSE3tgpKbNfO9HvrWaswN0CgTsAODUCd8CwO2i4I3AHYPTkKg1JUiLc/8DdwxfiCvisl1IXJsLyeXlZhUPUilJ5d/gDd91Ag40td81WW7v7Nc1GQ7adEwAwWroNd3Y+P53Fyk5JkvTAOQJ3AAAAAIDeW17qrpXNnuj3VjPW+9cUK2UB4NS4MwwMu2Cn4a5K4A7A6MmV65LkSMNd0OfVoxcSkqQULSY4SnbVOg554C6ZsAIN6zY2CGVKdbVNaZaGOwDAKSW7gbsBabi7ubsvSVqaHnd4EgAAAADAKFjubOK5nj7ZWtnVTFkeQ2zuAYAzIHAHDLuDhruis3MAgAPyZavhLu5Aw50kLS9NSOJbYLiHbNo6Dnngbr7zwcu6jQ1CWwUrHDETo+EOAHA6M9GgPIa0OSiBu07D3RINdwAAAACAPnjw3LgSEb+upk/YcLdX1nwifLDFBwBwcvwNCgw7r1/yR1gpC2AkdVfKxiMBR67/5APTkqSHZqOOXB9DwC2Bux6slN0u1CRZYQkAAE7D5/VoJhrSRmEwAncruyWF/B4lCZMDAAAAAPrA4zF0eXFC37mTV7nePNbvmKap1UyJIgEAOCMCd4AbBKM03AEYSblOw13CoYa7Dz84ref/8U/qqScuOHJ9DAGXBO56sVJ2q2ida5ZQAgDgDObiIW3m7QuEn8XN3X2lpsbk8RhOjwIAAAAAGBHLqUk126ZurOWO9fjd/brK9ZYWpiI9ngwA3I3AHeAGwZhUpeEOwOjJVeqSpETEmcCdJP3kpSlq13G0bFryhaTxOacnOZNYyK9o0GfzSlmr4Y7AHQDgLJLxkLaLNTVabUfnqDVbup2t6BLrZAEAAAAAfXQ5NSlJunbMtbJreyVJ0uIkgTsAOAvuDgNuQMMdgBGVP2i4c2alLHBf2bSUWJQ8w/+yO5kIacPGhrvtQrfhjpWyAIDTm4uHZJrSTrHm6BxrmbJMU1qaJnAHAAAAAOifh8/HFfR5dC29d6zHp3fLkqRFVsoCwJkM/50/AFIoRuAOwEjqrpSNO9hwBxyp3ZZyq0O/TrYrGQ9rPVeRaZq2nG+rUFXA51HcoZXQAAB3SMatplQ7Q+GncXPXagi4ND3u6BwAAAAAgNES8Hn06MWEXl7LqnmM9vfVvW7gjoY7ADgLAneAGwSjUq1g3dgHgBGSq9TlMaRo0Of0KMA7FTekVt01gbv5RFi1Zlt7pbot59su1jQTDcowDFvOBwAYTXPxsCRp0+nA3Y4VuFtipSwAAAAAoM+uLE2qXG/puxuF+z52LWO9f11gpSwAnAmBO8ANgnFJptQoOT0JAPRVvtJQPOyXx0NgBwMom7aObgnc2dwgtFWoaTYWsuVcAIDR9WbDXcXROVZ29yVJl1gpCwAAAADos8upSUnStXT2vo9NZ8o6Fw1qjCIDADgTAneAGwSj1rF6/28tAICb5MoNJSIBp8cADue2wF3CahC6kzt7oKHRaitTqmk2FjzzuQAAo20uNhgrZVd2S5qI+HltCgAAAADou8cXEvIY0rWVvfs+dm2vrEXa7QDgzAjcAW4QilnHWtHZOQCgz7oNd8BAyq5YR5cE7pKJTqDBhsDd7n5NpinNRGm4AwCczWwsJMMYjJWyl86NOzoDAAAAAGA0RUN+vTcZ0/XVPZmmeeTjCtWG9kp1LUwRuAOAsyJwB7hBt+GuRsMdgNGSKxO4wwA7aLhbdHQMu8zHrYY7OxqEtgs1SdIMDXcAgDMK+DyaHg86ulI2X24oU6priXWyAAAAAACHLKcmtbtf18pu6cjHrGXKkqTUFO9fAeCsCNwBbhDsNtwRuAMwOqqNliqNlhIRAncYUNm0NDYjBdzx4cVc3Gqjs2Ol7FbBCu3N0nAHALBBMh5ytOFuJWPdzCBwBwAAAABwynJqUpJ0PZ098jGrncDdIg13AHBmBO4AN+g23FUJ3AEYHYVKQ5KUoOEOgyqbds06WUkK+b2aHg/Y0nC3VbQa7mZjBO4AAGc3Fwtpq1hTq3302pxeurmzL0l64ByBOwAAAACAM5ZTE5Kkq+m9Ix+zumd9YWxhksAdAJwVgTvADULdhruis3MAQB/lOoG7eCTg8CTAIWr7UmnHVYE7SUrGw9qwoeFuu9twx0pZAIANkvGQWm1Tu/s1R67fXdezND3uyPUBAAAAAJiJhbQ4FdH1ewXudlkpCwB2IXAHuAErZQGMoFyZhjsMsNyqdXRZ4G4+EdJmoapmq32m82wXrEDEDCtlAQA2mIuHJcmWFtbTuLlbkmGwkgcAAAAA4Kzl1KTSmbK2i4e/P17dKyka8ikR4b4KAJwVgTvADYI03AEYPblyXZJ4Y4jBlE1bR5cF7pLxsNqmtF08W4PQVrGqoM+jWNhn02QAgFGWjFsB7s382VtYT2Nlp6T5eFghv9eR6wMAAAAAIL25VvZ6Onvon69lylqcisgwjH6OBQCuROAOcINg1DpWabgDMDq6K2UJ3GEguTRwdz7RbRA6W6Bhq1DTbCzEBzsAAFvMdQJ367n+N9y126ZWdku6dI51PAAAAAAAZy2nJiVJV1feuVa22mhpo1DVIutkAcAWBO4ANwjRcAdg9BQ6gbt4OODwJMAhXBq4SyasQMOdMwYatgtVzcaCdowEAMCbDXeF/gfuvrtRUKXR0oMz432/NgAAAAAAb7U0Pabp8YCur74zcHc7W5ZpSouTEQcmAwD3IXAHuIF/TJIh1fJOTwIAfZMr03CHAZZNS96gFE06PYmtkvFOw13u9A139WZbmVJdM9GQXWMBAEbcbMx6TtnI9z9w9wffTEuSPvHYhb5fGwAAAACAtzIMQ5cXJ/Xd9YKK1cZdf7aaKUuSFqcI3AGAHQjcAW7g8VhrZWm4AzBCcpW6JCkRJnCHAZRNSxOL1nO0i3RXyq6fIXC3u1+TJM3QcAcAsEnI79XUWECbZ1x5flK7+zX9yY11Lacm9PCFeF+vDQAAAADAYS6nJtQ2pVfWcnf9PH0QuGOlLADYwV13AIFRFoxJ1YLTUwBA33Qb7mIE7jBo2m0pu+q6dbKSdC4alM9jaP0MDUJbnXV/3TYiAADsMBcP9b3h7t/+9ZrqrbaefXKpr9cFAAAAAOAoV5YmJUnX0nevlV3LlCTRcAcAdiFwB7gFDXcARky+0tB40Ce/l5czGDD7m1Kr5srAnddjaDYW0sYZGoS2ClbD3SwNdwAAGyXjIW0Vqmq3zb5cr95s69/8zarOJ8L62ffN9uWaAAAAAADcz/uSMUUC3ncE7lb3ygr6PJqN8kVoALADd6gBtwjFpBoNdwBGR67cUJx2OwyibNo6ujBwJ0nziZDWc6dvENouWr87wwc7AAAbzcVDarRMZUr1vlzvT19b106xpk9/aFE+vgACAAAAABgQPq9Hjy9M6JW1nOrN9sHPVzNlLUxG5PEYDk4HAO7BJ4KAW9BwB2DE5Cp1JSIE7jCAXB64S8bD2ivVVW20TvX72zTcAQB6IBkPS5I2+7BW1jRNPfdiWiG/R88sX+z59QAAAAAAOInLqQnVmm29vp6XJDVbbd3OllknCwA2InAHuEUwJjXKUqvh9CQA0Be5coPAHQaT2wN3CauZbuOUgYatQqfhLkbDHQDAPnOx7vPT6deeH9fLa1l9+3Zen3z8ghKRQM+vBwAAAADASVxJTUqSrq1Ya2U38lU1WqYWp8acHAsAXIXAHeAWwah1pOUOwAhottoqVptKhLnBiQG0t2IdE4vOztEj5xNWg9B67nSBhq1iTWG/V9Ggz86xAAAjLhk/WyD8JH7/G2lJ0rNPpnp+LQAAAAAATurRhYR8HkPX0llJ1jpZSTTcAYCNCNwBbhGKWUcCdwBGQKHalCTFabjDIMqmpbFzUnDc6Ul6oruy77SBu+1CVbOxoAzDsHMsAMCIS3YC4b0O3K3nKvoP39nU337XtB6cifb0WgAAAAAAnEYk4NP7z8d1fXVP7bap1b2SJGlhksAdANiFwB3gFsFu4K7g7BwA0Af5irU+OxEmcIcBlE27dp2sJM2fcaXsdrGmmSjrZAEA9uqulN3s8UrZz35rVa22qf/qyaWeXgcAAAAAgLNYXpxQrtzQGzv7Bw13KVbKAoBtCNwBbhGk4Q7A6MiV65KkBA13GDT1klTadnfg7gwNd7VmS3ulumZiQbvHAgCMuHDAq0TE39OGu0q9pc9fXdOl6TF95KFzPbsOAAAAAABntbw0KUm6mt7TaqYkr8fQ+Ymww1MBgHsQuAPcIthZZVOl4Q6A++UOGu4CDk8CvE121Tq6OHCXiPgV8nu0fopAw06xJkmajdFwBwCw31wspM1C7wJ3/+6V28pXGvqNJ1PyeFiNDgAAAAAYXJcXJyRJ19NZrWbKmk+E5PcSDwEAu/A3KuAWIRruAIyOfNkK3MVYKYtBk01bRxcH7gzD0HwifKqGu61CN3BHwx0AwH7JeEgb+apM07T93KZp6g9eTCsa8umTj1+w/fwAAAAAANhpajyoB86N6erKntb2yqyTBQCbEbgD3KLbcFfLOzsHAPQBK2UxsEYgcCdZa2U3cpUTBxp2ilbr0EyUhjsAgP3m4mHVm21lO1/OsNM3fryrH23v61OXL2os6LP9/AAAAAAA2G05Nak7uYrK9ZYWJiNOjwMArkLgDnCLIA13AEbHwUpZAncYNCMSuEvGQyrVWypUmyf6vW7D3QwNdwCAHkjGrUD3Rv7kLaz389yLaXkM6dc/nLL93AAAAAAA9MJyavLgPy9OEbgDADsRuAPcohu4qxacnQMA+iDXaS1JhAMOTwK8TTYteQNSNOn0JD01nwhL0onXym4VrIa72RgNdwAA+811Aneb+aqt5725s6+vfX9bf/d9s7pIIwAAAAAAYEjcHbhjpSwA2InAHeAWIRruAIyOPA13GFTZtJRYkDxepyfpqfnE6RqEug13BO4AAL3Qbbhbtzlw96+/mZYkPfvkkq3nBQAAAACgly5OhjXb2TZCwx0A2IvAHeAWwah1rNFwB8D9cuW6gj6PQn53h5owZNptKbcqTbj/Znwy3m24O1mgYbtY1VjAq/GgrxdjAQBGXPf5adPGlbKFakNffOm23puM6SeWJu//CwAAAAAADAjDMPTkg9MK+71aoLEdAGzFnS7ALXwhyeOn4Q7ASMhVGrTbYfDsb0nNqjSRcnqSnjvtStntQk0ztNsBAHqku1J2w8aGuz+6dkulekvPPpmSYRi2nRcAAAAAgH74X/7h+/Xf/p0HFAkQDQEAO/G3KuAWhmG13FVpuAPgfvlKQ4lwwOkxgLtl09ZxJAJ3pws0bBWrevdstBcjAQCg8aBP0ZBPmzYF7lptU//6W2lNjQUGu8QSAAAgAElEQVT0jz44b8s5AQAAAADop3jYr3iYAgMAsBsrZQE3CcVYKQtgJOTLDcVpuMOgGaHAXSTgUyLi150TNNxVGy3lyg3N0nAHAOihZDxkW+DuP39vS7f2KvrVn1hQyO+15ZwAAAAAAAAAhh+BO8BNglECdwBczzRNa6Us38jCoBmhwJ0kJeNhbeSPH7jbKdYkSbOxYK9GAgBAc/GwNvJVmaZ55nM99+KK/F5Dv/aTizZMBgAAAAAAAMAtCNwBbhKMS7Wi01MAQE/t15pqtU0q0DF4sivWcWI0bsrPdxqE2u3jBRq2i1bb0EyUhjsAQO8kYyFVGi0VKs0zned7GwX99c09ffzhpGZoZwUAAAAAAADwFgTuADcJRqVqQbLhm/wAMKhy5YYkKcFKWQyabFqKTFvPxyNgPhFWo2Vqd792rMdvFazHzdBwBwDoobm4FY7bKBy/hfUwz71oBemffXLpzDMBAAAAAAAAcBcCd4CbBKNSuyE1j3fjGwCGUb7SDdwFHJ4EeJtsemTWyUpSMmEFGtbz1WM9fqtgPW6WliAAQA8lu4G7Yz4/HSazX9NXbqzricUJffBiwq7RAAAAAAAAALgEgTvATUIx61grODsHAPRQt+GOlbIYKPWytL81UoG7+XhYkrSRO16DULfhjsAdAKCXkonu89PpA3ef+5s11ZttPftkyqapAAAAAAAAALgJgTvATbor7GpFZ+cAgB7KVeqSWCmLAZNbtY6jFLjrBBruHDNwt120gg8zUVbKAgB6p9twt5k/3UrZerOtP/zrVSXjIf3c++fsHA0AAAAAAACASxC4A9wk2Gm4q+adnQMAeqjbcJcIs1IWAySbto4jFLg76cq+7UJN40GfxoK+Xo4FABhxc2dcKfvV1ze0Xazp0x9alN/Lx2YAAAAAAAAA3olPDgE3oeEOwAjIVzqBOxruMEhGMHA3Fw/JMKSNYzYIbRWqmonRbgcA6K1o0KexgFebhZMH7kzT1O9/Y0Uhv0e/srzQg+kAAAAAAAAAuAGBO8BNQnHrSOAOgIt1A3fxMIE7DJARDNz5vR7NRIO6kzteoGGrUNVsNNTjqQAAo84wDM3FQ6dquHt5LadXb+f1S49d0MQYbcoAAAAAAAAADkfgDnCTg4a7grNzAEAP5cp1STTcYcBk05LHL8XmnZ6kr5LxsDZy92+4qzZaKlSbmqXhDgDQB8l4WJunCNw99+KKJOnZJ1M2TwQAAAAAAADATQjcAW4SjFlHGu4AuFiu3JDXY2g86HN6FOBN2bSUWJA8Xqcn6avzibB29muqN9v3fNx2oSZJmonRcAcA6L25eEj7taaK1caxf2cjX9FXX9/U33pwWg/NRns4HQAAAAAAAIBhR+AOcJNuw12VhjsA7pWrNBQP+2UYhtOjABbTtAJ3I7ROtisZD8k0rXWx97JVtP58JkrDHQCg95JxK+B9kpa7P/zWqlptk3Y7AAAAAAAAAPdF4A5wk1C34Y7AHQD3ypcbSoRZJ4sBsr8lNavS5JLTk/RdMhGWJK3fZ61sN5A3S8MdAKAP5jqBu41jBu4q9ZY+d3VNqamIPvrumV6OBgAAAAAAAMAFCNwBbhIkcAfA/XKVuuIRAncYINm0dRzBhrvzCSvQsJ6/X+DOWilL4A4A0A/zcSsQvnGf56eur9y4o1y5od/4cEoeDy3KAAAAAAAAAO7tWIG73/7t31YqlZJhGHr99dfv+3NJSqVSes973qNHH31Ujz76qL7whS/YOzmAd+qulK0VnZ0DAHooR8MdBs0IB+6S8W7D3b0bhLZZKQsA6KOTNNyZpqnnXlxRNOjTU5cv9no0AAAAAAAAAC5wrMDdU089pW984xtaXFw81s+7vvjFL+rGjRu6ceOGPvWpT519WgD35vVLvrBUpeEOgDtVGy3Vmm0lIgGnRwHeNMqBu0Q30HDvBqHtTsPdTIzAHQCg95KdwN3mMQJ333wjox9u7evpyxc1HvT1ejQAAAAAAAAALnCsTxJ/6qd+6kQ/B+CgUIyGOwCulSs3JElxGu4wSLqBu8ThX0Jxs+mxoAJez30b7rYKVUVDPkUCBBkAAL0XD/sV8nuO1XD3+99YkWFIv/HhVO8HAwAAAAAAAOAKx2q4O61f/dVf1cMPP6zf/M3f1M7OzpGP+73f+z1duHDh4J/9/f1ejgW4WzAq1Wi4A+BOuUpdkpSIELjDANlbkSJTVuh9xHg8hubiIa3n7t1wt1WoajYW6tNUAIBRZxiGkvHwfRvu0rslfe0H2/rYe2e1MBXp03QAAAAAAAAAhl3PAndf//rX9eqrr+rll1/W1NSUfv3Xf/3Ix/7u7/6ubt++ffDP+Ph4r8YC3C9Iwx0A98p3Gu4SNNxhkGTTI7lOtms+Ebpvg9B2saaZKOtkAQD9MxcL3Xfl+R98My3TlJ59MtWfoQAAAAAAAAC4Qs8CdwsLC5Ikv9+v3/md39Ff/dVf9epSAN4qGJWqNNwBcKdcpRO4iwQcngToqJel/c3RDtzFw8pXGirVmof+ebneVLHapOEOANBXyXhIhWrzyOenYrWhL750W++Zi+pDl6b6PB0AAAAAAACAYdaTwF2pVFIulzv4vz//+c/rscce68WlALxdKGatlDVNpycBANt1G+7irJTFoMitWccRDtwlE1aQ7qgWoe1CTZI0E6PhDgDQP3Nx6/lps3B4C+sL129rv9bUs0+mZBhGP0cDAAAAAAAAMOSOFbj7rd/6LV24cEG3b9/Wxz72MT344IP3/PnW1pY++tGP6pFHHtHDDz+sv/zLv9RnP/vZ3v1/AeBNwZgkU6rvOz0JANguV6lLkuKslMWgyKat4wgH7uYTYUnSndzhgYatTtBhNkrDHQCgf5LdwN0ha89bbVN/8M20JiJ+/cKj5/s9GgAAAAAAAIAh5zvOgz7zmc/oM5/5zLF/funSJb3yyitnnw7AyQVj1rFWtNbLAoCL5DoNdwkCdxgUBO40H7cCdxu5wxvutopWwx0rZQEA/ZTsPD+tH/L89LXvb2ttr6x/9tEHFfJ7+z0aAAAAAAAAgCHXk5WyABzUDdlVC87OAQA9kKt0AneRgMOTAB0E7g5Wyq4f0iAkSdudhjtWygIA+mnuHg13z724Ip/H0Kc/tNjvsQAAAAAAAAC4AIE7wG1Cb2m4AwCXyXca7mKhY5X0Ar2XTUsenxQb3XV03ZWyhzUISdJ2t+GOlbIAgD7qrpTdKNwduPv+ZkHffCOjv/9wkvZVAAAAAAAAAKdC4A5wm27DXS3v7BwA0AO5Sl3RkE8+Ly9hMCCyaSmxIHlGdx1dLOTXeNCnjfwRK2VpuAMAOGByLKCA1/OOhrvnvpGWJD37ZKr/QwEAAAAAAABwBe5WA25zELij4Q6A++TKDSUifqfHACymaQXuRnidbNd8IqSN3OErZbcKVcXDfoX8oxtKBAD0n2EYmouHtPGWwN1eqa6v3LijxxYSemxhwsHpAAAAAAAAAAwzAneA2wTj1rFacHYOAOiBXLmhRDjg9BiAZX9balYI3ElKxsO6k6vINM13/Nl2saaZKO12AID+m4uHtPmWBtbPX11TrdnWs08uOTgVAAAAAAAAgGFH4A5wGxruALhYoULDHQZINm0dJ7hpP58IqdZsK1tuvOPPtgs1zcZCDkwFABh1yXhI2XJD1UZLjVZbn/1WWnOxkP7eB+acHg0AAAAAAADAECNwB7hNKGYdCdwBcJlGq61iral4mMAdBsRB4C7l5BQDYT4eliSt5yp3/Xy/1tR+ramZGA13AID+m4tbge/NfFV/9tqGtgo1ffpDi/J7+TgMAAAAAAAAwOnxCSPgNgcNd6yUBeAuhYrVnEXDHQYGgbsDycThgbvtQlWSaLgDADiiGwjfyFf13ItpBX0e/cqVBYenAgAAAAAAADDsCNwBbhPsNtwRuAPgLrlO4I6GOxyp3erv9Q4Cd4v9ve4Amu80CG3kq3f9fLtYkyTNRmm4AwD0X7fh7quvb+jGrZx+6bHzmhwLODwVAAAAAAAAgGFH4A5wm8C4JEOqErgD4C65cqfhLsxNUhyilJH+zyXpP/5zyTT7c81sWgpPSqF4f643wOaPaLjb6jTczdBwBwBwQLITuPvc36xJkn7jyZSD0wAAAAAAAABwCwJ3gNt4PNZa2VrR6UkAwFb5Sl2SFGelLA6zcUOq5qVv/Uvp6/+iP9fMrrBOtqPbILT+9oa7QqfhLkbDHQCg/7rPT822qQ8/MKX3zMUcnggAAAAAAACAGxC4A9woGGWlLADXebPhjsAdDpH5sXUMT0p/8b9J1/5Vb6/XqEjFDQJ3HSG/V1NjAW0c1XAXpeEOANB/02NB+TyGJOnZJ5ccngYAAAAAAACAWxC4A9woGKPhDoDrHATuIqyUxSF2f2gd/8uvSJOXpD/976XvfLl318tZq+kI3L1pPhF+50rZotVwN0PDHQDAAR6PoaXpMS1Nj+mn3zPj9DgAAAAAAAAAXMLn9AAAeiAYfTMIAAAukat0A3c03OEQuz+UAuPS3CPSp78i/auflb7030ihuPTAT9t/vWzaOhK4O5CMh/TdjYJabVPeTpvQdqGqRMSvoM/r8HQAgFH13LPL8ns9B89NAAAAAAAAAHBWNNwBbhSi4Q6A++TLdUmslMURdn8kTb9LMgxpYlH69JelQER6/tek2y/Zfz0Cd+8wnwir1Ta1Xawe/Gy7WNMs62QBAA66MBHRbIznIgAAAAAAAAD2IXAHuFEwKjVKUqvp9CQAYJt8p+EuRuAOb1crSsUNafqhN382+z7pv3hBMtvSv31K2vmBvdckcPcO8wkrzNBdK2uaprYKVdbJAgAAAAAAAAAAwFUI3AFuFIxZxzotdwDcI1dpKOz3KuRnNSXeZvdH1nHqXXf/fOEnpF/+rFQrSH/4S1L+tn3XzKYlj0+KnbfvnEMuGQ9LktZzVsPdfq2pcr1FqxAAAAAAAAAAAABchcAd4EbBqHWsFpydAwBslCs3lIjQbodDdAN30+9655899LPSL/7fUuGOFborZey5ZjYtxS9KXp8953OB+UQ3cGc13G0Xa5KkmSgNdwAAAAAAAAAAAHAPAneAG4Xi1rFGwx0A98hXGoqzThaHyXQDdw8d/ueP/LL08/+HtPtD6XNPS7X9s13PNK3AHetk79JdKbuRtxrutgrWkYY7AAAAAAAAAAAAuAmBO8CNug13NRruALhHrlwncIfD7f5QMjzS5KWjH/OT/1T6qf9BuvOS9IVfk5q101+vtCM1ygTu3mYmGpLXY7zZcFew/juejdFwBwAAAAAAAAAAAPcgcAe4UTBmHWm4A+AS7bapfIWVsjjC7o+kxILkv0+T2kf/ufTEs9LNv5C+/E+kdut018umrSOBu7t4PYbmYiGt563AXbfhboaGOwAAAAAAAAAAALiIz+kBAPRAt+GuSsMdAHco1ppqm1IiHHB6FAyadkvKvCFd+sj9H2sY0sf/L6myJ33ny1J4Qvr471k/P4lu4G5y6cTjul0y/v+zd/dBkud3fdjfPc8z2/NwN7M7o3ta7d6DwEbBAiMd4IgngV1xKDs82AafXElRMUmcUC5icBInBrmKmKRsKJejxMIhVUEHBhNsEztOHGRjBxmdZCEkDAJ2T7P3uDez07vb8/zQM9P54zezOt3t3u3udPevp/v1qlJ9pdXM9BtOpVvVvuv9GcuV2maS5Nr68cKdwh0AAAAAAAC9w8Id9KKx44U7hTugN6xuNZLEwh1vVn8pOdhN5p66u68fGEy+4+8mF78x+fT/lvzqf3/vn2nh7o7eMTOe65t72Wkc3Fq4O1t1UhYAAAAAAIDeoXAHveh44U7hDugR9e29JMm0wh1vVLtcvLNP3P33DI0mf/rZ5KGvSv6//zF57u/c22cq3N3RQzPFmt1rqzu5trabB8+MZGTI/+QAAAAAAACgd/jTL+hFo9PFu7tebg6AFqkfL9w5Kcsb1S4V790u3B0bnUz+7P9RfN//85eT3/rFu//emy8U52jHpu/tM/vAQ9PjSZLX6ttZXt/JuUnrdgAAAAAAAPQWhTvoRccLdzsW7oDesLrtpCx3cP1o4e5eC3dJcmY2eeYfJFMPJ//oP0ku/8rdfd/NF6zb3cFDM0Xh7tX6dq6t7WZ+aqzkRAAAAAAAANBaCnfQi26dlLVwB/SG+nHhblzhjjeoXS6W5s7M3d/3zzyafPAfJqNTyS98MHnpk2/99Y2dZO2qwt0dvGO6KNhdWl7PduPAwh0AAAAAAAA9R+EOetHweDIwpHAH9IzVrb0kybSFO96odqlYt6tU7v9nnH1XcV62MpD83Hcny5+/89fWX0rSVLi7g+OFu8++XE8SC3cAAAAAAAD0HIU76EWVSrFyt+ukLNAb6lvFwt20hTteb/tmsrlyf+dk3+iRr07+zLPJ3lby7HckN1+8/dfdfKF4Fe5u64GJ4YwND+TfvrqaJJmfsnAHAAAAAABAb1G4g141OqVwB/SMWydlJ0ZKTkJXqT1fvLNPtObnPf7NyXf8VLK+lHz0TyYbK2/+GoW7t1SpVPLQ9Hh2GodJknMW7gAAAAAAAOgxCnfQq0ankh2FO6A31LcaGRqo5MzIYNlR6Ca1S8XbioW7Y1/xHckf/5vJjcVi6e6Nfy9VuHtb75j5Ysnu3KSFOwAAAAAAAHqLwh30qrGpZHe97BQALbG6vZeZieFUKpWyo9BNrl8u3lYW7pLka74v+aa/kiz9VvLz35s0dr747918IakMJlOPtPYze8hD0+O3/vm8hTsAAAAAAAB6jMId9KrRSSdlgZ5R32pkeny47Bh0m9rlZGAoefBC63/2+38oee/3Jy/8WvJL35cc7Be/fvOFZObRZHCo9Z/ZI94x88XC3VkLdwAAAAAAAPQYhTvoVaNTycFesr9bdhKAE6tvNzIzMVJ2DLpN7VJx2nWwDWXMSiX5Yz+evPu7k9/7J8k/+YvJ4WFRuHNO9i09fHRSdq46kuFB/3MDAAAAAACA3mKaA3rV6GTx7qwl1bPlZgE4gWazmdWtRmYetnDH6xw0khtXkie/tX2fMTCQ/In/Odm+mfzmR4sSXmNT4e5tvOPopOy5SedkAQAAAAAA6D0mJ6BXjU0Vr7OywCm30zjM3sFhpicU7nidmy8mh41k7sn2fs7QSPKnfiZ55L3JZ36m+DWFu7f00NHC3bkp52QBAAAAAADoPQp30KuOF+4U7oBTrr69lySZGXdSltepXSre2TYX7pJk5Ezyvb+QnP3y4l8/cKH9n3mKPTwzkenx4bxrYbLsKAAAAAAAANByTspCrxo9XrhbLzcHwAnVtxpJkhkLd7zeceFu7qnOfN7Eg8mf+0fJbz6bPPltnfnMU2p8ZDD/4r/8hpwZ9T81AAAAAAAA6D3+FAx61XHhbsfCHXC6HRfupscV7nid65eLt90nZV9vciF5/1/q3OedYrNV52QBAAAAAADoTU7KQq8as3AH9IbV45OyFu54vdrlZGK2WJ4DAAAAAAAA6BCFO+hVo5PFu2vhDjjdLNxxW7VLnTsnCwAAAAAAAHBE4Q561fFJWYU74JSrbxeFu5mJkZKT0DU2ryfbNzt7ThYAAAAAAAAgCnfQu44X7rZulJsD4ISOF+5mLNxxrHapeGcV7gAAAAAAAIDOUriDXjX9SDL1cPK5n092VstOA3DfVrf3kiQzEwp3HDku3DkpCwAAAAAAAHSYwh30qsHh5Jv+m2T7RvLrf7vsNAD3rb7VSKWSTI4p3HHk+uXidVIWAAAAAAAA6DCFO+hlX/k9ydkvTz7x4WR9qew0APdldbuRqbHhDA5Uyo5Ct6hdTgZHkpnzZScBAAAAAAAA+ozCHfSygcHkAz+SNLaSf/U/lJ0G4L7UtxrOyfKlapeSBy8mg0NlJwEAAAAAAAD6jMId9Lqn/ljy2Ncmv/G/J7Xny04DcM9WtxuZGVe448j+bnLzBedkAQAAAAAAgFIo3EGvq1SSD3woaR4k/+KvlZ0G4J7Vt/YypXDHsRtXkuZhMvdU2UkAAAAAAACAPqRwB/3gsfclX/bvJ5//5eSVT5edBuCu7e0fZnPvIDMTI2VHoVvULhXvrIU7AAAAAAAAoPMU7qBffMtfTSoDya/8SNJslp0G4K6sbjeSxElZvui4cGfhDgAAAAAAACiBwh30i7PvSt7zTPLix5PnP1Z2GoC7srq9lySZmVC448j154t37olycwAAAAAAAAB9SeEO+sk3/tfJ0Fixcnd4UHYagLdV3yoW7qYt3HGsdimpzidj02UnAQAAAAAAAPqQwh30k6mHkqf/0+Ta7yS/9ffLTgPwto4LdzMTIyUnoSs0m0ntsnOyAAAAAAAAQGkU7qDffP1fTMZmkl/9saSxU3YagLdU3z4q3Fm4I0k2riW7a8nck2UnAQAAAAAAAPqUwh30m/GZ5P1/KVl9Ofk3/2vZaQDe0upx4W5C4Y4U52QTC3cAAAAAAABAaRTuoB99zX+cTD2S/NrfSLbrZacBuKPVrb0kCnccOS7czVq4AwAAAAAAAMqhcAf9aHgs+ea/kmzfTP713yo7DcAdHZ+UnR4fKTkJXeH688XrpCwAAAAAAABQEoU76Ff/zp9Ozv2B5Ln/JVm7WnYagNuqbx0X7izckWLhbmgsmX607CQAAAAAAABAn1K4g341MJh84EeT/e3kX/542WkAbqu+3cjEyGBGhvyWhRSFu9knkgH/eQAAAAAAAADK4U8roZ89+W3J+a9PfvOjycqlstMAvMnq1l5mrNuRJI3tpP6yc7IAAAAAAABAqRTuoJ9VKskHPpQ0D5N//qGy0wC8SX27kemJkbJj0A2ufyFJM5l7quwkAAAAAAAAQB9TuIN+9+jXJF/+7cnv/ZPk5U+VnQbgS9S3GhbuKNSOllhnLdwBAAAAAAAA5VG4A5Jv+ZGkMpj8yo8kzWbZaQCSJAeHzaztNDIzoXBHktrl4nVSFgAAAAAAACiRwh1QlBe+6s8lL/16cumflZ0GIEmyvtNIsxmFOwrXjwp3s0+UmwMAAAAAAADoawp3QOEb/6tkeCL52I8mhwdlpwHI6nYjSTI9PlJyErpC7VIy9XAyWi07CQAAAAAAANDHFO6AwuRC8vR/lqz8bvK5ny87DUDqW0XhzsIdaTaT2vPOyQIAAAAAAAClU7gDvujrfyAZfzD51R9LGttlpwH6XP1o4W5mXOGu761dTRqbydxTZScBAAAAAAAA+pzCHfBFY9PJ+38oWXs1+dTfLTsN0OfqW3tJkmmFO2qXilfhDgAAAAAAACiZwh3wpb7m+5Lpx5Jf+5vJ9s2y0wB9bPVo4W7aSVlql4t39olycwAAAAAAAAB9T+EO+FJDo8k3/7fJTj35+E+WnQboY/Wt45OyIyUnoXTXjwp3Fu4AAAAAAACAkincAW/27u9O5t+dPPd3ktVXyk4D9KlbhTsLd9QuJcNnkqmHyk4CAAAAAAAA9DmFO+DNBgaSD/xocrCb/Mu/XnYaoE/Vt/eSKNyR4qTs3BNJpVJ2EgAAAAAAAKDPKdwBt/fEtyTv/HeTz/5ccu13y04D9KHVrUZGBgcyPjxYdhTKtLuRrL3qnCwAAAAAAADQFRTugNurVJJv/VDSPEz++V8rOw3Qh+rbjUxPDKdi1ay/XX++eBXuAAAAAAAAgC6gcAfc2cNfnfyBP5n8/j9NXvxE2WmAPrO63cjMuHOyfa92uXhnnyg3BwAAAAAAAEAU7oC38y1/NakMJh/7kaTZLDsN0EfqW43MTCjc9b3apeK1cAcAAAAAAAB0AYU74K3NPp589X+YvPzJYukOoAOazWZWt/cyPT5SdhTKdv1ykkrx9yMAAAAAAACAkincAW/vG/5yMjyRfOxDycF+2WmAPrC1d5DGQTPTTspSu5zMPJoMj5edBAAAAAAAAEDhDrgLk/PJ1/7nSe33k8/9XNlpgD5Q324kiZOy/e7wMLn+vHOyAAAAAAAAQNdQuAPuztf9F8nEbPKrfz3Z2yo7DdDj6lt7SZIZC3f9bfXlZH9H4Q4AAAAAAADoGgp3wN0Zm0re/8PJ+tXkUx8pOw3Q41a3LNyR4pxsksw9WW4OAAAAAAAAgCMKd8Dd+8P/UTJzPvm1n0y2bpSdBuhhxydlpydGSk5CqWqXindW4Q4AAAAAAADoDgp3wN0bGk2++b9LdleTj/9E2WmAHlY/XrhzUra/HRfunJQFAAAAAAAAuoTCHXBvvuI7k4V3J5/8qaT+ctlpgB5V395L4qRs37v+fDI6nVTPlZ0EAAAAAAAAIInCHXCvBgaSD3woOdhN/uVfLzsN0KNWt48X7pyU7Wu1S8ncE0mlUnYSAAAAAAAAgCQKd8D9ePybkwvfkHz255Ll3yk7DdCDVo9Oyk5buOtfO6vJxrJzsgAAAAAAAEBXUbgD7l2lknzrh5I0k499qOw0QA+qbzUyUEkmR4fKjkJZas8X79yT5eYAAAAAAAAAeB2FO+D+PPSe5Cu+M7n8z5JXfqPsNECPqW/vZWp8OAMDTon2rdql4p1VuAMAAAAAAAC6h8IdcP++8nuLd+lz5eYAek59q5GZcedk+9px4c5JWQAAAAAAAKCLKNwB929yoXjXl8vNAfSc1e1GpidGyo5Bma5fTiqDyYMXyk4CAAAAAAAAcIvCHXD/jgt3G0vl5gB6joU7UrucPHA+GRotOwkAAAAAAADALQp3wP0bfzAZGLJwB7TUTuMg242DzEwo3PWtg/3k+heckwUAAAAAAAC6jsIdcP8GBpLqvIU7oKXWthtJYuGun9VfTA4bydyTZScBAAAAAAAA+BIKd8DJVM8lG9fKTgH0kPpR4W56YqTkJJSmdrl4LdwBAAAAAAAAXUbhDjiZ6kKysZwcHpadBOgRqxbuqF0q3lkLdwAAAAAAAEB3UbgDTmZyPjncT7ZvlJ0E6BH1raPC3YTCXd86LtxZuAMAAAAAAAC6jMIdcDLVheJdX2KllnAAACAASURBVCo3B9Az6lt7SRTu+tr155PxB5Mzs2UnAQAAAAAAAPgSCnfAyUzOF++Gwh3QGscnZaedlO1ftUvJnHOyAAAAAAAAQPdRuANO5tbC3XK5OYCecXxSdnp8pOQklGLrRrJ1XeEOAAAAAAAA6EoKd8DJWLgDWqy+7aRsX6tdLt65p8rNAQAAAAAAAHAbCnfAyVSPC3fXys0B9IwvLtwp3PWl2qXinbVwBwAAAAAAAHQfhTvgZM6cK951C3dAa6xuN1IdHcrwoN+m9KXjwp2FOwAAAAAAAKAL+ZNs4GSGRpKJ2WRjuewkQI+obzWs2/Wz688nA8PJA+fLTgIAAAAAAADwJgp3wMlVFyzcAS1T397LzITCXd+qXUoevJAM+s8AAAAAAAAA0H0U7oCTm5wvFu6azbKTAD1gdauhcNev9veSG1eckwUAAAAAAAC6lsIdcHLVhaSxleyul50EOOUODptZ29nPzPhI2VEow80rSfMgmXuy7CQAAAAAAAAAt6VwB5zc5HzxbiyXmwM49da2G0mSaQt3/al2uXgt3AEAAAAAAABdSuEOOLnqQvGuL5WbAzj16keFu5lxhbu+VLtUvLMW7gAAAAAAAIDupHAHnFz1XPFauANOqL61lySZVrjrT7cW7p4oNwcAAAAAAADAHSjcASc3ebRwp3AHnNCthTsnZfvT9cvJmXPJ+ANlJwEAAAAAAAC4LYU74OSq88XrpCxwQqtbReFuenyk5CR0XLNZnJSdc04WAAAAAAAA6F4Kd8DJWbgDWuT4pKyFuz60uZLsrCrcAQAAAAAAAF1N4Q44uZEzycikhTvgxJyU7WO1y8U791S5OQAAAAAAAADegsId0BqT8xbugBOrH52UnXFStv/ULhXvrIU7AAAAAAAAoHsp3AGtUV2wcAec2JqFu/51a+FO4Q4AAAAAAADoXgp3QGtUzyU79WR/t+wkwClW325kdGggY8ODZUeh065fTgZHk5nHyk4CAAAAAAAAcEcKd0BrTC4Ur7OywAnUt/as2/Wr2qVk9vFkQNkSAAAAAAAA6F4Kd0BrVOeLd13hDrh/9e1GZsZHyo5BpzV2kpsvOicLAAAAAAAAdD2FO6A1bi3cLZWbA97Gr3x+OZ+6cqPsGNzB6lYj0+MW7vrOjS8kaSZzT5WdBAAAAAAAAOAtKdwBrXFr4U7hju7VbDbzg7/w2fzY//X5sqNwG81mM/XtRqadlO0/tcvFq3AHAAAAAAAAdDmFO6A1bi3cOSlL97q2vpv13f1cXd0pOwq3sbG7n4PDZmYs3PWf48Ld7BPl5gAAAAAAAAB4Gwp3QGtYuOMU+MLKRpKktrGb/YPDktPwRvWtRpJkxsJd/6ldKt65J8vNAQAAAAAAAPA2FO6A1hh/IBkcSTaulZ0E7uhKbTNJ0mwmKxu7JafhjVa3jwt3IyUnoeOuX04mH0pGJ8tOAgAAAAAAAPCWFO6A1qhUipW7DQt3dK/Flc1b/3zJWdmuc7xwN+2kbH9pNouTsnPOyQIAAAAAAADdT+EOaJ3qfLK+XHYKuKPFo5OySbK8pnDXbb64cKdw11fWX0v2NpK5p8pOAgAAAAAAAPC2FO6A1plcSDavJYcHZSeB2zo+KZtYuOtG9e29JMnMuJOyfaV2uXgV7gAAAAAAAIBTQOEOaJ3qfNI8TDZrZSeBN9nbP8zLN7fz1Hw1SbK0tltyIt7o+KSshbs+U7tUvLNOygIAAAAAAADdT+EOaJ3JheLdWCo3B9zGSzc2c3DYzNdenE2SXHNStuscn5SdHle46ysW7gAAAAAAAIBTROEOaJ3qfPGuL5ebA25jcaU4J/sVD09ncnQoSwp3Xae+VZyUnbZw119ql5LhiWTq4bKTAAAAAAAAALwthTugdW4t3Cnc0X0Wa0Xh7uLZauanxxTuulB9q5HBgUomR4fKjkInXX8+mX08GfDbUgAAAAAAAKD7+ZNNoHWq54rXSVm60OLKRpLk4tyZLEyNZXlV4a7b1LcbmR4fTqVSKTsKnbK3may+7JwsAAAAAAAAcGoo3AGtUz1auHNSli50pbaZByaG88CZkZybGs3m3kHWdxplx+J1VrcamRl3TravXH++eBXuAAAAAAAAgFNC4Q5onTNnk1Qs3NGVFlc2c/FsNUmyMDWWJFle2y0zEm9Q397L9ITCXV+pXS7euSfLzQEAAAAAAABwlxTugNYZHCpKdxbu6DKrW41c39zLhbkzSZKF6ePCnbOy3aRu4a7/HBfuZhXuAAAAAAAAgNNB4Q5orcl5C3d0ncXaRpLk4tmicDd/tHC3tKpw1y12GgfZ3T/MzMRI2VHopNql4p19otwcAAAAAAAAAHdJ4Q5orepCsXDXbJadBG5ZXNlMklyc+9KTsksW7rrG6nYjSTJt4a6/XL+cTD+WjEyUnQQAAAAAAADgrijcAa01OZ8c7CY79bKTwC1vXLhzUrb71LeKwt3MhMJd3zg8TGrPJ3PW7QAAAAAAAIDTQ+EOaK3qfPFuXCs3B7zO4spmBirJ+dliRWv2zEgGKk7KdpP61l6SZMbCXf9YeyXZ307mnio7CQAAAAAAAMBdU7gDWqu6ULzrS+XmgNe5UtvMIw9MZHRoMEkyNDiQs5OjWV7fLTkZx+rHJ2Ut3PWP2uXinXuy3BwAAAAAAAAA90DhDmityeOFu+Vyc8CRw8NmrtQ2c2HuzJf8+sLUWJYt3HWN1eOTsuMjJSehY44Ld7MKdwAAAAAAAMDpoXAHtJaFO7rMq/Xt7O4f5uLZLy3czU+NZWVjNweHzZKS8Xr17eKkrIW7PlK7VLxOygIAAAAAAACniMId0FoW7ugyV2qbSZKLZ6tf8usL02M5OGymtuGsbDeo31q4U7jrG7VLychkMrlQdhIAAAAAAACAu6ZwB7SWhTu6zOLKRpLk4tybF+6SZMlZ2a5Q3z4q3E04Kds3rj+fzD2ZVCplJwEAAAAAAAC4awp3QGsNjyVj0xbu6BqLtxbu7lC4W1O46warRwt3U2NDJSehI3bWkvXXisIdAAAAAAAAwCmicAe0XnVe4Y6ucaW2mfHhwSwcFeyOHf/rawp3XWF1u5HJsaEMDfqtSV+4frl4Fe4AAAAAAACAU8afagOtV51P1hXu6A6LK5u5MHcmlTecrVyYHk1i4a5b1Lf3MjMxXHYMOqX2fPHOPVVuDgAAAAAAAIB7pHAHtN7kQrK7mjS2y05Cn9veO8ir9e03nZNNXndSdnW307G4jfpWIzPjI2XHoFNql4p31sIdAAAAAAAAcLoo3AGtV50v3vWlcnPQ9164vpkkuXi2+qZ/b3JsOGdGBrNs4a4rrG41LNz1k9qlpDKQPHix7CQAAAAAAAAA90ThDmi9yYXi3XBWlnItrhwV7ubevHCXFCt3TsqWr3FwmPXd/UyNK9z1jevPJzPnk+GxspMAAAAAAAAA3BOFO6D1qkeFOwt3lGxxZSNJbntSNikKdxbuyre23UiSzCjc9YfDg6JwN+ecLAAAAAAAAHD6KNwBrTd5dFLWwh0lu1IrFu4u3GHhbmF6LOs7+9na2+9kLN6gfly4c1K2P9RfTA72krmnyk4CAAAAAAAAcM8U7oDWqzopS3f4Qm0z5yZHMzl2+yLX/FRxznJp1cpdmepbxwt3IyUnoSNql4vXwh0AAAAAAABwCincAa1XPVe86wp3lKfZbGZxZeOO63ZJsjA1miRZcla2VKvbe0mSaQt3/eG4cDercAcAAAAAAACcPgp3QOuNTSdDY8nGUtlJ6GPXN/eyvrOfi2erd/ya44W7ZYW7Un1x4U7hri/ULhWvk7IAAAAAAADAKaRwB7RepZJU5y3cUarFlc0kyeNn77xwNz99fFJ2tyOZuL3V7aPC3YSTsn2hdjkZm0nOzJWdBAAAAAAAAOCeKdwB7TG5YOGOUi2ubCTJ25yUtXDXDW4t3Dkp2x+uXy7W7SqVspMAAAAAAAAA3DOFO6A9qvPJZi052C87CX1qsVYs3L3VSdmzk6OpVBTuynZr4c5J2d63dSPZXEnmniw7CQAAAAAAAMB9UbgD2mNyIUkz2bxWdhL61OLKZoYGKnn0gfE7fs3w4EDmqqNZUrgrVX1rL0kypXDX+64/X7wKdwAAAAAAAMAppXAHtEd1vng3lsvNQd9arG3ksdmJDA2+9d/qFqbGsryqcFem+nYjY8MDGRseLDsK7Va7XLxzT5WbAwAAAAAAAOA+KdwB7XFcuFtXuKPzGgeHeen6Vi7O3fmc7LH5qdFcW9/N4WGzA8m4nfpWIzPjI2XHoBNql4p31sIdAAAAAAAAcDop3AHtMblQvBtL5eagL71yczv7h808fvbM237t/NRY9g+bub6514Fk3M7qdiMzE87J9oXa5WRgKHnwQtlJAAAAAAAAAO6Lwh3QHhbuKNHiykaS5MLc2xfuFqbGkiTLa87KlqW+tZfpcYW7vnD9cvLAhWTQX28AAAAAAADgdFK4A9rDwh0lWlzZTJJcPHsXJ2Wni8Ld0qrCXRkOD5sW7vrFQSO5sZjMOScLAAAAAAAAnF4Kd0B7TMwllUELd5RisXZcuLv7hbslC3elWN/dz2EzmRkfKTsK7XbzheRwX+EOAAAAAAAAONUU7oD2GBhIqucs3FGKxZWNTI4NZfbM25e45p2ULdXadiNJLNz1g9ql4p17qtwcAAAAAAAAACegcAe0T3Xewh2lWKxt5uLZaiqVytt+7a2FOydlS1HfKgp30wp3va92uXhnLdwBAAAAAAAAp5fCHdA+kwvJxnLSbJadhD6yvtPIyvpuHp97+3OySTI1PpSx4YEsr++2ORm3U9/eS+KkbF84Ltw5KQsAAAAAAACcYgp3QPtUzyWHjWT7ZtlJ6CNXaptJkgt3WbirVCpZmBrLsoW7Uhwv3Dkp2wdql5KJuWTiwbKTAAAAAAAAANw3hTugfaoLxbu+VG4O+sriSlG4u3i2etffMz81lqU1hbsy1LePTsqOK9z1vOvPJ7NPlJ0CAAAAAAAA4EQU7oD2mZwv3g2FOzpnsXZcuLu7hbskWZgey+p2IzuNg3bF4g5Wt4qTsgp3PW5vK9m+kcw8VnYSAAAAAAAAgBNRuAPa59bC3XK5OegriysbSe7+pGxSLNwlyZKzsh3npGyfWH+teKfeUW4OAAAAAAAAgBNSuAPaZ/KocGfhjg5aXNnMwzPjGRsevOvvuVW4c1a2445Pys5MjJSchLZau1q8Uw+XmwMAAAAAAADghBTugPapHp2UtXBHhzSbzVypbd7TOdkkWTgq3C0r3HVcfauRoYFKzozcfUGSU+hW4e6hcnMAAAAAAAAAnJDCHdA+1XPFu6FwR2csre1ku3GQi/dwTjZJFqZHkyjclWF1ey8zE8OpVCplR6Gd1l4tXoU7AAAAAAAA4JRTuAPaZ2g0GX9A4Y6OWVzZTJJcuMfC3a2Tsqu7Lc/EW1vdbmR6fLjsGLSbk7IAAAAAAABAj1C4A9qrupCsL5Wdgj6xuLKRJLl4tnpP33du0knZstS3GpmZGCk7Bu22djUZGErOnC07CQAAAAAAAMCJKNwB7TU5b+GOjlmsFQt3F8/e28LdyNBAZs+MZEnhrqOazWbq243MWLjrfWuvJpPvSAYGy04CAAAAAAAAcCIKd0B7VReSvY1kd6PsJPSBxZXNjA4N5KHp8Xv+3vmpMQt3HbbTOMze/mGmJxTuet7a1WTqobJTAAAAAAAAAJyYwh3QXpPzxWvljg5YrG3kwtyZDAxU7vl7F6bHcm1tN81msw3JuJ369l6SZNrCXW/b30s2rxULdwAAAAAAAACnnMId0F7VheJdXyo3Bz1vd/8gr9zcvudzssfmp8ayd3CYG5t7LU7GndS3GkmSmfGRkpPQVhtH//0/9XC5OQAAAAAAAABaQOEOaC8Ld3TIi9e30mwmF+bur3C3MDWWJFlyVrZjbhXunJTtbWtXi9dJWQAAAAAAAKAHKNwB7VVVuKMzFlc2kiQX56r39f3zU6NJkmWFu45ZPTopq3DX49ZeLV6FOwAAAAAAAKAHKNwB7eWkLB2yWNtMkvs/KTt9tHC3utuyTLy144W76XGFu552a+HOSVkAAAAAAADg9FO4A9rLSVk6ZHHlqHB3nwt3xydlLdx1Tn37+KTsSMlJaCsnZQEAAAAAAIAeonAHtNfoZDJ8xsIdbbe4spHZMyOZvs/zpAp3nbd6XLizcNfb1l5NUkkmF8pOAgAAAAAAAHBiCndA+03OW7ij7a7UNu/7nGySzEwMZ2RoIEsKdx1zfFJ25j5LkpwSa1eT6nwy6K8zAAAAAAAAcPop3AHtV12wcEdb3dzcy82tRi7M3X/hrlKpZGFqLEurCnedsrq9l0olmRxTxOppa1eTqXeUnQIAAAAAAACgJRTugPabnE+2byT7e2UnoUct1jaSJBfPVk/0c+anRp2U7aD6ViNTY8MZHKiUHYV2OTwoCtdTD5edBAAAAAAAAKAlFO6A9qsuFO/mtXJz0LMWVzaTJBdPsHCXJPNTY7m51cju/kErYvEW9g8O84WVjcxVR8qOQjttXEuaB8nUQ2UnAQAAAAAAAGgJhTug/arnind9udwc9KzF2lHh7oQLdwtTY0mSa2u7J87EW/sXv3cty2u7+favVMTqaWtXi1fhDgAAAAAAAOgRCndA+00eLdxtLJWbg561uLKRwYFKHntw4kQ/Z2G6KNwtOSvbdh997sUMDlTyPe99rOwotNPaq8XrpCwAAAAAAADQIxTugParzhfvusId7bG4splHHxjPyNDJ/rY2f7Rwt7SqcNdOV2qb+bXLtXzbH5i/9f9zepSFOwAAAAAAAKDHKNwB7Xdr4c5JWVrv4LCZF69vnficbPLFwt2yhbu2+tnnXkySfPDp8yUnoe1uLdwp3AEAAAAAAAC9QeEOaL/qUeHOwh1t8OrN7ewdHObC3JkT/6wFC3dtt9M4yC/+xiu5ePZMvvbx2bLj0G7HC3eTCncAAAAAAABAb1C4A9pv4sFkYNjCHW3xhdpGkuTi2ZMX7s5NjSZJltd3T/yzuL1//LmrWd1u5INPn0+lUik7Du22djWZmE2GnQ4GAAAAAAAAeoPCHdB+lUpSnVe4oy2urGwmSS7Onfyk7NjwYB6YGM6yhbu2efa5FzM+PJjv+KpHyo5CJ6y9at0OAAAAAAAA6CkKd0BnVM8l6wp3tN5iCxfukmR+aixLawp37fBbr9TzuVdW8yf+0EOZHh8uOw7t1mwm668lUwp3AAAAAAAAQO9QuAM6Y3Ih2byWHB6WnYQes7iymTMjgzk3OdqSn7cwXRTums1mS34eX/Tscy8mSZ55+nzJSeiIrevJwZ7CHQAAAAAAANBTFO6AzqjOJ4f7RQEDWuhKbTMXz1ZTqVRa8vPmJ8eyt3+Y+lajJT+PwupWI7/82at5z2Mz+YqHp8uOQyesvVq8Uw+XmwMAAAAAAACghRTugM6YXCjejaVyc9BTtvb289rqTi7MteacbJLMT48lSZbXnZVtpV/8jZezu3+YD1q36x9rV4vXwh0AAAAAAADQQ+6qcPcDP/ADeec735lKpZLf/u3ffttfT5LLly/n677u6/LUU0/lve99bz7/+c+3NjlwulTni3d9udwc9JTFlc0kycWzrSvcLUwVhbulVYW7Vjk8bOZnP/lSHpgYzr/37neUHYdOubVwp3AHAAAAAAAA9I67Ktx913d9Vz7+8Y/n/Pnzd/XrSfL93//9+fN//s/n0qVL+eEf/uF83/d9X2sSA6eThTva4ErtuHBXbdnPXJgeTZIsrynctcq//kItV2qb+VN/+NGMDQ+WHYdOubVw56QsAAAAAAAA0DvuqnD3/ve/P4888shd//q1a9fymc98Js8880yS5Du/8ztz5cqVvPDCCydLC5xexwt3GxbuaJ1bC3etPCl7a+Fut2U/s989+9yLqVSS733fY2VHoZNuFe6sGgIAAAAAAAC9464Kd/fq5ZdfzkMPPZShoaEkSaVSyWOPPZaXXnrptl//Ez/xE3nkkUdu/WNjY6MdsYAyOSlLGyzWir9fXGhH4c7CXUu8trqdX/n8cr7hqbM5P9u6v06cAmuvJqNTyehk2UkAAAAAAAAAWqYthbukKNm9XrPZvOPX/uAP/mBeeeWVW/+oVlt3GhDoEtVzSSpOytJSV2qbWZgay5nRoZb9zAcnRjI8WHFStkX+3idfymEzeeZ9bz4/T49bey2ZeqjsFAAAAAAAAAAt1ZbC3aOPPppXXnkl+/v7SYqy3csvv5zHHnNKDvrW4HAyMWvhjpZpNptZXNls6bpdkgwMVHJuckzhrgUaB4f5e//m5Tw8M55v+rJzZcehk5rN4qSswh0AAAAAAADQY9pSuDt37lze85735Nlnn02S/NIv/VLe+c535p3vfGc7Pg44LSYXLNzRMivru9nY3c/Fs60/U7owrXDXCv/v7yxnZX033/u+xzI4UHn7b6B37KwmjU2FOwAAAAAAAKDn3FXh7i/8hb+QRx55JK+88ko+8IEP5IknnnjLX0+Sj3zkI/nIRz6Sp556Kj/+4z+en/7pn27P/wXA6VGdLxbu3uLENNytxdpmkuTi2dafIV+YGkttYy97+4ct/9n95KPPvZDhwUr+9Nc8WnYUOm3tavFOPVxuDgAAAAAAAIAWG7qbL/rwhz+cD3/4w3f960nyrne9K5/4xCdOlg7oLZMLyf52sruWjE2XnYZTbnHluHDX+oW7+amxJMm19Z088sBEy39+P7i8vJ7nFm/kT/yhhzJXHS07Dp12q3Bn4Q4AAAAAAADoLW05KQtwW9X54t24Vm4OesLiykaS5OJcOwp3RUHMWdn79+xzLyZJnnn6fMlJKMXaq8Vr4Q4AAAAAAADoMQp3QOdMLhTv+lK5OegJi7XNjAwOtGWBbmG6WLhbWt1t+c/uB5u7+/kHn3k1X7YwmT98/oGy41AGC3cAAAAAAABAj1K4Azqneq54N5bLzUFPuFLbzPnZiQwOVFr+s49Pylq4uz+//NmrWd/dzzNPn0+l0vq/PpwCxwt3k+8oNwcAAAAAAABAiyncAZ1TtXBHa+ztH+alG1u50IZzskmyoHB335rNZn7mEy+kOjqUP/ke50T71trVZGg8GbdwCAAAAAAAAPQWhTugcybni3dD4Y6TeenGVg4Om7l4ttqWn3/rpKzC3T37zEs383tL6/kP3vNwqqNDZcehLOuvFedkLRwCAAAAAAAAPUbhDuicWwt3TspyMldqm0mSi2fbs3A3NjyY6fHhLK0q3N2rj37ixSTJM0+fLzkJpVp7tSjcAQAAAAAAAPQYhTugc0YmktEpC3ec2OLKRpLkYptOyibJ/NSok7L36PrGbv7pv13Key88mHctTJYdh7LsbiQ7q8mUk8IAAAAAAABA71G4AzqrOp9sXCs7Bafc4srxwl17TsomyfzUWJbXdtNsNtv2Gb3m73/6lewdHOaD1u362/prxWvhDgAAAAAAAOhBCndAZ00uJOsW7jiZK7XNzEwM58EzI237jIWpsWw3DrK2s9+2z+glB4fN/OwnX8xcdTR/9A8ulB2HMq29WrwKdwAAAAAAAEAPUrgDOqt6LtmpJw2nOrl/i7WNXGjjOdkkWZgeSxJnZe/Sv7p0La/c3M6f+ZpHMzLktxd9be1q8TopCwAAAAAAAPQgfyIOdFb1aPlqY7ncHJxaq9uN1Db2cnGufedkk+KkbJIsrSrc3Y1nn3spA5Xke973WNlRKJuFOwAAAAAAAKCHKdwBnTU5X7wKd9ynK7XNJMnFs+1duLtVuLNw97ZevrGVX/39a/mWL5/PwzPjZcehbLcW7hTuAAAAAAAAgN6jcAd01vHC3fpSuTk4tRZXNpIkF9t9UvaocLds4e5t/ewnX0qzmXzw6fNlR6EbrL2WDAwnE3NlJwEAAAAAAABoOYU7oLMs3HFCiyvHC3dtPik7PZokWV5XuHsrO42D/P1Pv5zzsxP5I08oWJHipOzUO5IBv80EAAAAAAAAeo8/CQU6y8IdJ3SltplKJTk/O9HWz5k7M5qhgUqWVnfb+jmn3f/926/lxuZennnf+QwMVMqOQzdYu5pMPVx2CgAAAAAAAIC2ULgDOsvCHSf0hZWNPDwznrHhwbZ+zsBAJecmR7O8ZuHurTz73EsZHRrId331I2VHoRs0dpKtWjL1UNlJAAAAAAAAANpC4Q7orLGZZHBU4Y77cnjYzAvXN9t+TvbY/PRYlhTu7uh3rq7mN168mW//yofywJmRsuPQDdZfK16FOwAAAAAAAKBHKdwBnVWpJNV5J2W5L6+t7WSncZiLc2c68nnzk2OpbeymcXDYkc87bZ597qUkyTNPny85CV1j7WrxOikLAAAAAAAA9CiFO6DzJuct3HFfFlc2kiSPn+1M4W5heizNZlLb2O3I550mazuN/KPffDXvfng6X/nIdNlx6Ba3CncW7gAAAAAAAIDepHAHdF51PtlcSQ4Pyk7CKbO4spkkuTDXoZOyU2NJkqVVZ2Xf6B9+5tVsNw7ywafPp1KplB2HbrH2avFOKtwBAAAAAAAAvUnhDui8yYWkeViU7uAeHC/cXezYwt1okmR5TeHu9ZrNZj763IuZGhvKt3+lYhWvY+EOAAAAAAAA6HEKd0DnVReKd32p3BycOou1zYwPD2bhaHmu3Szc3d5zizfy/LWNfNdXP5rxkcGy49BN1q8mlYFiyRQAAAAAAACgByncAZ03eVTE2LhWbg5OncWVzbxz7kwGBjpzwvRW4W5ttyOfd1o8+9yLSZI/+/RjJSeh66xdLUrVg0NlJwEAAAAAAABoC4U7oPOOF+42LNxx93YaB7m6ut2xc7JJbi3pOSn7RdfWdvLPfmcpf+SJuTx+tlp2HLrN2lXnZAEAAAAAAICepnAHdF71XPGuL5eb49jHfzL5pz9UdgrexgvXN9NsJo/Pda5wd2Z0KJOjQwp3r/Pz/+bl7B82sy834QAAIABJREFU88zT58uOQrc5aBSnwhXuAAAAAAAAgB6mcAd03mQXLdw1m8mv/+3kUz+VvPIbZafhLSyubCZJLnRw4S5J5qfHsqRwlyTZPzjMz33ypSxMjeUDX36u7Dh0m43lJM1k6uGykwAAAAAAAAC0jcId0HlnziaVgWIJqWw3FpOt68U///W/VW4W3tLiykaS5OJcZ8+YLkyNZXlV4S5JPva717K0tpPvee9jGRr0WwjeYO1q8Vq4AwAAAAAAAHqYPy0HOm9gsCjdbXTBSdmXnive0enk8/9ncv0L5ebhjhZrJS3cTY1lc+8g6zuNjn5uN3r2uRczNFDJn3nvo2VHoRutvVq8CncAAAAAAABAD1O4A8pRnU/Wu6Bw9/Ini/eP/40kzeQT/1OpcbizxZXNzFVHMzU23NHPnZ8aTZIs9/lZ2cWVjXz8+Vr+6B9cyPzUWNlx6EYW7gAAAAAAAIA+oHAHlGNyoVi4azbLzfHyp5KpR5J3f3fy8Fcnn/25ZGOl3Ey8SbPZzOLKRi52eN0uSRami3LZ8tpuxz+7m/zsJ19Kkjzz9PmSk9C1FO4AAAAAAACAPqBwB5SjOp8c7CY79fIybNeTld9NHn1vUqkkX/cDyf5O8qmfKi8Tt3Vjcy9rO/t5vITC3fGa29Jq/y7cbe8d5Bc//XKeOFfN0xcfLDsO3eq4cDf5jnJzAAAAAAAAALSRwh1Qjup88ZZ5VvaVTxfvo+8r3i//9uSBC0XhbnejvFy8yWJtM0lyYa6Ehbvjwl0fn5T9x5+7mrWd/TzzvsdSqVTKjkO3WruanDmbDI2WnQQA4P9n796j3Lzre99/Hl1GmplHki9jSZ6LTRzPJCRO7MTxJckGAk2BAiEppaUUctru0k0L9LL22adnnd2zW2jP7jrdp2ud0hbohXazNwn7AN00CZdSoJAAIR4nIXZi5zLjjGPPxSPN+DLSMxdJIz3nj2c0wfHYHmn06JFG79darB/MPHp+X0isdK1+1ucLAAAAAAAAAK4hcAfAG5Gkc1qT3s0wOuic25YCdz6/dMdvOa17zzzg3Vy4xMiUE4Dc0WXW/e5XV8q2buDugcFTag/69Z69vV6PgkaWmWCdLAAAAAAAAAAAAIB1j8AdAG80QsPd6CEp2CEldr36sz2/JHV0SU98SiouejcbLlJuuNvhwUrZzZ1t8hmtu1L26OgFPTs2o/tu6VE0HPR6HDSqUknKTkjRHq8nAQAAAAAAAAAAAABXEbgD4A2vG+6Ki9LY01LPXsn/EyGiYLt04MPSzGnp+Ye8mQ2XGJmaVcBnqG9TR93vDvh92hIJtWzD3ecPnZIkffDgNo8nQUObnZJKizTcAQAAAAAAAAAAAFj3CNwB8IbXDXfp41JhVurbf+nv9n3Iab57/M8l267/bLjEyJSlbZs6FPR784+tZDSsVCbnyd1eOj+b11ePTujWbRt0Y3fM63HQyDLjzkngDgAAAAAAAAAAAMA6R+AOgDfKgTuvGu5GDztn34FLf9exSbr1f5Emn5NGvlffuXCJxWJJp8/NebJOtiwRDWvKyqlYaq0A5j8+PabcYkn3377d61HQ6DITzhkhcAcAAAAAAAAAAABgfSNwB8AbwbAU3iBZaW/uHx10zt59K//+4Eckwy89/sn6zYQVjZ2fV6Foa8cW07MZkrGwiiVb01brtNyVSrYeHDylTZ1t+pldW70eB42uHLij4Q4AAAAAAAAAAADAOkfgDoB3Ikkp61XD3aDUdZ3TZreSjdulG39WGnlUOnO0rqPhYiPTliTpmi5vG+4kaXJmwbMZ6u2HJ6b1ytk5/cJtfQoH/V6Pg0aXLQfuerydAwAAAAAAAAAAAABcRuAOgHfMuGSl6n9v5ox04bTUt//Kz9352875+F+4PxMua2RqVpK0oxECd5nWCdz987EzkqT37+/zeBI0heWGO9oQAQAAAAAAAAAAAKxvBO4AeMdMSrmMlJ+r773ldbJ9B6783Nbd0o43S8f/STr/iutjYWUj00uBOy9Xyi4F7lItFLgbSlna2BHUtk0dXo+CZpCZcNaEt3kXjAUAAAAAAAAAAACAeiBwB8A7kYRzWnVeKzt62DmvFriTpDt/R7KL0hOfdncmXNbIlKVIKKAus82zGZKxkKTWCdzZtq2hVFb9iYgMw/B6HDSDzDjrZAEAAAAAAAAAAAC0BAJ3ALxjJp0zW+e1sqODUvtGafPOqz+74y4pebP0zOeluXNuT4YVjEzNaseWTk+DX8srZWdyns1QT6lMTtmFRfXHvWsVRBOxbafhLtrt9SQAAAAAAAAAAAAA4DoCdwC8E1kK3NWz4a4wL5056rTb+VbxFWgYTstdYU568rPuz4eLWLlFpbM5T9fJSlIkHFRnm79lGu6G01lJ0kAi4vEkaArz56XFBQJ3AAAAAAAAAAAAAFoCgTsA3jHLK2XT9btz4hmpVJD69q/+MzfcJ8W2SYN/7QT2UDcnp2YlSdd0dXo8iZSIhTXZIoG7oZQlSepP0HCHVciMOyeBOwAAAAAAAAAAAAAtgMAdAO+UG+6ydWy4Gx10zr4Dq/+MPyDd8TFp7qx05EF35sKKRqad4NeOLQ0QuIuElZppjcDdiaWGu/44DXdYhcyEcxK4AwAAAAAAAAAAANACCNwB8I4Zd04rVb87Rw9Lhl/qvrWyz93yQal9o/Sjv5JKRXdmwyVGlhrudnR537SWjIWVzS1qNrfo9SiuG0pZ2tgRVJfZ5vUoaAYE7gAAAAAAAAAAAAC0EAJ3ALwTikqB9vo13Nm203C39WapraOyz7Z1Svt+XTp/Unrhq+7Mh0uMTDuBu9d1VfjXywWJaFiSlFrna2Vt29ZQKqv+eESGYXg9DprBcuCux9s5AAAAAAAAAAAAAKAOCNyhps5aOX3lx2N6cTLj9ShoBoYhRRL1a7g7N+Ksha1knexP2v/vpEBYevyTTngPrhuZstQdC6ujLeD1KEpGQ5KkyXUeuEtnc8ouLKo/4X2rIJoEDXcAAAAAAAAAAAAAWgiBO9TU+IV5/fsvHdV3X0x7PQqahZmsX8Pd6KBzVhu4M7dIez4gTfxYeuWHtZsLK7JtWyenZ7VjS2MEv5Kx1mi4G0plJUkDiYjHk6BpZMalNtNpLQUAAAAAAAAAAACAdY7AHWrKDDktVNbCoseToGlEEtLctFQsuH/X6UPOWW3gTpJu/6hk+JyWO7gqlclpLl/UNV2dXo8iSYovrZSdnMl5PIm7hlOWJKk/3hhBRzSBzITTbscKYgAAAAAAAAAAAAAtgMAdasoMLwXucgTusEpm0jlnp9y/a/SwFO2VYj3Vv2PztdLr75FOfFtKHa/dbLjEyJQT/NqxpTECd8loazTcDaedhrt+Gu6wWuXAHQAAAAAAAAAAAAC0AAJ3qKloOCiJhjtUIJJwTrfXys5fkKZekPr2r/1dd/6Oc/7oL9f+riYzM1+HJsIlI9OzktQwK2W3REIyjPUfuBtKWdrQEVSX2eb1KGgGCxkpn5UiBO4AAAAAAAAAAAAAtAYCd6ipUMCngM9QloY7rJa5FLizUu7eM/aUc65lnWxZz17pdW+QnvuyNDO29vc1iS8MntbuT3xL/++3h1Qq2a7fNzK1FLhrkJWyQb9PXWZIk+s4cGfbtoZTWQ3EIzJYD4rVyEw4Jw13AAAAAAAAAAAAAFoEgTvUlGEYMsMBGu6weuWVsm433I0OOue2GgTuJKflrrQoHfpMbd7XBL5w+JQk6ZP/Oqzf+h/PaD5fdPW+kWlLbQGfuje0u3pPJZLRsFIz6zdwl87mlFlYVH+iMVoF0QSyBO4AAAAAAAAAAAAAtBYCd6g5MxSQRcMdVitSp4a70UEp2CEldtXmfTvvluI3SE9/zllXu86dSFs6Np7RPbu79c6bturrz53Rz//Nj3RmZt61O0emZnXN5k75fY3TtJaIhpXO5urS8OeFoVRWktQfJ3CHVVpuuOvxdg4AAAAAAAAAAAAAqBMCd6g5MxRQdqHg9RhoFvVouCsuOitle/ZK/mBt3mkY0h2/LeUt6al/qM07G9gjR8YlSb+4r09/+f5b9Lt39+vYeEbv/qvH9czp8zW/L7dY1Nj5OV3TIOtkyxLRkBZLtqZnc16P4orhlCVJGkhEPJ4ETYOVsgAAAAAAAAAAAABaDIE71FwkTMMdKtCxWfIF3G24Sx+XCrNS3/7avnfXzzmtToN/LRXW75pR27b10JEJxSMhHdyxWT6fod+9e0Cf+qVblV0o6H1/e0gPPTNe0ztPn51TyZZ2bGmswF0yGpYkpTPrNHCXXmq4I3CH1cos/dmn4Q4AAAAAAAAAAABAiyBwh5pzGu4I3GGVfD6pM+5u4G70sHP2HajtewNt0sGPOLM/+8XavruBPDN6QafPzendu7svWu/6zpu36ssfvkObOtr0u188ov/yzRdrtmr15alZSdKOLY212jQRcwJ3kzPrM2A5nLK0oSOoLrPN61HQLDITkj8kdWzyehIAAAAAAAAAAAAAqAsCd6i5SDio3GJJ+cWS16OgWUQSUtbNwN2gc/buq/279/6yFIpJP/oLqbQ+/55/5IizMvLePZc2WN3UG9MjH7tTu/s26NOPvqwPP/B0TRouT06XA3eN2XA3mVl/gTvbtjWUymogHpFhGFf/ACA5gbtot7NmGwAAAAAAAAAAAABaAIE71JwZDkiSZlkri9Uyk05LnF2bdrRLjA5KXde508AUikj7/q109oT00jdq/36PLRZL+tqzE9qxpVO7eqIrPhOPhvXFf3dQ9+7p1refT+m9n/mRxs7PrenekSlLkrSjq8ECd0sNd6l1GLhLZ3PKLCxqZ6KxWgXR4DLjTuAOAAAAAAAAAAAAAFoEgTvUXCTkBO5q0XKFFmHGpVJBmjtX+3dnzkgXTkt9+2v/7rIDvyH525yWu3Xm8ZfPatrK697dPVdsPQsH/frz9+3R//a26/TiZFb3/tXjevKV6v96jkzPalNnmzZ0NNZq00Rk/a6UHU45IceBOIE7rFJ+Tpo/T+AOAAAAAAAAAAAAQEshcIeaM5cCd5mFgseToGlEks5pTdb+3eV1sn0Hav/uskhS2v2Lzl2nD7l3jwcefmZcknTvnqsHagzD0EffvFN/c/9ezReK+qW/O6QvPTVa1b0np2cbrt1OkqLtAYWDvnW5UnYolZUkDSQiHk+CppE945wE7gAAAAAAAAAAAAC0EAJ3qLnySllrgYY7rJKZcM6sG4G7w87pZuBOku74bUmG9Pgn3b2njubzRf3L8Unt7tug11UQfnvbjUn942/coXgkrN/7x2f1f33teRVLq18XfGEur3OzeV3TgIE7wzCUjIaVzuS8HqXmhtNOwx0rZbFqmQnnjPZ4OwcAAAAAAAAAAAAA1BGBO9ScyUpZVGq54S5V+3ePDkrtG6XNO2v/7p/U1S9d9w7ppW9IUy+5e1edfOeFlGbzRd23ina717qhO6qHP3anbtu+UZ/94Ul96L89uerWy5enZiVJO7Y0ZvArEQ2vy4a74VRWGzqC2mKGvB4FzWI5cEfDHQAAAAAAAAAAAIDWQeAONRcJByURuEMFzKXAXa0b7grz0pmjUu9+yVeHr7s7f8c5f/SX7t9VBw8fGZfPkN51c3Vhmi4zpAd//YDeu7dX33tpSu/59I906uzsVT93crocuGu8hjtJSsbCmpkvaKFQ9HqUmrFtW0OprPrjpgzD8HocNIuMs3KawB0AAAAAAAAAAACAVkLgDjUXWVopm2WlLFYrsrRS1krX9r0TR6RSQdrm8jrZsm0HpL6D0rNflDJn6nOnS87P5vXoS1O6c2eXtkSqbzwLBfz6f957s37/Ha/Xy1OW7v3U43ri5bNX/MzIlLPadEcDrpSVpGQ0LEmanFk/LXdT2ZwyC4vqT0S8HgXNhJWyAAAAAAAAAAAAAFoQgTvUHCtlUbHOuHNaNW64Gx10zr46Be4kp+WumJcG/7p+d7rgG8fOaLFk6749aw/SGIahX3/jDv39L9+mxaKt+/9+UF8YPH3Z50emZuUzpG2bO9Z8txvi5cDdOlorO5RyQo4D8cZc44sGlZmQfAGpc4vXkwAAAAAAAAAAAABA3RC4Q82Zyw13BY8nQdMItEntm6RsqrbvHR2UDL/UfWtt33slA2+Xugakp/5BWsjU794ae/jIhEIBn956Y6Jm73zL9Ql95SN3qHtDu/7jPz2njz9yXIvF0iXPnZyeVd+mDoUC/prdXUvlhrvUOgrcDaezkkTDHSqTGZciWyVfY/5ZBQAAAAAAAAAAAAA3ELhDzUXKDXeslEUlIsnaNtzZthO423qz1FbHpjSfT7rjt6RcRnr6c/W7t4bGL8zr8MlzuvuGhCLhYE3fPZCI6KGP3qkD12zS5370in7lvz6pmblXw7nFkq2TZ2d1TYOuk5WkZMxZsbueAnflhrv+BA13qEBmwgncAQAAAAAAAAAAAEALIXCHmltuuGOlLCphJmrbcHduRJo7W991smU3v8/573PoM9Jivv73r9EjRyYkSffu7nbl/Zs62/T5Xzug9+/v0w9PTOtnP/24RqacwNfEhXnlF0va0dW4wa9EeaXsTM7jSWpnOJVVrD2oLWbI61HQLBbz0mxairrzPQEAAAAAAAAAAAAAjYrAHWquPeiX32fQcIfKRJJSYVbKZWvzvtFB5/QicBcISQd/U8pOSMf+sf73r9HDR8YVaw/qruvirt3RFvDpT372Jn38nhv0ytlZ3fepx/WD4SmNTM9KknZsadyGu3hkfa2UtW1bw2lLAwlThmF4PQ6aRbmRNNrj7RwAAAAAAAAAAAAAUGcE7lBzhmHIDAVk0XCHSpgJ56xVy52XgTtJ2vurUltEevwvpFLJmxmq8NJkVi9OZvWOm7aqLeDuPyIMw9Cv3HmNPver+2VL+pX/+qQ+9d0TkqQdDbxSti3g0+bONk2uk8DdVDanmfmC+hMRr0dBM8k4TZg03AEAAAAAAAAAAABoNQTu4AoCd6hYJOmcVo0Cd6cHpWivFPOofal9g7T3l6WpF6QT3/Zmhio8fGRcknTvnvqFaN44sEUPffRObdvUocOvnJMk7djSuCtlJWet7OTM+gjcDaeddb798cb+3xwNJuN8VxC4AwAAAAAAAAAAANBqCNzBFZFwQFlWyqIS5Ya78prCtZi/4ATd+vav/V1rcfAjki/gtNw1gVLJ1sNHJrQ1Ftb+122q693XbjH10Efu1F3XbVF/3FQiGqrr/ZVKxsJKZxdk27bXo6zZUMpZ4zxAwx0qsdxwx0pZAAAAAAAAAAAAAK0l4PUAWJ/MUEDT1pzXY6CZ1HKl7NhTzunVOtmyWI900y9IR7/gzNR7m7fzXMWPT5/X+IV5ffiNO+TzGXW/P9YR1Od+db9KJVuGUf/7K5GIhlUo2jo3m9dms7HDgVczlFpquEvQcIcKsFIWAAAAAAAAAAAAQIui4Q6uMMMBWbmC12OgmSyvlK1Bw93ooHN63XAnSXf8lnM+/klv51iFh5bXyXrbWOVF2K9SyWhYkjSZaf61sifSWcXag9rS5MFB1FlmXJLx6nc3AAAAAAAAAAAAALQIAndwRSQc1EKhpEKx5PUoaBa1bLgbHZSCHVLyprW/a60SN0j9b5Ve+Kp09mWvp7msQrGkrz97Rv1xU6/fymrRq0nGnHBaqskDd7ZtayhlaSBhNnyrIBpMZkIy45I/6PUkAAAAAAAAAAAAAFBXBO7gCjPkbCuezS16PAmaRsiU2sy1N9wVF6Xxp6WevY0TBLnzdyTZ0uG/9XqSy/rB8JTOzxV03y09BK9WIV5uuJvJeTzJ2kxlc5qZL2hnnJAlKpSZYJ0sAAAAAAAAAAAAgJZE4A6uiISdwF12gcAdKmAm1t5wlz4u5a3GWCdbtv1OKRyTUse9nuSyHnpmQpL07t0EaFZjvayUHU5bkqSBhOnxJGgqpaKUnZSi3q6fBgAAAAAAAAAAAAAvELiDK8oNdxYNd6hEJClZawzcjR52zr4Da5+nVgxDivZKM2NeT7Ki2dyivv18Snu3b1Tfpg6vx2kK5cBduskDd0OprCRpIEHDHSpgpSW7SMMdAAAAAAAAAAAAgJZE4A6uKAfuaLhDRcyENH9OWsxX/47RQefs3VebmWol1iNlxqVSyetJLvHt51OaLxR13x7CM6u1oSOotoBv3TTc9cdpuEMFMk4jJoE7AAAAAAAAAAAAAK2IwB1cYYbLDXcFjydBU4kknXMtLXejg1LXgNSxqTYz1UqsVyrmpblprye5xMNHxuX3GXrHTVu9HqVpGIahZDSsyZkmD9ylsoq1B7UlEvJ6FDSTzLhzslIWAAAAAAAAAAAAQAsicAdXRMM03KEKZtw5qw3cZc5IF0431jrZsnIwpcHWyp61cvr+8LTe2N+lzSahq0oko2GlmrjhzrZtDaUs9cdNGYbh9ThoJjTcAQAAAAAAAAAAAGhhBO7gCjMUlCRZOQJ3qIC51HCXnazu82OHnbMRA3exXucsN0M1iK8/d0bFkq1799BUVal4NKTzcwUtFIpej1KVKSunmfmC+hMRr0dBs1luuCNwBwAAAAAAAAAAAKD1ELiDK5ZXytJwh0pEEs5pVRm4Oz3onI0YuGvQhruHj0yoPejXT9+Q8HqUppOMhiVJU9mcx5NUZzhlSZIGEqbHk6DplBvuIqyhBgAAAAAAAAAAANB6CNzBFWZoKXBHwx0qsdxwV+VK2dFBqX2jtHln7WaqlXLDXQMF7kbPzenpU+f11hsT6lz6M4vVS8acwN1kk66VHU5lJUn9cRruUKHMhNS+SQq2ez0JAAAAAAAAAAAAANQdgTu4IrLUcJel4Q6ViCwF7qwqAneFeenMUal3v+RrwK+28urFBlop+8hRp6Xq3j2shaxGYqnhbnKmOQN3Q2ka7lClzPirrZ0AAAAAAAAAAAAA0GIaMJWC9aDccEfgDhVp3yj526oL3E0ckUoFaVsDrpOVpEBI6ow3TMOdbdt66JlxbewI6g39W7wepymVG+5STdxwF2sPaksk5PUoaCa2LWXPvBoiBgAAAAAAAAAAAIAWQ+AOruho88tnSFau4PUoaCaGIZkJKTtZ+WdHB52zr0EDd5KzVnamMRruXjiT1XDa0jtv3qqgn38UVCMRad6GO9u2NZSy1B83ZRiG1+OgmcydlYp5AncAAAAAAAAAAAAAWhYpC7jCMAyZoYCsHA13qJAZr67hbvSwZPil7ltrP1OtxHoka1Iqev/n4uEjTvDvvj2shaxWPOo0w002YcPdlJXTzHxB/YmI16Og2ZTXYrNSFgAAAAAAAAAAAECLInAH10TCQVmslEWlzKRkpaVScfWfsW2n4W7rzVJbh3uzrVW0V7JLzjpGD5VKth45OqGeDe26ddtGT2dpZuGgXxs7gkpncl6PUrETKUuS1B83PZ4ETScz4Zw03AEAAAAAAAAAAABoUQTu4BozFFCWhjtUKpKQ7KKztnC1zo1Ic9ONvU5WchruJGlmzNMxDr9yTmdmFnTvnm75fKwTXYtENNyUDXdDqawkaYCGO1RqueGOwB0AAAAAAAAAAACA1kTgDq4xwwFlabhDpcykc2YnV/+Z0UHn7Ntf+3lqKdbrnOXAikeW18newkrItUrGnMCdbdtej1KRobTTcDeQoOEOFVpuuOP7AwAAAAAAAAAAAEBrInAH15ihACtlUblIwjmt1Oo/sxy4O1j7eWopuhS487DhLrdY1Deem9T1yQjtZjWQjIaVXyzpwlzB61EqciJlKRoOaEsk5PUoaDbLgbut3s4BAAAAAAAAAAAAAB4hcAfXmOGA5gtFLRZLXo+CZlJuuKsocHfYCbPFGrxxqQFWyj720pRm5gu029VIPBqWpKZaK2vbtobSWQ0kIjIMVgqjQplxKRSVQgR2AQAAAAAAAAAAALQmAndwTTQckCTN5ooeT4KmUm64W+1K2fkLUvqFxl8nK0lmQvIFPF0p+/ARp53qnt3dns2wniSXAnepJgrcTVt5XZgrqJ91sqhGZkKK8v0BAAAAAAAAAAAAoHURuINrzJATuMvmmmvVIjxmVrhSduwpSbbUd8C1kWrG55ci3Z413GUXCvrOCyntv2aTeja0ezLDepOMOStZmylwN5zKSpL64zSUoUK2LWXOELgDAAAAAAAAAAAA0NII3ME1ZigoSbJyix5PgqbSGZdkrL7hbnTQOZuh4U5y1sp61HD3L8dTyi2WdO8ewjK1kiivlJ3JeTzJ6g0tBe4GEgTuUKGFGakwS+AOAAAAAAAAAAAAQEsjcAfXmEsrZbMLBO5QAX9A6uxafcPd6KAU7JCSN7k7V63EeqW5s1J+ru5XP3xkXEG/oXfetLXud69X5ZWyk83UcJe2JImVsqhcxllJrWiPt3MAAAAAAAAAAAAAgIcI3ME1kaWVshaBO1TKTK6u4a64KI0/LfXslfxB9+eqhXJQpRxcqZN0dkGPn5jWmwbi2tDRVte717ONHW0K+o0mWylrKRoOKB4JeT0Kms1y4I6GOwAAAAAAAAAAAACti8AdXLPccMdKWVQqknAa7mz7ys+ln5fyVvOsk5WchjtJyozV9dqvP3tGJVusk60xn89QPBLW5ExzBO5s29ZQOqv+RESGYXg9DppNeR02DXcAAAAAAAAAAAAAWhiBO7gmEqbhDlUyk9LigpTLXPm50UHn7Dvg/ky1Ug6qzNQ3cPfQkQl1tvl19+sTdb23FSRjYaWzzRG4m7byujBX0ADrZFGNcsNdhLXUAAAAAAAAAAAAAFoXgTu4xiyvlM0VPJ4ETSeyFArLpq78XDlw17vP3XlqqdxwNzNetytPTs/q6OgFve3GpNrb/HW7t1Uko2FNW3nlF0tej3JVw6msJKk/HvF4EjSl5YY7mjIBAAAAAAAAAAAAtC4Cd3ANDXeompl0Tmvyys+NDkpdA1LHJvdnqhUPVso+csRppbr3FtZAuiERDUtSU7SGr1HTAAAgAElEQVTcDactSVI/DXeoRmZCCrRL7Ru9ngQAAAAAAAAAAAAAPEPgDq4xQ0FJUobAHSplxp3zSg13mTPShdNS3/76zFQr7RudwEqdVsratq2Hj4yry2zTnddursudrSYZC0mSUpnGD9wNLTXcDSRouEMVsmecdjvD8HoSAAAAAAAAAAAAAPAMgTu4xiw33OUI3KFCkVU03I0dds6+g+7PU0uG4bTc1Wml7LHxjEamZ/Wum7sV8POV74Zyw93kTM7jSa5uOGUpGg4oHgl5PQqaUWacdbIAAAAAAAAAAAAAWh7pC7imI+iXYbBSFlUwE86ZvULgbrQcuDvg/jy1Futxgiu27fpVDx1xgn337iEk45blwF2DN9zZtq2hdFb9iYgMGspQqZwlLcxIUVZTAwAAAAAAAAAAAGhtBO7gGp/PkBkK0HCHyi033F1hpezpQ8561s076zNTLUV7pfxSeMVFxZKtrx6d0PbNHdrTt8HVu1pZcilwl27wwN20ldeFuYIGEqbXo6AZZc84Jw13AAAAAAAAAAAAAFocgTu4KhIKKEvgDpUKtkuh2OUDd4V56cxRqXe/5GvCr7HYUkPUzJir1xwaOat0Nqd7d3fTaOaiZKw5Gu6G01lJ0s54xONJ0JQyS2uwCdwBAAAAAAAAAAAAaHFNmFRBMzHDAVkLBa/HQDOKJKTsZQJ3E0ekUkHq21/fmWol1uuc5QCLSx56xnn/u/ewAtJN4aBfsfagJmcaPHCXsiSJhjtUJzPhnATuAAAAAAAAAAAAALQ4AndwFStlUTUzIVmTK/9udNA5tx2s3zy1FHW/4W6hUNQ3j01qV09UO+MErNyWiIaUavCGu6GU03A3kKDhDlWg4Q4AAAAAAAAAAAAAJBG4g8vMcFDZBQJ3qIKZkBZmnPWxrzV6WDL8Uvet9Z+rFsoNdy4G7r73YlrZ3KLu3U27XT0komFNZhZk27bXo1zWcNpSJBxQPBLyehQ0o+WGO75TAAAAAAAAAAAAALQ2AndwVSQU0Fy+qGKpcUMoaFCRpHNar1kra9tOw93Wm6W2jvrPVQvlwIqLK2UfPjIhw5Du2U0bVT0ko2EtFErKNGjA2LZtDaeyGkhEZBiG1+OgGWXOSL6g1NHl9SQAAAAAAAAAAAAA4CkCd3BVJByQJNbKonJmwjmzrwncnRuR5qalvgP1n6lWQqYU3iDNuBO4m5kv6LsvpnX7js1KxsKu3IGLlf93btS1smdn8zo/V1A/64VRrcy4FN0q+fg/HQEAAAAAAAAAAAC0Nv6/pnCVGSJwhyotN9xNXvzz0UHn7Ntf33lqLdYrZdxZKfsvxyaVL5Z07x7a7eolEXUCd5MzjRm4G0plJUn9iYjHk6BpZSZYJwsAAAAAAAAAAAAAInAHl5nlhrsGXbOIBlZuuLPSF/98OXDXxA13khNcmRmXSqWav/qhI+Nq8/v09l1ba/5urCxZDtw1aMPdcMqSJA0kaLhDFQoLTrNolBAvAAAAAAAAAAAAABC4g6tebbgreDwJmk654S772oa7w1K012mIa2axXqlUkGanavrayZkFPTFyVm++foti7cGavhuXV264SzVow91weqnhLk7DHaqQPeOcBO4AAAAAAAAAAAAAgMAd3BVZarjL0HCHSi033P1E4G7+gpR+ofnXyUpSbGk1Y43Xyn7t2QnZtnTfHlY/1lMiFpLUuA13QylLkXBAiWjI61HQjDITzslKWQAAAAAAAAAAAAAgcAd3mSGnYYuVsqhYOCb5Q1I29erPxp+SZDf/OlnJaemTpJnaBu4eOjKuSCigN18fr+l7cWVdnSEFfIZSmZzXo6zoRNpSf9yUYRhej4JmVA7cRVhTDQAAAAAAAAAAAAAE7uCqcsOdlSNwhwoZhhRJXNxwd3rQOddFw105cDdes1eeSFs6Np7R23clFQ76a/ZeXJ3PZygeCSnVgA1301ZO52bzGkiwThZVyix9T9FwBwAAAAAAAAAAAAAE7uAusxy4o+EO1TCTFzfcjQ5KgXYpeZN3M9XK8krZ2gXuHjnivOu+WwjFeCERCzfkStmhVFaS1E/gDtVaXinb7e0cAAAAAAAAAAAAANAACNzBVZGQE7jL0nCHakQS0uyUVFx0/jX+tNSzV/IHvZ5s7SLdkoyarZS1bVsPH51QPBLSwR2ba/JOVCYRCWvayqlQLHk9ykVOpC1JUn/c9HgSNK3shGT4JDPh9SQAAAAAAAAAAAAA4DkCd3AVDXdYEzMpyXZCd+nnpbwlbTvg9VS1EWiTzHjNAnc/Pn1ep87O6V03d8vvM2ryTlQmGQvLtqWpbM7rUS5SbrhjpSyqlplwvo/9Aa8nAQAAAAAAAAAAAADPEbiDq8xyw91CweNJ0JQiS21KVspZJytJfeskcCdJsd6arZR98NBpSdL79vXV5H2oXCIaliSlGmyt7FDKUiQcUCIa8noUNKvMBOtkAQAAAAAAAAAAAGAJgTu4qrMtIMOQLFbKohpm0jmtlDR62Pn3vfu8m6fWoj1SdlIqri2Qem42r689e0b7X7dJ1yVpMfNKMuYE2hotcHcibak/bsowaD5EFYoF53uKwB0AAAAAAAAAAAAASCJwB5f5fIbMtgCBO1QnshS4y05Ko4ekrgGpY5O3M9VSrFeS7bRHrcGXnhpVvljSB2/fXpu5UJVyw93kTOME7qatnM7N5lkni+pZKUm2ExAGAAAAAAAAAAAAABC4g/vMcEDZBQJ3qIIZd84zR6ULp6W+/d7OU2uxXudcw1rZUsnWg4On1GW26e03Jms0GKqRLAfuMjmPJ3nVcMqSJO2Mmx5PgqZVDgRHt3o7BwAAAAAAAAAAAAA0CAJ3cJ0ZouEOVSqvlH3xa87Zd9C7WdxQboyaqT5w99jwlEbPzet9+/rUFuAr3UvlhrtGWik7nM5KEg13qF45EEzDHQAAAAAAAAAAAABIInCHOjDDAVk03KEanV2S4VtaaSip74C389RaueFuZrTqVzzwxCn5DOn9+7fVaChUqzMUUCQUaKiVskMpAndYo+WGu25v5wAAAAAAAAAAAACABkHgDq4zQwFlFwpej4Fm5PNLnUtrZds3Spt3ejtPrZUbo6pcKTt6bk7ffSmtt1yfUO/GjhoOhmolYmGlso0TuBtOWYqEAkpEQ16PgmZF4A4AAAAAAAAAAAAALkLgDq6LhAOazRdVLNlej4JmFEk4Z+9+ybfOvrLMhOQLVr1S9guHT8u2pftv317jwVCtZDSsVAM13A2nLfUnTBmG4fUoaFblwF1kq7dzAAAAAAAAAAAAAECDWGfpFTQiMxSQJM3mWSuLKphJ5+zb7+0cbvD5pOhWKTNW8Udzi0V98clRbd/coTfs7HJhOFQjEQ1rNl9siFbPs1ZO52bz6o+zThZrkJmQOrdIAVoSAQAAAAAAAAAAAEAicIc6iISDkiRrgcAdqlBuuOs74O0cbon2SjOVB+6+eWxS52bz+sCBbfL5aC9rFMmYE0pKZbxvuRtKWZKk/oTp8SRoapkJ1skCAAAAAAAAAAAAwE8gcAfXlRvurByBO1ThxvdIN9y3PhvuJCnWK82fl/JzFX3s80+cUlvAp5/f2+fSYKhGIhqWJE3O5DyeRBpOZyVJAwka7lClUknKTkjRHq8nAQAAAAAAAAAAAICGEfB6AKx/kbDzt1mWhjtU49o3O/9ar2JLQZbMuNTVv6qPPD+R0VOnzuvnbu3Vxs42F4dDpZYDdw3QcDdMwx3WanZKKi1Kka1eTwIAAAAAAAAAAAAADYOGO7iOhjvgCsrNUTOjq/7IA4OnJEn3377djYmwBsmlwF1jrJTNKhIKLM8EVCwz7pyslAUAAAAAAAAAAACAZQTu4DpzueGu4PEkQAOK9TrnzPiqHs8uFPTQM+Pa1RPV7t6Yi4OhGslY4wTuTqQt7UyYMgzD61HQrDITzslKWQAAAAAAAAAAAABYRuAOrltuuGOlLHCpcuAus7rA3T89M665fFH3H9xOkKoBdZkh+QxpcsbbwN1ZK6ezs3kNxCOezoEmtxy4o+EOAAAAAAAAAAAAAMoI3MF1kXBQEitlgRUtr5Qdu+qjtm3r80+cUiQc0Lt30zjViPw+Q1siIc8b7oZSliSpP2F6OgeaXJaGOwAAAAAAAAAAAAB4LQJ3cF1keaUsgTvgEu0bpWDHqgJ3gyfPaTht6ef39qm9zV+H4VCNZDSsSY8DdyfSWUlSf4KGO6zBcsPdVm/nAAAAAAAAAAAAAIAGQuAOrlteKUvDHXApw3DWyq5ipewDh05Jkj5wcJvbU2ENEtGwprI5FUu2ZzOUG+4GaLjDWmQmpPAGqa3T60kAAAAAAAAAAAAAoGEQuIPrzKWGO4uGO2Bl0R5pZlyyLx/QSmcX9M1jk7pz52Zdu4UQVSNLxsIq2dK0lfNshuF0VpFQQMlo2LMZsA5kxlknCwAAAAAAAAAAAACvQeAOrutsW1opmyt4PAnQoGI9UmFWmj9/2Ue+eHhUiyVb9x/cXsfBUI3EUshtcsa7tbLDKUs7E6YMw/BsBjQ523Ya7qLdXk8CAAAAAAAAAAAAAA2FwB1c5/cZ6mzzK0vDHbCyaK9zXmat7GKxpC8cPq1ENKS7X5+o42CoRrlVbjLjTeDurJXT2dm8BuIRT+7HOjF/XlpckKJbvZ4EAAAAAAAAAAAAABoKgTvURSQclJUjcAesKLYUuJtZOXD3ry+mdWZmQb+0f7sCfr62G1254S7lUeBuOG1JkvoTrB7GGpQDwKyUBQAAAAAAAAAAAICLkNxAXZjhgCwa7oCVxZYCLZmxFX/9wKFT8vsM/eL+vjoOhWolY07g7qXJrCf3D6ece/sTNNxhDTITzslKWQAAAAAAAAAAAAC4CIE71IUZCtBwB1xOeaXszKWBu5PTs/rB8LTedmNiuTkNjW1HV6du7I7qS0+N6uUpq+73D6WcOwdouMNaELgDAAAAAAAAAAAAgBURuENdRGi4Ay6v3HC3wkrZBw+dkiR98OD2ek6ENfD5DP3RvbtUKNr6+CPHZdt2Xe8fTmcVCQWUJKCJtVgO3LFSFgAAAAAAAAAAAAB+EoE71IUZCsjKL6pUqm/wBGgKbZ1S+0Ypc3HgbqFQ1JefHtO1Wzp1+47NHg2HauzdvlHv3durHwxP65vHJut693DK0s6EKcMw6nov1hka7gAAAAAAAAAAAABgRQTuUBdmKCDblmbztNwBK4r2SjOjF/3oq0cnNDNf0P0HtxOeakL/+9uvVyQc0B9/7XnN1em776yV09nZvPrjrJPFGmXGpTZTCkW9ngQAAAAAAAAAAAAAGgqBO9RFJByUJFk5AnfAimK9UuaMVCot/+iBQ6fUHvTrPXt7PRwM1doSCenf//SAJmYW9OnvvVyXO4fTliRpIBGpy30Nz7al7/2JNPKo15M0n8yE025H2BcAAAAAAAAAAAAALkLgDnVhhgOSJGuBwB2woliPVCpIs2lJ0tHRCzo6NqP7bulWdCmwiuZz/8Htuj4Z0d9+f0Qnp2ddv284lZUk9RO4c2TGpcf+VPr+n3k9SfPJTEiRrV5PAQAAAAAAAAAAAAANh8Ad6iIScgJ3WRrugJVFe5xzZkyS024nSR88uN2riVADAb9Pf3TvLuWLJX3iq8dl27ar95Ub7lgpu2TymHNOPCOVit7O0kwWMlI+++r3EgAAAAAAAAAAAABgGYE71AUNd8BVxJbWxs6MaWauoEeOTujWbRt0Y3fM27mwZvuv2aSfvaVHj740pW8/n3L1rqFUVmYooK2xsKv3NI3Uc86Zt6SpF72dpZlkJpwz2u3tHAAAAAAAAAAAAADQgAjcoS7McsMdgTtgZeXAXWZcX356VLnFEu1268j/8TPXywwF9Edfe14LBfea1k6kLe2MmzIMw7U7mkq54U6Sxp70bo5mkxl3TgJ3AAAAAAAAAAAAAHAJAneoi+WGu1zB40mABrW0utG+MKYHB09rY0dQ77hpq8dDoVbi0bB+9+5+jZ2f12cefdmVO87N5jVt5TWQYJ3sssnnpI7Nzr8ncLd62TPOyUpZAAAAAAAAAAAAALgEgTvURTRMwx1wRdFuSYbOTrysk9Oz+oV9fQoH/V5PhRr65Ttep4GEqc889rJOn52r+fuHUllJ0kAiUvN3N6X8rHRuRHrdG6QN26Sxp7yeqHmwUhYAAAAAAAAAAAAALovAHerCDAUlSVaOwB2wIn9QiiSVTZ+SYUgf2M862fUm6PfpE+/epfxiSX/0teM1f/9w2pIk7YzTcCdJSj0vyZaSu6TefdLUi9L8Ba+nag7LK2VpuAMAAAAAAAAAAACA1yJwh7pYXilLwx1wWfnOrepYmNRdA1u0bXOH1+PABbdfu1n37O7Wd15I67svpmr67mEa7i6Wes45Ezc5gTtJmvixd/M0k8yE5A9JHZu8ngQAAAAAAAAAAAAAGg6BO9SFGVoK3NFwB1zWK4UN2qIZ3b9vq9ejwEW//47Xq6PNr0989XktFIo1e+9wypIZCmhrLFyzdza1yaXAXbnhTmKt7GplJqToVskwvJ4EAAAAAAAAAAAAABoOgTvURTlwlyVwB6wov1jSk+c75DNsvWkrf07Ws2QsrN/+qX6dOjunv/v+SM3eO5zOamfclEFIyjF5TGrf6KxFTd4k+duksSe9nqo5ZMZZJwsAAAAAAAAAAAAAl0HgDnXh9xnqaPMry0pZYEXfen5SL+c2SpL82QmPp4Hb/u2d1+jaLZ361KMnNHZ+bs3vOzeb17SV10DCrMF060CpJKWOS4ldTktbICRt3e0E7mzb6+kaW35Omj8vRbu9ngQAAAAAAAAAAAAAGhKBO9RNJByQtVDwegygIT1w6JTSRpfzHzLj3g4D17UFfPrEu3dpoVDSH3/t+TW/bziVlST1xyNrfte6cP6kVJh1mu3Kevc5QbJztWsVXJeyZ5yTwB0AAAAAAAAAAAAArIjAHerGDAVksVIWuMRwKqtDI+d0zbUDzg9mRr0dCHXxb/q79I6bkvqX4yk9NjS1pncNpS1JUj8Nd47UMedM7Hr1Z723OSdrZa8ss9SwyUpZAAAAAAAAAAAAAFgRgTvUjRkOymKlLHCJBw6dkiT91IG9zg9maLhrFb//zhvUHvTr448cV26xWPV7Tiw13A0kaLiTJE0+55yvbbiTCNxdzXLgjoY7AAAAAAAAAAAAAFgJgTvUTSQUUJaGO+Ais7lF/c8fj+v6ZES7r98p+YKslG0hPRva9bG37NTJ6Vn9/Q9PVv2eoZQlMxTQ1li4htM1scljki8gbbnu1Z/F+iQzQeDuasrfPwTuAAAAAAAAAAAAAGBFBO5QN+WVsrZtez0K0DAePjIhK7eo+2/fLsPnd0IuM2Nej4U6+tAbrtE1XZ36y389oYkL81W9Yzid1c64KcMwajxdk0odk7qukwKhV39mGE7L3eQxKT/n3WyNjpWyAAAAAAAAAAAAAHBFBO5QN2Y4INuWZvPVr00E1hPbtvXfn3hFZiig+/YshVtivQTuWkwo4Ncf3nOD5gtF/eevv1Dx58/N5jVt5dUfN12YrgnNn5dmRqXkrkt/13ubZBelM0fqP1ezyEw47YCdW7yeBAAAAAAAAAAAAAAaEoE71I0ZCkiSrAXWygKS9OPT5/XiZFbvubVHnUt/PhTrlRYuSPlZb4dDXd11XVxvvSGhrz93Ro+fmK7os8OprCRpIBFxY7TmkzrunIkVAnc9tzkna2UvLzMumUnJ5/d6EgAAAAAAAAAAAABoSATuUDfR8FLgLlfweBKgMXz+iVOSpA8e3P7qD8trHGfGPZgIXvpP77pBoYBPf/jIceUXS6v+3FDakiT1J2i4kyRNPuecyZsu/V33LZLha77A3dmXpa//B2l62P27MhPOamsAAAAAAAAAAAAAwIoI3KFuzKXAXZaGO0BnrZy+8dykDlyz6eJmslg5cDfqzWDwTN+mDn3krp06kbb0uR+dXPXnTiw13PXTcOeYPOacKwXuQqYUv1EafVKy7frOtRY/+gvpyb+TPnOn9P0/k4ouBdcX89JsmsAdAAAAAAAAAAAAAFwBgTvUjRkKSpKsHIE74EtPjSlfLOn+27df/ItYn3NmaLhrRR9+0w5t29ShT35nWKnMwqo+M5SyZIYC6o6FXZ6uSaSec1aidnat/Pve2yRrsrn+jI08JpkJaeN26bt/LP3tXdL407W/x5p0znLTJgAAAAAAAAAAAADgEgTuUDflhjuLhju0uGLJ1oODp9RlhvTWG5IX/5KVsi0tHPTrD++5QbP5ov7z119Y1WeG05Z2xk0ZhuHydE2gWJDSL0rJXZd/pnefczbLWtnzp6TzJ6WBt0sf/oH0xt+Tpl6SPnu39M3/KOVna3dXZsI5abgDAAAAAAAAAAAAgMsicIe6iYRYKQtI0mNDaY2dn9f79/epLfCar+HllbJj9R8MDeGnXp/QT10f1yNHJ3Ro5OwVnz0/m9e0lVN/3KzTdA1uelgq5lZeJ1u2HLh7qj4zrdXJx5xzx5ukYFh6y+9LH/6+1H2rdOhT0qcPSie+U5u7yq1/BO4AAAAAAAAAAAAA4LII3KFuyg13WVbKosV9/olT8hnS+/dvu/SX4Q1SsFPKELhrZX9wzw1qC/j0hw8fV6FYuuxzQ6msJGkgEanXaI0tdcw5E1douNu8UwrHmqfhbmQpcHfNm179WeIG6de+Jb39T6XZs9IDPyd95cPS3Lm13bXccMdKWQAAAAAAAAAAAAC4HAJ3qJsIK2UBjZ6b06NDU7r79Ql1b2i/9AHDkGK9rJRtcds3d+o33rhDL6Wy+u9PnLrsc8NpS5K0M0HDnSRp8jnnvFLDnc8n9dwmnTkqLebrM1e1bFs6+X0nQNjZdfHvfH7p4G9IHz0k7fxp6dn/T/qrfdKzX3Y+Vw1WygIAAAAAAAAAAADAVRG4Q92YSytlrVzB40kA7zw4eFq2Ld1/+/bLPxTrcVbKVhuawbrwm3ftVM+Gdv35t4eUzi6s+MwwDXcXSx2TAmFp07VXfq53n7S48GojXqNKvyDNpqUdd13+mQ3bpA98WXrPZyXZ0lc+JH3hF6QLo5XflxmXZEiRZHXzAgAAAAAAAAAAAEALIHCHuomEgpIki5WyaFELhaK+9NSoXre5Q3de23X5B6M90uK8NH++fsOh4bS3+fUH99ygbG5R//c3XlzxmeG0pc42v7pj4TpP16Amj0nx10v+wJWf693nnGNPuT/TWow86pw/uU52JYYh3fzz0keflG7+RWn4W9KnDkiDfyOViqu/LzMhmXHJH6x6ZAAAAAAAAAAAAABY7wjcoW46Q35JUpaVsmhR/3zsjM7N5vXBg9vl8xmXfzDW55wzY/UZDA3rrTck9KaBLfrKM+N68pVzl/x+KGVpZyIiw7jC30+tIpty2uCutE62rOdW5xx70t2Z1urkY5IvIG2/Y3XPd26W3vM30gf/p9SxWfrn35P+4W1OU95qZCZYJwsAAAAAAAAAAAAAV0HgDnUT8PvUHvQTuEPLeuDQaYUCPr13b++VH4z1OGdm3P2h0NAMw9DH332j2vw+/cHDx7VYLC3/7vxsXtNWTgNx08MJG0jqOedMrCJw17FJ2tzf2IG74qL0yuNSz21SqMK/xjvvlj7yhHTwo9L409Jfv0H63p9Ii7nLf6ZUlLKTTsMmAAAAAAAAAAAAAOCyCNyhrsxwgJWyaEnHJ2b09Knzevfubm3oaLvyw+XACw13kHRNV6c+9IZr9MKZjB4cPL388+G0JUnqTxC4k+Ssk5Wk5K7VPd+7Tzp/Upqddm+mtZj4sZTPSjvuqu7zIVN6+59Iv/YdqWtAeuxPneDd6UMrP2+lJbtIwx0AAAAAAAAAAAAAXAWBO9RVJByQRcMdWtADh5yg1AcPbr/6w7GlBjwCd1jysbfsVHcsrD/71kuatpyWsqFUVpLUn4h4OVrjSC0F7hI3ru753tucc+wpd+ZZq5HHnHPHm9b2nt690ocfk97yn6TzrzgrZr/+v0oLmYufy0w4J4E7AAAAAAAAAAAAALgiAneoq0iIhju0nmLJ1sNHxnVTT0y7+zZc/QNRVsriYh1tAf2f77pB2YVF/ZdvvihJOrHUcDdA4M4x+Zy0YbsUjq3u+d59ztmoa2VHHpWCHc5K2bXyB6U3/gfpNx+Xtt0hPflZ6VMHpJf++dVnyt83rJQFAAAAAAAAAAAAgCsicIe6MsMBZRcKXo8B1NW0ldNcvqhbtq0ibCdJbR1S+yYa7nCRn9mV1L/Z2aUvPTWmH58+r6FUVp1tfnXHwv8/e3cfZfd91wf+fedBM5LmwbZszcgaWQ/xU2zJ2IntPJDYDoVAeQ4ODdCE0oaFc8ppl2ULB+jZbrunS7unLKW7hVPasl1CKE2JA6GFbiiEOHFwEjtOIo1N7MSSbY2sO5at6M6MpDuah7t//GbkBD9JM/fe372j1+ucOd94Hr7ftxxLyTl+n8+n7GjlW6gnz38lGT9w4T+z/aai0NaJhbtzZ5KpzyW735r0vcYK6otx5XXJj/1R8t3/Mjk3l/zuDyW/92PFOlkT7gAAAAAAAAAuiMIdbTW0MuGu0WiUHQXaplqrJ0nGL6YYNbozqZlwx4sqlUr+8ffenL6eSv7RRyfzxPRsrh0bTqVSKTta+U78ZdJYSsb2X/jP9PYlV78hOfZIsrzUumxr8cyDydK5ZO8618m+nJ6e5Pa/k/zUZ5Mbvit59PeTf31Hcuj3iq8P72j+mwAAAAAAAAAbiMIdbTU00J/lRnLmXIeVG6CFjq8W7kYupnC3K5l9tvOKQJTq2u1Def/b9mby2EyenzuX67YPlR2pM1Qni3P8Igp3STJxe3JuNjnxePMzrceR+4tz3z2te2Pk6uSHfif5Gx9I+gaSYw+/+HkAAAAAAAAAXpHCHW01PNiXJJmbXyw5CbTP9MwaJtyN7EyWF4tVj/B1/t5fuy5jIwNJkuvHFM1OjkUAACAASURBVO6SJNMrhbuLmXCXFIW7pPPWyh7+RLJl28X/ei5WpZLc9H3FtLs7/ofk9vcn/Ztb+yYAAAAAAABAl1O4o61WC3ezdYU7Lh1rm3C3szhrUy1IRDcbGujLP/nem9PfW8mb9m4rO05nqB5KBkaSy3Zf3M/t7MDC3ZmTyfGDyZ63F+tf22Hz5cl3/XLy3b/SnvcAAAAAAAAAulhf2QG4tAwNmHDHpadaO5vkYifcTRTnzFSSO5ofiq72Hft35LH/bSz9vXrzaTSKlbJjN198QW1kR7G+eerh1mRbi6c+laSR7Lu77CQAAAAAAAAAvAz/pp62GlpdKWvCHZeQ6kw9I4N92bLpIjrOoyuFu9qx1oSi6ynbragdTeZra1+/OnF7cuLLSb3W3Fxrdfj+4tx3T5kpAAAAAAAAAHgF/m09bfXihLuFkpNA+1Rr9ewY3XxxP2SlLFyY6mRxjq+1cHdHkkZy7JGmRVqXI/cno9ckl+8tOwkAAAAAAAAAL0PhjrYaXplwN2vCHZeIRqOR6kz94tbJJsnwjiSVlZWywCuaXi3cHVjbz0+srGzuhLWytankha8m++5KKpWy0wAAAAAAAADwMhTuaKuhgf4kCndcOmpnF1JfWM74yEUW7nr7i9KdlbLw6qoHk0pPsv2mtf38+C1JT38y9VBzc63F6jrZvfeUGgMAAAAAAACAV6ZwR1utTribm1e449JQnaknycVPuEuKtbJWysKrq04m265N+i9ybfOq/sFkxy1F4a7RaG62i3VktXB3V7k5AAAAAAAAAHhFCne01dCAwh2XluO1dRTuRnYmp59LFuebnAo2iPnZ5GtHkrH967tn4o7k7Mnk5OHm5FqLRqOYcLf9pmR4rLwcAAAAAAAAALwqhTvaanXCnZWyXCqm11O4G50ozplnm5gINpDpx4pz/MD67pm4ozinHl7fPetx4vFkrprsvbu8DAAAAAAAAAC8JoU72mqrCXdcYs5PuBtZT+HuWBMTwQZSPVic6y7c3V6cUw+t7571WF0nu0/hDgAAAAAAAKCTKdzRVv29PRns78lcfaHsKNAW1ZXC3Y61rpRNktpUExPBBjI9WZzrXSl72e5k61XlFu4O359UepPd31xeBgAAAAAAAABek8IdbTc00G+lLJeM6kw9A309Gd3cf/E/PKpwB6+qOpls2ZYMj6/vnkqlWCs7PZksnG1OtouxtJg89UCy843J4Ej73wcAAAAAAADgginc0XYjg31WynLJqNbq2TE6mEqlcvE/PLqrOK2UhZdaXkqee6yYbreW319/1cTtyfJicvxL67/rYh3/YjJfs04WAAAAAAAAoAtcUOHu7//9v589e/akUqlkcnLy/Oe/8pWv5K1vfWuuv/763HnnnXnsscfOf23Pnj258cYbc+utt+bWW2/Nhz70oeanpysNDfaZcMclozpTz9jIGtbJJsmWK5PeTSbcwcs5eSRZOJOMH2jOfRN3FGcZa2UPf6I49yrcAQAAAAAAAHS6Cyrcvfvd784DDzyQ3bt3f8Pnf/InfzI/8RM/kSeeeCI/93M/l/e///3f8PUPf/jD+eIXv5gvfvGLec973tO81HS1oQET7rg0nD23lNrZhewYXWPhrqcnGbk6qZlwBy9RPViczSrcXX1bUukpp3B35P6kb3Oy6872vw0AAAAAAADARbmgwt1dd92ViYmJb/jcc889l0ceeSTvfe97kyT33ntvjhw5kqeeeqrpIdlYVgt3jUaj7CjQUtWZepJkfHTz2i8Z3ZXMmHAHLzG9MnF3bH9z7hsYTrbflEw93Jz7LtTC2eSZzybXvDnpG2jv2wAAAAAAAABctAsq3L2co0eP5uqrr05fX1+SpFKp5Jprrskzzzxz/nv+5t/8mzlw4EB+/Md/PCdOnHjFu37lV34lExMT5z/m5ubWGosuMDTYl6XlRuoLy2VHgZY6XjubJBkfWUeJZmRnUq8l87NNSgUbRHUy6elPrry+eXdO3J7MHGvvVMmjn02W5pN997TvTQAAAAAAAADWbM2Fu6Qo2X29r59Y9slPfjJf+tKX8sgjj2Tbtm35W3/rb73iPT/zMz+Tqamp8x9DQ0PriUWHGx4oSpqz9YWSk0BrTTdlwt3O4rRWFr7R9GSy/cakb1Pz7tx5e3Eea+OUu8OfKM59d7fvTQAAAAAAAADWbM2Fu127dmVqaiqLi4tJirLd0aNHc8011yTJ+bO/vz8//dM/nU996lNNiMtGMDS4UribXyw5CbTW8dpq4W5w7ZeMrBTurJWFF505WUyiGzvQ3Hsn7ijOqYeae++rOXx/MnhZMn5L+94EAAAAAAAAYM3WXLjbvn17brvttnzwgx9Mktx3333Zs2dP9uzZk9OnT+fUqVPnv/d3f/d3c9ttt60/LRvC8GB/kmSurnDHxlZdKdztWE/hbnRXcZpwBy+qHirO8f3NvffK65OBkWSqTRPuzp5Kjn8x2fv2pKe3PW8CAAAAAAAAsC59F/JNP/VTP5WPfvSjqVar+dZv/dYMDQ3lq1/9an7jN34jP/ZjP5Zf+qVfysjISH7rt34rSTI9PZ177703S0tLaTQa2bdvXz7wgQ+09BdC9xhaWSk7Z8IdG1y1Vk9vTyVXDg2s/ZLzK2VNuIPzpieLc6zJhbuenmTnG5NnHkyWFpLe/ube/1c99UDSWE723dPadwAAAAAAAABomgsq3P3ar/1afu3Xfu0ln7/hhhvy4IMPvuTz+/btyxe+8IX1p2NDGl5dKWvCHRtcdaae7cMD6e2prP2S8ytlTbiD86orhbvxJq+UTYq1sof/vCj1Xd3i6byHP1Gce+9p7TsAAAAAAAAANM2aV8rCWplwx6WiWqtnbGQd62STZHA02TRswh18velDRRl1yxXNv3vijuJsx1rZI/cXv45tr2v9WwAAAAAAAAA0hcIdbbdauJutL5ScBFpnYWk5J+bms2N0nYW7SqVYK2vCHRQWzyXPfbn562RXTdxenFMPteb+VTPPJs8/key9u/h9DgAAAAAAAEBXULij7YZWVsrOWSnLBnZidj6NRjK+3sJdUkzAqk0ljcb674Ju9/wTyfJCMt6iwt2WK5IrXtf6wt2RTxbnvnta+w4AAAAAAAAATaVwR9uNDPYnsVKWje14rZ4kGV/vStmkmHC3WE/OnFz/XdDtpieLs1UT7pJirezJw8npF1r3xuH7i3PvXa17AwAAAAAAAICmU7ij7c6vlFW4YwObnlkp3DVjwt3oruKcmVr/XdDtqoeKc/yW1r2xulb22MOtub/RSA5/IrnyhmRkR2veAAAAAAAAAKAlFO5ou60DVsqy8TV1wt3IzuKsKdxBpieT/i3JFXtb98bEHcXZqrWyL3w1mX022Xd3a+4HAAAAAAAAoGUU7mi7TX09GejrsVKWDW11wt2O0c3rv2x0tXB3bP13QTdrNIoJd9tvSnp6W/fO2M1J3+bWFe4Of6I49yrcAQAAAAAAAHQbhTtKMTzYZ8IdG9rqhLvtIwPrv8xKWSjMVpMzLyTj+1v7Tm9/cvVtydTnk+Wl5t9/5P6k0pPseVvz7wYAAAAAAACgpRTuKMXQQF9m6gtlx4CWqdbO5oqtmzLY34QpXCNXF6eVslzqpieLc/xA69+auD05N5s8/0Rz711eSo58sij0bb6suXcDAAAAAAAA0HIKd5RieLDfSlk2tOpMPWMjg825rH9zsmWblbJQPVScY+0o3N1RnM1eK3v8S0m9Zp0sAAAAAAAAQJdSuKMUQwN9CndsWI1GI9O1+ewYbVLhLklGdiYzCndc4s4X7m5q/VutKtwdub849yncAQAAAAAAAHQjhTtKMTTYl7n6YhqNRtlRoOlOnj6Xc0vLGW9m4W50VzLzbLGOEi5V05PJ5XuTgeHWvzWyIxmZSKY+39x7D9+f9A0mu97c3HsBAAAAAAAAaAuFO0oxPNCXxeVG5heXy44CTXe8Vk+SjDdrpWySjO5MGkvJbLV5d0I3WTibvPDVZHx/+96ceGPy3GPJ/Gxz7luoJ898Jtn1pqS/iX8+AAAAAAAAANA2CneUYmiwL0kyW7dWlo1nemalcNfslbKJtbJcup57LGksJ+O3tO/NiTuSNJJjjzTnvqnPJYtnrZMFAAAAAAAA6GIKd5RiaGC1cLdQchJovtZMuJsoztpU8+6EblKdLM6xdk64u6M4px5qzn2H7y/Ovfc05z4AAAAAAAAA2k7hjlIMD/YnSebmTbhj41mdcLejmRPuFO641FUPFWc7V8ru+Kakpy+Zerg59x25PxkYTa6+tTn3AQAAAAAAANB2CneUYnWl7JyVsmxAqxPuxqyUheaZnkwGR5PRXe17s39zMn6gmHDXaKzvrnqtWE279+1JT29z8gEAAAAAAADQdgp3lGJ4daWsCXdsQNVaPVs39Z7/57wphncklR4T7rg0NRrJ9KPJ2IGkUmnv2xN3JGeeT7721PrueerTSWMp2Xt3U2IBAAAAAAAAUA6FO0oxNGDCHRtXdaaesdHBVJpZDOrtK0p3JtxxKTr1dDI/0951sqsm7ijO9a6VPXJ/ce5TuAMAAAAAAADoZgp3lOL8SlkT7tiAqrV6djRzneyqkZ0m3FFYXirWk653zWm3qE4W51gZhbvbi3PqofXdc/j+ZGg8ufL69WcCAAAAAAAAoDQKd5RidcLdbH2h5CTQXLP1hczNL2ZspAWFu9GdyekTyeJ88++mu/zxzyb/7h3JQ/++7CTtUT1UnGVMuLt8b7Jl2/oKd7PTyYm/TPbd0/6VuAAAAAAAAAA0lcIdpRgZ7E+SzJpwxwYzPVNPktZMuBudKE5rZS9tj/x28vBvFv/5k7+cLJwtN087TE8mld7kqte3/+1KpVgrWz249r/XRz5ZnNbJAgAAAAAAAHQ9hTtKcX6lbF3hjo2lWiumz42Pbm7+5SMrhTtrZS9dxz6f/NHPJKO7krt+NpmrJg//h7JTtV71ULGKtb8FRdYLMXF7sryYHD+4tp8//Ini3KtwBwAAAAAAANDtFO4oxdaB3iTJnAl3bDDHa8UErPFWrZRNkpoJd5ekuRPJh96XVHqS93wwefv/nAzvSB74leTc6bLTtU69lpx6upx1sqsm7ijOtayVbTSSI/cn26598fcwAAAAAAAAAF1L4Y5SDPT1ZlNfjwl3bDgtXSk7slLWmTHh7pKztJh8+G8X64S/+1eTq29N+jcXpbvTJ5KHfrPshK0z/WhxjpVYuLv6DUkqayvcnTyc1I6abgcAAAAAAACwQSjcUZrhgb7MmnDHBnO8VhTuxloy4W5XcZpwd+n57/8oeepTyZ0/kdz6wy9+/g0/WhQxP/2ryfxceflaqTpZnGVOuBscSba/Ppl6+OJ/9sj9xbnvnmYmAgAAAAAAAKAkCneUZmiwL7Mm3LHBVGv19PdWsm3rpuZfvvXKpHcgqZlwd0k5+HvJZ34tueYtybf/0jd+rW8guesfJGdeSD73b8vJ12rTh4pz/JZyc0zcXkyXnHn24n7u8CeSVJI9b2tFKgAAAAAAAADaTOGO0gwP9mVufqHsGNBU1Zl6tg8Ppqen0vzLK5Vk5OpirSiXhuMHkz/8e8nwjuQHfyvp7X/p99z63mT0muQv/q+kPtP+jK1WnUy2bk+GtpebY+KO4ryYKXfLy8mRTyU7vinZckVrcgEAAAAAAADQVgp3lGZooC9zJtyxwVRr9ewYbcE62VWjE1bKXirOnEw+9N5keTH5Gx9Ihsde/vv6NiV3/2xy9mvJZ3+jvRlbbWkxee6xctfJrjpfuHvown9m+lBy9mSy7+7WZAIAAAAAAACg7RTuKM3QQH/m5hfTaDTKjgJNMb+4lBdOn8tYqwt387WNOcmMFy0vJfe9Pzn1dPKd/yLZdeerf/83/XBy+Z7kwf87OXuqLRHb4uSTyWI9GeuAwt2VNyQDIxc34e7w/cW5755WJAIAAAAAAACgBAp3lGZ4sC8LS43MLy6XHQWa4rmZ+STJjpEWFu5GdhantbIb28f/afLkx5M3/Ghy+99+7e/v7U/u/vmkXks+8+utz9cu1UPFOX6g3BxJ0tOTXH1b8uwXkqULXId++BNJ76Zk15tbGg0AAAAAAACA9lG4ozRDA31Jkrl5a2XZGKoz9STJeEsn3K0U7qyV3bge+2jywK8kO9+YfOcvX/jPHfjBZNu1yYO/Xqyj3QimJ4uzEwp3SbFWdvFsMv3oa3/v4rnkmQeTXW9KNm1pfTYAAAAAAAAA2kLhjtIMDa4U7uoKd2wMx2vtKNztKs7a0da9QXme+3LyB3832XpV8jd+O+kbuPCf7e0rptydm00e/Nety9hO1cmkdyDZdl3ZSQoTdxTn1EOv/b1TDyULZ5K9d7c2EwAAAAAAAABtpXBHaVYn3M0q3LFBTK8U7na0snBnpezGVa8l/+lHkoWzyQ/+vy9OM7wY+38gufKG5DP/Jjn9QtMjtl31ULL9xqJM2Akmbi/OqYdf+3uP3F+c+xTuAAAAAAAAADYShTtKM7Iy4W52fqHkJNAcqxPuxkaslOUiLS8nH/nJ5OSTybf/UrLnbWu7p6c3uefnk4XTyV/8q+ZmbLfTzydz1WSsQ9bJJsnWK5PL9ybHLqBwd/j+ZNNwcvUbWp8LAAAAAAAAgLZRuKM0Vsqy0VRnzqZSSbYPt7BwNziaDIwkM1Ote4P2++S/SJ74b8kt70ne9JPru+um70+235R87t8lc881J18ZqoeKc7yDCndJsVb2ha8mZ06+8vfMzxalvD1v65zpfAAAAAAAAAA0hcIdpRka6E+SzM0r3LExVGv1bNs6kE19Lf6jdWRnUlO42zAe//+ST/xSUSz77l9NKpX13dfTk9zzC8nCmeTTXTzlbnqyOMf3l5vjr5q4oziPff6Vv+fpv0iWF62TBQAAAAAAANiAFO4ozdDAyoQ7hTs2iGqtnh2jLZxut2p0ZzLzbNJotP4tWuuFJ5OP/ESy+fLkPb+TbNrSnHtf/z3J+C3JQ/8+mTnenDvbrbpSuBu7udwcf9XE7cU59dArf8/h+4tzr8IdAAAAAAAAwEajcEdphldWys5aKcsGsLTcyHOz8xkbaUPhbmRnslhPzrzQ+rdonfm55D/9SHJuNnn3/5Ncvrt5d1cqyTt+sfjn5IF/2bx726l6KBndVZQRO8nY/qRv8NULd0fuT7ZuT7a/vn25AAAAAAAAAGgLhTtKszrhTuGOjeCFufksLjfaNOFuV3HWjrb+LVqj0Ug++neTE19O/to/Sl73Lc1/4/rvSK6+Lfn8f0hqx5p/fystzifPP16s2e00fZuSHbcmU59Plpdf+vW5E8U63H13r389MAAAAAAAAAAdR+GO0qxOuJubXyg5CaxfdaaeJBlv10rZpPtKVLzo0/8qeeyjyU3fl3zzT7fmjUolecc/TJbOJZ/6P1vzRquceDxZXiymyXWiiduT+Vrywlde+rUj1skCAAAAAAAAbGQKd5RmaLVwZ8IdG8Dx2krhrl0rZZNkRuGuKz358eTP/kly1euT7/v11k5Bu/Zbk4k7kkc+kJx6pnXvNNv0ZHGOd2rh7o7ifLm1squFu30KdwAAAAAAAAAbkcIdpRno682m3p7MzSvc0f2mVybctWel7ERx1qZa/xbN9bWnkg//nWTTcPJDv5MMDLX2vUoleccvJssLySd/ubVvNVN1pXDXsRPuXqVwd/j+5Ip9yWXXtDcTAAAAAAAAAG2hcEephgb7MmvCHRvA6oS7sXYU7lYn3CncdZdzZ5IPvTc5+7XkB/5tsu117Xl33zuSa96SfPF3kpNH2vPmelUPJpuGksv3lp3k5Y3uTIavTqYe/sbPnzySnHraOlkAAAAAAACADUzhjlINDfSZcMeGUG3nStn+wWTLlVbKdpNGI/mvP51UDyX3/EJyw3e07+1KJXnHP0yWF7tjyl2jUayUHbs56eng/5sycXvy3GPJ/OyLn7NOFgAAAAAAAGDD6+B/k82lYGjAhDs2hmqtnuHBvmwd6GvPg6MTSU3hrmt89jeSgx9Krv/ryV0/1/7397492fP25Eu/m7zwZPvfvxgzzxZTADt1neyqiTuSxnLy7Bde/NzhlcLdnrvKyQQAAAAAAABAyyncUarhQRPu2BiqM/XsaMc62VWjE8nss8mS3z8d76kHko/9YrLt2uQHfqO8qW3v+MWksZTc/3+U8/6Fmp4szvEuKNwlydRDxbm8nBz5ZDJ+INm6rbxcAAAAAAAAALSUwh2lGh7sy5wJd3S5RqORaq2esXask101srOYrjVXbd+bXLzaseT3fizp35y853eSwdHysux+a7LvHcmh30tOPF5ejtdSPVicYwfKzfFadnxT0tOXTD1c/PVzjyVnnk/23VNmKgAAAAAAAABaTOGOUg0N9OXc0nLmF5fKjgJrNnN2MWcXlto84W5ncVor27kW55P//L7k9Ink+3892X5j2YlWptwtd/aUu+pkkkoydlPZSV7dpi3J2M3FhLtGIzn8ieLze+8pMxUAAAAAAAAALaZwR6mGBvuSxJQ7ulp1pp4kGW/nhLvRieKcmWrfm1ycP/4HybHPJ2/7n5Kbvq/sNIVddybXflsy+ZFk+rGy07y86clk2+uSTVvLTvLaJu4oCpWnnk6O3J/09Ce731J2KgAAAAAAAABaSOGOUg0N9CdJ5uYV7uhex2tnkyTjo5vb9+jISuGupnDXkR7+D8kjH0he9y3Jt/wvZaf5Ru/4hSSN5P5/XnaSlzp3OnnhyWRsf9lJLszEHcX59IPJ039R/HU3FAUBAAAAAAAAWDOFO0o1vDLhbtaEO7rY9MqEOytlSZLMPJv8t59LLtud3PubSU9v2Ym+0c43Jjd8Z/LYR5PqobLTfKPn/jJJIxnvssLdZ/9Ncm4u2XdPmWkAAAAAAAAAaAOFO0qlcMdGcLxWFO7G2rlSdmg8qfQmMwp3HWfyI8nSueSd/zTZckXZaV7ePT9fnJ/osCl31YPFOXag3BwX6op9yebLk+NfLP56393l5gEAAAAAAACg5RTuKNXQQFG4s1KWblatlTDhrrcvGd6R1I62700uzOSHk4GR5Lp3lp3kle34puT135N8+b8mz36h7DQvqk4W53iXFO4qlRen3G0aKqYHAgAAAAAAALChKdxRqhcLdwslJ4G1q87Us6mvJ5dt6W/vw6M7rZTtNC88WRTYbvzupL+NBcy1uOcXivPP/1m5Ob7e9GQxMW7k6rKTXLjVwt3utya9bf4zAAAAAAAAAIC2U7ijVEMrK2XnrJSli1Vr9ewYHUylUmnvwyM7kzPPJwtn2/sur+zRjxTn/nvLzXEhxm5Obn5X8pWPJVMPl50mWV5Oph9NxvYXk+O6xZ63FWcnTzQEAAAAAAAAoGkU7ijV8EAxDWjWSlm6WHWmnrGREqaZjU4U58yz7X+blzf5kWTzFcm+u8tOcmHu/vkkleTPf6nsJMmpp5Jzc92zTnbV7rcmP/7x5Pa/U3YSAAAAAAAAANpA4Y5SrU64mzXhji5VX1jKqTML2TFaYuGuNtX+t3mp6ceS5x5Lbvq+7lktuv3G5MC7kyf/LHnmM+VmqR4qzm4r3CXJxBuTnt6yUwAAAAAAAADQBgp3lGrYSlm6XLVWT5KMlzHhbmRncc4ca//bvNTkfcXZDetkv97dP59UesqfcledLM6x/eXmAAAAAAAAAIBXoXBHqYYGVgp3VsrSpY6vFu5KnXCncFe6RqMo3A3vKFaMdpMrr01u+aHkyP3JUw+Ul2N6MunpS666obwMAAAAAAAAAPAaFO4o1UBfT/p7K1bK0rWmZ0qccHe+cHe0/W/zjZ79QvK1I8nN7+rO1aJ3/2xS6S2m3DUa5WSoTiZX3pD0DZTzPgAAAAAAAABcAIU7SlWpVDI00Je5+YWyo8CalDrhbsu2pG/QStlO0K3rZFddsS+59UeSpz9dTLprt7NfS2rPJOPWyQIAAAAAAADQ2RTuKN3QYJ+VsnStau1skmTH6Ob2P16pJCNXWylbtuXl5NHfTy67Jtn5xrLTrN1dP1usdC1jyt30o8U5fqC97wIAAAAAAADARVK4o3RDA/2Zs1KWLlWdqaenklw5tKmcAKMTSW2qnLcpHP1MMWVw/71FCbJbXb47ue19ydHPJk/+WXvfrk4W55gJdwAAAAAAAAB0NoU7Sjc82JdZhTu6VLVWz/bhwfT1lvTH6chEcm42qdfKeZ+vWyf77nJzNMNd/yDp3dT+KXfTh4rThDsAAAAAAAAAOpzCHaUbHujLrJWydKnqTD1jo4PlBRjdWZzWypZjaTF59A+SK29Ixm4uO836jU4kb/yx5Njnk6/8SfverU4mQ+PJ1ivb9yYAAAAAAAAArIHCHaUbGuzLucXlzC8ulR0FLsri0nJOzM5nx0iZhbuJ4pxRuCvFU59Mzjzf/etkv97bfibpHUj+/H9vz5S7pcXkub803Q4AAAAAAACArqBwR+mGBvqSJKfnFe7oLifm5rPcSMbLnHA3slK4qx0tL8Ol7Pw62R8oN0czjexI7nh/cvxLyeN/3Pr3XvhKsjSfjO9v/VsAAAAAAAAAsE4Kd5RuaLAo3M3VrZWluxyv1ZOUXLizUrY8i/PJY/8lGb8lufK6stM01zf/dNK3OfnTf5x89U+ThXrr3qpOFueYwh0AAAAAAAAAna+v7AAwvDLhbnZ+oeQkcHGmVwt3Za6UHVkp3Fkp235f/bNkvpYceHfZSZpveCx5+88Ua2U/eG/SvyXZe3dy3bcl170zuWxX896aPlScVsoCAAAAAAAA0AUU7ijd6krZWRPu6DIdMeFucCQZGE1qU+VluFStrpO9+V3l5miVu342ef33JF/5k+SJP1k5/1vxte03FcW7696Z7Loz6e1f+zvVQ8U0vW3XNic3AAAAAAAAALSQwh2lGx4sihpWytJtqjNF4W5HmYW7pFgrq3DXXudOJ4//cbLrTcll15SdFY1anQAAIABJREFUpjUqlWT764uPb/4fk7OnksN/nnzlvxflu0//avExMJpc+y1F+e7ab0uGrrq4d6qTxRs9va35dQAAAAAAAABAEyncUbqhweIfw7l5hTu6S3Vlwt1YmStlk2Kt7JFPJo1GUZKi9Z74WLJwJtl/b9lJ2mfzZcU0v5vflSwvJ8e/WBTvvvInyaN/kDz6+0kqydW3Jdd/e7F+dsdtSU/PK98591xy+rnkhu9o2y8DAAAAAAAAANZD4Y7SDa+ulFW4o8tUa/VcvqU/g/0lT+YanUiW5pPTz1/8dDHWZvK+pNKT3PT9ZScpR09PsvMNxcc9P5/MnUi++qfJVz6WfPXjySf+WfGx9api6t1135a87luK0t7Xqx4qzrED7f81AAAAAAAAAMAaKNxRuvMT7qyUpctUZ+rlT7dLipWySVI7qnDXDvVaMdVtz9uT4bGy03SGoauSW3+4+FhaTI5+9sXpd1/6j8VHpTe55s3F6tnr3lmskZ2eLH5+fH+5+QEAAAAAAADgAincUbqhgdWVsgslJ4EL12g0Up2p55tft63sKMnIRHHOHCsmjtFaX/6jZOncpbVO9mL09iV7vrn4+LZ/kpw6ulK+++/JkfuTpz+d/On/mozuKqYEJsnYzeVmBgAAAAAAAIALpHBH6VYn3M2acEcX+dqZhZxbXM74aCdNuDtWbo5LxeR9SU9f8vrvKTtJd7hsV3LH+4uPhXry9ANF+e6JjyVfO5Jc9fpkcLTslAAAAAAAAABwQRTuKN3IYH8SK2XpLsdrZ5Mk4yObS06SZHRlwl3taLk5LgWnX0ie/PPk2m9NtlxRdpru0z9Y/L279luT7/jnycnDyaahslMBAAAAAAAAwAVTuKN0A3096eupZHZe4Y7uMT1TT5KMjw6UnCTJyMqEuxkT7lrusT9IGkvWyTZDpZJse13ZKQAAAAAAAADgovSUHQAqlUqGBvtMuKOrHK+tFu46YMJd30Cy9SorZdth8iNJ32By43eWnQQAAAAAAAAAKIHCHR1haKAvcybc0UWmVwp3O0YHS06yYnQiqU2VnWJjm3k2efrTyfXfngwMl50GAAAAAAAAACiBwh0dQeGObrM64W5spEMKdyM7k7lqsuT3Ucs8+gdJGtbJAgAAAAAAAMAlTOGOjjA82JfZ+kLZMeCCVWfq2bKpNyODfWVHKYxOJI3lZPZ42Uk2rsn7kk1DyXXvLDsJAAAAAAAAAFAShTs6wvBgf2brJnPRPaq1esZHBlOpVMqOUhjZWZwzx8rNsVGdPJIcezi58buS/s1lpwEAAAAAAAAASqJwR0cYGujL/OJyzi0ulx0FLki1Vs/4aIesk02KCXdJUpsqN8dG9ehHinP/u8vNAQAAAAAAAACUSuGOjjC0spbz9Lwpd3S+ufnFzM4vZnykgwp3l+8pzhOPlxpjw5r8SLL58mTfPWUnAQAAAAAAAABKpHBHRxgeKAp3cwp3dIFqrZ4knTXhbvxAsmkoeeqBspNsPM99OZmeTF7/vUnfprLTAAAAAAAAAAAlUrijIwytFO5m6wp3dL7pmQ4s3PX2J7vfmkw9lJw7XXaajeX8Otl7y80BAAAAAAAAAJRO4Y6OsLpS1oQ7usHx1Ql3nbRSNkn23pUsLyTPfKbsJBtHo5Ec+nAyNJbseVvZaQAAAAAAAACAkinc0RGGB/uTJLP1hZKTwGvryAl3SVG4S5Ijnyw3x0Zy/EvJySeTm9+V9PSWnQYAAAAAAAAAKJnCHR1hdaWsCXd0g+O1s0k6sHA3diAZvEzhrpkm7ytO62QBAAAAAAAAgCjc0SGGV1bKztYV7uh81Vo9fT2VXLl1oOwo36inJ9n79uT4F5Ozp8pO0/2Wl5NHfz8ZvSaZuKPsNAAAAAAAAABAB1C4oyOYcEc3qc7UMzYymJ6eStlRXmrv3UljOXn6L8pO0v2mHkpqR5P970oqHfjfNQAAAAAAAADQdgp3dIShlQl3cybc0QWqtXrnrZNdtfeu4rRWdv0mP1yc1skCAAAAAAAAACsU7ugIwybc0SXOLS7n+blzGR/p0MLdldcnQ2MKd+u1tFisk912XTJ+S9lpAAAAAAAAAIAOoXBHRxge7E+SzNQXSk4Cr256pp4knTvhrlIpptw992gyd6LsNN3r6QeS0yeK6XbWyQIAAAAAAAAAKxTu6AiD/T3p7alYKUvHO1+469QJd8mLa2Wf+lS5ObrZ5H3Fuf8Hys0BAAAAAAAAAHQUhTs6QqVSydBAn5WydLzjtQ6fcJe8WLizVnZtFs8lj/1hMnYgueqGstMAAAAAAAAAAB1E4Y6OoXBHN+j4lbJJcvme5LJrFO7W6smPJ/VTptsBAAAAAAAAAC+hcEfHGB7ss1KWjnd+wl0nr5RNiil3J59MalNlJ+k+59fJ3ltuDgAAAAAAAACg4yjc0TGGBvoya8IdHa66Urgb6/jC3d3FeeRT5eboNufOJI//cTJxR3L57rLTAAAAAAAAAAAdRuGOjjE82JfZ+kLZMeBVVWfquXJoUzb1dfgfn3veXpzWyl6cr/xJcm7OdDsAAAAAAAAA4GV1eGOES8nQYH/qC8tZWFouOwq8omqtnvHRDp9ulyQjO5Irry8Kd41G2Wm6x+R9SSrJTd9fdhIAAAAAAAAAoAMp3NExhgb6kiSnrZWlQy0vNzI9U894p6+TXbX3rmRmKjl5uOwk3aE+kzzxsWTP24rCIgAAAAAAAADAX6FwR8cYHiwKd7N1hbtmWVhaTsN0s6Z5/vR8Fpcb3THhLikKd4m1shfq8T9OluatkwUAAAAAAAAAXpHCHR1jdcLdnAl3TVE7u5Db/+mf5l9//KtlR9kwpmvzSdI9E+72vL04Fe4uzOR9SU9f8vrvLTsJAAAAAAAAANChFO7oGAp3zfXFo6dSO7uQ3/z0kdQXlsqOsyEcr51NkoyPbi45yQXackUyfqAo3Jl0+OrOnEye/Hiy7x3J1m1lpwEAAAAAAAAAOpTCHR1j6PxK2YWSk2wMh6ZOJUlOnVnIf/nSsyWn2RimZ+pJumjCXZLsvTs583zy3F+WnaSz/eUfJsuL1skCAAAAAAAAAK9K4Y6OMXK+cGfCXTMcnKqlt6eSLZt684EHn07DhLN1O15bKdyNdlPh7q7itFb21R36cNI7kNz4XWUnAQAAAAAAAAA6mMIdHWNooD+JlbLNcuhYLddtH8r337Yzh47V8sWjp8qO1PWq3Vi4u+YtSaVX4e7VzFaTpx5Irn9nMjhSdhoAAAAAAAAAoIMp3NExVlfKzplwt24nZudzvFbPgZ2j+dG37E6S/PaDT5ecqvtVZ+oZHujL0EBf2VEu3OBIsvMNRaFseansNJ3p0T9I0rBOFgAAAAAAAAB4TQp3dIzVEpMJd+s3eayWJLllYjQ3jo/kzj1X5L8ePJ7n5+ZLTtbdqrV6d023W7X3rmS+lhz/UtlJOtPkfUn/1uS6by87CQAAAAAAAADQ4RTu6BjDKxPuZk24W7eDU0Xh7sDEZUmSH33r7pxbWs6HHjpaZqyu1mg0Up3p4sJdYq3sy/na08nU55IbvzPZtKXsNAAAAAAAAABAh1O4o2OYcNc8h46dSl9PJTeODydJvv3m8WwfHsh//OwzWVpulJyuO83UF3Pm3FLGR7qwcLfrTUnvgMLdy3n0I8W5/93l5gAAAAAAAAAAuoLCHR1jy6be9FSS2fpC2VG63sGpWm4YH85gf2+SpL+3Jz985zU5dups/uwvp0tO152mZ+pJ0p0T7vo3J7vuTJ55MFk8V3aazjJ5XzI4mrzuW8pOAgAAAAAAAAB0AYU7OkalUsnQQJ8Jd+s0PVPPc7PzObBz9Bs+/yNvuiZ9PZV84MGnS0rW3Y7XurhwlyR7704WziTHPl92ks5x4omkeih5/fcmfZvKTgMAAAAAAAAAdAGFOzrK8GB/5uoKd+txaKqWJDkw8Y2Fu7GRwXz7/vE88NXn8+SJuTKidbXp1cJdN66UTZK9dxWntbIvOr9O9t5ycwAAAAAAAAAAXUPhjo4yNNCXWRPu1uXgsaJwd8vOy17ytR998+4kyW+bcnfRun7C3c43JP1bFe5WNRrFOtmtVyV73l52GgAAAAAAAACgSyjc0VGGBvtMuFunQ1Onsqm3J9ePD73ka3fuvSI3jA3nvs9P5bRi40WpzpxN0sUT7nr7k91vTaY+l5w7U3aa8lUPJc8/kdz8rqS3r+w0AAAAAAAAAECXULijowwN9GVOEWzNGo1GDh2r5cYdwxno633J1yuVSn70rbszO7+Y3//CsRISdq9qrZ5NvT25YuumsqOs3d67kqVzydHPlp2kfJP3Fad1sgAAAAAAAADARVC4o6MMD/blzLmlLC4tlx2lK1Vn6nl+7lz27xx9xe/5/lt3ZnigL7/94NNpNBptTNfdjtfqGR8dTKVSKTvK2u29qzgv9bWyjUYy+ZFkZCKZuLPsNAAAAAAAAABAF1G4o6MMDxarHU/PL5WcpDsdnKolSW55lcLd1oG+3PvGiTw+PZvPHTnZrmhdb3qm3r3rZFeNH0gGL1O4m3o4qT2T7H9X0uN/BgEAAAAAAACAC6dpQEcZGigKd7PzCyUn6U6HVgp3ByZeuXCXJO97y+4kyQc+83TLM20E9YWlfO3MQsZHu7xw19Ob7Hlb8uwjSb1WdpryWCcLAAAAAAAAAKyRwh0dZWigP0kyN79YcpLudPBYLZv6enL92PCrft/rrhrK26+7Mh+brGZ6pt6mdN1r9e9R1xfukmTv3UljOXn6wbKTlOfxP0ou35vsuLXsJAAAAAAAAABAl1G4o6MMrayUnasr3F2sRqORyWO13LRjJP29r/1b+31v3p3F5Ub+42efaUO67na8tlK46/aVskmy967ivFTXyi4tJKeOFut1K5Wy0wAAAAAAAAAAXUbhjo4yfH6lrMLdxTp26mxOnj6XAztffZ3sqr/2+rHsvGxzfvdzz2RhabnF6brbhppwd9UNydbtl27hbm46SSMZ2Vl2EgAAAAAAAACgCync0VGGVybczZpwd9EOTdWSJAcmLqxw19tTyY+86Zo8Nzufjz1abWW0rnd+wt1GKNxVKsWUu+lDyekXyk7TfjPPFufI1eXmAAAAAAAAAAC6ksIdHcVK2bU7eKwo3N1ygYW7JPmhO3ZlU29PPvAXT7cq1oZQ3UgrZZMX18o+9alyc5Rh5lhxKtwBAAAAAAAAAGugcEdHGVpZKTs3v1Byku5zaKqWwf6eXHvV0AX/zLahgXz3LTvyuadO5svVmRam627VWj09leSq4YGyozTHauHuUlwre37CnZWyAAAAAAAAAMDFU7ijowybcLcmjUYjh47VcvPVo+nrvbjf1u97y+4kyQceNOXulRyfqefKoYH0X+Tf2451+Z5k9JpLvHBnwh0AAAAAAAAAcPE2SHuEjWJooD9JMjuvcHcxjp48m9rZhRzYeeHrZFfduuuyHNg5mt9/5FhqZ00WfDnTtXp2jG6QdbJJUqkUU+5e+MqLBbRLxepK2eEd5eYAAAAAAAAAALqSwh0dZciEuzU5eOxUkqypcFepVPKjb9mdswtLue/zU82O1vUWl5bz3Gw94xupcJd83VrZT5Wbo91mjidbtyd9m8pOAgAAAAAAAAB0IYU7OsrWTb2pVJJZhbuLcmiqliS5ZeLiC3dJ8j3fdHUu29KfD37m6SwvN5oZres9P3cuy41kfGSjFe7eXpyX2lrZmWetkwUAAAAAAAAA1kzhjo5SqVQyNNCXOStlL8rBqVq2bOrNvquG1vTzg/29ec/tu3L4+dP59JPPNzlddzteO5skGR/dXHKSJhu5Otl2XXLk/qRxiZQsl5eT2WeTkZ1lJwEAAAAAAAAAupTCHR1neKAvswp3F2x5uZHJZ2vZf/Voensqa77nvW/enUol+a2/eLqJ6brf9Ew9STI+OlBykhbYe1dSO5p87amyk7TH6RPJ8qIJdwAAAAAAAADAminc0XGGBvsyV18oO0bXePrkmczWF7N/59rWya7adcWWfMsN2/PxL09n6mtnmpSu+x2vrRTuRjbYhLukKNwll85a2ZljxalwBwAAAAAAAACskcIdHcdK2YtzcOpUkuSWifUV7pLkfW/ZneVG8juffWbdd20U1dXC3ehgyUlaYM/bi/OSKdw9W5xWygIAAAAAAAAAa6RwR8cZGuzPXF3h7kIdmqolSQ40oXB313VXZc+2LfnQQ0dTX1ha930bQXV1pezIBizcbd2WjB0oCneNRtlpWu984c6EOwAAAAAAAABgbRTu6DjDg305fW4pS8uXQAGoCQ4eq2VooC97t21d9109PZW89827c/L0ufzRweNNSNf9jtfqGd3cn82besuO0hp770pOP5eceLzsJK1npSwAAAAAAAAAsE4Kd3Sc4YG+JLFW9gIsLzfy6LFa9u8cSU9PpSl3/uAbd2Wwvycf+MzTTbmv203P1LNjI66TXbX3ruI8cn+5OdrBhDsAAAAAAAAAYJ0U7ug4Qwp3F+zw86dz+txSDuxc/zrZVaNb+vP9t+7Ml46eysGpU027txs1Go0cr9UzvpELd7vfmlR6i7WyG93Ms8nmK5L+zWUnAQAAAAAAAAC6lMIdHWdocKVwV1e4ey2HjhWFuAMTlzX13ve9ZXeS5AMPXtpT7k6dWci5xeWMj2zgwt3gSHL1bclTn0qWl8pO01ozx5KRnWWnAAAAAAAAAAC6mMIdHefFCXcLJSfpfAenakmSW5o44S5Jbr56NLfvvjx/+KVnc/L0uabe3U2O1+pJsrEn3CXFWtl6LakeLDtJ6zQaxYQ762QBAAAAAAAAgHVQuKPjDK9MuJs14e41HZqqZXiwL7u3bWn63e97y+6cW1zOf374aNPv7hbTMyuFu4084S4pCnfJxl4re+ZksjSvcAcAAAAAAAAArIvCHR1naKA/STI3r3D3apaWG3n02ZncMjGaSqXS9Pv/+v4duXJoIB/8zNNZWm40/f5ucMlMuNv1pqR308Yu3M0cK04rZQEAAAAAAACAdVC4o+OYcHdhnjwxl7MLS9nf5HWyqzb19eSH79yVqa+dzScef64lb3S66swlUrjbtCWZuDN5+sFkcYOuEJ55tjhNuAMAAAAAAAAA1kHhjo4ztFK4m1O4e1UHp2pJklt2XtayN37kTdekt6eS33rw6Za90cmqtbNJkh0jm0tO0gZ770oWTifPPlJ2ktY4P+FO4Q4AAAAAAAAAWDuFOzrO8MDKhDsrZV/VoalTSZJbJloz4S5JdoxuzjtvGssnnziRI8+fbtk7nep4rZ7B/p6MbO4rO0rr7b2rODfqWtnzE+6slAUAAAAAAAAA1k7hjo5jwt2FOXislsu29Gfi8tZOX3vfW3YnST74mUtvyt30TD07RjenUqmUHaX1dr4x6d9yCRTudpSbAwAAAAAAAADoagp3dJyhlQl3c/MLJSfpXItLy3ns2Zkc2Dna8jLYW/Zty3Xbh/KfHz6aM+curRLk8Vo9YyMDZcdoj75NyTVvSY5+Nlk4W3aa5ps5lgyMJAPDZScBAAD4/9m7t+A48/w8zG8DDTRIdgMcgBgCJIecGXB2vdqdWWkor6WVdyx5t1IpV+IktlJJObacWI6ViuJ1lS90n6pc+MpVtrQu68IXUVxJKrHscuXkSizbOpTXJ1Irclcr7ZIzQw5x4AEEuwESjWPnogHOzs6QBInu/ro5z1M19cf04fv/ajgkb956fwAAAADAABO4o+8cGy2nVErWrJR9rO/fXsvG9m7ePN29dbL7SqVSfu4nz2W1uZ1//K2Frt/XLx5sbGe1uZ3Zie42CPaV195JdjbbobsXTWMhGT9V9BQAAAAAAAAAwIATuKPvDA2VUh0tZ9VK2ce6crOeJHnrTPcDd0nyn7x9JtVKOb/2zetptVo9ubNoS41mkmRmYqzgSXrotXfa54u2VrbVErgDAAAAAAAAADpC4I6+VB0TuHuSy/P3kyRvnjnek/uqlXL+zNun893FRi5eX+nJnUW7Vd8L3I1/igJ3s19MKhMvXuCuWU+2HgjcAQAAAAAAAACHJnBHX6pWylbKPsGVm/VMHRvNqR62r/2FnziXJPkfv3m9Z3cWabH+KWy4GxpOXv3jyfylpNkoeprOaeytQh4/XewcAAAAAAAAAMDAE7ijL1XHylnTcPeJNrd3892l1bx5ZiKlUqln975xspYvz03ln3x7MbdXmz27tyiPVsp+mhrukvZa2dZOcuObRU/SOY8CdxruAAAAAAAAAIDDEbijL2m4e7zv3VrN5vZu3jw90fO7f+4nz2Vrp5X/9d980PO7e21pr+Fu9tPUcJe0A3fJi7VWtjHfPjXcAQAAAAAAAACHJHBHX6qNtQN3u7utokfpO1fm60lSSODua587mdmJsfzP//pGtnZ2e35/Ly3WmxkeKmWqWil6lN56+XPJ0RPJe79Z9CSdo+EOAAAAAAAAAOgQgTv6Uq0ykiRZ29Ry98Mu32wH7t46c7znd5eHh/LnvnQ2S41m/r/fv9Xz+3vpVqOZk7VKhod6t7a3L5RK7Za7pSvJw3tFT9MZjxruBO4AAAAAAAAAgMMRuKMvVcfKSZK1psDdD7syfz/TtUpOjhfTvPaff+lsRoZL+bVvvl/I/b2yWG/m5Kdtney+/bWy7/92sXN0SmMhGTmajPU+pAoAAAAAAAAAvFgE7uhL1cpe4G5D4O4HbWzv5A+XVvPW6YmUSsU0r03XKvlTb87mX717L9+7tVrIDN22ub2b5Qcbmf20B+7e+61i5+iUxkK73a6g3zMAAAAAAAAAwItD4I6+VNtruFvVcPcRf7i0mq2dVr5weqLQOX7uJ88lSf6nb14vdI5uub3aTKuVzIwfKXqUYky+noyfefECdwAAAAAAAAAAhyRwR1/ScPfJLt+sJ0neOlNs4O7tsy/lR2bH8w8v3cxqc6vQWbrhVqOZJJmZKGZtb+FKpXbL3d3vJY3Foqc5nI3VZKOejJ8uehIAAAAAAAAA4AUgcEdfqu413K1puPuIK3uBuzcLbrgrlUr5i18+lwebO/mHl+YLnaUbFuv7gbtPacNd8uFa2fd/u9g5Dms/MKjhDgAAAAAAAADoAIE7+lJtbCRJXsj2tMO4PF/PzPhYXh4fK3qU/Okvns7EkZH82jffT6vVKnqcjlraD9z1wX/nwrz2lfb53m8WO8dhNfYCoQJ3AAAAAAAAAEAHCNzRl6yU/bjm1k6+f2s1bxa8TnbfkdHh/KcXzuTanQf5t++vFD1OR+0H7mYnPsWBu4kzyeRc8t5vFT3J4TQW2qeVsgAAAAAAAABABwjc0ZdqeytlV62UfeS7i41s77YKXyf7g975zHSS5Pu3VwuepLMWG+3A3cvjlYInKdhr7yT3byQr7xc9yfN7FLjTcAcAAAAAAAAAHJ7AHX1Jw93HXZmvJ0nfNNwlyXStHUi7s7pR8CSddavezNSx0VTKw0WPUqzX3mmfg9xy92ilrIY7AAAAAAAAAODwBO7oS9W9hrs1DXePXL65F7jro4a7FzVwt1hv5uT4p3id7L5Xv9I+Bzpwt5AMjyZHp4qeBAAAAAAAAAB4AQjc0ZeOjWq4+2FXbtZz+viRnKj2z5rTl46OZnio9EIF7nZ3W7m92szshMBdqtPJy59vB+5araKneT6NhfY62VKp6EkAAAAAAAAAgBeAwB19aXiolGqlnFWBuyTJ+uZOvn97ta/a7ZL2r9PUsdHcWXtxAnfLDzaztdPKjMBd22vvJGu3krvfK3qS59OYt04WAAAAAAAAAOgYgTv6VrVSzmpzq+gx+sLvL9az20rePNNfgbukvVb2RWq4u9VoJklmrJRte+2d9jmIa2W31pP1e+2GOwAAAAAAAACADhC4o29Vx8pZa2q4S5LLN+tJ0ncNd8mHgbvWoK4c/SGL9b3AnYa7tnNfTkpDyXu/WfQkz66x0D4F7gAAAAAAAACADhG4o29VK+WsWSmbJLnSz4G7aiUb27svzK/VUkPg7iOOHE9mfzR577eT3d2ip3k2jwJ3VsoCAAAAAAAAAJ0hcEffqmm4e+TyfD2vTB7JS8dGix7lY6ZrlSR5YdbKLtXXkySzAncfeu2dpHk/uXWl6EmejYY7AAAAAAAAAKDDBO7oW9VKOWub29ndfTFWlT6vBxvbuXZnLW+dPl70KJ/oRPXFCtztr5Q9OS5w98hr77TP936r2DmeVWO+fQrcAQAAAAAAAAAdInBH36qNldNqJQ+3dooepVDfWWik1Uq+0IfrZJMfaLhbezECd7cazVQr5dTGRooepX+c/YlkaGQAA3dWygIAAAAAAAAAnSVwR9+qVtqBp9XmVsGTFOvyzftJkrfO9Hng7gVquDs5Xil6jP4yeiw580eT6/8y2Rmg34+NhWSonBybLnoSAAAAAAAAAOAFIXBH36qOlZMka83tnt/9d3/zWv70r/xOmn3Qrndlvp4k+cIpgbtua7VaWao3MztxpOhR+s9r7ySba8nC7xY9ycE15pPabDI0XPQkAAAAAAAAAMALQuCOvlWrtAN3qxu9D9z9o0vzuXyznv/l39zo+d0/7MrNel6dOpqJo/254vRFCtytbmzn4eZOTo6PFT1K/3ntnfb53m8WO8ezaCwk46eKngIAAAAAAAAAeIEI3NG3imq4q69v5Xu3V5O0m+6KbLlbbW7l3bsP8uaZ44XN8DS1SjmV8lDurA1+4O5WvZkkmZ0QuPuYMz+elI8k7/1W0ZMczPZm8uC2wB0AAAAAAAAA0FECd/St6l7D3VqPG+6+9cH9tFrJ3PSx3Gps5H//dx/09P4f9O35RpLkzdPjhc3wNKVSKdO1ygvRcLe4F7ibEbj7uHIlOfeTyY1/nWw1i57m6VYX2+f46WLnAAAAAAAAAABeKAJ39K2iGu4uXl9JkvwP//GbmTo2mr/zL65lY7uYlrsr8/eTJG+e7t+GuyQvTOBuqbEXuLO80goQAAAgAElEQVRS9pOd+6lkZyNZ/FbRkzxdY6F9argDAAAAAAAAADpI4I6+Nb4XuGs0t3p676XrKxkbGcqPv/pS/ut3Xs9ivZlfvzjf0xn2Xb5ZT5J8oY8b7pJkulrJ8oPN7Oy2ih7lUJY03D3Zy59rn8tXi53jIBp7v2cF7gAAAAAAAACADhK4o29VKyNJertSdme3ld+9sZK3zhzPyPBQ/sJPnMtLR0fyjX9+NVs7uz2bY9+35+t5ffpYamMjPb/7WUzXKtnZbWXl4WbRoxyKlbJPMTnXPgcicLffcGelLAAAAAAAAADQOQJ39K0iVsp+79ZqHmzu5MK5l5Ikxyrl/OWvvJ75++v5R5d623JXf7iV95cf5q3TEz2993lM1ypJMvBrZW81mhkdHsrk0dGiR+lPk68lKSXL14qe5OmslAUAAAAAAAAAukDgjr5VrewF7nrYcHfx+kqS5MLZlx699nM/eS7jY+X8yj+/mu0ettx9e2F/nazAXa8s1pt5ebySoaFS0aP0p3IlOX52QAJ380lpKKmeLHoSAAAAAAAAAOAFInBH39oP3K32MHB3aS9w9/a5DwN3tbGR/Pwffz037j3MP/7WQs9muXyzHbh768zxnt35vKarL0bg7lajmVnrZJ9sai65926y2/sVy8+ksdAO2w339zpmAAAAAAAAAGCwCNzRt4aHSjk6OtzTlbIXb6zk9RPHMnnsoytF/8ufejW1Srvlbme31ZNZrszfT6mUfP7UeE/uO4z9hru7a4MbuGtu7eTeg82cHBe4e6Kp88n2erLau/Dpc2ksWCcLAAAAAAAAAHScwB19rTZWzmpzqyd33VndyPXlhx9pt9s3cWQk/9VPvZr37j7I/3m5N0GjK/P1nJ+u5the018/exFWyt5utGfXcPcUk3Pts5/Xyu5sJ2tLAncAAAAAAAAAQMcJ3NHXqpVy1nq0UvbSjfY62QufELhLkr/0x1/LsdHh/PI/637L3cqDzXxwbz1vnpno6j2dcmJ/pewAN9wt1teTJDMTRwqepM9NnW+fy1eLneNJ1m4lrd1k/HTRkwAAAAAAAAAALxiBO/padWykZytlL11/cuDu+NHR/MUvv5qrt9fy/3x7sauzXJmvJ0nePD0YgbuxkeHUxsoD3XC31GgmSWaslH2yqdfb5713i53jSRp7LZQa7gAAAAAAAACADhO4o6/VKuWs9qjh7uL1ldTGyjk/XX3sZ/7yV17P0dHh/PJvXM1uF1vu9gN3bw1Iw13SXis70IG7+l7gzkrZJ5s4mwyN9HfD3ep+4E7DHQAAAAAAAADQWQJ39LX9lbKtVndXuG5s7+TyfD1vn30pQ0Olx35u8tho/sJPnMsf3lrN//v7S12b5/LN+xkqJT8yO0CBu2plwFfKCtwdyHA5mXytvwN3Gu4AAAAAAAAAgC4RuKOvVcfKabWSh5s7Xb3nOwuNbG7vPnad7A/6y195PWMjQ/lbv3G1a0HAb8838pmTtRwZHe7K87thulbJ/Ydb2dju7q9Vt9xqNFMqJS/XKkWP0v8m55KV95Od3rRPPrPGfPsUuAMAAAAAAAAAOkzgjr5WGysnSda6vFb20vWVJDlQ4G66Vsl/8cfO5buLjfzT797u+Cx31zYyf389b54enHa7pP3fJUmW1zYLnuT5LNabOVGtZGTYH4tPNTWX7G4n968XPckn22+4q80WOwcAAAAAAAAA8MKRLKGv1SrtwN1qc6ur91y8vpKhUvLFV44f6PO/8M7rGS0P5W//xvc73nJ3Zb6eJHnzzGAG7u6sDuZa2VuNZmatkz2Yqbn2ee/dYud4nMZCcmw6KWsrBAAAAAAAAAA6S+COvlYd2w/cda/hrtVq5d9dX8lnZ8ZT3Qv4Pc3L42P5c186myvz9fyLP7zT0Xmu3NwL3A1aw111cAN3O7ut3F7dyMlxgbsDmTrfPpevFjvH4zTmrZMFAAAAAAAAALpC4I6+Vq2MJOnuStmbK+u5s7qRC+cO1m637xf+xOsZHR7K3+pwy93lm/WUh0r53Ox4x57ZC48a7tYGL3B3d20jO7stDXcHNbnXcLd8rdg5PsnubtJYTMZPFz0JAAAAAAAAAPACErijr+033K11seHu0o2VJMmFcy890/dmJ47kP/ujr+RbH9zPb3//bsfm+fZ8PZ85WcvYyHDHntkLg7xSdrHeTBINdwdVm01GjvZnw93Du8nuloY7AAAAAAAAAKArBO7oa7W9Fa+rXWy4u3h9L3B3dvKZv/vf/PRcRoZLHWu5u91oZqnRzFtnBmudbDLYgbulvcCdhrsDGhpKJl/vz4a7xnz7FLgDAAAAAAAAALrgQIG7r3/963n11VdTKpXy7W9/+9Hr3//+9/PlL385n/nMZ/KlL30pv//7v3+g9+Cgaj1ouLt4fSUnqpW8Mnnkmb97+viR/OyFV3Lx+kr+5bXlQ89yZb6eJPnC6cEL3E0dq2SoNKiBu/UkyYzA3cFNzSX1D5KtZtGTfFRjoX1aKQsAAAAAAAAAdMGBAnc/+7M/m9/5nd/JuXPnPvL6L/zCL+Sv/JW/ku9973v5pV/6pfz8z//8gd6Dg9pfKbvapcDdg43tfHexkQvnjqdUKj3XM/7bn55LeajdcndYl2+2A3eD2HA3PFTK5LFK7qwNXuBusdEOjc1YKXtwU+eTtJKV94qe5KP2A3e12WLnAAAAAAAAAABeSAcK3L3zzjs5c+bMR167fft2Ll26lD//5/98kuTP/tk/m/feey/vv//+E9+DZ1HdWym7trHVlef/3gf3s9tKLpx76bmf8crk0fyZt0/n37x3L//q3cO13F2Zr2dkuJTPztQO9ZyiTNcquTuAgbtbeytlNdw9g8m59tlva2UfrZTVcAcAAAAAAAAAdN6BAnef5IMPPsipU6dSLrcDUaVSKWfPns2NGzee+N4n+Zt/82/mzJkzj/5ZW1t73rF4wdQqI0mStY3uNNxdvL6S5HCBuyT5xZ85n+GhUv72IVruWq1WrszX80dmxlMpDx9qnqJM1yoDuVJ2sd7M+Fg5R0fLRY8yOKbOt8/lq8XO8cMerZTVcAcAAAAAAAAAdN5zB+6SfGwFZ6vVOtB7P+yv//W/nps3bz76p1qtHmYsXiDHKu3gWbdWyl68sZLR4aF8/tThVriemzqW/+hHT+VfXlvOv33/3nM941ZjI3dWN/LmAK6T3TddreTh5k4edCkg2S23Gs3MThwpeozBMrXXcHev3xruFpKx48nosaInAQAAAAAAAABeQM8duHvllVdy8+bNbG+3gzWtVisffPBBzp49+8T34FmUh4dyZGS4Kw13u7utXLq+ki+cHs/YyOEb5X7xZ85nqJTnbrm7fPN+kuTN04MbuDtRG02SgWq5a7VaWaw3rZN9VkenkrGJ/lwpa50sAAAAAAAAANAlzx24e/nll/NjP/Zj+ft//+8nSX791389r776al599dUnvgfPqjZWzloXGu6u3VlLo7l96HWy++amq/kPv3gqv/39u7l0Y+WZv39lvp5ksAN309VKkuTO2uAE7u4/3MrG9m5mBe6eTamUTM71V+Cu1Wo33I2fKnoSAAAAAAAAAOAFdaDA3S/+4i/mzJkzuXnzZr72ta/l/PnzSZJf/dVfza/+6q/mM5/5TP7G3/gb+Xt/7+89+s6T3oNnUR0rd2Wl7H4orlOBuyT5737mfEql5Jefo+Xu8s16RstD+czJWsfm6bXp2l7gboAa7hbq60mi4e55TJ1P1paSjdWiJ2lbX0m2mwJ3AAAAAAAAAEDXlA/yoW984xv5xje+8bHXP/vZz+ab3/zmJ37nSe/Bs6hVyrm7ttnx51683g7cvX22c4G7N07W8qfenM3/dXkxl2/ez1tnjh/oe61WK9+er+dzs+MZLT938WThBjFwt1RvJklOTRwpeJIBNNUOX2f5WnLqR4udJWmvk02slAUAAAAAAAAAumZwkz18arQb7rY6/tyL11fyyuSRvDze2Wazv/on2yGkv/0bVw/8nYV6M8sPNvPWAK+TTZKXBzBwt7gXuNNw9xym5trnvT5ZK9tYaJ8a7gAAAAAAAACALhG4o+9VK+WsbWyn1Wp17JkrDzZz7c6DXOhgu92+PzIznn//8zP5p9+9lW/P1w/0nSs37ydJ3hzwwN10tR1aG6TA3X7D3azA3bPbD9wt90vgbr/hTuAOAAAAAAAAAOgOgTv6XrUykt1Wsr6107Fn/u4H7XWyF851PnCXJH/1q+2Wu1/5Zwdrubt8sx3Me/PMYAfuxo+UMzo8lDtrgxO403B3CJP9Frjbb7izUhYAAAAAAAAA6A6BO/pebaycJFlrbnfsmRevtwN3b3cpcPf5UxP52udO5p98Zyl/sNR46uevzNdTKQ/ljZerXZmnV0qlUqZrlcFquGusp1oppzY2UvQog2dsPDn2crJ88PXJXWWlLAAAAAAAAADQZQJ39L39wF2jw4G7Y6PD+ezJWsee+cO+vtdy98tPablrtVq5Ml/P50+Npzw8+L8lTwxY4G6x3tRudxhTc8m9fmm4m09Ga+0gIAAAAAAAAABAFwx+uocXXrWy13C30ZnA3dbObn7vg3p+9Ozxrgbc3jpzPD/z2en831cW8/1bq4/93M2V9dx/uJW3zhzv2iy9NF2t5O7aRnZ3W0WP8lStVitL9WZmBe6e39Rcsr6SPLxX9CTthjvtdgAAAAAAAABAFwnc0feqHV4p+weLq1nf2snbZ7uzTvYH/dWvvpFWK/mVf/74lrvLN+tJki+cnuj6PL0wXatke7eV++tbRY/yVI3mdh5u7mRmXODuuU3Otc/lglvuWq2kPi9wBwAAAAAAAAB0lcAdfe/DhrvOBLguXm83cb19rvuBu7fPvpSvvHEi/8fvLeTanbVP/Mzl+ftJkrfOvDiBuyQDsVZ2qd5MEg13hzHVXp2c5SevTu66jUay9SAZP13sHAAAAAAAAADAC03gjr5X22u4W+1Qw93FG+2A29uvdD9wlyR/7atvZLeVfOMxLXdXbtZzZGQ4c9PVnszTbfuBu7tr/R+4W6yvJ0lmJo4UPMkA65fAXWOhfWq4AwAAAAAAAAC6SOCOvletjCRJ1jY6E7i7dH0lb7xczcTRkY4872l+/NXJ/NT5qfzjby3k/bsPPvJeq9XKlfl6vnB6PMNDpZ7M023TVQ13nyqTr7XPewWvlG3Mt0+BOwAAAAAAAACgiwTu6HudbLhbrK9n/v56LvRgnewP+vqffCM7u638nX/x0Raw68sPs9rczpunj/d0nm4apJWyi3uBuxmBu+c3ciSZeKWPGu6slAUAAAAAAAAAukfgjr5XrbQDd51ouLt0fW+dbI8Dd3/s9an8sdcm8w8vzeeDew8fvX55vp4kefPMeE/n6aZHDXcDsFJWw12HTL6eLL+btFrFzWClLAAAAAAAAADQAwJ39L1ONtxdvL6SJD1vuEuSv/bVN7L9Qy13V262A4AvUsPdidpokgFpuGs0MzYylIkjvVkv/MKaOp9sPUhWl4qbwUpZAAAAAAAAAKAHBO7oe8c62HB38cZKjh8dyesnjh36Wc/qJ+em8uPnXso/uHgzN1faLXeXb9ZzbHS4kHm65ehoOdVKeSACd0v19cxOHEmpVCp6lME2Ndc+710rbobGQlI+khzpfZgWAAAAAAAAAPj0ELij740MD2VsZChrza1DPae5tZPvzNdz4exLhQSsSqVSvv7VN7K108rf/c1r2d1t5TsLjXzh9ESGhl6swNd0rTIQgbvF+83MjFsne2hT59vn8tUnf66bGgvtdjvhSQAAAAAAAACgiwTuGAjVysihG+4u36xne7eVtwtYJ7vvK2+cyI++cjz/27+9mW++u5y1je28dWaisHm6ZbpayZ21/g7crTa3srqxndnjAneH9ihwV2TD3bx1sgAAAAAAAABA1wncMRDGx8pZbR4ucHfx+kqS5EKBgbtSqZS/9tU3srmzm1/6B5eTJF84/QIG7mqV3Huwma2d3aJHeaxbjWaSZHZC4O7Qjp9NSsPFBe421pJmPRk/Xcz9AAAAAAAAAMCnhsAdA6HaocDd8FApXzxzvENTPZ+f/ux03jw9kfn760mStwqepxuma5UkyfLaZsGTPN5ivR24m5k4UvAkL4DhkeSlV4tbKbu62D413AEAAAAAAAAAXSZwx0CoVsqHWinbarVy6cZKPn9qPEdGhzs42bMrlUr5+lffSJLUxso5N3m00Hm6YT9wd2e1f9fK7gfuZsc13HXE1Fyy8l6yu9P7uxvz7VPgDgAAAAAAAADoMoE7BsJ+4K7Vaj3X999ffph7Dzbz9tni1sn+oK997uW885np/AdvncrQUKnocTpuuroXuFtrFjzJ4y09argTuOuIqfPJzmZS/6D3dzcW2qeVsgAAAAAAAABAl5WLHgAOojpWzs5uK82t3edqqLt4fSVJcuFcfwTuSqVSfu0vfanoMbpmoBruBO46Y/L19rl8rb1etpc03AEAAAAAAAAAPaLhjoFQq7SzoasbW8/1/Us3+itw96IbhMDdUn09o8NDmTw2WvQoL4ap8+1z+Vrv79ZwBwAAAAAAAAD0iMAdA6E2NpIkWWtuP9f3L11fyezEWE4dP9LJsXiMQQjcLdabmZkYS6n04q30LcTUXPu8V1Dgbng0OTrV+7sBAAAAAAAAgE8VgTsGQnVsr+HuOQJ3jeZW/vDWat7Wbtczk8dGUyold9c2ix7lsZYa7cAdHTJ+JhmuJMtXe393Yz6pzSZD/koDAAAAAAAAALpLOoGBUN1bKbu28eyBu2/duJ9WK7lwVuCuV0aGhzJ5dLRvG+7WN3dy/+FWZgXuOmdoqN1yV0jgbsE6WQAAAAAAAACgJwTuGAi1QzTcXby+kiQa7npsulbJnbX+DNwtNZpJouGu0yZfT+7fSLZ72Gy41UweLifjp3p3JwAAAAAAAADwqSVwx0A4TMPdpRsrqZSH8iOz450eiyeYrlX6tuFusb6eJJkdF7jrqKnzSWs3WXm/d3euLrRPgTsAAAAAAAAAoAcE7hgIjwJ3za1n+t7Obiu/e+N+vnjmeEbL/nfvpRPVStY2tvNw89lDkt22VN9vuDtS8CQvmKm59nnvWu/ubOwH7qyUBQAAAAAAAAC6TwKJgVAbG0ny7A1337u1mrWNbetkCzBdqyRJ7q72cL3oAS3uBe5mrZTtrKnz7XP5au/ubGi4AwAAAAAAAAB6R+COgVAbazfcrTafLXB38fpKkuSCwF3PTVfbgbs7a82CJ/m4JYG77pjca7hb7mXD3Xz71HAHAAAAAAAAAPSAwB0DYX+l7OozNtxd2gvcvX32eMdn4sn2G+7urG4UPMnHLdabKQ+VcmIvFEiHVF9ORmsa7gAAAAAAAACAF5bAHQPh2F7gbu1ZG+5urOS1E8cyJVjVc/0duFvPyfGxDA2Vih7lxVIqJVNzyb13e3dnYyEpDbfDfgAAAAAAAAAAXSZwx0AYLQ+lUh7K2jM03N1Z3cj15Yd5+6x1skXo58DdUr1pnWy3TM2117xuPujNfY35pDabDA335j4AAAAAAAAA4FNN4I6BURsrP1PD3aUb7XWyF84J3BVheq9V8M5afwXumls7WX6wmRmBu+6YOt8+e9Vy11iwThYAAAAAAAAA6BmBOwZGbWwkq8/QcHfpusBdkSaOjGRkuNR3DXe3G+15NNx1yeRc+1y+1v27tjeTtdsCdwAAAAAAAABAzwjcMTCqlXJWm1sH/vzF6yupVcp54+VqF6ficYaGSjlRrfRd4G6xvp4kmZk4UvAkL6j9hrvlq92/a20pSSsZP939uwAAAAAAAAAAInDHAKlWylk7YMPdxvZOLs/X82PnXsrQUKnLk/E407X+C9wtNZpJNNx1zdTr7bMXK2UbC+1Twx0AAAAAAAAA0CMCdwyM6lg5a83ttFqtp372OwuNbG7v5sJZ62SLNF2t5O7a5oF+zXplsd4O3M0I3HXHkZeSo1O9abhrzLdPgTsAAAAAAAAAoEcE7hgYtUo527utbGzvPvWzl66vJEkunBO4K9J0rZLNnd001g/WTNgLS3UNd103OZcsX+v+PY8a7qyUBQAAAAAAAAB6Q+COgVEdKydJVptPD29dvL6SoVLyxVcmuj0WTzBdqyRJ7qw1C57kQ4v19QyV2u17dMnU+eTh3WT9fnfvsVIWAAAAAAAAAOgxgTsGRm0vcLe28eTAXavVyr+7vpLPzoynNjbSi9F4jP3A3e3VjYIn+dBSvZmXa2MpD/vjr2um5trnvS633DXmk5SS2kx37wEAAAAAAAAA2CNxwsCoVtrhubWnNNzdXFnPndWNXDh3vBdj8QT7LXJ3+ihwt1hvZsY62e7aD9x1e61sYyGpnkyGBWsBAAAAAAAAgN4QuGNgfLhSduuJn7t0YyVJcuHcS12fiSc7UeuvwN3Wzm7urG1kVuCuu6bOt8/lq929p7FonSwAAAAAAAAA0FMCdwyMWmUvcPeUlbIXr+8F7s5Odn0mnuxRw91afwTubq9upNWKhrtum3y9fXaz4W53J1kVuAMAAAAAAAAAekvgjoFR3QvcPW2l7MXrKzlRreSVySO9GIsnmO6zhrul+nqSaLjrttFjSe1Udxvu1m4nrR2BOwAAAAAAAACgpwTuGBj7K2XXntBw92BjO3+wtJq3zx5PqVTq1Wg8xrFKOUdHh/smcLdYbyZJZiaEMbtuai65927SanXn+Y2F9ilwBwAAAAAAAAD0kMAdA+NRw90TAne/d/N+dnZbuXDupV6NxVNM1yp9E7hb2gvcndJw131Tc8lGI3lwpzvPb8y3z/HT3Xk+AAAAAAAAAMAnELhjYIyPjSRJVp+wUvbS9ZUkEbjrI9PVSu6u9Ufg7sOGO4G7rpuca5/L17rzfA13AAAAAAAAAEABBO4YGPsrZVebW4/9zMXrKxkZLuULpyd6NRZPMV2rZPnBZrZ3doseJYv19ZRKycs1gbuumzrfPpevduf5jxruBO4AAAAAAAAAgN4RuGNgHKsMJ3n8Stnd3VYu3bifL5yeyNjIcC9H4wmma5W0Wsm9B5tFj5LFejMnqpWMlv3R13X7gbt7XW64qwncAQAAAAAAAAC9I3XCwKiUhzNaHsraY1bKvnt3LfX1rVw4a51sP5muVpIkt1eLXyu7VG9m1jrZ3njp1aQ01MWGu4Xk6FQy4tcTAAAAAAAAAOgdgTsGSq1SzupjGu4uXl9Jklw4J3DXT6Zr7cDdnbViA3fbO7u5vbqRmXEBrZ4ojybHzybL3Wq4m7dOFgAAAAAAAADoOYE7Bkp1rPzYhrv9wN3bAnd95VHgruCGu7trm9nZbWm466XJueTeu8nubmefu7ubrC4m46c7+1wAAAAAAAAAgKcQuGOg1MbKWXtCw92Zl47kpAazvrIfuLtbcMPdYn09STIzcaTQOT5Vps4n2812G10nPVxOdjY13AEAAAAAAAAAPSdwx0CpVspZbW597PWVB5u5dueBdbJ9qF8a7pbqzSTRcNdLU3Pt816H18ruB/gE7gAAAAAAAACAHhO4Y6BUKyNZ29hOq9X6yOu/+0F7nazAXf+ZOtYfgbvFvcDdjMBd7+wH7pavdva5jYX2aaUsAAAAAAAAANBjAncMlNpYOVs7rWxs737k9YvX24G7t88K3PWb0fJQXjo6Unjgbqmh4a7nps63z+V3O/tcDXcAAAAAAAAAQEEE7hgo1Uo5SbK2sf2R1y9eX8nR0eH8kZlaEWPxFNO1Su6s9UfD3clxgbuemXglGR7VcAcAAAAAAAAAvDAE7hgo1bG9wF3zw8Dd1s5ufu+Den70leMpD/tfuh+dqFaKb7irr2fy2GjGRoYLneNTZWg4eem15N61zj53P3BXm+3scwEAAAAAAAAAnkI6iYFSG/t4w90fLK5mfWsnF85ZJ9uvpmuVrDa309zaKWyGxXozM9rtem9qLll5P9nZ6twzG/PJ2ERSqXbumQAAAAAAAAAAByBwx0Cp7a2UbTQ/DO9cvH4vSfK2wF3fmq5WkqSwlrvd3VZuNZqZnRC467mpuWR3O7l/o3PPbCxYJwsAAAAAAAAAFELgjoHySStlL964nyR5+xWBu341XdsL3K0VE7hbfrCZrZ1WZo8L3PXc5Fz7XO7QWtlWay9wd6ozzwMAAAAAAAAAeAYCdwyUamUkyUdXyl66vpI3Xq5m4uhIUWPxFI8CdwU13C3Vm0mS2Ykjhdz/qTZ1vn0uX+3M89ZXku11gTsAAAAAAAAAoBACdwyU6t5K2f3A3WJ9PfP313PBOtm+VnTgbrG+niSZGddw13NTew139zrUcNdYaJ9WygIAAAAAAAAABRC4Y6DU9lbKru6tlL10fW+drMBdXys+cLffcCdw13O12WTkaOca7h4F7jTcAQAAAAAAAAC9J3DHQNkP3O033F28vpIkefuswF0/m67uBe7Wig3czQjc9V6p1G65W363M89rzLdPgTsAAAAAAAAAoAACdwyURytl9xruLt5YyfGjI3n9xLEix+IpXjo6muGhUmENd0v7K2UF7ooxOZfUP0i21g//LCtlAQAAAAAAAIACCdwxUKqPVspupbm1k+/M1/P22ZcyNFQqeDKeZGiolBPV0UJXyk4cGcnR0XIh93/qTZ1P0kruvXf4Z1kpCwAAAAAAAAAUSOCOgVIpD2d0eChrG9u5Ml/P9m4rF85ZJzsIpmuV3C1opexSo5lZ7XbFmZprn/euHf5ZjflktJpUxg//LAAAAAAAAACAZyRwx8CpjpWz2tzOxesrSZK3zwrcDYLpaiV3VjfSarV6em+r1cpivWmdbJGmzrfP5auHf1Zjod1uV9JqCQAAAAAAAAD0nsAdA6daKWdtox24Gx4q5YuvTBQ9EgcwXatkY3s3qxvbPb135eFWNrd3NdwVaXKv4W65Ew13C9bJAgAAAAAAAACFEbhj4NT2Gu4uXV/Jj8yO5+houTE+gd0AACAASURBVOiROIDpWiVJcme1t2tlF+vrSZKZ8SM9vZcfcHQyGTt++MBds5FsribjpzszFwAAAAAAAADAMxK4Y+BUK+XcXHmY5QebuXDOOtlBMV0tJnC3VG8miYa7IpVK7bWy9w4ZuGsstE8NdwAAAAAAAABAQQTuGDi1sXJ2W+2f3xa4GxgnCmu4awfuZgTuijU1l6zdarfUPa/GfPsUuAMAAAAAAAAACiJwx8CpVj5cIavhbnBouPuUmzrfPu+9+/zPeNRwZ6UsAAAAAAAAAFAMgTsGTnWsHbibGR/LKSGqgTG933C3puHuU2ny9fa5fPX5n2GlLAAAAAAAAABQMIE7Bk61MpKk3W5XKpUKnoaDmi5opexSYz21Sjm1sZGe3ssP2W+4W772/M94tFJWwx0AAAAAAAAAUAyBOwZOba/h7m3rZAdKtVLO2MhQzwN3i/Wmdrt+MDXXPu8dJnC3kJTHkiN+7wMAAAAAAAAAxRC4Y+B89mQto8ND+ROfOVH0KDyDUqmU6Vqlp4G7VquVJYG7/lCpJdWTh18pO34q0WwJAAAAAAAAABSkXPQA8Ky+9iMnc+W///dSKQ8XPQrPaLpayQcr6z27r9HczsPNncwK3PWHybnk9neSVuv5QnON+WTmzc7PBQAAAAAAAABwQBruGEjCdoNpulbJ8tpGdnZbPblvqd5MksxMHOnJfTzF1FzSrCcP7z37dzcfJM377YY7AAAAAAAAAICCCNwBPTNdq2S3ldx7sNmT+xbq7TY9DXd9Yup8+7x37dm/21hsnwJ3AAAAAAAAAECBBO6AnpmutoNvd1Y3enLfhw13And9YWqufS5fffbvNubb5/jpzs0DAAAAAAAAAPCMBO6AnpmuVZIkd9d6E7hb3AvcabjrE/sNd8vP03C30D413AEAAAAAAAAABRK4A3pmP3DXu4a7vZWy40d6ch9P8dJrSUqHbLgTuAMAAAAAAAAAiiNwB/TMo8BdDxvujowMZ/xIuSf38RQjY8nEK4dsuLNSFgAAAAAAAAAojsAd0DO9b7hrZnZiLKVSqSf3cQBTryf3riWt1rN9r7GQDI0kR090Zy4AAAAAAAAAgAMQuAN65kR1NElvA3czE2M9uYsDmjqfbD1MVhef7XuN+WR8Nhny1xYAAAAAAAAAUBzJBaBnKuXhTBwZ6UngbrW5ldWNbYG7fjN1vn0+61rZxoJ1sgAAAAAAAABA4QTugJ46UR3NnbXuB+5uNZpJklmBu/4yOdc+l68e/DtbzeTh3WT8VHdmAgAAAAAAAAA4IIE7oKema5WeNNwt1tuBu5mJI12/i2cwtRe4u/cMDXf762cF7gAAAAAAAACAggncAT01XRtLfX0rG9s7Xb1nP3A3O67hrq8cP5cMlZ9tpWxjoX1aKQsAAAAAAAAAFEzgDuip6WolSXJ3bbOr9yztB+6OC9z1leFy8tKrzxm403AHAAAAAAAAABRL4A7oqelaO3DX7bWyjxrurJTtP5Nzyb13k90Dthw25tunhjsAAAAAAAAAoGACd0BP9Spwt1Rfz2h5KC8dHenqPTyHqfPJ7lZy/8bBPq/hDgAAAAAAAADoEwJ3QE/1suFudmIspVKpq/fwHKZeb5/3DrhWtjGflIaT6snuzQQAAAAAAAAAcAACd0BPTVd71HDXaGZmfKyrd/Ccps63z+WDBu4WktpMMjTcvZkAAAAAAAAAAA5A4A7oqUcNd2vNrt2xvrmT+w+3MjshcNeXnitwN9u9eQAAAAAAAAAADkjgDuipyWOjGSold1c3u3bHYn09STIzcaRrd3AItVNJeSxZvvr0z+5sJWu3kvFT3Z8LAAAAAAAAAOApBO6AnhoeKmWqWsmdte6tlF2qt9vzNNz1qaGhZHIuuXeAhrvVpSStZPx018cCAAAAAAAAAHgagTug56arldxZ7V7gbnEvcDcjcNe/pl5P7t9Itp/SdNhYaJ8a7gAAAAAAAACAPiBwB/TcdK0duGu1Wl15/lJDw13fmzqftHaTlfef/LnGfPsUuAMAAAAAAAAA+oDAHdBz07VK1rd28mBzpyvPX6yvJ9Fw19cm59rn8tUnf251sX1aKQsAAAAAAAAA9AGBO6DnpmuVJOnaWtmlejPloVJOHKt05fl0wNT59vm0wJ2VsgAAAAAAAABAHxG4A3ruRLW7gbvFejMnx8cyNFTqyvPpgP3A3b1rT/7c/krZ2mx35wEAAAAAAAAAOACBO6DnetFwN2udbH87diKpjCfLTwvcLSTHXk7Ko72ZCwAAAAAAAADgCQTugJ6bftRw1+z4s5tbO1l+sJkZgbv+ViolU3MHC9xZJwsAAAAAAAAA9AmBO6DnHjXcrXW+4e52o/3MU8ePdPzZdNjkXLK6kGw++OT3d3eS1cVk/HRv5wIAAAAAAAAAeAyBO6DnurlSdrG+niSZGddw1/emzrfPe+9+8vsP7iS72xruAAAAAAAAAIC+IXAH9Nz4WDmj5aGuBO6WGu01tbNWyva/qbn2uXz1k99vzLdPgTsAAAAAAAAAoE8I3AE9VyqVMl2tdGWl7GK9HbibEbjrf08N3C20TytlAQAAAAAAAIA+IXAHFGK6VulOw119v+HuSMefTYdN7gfuHrNS9lHgTsMdAAAAAAAAANAfBO6AQkzXKrm7tpnd3VZHn7tYX8/wUCnTtUpHn0sXHDmeHD1hpSwAAAAAAAAAMDAE7oBCTNcq2dlt5f76Vkefu1Rv5uVaJcNDpY4+ly6ZOp/cu/bJ72m4AwAAAAAAAAD6jMAdUIjparuBrtNrZRfqzcxMjHX0mXTR1FzycDlZX/n4e42F5MhkMmI9MAAAAAAAAADQHwTugELsr3ztZOBuc3s3d9c2MitwNzim5trn8rsff68xn4yf7u08AAAAAAAAAABPIHAHFOJR4G6t2bFn3l5tptVKZsY1og2Myf3A3dWPvt5qtRvurJMFAAAAAAAAAPqIwB1QiG403C3V2+E9DXcDZOp8+7x37aOvP1xOdjYF7gAAAAAAAACAviJwBxRiutr5wN3iXuBuRuBucEy+3j5/uOGuMd8+rZQFAAAAAAAAAPqIwB1QCA13JElGj7ZDdR8L3C20Tw13AAAAAAAAAEAfEbgDCjE2MpxapZw7axruPvWm5pLld5NW68PXHjXcCdwBAAAAAAAAAP1D4A4ozHSt0tmGu8Z6SqXk5ZrA3UCZnEs2V5O12x++9qjhzkpZAAAAAAAAAKB/CNwBhTnR4cDdYr2ZE9VKRsv+aBsoU+fb571rH772KHA32/t5AAAAAAAAAAAeQyoFKMx0rZKVh1vZ3N7tyPOW6s2csk528EzNtc/lqx++1phPKhNJpVbMTAAAAAAAAAAAn0DgDijMdLWSJFl+cPiWu+2d3dxe3ciMwN3g2W+4W/6hhrvxU8XMAwAAAAAAAADwGAJ3QGGma+3AXSfWyt5d28zObiuzE0cO/Sx67Pi5pDT0YcNdqyVwBwAAAAAAAAD0JYE7oDCdDNwt1teTRMPdICqPtkN3995t/3vzfrL1UOAOAAAAAAAAAOg7AndAYToZuFuqN5MkswJ3g2lqrr1Sdne33W6XJOOni50JAAAAAAAAAOCHCNwBhZmutgN3d9c60XDXDtzNjAvcDaSp88nORtK4+QOBOw13AAAAAAAAAEB/EbgDCvNyJxvuGvsNd0cO/SwKMHW+fS5fSxrz7Z813AEAAAAAAAAAfaZc9ADAp9fksdGUSsmdDjTcLdxfT5K8PF459LMowOTr7XP5avLgTvtnDXcAAAAAAAAAQJ8RuAMKUx4eytSx0c403NWbmTo2mrGR4Q5MRs/tN9zdezfZaLR/FrgDAAAAAAAAAPqMwB1QqBPVSkcCd4v1ZmYmxjowEYWYOJMMj7Yb7na3k5FjydhE0VMBAAAAAAAAAHzEUNEDAJ9u07XDB+52d1u51WhmVuBucA0Nt9fKLl9LGgvtdrtSqeipAAAAAAAAAAA+QuAOKNR0rZIHmzt5sLH93M+4+2Aj27stDXeDbnIuWXk/uf+BdbIAAAAAAAAAQF8SuAMKNV2tJEnurj1/y91SvZkkmZ040pGZKMjUXNLaSbYeJOOni54GAAAAAAAAAOBjBO6AQk3X2oG7w6yVXdwL3M2Ma7gbaFPnP/xZwx0AAAAAAAAA0IcE7oBCdSJw92HDncDdQJua+/BngTsAAAAAAAAAoA8J3AGF2l8pe+cQK2X3G+5mj1spO9A+0nBnpSwAAAAAAAAA0H8E7oBCdabhbj2JlbIDr3oyGa22f9ZwB/9/e/cbWvdd93/8dZI0Z+lOmrr2dEltu3TQQreqHZu7Nl23qnA5cYIKYrGViUIHsuuOqBTBf6gTVCYM9ZYyiuJAmEMpaJHBhgMr62/O/uqfrus/l2tpm1ZNm9mTNuu5brSNduu2b9c032+XxwMC7cm/961+ON8+eX8AAAAAAAAAqCDBHVCqqQjuhkdbmTt7Vnq6O6dqLMpQqyVXXXv6zzbcAQAAAAAAAAAV1FX2AMDM1tczK7M6axe34e5oy3a7N4rB25LWaDL7qrInAQAAAAAAAAB4GRvugFLVarU0G/WMjL2+4K7dbmd4tJWBPsHdG8J/fz35n/93etsdAAAAAAAAAEDF2HAHlK7ZW3/dG+7+8a+TOTFxKv19PVM8FaXo6EziamAAAAAAAAAAoJpsuANK1+w9veGu3W5f8PcOjx5PEhvuAAAAAAAAAAC45AR3QOmavfWcfLGd0eMnL/h7D4y2kiT9gjsAAAAAAAAAAC4xwR1QumajniSv61rZ4TPBnQ13AAAAAAAAAABcaoI7oHTN3osJ7lwpCwAAAAAAAADA9BDcAaWbDO7GXv+Gu/6+nimdCQAAAAAAAAAAXkpwB5TuYjbcHRhtpbfelUa9a6rHAgAAAAAAAACAcwjugNI1G6evg329wV2/62QBAAAAAAAAAJgGgjugdPN7u5NceHDXbrczLLgDAAAAAAAAAGCaCO6A0s3u7sqV3Z0ZGbuw4O7o8YkcP/liBgR3AAAAAAAAAABMA8EdUAnN3voFb7gbPno8STLQ13MpRgIAAAAAAAAAgHMI7oBKeF3B3WgrSWy4AwAAAAAAAABgWgjugEpo9tbz93+dyMkXTxX+ngNngrt+wR0AAAAAAAAAANNAcAdUQrNRT7ud/P2FE4W/598b7lwpCwAAAAAAAADApSe4Ayqh2VtPkgu6VvbA6PEkNtwBAAAAAAAAADA9BHdAJbye4G54tJXZ3Z2Zc0XXpRoLAAAAAAAAAAAmCe6ASpgM7sYuZMNdK/19V6RWq12qsQAAAAAAAAAAYJLgDqiEZuP0tbAXdqVsKwOukwUAAAAAAAAAYJoI7oBKuNArZY+1TubY+ET65/RcyrEAAAAAAAAAAGCS4A6ohHmN7iTFr5Q9eLSVJDbcAQAAAAAAAAAwbQR3QCXM6uzIVVd2F95w9/w/Twd3/YI7AAAAAAAAAACmieAOqIxmo57DBYO7A6M23AEAAAAAAAAAML0Ed0BlNHvrhTfcDY/acAcAAAAAAAAAwPQS3AGVMb/RnWPjEzl+4sXX/NoDR48nSQb6ei71WAAAAAAAAAAAkERwB1RIs7eeJDk89tpb7oZHW+nu6sibZs+61GMBAAAAAAAAAEASwR1QIWeDu0MFrpU9MNrKQN8VqdVql3osAAAAAAAAAABIIrgDKuRscDdSILgbPhPcAQAAAAAAAADAdBHcAZXRbJwO6EZe40rZf52YyOjxkxno65mOsQAAAAAAAAAAIIngDqiQohvuDoy2kiT9NtwBAAAAAAAAADCNBHdAZVxocOdKWQAAAAAAAAAAppPgDqiMuT2z0tVRe83gbvjshrs5gjsAAAAAAAAAAKaP4A6ojI6OWuY36jk89hob7o6e3XDXMx1jAQAAAAAAAABAEsEdUDHN3nqBDXfHkyT9rpQFAAAAAAAAAGAaCe6ASmn21jMyNp52u/2KX3NgtJVZnbXMu7J7GicDAAAAAAAAAGCmE9wBldJs1HNi4lSOtiZe8WuGR1u5es4V6eioTeNkAAAAAAAAAADMdII7oFKavfUkedVrZQ+MtjLgOlkAAAAAAAAAAKaZ4A6olNcK7lonX8yRF06kv69nOscCAAAAAAAAAADBHVAtk8Hd2PmDu4NHW0liwx0AAAAAAAAAANNOcAdUymttuBsePR3c9c8R3AEAAAAAAAAAML0Ed0ClzG+8enB3YNSGOwAAAAAAAAAAyiG4Ayql8IY7wR0AAAAAAAAAANNMcAdUypXdnemZ1ZmRsVfacHc8SbJwbs90jgUAAAAAAAAAAII7oFpqtVqavfVX3XDX2VGbvHoWAAAAAAAAAACmi+AOqJxXC+4OHG3l6t56Ojtq0zwVAAAAAAAAAAAzneAOqJxmo56/vzCeF0+1X/a54dFW+vuuKGEqAAAAAAAAAABmOsEdUDnN3npOtZMjL5y75e7ExKkcHhvPQF9PSZMBAAAAAAAAADCTCe6Aymn21pMkh4+dOOf1Q8daabdjwx0AAAAAAAAAAKUQ3AGVcza4Gxk7d8PdgdFWkmRAcAcAAAAAAAAAQAkEd0DlNBtngrtj5wZ3w2eCOxvuAAAAAAAAAAAog+AOqJzJDXfHbLgDAAAAAAAAAKA6BHdA5bxScPfvDXc90z4TAAAAAAAAAAAI7oDKmdfoTpKMjL1kw93R46nVkgVngjwAAAAAAAAAAJhOgjugcupdnZk7e1ZGjrXOeX14tJVmo55Znf7pAgAAAAAAAABg+qlWgEpqNuovu1L2wGgrA31XlDQRAAAAAAAAAAAzneAOqKT5LwnuJl48lYNHW+kX3AEAAAAAAAAAUBLBHVBJzd56jrYm0jr5YpJkZGw8p9rJQF9PyZMBAAAAAAAAADBTCe6ASmr21pMkh8dOb7kbHm0liQ13AAAAAAAAAACURnAHVNLZ4O7stbIHzgR3A4I7AAAAAAAAAABKMiXB3a9//evcdNNNeetb35pbbrklf/zjH5Mka9asybXXXptVq1Zl1apV+e53vzsVvw6YAZqNc4O74cngzpWyAAAAAAAAAACUo+tif8A//vGPrF+/Pr/97W+zYsWKPP7441m3bl127NiRJHnggQdy1113XfSgwMwyueFu7OyGu+NJbLgDAAAAAAAAAKA8F73hbvfu3VmwYEFWrFiRJLnjjjuyf//+PPXUUxc9HDBzvfRK2bMb7hbMqZc2EwAAAAAAAAAAM9tFB3fLli3LyMhItm7dmiR55JFHMjY2ln379iVJPve5z+Utb3lLPvrRj2bPnj3n/Rn3339/Fi1aNPkxNjZ2sWMBl7mzwd3hyQ13rcxvdKfe1VnmWAAAAAAAAAAAzGAXHdz19fXl4YcfzsaNG3PjjTfmsccey3XXXZdZs2blxz/+cf7yl79k+/btWb169SteLfuZz3wmQ0NDkx+NRuNixwIuc2+a3Z3Ojto5G+76XScLAAAAAAAAAECJuqbih9x+++157LHHkiTj4+Pp7+/PihUrsnjx4iRJrVbLvffem89+9rM5cuRI5s2bNxW/FngD6+yoZd6V3Rk5Np5Tp9o5eLSVFQNzyh4LAAAAAAAAAIAZ7KI33CXJ8PDw5J+/9rWv5d3vfncGBwdz8ODBydcffvjhXH311WI7oLBmbz0jY+M5/MJ4Jk61M2DDHQAAAAAAAAAAJZqSDXdf/OIX88QTT2RiYiK33nprfvSjH2V8fDzvf//7Mz4+no6OjsyfPz+//OUvp+LXATNEs7ee3SNjGf5nK0lcKQsAAAAAAAAAQKmmJLj74Q9/eN7Xt23bNhU/Hpihmo16WidP5dlDY0liwx0AAAAAAAAAAKWakitlAS6FZm89SfL//3c0iQ13AAAAAAAAAACUS3AHVNbZ4G770D+TJAN9PWWOAwAAAAAAAADADCe4AyrrbHD3p+ePJkn659hwBwAAAAAAAABAeQR3QGXNb5wO7sYnTmXu7Fnp6e4seSIAAAAAAAAAAGYywR1QWWc33CW22wEAAAAAAAAAUD7BHVBZ/xncLZzbU+IkAAAAAAAAAAAguAMqrLfelXrX6X+m+vtsuAMAAAAAAAAAoFyCO6CyarXa5Ja7AVfKAgAAAAAAAABQMsEdUGlngzsb7gAAAAAAAAAAKJvgDqi0ZuPMhru+npInAQAAAAAAAABgphPcAZX27w139ZInAQAAAAAAAABgpusqewCAV/Ox/1qSN83uzrXzG2WPAgAAAAAAAADADCe4Ayrt+oV9uX5hX9ljAAAAAAAAAACAK2UBAAAAAAAAAACgCMEdAAAAAAAAAAAAFCC4AwAAAAAAAAAAgAIEdwAAAAAAAAAAAFCA4A4AAAAAAAAAAAAKENwBAAAAAAAAAABAAYI7AAAAAAAAAAAAKEBwBwAAAAAAAAAAAAUI7gAAAAAAAAAAAKAAwR0AAAAAAAAAAAAUILgDAAAAAAAAAACAAgR3AAAAAAAAAAAAUIDgDgAAAAAAAAAAAAoQ3AEAAAAAAAAAAEABgjsAAAAAAAAAAAAoQHAHAAAAAAAAAAAABQjuAAAAAAAAAAAAoADBHQAAAAAAAAAAABQguAMAAAAAAAAAAIACBHcAAAAAAAAAAABQgOAOAAAAAAAAAAAAChDcAQAAAAAAAAAAQAGCOwAAAAAAAAAAAChAcAcAAAAAAAAAAAAFCO4AAAAAAAAAAACgAMEdAAAAAAAAAAAAFCC4AwAAAAAAAAAAgAIEdwAAAAAAAAAAAFCA4A4AAAAAAAAAAAAKENwBAAAAAAAAAABAAYI7AAAAAAAAAAAAKEBwBwAAAAAAAAAAAAUI7gAAAAAAAAAAAKAAwR0AAAAAAAAAAAAUILgDAAAAAAAAAACAAgR3AAAAAAAAAAAAUIDgDgAAAAAAAAAAAAoQ3AEAAAAAAAAAAEABgjsAAAAAAAAAAAAoQHAHAAAAAAAAAAAABQjuAAAAAAAAAAAAoADBHQAAAAAAAAAAABQguAMAAAAAAAAAAIACBHcAAAAAAAAAAABQgOAOAAAAAAAAAAAAChDcAQAAAAAAAAAAQAGCOwAAAAAAAAAAAChAcAcAAAAAAAAAAAAFCO4AAAAAAAAAAACgAMEdAAAAAAAAAAAAFCC4AwAAAAAAAAAAgAIEdwAAAAAAAAAAAFCA4A4AAAAAAAAAAAAKENwBAAAAAAAAAABAAYI7AAAAAAAAAAAAKEBwBwAAAAAAAAAAAAUI7gAAAAAAAAAAAKAAwR0AAAAAAAAAAAAUILgDAAAAAAAAAACAAgR3AAAAAAAAAAAAUIDgDgAAAAAAAAAAAAoQ3AEAAAAAAAAAAEABgjsAAAAAAAAAAAAoQHAHAAAAAAAAAAAABQjuAAAAAAAAAAAAoADBHQAAAAAAAAAAABQguAMAAAAAAAAAAIACBHcAAAAAAAAAAABQgOAOAAAAAAAAAAAAChDcAQAAAAAAAAAAQAGCOwAAAAAAAAAAAChAcAcAAAAAAAAAAAAFCO4AAAAAAAAAAACgAMEdAAAAAAAAAAAAFCC4AwAAAAAAAAAAgAIEdwAAAAAAAAAAAFCA4A4AAAAAAAAAAAAKENwBAAAAAAAAAABAAYI7AAAAAAAAAAAAKEBwBwAAAAAAAAAAAAXU2u12u+whXqper6fZbJY9BhdhbGwsjUaj7DEAgIKc3QBw+XF+A8DlxdkNAJcf5zfAzDUyMpLx8fHzfq6SwR2Xv0WLFmVoaKjsMQCAgpzdAHD5cX4DwOXF2Q0Alx/nNwDn40pZAAAAAAAAAAAAKEBwBwAAAAAAAAAAAAV0fuUrX/lK2UPwxnTrrbeWPQIAcAGc3QBw+XF+A8DlxdkNAJcf5zcAL1Vrt9vtsocAAAAAAAAAAACAqnOlLAAAAAAAAAAAABQguAMAAAAAAAAAAIACBHcAAAAAAAAAAABQgOCOKbVr16684x3vyPLly3PzzTfnz3/+c9kjAQD/odVq5YMf/GCWL1+eVatW5c4778y+ffuSJIcOHcqdd96ZZcuWZeXKlXniiSfKHRYAOMdXv/rV1Gq17NixI4n34ABQZePj47n33nuzbNmyXH/99Vm/fn0S5zcAVNWWLVty44035oYbbsjKlSuzadOmJJ6bA3B+gjum1D333JMNGzbkmWeeyec///l86lOfKnskAOAlNmzYkJ07d+bpp5/OXXfdlQ0bNiRJNm7cmFtuuSW7du3Kgw8+mHXr1mViYqLkaQGAJHnqqaeydevWLFmyZPI178EBoLo2btyYjo6OPPPMM/nTn/6Ub3/720mc3wBQRe12Ox/72Mfy4IMP5g9/+EM2b96ce+65J8eOHfPcHIDzqrXb7XbZQ/DGcOjQoSxfvjyHDx9OV1dX2u12BgYGsnXr1gwODpY9HgBwHtu2bcvatWvz7LPPptFoZO/evWk2m0mSm2++Od/61reyZs2acocEgBlufHw8a9asyU9/+tO8613vyubNm7NgwQLvwQGgol544YW8+c1vztDQUBqNxuTrnqEDQDW12+3Mnz8/jzzySG6//fZs374973vf+7J3795cddVVnpsD8DI23DFlnnvuuSxcuDBdXV1JklqtliVLluRvf/tbyZMBAK/kgQceyAc+8IEcOXIkp06dmnxokCSDg4POcQCogC996UtZv359li5dOvma9+AAUF27d+/OvHnz8vWvfz033XRTVq9enUcffdT5DQAVVavV8rOf/Swf/vCHc8011+S2227Lpk2bcuzYMc/NATgvwR1TqlarnfN3CxQBoLruu+++7Nq1K9/4xjeSOMcBoIp+97vf5cknn8ynP/3pl33O2Q0A1XTy5Mns2bMn1113XbZt25bvfe97Wbt2bSYmJpzfAFBBExMT+eY3v5lf/OIX2b9/fx599NHcfffdSbz3BuD8BHdMmcWLF2doaGjyzvp2u53nnnsuS5YsKXkyAOClvvOd7+TnP/95fvWrX2X27NmZN29ekmRkHgxEoQAAAiZJREFUZGTya/bv3+8cB4CSPf744/nrX/+apUuXZnBwMENDQ3nve9+bHTt2eA8OABV1zTXXpKOjI+vWrUuSvO1tb8vSpUuzf/9+5zcAVNDTTz+d559/Pu985zuTJG9/+9uzcOHCbN++PYnn5gC8nOCOKbNgwYLccMMN+clPfpIkefjhhzM4OJjBwcFyBwMAznH//ffnoYceym9+85vMnTt38vWPfOQj+f73v58kefLJJ3PgwIHcdtttZY0JACTZuHFjnn/++ezbty/79u3LokWLsmXLltx9993egwNARc2fPz/vec97smXLliSn/2N+7969Wb16tfMbACro7GKZnTt3JkmeffbZ7N69O8uXL/fcHIDzqrXtPGUK7dy5M5/4xCdy5MiRzJkzJ5s2bcr1119f9lgAwBlDQ0NZvHhxrr322vT29iZJ6vV6fv/73+fgwYP5+Mc/nr1796a7uzs/+MEPcscdd5Q8MQDwnwYHB7N58+asXLnSe3AAqLA9e/bkk5/8ZI4cOZLOzs58+ctfzoc+9CHnNwBU1EMPPZT77rsvHR0dabfb+cIXvpC1a9d6bg7AeQnuAAAAAAAAAAAAoABXygIAAAAAAAAAAEABgjsAAAAAAAAAAAAoQHAHAAAAAAAAAAAABQjuAAAAAAAAAAAAoADBHQAAAAAAAAAAABQguAMAAAAAAAAAAIACBHcAAAAAAAAAAABQgOAOAAAAAAAAAAAACvg/Wu+n092Kyb4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), unscaled_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Actual week + prediction of next week (10 days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(10), unscaled_y_test[-10:])\n",
    "plt.plot(range(10), np.append(unscaled_y_test[-10:-5], predicted_y_test[-5:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
