{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from joblib import load\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 5\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(len(data) * train_size)\n",
    "\n",
    "train = data.to_numpy()[:split]\n",
    "test = data.to_numpy()[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalisers\n",
    "normaliser = load('./normalisers/x_normaliser.joblib')\n",
    "y_normaliser = load('./normalisers/y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "train_norm = normaliser.transform(train)\n",
    "test_norm = normaliser.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now I get indexes for chunks from 5 in 5 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(train),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_train = np.array([train_norm[ix].copy() for ix in ordered_index])\n",
    "Y_train = np.array([train_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_train = np.expand_dims(Y_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_train = X_train[:Y_train.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(test),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_test = np.array([test_norm[ix].copy() for ix in ordered_index])\n",
    "Y_test = np.array([test_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_test = np.expand_dims(Y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_test = X_test[:Y_test.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 707us/step - loss: 0.0173 - val_loss: 0.0257\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0497 - val_loss: 0.0577\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0416 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0060 - val_loss: 0.0135\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0031 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0054 - val_loss: 0.0131\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0039 - val_loss: 0.0065\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0066 - val_loss: 0.0172\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0080 - val_loss: 0.0217\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0219 - val_loss: 0.0238\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: 0.0297 - val_loss: 0.0524\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0776 - val_loss: 0.0136\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0127 - val_loss: 0.0104\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0147 - val_loss: 0.0190\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0207 - val_loss: 0.0195\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0488 - val_loss: 0.0154\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0112 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0146 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0092 - val_loss: 0.0020\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 741us/step - loss: 0.0955 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.1459 - val_loss: 0.1533\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0230 - val_loss: 0.0533\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0576 - val_loss: 0.0142\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0093 - val_loss: 0.0109\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0096 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0064 - val_loss: 0.0108\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0086 - val_loss: 0.0162\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0324 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0226 - val_loss: 0.0085\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0547 - val_loss: 0.0358\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0057 - val_loss: 0.0174\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0121 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0082 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0071 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0155 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0121 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0258 - val_loss: 0.0080\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0059 - val_loss: 0.0081\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0071 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0032 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 702us/step - loss: 0.1664 - val_loss: 0.0406\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0190 - val_loss: 0.0071\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0178 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0222 - val_loss: 0.0150\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0234 - val_loss: 0.0150\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0209 - val_loss: 0.0078\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0213 - val_loss: 0.0067\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0210 - val_loss: 0.0063\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0190 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0193 - val_loss: 0.0051\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0184 - val_loss: 0.0047\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0176 - val_loss: 0.0043\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0162 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0164 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0153 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0153 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0143 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0144 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0147 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0134 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0128 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0131 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0134 - val_loss: 0.0032\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0124 - val_loss: 0.0033\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 752us/step - loss: 0.1591 - val_loss: 0.0176\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0127 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0122 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0095 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0068 - val_loss: 0.0082\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0138 - val_loss: 0.0954\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0178 - val_loss: 0.0113\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0162 - val_loss: 0.0133\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0173 - val_loss: 0.0092\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0154 - val_loss: 0.0062\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0139 - val_loss: 0.0046\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0129 - val_loss: 0.0046\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0129 - val_loss: 0.0056\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0118 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0105 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0104 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0107 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0112 - val_loss: 0.0043\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0094 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0091 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0091 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0100 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0093 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0084 - val_loss: 0.0025\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 787us/step - loss: 0.6815 - val_loss: 0.0548\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0561 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.1044 - val_loss: 0.0190\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0825 - val_loss: 0.0428\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0670 - val_loss: 0.0298\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0545 - val_loss: 0.0115\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0579 - val_loss: 0.0132\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0395 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0253 - val_loss: 0.0066\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0221 - val_loss: 0.0211\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0118 - val_loss: 0.0186\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0124 - val_loss: 0.0095\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0123 - val_loss: 0.0103\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0110 - val_loss: 0.0147\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0110 - val_loss: 0.0109\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0133 - val_loss: 0.0120\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0100 - val_loss: 0.0173\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0100 - val_loss: 0.0081\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0127 - val_loss: 0.0093\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0081 - val_loss: 0.0141\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0094 - val_loss: 0.0075\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0087 - val_loss: 0.0107\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0075 - val_loss: 0.0045\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 826us/step - loss: 0.5888 - val_loss: 0.0253\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0942 - val_loss: 0.1372\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0815 - val_loss: 0.0227\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0695 - val_loss: 0.0095\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0549 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0217 - val_loss: 0.0258\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0105 - val_loss: 0.0114\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0081 - val_loss: 0.0067\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0061 - val_loss: 0.0093\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0048 - val_loss: 0.0067\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 862us/step - loss: 0.1327 - val_loss: 0.0886\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0718 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0415 - val_loss: 0.0075\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0146 - val_loss: 0.0101\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0116 - val_loss: 0.0271\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0095 - val_loss: 0.0106\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0056 - val_loss: 0.0067\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 865us/step - loss: 0.3982 - val_loss: 0.1699\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.1084 - val_loss: 0.0354\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0706 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0396 - val_loss: 0.0127\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0133 - val_loss: 0.0131\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0134 - val_loss: 0.0196\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0084 - val_loss: 0.0068\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0055 - val_loss: 0.0098\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0035 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0030 - val_loss: 0.0051\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 889us/step - loss: 0.2063 - val_loss: 0.1968\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0822 - val_loss: 0.0071\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0593 - val_loss: 0.0291\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0263 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0105 - val_loss: 0.0235\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0080 - val_loss: 0.0186\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0044 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0037 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 901us/step - loss: 0.1003 - val_loss: 0.0653\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0412 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0134 - val_loss: 0.0058\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0072 - val_loss: 0.0058\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0037 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 938us/step - loss: 0.3833 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0811 - val_loss: 0.0482\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0720 - val_loss: 0.0637\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0699 - val_loss: 0.0400\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0660 - val_loss: 0.0252\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0629 - val_loss: 0.0173\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0515 - val_loss: 0.0057\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0273 - val_loss: 0.0205\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0145 - val_loss: 0.0216\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0130 - val_loss: 0.0126\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0124 - val_loss: 0.0224\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0106 - val_loss: 0.0187\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0097 - val_loss: 0.0066\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0068 - val_loss: 0.0087\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0054 - val_loss: 0.0113\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0054 - val_loss: 0.0061\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0048 - val_loss: 0.0111\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0044 - val_loss: 0.0197\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0041 - val_loss: 0.0119\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0036 - val_loss: 0.0082\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0035 - val_loss: 0.0115\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0032 - val_loss: 0.0075\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0030 - val_loss: 0.0104\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0028 - val_loss: 0.0128\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 951us/step - loss: 0.7768 - val_loss: 0.0051\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0809 - val_loss: 0.1058\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0854 - val_loss: 0.0619\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0683 - val_loss: 0.0210\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0649 - val_loss: 0.0114\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0497 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0226 - val_loss: 0.0295\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0118 - val_loss: 0.0216\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0106 - val_loss: 0.0141\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0068 - val_loss: 0.0135\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0062 - val_loss: 0.0089\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0054 - val_loss: 0.0058\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0049 - val_loss: 0.0059\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0048 - val_loss: 0.0091\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0048 - val_loss: 0.0074\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0039 - val_loss: 0.0070\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0036 - val_loss: 0.0089\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0034 - val_loss: 0.0077\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0032 - val_loss: 0.0056\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 904us/step - loss: 0.2118 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0812 - val_loss: 0.0872\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0552 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0246 - val_loss: 0.0393\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 0.0104 - val_loss: 0.0197\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0075 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0044 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0039 - val_loss: 0.0062\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0035 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 806us/step - loss: 0.0590 - val_loss: 0.0108\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0105 - val_loss: 0.0103\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0027 - val_loss: 0.0042\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 826us/step - loss: 0.0746 - val_loss: 0.0138\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0110 - val_loss: 0.0080\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0075 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0060 - val_loss: 0.0096\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0038 - val_loss: 0.0059\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0035 - val_loss: 0.0054\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 852us/step - loss: 0.0592 - val_loss: 0.0100\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0078 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0020 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 3s 881us/step - loss: 0.1155 - val_loss: 0.0280\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0220 - val_loss: 0.0145\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0081 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0046 - val_loss: 0.0066\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0026 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 0.0608 - val_loss: 0.0092\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0082 - val_loss: 0.0142\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0053 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0025 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 0.1534 - val_loss: 0.0147\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0169 - val_loss: 0.0075\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0039 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0030 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0022 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 942us/step - loss: 0.0962 - val_loss: 0.1018\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0420 - val_loss: 0.0140\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0142 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0078 - val_loss: 0.0098\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0056 - val_loss: 0.0106\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0049 - val_loss: 0.0087\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0032 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 964us/step - loss: 0.0622 - val_loss: 0.0205\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0114 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0067 - val_loss: 0.0103\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0027 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 0.0785 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0107 - val_loss: 0.0112\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0069 - val_loss: 0.0089\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0863 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0114 - val_loss: 0.0057\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0075 - val_loss: 0.0083\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 0.0777 - val_loss: 0.0067\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0236 - val_loss: 0.0049\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0165 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 0.0135 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0107 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0088 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0084 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0080 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 0.0075 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0077 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0076 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0071 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 0.0070 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0075 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0069 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 0.0067 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0068 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 0.0064 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 0.0066 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: 0.0061 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0667 - val_loss: 0.0090\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0108 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0075 - val_loss: 0.0085\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0033 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 502us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 0.0463 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0110 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0075 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 4s 1ms/step - loss: 0.0760 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0074 - val_loss: 0.0329\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0105 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0078 - val_loss: 0.0263\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0091 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0042 - val_loss: 0.0114\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 408us/step - loss: 0.0087 - val_loss: 0.0159\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0066 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 412us/step - loss: 0.0065 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0062 - val_loss: 0.0098\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0036 - val_loss: 0.0098\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0055 - val_loss: 0.0137\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0051 - val_loss: 0.0040\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0724 - val_loss: 0.0051\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0154 - val_loss: 0.0099\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0114 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0113 - val_loss: 0.0151\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 467us/step - loss: 0.0083 - val_loss: 0.0145\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0110 - val_loss: 0.0093\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0072 - val_loss: 0.0203\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 459us/step - loss: 0.0095 - val_loss: 0.0233\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 462us/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0077 - val_loss: 0.0147\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0075 - val_loss: 0.0158\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0067 - val_loss: 0.0155\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 463us/step - loss: 0.0065 - val_loss: 0.0123\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0074 - val_loss: 0.0119\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 467us/step - loss: 0.0054 - val_loss: 0.0136\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 462us/step - loss: 0.0061 - val_loss: 0.0171\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 462us/step - loss: 0.0057 - val_loss: 0.0075\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 464us/step - loss: 0.0056 - val_loss: 0.0151\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0052 - val_loss: 0.0056\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0055 - val_loss: 0.0135\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0046 - val_loss: 0.0075\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 460us/step - loss: 0.0052 - val_loss: 0.0213\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 467us/step - loss: 0.0049 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0044 - val_loss: 0.0112\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0683 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0134 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0070 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0101 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0054 - val_loss: 0.0083\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0073 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0081 - val_loss: 0.0053\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0060 - val_loss: 0.0066\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0041 - val_loss: 0.0063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0035 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0538 - val_loss: 0.0236\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0128 - val_loss: 0.0123\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0071 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0042 - val_loss: 0.0066\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 386us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 387us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 388us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 390us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0722 - val_loss: 0.0209\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0118 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 1ms/step - loss: 0.0528 - val_loss: 0.0086\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0093 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0060 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0016 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 1ms/step - loss: 0.0607 - val_loss: 0.0211\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0118 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0069 - val_loss: 0.0091\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: 0.0640 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0161 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 465us/step - loss: 0.0082 - val_loss: 0.0187\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0111 - val_loss: 0.0058\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0108 - val_loss: 0.0063\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0092 - val_loss: 0.0317\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0148 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0111 - val_loss: 0.0109\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0071 - val_loss: 0.0138\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 467us/step - loss: 0.0070 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0110 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0057 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0062 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 1ms/step - loss: 0.0568 - val_loss: 0.0055\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0112 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0077 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 467us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 477us/step - loss: 0.0040 - val_loss: 0.0078\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 477us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 476us/step - loss: 0.0017 - val_loss: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 5s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 486us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 467us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 1ms/step - loss: 0.0950 - val_loss: 0.0145\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 478us/step - loss: 0.0357 - val_loss: 0.0095\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0281 - val_loss: 0.0089\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0230 - val_loss: 0.0059\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0183 - val_loss: 0.0052\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0153 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0121 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0103 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0086 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0076 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0069 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 477us/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 476us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0056 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 477us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 0.0050 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 466us/step - loss: 0.0049 - val_loss: 0.0041\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 467us/step - loss: 0.0048 - val_loss: 0.0042\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 467us/step - loss: 0.0048 - val_loss: 0.0044\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.0511 - val_loss: 0.0058\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0091 - val_loss: 0.0107\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.0606 - val_loss: 0.0134\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0104 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0067 - val_loss: 0.0062\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0034 - val_loss: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0520 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0091 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.3437 - val_loss: 0.0094\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0299 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0153 - val_loss: 0.0183\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0079 - val_loss: 0.0102\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0040 - val_loss: 0.0101\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0034 - val_loss: 0.0122\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0046 - val_loss: 0.0058\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0026 - val_loss: 0.0051\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0037 - val_loss: 0.0071\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0030 - val_loss: 0.0078\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0025 - val_loss: 0.0054\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0024 - val_loss: 0.0068\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0024 - val_loss: 0.0055\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0024 - val_loss: 0.0068\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0025 - val_loss: 0.0092\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0027 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.2160 - val_loss: 0.0058\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0098 - val_loss: 0.0155\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0143 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 479us/step - loss: 0.0031 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0039 - val_loss: 0.0108\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0042 - val_loss: 0.0086\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.1171 - val_loss: 0.0609\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0685 - val_loss: 0.0601\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0290 - val_loss: 0.1095\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0335 - val_loss: 0.0092\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0098 - val_loss: 0.0118\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0083 - val_loss: 0.0133\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0065 - val_loss: 0.0114\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0083 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0047 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0069 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0032 - val_loss: 0.0062\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0060 - val_loss: 0.0096\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 477us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 6s 2ms/step - loss: 0.8680 - val_loss: 0.0054\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0166 - val_loss: 0.0273\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0172 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0043 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0051 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0066 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0036 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0033 - val_loss: 0.0054\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 477us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 477us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0034 - val_loss: 0.0059\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0041 - val_loss: 0.0062\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0764 - val_loss: 0.0112\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0752 - val_loss: 0.0216\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0550 - val_loss: 0.0483\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 478us/step - loss: 0.0468 - val_loss: 0.0429\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 476us/step - loss: 0.0327 - val_loss: 0.0215\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0160 - val_loss: 0.0306\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0137 - val_loss: 0.0186\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0074 - val_loss: 0.0105\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 479us/step - loss: 0.0057 - val_loss: 0.0137\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0079 - val_loss: 0.0230\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 476us/step - loss: 0.0109 - val_loss: 0.0201\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0108 - val_loss: 0.0222\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 476us/step - loss: 0.0101 - val_loss: 0.0206\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0094 - val_loss: 0.0170\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0100 - val_loss: 0.0180\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0091 - val_loss: 0.0116\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0073 - val_loss: 0.0138\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 476us/step - loss: 0.0098 - val_loss: 0.0223\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0106 - val_loss: 0.0138\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0082 - val_loss: 0.0169\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0087 - val_loss: 0.0223\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0113 - val_loss: 0.0125\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 473us/step - loss: 0.0058 - val_loss: 0.0095\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0063 - val_loss: 0.0132\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.1083 - val_loss: 0.0404\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0493 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0146 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0076 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 477us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 471us/step - loss: 0.0035 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 469us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 476us/step - loss: 0.0030 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 476us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 470us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 476us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 474us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 472us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 478us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 477us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 7s 2ms/step - loss: 0.0760 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0104 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0066 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0034 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0656 - val_loss: 0.0242\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0125 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0046 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 4.4569 - val_loss: 0.5876\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.1741 - val_loss: 0.0132\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0933 - val_loss: 0.0980\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0837 - val_loss: 0.0346\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0728 - val_loss: 0.0180\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0698 - val_loss: 0.0521\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0676 - val_loss: 0.0251\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0638 - val_loss: 0.0356\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0582 - val_loss: 0.0218\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0538 - val_loss: 0.0059\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0307 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0270 - val_loss: 0.0113\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0179 - val_loss: 0.0756\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0261 - val_loss: 0.0062\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0166 - val_loss: 0.0108\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0139 - val_loss: 0.0041\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0080 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0061 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0042 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0040 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0908 - val_loss: 0.0075\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0117 - val_loss: 0.0080\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0072 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.0611 - val_loss: 0.0135\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 479us/step - loss: 0.0093 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 483us/step - loss: 0.0053 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 479us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 484us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 479us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 485us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 477us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 487us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 475us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 480us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 479us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 481us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 482us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 8s 2ms/step - loss: 0.1708 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0605 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0231 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0091 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0055 - val_loss: 0.0103\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: 425857139306796739338075897856.0000 - val_loss: 46321.3477\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 20418948174092623292502376448.0000 - val_loss: 208.7759\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 23970.9170 - val_loss: 890.9719\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 17678955.8423 - val_loss: 1475.8246\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 858901011.7743 - val_loss: 614.5569\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 7656296401.3813 - val_loss: 624.5688\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 4981606865.9103 - val_loss: 1055.3568\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 4251208596.4629 - val_loss: 1404.1753\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 10780004000.5542 - val_loss: 1514.5613\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 37349441753.6678 - val_loss: 1422.5071\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 2705619369.3792 - val_loss: 1373.2648\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 4246243082989.3589 - val_loss: 2736.6191\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 162165030627.1824 - val_loss: 30083.8516\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 14387929509.5167 - val_loss: 53252.1445\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 223906391959.2002 - val_loss: 66029.4609\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 3985112513.2847 - val_loss: 72070.0625\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 15752136308.1774 - val_loss: 74552.7656\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 59104561195.5287 - val_loss: 75798.3281\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 5835095970.3427 - val_loss: 77833.3438\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 559us/step - loss: 6669897038.4088 - val_loss: 78702.8828\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 527354266798247.1250 - val_loss: 301257.2812\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 106969944910.8958 - val_loss: 454044.7812\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 89689583926.0751 - val_loss: 532330.6250\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 4182687856.2477 - val_loss: 568757.0000\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 8s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 0.2049 - val_loss: 0.0167\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0322 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0109 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0078 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0053 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0030 - val_loss: 0.0069\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0033 - val_loss: 0.0086\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0033 - val_loss: 0.0067\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0037 - val_loss: 0.0091\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 0.0741 - val_loss: 0.0213\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0140 - val_loss: 0.0050\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0083 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0031 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0027 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 0.0579 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0117 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0074 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 0.0775 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0115 - val_loss: 0.0148\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0073 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0031 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0024 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 570us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 573us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 572us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 0.0829 - val_loss: 0.0217\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0149 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0095 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0065 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0042 - val_loss: 0.0081\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0034 - val_loss: 0.0053\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 503us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 0.0582 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0108 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0069 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0054 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0048 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0040 - val_loss: 0.0050\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0038 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 1.1716 - val_loss: 0.0070\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0182 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0131 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0095 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0081 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0078 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0071 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0069 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0065 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0062 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 365us/step - loss: 0.0057 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0055 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0054 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0052 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 9s 2ms/step - loss: 0.0824 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0068 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0056 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0073 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0073 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0059 - val_loss: 0.0050\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0059 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0072 - val_loss: 0.0167\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0070 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0076 - val_loss: 0.0079\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.0887 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0099 - val_loss: 0.0704\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0132 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0086 - val_loss: 0.0278\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0099 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0051 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0084 - val_loss: 0.0062\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0067 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0048 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0060 - val_loss: 0.0048\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0043 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0044 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0053 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0024 - val_loss: 0.0035\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 10s 3ms/step - loss: 0.6171 - val_loss: 0.0074\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0502 - val_loss: 0.0204\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0230 - val_loss: 0.0244\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0120 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0072 - val_loss: 0.0084\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 567us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 568us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 566us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0833 - val_loss: 0.0187\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0114 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0072 - val_loss: 0.0098\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0741 - val_loss: 0.0270\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0139 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0069 - val_loss: 0.0147\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0052 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0016 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0646 - val_loss: 0.0269\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0132 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0067 - val_loss: 0.0120\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0457 - val_loss: 0.0118\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0094 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 0.0063 - val_loss: 0.0100\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 12s 3ms/step - loss: 0.0987 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0043 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0056 - val_loss: 0.0209\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0157 - val_loss: 0.0250\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0093 - val_loss: 0.0123\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0082 - val_loss: 0.0117\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0075 - val_loss: 0.0160\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0118 - val_loss: 0.0165\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0086 - val_loss: 0.0138\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0081 - val_loss: 0.0095\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0070 - val_loss: 0.0098\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0062 - val_loss: 0.0092\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0058 - val_loss: 0.0166\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0101 - val_loss: 0.0176\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0084 - val_loss: 0.0139\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0088 - val_loss: 0.0117\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0072 - val_loss: 0.0085\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0051 - val_loss: 0.0087\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0058 - val_loss: 0.0100\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0067 - val_loss: 0.0098\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0059 - val_loss: 0.0122\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 11s 3ms/step - loss: 0.0719 - val_loss: 0.0197\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0155 - val_loss: 0.0162\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0100 - val_loss: 0.0108\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0078 - val_loss: 0.0161\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0112 - val_loss: 0.0139\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0091 - val_loss: 0.0143\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0086 - val_loss: 0.0149\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0086 - val_loss: 0.0088\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0056 - val_loss: 0.0081\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0064 - val_loss: 0.0153\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0105 - val_loss: 0.0123\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0079 - val_loss: 0.0136\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0096 - val_loss: 0.0081\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0049 - val_loss: 0.0055\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0062 - val_loss: 0.0141\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0094 - val_loss: 0.0133\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0086 - val_loss: 0.0093\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0061 - val_loss: 0.0132\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0067 - val_loss: 0.0102\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0064 - val_loss: 0.0108\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0067 - val_loss: 0.0125\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0079 - val_loss: 0.0089\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0052 - val_loss: 0.0090\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 12s 3ms/step - loss: 0.4472 - val_loss: 0.3136\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.1506 - val_loss: 0.1213\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0837 - val_loss: 0.0650\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0712 - val_loss: 0.0451\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0690 - val_loss: 0.0394\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0687 - val_loss: 0.0377\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0687 - val_loss: 0.0365\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0686 - val_loss: 0.0362\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0686 - val_loss: 0.0372\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0685 - val_loss: 0.0362\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0685 - val_loss: 0.0355\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0685 - val_loss: 0.0362\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0684 - val_loss: 0.0359\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0684 - val_loss: 0.0329\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0684 - val_loss: 0.0356\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0683 - val_loss: 0.0329\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0682 - val_loss: 0.0316\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0682 - val_loss: 0.0354\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0683 - val_loss: 0.0314\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0684 - val_loss: 0.0317\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0680 - val_loss: 0.0441\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0681 - val_loss: 0.0329\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0677 - val_loss: 0.0393\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0679 - val_loss: 0.0329\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 13s 3ms/step - loss: 0.1102 - val_loss: 0.0236\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 445us/step - loss: 0.0694 - val_loss: 0.0346\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 440us/step - loss: 0.0689 - val_loss: 0.0363\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 442us/step - loss: 0.0689 - val_loss: 0.0374\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 446us/step - loss: 0.0688 - val_loss: 0.0323\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 443us/step - loss: 0.0688 - val_loss: 0.0354\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.0688 - val_loss: 0.0379\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.0689 - val_loss: 0.0302\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 448us/step - loss: 0.0687 - val_loss: 0.0396\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 440us/step - loss: 0.0686 - val_loss: 0.0318\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 442us/step - loss: 0.0686 - val_loss: 0.0357\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: 0.0685 - val_loss: 0.0300\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 441us/step - loss: 0.0685 - val_loss: 0.0394\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 445us/step - loss: 0.0686 - val_loss: 0.0345\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 444us/step - loss: 0.0686 - val_loss: 0.0460\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 445us/step - loss: 0.0685 - val_loss: 0.0310\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 437us/step - loss: 0.0681 - val_loss: 0.0282\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 445us/step - loss: 0.0682 - val_loss: 0.0320\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 441us/step - loss: 0.0679 - val_loss: 0.0362\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 440us/step - loss: 0.0676 - val_loss: 0.0268\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 446us/step - loss: 0.0677 - val_loss: 0.0381\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 441us/step - loss: 0.0673 - val_loss: 0.0257\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 447us/step - loss: 0.0669 - val_loss: 0.0283\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 445us/step - loss: 0.0663 - val_loss: 0.0215\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 13s 3ms/step - loss: 0.0620 - val_loss: 0.0120\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0099 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0020 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 13s 3ms/step - loss: 0.0646 - val_loss: 0.0205\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0107 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0064 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0041 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0030 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 13s 3ms/step - loss: 0.0756 - val_loss: 0.0120\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0096 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 13s 3ms/step - loss: 0.0525 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0143 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0060 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0082 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0069 - val_loss: 0.0047\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0021 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0022 - val_loss: 0.0062\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0072 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0039 - val_loss: 0.0069\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0021 - val_loss: 0.0072\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0024 - val_loss: 0.0052\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 14s 4ms/step - loss: 0.0568 - val_loss: 0.0167\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0195 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0053 - val_loss: 0.0075\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0053 - val_loss: 0.0302\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0082 - val_loss: 0.0068\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0034 - val_loss: 0.0085\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0050 - val_loss: 0.0173\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0069 - val_loss: 0.0121\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0030 - val_loss: 0.0090\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0032 - val_loss: 0.0155\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0079 - val_loss: 0.0157\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0108 - val_loss: 0.0066\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 575us/step - loss: 0.0027 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0020 - val_loss: 0.0076\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0054 - val_loss: 0.0169\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0037 - val_loss: 0.0041\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 14s 4ms/step - loss: 0.0534 - val_loss: 0.0649\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0275 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0055 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0050 - val_loss: 0.0060\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0101 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0022 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 14s 4ms/step - loss: 0.0796 - val_loss: 0.0343\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0179 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0080 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0053 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 554us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0017 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 14s 4ms/step - loss: 0.0744 - val_loss: 0.0202\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0121 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0071 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0048 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 13s 4ms/step - loss: 0.0681 - val_loss: 0.0125\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0111 - val_loss: 0.0063\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0069 - val_loss: 0.0086\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0032 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: 0.0711 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0144 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0089 - val_loss: 0.0287\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0122 - val_loss: 0.0077\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0112 - val_loss: 0.0136\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0119 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0066 - val_loss: 0.0140\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0126 - val_loss: 0.0058\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0125 - val_loss: 0.0285\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0078 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0085 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0033 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0090 - val_loss: 0.0043\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0069 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0042 - val_loss: 0.0095\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0064 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: 0.0421 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0095 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0045 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0022 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: 0.0632 - val_loss: 0.0064\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0109 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0070 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: 0.1001 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0150 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0151 - val_loss: 0.0073\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0069 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0174 - val_loss: 0.0116\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0171 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0034 - val_loss: 0.0067\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0144 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0073 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0065 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0091 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0145 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0060 - val_loss: 0.0056\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0118 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0078 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0067 - val_loss: 0.0138\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0044 - val_loss: 0.0208\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0049 - val_loss: 0.0196\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0087 - val_loss: 0.0046\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0029 - val_loss: 0.0122\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 16s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 349us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 359us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 359us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 349us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 353us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: 0.1087 - val_loss: 0.0175\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 349us/step - loss: 0.0253 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0127 - val_loss: 0.0112\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0084 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 360us/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0041 - val_loss: 0.0053\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0041 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0034 - val_loss: 0.0068\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0033 - val_loss: 0.0072\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0033 - val_loss: 0.0062\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0031 - val_loss: 0.0067\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0030 - val_loss: 0.0073\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0030 - val_loss: 0.0090\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0030 - val_loss: 0.0084\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0027 - val_loss: 0.0111\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0027 - val_loss: 0.0146\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0027 - val_loss: 0.0122\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0025 - val_loss: 0.0113\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0025 - val_loss: 0.0158\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0024 - val_loss: 0.0163\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 354us/step - loss: 0.0023 - val_loss: 0.0179\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 15s 4ms/step - loss: 0.1747 - val_loss: 0.0282\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 347us/step - loss: 0.0319 - val_loss: 0.0272\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0353 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0101 - val_loss: 0.0152\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 350us/step - loss: 0.0070 - val_loss: 0.0156\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 364us/step - loss: 0.0059 - val_loss: 0.0106\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0052 - val_loss: 0.0098\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 357us/step - loss: 0.0038 - val_loss: 0.0162\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0045 - val_loss: 0.0098\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 358us/step - loss: 0.0037 - val_loss: 0.0107\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 349us/step - loss: 0.0042 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 356us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 348us/step - loss: 0.0033 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 348us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 348us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 347us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 348us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 349us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 355us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 351us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 352us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 16s 4ms/step - loss: 0.0555 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0124 - val_loss: 0.0115\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0126 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0092 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0093 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0094 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0090 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0087 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0070 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0065 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0076 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0072 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0062 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0065 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0039 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0030 - val_loss: 0.0068\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0038 - val_loss: 0.0256\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 17s 4ms/step - loss: 0.0723 - val_loss: 0.0248\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0141 - val_loss: 0.0122\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0072 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0044 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0030 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0573 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0088 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0016 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 17s 5ms/step - loss: 0.0643 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0094 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0073 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0033 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.1277 - val_loss: 0.0630\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0560 - val_loss: 0.0322\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0488 - val_loss: 0.0237\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0452 - val_loss: 0.0205\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0418 - val_loss: 0.0188\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0385 - val_loss: 0.0178\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0356 - val_loss: 0.0159\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0325 - val_loss: 0.0145\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0293 - val_loss: 0.0129\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0263 - val_loss: 0.0112\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0235 - val_loss: 0.0101\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0208 - val_loss: 0.0085\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0182 - val_loss: 0.0075\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0157 - val_loss: 0.0065\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0137 - val_loss: 0.0053\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0123 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0106 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0094 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0084 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0078 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0072 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0064 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0626 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0160 - val_loss: 0.0068\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0049 - val_loss: 0.0177\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0095 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0029 - val_loss: 0.0082\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0057 - val_loss: 0.0154\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0060 - val_loss: 0.0110\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0050 - val_loss: 0.0063\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0034 - val_loss: 0.0071\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0037 - val_loss: 0.0075\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0040 - val_loss: 0.0134\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0059 - val_loss: 0.0147\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0025 - val_loss: 0.0068\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0031 - val_loss: 0.0059\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0027 - val_loss: 0.0072\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0022 - val_loss: 0.0065\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0037 - val_loss: 0.0113\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0039 - val_loss: 0.0081\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0028 - val_loss: 0.0071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0026 - val_loss: 0.0073\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0524 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0065 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0560 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0072 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 383us/step - loss: 0.0050 - val_loss: 0.0098\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0038 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0029 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 380us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 385us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 0.0642 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0084 - val_loss: 0.0158\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0064 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0028 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0023 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 382us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 372us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 18s 5ms/step - loss: 2.4200 - val_loss: 0.2332\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 384us/step - loss: 0.1552 - val_loss: 0.2389\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.1535 - val_loss: 0.1160\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0725 - val_loss: 0.0091\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0767 - val_loss: 0.0109\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0638 - val_loss: 0.0379\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0563 - val_loss: 0.0262\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0410 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0235 - val_loss: 0.0045\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0102 - val_loss: 0.0097\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0080 - val_loss: 0.0084\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0059 - val_loss: 0.0053\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 375us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0048 - val_loss: 0.0046\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 374us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 379us/step - loss: 0.0046 - val_loss: 0.0051\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 378us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0043 - val_loss: 0.0042\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 377us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 381us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0041 - val_loss: 0.0039\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 20s 5ms/step - loss: 0.0636 - val_loss: 0.0289\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 411us/step - loss: 0.0157 - val_loss: 0.0124\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0079 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0038 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 410us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 412us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 410us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 411us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 418us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 410us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 410us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 413us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 19s 5ms/step - loss: 0.0587 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0091 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0065 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0046 - val_loss: 0.0080\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 574us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0021 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 576us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 20s 5ms/step - loss: 0.0611 - val_loss: 0.0163\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0102 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0061 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0021 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0020 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 579us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 20s 5ms/step - loss: 0.0461 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0055 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 21s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 21s 5ms/step - loss: 0.1660 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0160 - val_loss: 0.0508\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0188 - val_loss: 0.0321\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0195 - val_loss: 0.0183\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0166 - val_loss: 0.0221\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0146 - val_loss: 0.0186\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0119 - val_loss: 0.0158\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0155 - val_loss: 0.0218\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0106 - val_loss: 0.0080\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0110 - val_loss: 0.0148\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0123 - val_loss: 0.0073\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0075 - val_loss: 0.0122\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0103 - val_loss: 0.0138\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0102 - val_loss: 0.0076\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0064 - val_loss: 0.0098\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0112 - val_loss: 0.0040\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0054 - val_loss: 0.0075\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0102 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 577us/step - loss: 0.0054 - val_loss: 0.0098\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0085 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 578us/step - loss: 0.0053 - val_loss: 0.0133\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0082 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0069 - val_loss: 0.0068\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 21s 6ms/step - loss: 2.9642 - val_loss: 1.9110\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 1.1268 - val_loss: 0.9518\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.5351 - val_loss: 0.4968\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.2648 - val_loss: 0.2579\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.1403 - val_loss: 0.1344\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0892 - val_loss: 0.0720\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0725 - val_loss: 0.0460\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0692 - val_loss: 0.0355\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0690 - val_loss: 0.0350\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0690 - val_loss: 0.0329\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0690 - val_loss: 0.0389\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0690 - val_loss: 0.0348\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0690 - val_loss: 0.0420\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0690 - val_loss: 0.0258\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0698 - val_loss: 0.0294\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0692 - val_loss: 0.0370\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 498us/step - loss: 0.0668 - val_loss: 0.0494\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0501 - val_loss: 0.0162\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0382 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0163 - val_loss: 0.0122\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0158 - val_loss: 0.0152\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 497us/step - loss: 0.0156 - val_loss: 0.0113\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0149 - val_loss: 0.0181\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0108 - val_loss: 0.0228\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 21s 5ms/step - loss: 0.0708 - val_loss: 0.0378\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0481 - val_loss: 0.0311\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 496us/step - loss: 0.0219 - val_loss: 0.0102\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0157 - val_loss: 0.0233\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 500us/step - loss: 0.0166 - val_loss: 0.0214\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0120 - val_loss: 0.0404\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 493us/step - loss: 0.0126 - val_loss: 0.0336\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0123 - val_loss: 0.0408\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 490us/step - loss: 0.0074 - val_loss: 0.0405\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 488us/step - loss: 0.0117 - val_loss: 0.0265\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0079 - val_loss: 0.0240\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0075 - val_loss: 0.0090\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0100 - val_loss: 0.0188\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0052 - val_loss: 0.0353\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0079 - val_loss: 0.0298\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0071 - val_loss: 0.0346\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0064 - val_loss: 0.0123\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 494us/step - loss: 0.0073 - val_loss: 0.0256\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 489us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 499us/step - loss: 0.0068 - val_loss: 0.0202\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0047 - val_loss: 0.0168\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 492us/step - loss: 0.0076 - val_loss: 0.0124\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 491us/step - loss: 0.0045 - val_loss: 0.0212\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 495us/step - loss: 0.0064 - val_loss: 0.0157\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 21s 6ms/step - loss: 0.0686 - val_loss: 0.0299\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0492 - val_loss: 0.0099\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0261 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0124 - val_loss: 0.0247\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0119 - val_loss: 0.0330\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0108 - val_loss: 0.0259\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0102 - val_loss: 0.0256\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0078 - val_loss: 0.0469\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0082 - val_loss: 0.0268\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0091 - val_loss: 0.0264\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0061 - val_loss: 0.0094\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0079 - val_loss: 0.0246\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0049 - val_loss: 0.0168\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0084 - val_loss: 0.0088\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0050 - val_loss: 0.0324\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0067 - val_loss: 0.0076\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0067 - val_loss: 0.0159\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0039 - val_loss: 0.0266\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0071 - val_loss: 0.0073\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0044 - val_loss: 0.0273\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0065 - val_loss: 0.0053\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0048 - val_loss: 0.0368\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0049 - val_loss: 0.0095\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 22s 6ms/step - loss: 0.1001 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0078 - val_loss: 0.0256\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0173 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0056 - val_loss: 0.0429\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0142 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0116 - val_loss: 0.0070\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0140 - val_loss: 0.0120\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0103 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0071 - val_loss: 0.0075\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0146 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0088 - val_loss: 0.0059\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0067 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0063 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0086 - val_loss: 0.0066\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0049 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0050 - val_loss: 0.0207\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0086 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0087 - val_loss: 0.0171\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0042 - val_loss: 0.0061\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 23s 6ms/step - loss: 0.0750 - val_loss: 0.0146\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0091 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0062 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0035 - val_loss: 0.0067\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 580us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 23s 6ms/step - loss: 0.0557 - val_loss: 0.0046\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0092 - val_loss: 0.0125\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0050 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0053 - val_loss: 0.0120\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0070 - val_loss: 0.0127\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0055 - val_loss: 0.0084\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0043 - val_loss: 0.0108\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 0.0064 - val_loss: 0.0109\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 0.0049 - val_loss: 0.0083\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0041 - val_loss: 0.0134\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 0.0057 - val_loss: 0.0118\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0045 - val_loss: 0.0087\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0035 - val_loss: 0.0050\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 514us/step - loss: 0.0026 - val_loss: 0.0053\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 515us/step - loss: 0.0040 - val_loss: 0.0123\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 0.0074 - val_loss: 0.0217\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 0.0086 - val_loss: 0.0050\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0025 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 23s 6ms/step - loss: 0.0443 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0186 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 394us/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0094 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0043 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 394us/step - loss: 0.0027 - val_loss: 0.0070\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0051 - val_loss: 0.0092\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0042 - val_loss: 0.0085\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0045 - val_loss: 0.0088\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0032 - val_loss: 0.0061\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0033 - val_loss: 0.0052\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0031 - val_loss: 0.0085\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0045 - val_loss: 0.0098\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0030 - val_loss: 0.0080\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0037 - val_loss: 0.0085\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0028 - val_loss: 0.0060\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 24s 6ms/step - loss: 0.0661 - val_loss: 0.0077\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0184 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0082 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0052 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0075 - val_loss: 0.0068\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0026 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0071 - val_loss: 0.0056\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0060 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 25s 6ms/step - loss: 0.0629 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0060 - val_loss: 0.0119\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0125 - val_loss: 0.0141\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0039 - val_loss: 0.0083\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0081 - val_loss: 0.0109\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0048 - val_loss: 0.0139\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0057 - val_loss: 0.0154\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0047 - val_loss: 0.0077\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0039 - val_loss: 0.0089\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0041 - val_loss: 0.0175\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0106 - val_loss: 0.0088\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0035 - val_loss: 0.0057\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0028 - val_loss: 0.0090\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0027 - val_loss: 0.0060\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0027 - val_loss: 0.0068\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0030 - val_loss: 0.0060\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0020 - val_loss: 0.0061\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0049 - val_loss: 0.0085\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0022 - val_loss: 0.0054\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0024 - val_loss: 0.0073\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 25s 7ms/step - loss: 0.0690 - val_loss: 0.0079\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0151 - val_loss: 0.0156\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0084 - val_loss: 0.0026\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0048 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0040 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 25s 7ms/step - loss: 0.0739 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0111 - val_loss: 0.0128\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0081 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0057 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 26s 7ms/step - loss: 0.0851 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0112 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0073 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0021 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 26s 7ms/step - loss: 0.0611 - val_loss: 0.0123\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0117 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0078 - val_loss: 0.0105\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0036 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0028 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0021 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 27s 7ms/step - loss: 0.0499 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0091 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0056 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 27s 7ms/step - loss: 1.2214 - val_loss: 0.9998\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.5406 - val_loss: 0.4639\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.2357 - val_loss: 0.2080\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.1130 - val_loss: 0.0916\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0752 - val_loss: 0.0435\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0692 - val_loss: 0.0263\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0705 - val_loss: 0.0222\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0708 - val_loss: 0.0238\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 582us/step - loss: 0.0700 - val_loss: 0.0283\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0692 - val_loss: 0.0326\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0690 - val_loss: 0.0360\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0690 - val_loss: 0.0376\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0690 - val_loss: 0.0377\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0690 - val_loss: 0.0368\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0690 - val_loss: 0.0362\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0689 - val_loss: 0.0360\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0689 - val_loss: 0.0358\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0689 - val_loss: 0.0360\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0689 - val_loss: 0.0358\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0690 - val_loss: 0.0354\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0690 - val_loss: 0.0354\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0689 - val_loss: 0.0360\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.0689 - val_loss: 0.0360\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0689 - val_loss: 0.0359\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 27s 7ms/step - loss: 0.0568 - val_loss: 0.0138\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0098 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0050 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0038 - val_loss: 0.0074\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 581us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0020 - val_loss: 0.0020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 584us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 583us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 28s 7ms/step - loss: 0.0921 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0143 - val_loss: 0.0179\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 562us/step - loss: 0.0087 - val_loss: 0.0151\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 569us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 571us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 561us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 565us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 560us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 564us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 563us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 27s 7ms/step - loss: 0.0445 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0076 - val_loss: 0.0070\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 413us/step - loss: 0.0057 - val_loss: 0.0094\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 410us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 411us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 410us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 413us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 408us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 28s 7ms/step - loss: 0.2167 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 413us/step - loss: 0.0149 - val_loss: 0.0096\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0097 - val_loss: 0.0235\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 410us/step - loss: 0.0150 - val_loss: 0.0335\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0164 - val_loss: 0.0202\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0143 - val_loss: 0.0217\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 404us/step - loss: 0.0167 - val_loss: 0.0446\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0127 - val_loss: 0.0139\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0110 - val_loss: 0.0199\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 408us/step - loss: 0.0200 - val_loss: 0.0106\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 408us/step - loss: 0.0034 - val_loss: 0.0077\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 403us/step - loss: 0.0127 - val_loss: 0.0304\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 410us/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 407us/step - loss: 0.0079 - val_loss: 0.0118\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 408us/step - loss: 0.0125 - val_loss: 0.0198\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 402us/step - loss: 0.0052 - val_loss: 0.0128\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0077 - val_loss: 0.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 410us/step - loss: 0.0102 - val_loss: 0.0111\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0048 - val_loss: 0.0111\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0093 - val_loss: 0.0222\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 406us/step - loss: 0.0057 - val_loss: 0.0092\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 409us/step - loss: 0.0067 - val_loss: 0.0119\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 405us/step - loss: 0.0057 - val_loss: 0.0134\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 28s 7ms/step - loss: 0.1131 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0117 - val_loss: 0.0070\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0120 - val_loss: 0.0173\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0098 - val_loss: 0.0271\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0132 - val_loss: 0.0191\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0116 - val_loss: 0.0226\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0109 - val_loss: 0.0312\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0155 - val_loss: 0.0092\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0058 - val_loss: 0.0299\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0115 - val_loss: 0.0193\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0067 - val_loss: 0.0139\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0117 - val_loss: 0.0333\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0084 - val_loss: 0.0112\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0066 - val_loss: 0.0175\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0091 - val_loss: 0.0134\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0050 - val_loss: 0.0146\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0077 - val_loss: 0.0283\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0065 - val_loss: 0.0128\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0055 - val_loss: 0.0163\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0049 - val_loss: 0.0126\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0052 - val_loss: 0.0206\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 29s 8ms/step - loss: 0.4550 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0044 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0144 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0111 - val_loss: 0.0467\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0144 - val_loss: 0.0234\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0174 - val_loss: 0.0211\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0196 - val_loss: 0.0637\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0191 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0106 - val_loss: 0.0264\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0137 - val_loss: 0.0346\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0189 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0055 - val_loss: 0.0189\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0122 - val_loss: 0.0176\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0142 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0053 - val_loss: 0.0149\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0119 - val_loss: 0.0097\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0077 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0080 - val_loss: 0.0125\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0125 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0036 - val_loss: 0.0120\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0088 - val_loss: 0.0070\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0069 - val_loss: 0.0143\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 29s 8ms/step - loss: 0.0579 - val_loss: 0.0161\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0097 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: 0.0065 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 0.0044 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0017 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 30s 8ms/step - loss: 0.0755 - val_loss: 0.0075\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0093 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0035 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 30s 8ms/step - loss: 0.0915 - val_loss: 0.0322\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0130 - val_loss: 0.0110\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0043 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 0.0680 - val_loss: 0.0241\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0111 - val_loss: 0.0092\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0039 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 98.4309 - val_loss: 8.4298\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 432us/step - loss: 2.4736 - val_loss: 0.5580\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 429us/step - loss: 0.3159 - val_loss: 0.5713\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 435us/step - loss: 0.3043 - val_loss: 0.1554\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 437us/step - loss: 0.0943 - val_loss: 0.0083\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 431us/step - loss: 0.1088 - val_loss: 0.0086\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 432us/step - loss: 0.0662 - val_loss: 0.0596\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 434us/step - loss: 0.0625 - val_loss: 0.0342\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 432us/step - loss: 0.0500 - val_loss: 0.0116\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 435us/step - loss: 0.0478 - val_loss: 0.0128\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 434us/step - loss: 0.0458 - val_loss: 0.0181\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 432us/step - loss: 0.0421 - val_loss: 0.0152\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 429us/step - loss: 0.0419 - val_loss: 0.0118\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 434us/step - loss: 0.0397 - val_loss: 0.0096\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 433us/step - loss: 0.0393 - val_loss: 0.0109\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 435us/step - loss: 0.0381 - val_loss: 0.0099\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 430us/step - loss: 0.0378 - val_loss: 0.0093\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 429us/step - loss: 0.0366 - val_loss: 0.0091\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 432us/step - loss: 0.0368 - val_loss: 0.0088\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 431us/step - loss: 0.0356 - val_loss: 0.0088\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 432us/step - loss: 0.0344 - val_loss: 0.0087\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 430us/step - loss: 0.0338 - val_loss: 0.0097\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 430us/step - loss: 0.0330 - val_loss: 0.0077\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: 0.0335 - val_loss: 0.0090\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 31s 8ms/step - loss: 538920.3966 - val_loss: 54.8114\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 432us/step - loss: 737.7381 - val_loss: 546.3117\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 429us/step - loss: 506.0462 - val_loss: 135.0137\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 433us/step - loss: 99.6947 - val_loss: 32.2209\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 435us/step - loss: 47.0100 - val_loss: 12.5801\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 435us/step - loss: 37.2654 - val_loss: 7.2405\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 433us/step - loss: 33.6046 - val_loss: 5.4084\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 436us/step - loss: 31.9694 - val_loss: 4.7379\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 431us/step - loss: 30.5085 - val_loss: 4.5145\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 433us/step - loss: 29.9351 - val_loss: 4.4839\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 434us/step - loss: 28.8418 - val_loss: 4.5414\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 435us/step - loss: 28.1176 - val_loss: 4.6289\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 434us/step - loss: 27.5759 - val_loss: 4.7304\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 434us/step - loss: 26.6302 - val_loss: 4.8256\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 433us/step - loss: 25.6945 - val_loss: 4.8980\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: 24.8148 - val_loss: 4.9550\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 434us/step - loss: 24.0684 - val_loss: 4.9923\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 432us/step - loss: 23.4081 - val_loss: 5.0103\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 437us/step - loss: 22.5525 - val_loss: 5.0077\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 433us/step - loss: 21.5228 - val_loss: 4.9868\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 431us/step - loss: 21.0705 - val_loss: 4.9421\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 433us/step - loss: 20.4022 - val_loss: 4.8959\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 433us/step - loss: 19.5830 - val_loss: 4.8249\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 432us/step - loss: 18.8766 - val_loss: 4.7462\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 32s 8ms/step - loss: 550.8532 - val_loss: 1.5331\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 18.0509 - val_loss: 3.5079\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 440us/step - loss: 4.2408 - val_loss: 7.9434\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 433us/step - loss: 4.2146 - val_loss: 0.0964\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: 1.5801 - val_loss: 0.3951\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: 1.0933 - val_loss: 0.2650\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 433us/step - loss: 0.8451 - val_loss: 0.3731\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 440us/step - loss: 0.6128 - val_loss: 0.0045\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 435us/step - loss: 0.6009 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 433us/step - loss: 0.5179 - val_loss: 0.0672\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.4969 - val_loss: 0.0258\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.4483 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 432us/step - loss: 0.4361 - val_loss: 0.0100\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: 0.4041 - val_loss: 0.0185\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 436us/step - loss: 0.3682 - val_loss: 0.0054\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 435us/step - loss: 0.3854 - val_loss: 0.0052\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.3454 - val_loss: 0.0087\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 436us/step - loss: 0.3370 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 432us/step - loss: 0.3256 - val_loss: 0.0078\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 435us/step - loss: 0.3163 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 440us/step - loss: 0.2886 - val_loss: 0.0055\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 435us/step - loss: 0.2958 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 435us/step - loss: 0.2760 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.2648 - val_loss: 0.0037\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 33s 9ms/step - loss: 87762964315.2142 - val_loss: 6101.1880\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 511us/step - loss: 234870.5052 - val_loss: 18077.0723\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 34123443.0196 - val_loss: 7520.2954\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 5926015.9919 - val_loss: 2031.1532\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: 41120.7959 - val_loss: 429.4396\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 347042.0266 - val_loss: 142.4355\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 513us/step - loss: 490038.5463 - val_loss: 192.1730\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 505us/step - loss: 56756.2826 - val_loss: 280.3346\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 118419.9956 - val_loss: 375.8777\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 62256.3411 - val_loss: 457.7121\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 99524.7108 - val_loss: 543.8903\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 508us/step - loss: 86310.0221 - val_loss: 635.6953\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 45667.0584 - val_loss: 725.9351\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 23137.3625 - val_loss: 807.2629\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 506us/step - loss: 13248.7753 - val_loss: 849.9200\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 501us/step - loss: 20813.1691 - val_loss: 840.8782\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 422942.0287 - val_loss: 858.5261\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 512us/step - loss: 49937.6785 - val_loss: 262.6838\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 509us/step - loss: 42970.0997 - val_loss: 308.8400\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 504us/step - loss: 14414.5025 - val_loss: 437.9438\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 507us/step - loss: 6650.5250 - val_loss: 212.6931\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 10308.1263 - val_loss: 236.8466\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 510us/step - loss: 169330.3589 - val_loss: 192.0426\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 505us/step - loss: 114041.7360 - val_loss: 23.3703\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 33s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 34s 9ms/step - loss: 0.1211 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0112 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0034 - val_loss: 0.0083\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0091 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0041 - val_loss: 0.0050\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.0047 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0042 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 34s 9ms/step - loss: 0.0623 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0096 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0060 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0043 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0028 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 590us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 588us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 587us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 586us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 35s 9ms/step - loss: 1.4199 - val_loss: 0.0064\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.0320 - val_loss: 0.0603\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0381 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.0087 - val_loss: 0.0087\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0079 - val_loss: 0.0318\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.0122 - val_loss: 0.0105\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0068 - val_loss: 0.0357\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0125 - val_loss: 0.0128\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.0064 - val_loss: 0.0056\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.0058 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 589us/step - loss: 0.0058 - val_loss: 0.0131\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0079 - val_loss: 0.0070\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0051 - val_loss: 0.0066\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0049 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.0058 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 591us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 3s 696us/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0051 - val_loss: 0.0061\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0052 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0040 - val_loss: 0.0051\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 35s 9ms/step - loss: 24.9379 - val_loss: 0.0137\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0167 - val_loss: 0.0120\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0146 - val_loss: 0.0107\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0130 - val_loss: 0.0099\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0122 - val_loss: 0.0088\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0114 - val_loss: 0.0081\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0107 - val_loss: 0.0076\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0096 - val_loss: 0.0070\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0094 - val_loss: 0.0065\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0087 - val_loss: 0.0063\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0068 - val_loss: 0.0048\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0059 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0053 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 595us/step - loss: 0.0051 - val_loss: 0.0035\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 35s 9ms/step - loss: 0.3930 - val_loss: 0.0292\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0434 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0093 - val_loss: 0.0089\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0096 - val_loss: 0.0149\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0051 - val_loss: 0.0083\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0046 - val_loss: 0.0132\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0043 - val_loss: 0.0076\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0043 - val_loss: 0.0093\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0032 - val_loss: 0.0094\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0051 - val_loss: 0.0079\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0025 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 36s 10ms/step - loss: 0.1017 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0134 - val_loss: 0.0109\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0092 - val_loss: 0.0058\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0142 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0124 - val_loss: 0.0214\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0197 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0126 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0075 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0096 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0070 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0110 - val_loss: 0.0100\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0076 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0078 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0072 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0050 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0034 - val_loss: 0.0142\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0089 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 37s 10ms/step - loss: 0.1109 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0133 - val_loss: 0.0087\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0082 - val_loss: 0.0369\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 531us/step - loss: 0.0151 - val_loss: 0.0240\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0147 - val_loss: 0.0229\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0169 - val_loss: 0.0100\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0047 - val_loss: 0.0325\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0205 - val_loss: 0.0234\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0055 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0105 - val_loss: 0.0178\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0100 - val_loss: 0.0047\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0047 - val_loss: 0.0175\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0121 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0033 - val_loss: 0.0065\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0102 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0049 - val_loss: 0.0057\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0070 - val_loss: 0.0305\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0074 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0035 - val_loss: 0.0354\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0095 - val_loss: 0.0055\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0030 - val_loss: 0.0166\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0078 - val_loss: 0.0173\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0042 - val_loss: 0.0147\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 41s 11ms/step - loss: 2.0309 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0099 - val_loss: 0.0993\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 529us/step - loss: 0.0470 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0327 - val_loss: 0.0714\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0305 - val_loss: 0.0276\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0388 - val_loss: 0.0393\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0415 - val_loss: 0.0828\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0974 - val_loss: 0.1524\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0252 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0049 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0205 - val_loss: 0.0049\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0174 - val_loss: 0.0530\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0854 - val_loss: 0.0470\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0103 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0161 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0107 - val_loss: 0.0687\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0230 - val_loss: 0.0064\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 528us/step - loss: 0.0102 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0166 - val_loss: 0.0157\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0171 - val_loss: 0.0029\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0069 - val_loss: 0.0118\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0209 - val_loss: 0.0024\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 42s 11ms/step - loss: 0.7510 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0099 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0073 - val_loss: 0.0113\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0253 - val_loss: 0.0337\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 530us/step - loss: 0.0106 - val_loss: 0.0158\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 519us/step - loss: 0.0281 - val_loss: 0.0243\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0155 - val_loss: 0.0104\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 518us/step - loss: 0.0184 - val_loss: 0.0567\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0482 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0035 - val_loss: 0.0073\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0140 - val_loss: 0.0199\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0086 - val_loss: 0.0179\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0327 - val_loss: 0.0429\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 520us/step - loss: 0.0089 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0028 - val_loss: 0.0085\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0152 - val_loss: 0.0095\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0069 - val_loss: 0.0268\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0163 - val_loss: 0.0066\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0031 - val_loss: 0.0072\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0141 - val_loss: 0.0158\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0078 - val_loss: 0.0144\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0102 - val_loss: 0.0178\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 43s 11ms/step - loss: 0.0644 - val_loss: 0.0107\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 0.0097 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 0.0060 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 0.0043 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 0.0028 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 44s 12ms/step - loss: 0.0700 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 0.0108 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 0.0069 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 0.0048 - val_loss: 0.0088\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 44s 11ms/step - loss: 0.1076 - val_loss: 0.0501\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 0.0204 - val_loss: 0.0074\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 640us/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 0.0031 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 45s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 44s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 45s 12ms/step - loss: 0.8917 - val_loss: 0.0069\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 0.0158 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 0.0089 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 0.0039 - val_loss: 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 0.0038 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 0.0037 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 0.0037 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 45s 12ms/step - loss: 0.0685 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 425us/step - loss: 0.0061 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 425us/step - loss: 0.0129 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 434us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 435us/step - loss: 0.0065 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 425us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 424us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0078 - val_loss: 0.0127\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 454us/step - loss: 0.0191 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 400us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 396us/step - loss: 0.0020 - val_loss: 0.0048\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0047 - val_loss: 0.0070\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 401us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 392us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 393us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 389us/step - loss: 0.0032 - val_loss: 0.0130\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 395us/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 391us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 397us/step - loss: 0.0018 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 398us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 399us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 40s 10ms/step - loss: 1.2392 - val_loss: 0.6631\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.2987 - val_loss: 0.2159\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.1148 - val_loss: 0.0978\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0784 - val_loss: 0.0601\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0710 - val_loss: 0.0459\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0694 - val_loss: 0.0407\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0691 - val_loss: 0.0379\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0690 - val_loss: 0.0364\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0690 - val_loss: 0.0364\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0690 - val_loss: 0.0362\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0690 - val_loss: 0.0365\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0690 - val_loss: 0.0365\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0690 - val_loss: 0.0360\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0690 - val_loss: 0.0358\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0690 - val_loss: 0.0361\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0690 - val_loss: 0.0365\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0690 - val_loss: 0.0359\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 546us/step - loss: 0.0690 - val_loss: 0.0361\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0690 - val_loss: 0.0356\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0690 - val_loss: 0.0359\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0690 - val_loss: 0.0360\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0690 - val_loss: 0.0361\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0690 - val_loss: 0.0354\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0690 - val_loss: 0.0355\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 41s 11ms/step - loss: 0.1132 - val_loss: 0.0527\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0531 - val_loss: 0.0300\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0468 - val_loss: 0.0228\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0426 - val_loss: 0.0208\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0387 - val_loss: 0.0185\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0348 - val_loss: 0.0169\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0310 - val_loss: 0.0146\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0272 - val_loss: 0.0125\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0234 - val_loss: 0.0106\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0201 - val_loss: 0.0083\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0171 - val_loss: 0.0073\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0148 - val_loss: 0.0057\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0127 - val_loss: 0.0046\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0111 - val_loss: 0.0041\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0098 - val_loss: 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0087 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0079 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0073 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0068 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0063 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0060 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 548us/step - loss: 0.0058 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 544us/step - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0053 - val_loss: 0.0041\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 42s 11ms/step - loss: 0.0735 - val_loss: 0.0250\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0148 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0076 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0031 - val_loss: 0.0067\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 43s 11ms/step - loss: 0.0536 - val_loss: 0.0059\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0091 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 44s 12ms/step - loss: 0.1134 - val_loss: 0.0592\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0709 - val_loss: 0.0151\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0737 - val_loss: 0.0197\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0686 - val_loss: 0.0362\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0650 - val_loss: 0.0409\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0626 - val_loss: 0.0296\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0579 - val_loss: 0.0217\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0539 - val_loss: 0.0236\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 0.0500 - val_loss: 0.0281\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0472 - val_loss: 0.0292\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0453 - val_loss: 0.0313\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0443 - val_loss: 0.0337\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0443 - val_loss: 0.0374\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0441 - val_loss: 0.0363\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0442 - val_loss: 0.0383\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 0.0442 - val_loss: 0.0380\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0442 - val_loss: 0.0367\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0441 - val_loss: 0.0363\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0441 - val_loss: 0.0377\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 0.0440 - val_loss: 0.0356\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0441 - val_loss: 0.0357\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0440 - val_loss: 0.0374\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 0.0441 - val_loss: 0.0356\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0439 - val_loss: 0.0374\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 42s 11ms/step - loss: 0.4620 - val_loss: 0.3496\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 0.1613 - val_loss: 0.1085\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0765 - val_loss: 0.0306\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0717 - val_loss: 0.0141\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 0.0755 - val_loss: 0.0154\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0725 - val_loss: 0.0246\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0694 - val_loss: 0.0356\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0690 - val_loss: 0.0419\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0692 - val_loss: 0.0416\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0691 - val_loss: 0.0376\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0689 - val_loss: 0.0350\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0690 - val_loss: 0.0346\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0690 - val_loss: 0.0350\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0689 - val_loss: 0.0361\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0690 - val_loss: 0.0357\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0690 - val_loss: 0.0357\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 0.0690 - val_loss: 0.0357\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0690 - val_loss: 0.0356\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0690 - val_loss: 0.0365\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0690 - val_loss: 0.0356\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0689 - val_loss: 0.0358\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0690 - val_loss: 0.0365\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0690 - val_loss: 0.0359\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0689 - val_loss: 0.0359\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 44s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 441us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 445us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 442us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 440us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 444us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 451us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 442us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 443us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 443us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 440us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 444us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 442us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 448us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 441us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 440us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 445us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 442us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 442us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 43s 11ms/step - loss: 0.1420 - val_loss: 0.0161\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0235 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0109 - val_loss: 0.0112\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 420us/step - loss: 0.0078 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0054 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 416us/step - loss: 0.0048 - val_loss: 0.0045\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 423us/step - loss: 0.0042 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0038 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 414us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 418us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 419us/step - loss: 0.0030 - val_loss: 0.0061\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 415us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 419us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0029 - val_loss: 0.0067\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0028 - val_loss: 0.0055\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 418us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 417us/step - loss: 0.0026 - val_loss: 0.0078\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 420us/step - loss: 0.0026 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0024 - val_loss: 0.0062\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 423us/step - loss: 0.0024 - val_loss: 0.0075\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 44s 12ms/step - loss: 0.8533 - val_loss: 0.0202\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 1s 370us/step - loss: 0.0368 - val_loss: 0.0184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 1s 365us/step - loss: 0.0450 - val_loss: 0.0496\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0406 - val_loss: 0.0900\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.0469 - val_loss: 0.0466\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0484 - val_loss: 0.0359\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 1s 371us/step - loss: 0.0372 - val_loss: 0.0420\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 1s 364us/step - loss: 0.0370 - val_loss: 0.0379\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0365 - val_loss: 0.0351\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0275 - val_loss: 0.0208\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0337 - val_loss: 0.0078\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 1s 365us/step - loss: 0.0260 - val_loss: 0.0297\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 1s 366us/step - loss: 0.0200 - val_loss: 0.0136\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0312 - val_loss: 0.0050\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 1s 373us/step - loss: 0.0169 - val_loss: 0.0196\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0199 - val_loss: 0.0138\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 1s 364us/step - loss: 0.0223 - val_loss: 0.0092\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0135 - val_loss: 0.0181\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 1s 376us/step - loss: 0.0213 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 1s 363us/step - loss: 0.0168 - val_loss: 0.0095\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 1s 369us/step - loss: 0.0135 - val_loss: 0.0125\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 1s 368us/step - loss: 0.0175 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 1s 364us/step - loss: 0.0157 - val_loss: 0.0078\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 1s 367us/step - loss: 0.0140 - val_loss: 0.0080\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 44s 11ms/step - loss: 1.0218 - val_loss: 0.0195\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 423us/step - loss: 0.0242 - val_loss: 0.1010\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 430us/step - loss: 0.0470 - val_loss: 0.0257\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0224 - val_loss: 0.0191\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 424us/step - loss: 0.0209 - val_loss: 0.0162\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 424us/step - loss: 0.0174 - val_loss: 0.0189\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0191 - val_loss: 0.0285\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 430us/step - loss: 0.0227 - val_loss: 0.0379\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 427us/step - loss: 0.0301 - val_loss: 0.0259\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 422us/step - loss: 0.0213 - val_loss: 0.0297\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 425us/step - loss: 0.0210 - val_loss: 0.0252\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 427us/step - loss: 0.0191 - val_loss: 0.0259\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 426us/step - loss: 0.0273 - val_loss: 0.0354\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 424us/step - loss: 0.0245 - val_loss: 0.0220\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 426us/step - loss: 0.0233 - val_loss: 0.0358\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 429us/step - loss: 0.0244 - val_loss: 0.0127\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 427us/step - loss: 0.0168 - val_loss: 0.0215\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 424us/step - loss: 0.0217 - val_loss: 0.0211\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 437us/step - loss: 0.0209 - val_loss: 0.0223\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 448us/step - loss: 0.0217 - val_loss: 0.0130\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 451us/step - loss: 0.0159 - val_loss: 0.0157\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 453us/step - loss: 0.0165 - val_loss: 0.0168\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 442us/step - loss: 0.0194 - val_loss: 0.0132\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 454us/step - loss: 0.0157 - val_loss: 0.0157\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 51s 13ms/step - loss: 0.4188 - val_loss: 0.3029\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 446us/step - loss: 0.1490 - val_loss: 0.1260\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 449us/step - loss: 0.0858 - val_loss: 0.0702\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 450us/step - loss: 0.0722 - val_loss: 0.0486\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 453us/step - loss: 0.0691 - val_loss: 0.0410\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 444us/step - loss: 0.0686 - val_loss: 0.0381\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 451us/step - loss: 0.0685 - val_loss: 0.0367\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 459us/step - loss: 0.0684 - val_loss: 0.0361\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 454us/step - loss: 0.0684 - val_loss: 0.0351\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 444us/step - loss: 0.0683 - val_loss: 0.0354\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 449us/step - loss: 0.0683 - val_loss: 0.0353\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 448us/step - loss: 0.0682 - val_loss: 0.0358\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 456us/step - loss: 0.0682 - val_loss: 0.0368\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 468us/step - loss: 0.0681 - val_loss: 0.0364\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 438us/step - loss: 0.0681 - val_loss: 0.0370\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0680 - val_loss: 0.0429\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0681 - val_loss: 0.0388\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 430us/step - loss: 0.0679 - val_loss: 0.0339\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 424us/step - loss: 0.0677 - val_loss: 0.0345\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 429us/step - loss: 0.0676 - val_loss: 0.0424\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 427us/step - loss: 0.0676 - val_loss: 0.0325\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 427us/step - loss: 0.0673 - val_loss: 0.0419\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 426us/step - loss: 0.0673 - val_loss: 0.0371\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 421us/step - loss: 0.0671 - val_loss: 0.0300\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 46s 12ms/step - loss: 0.0670 - val_loss: 0.0140\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 533us/step - loss: 0.0113 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0073 - val_loss: 0.0111\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 535us/step - loss: 0.0052 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0029 - val_loss: 0.0028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 541us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 534us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 545us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 537us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 532us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 543us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 538us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 540us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 536us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 542us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 539us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 48s 13ms/step - loss: 0.0600 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0069 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 0.0053 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 48s 13ms/step - loss: 0.0538 - val_loss: 0.0139\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0143 - val_loss: 0.0080\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0059 - val_loss: 0.0093\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0059 - val_loss: 0.0143\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0096 - val_loss: 0.0157\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0085 - val_loss: 0.0169\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0071 - val_loss: 0.0128\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0066 - val_loss: 0.0149\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0072 - val_loss: 0.0138\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0081 - val_loss: 0.0126\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0070 - val_loss: 0.0126\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0068 - val_loss: 0.0137\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 0.0079 - val_loss: 0.0068\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0044 - val_loss: 0.0058\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0043 - val_loss: 0.0079\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0048 - val_loss: 0.0141\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0089 - val_loss: 0.0172\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0078 - val_loss: 0.0122\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0051 - val_loss: 0.0094\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0040 - val_loss: 0.0071\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0040 - val_loss: 0.0161\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0079 - val_loss: 0.0080\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0048 - val_loss: 0.0125\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 49s 13ms/step - loss: 0.0583 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0083 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 0.0051 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0032 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0019 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 49s 13ms/step - loss: 0.0527 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0062 - val_loss: 0.0170\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0101 - val_loss: 0.0137\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0072 - val_loss: 0.0112\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0073 - val_loss: 0.0173\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0083 - val_loss: 0.0139\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0072 - val_loss: 0.0134\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0065 - val_loss: 0.0153\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0082 - val_loss: 0.0115\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0055 - val_loss: 0.0060\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0041 - val_loss: 0.0086\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0095 - val_loss: 0.0171\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0081 - val_loss: 0.0090\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 0.0044 - val_loss: 0.0065\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0048 - val_loss: 0.0167\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0089 - val_loss: 0.0143\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0060 - val_loss: 0.0084\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0048 - val_loss: 0.0082\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0046 - val_loss: 0.0120\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0038 - val_loss: 0.0104\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0063 - val_loss: 0.0123\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0057 - val_loss: 0.0130\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0055 - val_loss: 0.0098\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 50s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 50s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 616us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: nan - val_loss: nan\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 51s 13ms/step - loss: 61034998899781073371136.0000 - val_loss: 5261.3262\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 8342965.6089 - val_loss: 36383680.0000\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 266974626.7961 - val_loss: 303517312.0000\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 1259110312.6403 - val_loss: 493318336.0000\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2701996863.1771 - val_loss: 430656864.0000\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1683326974.3207 - val_loss: 332881600.0000\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1284314665.1441 - val_loss: 228508176.0000\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 750870980.3243 - val_loss: 153900944.0000\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 397035760.9950 - val_loss: 99083528.0000\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 165199899.3209 - val_loss: 49167588.0000\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 568289121.6720 - val_loss: 38600596.0000\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 192037876.7410 - val_loss: 43966692.0000\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 116724488.7652 - val_loss: 46910304.0000\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 79295077.4789 - val_loss: 47701136.0000\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 82430039.5739 - val_loss: 46948740.0000\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 76890077.8389 - val_loss: 45921700.0000\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 80298360.2078 - val_loss: 45177020.0000\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 71523093.8231 - val_loss: 43416648.0000\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 56743137.2238 - val_loss: 42328096.0000\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 48146625.2259 - val_loss: 41056712.0000\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 71880897.5702 - val_loss: 40232704.0000\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 54955164.1008 - val_loss: 39806240.0000\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 71612163.4038 - val_loss: 39340716.0000\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 71376774.9116 - val_loss: 38858304.0000\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 52s 14ms/step - loss: 0.6063 - val_loss: 0.1353\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0546 - val_loss: 0.0459\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0170 - val_loss: 0.0318\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0087 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0066 - val_loss: 0.0081\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0049 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 52s 14ms/step - loss: 0.0680 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0103 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0046 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0029 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 53s 14ms/step - loss: 0.0810 - val_loss: 0.0199\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0107 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0060 - val_loss: 0.0086\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 0.0043 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0017 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 54s 14ms/step - loss: 0.0444 - val_loss: 0.0192\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0092 - val_loss: 0.0174\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0062 - val_loss: 0.0068\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0038 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0024 - val_loss: 0.0037\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0024 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 54s 14ms/step - loss: 0.3160 - val_loss: 0.0135\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0212 - val_loss: 0.0088\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0160 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 596us/step - loss: 0.0065 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0092 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0035 - val_loss: 0.0087\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0034 - val_loss: 0.0071\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0034 - val_loss: 0.0079\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0039 - val_loss: 0.0049\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0026 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0023 - val_loss: 0.0039\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 55s 14ms/step - loss: 0.4030 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0222 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0062 - val_loss: 0.0100\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0100 - val_loss: 0.0116\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0047 - val_loss: 0.0065\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0037 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0036 - val_loss: 0.0187\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0032 - val_loss: 0.0123\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0047 - val_loss: 0.0060\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 0.0028 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 54s 14ms/step - loss: 0.2334 - val_loss: 0.0194\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 593us/step - loss: 0.0219 - val_loss: 0.0162\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0413 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 0.0088 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 592us/step - loss: 0.0058 - val_loss: 0.0169\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.0068 - val_loss: 0.0095\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0044 - val_loss: 0.0072\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 594us/step - loss: 0.0047 - val_loss: 0.0113\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0040 - val_loss: 0.0108\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0034 - val_loss: 0.0115\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0040 - val_loss: 0.0088\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0035 - val_loss: 0.0074\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0029 - val_loss: 0.0059\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0031 - val_loss: 0.0047\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0030 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 597us/step - loss: 0.0024 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0023 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 598us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 599us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 55s 15ms/step - loss: 0.9071 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0062 - val_loss: 0.0096\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0075 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0033 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 522us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 527us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 523us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 521us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 526us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 525us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 524us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 57s 15ms/step - loss: 2.8696 - val_loss: 0.0275\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0559 - val_loss: 0.0109\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0528 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0119 - val_loss: 0.0476\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0403 - val_loss: 0.0087\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0085 - val_loss: 0.0312\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 547us/step - loss: 0.0128 - val_loss: 0.0681\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0171 - val_loss: 0.0170\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0062 - val_loss: 0.0152\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 558us/step - loss: 0.0103 - val_loss: 0.0415\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0109 - val_loss: 0.0177\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0064 - val_loss: 0.0195\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0090 - val_loss: 0.0285\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0080 - val_loss: 0.0114\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0056 - val_loss: 0.0097\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 551us/step - loss: 0.0069 - val_loss: 0.0239\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 557us/step - loss: 0.0095 - val_loss: 0.0146\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0064 - val_loss: 0.0144\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0054 - val_loss: 0.0081\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 553us/step - loss: 0.0054 - val_loss: 0.0168\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 550us/step - loss: 0.0068 - val_loss: 0.0121\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 552us/step - loss: 0.0047 - val_loss: 0.0078\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 549us/step - loss: 0.0042 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 555us/step - loss: 0.0046 - val_loss: 0.0116\n",
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/24\n",
      "3811/3811 [==============================] - 57s 15ms/step - loss: 1.2162 - val_loss: 0.0268\n",
      "Epoch 2/24\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 0.0560 - val_loss: 0.0526\n",
      "Epoch 3/24\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 0.0838 - val_loss: 0.0135\n",
      "Epoch 4/24\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 0.0484 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 0.0376 - val_loss: 0.0084\n",
      "Epoch 6/24\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 0.0128 - val_loss: 0.0078\n",
      "Epoch 7/24\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 0.0063 - val_loss: 0.0217\n",
      "Epoch 8/24\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 0.0245 - val_loss: 0.0181\n",
      "Epoch 9/24\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 10/24\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 11/24\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 0.0072 - val_loss: 0.0106\n",
      "Epoch 12/24\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 0.0102 - val_loss: 0.0063\n",
      "Epoch 13/24\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 0.0043 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 16/24\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 17/24\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 0.0065 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 20/24\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 0.0053 - val_loss: 0.0077\n",
      "Epoch 22/24\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 0.0035 - val_loss: 0.0032\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0028130996506661177,\n",
       " 0.00337393069639802,\n",
       " 0.0023910412564873695,\n",
       " 0.002850919496268034,\n",
       " 0.0029887736309319735,\n",
       " 0.0028325614985078573,\n",
       " 0.0020027209538966417,\n",
       " 0.002083950210362673,\n",
       " 0.002471914514899254,\n",
       " 0.0022385073825716972,\n",
       " 0.0018101120367646217,\n",
       " 0.002176805632188916,\n",
       " 0.0017062816768884659,\n",
       " 0.0016743424348533154,\n",
       " 0.001963894348591566,\n",
       " 0.0017143437871709466,\n",
       " 0.0018961011664941907,\n",
       " 0.00143824506085366,\n",
       " 0.0017301625339314342,\n",
       " 0.001865064026787877,\n",
       " 0.0013750952202826738,\n",
       " 0.0013359305448830128,\n",
       " 0.001858892966993153,\n",
       " 0.0013230516342446208]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "lstmsize: 178\n",
      "twice: True\n",
      "full_density: True\n",
      "density: 142\n",
      "dropout: 0.1\n",
      "optimizer: adam\n",
      "activation: softsign\n",
      "shuffle: True\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_40\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_79 (LSTM)               (None, 92, 178)           131008    \n",
      "_________________________________________________________________\n",
      "dropout_77 (Dropout)         (None, 92, 178)           0         \n",
      "_________________________________________________________________\n",
      "lstm_80 (LSTM)               (None, 178)               254184    \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 178)               0         \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 142)               25418     \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 71)                10153     \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 35)                2520      \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 17)                612       \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 423,913\n",
      "Trainable params: 423,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3811 samples, validate on 424 samples\n",
      "Epoch 1/2000\n",
      "3811/3811 [==============================] - 57s 15ms/step - loss: 0.0624 - val_loss: 0.0259\n",
      "Epoch 2/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0141 - val_loss: 0.0026\n",
      "Epoch 3/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 4/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0046 - val_loss: 0.0069\n",
      "Epoch 5/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0036 - val_loss: 0.0052\n",
      "Epoch 6/2000\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 7/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 8/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 9/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 10/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 11/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 12/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 13/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 14/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 15/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 16/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 17/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 18/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 19/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 20/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 21/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 22/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 23/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 25/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 26/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 27/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 28/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 29/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 30/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 31/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 32/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 33/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 34/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 35/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 36/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 37/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 38/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 39/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 40/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 41/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 42/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 43/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 44/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 45/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 46/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 47/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 48/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 49/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 50/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 51/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 52/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 53/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 54/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 55/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0011 - val_loss: 9.9545e-04\n",
      "Epoch 56/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0011 - val_loss: 9.9942e-04\n",
      "Epoch 57/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 0.0011 - val_loss: 9.8143e-04\n",
      "Epoch 58/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 59/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0010 - val_loss: 9.5665e-04\n",
      "Epoch 60/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 61/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0011 - val_loss: 9.4083e-04\n",
      "Epoch 62/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 63/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 64/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 65/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 66/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 67/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 68/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 69/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 70/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 9.6795e-04 - val_loss: 8.6089e-04\n",
      "Epoch 71/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 9.5990e-04 - val_loss: 9.7705e-04\n",
      "Epoch 72/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 9.3470e-04 - val_loss: 8.8680e-04\n",
      "Epoch 73/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 9.2793e-04 - val_loss: 9.2469e-04\n",
      "Epoch 74/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 9.3714e-04 - val_loss: 0.0012\n",
      "Epoch 75/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 9.2947e-04 - val_loss: 0.0011\n",
      "Epoch 76/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 608us/step - loss: 9.4030e-04 - val_loss: 8.2902e-04\n",
      "Epoch 77/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 8.8221e-04 - val_loss: 8.7088e-04\n",
      "Epoch 78/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 8.8054e-04 - val_loss: 0.0010\n",
      "Epoch 79/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 8.8830e-04 - val_loss: 8.0186e-04\n",
      "Epoch 80/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 9.6511e-04 - val_loss: 8.9932e-04\n",
      "Epoch 81/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 9.4796e-04 - val_loss: 7.9814e-04\n",
      "Epoch 82/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 9.3885e-04 - val_loss: 8.0657e-04\n",
      "Epoch 83/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 9.1419e-04 - val_loss: 0.0011\n",
      "Epoch 84/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 8.8757e-04 - val_loss: 9.2193e-04\n",
      "Epoch 85/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 8.4802e-04 - val_loss: 7.9377e-04\n",
      "Epoch 86/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 8.5702e-04 - val_loss: 7.9290e-04\n",
      "Epoch 87/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 8.4678e-04 - val_loss: 0.0011\n",
      "Epoch 88/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 8.1639e-04 - val_loss: 8.8243e-04\n",
      "Epoch 89/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 7.9415e-04 - val_loss: 7.9853e-04\n",
      "Epoch 90/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 8.1463e-04 - val_loss: 7.1651e-04\n",
      "Epoch 91/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 8.0452e-04 - val_loss: 8.2716e-04\n",
      "Epoch 92/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 7.8764e-04 - val_loss: 8.1112e-04\n",
      "Epoch 93/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 7.8614e-04 - val_loss: 8.2148e-04\n",
      "Epoch 94/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 8.1830e-04 - val_loss: 7.4606e-04\n",
      "Epoch 95/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 8.2251e-04 - val_loss: 7.1970e-04\n",
      "Epoch 96/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 7.8785e-04 - val_loss: 7.3620e-04\n",
      "Epoch 97/2000\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 7.5068e-04 - val_loss: 6.8520e-04\n",
      "Epoch 98/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 7.5093e-04 - val_loss: 7.8221e-04\n",
      "Epoch 99/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 8.0186e-04 - val_loss: 7.9646e-04\n",
      "Epoch 100/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 8.8602e-04 - val_loss: 8.6100e-04\n",
      "Epoch 101/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 8.6890e-04 - val_loss: 9.4035e-04\n",
      "Epoch 102/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 9.2478e-04 - val_loss: 8.5113e-04\n",
      "Epoch 103/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 8.8402e-04 - val_loss: 7.4147e-04\n",
      "Epoch 104/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 7.5787e-04 - val_loss: 0.0011\n",
      "Epoch 105/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 7.5656e-04 - val_loss: 6.4160e-04\n",
      "Epoch 106/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 8.3123e-04 - val_loss: 7.1580e-04\n",
      "Epoch 107/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 7.8752e-04 - val_loss: 6.7278e-04\n",
      "Epoch 108/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 7.2797e-04 - val_loss: 6.5744e-04\n",
      "Epoch 109/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 7.2114e-04 - val_loss: 6.8249e-04\n",
      "Epoch 110/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 7.3324e-04 - val_loss: 6.4729e-04\n",
      "Epoch 111/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 7.0943e-04 - val_loss: 6.3014e-04\n",
      "Epoch 112/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 7.4683e-04 - val_loss: 6.4186e-04\n",
      "Epoch 113/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 7.1468e-04 - val_loss: 6.4982e-04\n",
      "Epoch 114/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 7.1467e-04 - val_loss: 7.8466e-04\n",
      "Epoch 115/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 7.8272e-04 - val_loss: 8.1075e-04\n",
      "Epoch 116/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 8.0015e-04 - val_loss: 6.1908e-04\n",
      "Epoch 117/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 7.6054e-04 - val_loss: 6.2595e-04\n",
      "Epoch 118/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 7.1505e-04 - val_loss: 6.9718e-04\n",
      "Epoch 119/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 6.9278e-04 - val_loss: 6.5443e-04\n",
      "Epoch 120/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.7484e-04 - val_loss: 6.3329e-04\n",
      "Epoch 121/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.8975e-04 - val_loss: 5.9610e-04\n",
      "Epoch 122/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 6.8727e-04 - val_loss: 5.9749e-04\n",
      "Epoch 123/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.6289e-04 - val_loss: 6.4612e-04\n",
      "Epoch 124/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 7.2733e-04 - val_loss: 6.1491e-04\n",
      "Epoch 125/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.9053e-04 - val_loss: 6.6746e-04\n",
      "Epoch 126/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 7.7718e-04 - val_loss: 6.2681e-04\n",
      "Epoch 127/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 7.0462e-04 - val_loss: 8.1362e-04\n",
      "Epoch 128/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.7534e-04 - val_loss: 6.8043e-04\n",
      "Epoch 129/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 6.5614e-04 - val_loss: 0.0011\n",
      "Epoch 130/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 7.5273e-04 - val_loss: 6.7459e-04\n",
      "Epoch 131/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.7642e-04 - val_loss: 7.4816e-04\n",
      "Epoch 132/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 6.5528e-04 - val_loss: 6.6028e-04\n",
      "Epoch 133/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.6897e-04 - val_loss: 6.0156e-04\n",
      "Epoch 134/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.7854e-04 - val_loss: 6.0749e-04\n",
      "Epoch 135/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.5414e-04 - val_loss: 5.7655e-04\n",
      "Epoch 136/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 6.5268e-04 - val_loss: 5.8940e-04\n",
      "Epoch 137/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.4959e-04 - val_loss: 8.4290e-04\n",
      "Epoch 138/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.8883e-04 - val_loss: 7.5617e-04\n",
      "Epoch 139/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.7345e-04 - val_loss: 5.8120e-04\n",
      "Epoch 140/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.7421e-04 - val_loss: 6.6106e-04\n",
      "Epoch 141/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.6273e-04 - val_loss: 5.8488e-04\n",
      "Epoch 142/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.3455e-04 - val_loss: 5.9046e-04\n",
      "Epoch 143/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 6.4711e-04 - val_loss: 6.7902e-04\n",
      "Epoch 144/2000\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 6.8511e-04 - val_loss: 8.4293e-04\n",
      "Epoch 145/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 6.7347e-04 - val_loss: 5.9547e-04\n",
      "Epoch 146/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.1615e-04 - val_loss: 7.0208e-04\n",
      "Epoch 147/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.2953e-04 - val_loss: 6.2225e-04\n",
      "Epoch 148/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.4827e-04 - val_loss: 6.2580e-04\n",
      "Epoch 149/2000\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 6.7381e-04 - val_loss: 5.9485e-04\n",
      "Epoch 150/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 6.4318e-04 - val_loss: 7.1438e-04\n",
      "Epoch 151/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.7490e-04 - val_loss: 5.8936e-04\n",
      "Epoch 152/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.3358e-04 - val_loss: 6.6360e-04\n",
      "Epoch 153/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.6592e-04 - val_loss: 5.8880e-04\n",
      "Epoch 154/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.7715e-04 - val_loss: 8.5162e-04\n",
      "Epoch 155/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.7882e-04 - val_loss: 5.8408e-04\n",
      "Epoch 156/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.4735e-04 - val_loss: 6.0104e-04\n",
      "Epoch 157/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.5667e-04 - val_loss: 8.0073e-04\n",
      "Epoch 158/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.5350e-04 - val_loss: 7.4427e-04\n",
      "Epoch 159/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.4700e-04 - val_loss: 6.3656e-04\n",
      "Epoch 160/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.3158e-04 - val_loss: 6.0262e-04\n",
      "Epoch 161/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.1175e-04 - val_loss: 5.8962e-04\n",
      "Epoch 162/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.9840e-04 - val_loss: 5.7257e-04\n",
      "Epoch 163/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.3259e-04 - val_loss: 5.7536e-04\n",
      "Epoch 164/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.1228e-04 - val_loss: 5.7841e-04\n",
      "Epoch 165/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.1395e-04 - val_loss: 5.7449e-04\n",
      "Epoch 166/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.2326e-04 - val_loss: 6.6475e-04\n",
      "Epoch 167/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.2911e-04 - val_loss: 7.9874e-04\n",
      "Epoch 168/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.7641e-04 - val_loss: 8.2719e-04\n",
      "Epoch 169/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.5637e-04 - val_loss: 5.9205e-04\n",
      "Epoch 170/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 6.1872e-04 - val_loss: 6.2364e-04\n",
      "Epoch 171/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 6.1890e-04 - val_loss: 6.2241e-04\n",
      "Epoch 172/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.2148e-04 - val_loss: 6.3645e-04\n",
      "Epoch 173/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.1765e-04 - val_loss: 7.7782e-04\n",
      "Epoch 174/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.5762e-04 - val_loss: 6.0242e-04\n",
      "Epoch 175/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.2988e-04 - val_loss: 5.8866e-04\n",
      "Epoch 176/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.3623e-04 - val_loss: 6.0067e-04\n",
      "Epoch 177/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.7633e-04 - val_loss: 7.2036e-04\n",
      "Epoch 178/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.7534e-04 - val_loss: 5.8002e-04\n",
      "Epoch 179/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.0271e-04 - val_loss: 5.6658e-04\n",
      "Epoch 180/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.1351e-04 - val_loss: 5.6732e-04\n",
      "Epoch 181/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.0498e-04 - val_loss: 5.7592e-04\n",
      "Epoch 182/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.1185e-04 - val_loss: 5.7442e-04\n",
      "Epoch 183/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.2038e-04 - val_loss: 5.9604e-04\n",
      "Epoch 184/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 6.1123e-04 - val_loss: 5.8703e-04\n",
      "Epoch 185/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.1977e-04 - val_loss: 5.7699e-04\n",
      "Epoch 186/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.5127e-04 - val_loss: 6.3484e-04\n",
      "Epoch 187/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 6.2479e-04 - val_loss: 6.1642e-04\n",
      "Epoch 188/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.4027e-04 - val_loss: 5.9115e-04\n",
      "Epoch 189/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.0226e-04 - val_loss: 5.6585e-04\n",
      "Epoch 190/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 5.9324e-04 - val_loss: 5.7760e-04\n",
      "Epoch 191/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.9591e-04 - val_loss: 6.0906e-04\n",
      "Epoch 192/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 6.1405e-04 - val_loss: 6.7642e-04\n",
      "Epoch 193/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.4598e-04 - val_loss: 5.6826e-04\n",
      "Epoch 194/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.9582e-04 - val_loss: 6.1498e-04\n",
      "Epoch 195/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.3816e-04 - val_loss: 6.0351e-04\n",
      "Epoch 196/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.2427e-04 - val_loss: 6.7298e-04\n",
      "Epoch 197/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.2733e-04 - val_loss: 5.7822e-04\n",
      "Epoch 198/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 6.1313e-04 - val_loss: 7.0743e-04\n",
      "Epoch 199/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.4192e-04 - val_loss: 7.6637e-04\n",
      "Epoch 200/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.0327e-04 - val_loss: 5.8214e-04\n",
      "Epoch 201/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.0042e-04 - val_loss: 5.7098e-04\n",
      "Epoch 202/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.1678e-04 - val_loss: 6.7038e-04\n",
      "Epoch 203/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.7611e-04 - val_loss: 6.1568e-04\n",
      "Epoch 204/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 6.0615e-04 - val_loss: 5.9240e-04\n",
      "Epoch 205/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.9704e-04 - val_loss: 6.0198e-04\n",
      "Epoch 206/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.9977e-04 - val_loss: 6.1388e-04\n",
      "Epoch 207/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.9250e-04 - val_loss: 7.1607e-04\n",
      "Epoch 208/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.8674e-04 - val_loss: 5.7489e-04\n",
      "Epoch 209/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.3322e-04 - val_loss: 6.3155e-04\n",
      "Epoch 210/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.8084e-04 - val_loss: 6.8541e-04\n",
      "Epoch 211/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 6.5628e-04 - val_loss: 8.1025e-04\n",
      "Epoch 212/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.6698e-04 - val_loss: 5.6819e-04\n",
      "Epoch 213/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.1551e-04 - val_loss: 6.3087e-04\n",
      "Epoch 214/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.9123e-04 - val_loss: 6.1900e-04\n",
      "Epoch 215/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.9486e-04 - val_loss: 5.8337e-04\n",
      "Epoch 216/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.9041e-04 - val_loss: 5.7610e-04\n",
      "Epoch 217/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.9792e-04 - val_loss: 6.9133e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 218/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 6.5049e-04 - val_loss: 6.6148e-04\n",
      "Epoch 219/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 6.2688e-04 - val_loss: 7.2595e-04\n",
      "Epoch 220/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.3315e-04 - val_loss: 7.8211e-04\n",
      "Epoch 221/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.0870e-04 - val_loss: 5.7342e-04\n",
      "Epoch 222/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.9500e-04 - val_loss: 5.8708e-04\n",
      "Epoch 223/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.9171e-04 - val_loss: 5.7464e-04\n",
      "Epoch 224/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 5.8053e-04 - val_loss: 5.7354e-04\n",
      "Epoch 225/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.9620e-04 - val_loss: 6.4874e-04\n",
      "Epoch 226/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 6.0171e-04 - val_loss: 6.3067e-04\n",
      "Epoch 227/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.8141e-04 - val_loss: 6.1469e-04\n",
      "Epoch 228/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.0566e-04 - val_loss: 5.9048e-04\n",
      "Epoch 229/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.0015e-04 - val_loss: 5.8995e-04\n",
      "Epoch 230/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.0439e-04 - val_loss: 6.5790e-04\n",
      "Epoch 231/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 6.1934e-04 - val_loss: 5.9224e-04\n",
      "Epoch 232/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 6.0662e-04 - val_loss: 6.3545e-04\n",
      "Epoch 233/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.9562e-04 - val_loss: 5.8508e-04\n",
      "Epoch 234/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.8650e-04 - val_loss: 5.8555e-04\n",
      "Epoch 235/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.2198e-04 - val_loss: 6.7200e-04\n",
      "Epoch 236/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.1187e-04 - val_loss: 5.6719e-04\n",
      "Epoch 237/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.0741e-04 - val_loss: 5.7612e-04\n",
      "Epoch 238/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.9560e-04 - val_loss: 5.7516e-04\n",
      "Epoch 239/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.8189e-04 - val_loss: 5.7019e-04\n",
      "Epoch 240/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.8844e-04 - val_loss: 5.9830e-04\n",
      "Epoch 241/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.8951e-04 - val_loss: 8.1416e-04\n",
      "Epoch 242/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 7.0705e-04 - val_loss: 6.9929e-04\n",
      "Epoch 243/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.9357e-04 - val_loss: 5.7750e-04\n",
      "Epoch 244/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 5.8353e-04 - val_loss: 6.6537e-04\n",
      "Epoch 245/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 5.8242e-04 - val_loss: 6.3583e-04\n",
      "Epoch 246/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.0164e-04 - val_loss: 7.2509e-04\n",
      "Epoch 247/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.2809e-04 - val_loss: 0.0010\n",
      "Epoch 248/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.6350e-04 - val_loss: 9.7856e-04\n",
      "Epoch 249/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 6.8736e-04 - val_loss: 5.7576e-04\n",
      "Epoch 250/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 6.1259e-04 - val_loss: 5.7822e-04\n",
      "Epoch 251/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.8882e-04 - val_loss: 6.7761e-04\n",
      "Epoch 252/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 6.3359e-04 - val_loss: 5.7959e-04\n",
      "Epoch 253/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.8862e-04 - val_loss: 6.0408e-04\n",
      "Epoch 254/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.9557e-04 - val_loss: 6.1697e-04\n",
      "Epoch 255/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.0123e-04 - val_loss: 7.7463e-04\n",
      "Epoch 256/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.1996e-04 - val_loss: 7.4815e-04\n",
      "Epoch 257/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.2250e-04 - val_loss: 6.8607e-04\n",
      "Epoch 258/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.0104e-04 - val_loss: 5.8799e-04\n",
      "Epoch 259/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 5.9461e-04 - val_loss: 5.7551e-04\n",
      "Epoch 260/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.8934e-04 - val_loss: 6.0058e-04\n",
      "Epoch 261/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.9904e-04 - val_loss: 6.0096e-04\n",
      "Epoch 262/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.8885e-04 - val_loss: 5.9945e-04\n",
      "Epoch 263/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.9314e-04 - val_loss: 5.8537e-04\n",
      "Epoch 264/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.1205e-04 - val_loss: 5.8517e-04\n",
      "Epoch 265/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.8135e-04 - val_loss: 6.5632e-04\n",
      "Epoch 266/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 6.2055e-04 - val_loss: 9.9347e-04\n",
      "Epoch 267/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.4931e-04 - val_loss: 7.8839e-04\n",
      "Epoch 268/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 6.7966e-04 - val_loss: 6.0201e-04\n",
      "Epoch 269/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.8235e-04 - val_loss: 8.4994e-04\n",
      "Epoch 270/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 6.6497e-04 - val_loss: 6.4884e-04\n",
      "Epoch 271/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.7592e-04 - val_loss: 6.2637e-04\n",
      "Epoch 272/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.9517e-04 - val_loss: 7.1480e-04\n",
      "Epoch 273/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 6.3708e-04 - val_loss: 5.9095e-04\n",
      "Epoch 274/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.5873e-04 - val_loss: 6.6523e-04\n",
      "Epoch 275/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.0743e-04 - val_loss: 5.9098e-04\n",
      "Epoch 276/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 6.0031e-04 - val_loss: 7.3191e-04\n",
      "Epoch 277/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.1085e-04 - val_loss: 6.7231e-04\n",
      "Epoch 278/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.9419e-04 - val_loss: 6.3862e-04\n",
      "Epoch 279/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 6.3218e-04 - val_loss: 6.8279e-04\n",
      "Epoch 280/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 6.3914e-04 - val_loss: 6.2999e-04\n",
      "Epoch 281/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.9966e-04 - val_loss: 7.2071e-04\n",
      "Epoch 282/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.9092e-04 - val_loss: 5.9170e-04\n",
      "Epoch 283/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.8754e-04 - val_loss: 5.9433e-04\n",
      "Epoch 284/2000\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 5.8550e-04 - val_loss: 6.2729e-04\n",
      "Epoch 285/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.7944e-04 - val_loss: 5.7208e-04\n",
      "Epoch 286/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.6896e-04 - val_loss: 5.7516e-04\n",
      "Epoch 287/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.6377e-04 - val_loss: 5.7291e-04\n",
      "Epoch 288/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.9141e-04 - val_loss: 5.8626e-04\n",
      "Epoch 289/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.9980e-04 - val_loss: 5.9282e-04\n",
      "Epoch 290/2000\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 5.8786e-04 - val_loss: 5.8504e-04\n",
      "Epoch 291/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.7125e-04 - val_loss: 6.0979e-04\n",
      "Epoch 292/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.9455e-04 - val_loss: 5.7700e-04\n",
      "Epoch 293/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 6.0172e-04 - val_loss: 5.7453e-04\n",
      "Epoch 294/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.9864e-04 - val_loss: 7.8964e-04\n",
      "Epoch 295/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 6.3998e-04 - val_loss: 5.9663e-04\n",
      "Epoch 296/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.8264e-04 - val_loss: 6.8244e-04\n",
      "Epoch 297/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 6.1725e-04 - val_loss: 6.0261e-04\n",
      "Epoch 298/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 6.0363e-04 - val_loss: 5.8298e-04\n",
      "Epoch 299/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.8772e-04 - val_loss: 6.1645e-04\n",
      "Epoch 300/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.7536e-04 - val_loss: 5.7373e-04\n",
      "Epoch 301/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.9803e-04 - val_loss: 6.3770e-04\n",
      "Epoch 302/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.9237e-04 - val_loss: 5.7624e-04\n",
      "Epoch 303/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.5335e-04 - val_loss: 5.9835e-04\n",
      "Epoch 304/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.7657e-04 - val_loss: 5.7208e-04\n",
      "Epoch 305/2000\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 5.6219e-04 - val_loss: 6.0140e-04\n",
      "Epoch 306/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.9096e-04 - val_loss: 6.5298e-04\n",
      "Epoch 307/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.6352e-04 - val_loss: 5.7401e-04\n",
      "Epoch 308/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.7621e-04 - val_loss: 6.0260e-04\n",
      "Epoch 309/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.9319e-04 - val_loss: 7.2495e-04\n",
      "Epoch 310/2000\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 6.2542e-04 - val_loss: 7.8496e-04\n",
      "Epoch 311/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 6.0669e-04 - val_loss: 5.8982e-04\n",
      "Epoch 312/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.6821e-04 - val_loss: 6.2127e-04\n",
      "Epoch 313/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.7002e-04 - val_loss: 5.7530e-04\n",
      "Epoch 314/2000\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 5.7506e-04 - val_loss: 6.5977e-04\n",
      "Epoch 315/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.6942e-04 - val_loss: 6.1694e-04\n",
      "Epoch 316/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.6867e-04 - val_loss: 5.8475e-04\n",
      "Epoch 317/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.8107e-04 - val_loss: 6.6135e-04\n",
      "Epoch 318/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.6437e-04 - val_loss: 5.7795e-04\n",
      "Epoch 319/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.7239e-04 - val_loss: 6.0597e-04\n",
      "Epoch 320/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.6950e-04 - val_loss: 5.7756e-04\n",
      "Epoch 321/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.5912e-04 - val_loss: 6.0772e-04\n",
      "Epoch 322/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.6384e-04 - val_loss: 6.1147e-04\n",
      "Epoch 323/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.6209e-04 - val_loss: 5.9880e-04\n",
      "Epoch 324/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.9124e-04 - val_loss: 6.1091e-04\n",
      "Epoch 325/2000\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 5.7407e-04 - val_loss: 6.1110e-04\n",
      "Epoch 326/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.6970e-04 - val_loss: 6.1770e-04\n",
      "Epoch 327/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.4672e-04 - val_loss: 6.2159e-04\n",
      "Epoch 328/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.6798e-04 - val_loss: 6.7492e-04\n",
      "Epoch 329/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.8258e-04 - val_loss: 5.9000e-04\n",
      "Epoch 330/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.6916e-04 - val_loss: 5.9714e-04\n",
      "Epoch 331/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.8071e-04 - val_loss: 5.7765e-04\n",
      "Epoch 332/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 6.0703e-04 - val_loss: 0.0010\n",
      "Epoch 333/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 6.4549e-04 - val_loss: 6.9503e-04\n",
      "Epoch 334/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.8616e-04 - val_loss: 6.2241e-04\n",
      "Epoch 335/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.1904e-04 - val_loss: 5.9800e-04\n",
      "Epoch 336/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.8900e-04 - val_loss: 5.9286e-04\n",
      "Epoch 337/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.8958e-04 - val_loss: 5.9446e-04\n",
      "Epoch 338/2000\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 5.9973e-04 - val_loss: 6.3564e-04\n",
      "Epoch 339/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 6.1658e-04 - val_loss: 6.4963e-04\n",
      "Epoch 340/2000\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 5.8980e-04 - val_loss: 6.1055e-04\n",
      "Epoch 341/2000\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 5.7747e-04 - val_loss: 5.8715e-04\n",
      "Epoch 342/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.7193e-04 - val_loss: 6.3570e-04\n",
      "Epoch 343/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.7117e-04 - val_loss: 5.8439e-04\n",
      "Epoch 344/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.7480e-04 - val_loss: 6.9402e-04\n",
      "Epoch 345/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.9525e-04 - val_loss: 5.9926e-04\n",
      "Epoch 346/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 6.0178e-04 - val_loss: 6.4457e-04\n",
      "Epoch 347/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.6473e-04 - val_loss: 6.1774e-04\n",
      "Epoch 348/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.7660e-04 - val_loss: 6.1097e-04\n",
      "Epoch 349/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.5929e-04 - val_loss: 5.9845e-04\n",
      "Epoch 350/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.5267e-04 - val_loss: 6.2728e-04\n",
      "Epoch 351/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.5387e-04 - val_loss: 6.0065e-04\n",
      "Epoch 352/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.7626e-04 - val_loss: 5.8547e-04\n",
      "Epoch 353/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.7109e-04 - val_loss: 6.0435e-04\n",
      "Epoch 354/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.6755e-04 - val_loss: 6.1154e-04\n",
      "Epoch 355/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.7816e-04 - val_loss: 6.4504e-04\n",
      "Epoch 356/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.8132e-04 - val_loss: 6.1419e-04\n",
      "Epoch 357/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.6290e-04 - val_loss: 6.9529e-04\n",
      "Epoch 358/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.5042e-04 - val_loss: 6.8533e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.7945e-04 - val_loss: 6.2457e-04\n",
      "Epoch 360/2000\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 6.4691e-04 - val_loss: 8.2780e-04\n",
      "Epoch 361/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 6.7264e-04 - val_loss: 7.6171e-04\n",
      "Epoch 362/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 6.0555e-04 - val_loss: 6.3128e-04\n",
      "Epoch 363/2000\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 5.6696e-04 - val_loss: 5.9139e-04\n",
      "Epoch 364/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.6684e-04 - val_loss: 5.9318e-04\n",
      "Epoch 365/2000\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 5.8951e-04 - val_loss: 5.8657e-04\n",
      "Epoch 366/2000\n",
      "3811/3811 [==============================] - 2s 600us/step - loss: 5.7721e-04 - val_loss: 5.9279e-04\n",
      "Epoch 367/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.6678e-04 - val_loss: 6.2085e-04\n",
      "Epoch 368/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.5564e-04 - val_loss: 5.9021e-04\n",
      "Epoch 369/2000\n",
      "3811/3811 [==============================] - 2s 601us/step - loss: 5.5985e-04 - val_loss: 6.3116e-04\n",
      "Epoch 370/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.7302e-04 - val_loss: 6.0951e-04\n",
      "Epoch 371/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.6039e-04 - val_loss: 5.8891e-04\n",
      "Epoch 372/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.7536e-04 - val_loss: 5.9666e-04\n",
      "Epoch 373/2000\n",
      "3811/3811 [==============================] - 2s 602us/step - loss: 5.7983e-04 - val_loss: 7.3956e-04\n",
      "Epoch 374/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.8901e-04 - val_loss: 5.8581e-04\n",
      "Epoch 375/2000\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 5.8832e-04 - val_loss: 6.5256e-04\n",
      "Epoch 376/2000\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 5.6872e-04 - val_loss: 5.8658e-04\n",
      "Epoch 377/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.8969e-04 - val_loss: 5.9013e-04\n",
      "Epoch 378/2000\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 5.9186e-04 - val_loss: 6.7273e-04\n",
      "Epoch 379/2000\n",
      "3811/3811 [==============================] - 2s 603us/step - loss: 5.8594e-04 - val_loss: 6.0203e-04\n",
      "Epoch 380/2000\n",
      "3811/3811 [==============================] - 3s 671us/step - loss: 5.7304e-04 - val_loss: 6.4469e-04\n",
      "Epoch 381/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 5.7283e-04 - val_loss: 5.8768e-04\n",
      "Epoch 382/2000\n",
      "3811/3811 [==============================] - 3s 663us/step - loss: 5.5727e-04 - val_loss: 6.0496e-04\n",
      "Epoch 383/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 5.4891e-04 - val_loss: 6.0270e-04\n",
      "Epoch 384/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 5.7139e-04 - val_loss: 7.3033e-04\n",
      "Epoch 385/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 6.0723e-04 - val_loss: 8.1980e-04\n",
      "Epoch 386/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 5.8173e-04 - val_loss: 6.6419e-04\n",
      "Epoch 387/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 5.7131e-04 - val_loss: 5.9769e-04\n",
      "Epoch 388/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 5.6178e-04 - val_loss: 6.0564e-04\n",
      "Epoch 389/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.6987e-04 - val_loss: 8.0589e-04\n",
      "Epoch 390/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.9742e-04 - val_loss: 7.8721e-04\n",
      "Epoch 391/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 6.2414e-04 - val_loss: 6.6528e-04\n",
      "Epoch 392/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 5.6803e-04 - val_loss: 7.4143e-04\n",
      "Epoch 393/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.8678e-04 - val_loss: 5.9877e-04\n",
      "Epoch 394/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 5.4860e-04 - val_loss: 6.1359e-04\n",
      "Epoch 395/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 5.6175e-04 - val_loss: 6.0313e-04\n",
      "Epoch 396/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 5.6061e-04 - val_loss: 6.5037e-04\n",
      "Epoch 397/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 5.8724e-04 - val_loss: 6.8882e-04\n",
      "Epoch 398/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 5.9758e-04 - val_loss: 6.7776e-04\n",
      "Epoch 399/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.7969e-04 - val_loss: 6.3833e-04\n",
      "Epoch 400/2000\n",
      "3811/3811 [==============================] - 2s 604us/step - loss: 5.6870e-04 - val_loss: 5.9808e-04\n",
      "Epoch 401/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.3458e-04 - val_loss: 6.1756e-04\n",
      "Epoch 402/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 5.5403e-04 - val_loss: 5.9997e-04\n",
      "Epoch 403/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 5.7392e-04 - val_loss: 6.0592e-04\n",
      "Epoch 404/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 5.5587e-04 - val_loss: 6.2363e-04\n",
      "Epoch 405/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 5.5325e-04 - val_loss: 6.7322e-04\n",
      "Epoch 406/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 5.7550e-04 - val_loss: 6.4488e-04\n",
      "Epoch 407/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.5449e-04 - val_loss: 6.0278e-04\n",
      "Epoch 408/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.5332e-04 - val_loss: 6.1253e-04\n",
      "Epoch 409/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 6.0403e-04 - val_loss: 9.7623e-04\n",
      "Epoch 410/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 6.9573e-04 - val_loss: 6.8579e-04\n",
      "Epoch 411/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 6.3524e-04 - val_loss: 7.3885e-04\n",
      "Epoch 412/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 5.8708e-04 - val_loss: 6.2845e-04\n",
      "Epoch 413/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 5.7603e-04 - val_loss: 6.5011e-04\n",
      "Epoch 414/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 6.2257e-04 - val_loss: 6.3545e-04\n",
      "Epoch 415/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.8884e-04 - val_loss: 5.9194e-04\n",
      "Epoch 416/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.8044e-04 - val_loss: 6.7034e-04\n",
      "Epoch 417/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.3990e-04 - val_loss: 6.5302e-04\n",
      "Epoch 418/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 5.6242e-04 - val_loss: 7.1475e-04\n",
      "Epoch 419/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.9204e-04 - val_loss: 8.0776e-04\n",
      "Epoch 420/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.7701e-04 - val_loss: 6.9621e-04\n",
      "Epoch 421/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.6792e-04 - val_loss: 5.9772e-04\n",
      "Epoch 422/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 5.5334e-04 - val_loss: 6.2362e-04\n",
      "Epoch 423/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 5.5725e-04 - val_loss: 6.1636e-04\n",
      "Epoch 424/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 5.4729e-04 - val_loss: 7.3570e-04\n",
      "Epoch 425/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.4758e-04 - val_loss: 6.0598e-04\n",
      "Epoch 426/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.4544e-04 - val_loss: 8.1124e-04\n",
      "Epoch 427/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.8444e-04 - val_loss: 6.2084e-04\n",
      "Epoch 428/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 6.0706e-04 - val_loss: 6.8984e-04\n",
      "Epoch 429/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.6960e-04 - val_loss: 6.4967e-04\n",
      "Epoch 430/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 5.4458e-04 - val_loss: 6.0238e-04\n",
      "Epoch 431/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 5.7430e-04 - val_loss: 6.2413e-04\n",
      "Epoch 432/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.5961e-04 - val_loss: 6.0204e-04\n",
      "Epoch 433/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.5847e-04 - val_loss: 6.4016e-04\n",
      "Epoch 434/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.5041e-04 - val_loss: 6.1863e-04\n",
      "Epoch 435/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.5588e-04 - val_loss: 6.1503e-04\n",
      "Epoch 436/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 5.4938e-04 - val_loss: 6.0322e-04\n",
      "Epoch 437/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.5187e-04 - val_loss: 6.3536e-04\n",
      "Epoch 438/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 5.5779e-04 - val_loss: 6.8964e-04\n",
      "Epoch 439/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 5.6097e-04 - val_loss: 8.4317e-04\n",
      "Epoch 440/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 6.0606e-04 - val_loss: 6.1273e-04\n",
      "Epoch 441/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 5.3981e-04 - val_loss: 6.1754e-04\n",
      "Epoch 442/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 5.5536e-04 - val_loss: 6.1457e-04\n",
      "Epoch 443/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.6121e-04 - val_loss: 6.2852e-04\n",
      "Epoch 444/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.4210e-04 - val_loss: 6.6233e-04\n",
      "Epoch 445/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 5.9485e-04 - val_loss: 7.2478e-04\n",
      "Epoch 446/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 6.6520e-04 - val_loss: 6.4243e-04\n",
      "Epoch 447/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 6.1679e-04 - val_loss: 6.4942e-04\n",
      "Epoch 448/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.7530e-04 - val_loss: 7.1514e-04\n",
      "Epoch 449/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.5115e-04 - val_loss: 6.3789e-04\n",
      "Epoch 450/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 5.4029e-04 - val_loss: 6.7698e-04\n",
      "Epoch 451/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 5.4671e-04 - val_loss: 6.5381e-04\n",
      "Epoch 452/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.3812e-04 - val_loss: 6.1839e-04\n",
      "Epoch 453/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 5.2653e-04 - val_loss: 6.1386e-04\n",
      "Epoch 454/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 5.3137e-04 - val_loss: 6.4568e-04\n",
      "Epoch 455/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 5.5841e-04 - val_loss: 6.3104e-04\n",
      "Epoch 456/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 5.4339e-04 - val_loss: 6.0816e-04\n",
      "Epoch 457/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.4568e-04 - val_loss: 6.5623e-04\n",
      "Epoch 458/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 6.0226e-04 - val_loss: 6.3680e-04\n",
      "Epoch 459/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.9450e-04 - val_loss: 6.7163e-04\n",
      "Epoch 460/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.8233e-04 - val_loss: 7.8653e-04\n",
      "Epoch 461/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.7199e-04 - val_loss: 6.6352e-04\n",
      "Epoch 462/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.7110e-04 - val_loss: 6.1317e-04\n",
      "Epoch 463/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 5.2977e-04 - val_loss: 6.1921e-04\n",
      "Epoch 464/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.3344e-04 - val_loss: 6.3787e-04\n",
      "Epoch 465/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 5.1983e-04 - val_loss: 6.6795e-04\n",
      "Epoch 466/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.4276e-04 - val_loss: 6.2312e-04\n",
      "Epoch 467/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.4841e-04 - val_loss: 6.3239e-04\n",
      "Epoch 468/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.3565e-04 - val_loss: 7.1234e-04\n",
      "Epoch 469/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.9187e-04 - val_loss: 7.4024e-04\n",
      "Epoch 470/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.5204e-04 - val_loss: 6.2848e-04\n",
      "Epoch 471/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.4540e-04 - val_loss: 6.2808e-04\n",
      "Epoch 472/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 5.3203e-04 - val_loss: 6.7935e-04\n",
      "Epoch 473/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.3358e-04 - val_loss: 6.0638e-04\n",
      "Epoch 474/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.5850e-04 - val_loss: 7.5825e-04\n",
      "Epoch 475/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.8686e-04 - val_loss: 8.4217e-04\n",
      "Epoch 476/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 6.4862e-04 - val_loss: 6.5740e-04\n",
      "Epoch 477/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 6.2359e-04 - val_loss: 6.4293e-04\n",
      "Epoch 478/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.4502e-04 - val_loss: 6.6578e-04\n",
      "Epoch 479/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 5.6528e-04 - val_loss: 6.1036e-04\n",
      "Epoch 480/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.2489e-04 - val_loss: 6.4635e-04\n",
      "Epoch 481/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.5418e-04 - val_loss: 6.7689e-04\n",
      "Epoch 482/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.3203e-04 - val_loss: 6.2661e-04\n",
      "Epoch 483/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.3122e-04 - val_loss: 6.8868e-04\n",
      "Epoch 484/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.4087e-04 - val_loss: 6.2756e-04\n",
      "Epoch 485/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.1673e-04 - val_loss: 6.7045e-04\n",
      "Epoch 486/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 5.5847e-04 - val_loss: 6.6987e-04\n",
      "Epoch 487/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.4214e-04 - val_loss: 6.6530e-04\n",
      "Epoch 488/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.5338e-04 - val_loss: 6.3478e-04\n",
      "Epoch 489/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 5.2755e-04 - val_loss: 8.0160e-04\n",
      "Epoch 490/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.6030e-04 - val_loss: 6.6643e-04\n",
      "Epoch 491/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.5737e-04 - val_loss: 6.3643e-04\n",
      "Epoch 492/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.2203e-04 - val_loss: 6.1657e-04\n",
      "Epoch 493/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.8949e-04 - val_loss: 6.6786e-04\n",
      "Epoch 494/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.9550e-04 - val_loss: 6.4164e-04\n",
      "Epoch 495/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.4491e-04 - val_loss: 6.9187e-04\n",
      "Epoch 496/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.5305e-04 - val_loss: 6.6060e-04\n",
      "Epoch 497/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.6481e-04 - val_loss: 0.0011\n",
      "Epoch 498/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 6.4314e-04 - val_loss: 7.6877e-04\n",
      "Epoch 499/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.5713e-04 - val_loss: 6.7422e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.4711e-04 - val_loss: 6.5901e-04\n",
      "Epoch 501/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.1329e-04 - val_loss: 6.6122e-04\n",
      "Epoch 502/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 5.2023e-04 - val_loss: 6.3987e-04\n",
      "Epoch 503/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.0495e-04 - val_loss: 6.3587e-04\n",
      "Epoch 504/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.1116e-04 - val_loss: 6.2812e-04\n",
      "Epoch 505/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.0972e-04 - val_loss: 6.6579e-04\n",
      "Epoch 506/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.3111e-04 - val_loss: 7.0671e-04\n",
      "Epoch 507/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 5.3452e-04 - val_loss: 6.5351e-04\n",
      "Epoch 508/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.3191e-04 - val_loss: 6.1155e-04\n",
      "Epoch 509/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.2212e-04 - val_loss: 6.3521e-04\n",
      "Epoch 510/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.3362e-04 - val_loss: 7.0559e-04\n",
      "Epoch 511/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.3886e-04 - val_loss: 7.7053e-04\n",
      "Epoch 512/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.5525e-04 - val_loss: 6.5760e-04\n",
      "Epoch 513/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.3075e-04 - val_loss: 6.1623e-04\n",
      "Epoch 514/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 5.1037e-04 - val_loss: 6.3533e-04\n",
      "Epoch 515/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.0969e-04 - val_loss: 6.3405e-04\n",
      "Epoch 516/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.0663e-04 - val_loss: 6.4646e-04\n",
      "Epoch 517/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.4404e-04 - val_loss: 6.7604e-04\n",
      "Epoch 518/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.4764e-04 - val_loss: 6.6810e-04\n",
      "Epoch 519/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.5455e-04 - val_loss: 6.2219e-04\n",
      "Epoch 520/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 5.1120e-04 - val_loss: 7.0040e-04\n",
      "Epoch 521/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.6041e-04 - val_loss: 7.2687e-04\n",
      "Epoch 522/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 5.1608e-04 - val_loss: 6.6598e-04\n",
      "Epoch 523/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 5.1495e-04 - val_loss: 6.5085e-04\n",
      "Epoch 524/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.2258e-04 - val_loss: 7.1903e-04\n",
      "Epoch 525/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.6235e-04 - val_loss: 6.5355e-04\n",
      "Epoch 526/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.8587e-04 - val_loss: 9.5385e-04\n",
      "Epoch 527/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 5.7493e-04 - val_loss: 6.6302e-04\n",
      "Epoch 528/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 5.3430e-04 - val_loss: 7.5130e-04\n",
      "Epoch 529/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.4342e-04 - val_loss: 7.7234e-04\n",
      "Epoch 530/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.2595e-04 - val_loss: 6.6982e-04\n",
      "Epoch 531/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 5.2577e-04 - val_loss: 6.5933e-04\n",
      "Epoch 532/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.2259e-04 - val_loss: 6.6909e-04\n",
      "Epoch 533/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 5.1349e-04 - val_loss: 6.9288e-04\n",
      "Epoch 534/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 5.2283e-04 - val_loss: 6.4707e-04\n",
      "Epoch 535/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 5.3007e-04 - val_loss: 6.7793e-04\n",
      "Epoch 536/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.1169e-04 - val_loss: 7.2384e-04\n",
      "Epoch 537/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.2540e-04 - val_loss: 6.6282e-04\n",
      "Epoch 538/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 5.2041e-04 - val_loss: 7.4282e-04\n",
      "Epoch 539/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.7112e-04 - val_loss: 7.0594e-04\n",
      "Epoch 540/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.2334e-04 - val_loss: 6.6376e-04\n",
      "Epoch 541/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 5.2486e-04 - val_loss: 8.2091e-04\n",
      "Epoch 542/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.5385e-04 - val_loss: 8.1981e-04\n",
      "Epoch 543/2000\n",
      "3811/3811 [==============================] - 2s 605us/step - loss: 5.3452e-04 - val_loss: 6.7970e-04\n",
      "Epoch 544/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.2916e-04 - val_loss: 6.8150e-04\n",
      "Epoch 545/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.6118e-04 - val_loss: 6.9579e-04\n",
      "Epoch 546/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.5151e-04 - val_loss: 8.1404e-04\n",
      "Epoch 547/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 5.6679e-04 - val_loss: 7.0755e-04\n",
      "Epoch 548/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 5.3432e-04 - val_loss: 7.1004e-04\n",
      "Epoch 549/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.3122e-04 - val_loss: 7.1679e-04\n",
      "Epoch 550/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.4139e-04 - val_loss: 6.3907e-04\n",
      "Epoch 551/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.6344e-04 - val_loss: 6.9159e-04\n",
      "Epoch 552/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.3809e-04 - val_loss: 7.7347e-04\n",
      "Epoch 553/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 5.2716e-04 - val_loss: 7.2505e-04\n",
      "Epoch 554/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.1251e-04 - val_loss: 6.1960e-04\n",
      "Epoch 555/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.0414e-04 - val_loss: 6.4204e-04\n",
      "Epoch 556/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 5.1083e-04 - val_loss: 6.3916e-04\n",
      "Epoch 557/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.0503e-04 - val_loss: 6.6841e-04\n",
      "Epoch 558/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 4.9231e-04 - val_loss: 6.5918e-04\n",
      "Epoch 559/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 4.8952e-04 - val_loss: 6.6108e-04\n",
      "Epoch 560/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 4.9153e-04 - val_loss: 7.3581e-04\n",
      "Epoch 561/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.2893e-04 - val_loss: 6.7230e-04\n",
      "Epoch 562/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 5.0154e-04 - val_loss: 6.5379e-04\n",
      "Epoch 563/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 4.9715e-04 - val_loss: 7.1970e-04\n",
      "Epoch 564/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.1726e-04 - val_loss: 7.3497e-04\n",
      "Epoch 565/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 4.8929e-04 - val_loss: 6.7448e-04\n",
      "Epoch 566/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 5.1683e-04 - val_loss: 7.7009e-04\n",
      "Epoch 567/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 5.1110e-04 - val_loss: 6.6551e-04\n",
      "Epoch 568/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 5.0991e-04 - val_loss: 6.8605e-04\n",
      "Epoch 569/2000\n",
      "3811/3811 [==============================] - 3s 666us/step - loss: 4.9191e-04 - val_loss: 7.3910e-04\n",
      "Epoch 570/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 627us/step - loss: 4.9401e-04 - val_loss: 6.9703e-04\n",
      "Epoch 571/2000\n",
      "3811/3811 [==============================] - 3s 671us/step - loss: 4.8740e-04 - val_loss: 7.4981e-04\n",
      "Epoch 572/2000\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 5.0147e-04 - val_loss: 7.0302e-04\n",
      "Epoch 573/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 4.9867e-04 - val_loss: 7.2374e-04\n",
      "Epoch 574/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 4.8383e-04 - val_loss: 7.4074e-04\n",
      "Epoch 575/2000\n",
      "3811/3811 [==============================] - 3s 667us/step - loss: 4.9432e-04 - val_loss: 7.2539e-04\n",
      "Epoch 576/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 5.2675e-04 - val_loss: 7.3326e-04\n",
      "Epoch 577/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 5.2873e-04 - val_loss: 7.2808e-04\n",
      "Epoch 578/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 4.9957e-04 - val_loss: 7.2534e-04\n",
      "Epoch 579/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 4.7994e-04 - val_loss: 7.2734e-04\n",
      "Epoch 580/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 4.9677e-04 - val_loss: 7.7659e-04\n",
      "Epoch 581/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 4.9417e-04 - val_loss: 8.9156e-04\n",
      "Epoch 582/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 5.1955e-04 - val_loss: 7.6461e-04\n",
      "Epoch 583/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 4.9226e-04 - val_loss: 7.4709e-04\n",
      "Epoch 584/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 4.8639e-04 - val_loss: 8.8869e-04\n",
      "Epoch 585/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 5.0938e-04 - val_loss: 7.9771e-04\n",
      "Epoch 586/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 4.9832e-04 - val_loss: 7.7179e-04\n",
      "Epoch 587/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 4.7248e-04 - val_loss: 8.5989e-04\n",
      "Epoch 588/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 4.6539e-04 - val_loss: 7.6907e-04\n",
      "Epoch 589/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 4.6758e-04 - val_loss: 8.9308e-04\n",
      "Epoch 590/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 4.9130e-04 - val_loss: 7.9058e-04\n",
      "Epoch 591/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 4.5703e-04 - val_loss: 8.5631e-04\n",
      "Epoch 592/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 4.5727e-04 - val_loss: 8.1958e-04\n",
      "Epoch 593/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 4.6824e-04 - val_loss: 8.4501e-04\n",
      "Epoch 594/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 4.7896e-04 - val_loss: 8.2993e-04\n",
      "Epoch 595/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 4.8236e-04 - val_loss: 8.7601e-04\n",
      "Epoch 596/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 4.7902e-04 - val_loss: 8.2556e-04\n",
      "Epoch 597/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 5.0954e-04 - val_loss: 8.2046e-04\n",
      "Epoch 598/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 5.0720e-04 - val_loss: 8.3085e-04\n",
      "Epoch 599/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 5.1493e-04 - val_loss: 9.2969e-04\n",
      "Epoch 600/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 5.0858e-04 - val_loss: 8.2241e-04\n",
      "Epoch 601/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 4.6167e-04 - val_loss: 7.9775e-04\n",
      "Epoch 602/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 4.6999e-04 - val_loss: 8.2713e-04\n",
      "Epoch 603/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 4.7673e-04 - val_loss: 9.3761e-04\n",
      "Epoch 604/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 4.8015e-04 - val_loss: 8.6320e-04\n",
      "Epoch 605/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 4.5650e-04 - val_loss: 8.2259e-04\n",
      "Epoch 606/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 4.7468e-04 - val_loss: 0.0010\n",
      "Epoch 607/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 4.7001e-04 - val_loss: 8.5087e-04\n",
      "Epoch 608/2000\n",
      "3811/3811 [==============================] - 3s 667us/step - loss: 4.5179e-04 - val_loss: 8.9311e-04\n",
      "Epoch 609/2000\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 4.5611e-04 - val_loss: 8.9210e-04\n",
      "Epoch 610/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 4.7177e-04 - val_loss: 9.1350e-04\n",
      "Epoch 611/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 4.5766e-04 - val_loss: 9.5931e-04\n",
      "Epoch 612/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 4.4484e-04 - val_loss: 9.9091e-04\n",
      "Epoch 613/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 4.4816e-04 - val_loss: 9.4806e-04\n",
      "Epoch 614/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 4.7846e-04 - val_loss: 9.7741e-04\n",
      "Epoch 615/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 4.5814e-04 - val_loss: 0.0010\n",
      "Epoch 616/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 4.4820e-04 - val_loss: 0.0010\n",
      "Epoch 617/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 4.9750e-04 - val_loss: 9.6751e-04\n",
      "Epoch 618/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 4.6829e-04 - val_loss: 0.0011\n",
      "Epoch 619/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 4.8423e-04 - val_loss: 9.0080e-04\n",
      "Epoch 620/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 4.9437e-04 - val_loss: 0.0010\n",
      "Epoch 621/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 4.9346e-04 - val_loss: 9.6743e-04\n",
      "Epoch 622/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 5.0002e-04 - val_loss: 9.1709e-04\n",
      "Epoch 623/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 4.5835e-04 - val_loss: 9.6382e-04\n",
      "Epoch 624/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 4.8710e-04 - val_loss: 9.2841e-04\n",
      "Epoch 625/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 5.0824e-04 - val_loss: 9.7321e-04\n",
      "Epoch 626/2000\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 4.7042e-04 - val_loss: 9.1909e-04\n",
      "Epoch 627/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 4.9295e-04 - val_loss: 9.7740e-04\n",
      "Epoch 628/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 4.6107e-04 - val_loss: 9.5503e-04\n",
      "Epoch 629/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 4.7267e-04 - val_loss: 0.0011\n",
      "Epoch 630/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 4.7821e-04 - val_loss: 0.0010\n",
      "Epoch 631/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 4.8470e-04 - val_loss: 0.0014\n",
      "Epoch 632/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 4.9523e-04 - val_loss: 0.0011\n",
      "Epoch 633/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 4.7433e-04 - val_loss: 0.0010\n",
      "Epoch 634/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 4.6225e-04 - val_loss: 9.4038e-04\n",
      "Epoch 635/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 4.5744e-04 - val_loss: 0.0011\n",
      "Epoch 636/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 4.5988e-04 - val_loss: 9.5172e-04\n",
      "Epoch 637/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 4.4675e-04 - val_loss: 0.0011\n",
      "Epoch 638/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 4.5034e-04 - val_loss: 9.9187e-04\n",
      "Epoch 639/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 4.5054e-04 - val_loss: 0.0012\n",
      "Epoch 640/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 4.4321e-04 - val_loss: 0.0012\n",
      "Epoch 641/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 616us/step - loss: 4.6328e-04 - val_loss: 0.0012\n",
      "Epoch 642/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 4.6196e-04 - val_loss: 0.0011\n",
      "Epoch 643/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 4.8589e-04 - val_loss: 0.0012\n",
      "Epoch 644/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 4.6567e-04 - val_loss: 0.0012\n",
      "Epoch 645/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 4.5353e-04 - val_loss: 0.0014\n",
      "Epoch 646/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 4.2860e-04 - val_loss: 0.0013\n",
      "Epoch 647/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 4.2801e-04 - val_loss: 0.0013\n",
      "Epoch 648/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 4.2606e-04 - val_loss: 0.0012\n",
      "Epoch 649/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 4.2488e-04 - val_loss: 0.0012\n",
      "Epoch 650/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 4.1619e-04 - val_loss: 0.0013\n",
      "Epoch 651/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 4.4928e-04 - val_loss: 0.0013\n",
      "Epoch 652/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 4.2851e-04 - val_loss: 0.0012\n",
      "Epoch 653/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 4.2202e-04 - val_loss: 0.0014\n",
      "Epoch 654/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 4.2685e-04 - val_loss: 0.0014\n",
      "Epoch 655/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 4.3277e-04 - val_loss: 0.0013\n",
      "Epoch 656/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 4.1507e-04 - val_loss: 0.0013\n",
      "Epoch 657/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 4.1714e-04 - val_loss: 0.0013\n",
      "Epoch 658/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 4.1954e-04 - val_loss: 0.0014\n",
      "Epoch 659/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 4.2764e-04 - val_loss: 0.0012\n",
      "Epoch 660/2000\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 4.2402e-04 - val_loss: 0.0014\n",
      "Epoch 661/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 4.2423e-04 - val_loss: 0.0013\n",
      "Epoch 662/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 4.3643e-04 - val_loss: 0.0014\n",
      "Epoch 663/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 4.6146e-04 - val_loss: 0.0014\n",
      "Epoch 664/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 4.3273e-04 - val_loss: 0.0015\n",
      "Epoch 665/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 4.2484e-04 - val_loss: 0.0014\n",
      "Epoch 666/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 4.2482e-04 - val_loss: 0.0014\n",
      "Epoch 667/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 4.3282e-04 - val_loss: 0.0018\n",
      "Epoch 668/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 4.5694e-04 - val_loss: 0.0013\n",
      "Epoch 669/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 4.5045e-04 - val_loss: 0.0013\n",
      "Epoch 670/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 4.3765e-04 - val_loss: 0.0012\n",
      "Epoch 671/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 4.5195e-04 - val_loss: 0.0015\n",
      "Epoch 672/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 4.4762e-04 - val_loss: 0.0013\n",
      "Epoch 673/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 4.2927e-04 - val_loss: 0.0018\n",
      "Epoch 674/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 4.3518e-04 - val_loss: 0.0014\n",
      "Epoch 675/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 4.0849e-04 - val_loss: 0.0016\n",
      "Epoch 676/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 4.2694e-04 - val_loss: 0.0018\n",
      "Epoch 677/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 4.6443e-04 - val_loss: 0.0014\n",
      "Epoch 678/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 4.4560e-04 - val_loss: 0.0015\n",
      "Epoch 679/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 4.3009e-04 - val_loss: 0.0015\n",
      "Epoch 680/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 4.1917e-04 - val_loss: 0.0015\n",
      "Epoch 681/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 4.2284e-04 - val_loss: 0.0015\n",
      "Epoch 682/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 4.0181e-04 - val_loss: 0.0016\n",
      "Epoch 683/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 4.2584e-04 - val_loss: 0.0017\n",
      "Epoch 684/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 4.1954e-04 - val_loss: 0.0018\n",
      "Epoch 685/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 3.8611e-04 - val_loss: 0.0017\n",
      "Epoch 686/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 4.1617e-04 - val_loss: 0.0021\n",
      "Epoch 687/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 3.9994e-04 - val_loss: 0.0017\n",
      "Epoch 688/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 4.1516e-04 - val_loss: 0.0020\n",
      "Epoch 689/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 4.3636e-04 - val_loss: 0.0017\n",
      "Epoch 690/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 3.9628e-04 - val_loss: 0.0019\n",
      "Epoch 691/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 4.0799e-04 - val_loss: 0.0018\n",
      "Epoch 692/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 3.9549e-04 - val_loss: 0.0019\n",
      "Epoch 693/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 3.9676e-04 - val_loss: 0.0018\n",
      "Epoch 694/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 4.0653e-04 - val_loss: 0.0020\n",
      "Epoch 695/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 3.9166e-04 - val_loss: 0.0019\n",
      "Epoch 696/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 4.0108e-04 - val_loss: 0.0019\n",
      "Epoch 697/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 3.9142e-04 - val_loss: 0.0017\n",
      "Epoch 698/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 4.1548e-04 - val_loss: 0.0027\n",
      "Epoch 699/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 3.8898e-04 - val_loss: 0.0019\n",
      "Epoch 700/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 3.9891e-04 - val_loss: 0.0020\n",
      "Epoch 701/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 3.8795e-04 - val_loss: 0.0020\n",
      "Epoch 702/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 4.1423e-04 - val_loss: 0.0030\n",
      "Epoch 703/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 5.2060e-04 - val_loss: 0.0020\n",
      "Epoch 704/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 4.4781e-04 - val_loss: 0.0020\n",
      "Epoch 705/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 4.0319e-04 - val_loss: 0.0020\n",
      "Epoch 706/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 4.0885e-04 - val_loss: 0.0018\n",
      "Epoch 707/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 4.1030e-04 - val_loss: 0.0023\n",
      "Epoch 708/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 4.0277e-04 - val_loss: 0.0020\n",
      "Epoch 709/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 3.8981e-04 - val_loss: 0.0026\n",
      "Epoch 710/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 4.1436e-04 - val_loss: 0.0021\n",
      "Epoch 711/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 4.1826e-04 - val_loss: 0.0021\n",
      "Epoch 712/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 3.9154e-04 - val_loss: 0.0023\n",
      "Epoch 713/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 4.0011e-04 - val_loss: 0.0029\n",
      "Epoch 714/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 645us/step - loss: 3.9831e-04 - val_loss: 0.0023\n",
      "Epoch 715/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 3.7971e-04 - val_loss: 0.0023\n",
      "Epoch 716/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 3.7757e-04 - val_loss: 0.0023\n",
      "Epoch 717/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 3.7051e-04 - val_loss: 0.0030\n",
      "Epoch 718/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 3.6474e-04 - val_loss: 0.0030\n",
      "Epoch 719/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 3.7398e-04 - val_loss: 0.0022\n",
      "Epoch 720/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 3.4412e-04 - val_loss: 0.0029\n",
      "Epoch 721/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 3.6530e-04 - val_loss: 0.0023\n",
      "Epoch 722/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 3.6860e-04 - val_loss: 0.0026\n",
      "Epoch 723/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 3.6156e-04 - val_loss: 0.0026\n",
      "Epoch 724/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 3.5669e-04 - val_loss: 0.0029\n",
      "Epoch 725/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 3.6563e-04 - val_loss: 0.0025\n",
      "Epoch 726/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 3.7567e-04 - val_loss: 0.0023\n",
      "Epoch 727/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 4.0011e-04 - val_loss: 0.0028\n",
      "Epoch 728/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 3.9944e-04 - val_loss: 0.0023\n",
      "Epoch 729/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 4.0750e-04 - val_loss: 0.0021\n",
      "Epoch 730/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 3.9614e-04 - val_loss: 0.0020\n",
      "Epoch 731/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 3.8427e-04 - val_loss: 0.0022\n",
      "Epoch 732/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 3.5283e-04 - val_loss: 0.0022\n",
      "Epoch 733/2000\n",
      "3811/3811 [==============================] - 3s 657us/step - loss: 3.7591e-04 - val_loss: 0.0026\n",
      "Epoch 734/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 3.5424e-04 - val_loss: 0.0026\n",
      "Epoch 735/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 3.6033e-04 - val_loss: 0.0024\n",
      "Epoch 736/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 3.5583e-04 - val_loss: 0.0026\n",
      "Epoch 737/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 3.4339e-04 - val_loss: 0.0024\n",
      "Epoch 738/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 3.4425e-04 - val_loss: 0.0030\n",
      "Epoch 739/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 3.5074e-04 - val_loss: 0.0026\n",
      "Epoch 740/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 3.5420e-04 - val_loss: 0.0028\n",
      "Epoch 741/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 3.5661e-04 - val_loss: 0.0031\n",
      "Epoch 742/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 3.7057e-04 - val_loss: 0.0024\n",
      "Epoch 743/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 3.7686e-04 - val_loss: 0.0025\n",
      "Epoch 744/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 3.6472e-04 - val_loss: 0.0032\n",
      "Epoch 745/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 3.5194e-04 - val_loss: 0.0033\n",
      "Epoch 746/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 3.4830e-04 - val_loss: 0.0029\n",
      "Epoch 747/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 3.3630e-04 - val_loss: 0.0035\n",
      "Epoch 748/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 3.2966e-04 - val_loss: 0.0028\n",
      "Epoch 749/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 3.3882e-04 - val_loss: 0.0043\n",
      "Epoch 750/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 3.5273e-04 - val_loss: 0.0030\n",
      "Epoch 751/2000\n",
      "3811/3811 [==============================] - 3s 657us/step - loss: 3.3730e-04 - val_loss: 0.0031\n",
      "Epoch 752/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 3.2596e-04 - val_loss: 0.0033\n",
      "Epoch 753/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 3.3359e-04 - val_loss: 0.0028\n",
      "Epoch 754/2000\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 3.4021e-04 - val_loss: 0.0029\n",
      "Epoch 755/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 3.3752e-04 - val_loss: 0.0031\n",
      "Epoch 756/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 3.3990e-04 - val_loss: 0.0030\n",
      "Epoch 757/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 3.6337e-04 - val_loss: 0.0038\n",
      "Epoch 758/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 3.4059e-04 - val_loss: 0.0034\n",
      "Epoch 759/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 3.3796e-04 - val_loss: 0.0031\n",
      "Epoch 760/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 3.4250e-04 - val_loss: 0.0032\n",
      "Epoch 761/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 3.7919e-04 - val_loss: 0.0036\n",
      "Epoch 762/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 3.5908e-04 - val_loss: 0.0040\n",
      "Epoch 763/2000\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 3.4422e-04 - val_loss: 0.0036\n",
      "Epoch 764/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 3.2443e-04 - val_loss: 0.0040\n",
      "Epoch 765/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 3.1564e-04 - val_loss: 0.0044\n",
      "Epoch 766/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 3.3291e-04 - val_loss: 0.0041\n",
      "Epoch 767/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 3.3184e-04 - val_loss: 0.0039\n",
      "Epoch 768/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 3.4606e-04 - val_loss: 0.0035\n",
      "Epoch 769/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 3.6813e-04 - val_loss: 0.0033\n",
      "Epoch 770/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 3.3992e-04 - val_loss: 0.0030\n",
      "Epoch 771/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 3.3515e-04 - val_loss: 0.0039\n",
      "Epoch 772/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 3.2622e-04 - val_loss: 0.0035\n",
      "Epoch 773/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 3.2684e-04 - val_loss: 0.0035\n",
      "Epoch 774/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 3.1409e-04 - val_loss: 0.0030\n",
      "Epoch 775/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 3.1339e-04 - val_loss: 0.0046\n",
      "Epoch 776/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 3.1070e-04 - val_loss: 0.0040\n",
      "Epoch 777/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 3.0828e-04 - val_loss: 0.0031\n",
      "Epoch 778/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 3.0321e-04 - val_loss: 0.0036\n",
      "Epoch 779/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 3.3381e-04 - val_loss: 0.0044\n",
      "Epoch 780/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 3.4908e-04 - val_loss: 0.0039\n",
      "Epoch 781/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 3.4489e-04 - val_loss: 0.0036\n",
      "Epoch 782/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 3.1987e-04 - val_loss: 0.0033\n",
      "Epoch 783/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 3.1161e-04 - val_loss: 0.0036\n",
      "Epoch 784/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 3.2153e-04 - val_loss: 0.0043\n",
      "Epoch 785/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 3.1916e-04 - val_loss: 0.0045\n",
      "Epoch 786/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 3.1958e-04 - val_loss: 0.0039\n",
      "Epoch 787/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 651us/step - loss: 2.9692e-04 - val_loss: 0.0046\n",
      "Epoch 788/2000\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 3.2901e-04 - val_loss: 0.0033\n",
      "Epoch 789/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 3.2587e-04 - val_loss: 0.0038\n",
      "Epoch 790/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 3.2794e-04 - val_loss: 0.0040\n",
      "Epoch 791/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 3.2098e-04 - val_loss: 0.0037\n",
      "Epoch 792/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 2.9262e-04 - val_loss: 0.0044\n",
      "Epoch 793/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 3.0430e-04 - val_loss: 0.0054\n",
      "Epoch 794/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 3.1127e-04 - val_loss: 0.0039\n",
      "Epoch 795/2000\n",
      "3811/3811 [==============================] - 2s 606us/step - loss: 3.0609e-04 - val_loss: 0.0044\n",
      "Epoch 796/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 3.1090e-04 - val_loss: 0.0032\n",
      "Epoch 797/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 3.2352e-04 - val_loss: 0.0031\n",
      "Epoch 798/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 3.0911e-04 - val_loss: 0.0040\n",
      "Epoch 799/2000\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 2.8988e-04 - val_loss: 0.0049\n",
      "Epoch 800/2000\n",
      "3811/3811 [==============================] - 3s 661us/step - loss: 2.9418e-04 - val_loss: 0.0044\n",
      "Epoch 801/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 2.8899e-04 - val_loss: 0.0042\n",
      "Epoch 802/2000\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 2.8378e-04 - val_loss: 0.0035\n",
      "Epoch 803/2000\n",
      "3811/3811 [==============================] - 2s 656us/step - loss: 2.8821e-04 - val_loss: 0.0038\n",
      "Epoch 804/2000\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 2.9741e-04 - val_loss: 0.0037\n",
      "Epoch 805/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 2.9108e-04 - val_loss: 0.0044\n",
      "Epoch 806/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 2.8707e-04 - val_loss: 0.0037\n",
      "Epoch 807/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 3.0196e-04 - val_loss: 0.0040\n",
      "Epoch 808/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 2.9035e-04 - val_loss: 0.0038\n",
      "Epoch 809/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 3.0302e-04 - val_loss: 0.0053\n",
      "Epoch 810/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 2.8807e-04 - val_loss: 0.0040\n",
      "Epoch 811/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 3.0915e-04 - val_loss: 0.0041\n",
      "Epoch 812/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 3.2671e-04 - val_loss: 0.0042\n",
      "Epoch 813/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 3.1214e-04 - val_loss: 0.0038\n",
      "Epoch 814/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 3.2508e-04 - val_loss: 0.0044\n",
      "Epoch 815/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 3.1463e-04 - val_loss: 0.0046\n",
      "Epoch 816/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 3.0637e-04 - val_loss: 0.0037\n",
      "Epoch 817/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 2.9999e-04 - val_loss: 0.0041\n",
      "Epoch 818/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 3.2088e-04 - val_loss: 0.0034\n",
      "Epoch 819/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 3.0362e-04 - val_loss: 0.0043\n",
      "Epoch 820/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 2.8174e-04 - val_loss: 0.0049\n",
      "Epoch 821/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 2.7616e-04 - val_loss: 0.0047\n",
      "Epoch 822/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 2.7397e-04 - val_loss: 0.0049\n",
      "Epoch 823/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.7406e-04 - val_loss: 0.0043\n",
      "Epoch 824/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 2.7634e-04 - val_loss: 0.0046\n",
      "Epoch 825/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 2.8813e-04 - val_loss: 0.0049\n",
      "Epoch 826/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.9682e-04 - val_loss: 0.0047\n",
      "Epoch 827/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 3.0097e-04 - val_loss: 0.0052\n",
      "Epoch 828/2000\n",
      "3811/3811 [==============================] - 3s 670us/step - loss: 3.0324e-04 - val_loss: 0.0048\n",
      "Epoch 829/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 3.0638e-04 - val_loss: 0.0038\n",
      "Epoch 830/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 2.8694e-04 - val_loss: 0.0046\n",
      "Epoch 831/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 2.6536e-04 - val_loss: 0.0038\n",
      "Epoch 832/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.7350e-04 - val_loss: 0.0048\n",
      "Epoch 833/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 2.8791e-04 - val_loss: 0.0039\n",
      "Epoch 834/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.7756e-04 - val_loss: 0.0039\n",
      "Epoch 835/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 2.8328e-04 - val_loss: 0.0045\n",
      "Epoch 836/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 2.9394e-04 - val_loss: 0.0038\n",
      "Epoch 837/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 2.7247e-04 - val_loss: 0.0038\n",
      "Epoch 838/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 2.7642e-04 - val_loss: 0.0046\n",
      "Epoch 839/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 2.8515e-04 - val_loss: 0.0046\n",
      "Epoch 840/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 2.8927e-04 - val_loss: 0.0056\n",
      "Epoch 841/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 3.2676e-04 - val_loss: 0.0049\n",
      "Epoch 842/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 3.0533e-04 - val_loss: 0.0043\n",
      "Epoch 843/2000\n",
      "3811/3811 [==============================] - 3s 666us/step - loss: 2.9039e-04 - val_loss: 0.0042\n",
      "Epoch 844/2000\n",
      "3811/3811 [==============================] - 3s 662us/step - loss: 2.7664e-04 - val_loss: 0.0049\n",
      "Epoch 845/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 2.8167e-04 - val_loss: 0.0054\n",
      "Epoch 846/2000\n",
      "3811/3811 [==============================] - 3s 662us/step - loss: 2.7265e-04 - val_loss: 0.0043\n",
      "Epoch 847/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 2.6962e-04 - val_loss: 0.0057\n",
      "Epoch 848/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 2.7114e-04 - val_loss: 0.0039\n",
      "Epoch 849/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 2.6212e-04 - val_loss: 0.0040\n",
      "Epoch 850/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 2.6265e-04 - val_loss: 0.0046\n",
      "Epoch 851/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 2.5818e-04 - val_loss: 0.0050\n",
      "Epoch 852/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 2.7220e-04 - val_loss: 0.0052\n",
      "Epoch 853/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.6028e-04 - val_loss: 0.0048\n",
      "Epoch 854/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 2.6119e-04 - val_loss: 0.0045\n",
      "Epoch 855/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 2.7063e-04 - val_loss: 0.0045\n",
      "Epoch 856/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 2.6115e-04 - val_loss: 0.0056\n",
      "Epoch 857/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 2.5714e-04 - val_loss: 0.0057\n",
      "Epoch 858/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.6333e-04 - val_loss: 0.0055\n",
      "Epoch 859/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 2.5640e-04 - val_loss: 0.0049\n",
      "Epoch 860/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 621us/step - loss: 2.6142e-04 - val_loss: 0.0043\n",
      "Epoch 861/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 2.5432e-04 - val_loss: 0.0047\n",
      "Epoch 862/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 2.5989e-04 - val_loss: 0.0045\n",
      "Epoch 863/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 2.7726e-04 - val_loss: 0.0048\n",
      "Epoch 864/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 2.7563e-04 - val_loss: 0.0040\n",
      "Epoch 865/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.7882e-04 - val_loss: 0.0051\n",
      "Epoch 866/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.7257e-04 - val_loss: 0.0051\n",
      "Epoch 867/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 2.8255e-04 - val_loss: 0.0053\n",
      "Epoch 868/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 2.8931e-04 - val_loss: 0.0048\n",
      "Epoch 869/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 2.4995e-04 - val_loss: 0.0056\n",
      "Epoch 870/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 2.6392e-04 - val_loss: 0.0048\n",
      "Epoch 871/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 2.7183e-04 - val_loss: 0.0059\n",
      "Epoch 872/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 2.6415e-04 - val_loss: 0.0043\n",
      "Epoch 873/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.7658e-04 - val_loss: 0.0063\n",
      "Epoch 874/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 2.6807e-04 - val_loss: 0.0046\n",
      "Epoch 875/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 2.7341e-04 - val_loss: 0.0065\n",
      "Epoch 876/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 2.5514e-04 - val_loss: 0.0046\n",
      "Epoch 877/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 2.4846e-04 - val_loss: 0.0046\n",
      "Epoch 878/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 2.4546e-04 - val_loss: 0.0044\n",
      "Epoch 879/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.5249e-04 - val_loss: 0.0054\n",
      "Epoch 880/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 2.5723e-04 - val_loss: 0.0051\n",
      "Epoch 881/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 2.6349e-04 - val_loss: 0.0058\n",
      "Epoch 882/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 2.6938e-04 - val_loss: 0.0052\n",
      "Epoch 883/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 2.7082e-04 - val_loss: 0.0043\n",
      "Epoch 884/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 2.6274e-04 - val_loss: 0.0050\n",
      "Epoch 885/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 2.6579e-04 - val_loss: 0.0045\n",
      "Epoch 886/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.5808e-04 - val_loss: 0.0045\n",
      "Epoch 887/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 2.6950e-04 - val_loss: 0.0054\n",
      "Epoch 888/2000\n",
      "3811/3811 [==============================] - 3s 675us/step - loss: 2.7159e-04 - val_loss: 0.0047\n",
      "Epoch 889/2000\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 2.6537e-04 - val_loss: 0.0053\n",
      "Epoch 890/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.6499e-04 - val_loss: 0.0055\n",
      "Epoch 891/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.6587e-04 - val_loss: 0.0049\n",
      "Epoch 892/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.7367e-04 - val_loss: 0.0040\n",
      "Epoch 893/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 2.3845e-04 - val_loss: 0.0045\n",
      "Epoch 894/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 2.4906e-04 - val_loss: 0.0050\n",
      "Epoch 895/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 2.3739e-04 - val_loss: 0.0050\n",
      "Epoch 896/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.4520e-04 - val_loss: 0.0058\n",
      "Epoch 897/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.4119e-04 - val_loss: 0.0052\n",
      "Epoch 898/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 2.3041e-04 - val_loss: 0.0049\n",
      "Epoch 899/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 2.3815e-04 - val_loss: 0.0054\n",
      "Epoch 900/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 2.4771e-04 - val_loss: 0.0054\n",
      "Epoch 901/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.5756e-04 - val_loss: 0.0062\n",
      "Epoch 902/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 2.4084e-04 - val_loss: 0.0054\n",
      "Epoch 903/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 2.5329e-04 - val_loss: 0.0054\n",
      "Epoch 904/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.5653e-04 - val_loss: 0.0042\n",
      "Epoch 905/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 2.4048e-04 - val_loss: 0.0047\n",
      "Epoch 906/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 2.5044e-04 - val_loss: 0.0052\n",
      "Epoch 907/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.4640e-04 - val_loss: 0.0067\n",
      "Epoch 908/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 2.6118e-04 - val_loss: 0.0053\n",
      "Epoch 909/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.3969e-04 - val_loss: 0.0061\n",
      "Epoch 910/2000\n",
      "3811/3811 [==============================] - 3s 669us/step - loss: 2.5040e-04 - val_loss: 0.0055\n",
      "Epoch 911/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 2.4603e-04 - val_loss: 0.0051\n",
      "Epoch 912/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 2.3275e-04 - val_loss: 0.0048\n",
      "Epoch 913/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 2.2386e-04 - val_loss: 0.0048\n",
      "Epoch 914/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 2.3350e-04 - val_loss: 0.0058\n",
      "Epoch 915/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 2.1589e-04 - val_loss: 0.0053\n",
      "Epoch 916/2000\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 2.3500e-04 - val_loss: 0.0050\n",
      "Epoch 917/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 2.2466e-04 - val_loss: 0.0061\n",
      "Epoch 918/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 2.2657e-04 - val_loss: 0.0060\n",
      "Epoch 919/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 2.1432e-04 - val_loss: 0.0068\n",
      "Epoch 920/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 2.4110e-04 - val_loss: 0.0076\n",
      "Epoch 921/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 2.2385e-04 - val_loss: 0.0053\n",
      "Epoch 922/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 2.1846e-04 - val_loss: 0.0052\n",
      "Epoch 923/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 2.4031e-04 - val_loss: 0.0062\n",
      "Epoch 924/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.5459e-04 - val_loss: 0.0064\n",
      "Epoch 925/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 2.3085e-04 - val_loss: 0.0067\n",
      "Epoch 926/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 2.2089e-04 - val_loss: 0.0054\n",
      "Epoch 927/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 2.3317e-04 - val_loss: 0.0045\n",
      "Epoch 928/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 2.3698e-04 - val_loss: 0.0046\n",
      "Epoch 929/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 2.4447e-04 - val_loss: 0.0049\n",
      "Epoch 930/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 2.3342e-04 - val_loss: 0.0056\n",
      "Epoch 931/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 2.3840e-04 - val_loss: 0.0058\n",
      "Epoch 932/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 2.1901e-04 - val_loss: 0.0059\n",
      "Epoch 933/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 616us/step - loss: 2.1156e-04 - val_loss: 0.0053\n",
      "Epoch 934/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.1320e-04 - val_loss: 0.0054\n",
      "Epoch 935/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.1013e-04 - val_loss: 0.0052\n",
      "Epoch 936/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.1249e-04 - val_loss: 0.0051\n",
      "Epoch 937/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 2.2096e-04 - val_loss: 0.0076\n",
      "Epoch 938/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 2.5263e-04 - val_loss: 0.0063\n",
      "Epoch 939/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.4670e-04 - val_loss: 0.0052\n",
      "Epoch 940/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.3775e-04 - val_loss: 0.0052\n",
      "Epoch 941/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 2.1740e-04 - val_loss: 0.0062\n",
      "Epoch 942/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.0580e-04 - val_loss: 0.0066\n",
      "Epoch 943/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 2.0530e-04 - val_loss: 0.0060\n",
      "Epoch 944/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 2.1807e-04 - val_loss: 0.0051\n",
      "Epoch 945/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 2.1502e-04 - val_loss: 0.0065\n",
      "Epoch 946/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 2.0147e-04 - val_loss: 0.0074\n",
      "Epoch 947/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 2.1432e-04 - val_loss: 0.0069\n",
      "Epoch 948/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 2.0817e-04 - val_loss: 0.0050\n",
      "Epoch 949/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 2.0390e-04 - val_loss: 0.0052\n",
      "Epoch 950/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 2.1098e-04 - val_loss: 0.0064\n",
      "Epoch 951/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 2.1334e-04 - val_loss: 0.0058\n",
      "Epoch 952/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 2.0932e-04 - val_loss: 0.0051\n",
      "Epoch 953/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.0962e-04 - val_loss: 0.0061\n",
      "Epoch 954/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 2.1606e-04 - val_loss: 0.0044\n",
      "Epoch 955/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.1137e-04 - val_loss: 0.0057\n",
      "Epoch 956/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 2.0286e-04 - val_loss: 0.0052\n",
      "Epoch 957/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 2.1406e-04 - val_loss: 0.0050\n",
      "Epoch 958/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 2.0239e-04 - val_loss: 0.0057\n",
      "Epoch 959/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 2.0164e-04 - val_loss: 0.0063\n",
      "Epoch 960/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.2091e-04 - val_loss: 0.0051\n",
      "Epoch 961/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.2025e-04 - val_loss: 0.0059\n",
      "Epoch 962/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 2.3226e-04 - val_loss: 0.0053\n",
      "Epoch 963/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.1709e-04 - val_loss: 0.0066\n",
      "Epoch 964/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.9526e-04 - val_loss: 0.0049\n",
      "Epoch 965/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.0719e-04 - val_loss: 0.0047\n",
      "Epoch 966/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.9666e-04 - val_loss: 0.0058\n",
      "Epoch 967/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 2.1505e-04 - val_loss: 0.0062\n",
      "Epoch 968/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 2.1827e-04 - val_loss: 0.0070\n",
      "Epoch 969/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 2.1660e-04 - val_loss: 0.0082\n",
      "Epoch 970/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 1.9595e-04 - val_loss: 0.0062\n",
      "Epoch 971/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 2.0522e-04 - val_loss: 0.0080\n",
      "Epoch 972/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 1.9400e-04 - val_loss: 0.0083\n",
      "Epoch 973/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 2.1487e-04 - val_loss: 0.0063\n",
      "Epoch 974/2000\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 2.2462e-04 - val_loss: 0.0060\n",
      "Epoch 975/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 2.1138e-04 - val_loss: 0.0061\n",
      "Epoch 976/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 2.1292e-04 - val_loss: 0.0052\n",
      "Epoch 977/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 2.1506e-04 - val_loss: 0.0067\n",
      "Epoch 978/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 1.9817e-04 - val_loss: 0.0079\n",
      "Epoch 979/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 2.0156e-04 - val_loss: 0.0061\n",
      "Epoch 980/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 2.0217e-04 - val_loss: 0.0074\n",
      "Epoch 981/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 2.0400e-04 - val_loss: 0.0057\n",
      "Epoch 982/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 2.1291e-04 - val_loss: 0.0054\n",
      "Epoch 983/2000\n",
      "3811/3811 [==============================] - 3s 661us/step - loss: 2.0192e-04 - val_loss: 0.0045\n",
      "Epoch 984/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 2.0436e-04 - val_loss: 0.0045\n",
      "Epoch 985/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 2.1326e-04 - val_loss: 0.0049\n",
      "Epoch 986/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 2.1141e-04 - val_loss: 0.0073\n",
      "Epoch 987/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 2.2114e-04 - val_loss: 0.0072\n",
      "Epoch 988/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 2.1567e-04 - val_loss: 0.0059\n",
      "Epoch 989/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 2.1062e-04 - val_loss: 0.0057\n",
      "Epoch 990/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 2.0079e-04 - val_loss: 0.0048\n",
      "Epoch 991/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 1.9715e-04 - val_loss: 0.0045\n",
      "Epoch 992/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 1.9272e-04 - val_loss: 0.0059\n",
      "Epoch 993/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 2.1294e-04 - val_loss: 0.0054\n",
      "Epoch 994/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.8276e-04 - val_loss: 0.0051\n",
      "Epoch 995/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 1.9480e-04 - val_loss: 0.0073\n",
      "Epoch 996/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 1.9565e-04 - val_loss: 0.0073\n",
      "Epoch 997/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.8755e-04 - val_loss: 0.0068\n",
      "Epoch 998/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.8834e-04 - val_loss: 0.0068\n",
      "Epoch 999/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 2.1367e-04 - val_loss: 0.0049\n",
      "Epoch 1000/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 1.9903e-04 - val_loss: 0.0070\n",
      "Epoch 1001/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 1.9140e-04 - val_loss: 0.0047\n",
      "Epoch 1002/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 1.9132e-04 - val_loss: 0.0054\n",
      "Epoch 1003/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.8362e-04 - val_loss: 0.0048\n",
      "Epoch 1004/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 1.8814e-04 - val_loss: 0.0052\n",
      "Epoch 1005/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 2.0481e-04 - val_loss: 0.0055\n",
      "Epoch 1006/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 621us/step - loss: 2.2500e-04 - val_loss: 0.0081\n",
      "Epoch 1007/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 2.3177e-04 - val_loss: 0.0059\n",
      "Epoch 1008/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 2.0167e-04 - val_loss: 0.0055\n",
      "Epoch 1009/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 2.0373e-04 - val_loss: 0.0048\n",
      "Epoch 1010/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.9317e-04 - val_loss: 0.0058\n",
      "Epoch 1011/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 2.0917e-04 - val_loss: 0.0047\n",
      "Epoch 1012/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 2.0762e-04 - val_loss: 0.0050\n",
      "Epoch 1013/2000\n",
      "3811/3811 [==============================] - 3s 667us/step - loss: 1.8938e-04 - val_loss: 0.0056\n",
      "Epoch 1014/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 1.9673e-04 - val_loss: 0.0056\n",
      "Epoch 1015/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.9645e-04 - val_loss: 0.0053\n",
      "Epoch 1016/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 1.9120e-04 - val_loss: 0.0060\n",
      "Epoch 1017/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 2.0353e-04 - val_loss: 0.0059\n",
      "Epoch 1018/2000\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 2.1521e-04 - val_loss: 0.0044\n",
      "Epoch 1019/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.9686e-04 - val_loss: 0.0072\n",
      "Epoch 1020/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.8945e-04 - val_loss: 0.0058\n",
      "Epoch 1021/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 1.9389e-04 - val_loss: 0.0059\n",
      "Epoch 1022/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 1.9133e-04 - val_loss: 0.0060\n",
      "Epoch 1023/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 1.8205e-04 - val_loss: 0.0069\n",
      "Epoch 1024/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.8555e-04 - val_loss: 0.0067\n",
      "Epoch 1025/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.9394e-04 - val_loss: 0.0057\n",
      "Epoch 1026/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 1.9576e-04 - val_loss: 0.0073\n",
      "Epoch 1027/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 1.9420e-04 - val_loss: 0.0049\n",
      "Epoch 1028/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 1.9295e-04 - val_loss: 0.0071\n",
      "Epoch 1029/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.7741e-04 - val_loss: 0.0048\n",
      "Epoch 1030/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 2.0110e-04 - val_loss: 0.0064\n",
      "Epoch 1031/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 1.8023e-04 - val_loss: 0.0052\n",
      "Epoch 1032/2000\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 1.7853e-04 - val_loss: 0.0059\n",
      "Epoch 1033/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 1.8080e-04 - val_loss: 0.0048\n",
      "Epoch 1034/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 1.7355e-04 - val_loss: 0.0054\n",
      "Epoch 1035/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.6735e-04 - val_loss: 0.0049\n",
      "Epoch 1036/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 1.6927e-04 - val_loss: 0.0051\n",
      "Epoch 1037/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.7815e-04 - val_loss: 0.0048\n",
      "Epoch 1038/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.7453e-04 - val_loss: 0.0050\n",
      "Epoch 1039/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 1.6153e-04 - val_loss: 0.0057\n",
      "Epoch 1040/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 1.6826e-04 - val_loss: 0.0058\n",
      "Epoch 1041/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.6588e-04 - val_loss: 0.0068\n",
      "Epoch 1042/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.8372e-04 - val_loss: 0.0075\n",
      "Epoch 1043/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.7576e-04 - val_loss: 0.0061\n",
      "Epoch 1044/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.6991e-04 - val_loss: 0.0069\n",
      "Epoch 1045/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 1.6844e-04 - val_loss: 0.0054\n",
      "Epoch 1046/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.6256e-04 - val_loss: 0.0087\n",
      "Epoch 1047/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.8852e-04 - val_loss: 0.0103\n",
      "Epoch 1048/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 2.0136e-04 - val_loss: 0.0064\n",
      "Epoch 1049/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.9327e-04 - val_loss: 0.0056\n",
      "Epoch 1050/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.8532e-04 - val_loss: 0.0048\n",
      "Epoch 1051/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.6935e-04 - val_loss: 0.0072\n",
      "Epoch 1052/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 1.7674e-04 - val_loss: 0.0100\n",
      "Epoch 1053/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 1.7252e-04 - val_loss: 0.0061\n",
      "Epoch 1054/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 1.9059e-04 - val_loss: 0.0063\n",
      "Epoch 1055/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 2.0699e-04 - val_loss: 0.0051\n",
      "Epoch 1056/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 1.8670e-04 - val_loss: 0.0069\n",
      "Epoch 1057/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 1.7518e-04 - val_loss: 0.0065\n",
      "Epoch 1058/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 1.6970e-04 - val_loss: 0.0077\n",
      "Epoch 1059/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.6901e-04 - val_loss: 0.0059\n",
      "Epoch 1060/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 1.5982e-04 - val_loss: 0.0059\n",
      "Epoch 1061/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.6950e-04 - val_loss: 0.0067\n",
      "Epoch 1062/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.9813e-04 - val_loss: 0.0068\n",
      "Epoch 1063/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.8102e-04 - val_loss: 0.0107\n",
      "Epoch 1064/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.7048e-04 - val_loss: 0.0062\n",
      "Epoch 1065/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.5965e-04 - val_loss: 0.0079\n",
      "Epoch 1066/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.6333e-04 - val_loss: 0.0057\n",
      "Epoch 1067/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.6177e-04 - val_loss: 0.0062\n",
      "Epoch 1068/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.6259e-04 - val_loss: 0.0051\n",
      "Epoch 1069/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.6167e-04 - val_loss: 0.0056\n",
      "Epoch 1070/2000\n",
      "3811/3811 [==============================] - 3s 664us/step - loss: 1.6393e-04 - val_loss: 0.0054\n",
      "Epoch 1071/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.6713e-04 - val_loss: 0.0060\n",
      "Epoch 1072/2000\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 1.6993e-04 - val_loss: 0.0058\n",
      "Epoch 1073/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.7100e-04 - val_loss: 0.0064\n",
      "Epoch 1074/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.6038e-04 - val_loss: 0.0050\n",
      "Epoch 1075/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.5960e-04 - val_loss: 0.0059\n",
      "Epoch 1076/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.6739e-04 - val_loss: 0.0050\n",
      "Epoch 1077/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.7000e-04 - val_loss: 0.0068\n",
      "Epoch 1078/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.7775e-04 - val_loss: 0.0056\n",
      "Epoch 1079/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.9811e-04 - val_loss: 0.0077\n",
      "Epoch 1080/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 1.6611e-04 - val_loss: 0.0054\n",
      "Epoch 1081/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 1.6168e-04 - val_loss: 0.0066\n",
      "Epoch 1082/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 1.5738e-04 - val_loss: 0.0049\n",
      "Epoch 1083/2000\n",
      "3811/3811 [==============================] - 3s 674us/step - loss: 1.8263e-04 - val_loss: 0.0064\n",
      "Epoch 1084/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.7063e-04 - val_loss: 0.0061\n",
      "Epoch 1085/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.8928e-04 - val_loss: 0.0049\n",
      "Epoch 1086/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.6831e-04 - val_loss: 0.0050\n",
      "Epoch 1087/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.5974e-04 - val_loss: 0.0072\n",
      "Epoch 1088/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.6162e-04 - val_loss: 0.0051\n",
      "Epoch 1089/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.6304e-04 - val_loss: 0.0051\n",
      "Epoch 1090/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.5399e-04 - val_loss: 0.0068\n",
      "Epoch 1091/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.5949e-04 - val_loss: 0.0054\n",
      "Epoch 1092/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.6589e-04 - val_loss: 0.0078\n",
      "Epoch 1093/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.5230e-04 - val_loss: 0.0070\n",
      "Epoch 1094/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.4914e-04 - val_loss: 0.0066\n",
      "Epoch 1095/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 1.7001e-04 - val_loss: 0.0057\n",
      "Epoch 1096/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.9260e-04 - val_loss: 0.0084\n",
      "Epoch 1097/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 1.9437e-04 - val_loss: 0.0090\n",
      "Epoch 1098/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.6577e-04 - val_loss: 0.0056\n",
      "Epoch 1099/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.7215e-04 - val_loss: 0.0085\n",
      "Epoch 1100/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.6959e-04 - val_loss: 0.0053\n",
      "Epoch 1101/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.5843e-04 - val_loss: 0.0047\n",
      "Epoch 1102/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.6715e-04 - val_loss: 0.0065\n",
      "Epoch 1103/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.6619e-04 - val_loss: 0.0075\n",
      "Epoch 1104/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 1.6094e-04 - val_loss: 0.0076\n",
      "Epoch 1105/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 1.4984e-04 - val_loss: 0.0057\n",
      "Epoch 1106/2000\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 1.6112e-04 - val_loss: 0.0081\n",
      "Epoch 1107/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 1.6349e-04 - val_loss: 0.0063\n",
      "Epoch 1108/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 1.4876e-04 - val_loss: 0.0056\n",
      "Epoch 1109/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 1.5217e-04 - val_loss: 0.0059\n",
      "Epoch 1110/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.5538e-04 - val_loss: 0.0059\n",
      "Epoch 1111/2000\n",
      "3811/3811 [==============================] - 3s 657us/step - loss: 1.5342e-04 - val_loss: 0.0064\n",
      "Epoch 1112/2000\n",
      "3811/3811 [==============================] - 3s 674us/step - loss: 1.6964e-04 - val_loss: 0.0058\n",
      "Epoch 1113/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 1.8055e-04 - val_loss: 0.0054\n",
      "Epoch 1114/2000\n",
      "3811/3811 [==============================] - 3s 664us/step - loss: 1.8810e-04 - val_loss: 0.0055\n",
      "Epoch 1115/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 1.7798e-04 - val_loss: 0.0054\n",
      "Epoch 1116/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.7186e-04 - val_loss: 0.0103\n",
      "Epoch 1117/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.6334e-04 - val_loss: 0.0065\n",
      "Epoch 1118/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.6626e-04 - val_loss: 0.0071\n",
      "Epoch 1119/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.5613e-04 - val_loss: 0.0066\n",
      "Epoch 1120/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.4343e-04 - val_loss: 0.0066\n",
      "Epoch 1121/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.5813e-04 - val_loss: 0.0066\n",
      "Epoch 1122/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.5077e-04 - val_loss: 0.0057\n",
      "Epoch 1123/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.4865e-04 - val_loss: 0.0058\n",
      "Epoch 1124/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.4844e-04 - val_loss: 0.0074\n",
      "Epoch 1125/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.5306e-04 - val_loss: 0.0057\n",
      "Epoch 1126/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.5298e-04 - val_loss: 0.0052\n",
      "Epoch 1127/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.4443e-04 - val_loss: 0.0057\n",
      "Epoch 1128/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.5161e-04 - val_loss: 0.0064\n",
      "Epoch 1129/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.4943e-04 - val_loss: 0.0046\n",
      "Epoch 1130/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.4684e-04 - val_loss: 0.0054\n",
      "Epoch 1131/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.4974e-04 - val_loss: 0.0078\n",
      "Epoch 1132/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.6230e-04 - val_loss: 0.0048\n",
      "Epoch 1133/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.5680e-04 - val_loss: 0.0049\n",
      "Epoch 1134/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.5058e-04 - val_loss: 0.0049\n",
      "Epoch 1135/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.3782e-04 - val_loss: 0.0054\n",
      "Epoch 1136/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.4759e-04 - val_loss: 0.0054\n",
      "Epoch 1137/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.4761e-04 - val_loss: 0.0053\n",
      "Epoch 1138/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.5978e-04 - val_loss: 0.0058\n",
      "Epoch 1139/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.5431e-04 - val_loss: 0.0056\n",
      "Epoch 1140/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.4829e-04 - val_loss: 0.0057\n",
      "Epoch 1141/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.5749e-04 - val_loss: 0.0057\n",
      "Epoch 1142/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.4893e-04 - val_loss: 0.0061\n",
      "Epoch 1143/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 1.4806e-04 - val_loss: 0.0055\n",
      "Epoch 1144/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 1.3639e-04 - val_loss: 0.0065\n",
      "Epoch 1145/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 1.3148e-04 - val_loss: 0.0058\n",
      "Epoch 1146/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 1.3370e-04 - val_loss: 0.0050\n",
      "Epoch 1147/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 1.4138e-04 - val_loss: 0.0058\n",
      "Epoch 1148/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.4076e-04 - val_loss: 0.0049\n",
      "Epoch 1149/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.3487e-04 - val_loss: 0.0054\n",
      "Epoch 1150/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.4152e-04 - val_loss: 0.0057\n",
      "Epoch 1151/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.3733e-04 - val_loss: 0.0054\n",
      "Epoch 1152/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 1.3792e-04 - val_loss: 0.0071\n",
      "Epoch 1153/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 1.4613e-04 - val_loss: 0.0051\n",
      "Epoch 1154/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.4484e-04 - val_loss: 0.0070\n",
      "Epoch 1155/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.4072e-04 - val_loss: 0.0048\n",
      "Epoch 1156/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.5332e-04 - val_loss: 0.0072\n",
      "Epoch 1157/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.4911e-04 - val_loss: 0.0061\n",
      "Epoch 1158/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 1.4229e-04 - val_loss: 0.0074\n",
      "Epoch 1159/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.4781e-04 - val_loss: 0.0058\n",
      "Epoch 1160/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 1.5125e-04 - val_loss: 0.0066\n",
      "Epoch 1161/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 1.4611e-04 - val_loss: 0.0055\n",
      "Epoch 1162/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 1.3893e-04 - val_loss: 0.0061\n",
      "Epoch 1163/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.3906e-04 - val_loss: 0.0068\n",
      "Epoch 1164/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.3883e-04 - val_loss: 0.0066\n",
      "Epoch 1165/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.4106e-04 - val_loss: 0.0068\n",
      "Epoch 1166/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 1.3690e-04 - val_loss: 0.0070\n",
      "Epoch 1167/2000\n",
      "3811/3811 [==============================] - 2s 654us/step - loss: 1.4144e-04 - val_loss: 0.0056\n",
      "Epoch 1168/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 1.4015e-04 - val_loss: 0.0065\n",
      "Epoch 1169/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.3959e-04 - val_loss: 0.0058\n",
      "Epoch 1170/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 1.3989e-04 - val_loss: 0.0049\n",
      "Epoch 1171/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 1.4403e-04 - val_loss: 0.0082\n",
      "Epoch 1172/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 1.5049e-04 - val_loss: 0.0102\n",
      "Epoch 1173/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 1.8464e-04 - val_loss: 0.0103\n",
      "Epoch 1174/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 1.7908e-04 - val_loss: 0.0067\n",
      "Epoch 1175/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.5477e-04 - val_loss: 0.0052\n",
      "Epoch 1176/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.4890e-04 - val_loss: 0.0054\n",
      "Epoch 1177/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.5177e-04 - val_loss: 0.0060\n",
      "Epoch 1178/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.5519e-04 - val_loss: 0.0068\n",
      "Epoch 1179/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.4793e-04 - val_loss: 0.0057\n",
      "Epoch 1180/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.4551e-04 - val_loss: 0.0047\n",
      "Epoch 1181/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.3762e-04 - val_loss: 0.0060\n",
      "Epoch 1182/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.2775e-04 - val_loss: 0.0065\n",
      "Epoch 1183/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.4129e-04 - val_loss: 0.0063\n",
      "Epoch 1184/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.4492e-04 - val_loss: 0.0059\n",
      "Epoch 1185/2000\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 1.4177e-04 - val_loss: 0.0058\n",
      "Epoch 1186/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 1.3411e-04 - val_loss: 0.0065\n",
      "Epoch 1187/2000\n",
      "3811/3811 [==============================] - 3s 687us/step - loss: 1.3058e-04 - val_loss: 0.0064\n",
      "Epoch 1188/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 1.2649e-04 - val_loss: 0.0060\n",
      "Epoch 1189/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 1.2947e-04 - val_loss: 0.0069\n",
      "Epoch 1190/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.3552e-04 - val_loss: 0.0089\n",
      "Epoch 1191/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 1.3932e-04 - val_loss: 0.0060\n",
      "Epoch 1192/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 1.3383e-04 - val_loss: 0.0065\n",
      "Epoch 1193/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.3512e-04 - val_loss: 0.0057\n",
      "Epoch 1194/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 1.2934e-04 - val_loss: 0.0057\n",
      "Epoch 1195/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.3585e-04 - val_loss: 0.0057\n",
      "Epoch 1196/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.2876e-04 - val_loss: 0.0055\n",
      "Epoch 1197/2000\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 1.3613e-04 - val_loss: 0.0049\n",
      "Epoch 1198/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.5136e-04 - val_loss: 0.0053\n",
      "Epoch 1199/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.4739e-04 - val_loss: 0.0054\n",
      "Epoch 1200/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.4171e-04 - val_loss: 0.0070\n",
      "Epoch 1201/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.3264e-04 - val_loss: 0.0058\n",
      "Epoch 1202/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 1.3883e-04 - val_loss: 0.0051\n",
      "Epoch 1203/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.3404e-04 - val_loss: 0.0065\n",
      "Epoch 1204/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.3624e-04 - val_loss: 0.0061\n",
      "Epoch 1205/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 1.2616e-04 - val_loss: 0.0061\n",
      "Epoch 1206/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.3021e-04 - val_loss: 0.0065\n",
      "Epoch 1207/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.3373e-04 - val_loss: 0.0063\n",
      "Epoch 1208/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.3910e-04 - val_loss: 0.0070\n",
      "Epoch 1209/2000\n",
      "3811/3811 [==============================] - 3s 660us/step - loss: 1.3852e-04 - val_loss: 0.0054\n",
      "Epoch 1210/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 1.4404e-04 - val_loss: 0.0063\n",
      "Epoch 1211/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 1.4930e-04 - val_loss: 0.0049\n",
      "Epoch 1212/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.3760e-04 - val_loss: 0.0049\n",
      "Epoch 1213/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.3325e-04 - val_loss: 0.0048\n",
      "Epoch 1214/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.2706e-04 - val_loss: 0.0055\n",
      "Epoch 1215/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.2254e-04 - val_loss: 0.0060\n",
      "Epoch 1216/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.2227e-04 - val_loss: 0.0049\n",
      "Epoch 1217/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.3237e-04 - val_loss: 0.0048\n",
      "Epoch 1218/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.4291e-04 - val_loss: 0.0062\n",
      "Epoch 1219/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.3258e-04 - val_loss: 0.0080\n",
      "Epoch 1220/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.3217e-04 - val_loss: 0.0060\n",
      "Epoch 1221/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.3947e-04 - val_loss: 0.0059\n",
      "Epoch 1222/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 621us/step - loss: 1.4593e-04 - val_loss: 0.0049\n",
      "Epoch 1223/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.2575e-04 - val_loss: 0.0052\n",
      "Epoch 1224/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.2785e-04 - val_loss: 0.0051\n",
      "Epoch 1225/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.2458e-04 - val_loss: 0.0057\n",
      "Epoch 1226/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.3184e-04 - val_loss: 0.0059\n",
      "Epoch 1227/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.3039e-04 - val_loss: 0.0056\n",
      "Epoch 1228/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.2719e-04 - val_loss: 0.0051\n",
      "Epoch 1229/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.2662e-04 - val_loss: 0.0051\n",
      "Epoch 1230/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.2796e-04 - val_loss: 0.0057\n",
      "Epoch 1231/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.2511e-04 - val_loss: 0.0049\n",
      "Epoch 1232/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.2943e-04 - val_loss: 0.0076\n",
      "Epoch 1233/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.3022e-04 - val_loss: 0.0050\n",
      "Epoch 1234/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.3605e-04 - val_loss: 0.0058\n",
      "Epoch 1235/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.3623e-04 - val_loss: 0.0052\n",
      "Epoch 1236/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 1.3485e-04 - val_loss: 0.0057\n",
      "Epoch 1237/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 1.3068e-04 - val_loss: 0.0084\n",
      "Epoch 1238/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 1.2943e-04 - val_loss: 0.0068\n",
      "Epoch 1239/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 1.2159e-04 - val_loss: 0.0069\n",
      "Epoch 1240/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 1.3024e-04 - val_loss: 0.0046\n",
      "Epoch 1241/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 1.3417e-04 - val_loss: 0.0066\n",
      "Epoch 1242/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 1.2503e-04 - val_loss: 0.0055\n",
      "Epoch 1243/2000\n",
      "3811/3811 [==============================] - 3s 668us/step - loss: 1.2985e-04 - val_loss: 0.0072\n",
      "Epoch 1244/2000\n",
      "3811/3811 [==============================] - 3s 668us/step - loss: 1.2869e-04 - val_loss: 0.0053\n",
      "Epoch 1245/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 1.2498e-04 - val_loss: 0.0050\n",
      "Epoch 1246/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.2872e-04 - val_loss: 0.0054\n",
      "Epoch 1247/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 1.1643e-04 - val_loss: 0.0057\n",
      "Epoch 1248/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.2524e-04 - val_loss: 0.0049\n",
      "Epoch 1249/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.2316e-04 - val_loss: 0.0054\n",
      "Epoch 1250/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 1.1645e-04 - val_loss: 0.0063\n",
      "Epoch 1251/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 1.2144e-04 - val_loss: 0.0052\n",
      "Epoch 1252/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 1.1028e-04 - val_loss: 0.0050\n",
      "Epoch 1253/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 1.1220e-04 - val_loss: 0.0059\n",
      "Epoch 1254/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 1.1594e-04 - val_loss: 0.0055\n",
      "Epoch 1255/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.1165e-04 - val_loss: 0.0055\n",
      "Epoch 1256/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 1.2425e-04 - val_loss: 0.0050\n",
      "Epoch 1257/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 1.2082e-04 - val_loss: 0.0058\n",
      "Epoch 1258/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.1673e-04 - val_loss: 0.0052\n",
      "Epoch 1259/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.1599e-04 - val_loss: 0.0056\n",
      "Epoch 1260/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 1.1207e-04 - val_loss: 0.0062\n",
      "Epoch 1261/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 1.2406e-04 - val_loss: 0.0060\n",
      "Epoch 1262/2000\n",
      "3811/3811 [==============================] - 3s 666us/step - loss: 1.1554e-04 - val_loss: 0.0057\n",
      "Epoch 1263/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 1.1715e-04 - val_loss: 0.0063\n",
      "Epoch 1264/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 1.2047e-04 - val_loss: 0.0059\n",
      "Epoch 1265/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 1.2258e-04 - val_loss: 0.0076\n",
      "Epoch 1266/2000\n",
      "3811/3811 [==============================] - 3s 662us/step - loss: 1.3602e-04 - val_loss: 0.0058\n",
      "Epoch 1267/2000\n",
      "3811/3811 [==============================] - 3s 689us/step - loss: 1.2751e-04 - val_loss: 0.0055\n",
      "Epoch 1268/2000\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 1.3674e-04 - val_loss: 0.0054\n",
      "Epoch 1269/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 1.2477e-04 - val_loss: 0.0053\n",
      "Epoch 1270/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 1.4761e-04 - val_loss: 0.0051\n",
      "Epoch 1271/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 1.4315e-04 - val_loss: 0.0069\n",
      "Epoch 1272/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.2882e-04 - val_loss: 0.0052\n",
      "Epoch 1273/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 1.1308e-04 - val_loss: 0.0062\n",
      "Epoch 1274/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.2430e-04 - val_loss: 0.0055\n",
      "Epoch 1275/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.1688e-04 - val_loss: 0.0046\n",
      "Epoch 1276/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.1769e-04 - val_loss: 0.0051\n",
      "Epoch 1277/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.2293e-04 - val_loss: 0.0060\n",
      "Epoch 1278/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.1553e-04 - val_loss: 0.0047\n",
      "Epoch 1279/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.1156e-04 - val_loss: 0.0058\n",
      "Epoch 1280/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.3061e-04 - val_loss: 0.0054\n",
      "Epoch 1281/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.2824e-04 - val_loss: 0.0060\n",
      "Epoch 1282/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.2266e-04 - val_loss: 0.0065\n",
      "Epoch 1283/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.2090e-04 - val_loss: 0.0056\n",
      "Epoch 1284/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.2382e-04 - val_loss: 0.0065\n",
      "Epoch 1285/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.3390e-04 - val_loss: 0.0045\n",
      "Epoch 1286/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.2856e-04 - val_loss: 0.0048\n",
      "Epoch 1287/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.2020e-04 - val_loss: 0.0071\n",
      "Epoch 1288/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 1.1036e-04 - val_loss: 0.0053\n",
      "Epoch 1289/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.1401e-04 - val_loss: 0.0055\n",
      "Epoch 1290/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 1.0825e-04 - val_loss: 0.0054\n",
      "Epoch 1291/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 1.0872e-04 - val_loss: 0.0066\n",
      "Epoch 1292/2000\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 1.1409e-04 - val_loss: 0.0070\n",
      "Epoch 1293/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 1.1600e-04 - val_loss: 0.0057\n",
      "Epoch 1294/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 649us/step - loss: 1.3023e-04 - val_loss: 0.0062\n",
      "Epoch 1295/2000\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 1.1910e-04 - val_loss: 0.0057\n",
      "Epoch 1296/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 1.1148e-04 - val_loss: 0.0054\n",
      "Epoch 1297/2000\n",
      "3811/3811 [==============================] - 3s 695us/step - loss: 1.1774e-04 - val_loss: 0.0055\n",
      "Epoch 1298/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 1.1760e-04 - val_loss: 0.0065\n",
      "Epoch 1299/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 1.1029e-04 - val_loss: 0.0052\n",
      "Epoch 1300/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.1667e-04 - val_loss: 0.0058\n",
      "Epoch 1301/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.0655e-04 - val_loss: 0.0052\n",
      "Epoch 1302/2000\n",
      "3811/3811 [==============================] - 2s 607us/step - loss: 1.0816e-04 - val_loss: 0.0065\n",
      "Epoch 1303/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.0419e-04 - val_loss: 0.0053\n",
      "Epoch 1304/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.0769e-04 - val_loss: 0.0047\n",
      "Epoch 1305/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 1.1452e-04 - val_loss: 0.0071\n",
      "Epoch 1306/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.1018e-04 - val_loss: 0.0060\n",
      "Epoch 1307/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.1158e-04 - val_loss: 0.0051\n",
      "Epoch 1308/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.1116e-04 - val_loss: 0.0062\n",
      "Epoch 1309/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.1687e-04 - val_loss: 0.0053\n",
      "Epoch 1310/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 1.1435e-04 - val_loss: 0.0053\n",
      "Epoch 1311/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.1667e-04 - val_loss: 0.0068\n",
      "Epoch 1312/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.2632e-04 - val_loss: 0.0053\n",
      "Epoch 1313/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.2226e-04 - val_loss: 0.0057\n",
      "Epoch 1314/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.2399e-04 - val_loss: 0.0049\n",
      "Epoch 1315/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 1.2461e-04 - val_loss: 0.0059\n",
      "Epoch 1316/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.1245e-04 - val_loss: 0.0052\n",
      "Epoch 1317/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.1787e-04 - val_loss: 0.0064\n",
      "Epoch 1318/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.2190e-04 - val_loss: 0.0066\n",
      "Epoch 1319/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.2407e-04 - val_loss: 0.0057\n",
      "Epoch 1320/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.2048e-04 - val_loss: 0.0060\n",
      "Epoch 1321/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 1.2211e-04 - val_loss: 0.0059\n",
      "Epoch 1322/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 1.2904e-04 - val_loss: 0.0052\n",
      "Epoch 1323/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.2120e-04 - val_loss: 0.0058\n",
      "Epoch 1324/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.2764e-04 - val_loss: 0.0060\n",
      "Epoch 1325/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.1018e-04 - val_loss: 0.0077\n",
      "Epoch 1326/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.1097e-04 - val_loss: 0.0087\n",
      "Epoch 1327/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.1121e-04 - val_loss: 0.0064\n",
      "Epoch 1328/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.1701e-04 - val_loss: 0.0077\n",
      "Epoch 1329/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.1071e-04 - val_loss: 0.0080\n",
      "Epoch 1330/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 1.0678e-04 - val_loss: 0.0053\n",
      "Epoch 1331/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.1154e-04 - val_loss: 0.0075\n",
      "Epoch 1332/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.2270e-04 - val_loss: 0.0059\n",
      "Epoch 1333/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.0856e-04 - val_loss: 0.0054\n",
      "Epoch 1334/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.0918e-04 - val_loss: 0.0059\n",
      "Epoch 1335/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.0687e-04 - val_loss: 0.0056\n",
      "Epoch 1336/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.0993e-04 - val_loss: 0.0050\n",
      "Epoch 1337/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.2244e-04 - val_loss: 0.0064\n",
      "Epoch 1338/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.1441e-04 - val_loss: 0.0051\n",
      "Epoch 1339/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.1031e-04 - val_loss: 0.0057\n",
      "Epoch 1340/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.0785e-04 - val_loss: 0.0051\n",
      "Epoch 1341/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.0400e-04 - val_loss: 0.0051\n",
      "Epoch 1342/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 1.0178e-04 - val_loss: 0.0066\n",
      "Epoch 1343/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 1.0834e-04 - val_loss: 0.0052\n",
      "Epoch 1344/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 1.0288e-04 - val_loss: 0.0047\n",
      "Epoch 1345/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.0666e-04 - val_loss: 0.0055\n",
      "Epoch 1346/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 1.1237e-04 - val_loss: 0.0050\n",
      "Epoch 1347/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 1.0738e-04 - val_loss: 0.0056\n",
      "Epoch 1348/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 1.0633e-04 - val_loss: 0.0061\n",
      "Epoch 1349/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 1.0841e-04 - val_loss: 0.0046\n",
      "Epoch 1350/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 1.0795e-04 - val_loss: 0.0056\n",
      "Epoch 1351/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 1.1506e-04 - val_loss: 0.0062\n",
      "Epoch 1352/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 1.1384e-04 - val_loss: 0.0052\n",
      "Epoch 1353/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 1.0885e-04 - val_loss: 0.0060\n",
      "Epoch 1354/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 1.0778e-04 - val_loss: 0.0055\n",
      "Epoch 1355/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.0583e-04 - val_loss: 0.0052\n",
      "Epoch 1356/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.0674e-04 - val_loss: 0.0055\n",
      "Epoch 1357/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.0417e-04 - val_loss: 0.0054\n",
      "Epoch 1358/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 9.9597e-05 - val_loss: 0.0050\n",
      "Epoch 1359/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 9.4620e-05 - val_loss: 0.0053\n",
      "Epoch 1360/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.0847e-04 - val_loss: 0.0051\n",
      "Epoch 1361/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.0315e-04 - val_loss: 0.0058\n",
      "Epoch 1362/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.0633e-04 - val_loss: 0.0049\n",
      "Epoch 1363/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.0324e-04 - val_loss: 0.0045\n",
      "Epoch 1364/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.1835e-04 - val_loss: 0.0051\n",
      "Epoch 1365/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.2179e-04 - val_loss: 0.0046\n",
      "Epoch 1366/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.2855e-04 - val_loss: 0.0042\n",
      "Epoch 1367/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.2869e-04 - val_loss: 0.0048\n",
      "Epoch 1368/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 1.0998e-04 - val_loss: 0.0054\n",
      "Epoch 1369/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.1151e-04 - val_loss: 0.0054\n",
      "Epoch 1370/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 9.9565e-05 - val_loss: 0.0051\n",
      "Epoch 1371/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 9.5846e-05 - val_loss: 0.0067\n",
      "Epoch 1372/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 9.4311e-05 - val_loss: 0.0053\n",
      "Epoch 1373/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 9.5139e-05 - val_loss: 0.0054\n",
      "Epoch 1374/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 1.0138e-04 - val_loss: 0.0056\n",
      "Epoch 1375/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 1.1720e-04 - val_loss: 0.0048\n",
      "Epoch 1376/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 1.3548e-04 - val_loss: 0.0055\n",
      "Epoch 1377/2000\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 1.2742e-04 - val_loss: 0.0048\n",
      "Epoch 1378/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 1.1438e-04 - val_loss: 0.0057\n",
      "Epoch 1379/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 1.1415e-04 - val_loss: 0.0056\n",
      "Epoch 1380/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 1.0724e-04 - val_loss: 0.0052\n",
      "Epoch 1381/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 9.7572e-05 - val_loss: 0.0058\n",
      "Epoch 1382/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 1.0260e-04 - val_loss: 0.0060\n",
      "Epoch 1383/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 1.0717e-04 - val_loss: 0.0050\n",
      "Epoch 1384/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.1294e-04 - val_loss: 0.0055\n",
      "Epoch 1385/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 1.1124e-04 - val_loss: 0.0063\n",
      "Epoch 1386/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 1.0503e-04 - val_loss: 0.0054\n",
      "Epoch 1387/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 1.0706e-04 - val_loss: 0.0060\n",
      "Epoch 1388/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.1270e-04 - val_loss: 0.0056\n",
      "Epoch 1389/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.0362e-04 - val_loss: 0.0059\n",
      "Epoch 1390/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.0305e-04 - val_loss: 0.0051\n",
      "Epoch 1391/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 9.7430e-05 - val_loss: 0.0055\n",
      "Epoch 1392/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 9.9920e-05 - val_loss: 0.0051\n",
      "Epoch 1393/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.0635e-04 - val_loss: 0.0051\n",
      "Epoch 1394/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.1732e-04 - val_loss: 0.0055\n",
      "Epoch 1395/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.0611e-04 - val_loss: 0.0050\n",
      "Epoch 1396/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.0078e-04 - val_loss: 0.0051\n",
      "Epoch 1397/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.0368e-04 - val_loss: 0.0055\n",
      "Epoch 1398/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 9.9022e-05 - val_loss: 0.0052\n",
      "Epoch 1399/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 1.0454e-04 - val_loss: 0.0074\n",
      "Epoch 1400/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 9.8115e-05 - val_loss: 0.0059\n",
      "Epoch 1401/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.0632e-04 - val_loss: 0.0057\n",
      "Epoch 1402/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.0963e-04 - val_loss: 0.0055\n",
      "Epoch 1403/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.0290e-04 - val_loss: 0.0047\n",
      "Epoch 1404/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.0929e-04 - val_loss: 0.0057\n",
      "Epoch 1405/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.0436e-04 - val_loss: 0.0064\n",
      "Epoch 1406/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.0347e-04 - val_loss: 0.0049\n",
      "Epoch 1407/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 9.5592e-05 - val_loss: 0.0051\n",
      "Epoch 1408/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.0417e-04 - val_loss: 0.0063\n",
      "Epoch 1409/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.1169e-04 - val_loss: 0.0051\n",
      "Epoch 1410/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 1.1071e-04 - val_loss: 0.0059\n",
      "Epoch 1411/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 9.4956e-05 - val_loss: 0.0069\n",
      "Epoch 1412/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 9.4791e-05 - val_loss: 0.0056\n",
      "Epoch 1413/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 9.6070e-05 - val_loss: 0.0055\n",
      "Epoch 1414/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 9.1296e-05 - val_loss: 0.0054\n",
      "Epoch 1415/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 9.5060e-05 - val_loss: 0.0056\n",
      "Epoch 1416/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 1.0228e-04 - val_loss: 0.0064\n",
      "Epoch 1417/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 1.0101e-04 - val_loss: 0.0058\n",
      "Epoch 1418/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.0361e-04 - val_loss: 0.0054\n",
      "Epoch 1419/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 9.9805e-05 - val_loss: 0.0063\n",
      "Epoch 1420/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 8.9072e-05 - val_loss: 0.0067\n",
      "Epoch 1421/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 9.0175e-05 - val_loss: 0.0056\n",
      "Epoch 1422/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 9.2485e-05 - val_loss: 0.0057\n",
      "Epoch 1423/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 1.0696e-04 - val_loss: 0.0073\n",
      "Epoch 1424/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 9.8978e-05 - val_loss: 0.0057\n",
      "Epoch 1425/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 9.2394e-05 - val_loss: 0.0077\n",
      "Epoch 1426/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 9.5514e-05 - val_loss: 0.0052\n",
      "Epoch 1427/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 9.6403e-05 - val_loss: 0.0056\n",
      "Epoch 1428/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 9.4039e-05 - val_loss: 0.0068\n",
      "Epoch 1429/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 9.1081e-05 - val_loss: 0.0055\n",
      "Epoch 1430/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 9.7266e-05 - val_loss: 0.0055\n",
      "Epoch 1431/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 9.8442e-05 - val_loss: 0.0057\n",
      "Epoch 1432/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 9.7910e-05 - val_loss: 0.0055\n",
      "Epoch 1433/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 9.1621e-05 - val_loss: 0.0058\n",
      "Epoch 1434/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 9.3156e-05 - val_loss: 0.0057\n",
      "Epoch 1435/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 9.6028e-05 - val_loss: 0.0064\n",
      "Epoch 1436/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 9.8417e-05 - val_loss: 0.0060\n",
      "Epoch 1437/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 1.1178e-04 - val_loss: 0.0051\n",
      "Epoch 1438/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 634us/step - loss: 1.1134e-04 - val_loss: 0.0059\n",
      "Epoch 1439/2000\n",
      "3811/3811 [==============================] - 2s 636us/step - loss: 1.0876e-04 - val_loss: 0.0058\n",
      "Epoch 1440/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 1.0058e-04 - val_loss: 0.0062\n",
      "Epoch 1441/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 1.0768e-04 - val_loss: 0.0063\n",
      "Epoch 1442/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 1.1041e-04 - val_loss: 0.0058\n",
      "Epoch 1443/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 1.0266e-04 - val_loss: 0.0055\n",
      "Epoch 1444/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 9.1678e-05 - val_loss: 0.0056\n",
      "Epoch 1445/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 9.4963e-05 - val_loss: 0.0065\n",
      "Epoch 1446/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 9.9173e-05 - val_loss: 0.0060\n",
      "Epoch 1447/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 9.8444e-05 - val_loss: 0.0059\n",
      "Epoch 1448/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 1.1497e-04 - val_loss: 0.0060\n",
      "Epoch 1449/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 1.2091e-04 - val_loss: 0.0060\n",
      "Epoch 1450/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 1.2518e-04 - val_loss: 0.0048\n",
      "Epoch 1451/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 1.2108e-04 - val_loss: 0.0055\n",
      "Epoch 1452/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 1.1038e-04 - val_loss: 0.0053\n",
      "Epoch 1453/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 1.0483e-04 - val_loss: 0.0068\n",
      "Epoch 1454/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 1.0312e-04 - val_loss: 0.0053\n",
      "Epoch 1455/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 9.6902e-05 - val_loss: 0.0057\n",
      "Epoch 1456/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 9.8959e-05 - val_loss: 0.0046\n",
      "Epoch 1457/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 1.1629e-04 - val_loss: 0.0051\n",
      "Epoch 1458/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 1.1311e-04 - val_loss: 0.0057\n",
      "Epoch 1459/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 1.0705e-04 - val_loss: 0.0055\n",
      "Epoch 1460/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 1.0810e-04 - val_loss: 0.0062\n",
      "Epoch 1461/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 9.8924e-05 - val_loss: 0.0054\n",
      "Epoch 1462/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 9.5980e-05 - val_loss: 0.0055\n",
      "Epoch 1463/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 9.1156e-05 - val_loss: 0.0052\n",
      "Epoch 1464/2000\n",
      "3811/3811 [==============================] - 2s 608us/step - loss: 9.7105e-05 - val_loss: 0.0059\n",
      "Epoch 1465/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 9.1387e-05 - val_loss: 0.0052\n",
      "Epoch 1466/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 1.0717e-04 - val_loss: 0.0046\n",
      "Epoch 1467/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 9.7523e-05 - val_loss: 0.0066\n",
      "Epoch 1468/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 9.0264e-05 - val_loss: 0.0059\n",
      "Epoch 1469/2000\n",
      "3811/3811 [==============================] - 2s 633us/step - loss: 8.5386e-05 - val_loss: 0.0052\n",
      "Epoch 1470/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 9.5126e-05 - val_loss: 0.0053\n",
      "Epoch 1471/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 8.8821e-05 - val_loss: 0.0044\n",
      "Epoch 1472/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 9.1417e-05 - val_loss: 0.0060\n",
      "Epoch 1473/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 8.8364e-05 - val_loss: 0.0053\n",
      "Epoch 1474/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 9.5721e-05 - val_loss: 0.0064\n",
      "Epoch 1475/2000\n",
      "3811/3811 [==============================] - 2s 638us/step - loss: 9.8181e-05 - val_loss: 0.0051\n",
      "Epoch 1476/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 9.1390e-05 - val_loss: 0.0050\n",
      "Epoch 1477/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 9.8159e-05 - val_loss: 0.0049\n",
      "Epoch 1478/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 1.0651e-04 - val_loss: 0.0057\n",
      "Epoch 1479/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 1.0487e-04 - val_loss: 0.0056\n",
      "Epoch 1480/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 9.8822e-05 - val_loss: 0.0056\n",
      "Epoch 1481/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 1.0208e-04 - val_loss: 0.0077\n",
      "Epoch 1482/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 9.5805e-05 - val_loss: 0.0056\n",
      "Epoch 1483/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 9.0479e-05 - val_loss: 0.0060\n",
      "Epoch 1484/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 9.0133e-05 - val_loss: 0.0053\n",
      "Epoch 1485/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 9.7632e-05 - val_loss: 0.0057\n",
      "Epoch 1486/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.0308e-04 - val_loss: 0.0069\n",
      "Epoch 1487/2000\n",
      "3811/3811 [==============================] - 2s 625us/step - loss: 1.0328e-04 - val_loss: 0.0051\n",
      "Epoch 1488/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 1.0705e-04 - val_loss: 0.0058\n",
      "Epoch 1489/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 1.0630e-04 - val_loss: 0.0060\n",
      "Epoch 1490/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 9.7632e-05 - val_loss: 0.0053\n",
      "Epoch 1491/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 8.8718e-05 - val_loss: 0.0055\n",
      "Epoch 1492/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 8.7974e-05 - val_loss: 0.0056\n",
      "Epoch 1493/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 9.4053e-05 - val_loss: 0.0057\n",
      "Epoch 1494/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 9.4405e-05 - val_loss: 0.0059\n",
      "Epoch 1495/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 9.4220e-05 - val_loss: 0.0060\n",
      "Epoch 1496/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 8.3271e-05 - val_loss: 0.0056\n",
      "Epoch 1497/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 8.8765e-05 - val_loss: 0.0058\n",
      "Epoch 1498/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 8.3520e-05 - val_loss: 0.0060\n",
      "Epoch 1499/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 7.9551e-05 - val_loss: 0.0059\n",
      "Epoch 1500/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 7.8735e-05 - val_loss: 0.0064\n",
      "Epoch 1501/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 8.1689e-05 - val_loss: 0.0057\n",
      "Epoch 1502/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 8.3192e-05 - val_loss: 0.0057\n",
      "Epoch 1503/2000\n",
      "3811/3811 [==============================] - 3s 667us/step - loss: 9.1069e-05 - val_loss: 0.0053\n",
      "Epoch 1504/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 8.7575e-05 - val_loss: 0.0058\n",
      "Epoch 1505/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 8.8496e-05 - val_loss: 0.0057\n",
      "Epoch 1506/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 8.3606e-05 - val_loss: 0.0061\n",
      "Epoch 1507/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 8.4219e-05 - val_loss: 0.0064\n",
      "Epoch 1508/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 8.3264e-05 - val_loss: 0.0056\n",
      "Epoch 1509/2000\n",
      "3811/3811 [==============================] - 2s 626us/step - loss: 8.0569e-05 - val_loss: 0.0057\n",
      "Epoch 1510/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 635us/step - loss: 8.5353e-05 - val_loss: 0.0059\n",
      "Epoch 1511/2000\n",
      "3811/3811 [==============================] - 2s 630us/step - loss: 8.4893e-05 - val_loss: 0.0059\n",
      "Epoch 1512/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 8.5909e-05 - val_loss: 0.0060\n",
      "Epoch 1513/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 8.7525e-05 - val_loss: 0.0058\n",
      "Epoch 1514/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 9.0541e-05 - val_loss: 0.0061\n",
      "Epoch 1515/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 9.1008e-05 - val_loss: 0.0061\n",
      "Epoch 1516/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 9.1240e-05 - val_loss: 0.0056\n",
      "Epoch 1517/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 9.2368e-05 - val_loss: 0.0058\n",
      "Epoch 1518/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 8.7420e-05 - val_loss: 0.0055\n",
      "Epoch 1519/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 8.2907e-05 - val_loss: 0.0061\n",
      "Epoch 1520/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 8.6420e-05 - val_loss: 0.0060\n",
      "Epoch 1521/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 1.0322e-04 - val_loss: 0.0047\n",
      "Epoch 1522/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 9.7834e-05 - val_loss: 0.0058\n",
      "Epoch 1523/2000\n",
      "3811/3811 [==============================] - 2s 624us/step - loss: 8.6142e-05 - val_loss: 0.0062\n",
      "Epoch 1524/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 9.4765e-05 - val_loss: 0.0064\n",
      "Epoch 1525/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 8.9325e-05 - val_loss: 0.0057\n",
      "Epoch 1526/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 8.7985e-05 - val_loss: 0.0070\n",
      "Epoch 1527/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 8.9983e-05 - val_loss: 0.0060\n",
      "Epoch 1528/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 8.7761e-05 - val_loss: 0.0052\n",
      "Epoch 1529/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 8.8146e-05 - val_loss: 0.0062\n",
      "Epoch 1530/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 9.2358e-05 - val_loss: 0.0050\n",
      "Epoch 1531/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 8.6531e-05 - val_loss: 0.0056\n",
      "Epoch 1532/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 8.6941e-05 - val_loss: 0.0057\n",
      "Epoch 1533/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 8.6757e-05 - val_loss: 0.0058\n",
      "Epoch 1534/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 8.7350e-05 - val_loss: 0.0066\n",
      "Epoch 1535/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 8.6235e-05 - val_loss: 0.0058\n",
      "Epoch 1536/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 8.8584e-05 - val_loss: 0.0057\n",
      "Epoch 1537/2000\n",
      "3811/3811 [==============================] - 2s 619us/step - loss: 8.8717e-05 - val_loss: 0.0058\n",
      "Epoch 1538/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 8.3993e-05 - val_loss: 0.0062\n",
      "Epoch 1539/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 8.4868e-05 - val_loss: 0.0062\n",
      "Epoch 1540/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 8.9836e-05 - val_loss: 0.0066\n",
      "Epoch 1541/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 9.0544e-05 - val_loss: 0.0056\n",
      "Epoch 1542/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 8.4490e-05 - val_loss: 0.0062\n",
      "Epoch 1543/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 7.8453e-05 - val_loss: 0.0065\n",
      "Epoch 1544/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 7.8275e-05 - val_loss: 0.0058\n",
      "Epoch 1545/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 8.6358e-05 - val_loss: 0.0066\n",
      "Epoch 1546/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 8.6884e-05 - val_loss: 0.0061\n",
      "Epoch 1547/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 8.4640e-05 - val_loss: 0.0058\n",
      "Epoch 1548/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 8.9429e-05 - val_loss: 0.0057\n",
      "Epoch 1549/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 8.4808e-05 - val_loss: 0.0068\n",
      "Epoch 1550/2000\n",
      "3811/3811 [==============================] - 2s 632us/step - loss: 8.3495e-05 - val_loss: 0.0069\n",
      "Epoch 1551/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 9.3445e-05 - val_loss: 0.0056\n",
      "Epoch 1552/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 9.1308e-05 - val_loss: 0.0063\n",
      "Epoch 1553/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 9.3033e-05 - val_loss: 0.0066\n",
      "Epoch 1554/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 8.6030e-05 - val_loss: 0.0063\n",
      "Epoch 1555/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 7.9185e-05 - val_loss: 0.0055\n",
      "Epoch 1556/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 8.3071e-05 - val_loss: 0.0061\n",
      "Epoch 1557/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 9.0279e-05 - val_loss: 0.0064\n",
      "Epoch 1558/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 8.1662e-05 - val_loss: 0.0061\n",
      "Epoch 1559/2000\n",
      "3811/3811 [==============================] - 2s 616us/step - loss: 8.5153e-05 - val_loss: 0.0065\n",
      "Epoch 1560/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 8.6390e-05 - val_loss: 0.0059\n",
      "Epoch 1561/2000\n",
      "3811/3811 [==============================] - 3s 663us/step - loss: 9.6947e-05 - val_loss: 0.0055\n",
      "Epoch 1562/2000\n",
      "3811/3811 [==============================] - 2s 628us/step - loss: 9.4716e-05 - val_loss: 0.0064\n",
      "Epoch 1563/2000\n",
      "3811/3811 [==============================] - 2s 620us/step - loss: 9.3342e-05 - val_loss: 0.0053\n",
      "Epoch 1564/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 7.8980e-05 - val_loss: 0.0065\n",
      "Epoch 1565/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 7.8303e-05 - val_loss: 0.0064\n",
      "Epoch 1566/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 8.3716e-05 - val_loss: 0.0061\n",
      "Epoch 1567/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 8.4652e-05 - val_loss: 0.0072\n",
      "Epoch 1568/2000\n",
      "3811/3811 [==============================] - 2s 623us/step - loss: 8.2990e-05 - val_loss: 0.0061\n",
      "Epoch 1569/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 8.0858e-05 - val_loss: 0.0064\n",
      "Epoch 1570/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 8.1767e-05 - val_loss: 0.0058\n",
      "Epoch 1571/2000\n",
      "3811/3811 [==============================] - 2s 614us/step - loss: 7.9121e-05 - val_loss: 0.0059\n",
      "Epoch 1572/2000\n",
      "3811/3811 [==============================] - 2s 618us/step - loss: 7.6525e-05 - val_loss: 0.0061\n",
      "Epoch 1573/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 7.8680e-05 - val_loss: 0.0067\n",
      "Epoch 1574/2000\n",
      "3811/3811 [==============================] - 2s 610us/step - loss: 7.9346e-05 - val_loss: 0.0065\n",
      "Epoch 1575/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 8.1435e-05 - val_loss: 0.0061\n",
      "Epoch 1576/2000\n",
      "3811/3811 [==============================] - 2s 631us/step - loss: 8.7365e-05 - val_loss: 0.0061\n",
      "Epoch 1577/2000\n",
      "3811/3811 [==============================] - 2s 627us/step - loss: 8.7426e-05 - val_loss: 0.0062\n",
      "Epoch 1578/2000\n",
      "3811/3811 [==============================] - 2s 622us/step - loss: 8.5617e-05 - val_loss: 0.0053\n",
      "Epoch 1579/2000\n",
      "3811/3811 [==============================] - 2s 613us/step - loss: 8.2499e-05 - val_loss: 0.0065\n",
      "Epoch 1580/2000\n",
      "3811/3811 [==============================] - 3s 670us/step - loss: 8.3580e-05 - val_loss: 0.0063\n",
      "Epoch 1581/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 8.6093e-05 - val_loss: 0.0056\n",
      "Epoch 1582/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 610us/step - loss: 8.8001e-05 - val_loss: 0.0057\n",
      "Epoch 1583/2000\n",
      "3811/3811 [==============================] - 2s 612us/step - loss: 9.5837e-05 - val_loss: 0.0062\n",
      "Epoch 1584/2000\n",
      "3811/3811 [==============================] - 2s 615us/step - loss: 8.4811e-05 - val_loss: 0.0059\n",
      "Epoch 1585/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 8.2051e-05 - val_loss: 0.0059\n",
      "Epoch 1586/2000\n",
      "3811/3811 [==============================] - 2s 621us/step - loss: 7.5258e-05 - val_loss: 0.0057\n",
      "Epoch 1587/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 7.7215e-05 - val_loss: 0.0063\n",
      "Epoch 1588/2000\n",
      "3811/3811 [==============================] - 2s 617us/step - loss: 7.2884e-05 - val_loss: 0.0061\n",
      "Epoch 1589/2000\n",
      "3811/3811 [==============================] - 2s 611us/step - loss: 7.7356e-05 - val_loss: 0.0064\n",
      "Epoch 1590/2000\n",
      "3811/3811 [==============================] - 2s 609us/step - loss: 7.6491e-05 - val_loss: 0.0060\n",
      "Epoch 1591/2000\n",
      "3811/3811 [==============================] - 2s 629us/step - loss: 7.5832e-05 - val_loss: 0.0057\n",
      "Epoch 1592/2000\n",
      "3811/3811 [==============================] - 2s 634us/step - loss: 7.3407e-05 - val_loss: 0.0054\n",
      "Epoch 1593/2000\n",
      "3811/3811 [==============================] - 3s 667us/step - loss: 7.4547e-05 - val_loss: 0.0055\n",
      "Epoch 1594/2000\n",
      "3811/3811 [==============================] - 3s 657us/step - loss: 7.7002e-05 - val_loss: 0.0063\n",
      "Epoch 1595/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 7.2075e-05 - val_loss: 0.0055\n",
      "Epoch 1596/2000\n",
      "3811/3811 [==============================] - 3s 672us/step - loss: 7.0000e-05 - val_loss: 0.0057\n",
      "Epoch 1597/2000\n",
      "3811/3811 [==============================] - 3s 664us/step - loss: 7.6253e-05 - val_loss: 0.0054\n",
      "Epoch 1598/2000\n",
      "3811/3811 [==============================] - 3s 664us/step - loss: 7.8454e-05 - val_loss: 0.0057\n",
      "Epoch 1599/2000\n",
      "3811/3811 [==============================] - 3s 657us/step - loss: 7.9127e-05 - val_loss: 0.0061\n",
      "Epoch 1600/2000\n",
      "3811/3811 [==============================] - 3s 662us/step - loss: 7.5341e-05 - val_loss: 0.0060\n",
      "Epoch 1601/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 8.2728e-05 - val_loss: 0.0057\n",
      "Epoch 1602/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 8.4203e-05 - val_loss: 0.0058\n",
      "Epoch 1603/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 9.5828e-05 - val_loss: 0.0057\n",
      "Epoch 1604/2000\n",
      "3811/3811 [==============================] - 2s 656us/step - loss: 9.7197e-05 - val_loss: 0.0062\n",
      "Epoch 1605/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 9.6297e-05 - val_loss: 0.0054\n",
      "Epoch 1606/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 9.1808e-04 - val_loss: 0.0082\n",
      "Epoch 1607/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 1608/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 0.0011 - val_loss: 0.0066\n",
      "Epoch 1609/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 6.8870e-04 - val_loss: 0.0052\n",
      "Epoch 1610/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 4.8256e-04 - val_loss: 0.0054\n",
      "Epoch 1611/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 3.9733e-04 - val_loss: 0.0045\n",
      "Epoch 1612/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 3.1530e-04 - val_loss: 0.0052\n",
      "Epoch 1613/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 2.7285e-04 - val_loss: 0.0053\n",
      "Epoch 1614/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 2.5224e-04 - val_loss: 0.0051\n",
      "Epoch 1615/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 2.3953e-04 - val_loss: 0.0064\n",
      "Epoch 1616/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 2.0273e-04 - val_loss: 0.0059\n",
      "Epoch 1617/2000\n",
      "3811/3811 [==============================] - 3s 663us/step - loss: 1.9210e-04 - val_loss: 0.0058\n",
      "Epoch 1618/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 1.9940e-04 - val_loss: 0.0054\n",
      "Epoch 1619/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 1.7912e-04 - val_loss: 0.0056\n",
      "Epoch 1620/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 1.7246e-04 - val_loss: 0.0059\n",
      "Epoch 1621/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 1.6917e-04 - val_loss: 0.0052\n",
      "Epoch 1622/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 1.6238e-04 - val_loss: 0.0061\n",
      "Epoch 1623/2000\n",
      "3811/3811 [==============================] - 3s 665us/step - loss: 1.5708e-04 - val_loss: 0.0052\n",
      "Epoch 1624/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 1.4868e-04 - val_loss: 0.0055\n",
      "Epoch 1625/2000\n",
      "3811/3811 [==============================] - 3s 663us/step - loss: 1.5201e-04 - val_loss: 0.0053\n",
      "Epoch 1626/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 1.5705e-04 - val_loss: 0.0048\n",
      "Epoch 1627/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 1.4776e-04 - val_loss: 0.0048\n",
      "Epoch 1628/2000\n",
      "3811/3811 [==============================] - 3s 661us/step - loss: 1.4772e-04 - val_loss: 0.0058\n",
      "Epoch 1629/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 1.3846e-04 - val_loss: 0.0043\n",
      "Epoch 1630/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 1.3358e-04 - val_loss: 0.0045\n",
      "Epoch 1631/2000\n",
      "3811/3811 [==============================] - 3s 665us/step - loss: 1.3388e-04 - val_loss: 0.0053\n",
      "Epoch 1632/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 1.3768e-04 - val_loss: 0.0051\n",
      "Epoch 1633/2000\n",
      "3811/3811 [==============================] - 3s 657us/step - loss: 1.2982e-04 - val_loss: 0.0051\n",
      "Epoch 1634/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 1.3244e-04 - val_loss: 0.0061\n",
      "Epoch 1635/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 1.2561e-04 - val_loss: 0.0047\n",
      "Epoch 1636/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 1.1295e-04 - val_loss: 0.0056\n",
      "Epoch 1637/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 1.1894e-04 - val_loss: 0.0055\n",
      "Epoch 1638/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 1.2062e-04 - val_loss: 0.0061\n",
      "Epoch 1639/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 1.2095e-04 - val_loss: 0.0059\n",
      "Epoch 1640/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 1.2338e-04 - val_loss: 0.0053\n",
      "Epoch 1641/2000\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 1.1657e-04 - val_loss: 0.0057\n",
      "Epoch 1642/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 1.1386e-04 - val_loss: 0.0058\n",
      "Epoch 1643/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 1.0919e-04 - val_loss: 0.0061\n",
      "Epoch 1644/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 1.0738e-04 - val_loss: 0.0064\n",
      "Epoch 1645/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 1.2551e-04 - val_loss: 0.0061\n",
      "Epoch 1646/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 1.2114e-04 - val_loss: 0.0060\n",
      "Epoch 1647/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 1.1457e-04 - val_loss: 0.0063\n",
      "Epoch 1648/2000\n",
      "3811/3811 [==============================] - 3s 672us/step - loss: 1.0703e-04 - val_loss: 0.0064\n",
      "Epoch 1649/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 1.0465e-04 - val_loss: 0.0056\n",
      "Epoch 1650/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 1.0581e-04 - val_loss: 0.0059\n",
      "Epoch 1651/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 1.0154e-04 - val_loss: 0.0055\n",
      "Epoch 1652/2000\n",
      "3811/3811 [==============================] - 3s 665us/step - loss: 1.0799e-04 - val_loss: 0.0061\n",
      "Epoch 1653/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 1.0813e-04 - val_loss: 0.0056\n",
      "Epoch 1654/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 651us/step - loss: 1.0480e-04 - val_loss: 0.0070\n",
      "Epoch 1655/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 9.7133e-05 - val_loss: 0.0067\n",
      "Epoch 1656/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 1.0217e-04 - val_loss: 0.0060\n",
      "Epoch 1657/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 1.0625e-04 - val_loss: 0.0071\n",
      "Epoch 1658/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 1.0358e-04 - val_loss: 0.0065\n",
      "Epoch 1659/2000\n",
      "3811/3811 [==============================] - 2s 635us/step - loss: 1.0791e-04 - val_loss: 0.0092\n",
      "Epoch 1660/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 1.0361e-04 - val_loss: 0.0060\n",
      "Epoch 1661/2000\n",
      "3811/3811 [==============================] - 3s 665us/step - loss: 1.0027e-04 - val_loss: 0.0068\n",
      "Epoch 1662/2000\n",
      "3811/3811 [==============================] - 3s 705us/step - loss: 1.0051e-04 - val_loss: 0.0049\n",
      "Epoch 1663/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 9.9475e-05 - val_loss: 0.0069\n",
      "Epoch 1664/2000\n",
      "3811/3811 [==============================] - 3s 673us/step - loss: 9.2794e-05 - val_loss: 0.0060\n",
      "Epoch 1665/2000\n",
      "3811/3811 [==============================] - 3s 716us/step - loss: 9.1175e-05 - val_loss: 0.0080\n",
      "Epoch 1666/2000\n",
      "3811/3811 [==============================] - 3s 674us/step - loss: 9.5630e-05 - val_loss: 0.0070\n",
      "Epoch 1667/2000\n",
      "3811/3811 [==============================] - 3s 675us/step - loss: 9.3094e-05 - val_loss: 0.0062\n",
      "Epoch 1668/2000\n",
      "3811/3811 [==============================] - 3s 684us/step - loss: 9.0703e-05 - val_loss: 0.0077\n",
      "Epoch 1669/2000\n",
      "3811/3811 [==============================] - 3s 680us/step - loss: 9.4950e-05 - val_loss: 0.0069\n",
      "Epoch 1670/2000\n",
      "3811/3811 [==============================] - 3s 685us/step - loss: 9.1082e-05 - val_loss: 0.0066\n",
      "Epoch 1671/2000\n",
      "3811/3811 [==============================] - 3s 682us/step - loss: 9.2064e-05 - val_loss: 0.0088\n",
      "Epoch 1672/2000\n",
      "3811/3811 [==============================] - 3s 684us/step - loss: 9.8053e-05 - val_loss: 0.0081\n",
      "Epoch 1673/2000\n",
      "3811/3811 [==============================] - 3s 678us/step - loss: 9.2771e-05 - val_loss: 0.0070\n",
      "Epoch 1674/2000\n",
      "3811/3811 [==============================] - 3s 689us/step - loss: 9.0520e-05 - val_loss: 0.0064\n",
      "Epoch 1675/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 9.0993e-05 - val_loss: 0.0066\n",
      "Epoch 1676/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 8.5973e-05 - val_loss: 0.0066\n",
      "Epoch 1677/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 8.8743e-05 - val_loss: 0.0069\n",
      "Epoch 1678/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 9.3335e-05 - val_loss: 0.0084\n",
      "Epoch 1679/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 9.5233e-05 - val_loss: 0.0056\n",
      "Epoch 1680/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 8.8637e-05 - val_loss: 0.0056\n",
      "Epoch 1681/2000\n",
      "3811/3811 [==============================] - 2s 654us/step - loss: 8.8224e-05 - val_loss: 0.0082\n",
      "Epoch 1682/2000\n",
      "3811/3811 [==============================] - 2s 654us/step - loss: 8.9470e-05 - val_loss: 0.0062\n",
      "Epoch 1683/2000\n",
      "3811/3811 [==============================] - 3s 668us/step - loss: 9.4703e-05 - val_loss: 0.0054\n",
      "Epoch 1684/2000\n",
      "3811/3811 [==============================] - 3s 660us/step - loss: 9.0725e-05 - val_loss: 0.0063\n",
      "Epoch 1685/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 9.3461e-05 - val_loss: 0.0080\n",
      "Epoch 1686/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 9.0352e-05 - val_loss: 0.0070\n",
      "Epoch 1687/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 9.2313e-05 - val_loss: 0.0076\n",
      "Epoch 1688/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 9.2079e-05 - val_loss: 0.0085\n",
      "Epoch 1689/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 9.7609e-05 - val_loss: 0.0072\n",
      "Epoch 1690/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 9.5987e-05 - val_loss: 0.0088\n",
      "Epoch 1691/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 9.6171e-05 - val_loss: 0.0063\n",
      "Epoch 1692/2000\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 9.2094e-05 - val_loss: 0.0071\n",
      "Epoch 1693/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 9.1549e-05 - val_loss: 0.0089\n",
      "Epoch 1694/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 8.9002e-05 - val_loss: 0.0081\n",
      "Epoch 1695/2000\n",
      "3811/3811 [==============================] - 3s 665us/step - loss: 8.5195e-05 - val_loss: 0.0076\n",
      "Epoch 1696/2000\n",
      "3811/3811 [==============================] - 3s 674us/step - loss: 8.9158e-05 - val_loss: 0.0082\n",
      "Epoch 1697/2000\n",
      "3811/3811 [==============================] - 3s 657us/step - loss: 8.6089e-05 - val_loss: 0.0086\n",
      "Epoch 1698/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 8.6202e-05 - val_loss: 0.0054\n",
      "Epoch 1699/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 8.6214e-05 - val_loss: 0.0069\n",
      "Epoch 1700/2000\n",
      "3811/3811 [==============================] - 3s 661us/step - loss: 8.5299e-05 - val_loss: 0.0077\n",
      "Epoch 1701/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 8.4060e-05 - val_loss: 0.0057\n",
      "Epoch 1702/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 8.3603e-05 - val_loss: 0.0059\n",
      "Epoch 1703/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 8.2251e-05 - val_loss: 0.0045\n",
      "Epoch 1704/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 8.1884e-05 - val_loss: 0.0074\n",
      "Epoch 1705/2000\n",
      "3811/3811 [==============================] - 3s 662us/step - loss: 8.4631e-05 - val_loss: 0.0061\n",
      "Epoch 1706/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 8.5170e-05 - val_loss: 0.0062\n",
      "Epoch 1707/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 8.9330e-05 - val_loss: 0.0081\n",
      "Epoch 1708/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 8.8315e-05 - val_loss: 0.0082\n",
      "Epoch 1709/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 8.9831e-05 - val_loss: 0.0072\n",
      "Epoch 1710/2000\n",
      "3811/3811 [==============================] - 3s 666us/step - loss: 9.9973e-05 - val_loss: 0.0069\n",
      "Epoch 1711/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 9.5094e-05 - val_loss: 0.0069\n",
      "Epoch 1712/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 9.5050e-05 - val_loss: 0.0076\n",
      "Epoch 1713/2000\n",
      "3811/3811 [==============================] - 3s 670us/step - loss: 9.0383e-05 - val_loss: 0.0051\n",
      "Epoch 1714/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 8.6948e-05 - val_loss: 0.0066\n",
      "Epoch 1715/2000\n",
      "3811/3811 [==============================] - 3s 662us/step - loss: 8.1512e-05 - val_loss: 0.0050\n",
      "Epoch 1716/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 7.7310e-05 - val_loss: 0.0061\n",
      "Epoch 1717/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 7.5729e-05 - val_loss: 0.0060\n",
      "Epoch 1718/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 7.8190e-05 - val_loss: 0.0066\n",
      "Epoch 1719/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 7.9125e-05 - val_loss: 0.0078\n",
      "Epoch 1720/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 8.0245e-05 - val_loss: 0.0066\n",
      "Epoch 1721/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 8.1108e-05 - val_loss: 0.0064\n",
      "Epoch 1722/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 8.5642e-05 - val_loss: 0.0072\n",
      "Epoch 1723/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 8.7739e-05 - val_loss: 0.0062\n",
      "Epoch 1724/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 8.3367e-05 - val_loss: 0.0069\n",
      "Epoch 1725/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 8.5537e-05 - val_loss: 0.0041\n",
      "Epoch 1726/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 642us/step - loss: 8.0889e-05 - val_loss: 0.0060\n",
      "Epoch 1727/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 7.9248e-05 - val_loss: 0.0054\n",
      "Epoch 1728/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 7.8681e-05 - val_loss: 0.0066\n",
      "Epoch 1729/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 7.7705e-05 - val_loss: 0.0071\n",
      "Epoch 1730/2000\n",
      "3811/3811 [==============================] - 3s 662us/step - loss: 7.9213e-05 - val_loss: 0.0069\n",
      "Epoch 1731/2000\n",
      "3811/3811 [==============================] - 3s 703us/step - loss: 7.6263e-05 - val_loss: 0.0075\n",
      "Epoch 1732/2000\n",
      "3811/3811 [==============================] - 3s 677us/step - loss: 8.1888e-05 - val_loss: 0.0062\n",
      "Epoch 1733/2000\n",
      "3811/3811 [==============================] - 3s 664us/step - loss: 7.8834e-05 - val_loss: 0.0069\n",
      "Epoch 1734/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 7.5297e-05 - val_loss: 0.0065\n",
      "Epoch 1735/2000\n",
      "3811/3811 [==============================] - 3s 660us/step - loss: 7.7943e-05 - val_loss: 0.0077\n",
      "Epoch 1736/2000\n",
      "3811/3811 [==============================] - 3s 657us/step - loss: 7.2735e-05 - val_loss: 0.0060\n",
      "Epoch 1737/2000\n",
      "3811/3811 [==============================] - 3s 665us/step - loss: 8.1818e-05 - val_loss: 0.0059\n",
      "Epoch 1738/2000\n",
      "3811/3811 [==============================] - 3s 662us/step - loss: 8.3530e-05 - val_loss: 0.0069\n",
      "Epoch 1739/2000\n",
      "3811/3811 [==============================] - 3s 664us/step - loss: 8.1783e-05 - val_loss: 0.0058\n",
      "Epoch 1740/2000\n",
      "3811/3811 [==============================] - 3s 663us/step - loss: 8.6025e-05 - val_loss: 0.0068\n",
      "Epoch 1741/2000\n",
      "3811/3811 [==============================] - 3s 669us/step - loss: 8.4100e-05 - val_loss: 0.0059\n",
      "Epoch 1742/2000\n",
      "3811/3811 [==============================] - 3s 667us/step - loss: 8.4051e-05 - val_loss: 0.0047\n",
      "Epoch 1743/2000\n",
      "3811/3811 [==============================] - 3s 661us/step - loss: 8.2179e-05 - val_loss: 0.0072\n",
      "Epoch 1744/2000\n",
      "3811/3811 [==============================] - 3s 660us/step - loss: 8.4825e-05 - val_loss: 0.0047\n",
      "Epoch 1745/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 7.8039e-05 - val_loss: 0.0060\n",
      "Epoch 1746/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 8.0934e-05 - val_loss: 0.0058\n",
      "Epoch 1747/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 7.6597e-05 - val_loss: 0.0052\n",
      "Epoch 1748/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 7.6117e-05 - val_loss: 0.0054\n",
      "Epoch 1749/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 7.4911e-05 - val_loss: 0.0059\n",
      "Epoch 1750/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 7.0788e-05 - val_loss: 0.0068\n",
      "Epoch 1751/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 8.3658e-05 - val_loss: 0.0047\n",
      "Epoch 1752/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 8.2678e-05 - val_loss: 0.0076\n",
      "Epoch 1753/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 8.3676e-05 - val_loss: 0.0065\n",
      "Epoch 1754/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 7.6195e-05 - val_loss: 0.0064\n",
      "Epoch 1755/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 8.2425e-05 - val_loss: 0.0039\n",
      "Epoch 1756/2000\n",
      "3811/3811 [==============================] - 3s 662us/step - loss: 8.0344e-05 - val_loss: 0.0054\n",
      "Epoch 1757/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 7.8096e-05 - val_loss: 0.0079\n",
      "Epoch 1758/2000\n",
      "3811/3811 [==============================] - 3s 668us/step - loss: 7.8008e-05 - val_loss: 0.0052\n",
      "Epoch 1759/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 7.5524e-05 - val_loss: 0.0065\n",
      "Epoch 1760/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 7.5355e-05 - val_loss: 0.0065\n",
      "Epoch 1761/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 7.2310e-05 - val_loss: 0.0066\n",
      "Epoch 1762/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 7.2972e-05 - val_loss: 0.0057\n",
      "Epoch 1763/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 7.1750e-05 - val_loss: 0.0062\n",
      "Epoch 1764/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 7.4841e-05 - val_loss: 0.0060\n",
      "Epoch 1765/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 7.4197e-05 - val_loss: 0.0077\n",
      "Epoch 1766/2000\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 7.1688e-05 - val_loss: 0.0058\n",
      "Epoch 1767/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 7.3985e-05 - val_loss: 0.0063\n",
      "Epoch 1768/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 6.9741e-05 - val_loss: 0.0066\n",
      "Epoch 1769/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 7.7695e-05 - val_loss: 0.0069\n",
      "Epoch 1770/2000\n",
      "3811/3811 [==============================] - 3s 671us/step - loss: 7.1111e-05 - val_loss: 0.0053\n",
      "Epoch 1771/2000\n",
      "3811/3811 [==============================] - 2s 656us/step - loss: 7.4141e-05 - val_loss: 0.0083\n",
      "Epoch 1772/2000\n",
      "3811/3811 [==============================] - 3s 680us/step - loss: 6.9874e-05 - val_loss: 0.0061\n",
      "Epoch 1773/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 7.6007e-05 - val_loss: 0.0070\n",
      "Epoch 1774/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 7.6287e-05 - val_loss: 0.0076\n",
      "Epoch 1775/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 7.5010e-05 - val_loss: 0.0071\n",
      "Epoch 1776/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 7.4677e-05 - val_loss: 0.0068\n",
      "Epoch 1777/2000\n",
      "3811/3811 [==============================] - 2s 656us/step - loss: 7.7245e-05 - val_loss: 0.0074\n",
      "Epoch 1778/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 8.0347e-05 - val_loss: 0.0065\n",
      "Epoch 1779/2000\n",
      "3811/3811 [==============================] - 2s 639us/step - loss: 7.5260e-05 - val_loss: 0.0060\n",
      "Epoch 1780/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 7.4890e-05 - val_loss: 0.0073\n",
      "Epoch 1781/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 7.4542e-05 - val_loss: 0.0057\n",
      "Epoch 1782/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 7.1936e-05 - val_loss: 0.0068\n",
      "Epoch 1783/2000\n",
      "3811/3811 [==============================] - 3s 669us/step - loss: 6.9805e-05 - val_loss: 0.0062\n",
      "Epoch 1784/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 7.0538e-05 - val_loss: 0.0053\n",
      "Epoch 1785/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 7.9068e-05 - val_loss: 0.0073\n",
      "Epoch 1786/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 8.2119e-05 - val_loss: 0.0048\n",
      "Epoch 1787/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 8.5064e-05 - val_loss: 0.0049\n",
      "Epoch 1788/2000\n",
      "3811/3811 [==============================] - 3s 674us/step - loss: 8.6132e-05 - val_loss: 0.0058\n",
      "Epoch 1789/2000\n",
      "3811/3811 [==============================] - 2s 637us/step - loss: 8.1381e-05 - val_loss: 0.0079\n",
      "Epoch 1790/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 7.2477e-05 - val_loss: 0.0061\n",
      "Epoch 1791/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 7.4521e-05 - val_loss: 0.0055\n",
      "Epoch 1792/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 7.2466e-05 - val_loss: 0.0067\n",
      "Epoch 1793/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 6.9116e-05 - val_loss: 0.0075\n",
      "Epoch 1794/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 7.0682e-05 - val_loss: 0.0066\n",
      "Epoch 1795/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 7.1981e-05 - val_loss: 0.0061\n",
      "Epoch 1796/2000\n",
      "3811/3811 [==============================] - 3s 657us/step - loss: 6.9149e-05 - val_loss: 0.0069\n",
      "Epoch 1797/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 7.3447e-05 - val_loss: 0.0065\n",
      "Epoch 1798/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 644us/step - loss: 7.3537e-05 - val_loss: 0.0078\n",
      "Epoch 1799/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 7.3057e-05 - val_loss: 0.0048\n",
      "Epoch 1800/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 7.3844e-05 - val_loss: 0.0059\n",
      "Epoch 1801/2000\n",
      "3811/3811 [==============================] - 3s 670us/step - loss: 7.8530e-05 - val_loss: 0.0046\n",
      "Epoch 1802/2000\n",
      "3811/3811 [==============================] - 3s 683us/step - loss: 7.6942e-05 - val_loss: 0.0056\n",
      "Epoch 1803/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 7.8613e-05 - val_loss: 0.0054\n",
      "Epoch 1804/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 8.2304e-05 - val_loss: 0.0068\n",
      "Epoch 1805/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 7.5476e-05 - val_loss: 0.0054\n",
      "Epoch 1806/2000\n",
      "3811/3811 [==============================] - 3s 660us/step - loss: 7.2786e-05 - val_loss: 0.0051\n",
      "Epoch 1807/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 7.1216e-05 - val_loss: 0.0045\n",
      "Epoch 1808/2000\n",
      "3811/3811 [==============================] - 2s 654us/step - loss: 7.0532e-05 - val_loss: 0.0053\n",
      "Epoch 1809/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 6.7738e-05 - val_loss: 0.0059\n",
      "Epoch 1810/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 6.7911e-05 - val_loss: 0.0058\n",
      "Epoch 1811/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 6.9655e-05 - val_loss: 0.0061\n",
      "Epoch 1812/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 7.0456e-05 - val_loss: 0.0082\n",
      "Epoch 1813/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 7.2147e-05 - val_loss: 0.0047\n",
      "Epoch 1814/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 7.4801e-05 - val_loss: 0.0057\n",
      "Epoch 1815/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 7.5990e-05 - val_loss: 0.0061\n",
      "Epoch 1816/2000\n",
      "3811/3811 [==============================] - 3s 669us/step - loss: 7.3878e-05 - val_loss: 0.0059\n",
      "Epoch 1817/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 7.3290e-05 - val_loss: 0.0056\n",
      "Epoch 1818/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 7.0360e-05 - val_loss: 0.0090\n",
      "Epoch 1819/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 7.9720e-05 - val_loss: 0.0050\n",
      "Epoch 1820/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 7.9811e-05 - val_loss: 0.0061\n",
      "Epoch 1821/2000\n",
      "3811/3811 [==============================] - 3s 661us/step - loss: 7.3546e-05 - val_loss: 0.0061\n",
      "Epoch 1822/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 7.6101e-05 - val_loss: 0.0070\n",
      "Epoch 1823/2000\n",
      "3811/3811 [==============================] - 3s 685us/step - loss: 6.9843e-05 - val_loss: 0.0068\n",
      "Epoch 1824/2000\n",
      "3811/3811 [==============================] - 3s 674us/step - loss: 7.0367e-05 - val_loss: 0.0059\n",
      "Epoch 1825/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 6.9338e-05 - val_loss: 0.0056\n",
      "Epoch 1826/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 7.3254e-05 - val_loss: 0.0054\n",
      "Epoch 1827/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 8.5160e-05 - val_loss: 0.0056\n",
      "Epoch 1828/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 8.2430e-05 - val_loss: 0.0056\n",
      "Epoch 1829/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 8.8201e-05 - val_loss: 0.0063\n",
      "Epoch 1830/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 8.9723e-05 - val_loss: 0.0070\n",
      "Epoch 1831/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 7.9603e-05 - val_loss: 0.0072\n",
      "Epoch 1832/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 8.2024e-05 - val_loss: 0.0057\n",
      "Epoch 1833/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 7.8453e-05 - val_loss: 0.0060\n",
      "Epoch 1834/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 7.5676e-05 - val_loss: 0.0065\n",
      "Epoch 1835/2000\n",
      "3811/3811 [==============================] - 3s 677us/step - loss: 7.4675e-05 - val_loss: 0.0067\n",
      "Epoch 1836/2000\n",
      "3811/3811 [==============================] - 3s 697us/step - loss: 7.4074e-05 - val_loss: 0.0064\n",
      "Epoch 1837/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 6.9369e-05 - val_loss: 0.0076\n",
      "Epoch 1838/2000\n",
      "3811/3811 [==============================] - 3s 662us/step - loss: 6.9190e-05 - val_loss: 0.0064\n",
      "Epoch 1839/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 6.7975e-05 - val_loss: 0.0070\n",
      "Epoch 1840/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 6.9915e-05 - val_loss: 0.0065\n",
      "Epoch 1841/2000\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 7.1761e-05 - val_loss: 0.0058\n",
      "Epoch 1842/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 6.7249e-05 - val_loss: 0.0065\n",
      "Epoch 1843/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 6.7377e-05 - val_loss: 0.0062\n",
      "Epoch 1844/2000\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 6.7245e-05 - val_loss: 0.0066\n",
      "Epoch 1845/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 6.3361e-05 - val_loss: 0.0061\n",
      "Epoch 1846/2000\n",
      "3811/3811 [==============================] - 3s 665us/step - loss: 6.9682e-05 - val_loss: 0.0060\n",
      "Epoch 1847/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 7.3766e-05 - val_loss: 0.0057\n",
      "Epoch 1848/2000\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 6.8718e-05 - val_loss: 0.0068\n",
      "Epoch 1849/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 6.8989e-05 - val_loss: 0.0059\n",
      "Epoch 1850/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 7.4727e-05 - val_loss: 0.0067\n",
      "Epoch 1851/2000\n",
      "3811/3811 [==============================] - 3s 667us/step - loss: 8.5236e-05 - val_loss: 0.0055\n",
      "Epoch 1852/2000\n",
      "3811/3811 [==============================] - 3s 674us/step - loss: 8.8383e-05 - val_loss: 0.0057\n",
      "Epoch 1853/2000\n",
      "3811/3811 [==============================] - 3s 670us/step - loss: 8.0658e-05 - val_loss: 0.0063\n",
      "Epoch 1854/2000\n",
      "3811/3811 [==============================] - 3s 663us/step - loss: 7.6975e-05 - val_loss: 0.0064\n",
      "Epoch 1855/2000\n",
      "3811/3811 [==============================] - 2s 656us/step - loss: 7.1211e-05 - val_loss: 0.0061\n",
      "Epoch 1856/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 7.1143e-05 - val_loss: 0.0045\n",
      "Epoch 1857/2000\n",
      "3811/3811 [==============================] - 2s 656us/step - loss: 7.0681e-05 - val_loss: 0.0063\n",
      "Epoch 1858/2000\n",
      "3811/3811 [==============================] - 3s 669us/step - loss: 7.0728e-05 - val_loss: 0.0051\n",
      "Epoch 1859/2000\n",
      "3811/3811 [==============================] - 3s 666us/step - loss: 6.2931e-05 - val_loss: 0.0051\n",
      "Epoch 1860/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 6.4271e-05 - val_loss: 0.0073\n",
      "Epoch 1861/2000\n",
      "3811/3811 [==============================] - 3s 669us/step - loss: 6.6319e-05 - val_loss: 0.0058\n",
      "Epoch 1862/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 6.8097e-05 - val_loss: 0.0063\n",
      "Epoch 1863/2000\n",
      "3811/3811 [==============================] - 3s 678us/step - loss: 7.2296e-05 - val_loss: 0.0077\n",
      "Epoch 1864/2000\n",
      "3811/3811 [==============================] - 3s 683us/step - loss: 7.4445e-05 - val_loss: 0.0055\n",
      "Epoch 1865/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 7.2216e-05 - val_loss: 0.0067\n",
      "Epoch 1866/2000\n",
      "3811/3811 [==============================] - 3s 668us/step - loss: 7.0402e-05 - val_loss: 0.0055\n",
      "Epoch 1867/2000\n",
      "3811/3811 [==============================] - 3s 661us/step - loss: 7.2783e-05 - val_loss: 0.0062\n",
      "Epoch 1868/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 6.5831e-05 - val_loss: 0.0056\n",
      "Epoch 1869/2000\n",
      "3811/3811 [==============================] - 3s 665us/step - loss: 6.9503e-05 - val_loss: 0.0069\n",
      "Epoch 1870/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 3s 672us/step - loss: 7.0992e-05 - val_loss: 0.0058\n",
      "Epoch 1871/2000\n",
      "3811/3811 [==============================] - 3s 672us/step - loss: 7.3107e-05 - val_loss: 0.0085\n",
      "Epoch 1872/2000\n",
      "3811/3811 [==============================] - 3s 669us/step - loss: 7.8882e-05 - val_loss: 0.0084\n",
      "Epoch 1873/2000\n",
      "3811/3811 [==============================] - 3s 666us/step - loss: 7.6379e-05 - val_loss: 0.0070\n",
      "Epoch 1874/2000\n",
      "3811/3811 [==============================] - 2s 654us/step - loss: 7.5291e-05 - val_loss: 0.0058\n",
      "Epoch 1875/2000\n",
      "3811/3811 [==============================] - 3s 663us/step - loss: 7.5668e-05 - val_loss: 0.0072\n",
      "Epoch 1876/2000\n",
      "3811/3811 [==============================] - 2s 654us/step - loss: 6.9056e-05 - val_loss: 0.0059\n",
      "Epoch 1877/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 6.5579e-05 - val_loss: 0.0059\n",
      "Epoch 1878/2000\n",
      "3811/3811 [==============================] - 3s 663us/step - loss: 6.6309e-05 - val_loss: 0.0065\n",
      "Epoch 1879/2000\n",
      "3811/3811 [==============================] - 3s 667us/step - loss: 6.7227e-05 - val_loss: 0.0062\n",
      "Epoch 1880/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 7.1205e-05 - val_loss: 0.0060\n",
      "Epoch 1881/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 6.8771e-05 - val_loss: 0.0063\n",
      "Epoch 1882/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 6.9894e-05 - val_loss: 0.0064\n",
      "Epoch 1883/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 6.9360e-05 - val_loss: 0.0060\n",
      "Epoch 1884/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 6.6229e-05 - val_loss: 0.0063\n",
      "Epoch 1885/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 6.6074e-05 - val_loss: 0.0062\n",
      "Epoch 1886/2000\n",
      "3811/3811 [==============================] - 3s 664us/step - loss: 6.8022e-05 - val_loss: 0.0054\n",
      "Epoch 1887/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 7.2803e-05 - val_loss: 0.0064\n",
      "Epoch 1888/2000\n",
      "3811/3811 [==============================] - 3s 672us/step - loss: 6.3175e-05 - val_loss: 0.0053\n",
      "Epoch 1889/2000\n",
      "3811/3811 [==============================] - 3s 665us/step - loss: 6.4956e-05 - val_loss: 0.0050\n",
      "Epoch 1890/2000\n",
      "3811/3811 [==============================] - 3s 669us/step - loss: 6.2889e-05 - val_loss: 0.0053\n",
      "Epoch 1891/2000\n",
      "3811/3811 [==============================] - 3s 662us/step - loss: 6.4580e-05 - val_loss: 0.0062\n",
      "Epoch 1892/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 6.3919e-05 - val_loss: 0.0062\n",
      "Epoch 1893/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 6.8662e-05 - val_loss: 0.0048\n",
      "Epoch 1894/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 7.1558e-05 - val_loss: 0.0052\n",
      "Epoch 1895/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 7.3401e-05 - val_loss: 0.0049\n",
      "Epoch 1896/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 7.1962e-05 - val_loss: 0.0086\n",
      "Epoch 1897/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 7.3933e-05 - val_loss: 0.0048\n",
      "Epoch 1898/2000\n",
      "3811/3811 [==============================] - 3s 661us/step - loss: 6.8356e-05 - val_loss: 0.0056\n",
      "Epoch 1899/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 6.6960e-05 - val_loss: 0.0063\n",
      "Epoch 1900/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 6.6965e-05 - val_loss: 0.0063\n",
      "Epoch 1901/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 6.6069e-05 - val_loss: 0.0059\n",
      "Epoch 1902/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 6.3961e-05 - val_loss: 0.0060\n",
      "Epoch 1903/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 6.5106e-05 - val_loss: 0.0063\n",
      "Epoch 1904/2000\n",
      "3811/3811 [==============================] - 3s 665us/step - loss: 6.2254e-05 - val_loss: 0.0063\n",
      "Epoch 1905/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 6.5448e-05 - val_loss: 0.0062\n",
      "Epoch 1906/2000\n",
      "3811/3811 [==============================] - 2s 654us/step - loss: 6.2781e-05 - val_loss: 0.0064\n",
      "Epoch 1907/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 6.2952e-05 - val_loss: 0.0060\n",
      "Epoch 1908/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 6.4962e-05 - val_loss: 0.0065\n",
      "Epoch 1909/2000\n",
      "3811/3811 [==============================] - 3s 669us/step - loss: 6.4249e-05 - val_loss: 0.0062\n",
      "Epoch 1910/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 6.7145e-05 - val_loss: 0.0050\n",
      "Epoch 1911/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 6.9885e-05 - val_loss: 0.0062\n",
      "Epoch 1912/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 7.1499e-05 - val_loss: 0.0066\n",
      "Epoch 1913/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 6.5937e-05 - val_loss: 0.0055\n",
      "Epoch 1914/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 6.5572e-05 - val_loss: 0.0072\n",
      "Epoch 1915/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 6.2778e-05 - val_loss: 0.0070\n",
      "Epoch 1916/2000\n",
      "3811/3811 [==============================] - 3s 678us/step - loss: 6.0850e-05 - val_loss: 0.0061\n",
      "Epoch 1917/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 6.1018e-05 - val_loss: 0.0052\n",
      "Epoch 1918/2000\n",
      "3811/3811 [==============================] - 3s 668us/step - loss: 6.2758e-05 - val_loss: 0.0085\n",
      "Epoch 1919/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 6.3480e-05 - val_loss: 0.0058\n",
      "Epoch 1920/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 6.3035e-05 - val_loss: 0.0064\n",
      "Epoch 1921/2000\n",
      "3811/3811 [==============================] - 3s 664us/step - loss: 6.2377e-05 - val_loss: 0.0058\n",
      "Epoch 1922/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 6.1407e-05 - val_loss: 0.0059\n",
      "Epoch 1923/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 6.1979e-05 - val_loss: 0.0057\n",
      "Epoch 1924/2000\n",
      "3811/3811 [==============================] - 3s 660us/step - loss: 6.3491e-05 - val_loss: 0.0060\n",
      "Epoch 1925/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 6.5003e-05 - val_loss: 0.0048\n",
      "Epoch 1926/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 6.6323e-05 - val_loss: 0.0063\n",
      "Epoch 1927/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 6.0847e-05 - val_loss: 0.0052\n",
      "Epoch 1928/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 6.3826e-05 - val_loss: 0.0067\n",
      "Epoch 1929/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 5.9523e-05 - val_loss: 0.0061\n",
      "Epoch 1930/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 6.2220e-05 - val_loss: 0.0064\n",
      "Epoch 1931/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 6.4810e-05 - val_loss: 0.0059\n",
      "Epoch 1932/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 8.4417e-05 - val_loss: 0.0078\n",
      "Epoch 1933/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 7.8139e-05 - val_loss: 0.0051\n",
      "Epoch 1934/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 8.7429e-05 - val_loss: 0.0052\n",
      "Epoch 1935/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 2.0674e-04 - val_loss: 0.0037\n",
      "Epoch 1936/2000\n",
      "3811/3811 [==============================] - 2s 654us/step - loss: 3.1225e-04 - val_loss: 0.0095\n",
      "Epoch 1937/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 2.2885e-04 - val_loss: 0.0075\n",
      "Epoch 1938/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 1.6231e-04 - val_loss: 0.0090\n",
      "Epoch 1939/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 1.3684e-04 - val_loss: 0.0057\n",
      "Epoch 1940/2000\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 1.2205e-04 - val_loss: 0.0100\n",
      "Epoch 1941/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 1.0812e-04 - val_loss: 0.0039\n",
      "Epoch 1942/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3811/3811 [==============================] - 2s 644us/step - loss: 1.0293e-04 - val_loss: 0.0076\n",
      "Epoch 1943/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 8.4372e-05 - val_loss: 0.0060\n",
      "Epoch 1944/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 8.3176e-05 - val_loss: 0.0053\n",
      "Epoch 1945/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 7.9404e-05 - val_loss: 0.0051\n",
      "Epoch 1946/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 7.4983e-05 - val_loss: 0.0054\n",
      "Epoch 1947/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 7.3210e-05 - val_loss: 0.0051\n",
      "Epoch 1948/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 7.2630e-05 - val_loss: 0.0055\n",
      "Epoch 1949/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 6.6997e-05 - val_loss: 0.0047\n",
      "Epoch 1950/2000\n",
      "3811/3811 [==============================] - 2s 646us/step - loss: 7.2146e-05 - val_loss: 0.0052\n",
      "Epoch 1951/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 6.8212e-05 - val_loss: 0.0052\n",
      "Epoch 1952/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 6.5042e-05 - val_loss: 0.0048\n",
      "Epoch 1953/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 6.5424e-05 - val_loss: 0.0056\n",
      "Epoch 1954/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 6.6570e-05 - val_loss: 0.0057\n",
      "Epoch 1955/2000\n",
      "3811/3811 [==============================] - 2s 650us/step - loss: 6.6750e-05 - val_loss: 0.0052\n",
      "Epoch 1956/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 6.4963e-05 - val_loss: 0.0045\n",
      "Epoch 1957/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 6.6329e-05 - val_loss: 0.0051\n",
      "Epoch 1958/2000\n",
      "3811/3811 [==============================] - 3s 660us/step - loss: 7.2390e-05 - val_loss: 0.0052\n",
      "Epoch 1959/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 7.0543e-05 - val_loss: 0.0049\n",
      "Epoch 1960/2000\n",
      "3811/3811 [==============================] - 2s 654us/step - loss: 6.9953e-05 - val_loss: 0.0043\n",
      "Epoch 1961/2000\n",
      "3811/3811 [==============================] - 3s 657us/step - loss: 7.1302e-05 - val_loss: 0.0042\n",
      "Epoch 1962/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 6.5669e-05 - val_loss: 0.0044\n",
      "Epoch 1963/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 6.4925e-05 - val_loss: 0.0050\n",
      "Epoch 1964/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 6.7542e-05 - val_loss: 0.0052\n",
      "Epoch 1965/2000\n",
      "3811/3811 [==============================] - 3s 666us/step - loss: 6.5280e-05 - val_loss: 0.0045\n",
      "Epoch 1966/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 6.9902e-05 - val_loss: 0.0049\n",
      "Epoch 1967/2000\n",
      "3811/3811 [==============================] - 2s 655us/step - loss: 6.9000e-05 - val_loss: 0.0049\n",
      "Epoch 1968/2000\n",
      "3811/3811 [==============================] - 3s 665us/step - loss: 7.0692e-05 - val_loss: 0.0048\n",
      "Epoch 1969/2000\n",
      "3811/3811 [==============================] - 3s 668us/step - loss: 6.8480e-05 - val_loss: 0.0051\n",
      "Epoch 1970/2000\n",
      "3811/3811 [==============================] - 3s 658us/step - loss: 6.3537e-05 - val_loss: 0.0046\n",
      "Epoch 1971/2000\n",
      "3811/3811 [==============================] - 3s 656us/step - loss: 6.6060e-05 - val_loss: 0.0057\n",
      "Epoch 1972/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 6.3026e-05 - val_loss: 0.0046\n",
      "Epoch 1973/2000\n",
      "3811/3811 [==============================] - 2s 648us/step - loss: 6.5523e-05 - val_loss: 0.0049\n",
      "Epoch 1974/2000\n",
      "3811/3811 [==============================] - 3s 659us/step - loss: 6.8461e-05 - val_loss: 0.0052\n",
      "Epoch 1975/2000\n",
      "3811/3811 [==============================] - 3s 661us/step - loss: 6.5979e-05 - val_loss: 0.0047\n",
      "Epoch 1976/2000\n",
      "3811/3811 [==============================] - 3s 661us/step - loss: 6.7537e-05 - val_loss: 0.0046\n",
      "Epoch 1977/2000\n",
      "3811/3811 [==============================] - 2s 653us/step - loss: 6.9419e-05 - val_loss: 0.0057\n",
      "Epoch 1978/2000\n",
      "3811/3811 [==============================] - 2s 649us/step - loss: 6.6962e-05 - val_loss: 0.0050\n",
      "Epoch 1979/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 7.1135e-05 - val_loss: 0.0058\n",
      "Epoch 1980/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 7.0223e-05 - val_loss: 0.0058\n",
      "Epoch 1981/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 6.1548e-05 - val_loss: 0.0061\n",
      "Epoch 1982/2000\n",
      "3811/3811 [==============================] - 2s 640us/step - loss: 6.7338e-05 - val_loss: 0.0052\n",
      "Epoch 1983/2000\n",
      "3811/3811 [==============================] - 2s 641us/step - loss: 7.5472e-05 - val_loss: 0.0058\n",
      "Epoch 1984/2000\n",
      "3811/3811 [==============================] - 2s 647us/step - loss: 7.0937e-05 - val_loss: 0.0052\n",
      "Epoch 1985/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 6.9438e-05 - val_loss: 0.0061\n",
      "Epoch 1986/2000\n",
      "3811/3811 [==============================] - 2s 644us/step - loss: 6.7291e-05 - val_loss: 0.0055\n",
      "Epoch 1987/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 6.6464e-05 - val_loss: 0.0057\n",
      "Epoch 1988/2000\n",
      "3811/3811 [==============================] - 2s 651us/step - loss: 6.1401e-05 - val_loss: 0.0054\n",
      "Epoch 1989/2000\n",
      "3811/3811 [==============================] - 2s 645us/step - loss: 5.6848e-05 - val_loss: 0.0052\n",
      "Epoch 1990/2000\n",
      "3811/3811 [==============================] - 2s 643us/step - loss: 5.7560e-05 - val_loss: 0.0058\n",
      "Epoch 1991/2000\n",
      "3811/3811 [==============================] - 2s 652us/step - loss: 5.7081e-05 - val_loss: 0.0057\n",
      "Epoch 1992/2000\n",
      "3811/3811 [==============================] - 2s 642us/step - loss: 5.7758e-05 - val_loss: 0.0055\n",
      "Epoch 1993/2000\n",
      "3811/3811 [==============================] - 3s 663us/step - loss: 5.8102e-05 - val_loss: 0.0050\n",
      "Epoch 1994/2000\n",
      "3811/3811 [==============================] - 3s 668us/step - loss: 5.9107e-05 - val_loss: 0.0053\n",
      "Epoch 1995/2000\n",
      "3811/3811 [==============================] - 3s 675us/step - loss: 5.8635e-05 - val_loss: 0.0045\n",
      "Epoch 1996/2000\n",
      "3811/3811 [==============================] - 3s 672us/step - loss: 6.1977e-05 - val_loss: 0.0047\n",
      "Epoch 1997/2000\n",
      "3811/3811 [==============================] - 3s 683us/step - loss: 5.9405e-05 - val_loss: 0.0048\n",
      "Epoch 1998/2000\n",
      "3811/3811 [==============================] - 3s 682us/step - loss: 5.9261e-05 - val_loss: 0.0043\n",
      "Epoch 1999/2000\n",
      "3811/3811 [==============================] - 3s 673us/step - loss: 5.8735e-05 - val_loss: 0.0048\n",
      "Epoch 2000/2000\n",
      "3811/3811 [==============================] - 3s 674us/step - loss: 5.9978e-05 - val_loss: 0.0047\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstmsize': 178,\n",
       " 'twice': True,\n",
       " 'full_density': True,\n",
       " 'density': 142,\n",
       " 'dropout': 0.1,\n",
       " 'optimizer': 'adam',\n",
       " 'activation': 'softsign',\n",
       " 'shuffle': True,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x1bcc56f0d48>]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_183\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_365 (LSTM)              (None, 92, 178)           131008    \n",
      "_________________________________________________________________\n",
      "dropout_363 (Dropout)        (None, 92, 178)           0         \n",
      "_________________________________________________________________\n",
      "lstm_366 (LSTM)              (None, 178)               254184    \n",
      "_________________________________________________________________\n",
      "dropout_364 (Dropout)        (None, 178)               0         \n",
      "_________________________________________________________________\n",
      "dense_934 (Dense)            (None, 142)               25418     \n",
      "_________________________________________________________________\n",
      "dense_935 (Dense)            (None, 71)                10153     \n",
      "_________________________________________________________________\n",
      "dense_936 (Dense)            (None, 35)                2520      \n",
      "_________________________________________________________________\n",
      "dense_937 (Dense)            (None, 17)                612       \n",
      "_________________________________________________________________\n",
      "dense_938 (Dense)            (None, 1)                 18        \n",
      "=================================================================\n",
      "Total params: 423,913\n",
      "Trainable params: 423,913\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_5days/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 28.55\n",
      "Medium error is 4.28\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 63.33%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 56.25%\n",
      "Accuracy for downward trend is: 71.43%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 60 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(60), true_y_test)\n",
    "plt.plot(range(60), predicted_y_test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last 20 days + prediction of last 10 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(20), true_y_test[-20:])\n",
    "plt.plot(range(20), np.append(true_y_test[-20:-10], predicted_y_test[-10:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
