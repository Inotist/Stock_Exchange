{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "normaliser = preprocessing.MinMaxScaler()\n",
    "data_norm = normaliser.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised chunks\n",
    "historical_sequences_norm = np.array([data_norm[i : i + backlook].copy() for i in range(len(data_norm) - backlook)])\n",
    "next_day_open_values_norm = np.array([data_norm[:,0][i + backlook].copy() for i in range(len(data_norm) - backlook)])\n",
    "next_day_open_values_norm = np.expand_dims(next_day_open_values_norm, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3303677 ],\n",
       "       [0.32881229],\n",
       "       [0.33814471],\n",
       "       ...,\n",
       "       [0.44689853],\n",
       "       [0.43681951],\n",
       "       [0.44279226]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y raw data\n",
    "next_day_open_values = np.array([data.to_numpy()[:,0][i + backlook].copy() for i in range(len(data) - backlook)])\n",
    "next_day_open_values = np.expand_dims(next_day_open_values, -1)\n",
    "\n",
    "# Y normaliser\n",
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "y_normaliser.fit_transform(next_day_open_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(historical_sequences_norm.shape[0] * train_size)\n",
    "\n",
    "X_train = historical_sequences_norm[:split]\n",
    "Y_train = next_day_open_values_norm[:split]\n",
    "\n",
    "X_test = historical_sequences_norm[split:]\n",
    "Y_test = next_day_open_values_norm[split:]\n",
    "unscaled_y_test = next_day_open_values[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 2s 408us/step - loss: 0.1251 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 159us/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 159us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 162us/step - loss: 0.0037 - val_loss: 6.2091e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 160us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 159us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 161us/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 159us/step - loss: 0.0045 - val_loss: 0.0138\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 161us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 159us/step - loss: 0.0025 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 160us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 162us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 159us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 158us/step - loss: 0.0016 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 161us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 167us/step - loss: 0.0033 - val_loss: 0.0049\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 164us/step - loss: 0.0026 - val_loss: 0.0061\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 160us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 160us/step - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 162us/step - loss: 0.0027 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 162us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 159us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 165us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 161us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.1134 - val_loss: 0.0133\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 331us/step - loss: 0.0169 - val_loss: 0.0181\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 332us/step - loss: 0.0151 - val_loss: 0.0122\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 332us/step - loss: 0.0098 - val_loss: 0.0127\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 348us/step - loss: 0.0081 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 351us/step - loss: 0.0053 - val_loss: 0.0080\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 346us/step - loss: 0.0070 - val_loss: 0.0054\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 339us/step - loss: 0.0066 - val_loss: 0.0065\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 343us/step - loss: 0.0074 - val_loss: 0.0059\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 339us/step - loss: 0.0043 - val_loss: 8.7176e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 348us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 334us/step - loss: 0.0058 - val_loss: 0.0111\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 336us/step - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 336us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 343us/step - loss: 0.0046 - val_loss: 0.0077\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 337us/step - loss: 0.0050 - val_loss: 0.0083\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 331us/step - loss: 0.0065 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 336us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 344us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 357us/step - loss: 0.0028 - val_loss: 0.0072\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 351us/step - loss: 0.0048 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 336us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 335us/step - loss: 0.0055 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 334us/step - loss: 0.0038 - val_loss: 0.0045\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.1817 - val_loss: 0.1757\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.1020 - val_loss: 0.0942\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 333us/step - loss: 0.0703 - val_loss: 0.0541\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 352us/step - loss: 0.0578 - val_loss: 0.0349\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 348us/step - loss: 0.0525 - val_loss: 0.0272\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 334us/step - loss: 0.0490 - val_loss: 0.0242\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 348us/step - loss: 0.0466 - val_loss: 0.0217\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 345us/step - loss: 0.0445 - val_loss: 0.0217\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 344us/step - loss: 0.0427 - val_loss: 0.0204\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 343us/step - loss: 0.0406 - val_loss: 0.0180\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 343us/step - loss: 0.0383 - val_loss: 0.0170\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 331us/step - loss: 0.0362 - val_loss: 0.0152\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 343us/step - loss: 0.0343 - val_loss: 0.0141\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 334us/step - loss: 0.0318 - val_loss: 0.0125\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 332us/step - loss: 0.0299 - val_loss: 0.0117\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 331us/step - loss: 0.0275 - val_loss: 0.0106\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.0249 - val_loss: 0.0085\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.0224 - val_loss: 0.0079\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 331us/step - loss: 0.0201 - val_loss: 0.0070\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 332us/step - loss: 0.0183 - val_loss: 0.0060\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 349us/step - loss: 0.0163 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 339us/step - loss: 0.0143 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 336us/step - loss: 0.0128 - val_loss: 0.0030\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 1s 339us/step - loss: 0.0111 - val_loss: 0.0024\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0387 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 343us/step - loss: 0.0164 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 356us/step - loss: 0.0122 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 364us/step - loss: 0.0084 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 331us/step - loss: 0.0068 - val_loss: 7.8017e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 329us/step - loss: 0.0054 - val_loss: 6.3327e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0051 - val_loss: 7.7232e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0045 - val_loss: 6.5197e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 327us/step - loss: 0.0044 - val_loss: 6.2224e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 326us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 324us/step - loss: 0.0039 - val_loss: 9.3758e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 323us/step - loss: 0.0038 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 323us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 324us/step - loss: 0.0038 - val_loss: 9.5698e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0035 - val_loss: 8.3264e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0036 - val_loss: 9.2087e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 323us/step - loss: 0.0035 - val_loss: 8.8786e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0034 - val_loss: 8.5017e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0037 - val_loss: 9.1543e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 324us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0030 - val_loss: 7.8125e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0031 - val_loss: 9.3990e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0031 - val_loss: 9.6355e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 3s 794us/step - loss: 1.2997 - val_loss: 0.0357\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0142 - val_loss: 0.0116\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0075 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0036 - val_loss: 7.9812e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0013 - val_loss: 8.0308e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0013 - val_loss: 8.5042e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0013 - val_loss: 9.1906e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0012 - val_loss: 7.5336e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0013 - val_loss: 8.1305e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 0.0012 - val_loss: 8.4130e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0011 - val_loss: 8.6864e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0011 - val_loss: 7.7595e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0011 - val_loss: 9.4156e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0010 - val_loss: 6.9540e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0011 - val_loss: 5.9496e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 3s 809us/step - loss: 0.9700 - val_loss: 0.0074\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0162 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0062 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0030 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0019 - val_loss: 8.3583e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0017 - val_loss: 7.7224e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0018 - val_loss: 8.1999e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0023 - val_loss: 7.7897e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0015 - val_loss: 9.5953e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0016 - val_loss: 9.0297e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 3s 835us/step - loss: 0.6673 - val_loss: 0.0603\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0665 - val_loss: 0.0503\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0559 - val_loss: 0.0278\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0597 - val_loss: 0.0061\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0409 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0162 - val_loss: 0.0446\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0116 - val_loss: 0.0057\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0040 - val_loss: 0.0115\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0040 - val_loss: 0.0175\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 0.0087 - val_loss: 0.0177\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0046 - val_loss: 0.0065\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.8325 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 329us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 326us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 335us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 329us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 326us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 329us/step - loss: 0.0016 - val_loss: 9.4562e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 326us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 326us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 327us/step - loss: 0.0014 - val_loss: 8.4143e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 331us/step - loss: 0.0014 - val_loss: 5.4368e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0012 - val_loss: 6.5853e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 2s 611us/step - loss: 1.2972 - val_loss: 0.0135\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 326us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 344us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 327us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0019 - val_loss: 7.0364e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 326us/step - loss: 0.0019 - val_loss: 9.1493e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 327us/step - loss: 0.0018 - val_loss: 6.7967e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 324us/step - loss: 0.0017 - val_loss: 8.2170e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 324us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0018 - val_loss: 6.5203e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 324us/step - loss: 0.0017 - val_loss: 6.8500e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 326us/step - loss: 0.0017 - val_loss: 6.4214e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 326us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 323us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 330us/step - loss: 0.0016 - val_loss: 7.7099e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0015 - val_loss: 6.5214e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 326us/step - loss: 0.0014 - val_loss: 7.4751e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 328us/step - loss: 0.0015 - val_loss: 9.6585e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 325us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 3s 846us/step - loss: 0.7793 - val_loss: 0.0089\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0147 - val_loss: 8.9418e-04\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0011 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.5952e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 9.8709e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 9.0943e-04 - val_loss: 8.9709e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.8784e-04 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.4083e-04 - val_loss: 5.2854e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.4802e-04 - val_loss: 7.0632e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.1122e-04 - val_loss: 8.4873e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.2105e-04 - val_loss: 7.5083e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.1309e-04 - val_loss: 9.0034e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.8620e-04 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.1914e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.6320e-04 - val_loss: 8.6927e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 7.3671e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.3061e-04 - val_loss: 9.8052e-04\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 3s 872us/step - loss: 1.2783 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0084 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0013 - val_loss: 8.5965e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 7.8396e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 3s 938us/step - loss: 0.7625 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0033 - val_loss: 0.0056\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0028 - val_loss: 0.0136\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 598us/step - loss: 0.0018 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 598us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0014 - val_loss: 9.0605e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 9.5244e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 593us/step - loss: 0.0021 - val_loss: 8.7344e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 0.0016 - val_loss: 8.9031e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 598us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 617us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 597us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 595us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0050\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0056\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 9.5259e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0011 - val_loss: 9.0540e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 3s 934us/step - loss: 1.8302 - val_loss: 0.0233\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0283 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0064 - val_loss: 0.0414\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 599us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 594us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0015 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 0.0015 - val_loss: 6.8414e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 7.5550e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0013 - val_loss: 6.5538e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0013 - val_loss: 7.4739e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 9.3278e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 0.0012 - val_loss: 6.8215e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0012 - val_loss: 9.1042e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 3s 914us/step - loss: 1.1900 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0081 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0016 - val_loss: 8.6527e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0015 - val_loss: 8.9216e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0015 - val_loss: 7.3543e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0014 - val_loss: 6.7078e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0014 - val_loss: 9.1765e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0013 - val_loss: 8.3910e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0013 - val_loss: 6.8162e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 3s 932us/step - loss: 0.6795 - val_loss: 0.0593\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0677 - val_loss: 0.0203\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0687 - val_loss: 0.0285\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0673 - val_loss: 0.0191\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0628 - val_loss: 0.0143\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0688 - val_loss: 0.0182\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0682 - val_loss: 0.0403\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0439 - val_loss: 0.1778\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0728 - val_loss: 0.0263\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0359 - val_loss: 0.0142\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0588 - val_loss: 0.0379\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0526 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0106 - val_loss: 0.0177\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0074 - val_loss: 0.0184\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0039 - val_loss: 0.0126\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0060 - val_loss: 0.0106\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0033 - val_loss: 0.0333\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0063 - val_loss: 0.0066\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0023 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0031 - val_loss: 0.0067\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 979us/step - loss: 0.4611 - val_loss: 0.0287\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0684 - val_loss: 0.0344\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0682 - val_loss: 0.0358\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0683 - val_loss: 0.0286\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0683 - val_loss: 0.0470\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0681 - val_loss: 0.0339\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0682 - val_loss: 0.0351\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0681 - val_loss: 0.0431\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0682 - val_loss: 0.0489\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0677 - val_loss: 0.0440\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0683 - val_loss: 0.0409\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0679 - val_loss: 0.0452\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0677 - val_loss: 0.0358\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0682 - val_loss: 0.0406\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0679 - val_loss: 0.0378\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0676 - val_loss: 0.0469\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0668 - val_loss: 0.0421\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0669 - val_loss: 0.0326\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0672 - val_loss: 0.0437\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0659 - val_loss: 0.0463\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0664 - val_loss: 0.0487\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0658 - val_loss: 0.0589\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0594 - val_loss: 0.0094\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0667 - val_loss: 0.0346\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 1ms/step - loss: 0.8053 - val_loss: 0.0111\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 0.0149 - val_loss: 0.0069\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0024 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0020 - val_loss: 0.0083\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0023 - val_loss: 0.0058\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0019 - val_loss: 0.0098\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0020 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0018 - val_loss: 0.0064\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0050\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0015 - val_loss: 8.1901e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0013 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 1ms/step - loss: 0.0828 - val_loss: 7.1995e-04\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0029 - val_loss: 8.1196e-04\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0021 - val_loss: 5.5077e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0021 - val_loss: 5.5763e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0036 - val_loss: 0.0138\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0131 - val_loss: 0.0181\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0080 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0033 - val_loss: 0.0135\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0109 - val_loss: 0.0071\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0073 - val_loss: 0.0119\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0073 - val_loss: 0.0094\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0076 - val_loss: 0.0114\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0067 - val_loss: 0.0142\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0075 - val_loss: 0.0063\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0075 - val_loss: 0.0075\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0052 - val_loss: 0.0081\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0067 - val_loss: 0.0129\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0073 - val_loss: 0.0078\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0054 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0041 - val_loss: 0.0083\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0066 - val_loss: 0.0102\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 1ms/step - loss: 0.0504 - val_loss: 0.0341\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0130 - val_loss: 0.0140\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0081 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0064 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0054 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0051 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0069 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0054 - val_loss: 0.0106\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0065 - val_loss: 9.1590e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0037 - val_loss: 0.0033\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0053 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0041 - val_loss: 0.0040\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0046 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0034 - val_loss: 0.0036\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 1ms/step - loss: 1.3517 - val_loss: 0.0780\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0680 - val_loss: 0.1311\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0665 - val_loss: 0.0381\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0456 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0414 - val_loss: 0.0110\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0045 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0043 - val_loss: 0.0136\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0150 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0022 - val_loss: 0.0173\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0167 - val_loss: 0.0148\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0043 - val_loss: 0.0059\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0013 - val_loss: 7.6092e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0143 - val_loss: 0.0132\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 0.0052 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0012 - val_loss: 7.0610e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 1ms/step - loss: 1.0281 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 0.0043 - val_loss: 0.0115\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0014 - val_loss: 8.9069e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0016 - val_loss: 7.4351e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0013 - val_loss: 9.5592e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0013 - val_loss: 8.3652e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0012 - val_loss: 8.7845e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0012 - val_loss: 7.6698e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0012 - val_loss: 8.3077e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 1ms/step - loss: 1.1078 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0064 - val_loss: 7.6323e-04\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0013 - val_loss: 9.7595e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0013 - val_loss: 0.0053\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0012 - val_loss: 8.3637e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0011 - val_loss: 6.4871e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0011 - val_loss: 5.9742e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 1ms/step - loss: 1.1145 - val_loss: 0.0563\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 0.0646 - val_loss: 0.0230\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 0.0310 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0085 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0177 - val_loss: 8.1583e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0014 - val_loss: 9.0338e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 1ms/step - loss: 0.6583 - val_loss: 0.1024\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0787 - val_loss: 0.0063\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.1060 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0833 - val_loss: 0.0235\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0685 - val_loss: 0.0493\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0697 - val_loss: 0.0561\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0696 - val_loss: 0.0482\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0685 - val_loss: 0.0398\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0682 - val_loss: 0.0362\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0682 - val_loss: 0.0357\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0682 - val_loss: 0.0374\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0681 - val_loss: 0.0381\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0681 - val_loss: 0.0386\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0681 - val_loss: 0.0381\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0681 - val_loss: 0.0378\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0681 - val_loss: 0.0382\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 0.0681 - val_loss: 0.0381\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0681 - val_loss: 0.0380\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0681 - val_loss: 0.0378\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0681 - val_loss: 0.0388\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0681 - val_loss: 0.0391\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0681 - val_loss: 0.0377\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0682 - val_loss: 0.0366\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0682 - val_loss: 0.0371\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 996us/step - loss: 0.6749 - val_loss: 0.2282\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 403us/step - loss: 0.1048 - val_loss: 0.0710\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 406us/step - loss: 0.0705 - val_loss: 0.0443\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 404us/step - loss: 0.0682 - val_loss: 0.0372\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 407us/step - loss: 0.0681 - val_loss: 0.0372\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 405us/step - loss: 0.0681 - val_loss: 0.0408\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 407us/step - loss: 0.0681 - val_loss: 0.0395\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 412us/step - loss: 0.0681 - val_loss: 0.0401\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 402us/step - loss: 0.0681 - val_loss: 0.0399\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 408us/step - loss: 0.0681 - val_loss: 0.0403\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 409us/step - loss: 0.0681 - val_loss: 0.0384\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 404us/step - loss: 0.0681 - val_loss: 0.0366\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 403us/step - loss: 0.0681 - val_loss: 0.0373\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 405us/step - loss: 0.0681 - val_loss: 0.0395\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 408us/step - loss: 0.0681 - val_loss: 0.0408\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 404us/step - loss: 0.0681 - val_loss: 0.0399\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 408us/step - loss: 0.0681 - val_loss: 0.0381\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 404us/step - loss: 0.0681 - val_loss: 0.0378\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 407us/step - loss: 0.0681 - val_loss: 0.0396\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 404us/step - loss: 0.0681 - val_loss: 0.0386\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 407us/step - loss: 0.0681 - val_loss: 0.0404\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 405us/step - loss: 0.0681 - val_loss: 0.0396\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 405us/step - loss: 0.0681 - val_loss: 0.0352\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 403us/step - loss: 0.0681 - val_loss: 0.0390\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 1ms/step - loss: 0.0694 - val_loss: 0.0403\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0683 - val_loss: 0.0398\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0683 - val_loss: 0.0406\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0683 - val_loss: 0.0391\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0682 - val_loss: 0.0414\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0683 - val_loss: 0.0366\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0683 - val_loss: 0.0350\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0683 - val_loss: 0.0383\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0682 - val_loss: 0.0370\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0683 - val_loss: 0.0361\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0683 - val_loss: 0.0404\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0683 - val_loss: 0.0390\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0683 - val_loss: 0.0396\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0683 - val_loss: 0.0378\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0683 - val_loss: 0.0397\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0683 - val_loss: 0.0398\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0682 - val_loss: 0.0412\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0683 - val_loss: 0.0397\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0682 - val_loss: 0.0399\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0682 - val_loss: 0.0374\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0682 - val_loss: 0.0372\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0682 - val_loss: 0.0389\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0683 - val_loss: 0.0385\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0682 - val_loss: 0.0396\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 5s 1ms/step - loss: 0.0838 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0108 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0065 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 594us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0010 - val_loss: 8.8185e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 9.4083e-04 - val_loss: 8.1301e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 9.0835e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 9.3158e-04 - val_loss: 8.8841e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 8.5997e-04 - val_loss: 9.6537e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 8.9600e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 9.1957e-04 - val_loss: 8.2924e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 8.7064e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.6923e-04 - val_loss: 6.4508e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 8.1229e-04 - val_loss: 7.4959e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 5s 1ms/step - loss: 0.0856 - val_loss: 0.0338\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0155 - val_loss: 0.0131\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0118 - val_loss: 0.0139\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0104 - val_loss: 0.0224\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0119 - val_loss: 0.0207\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 0.0055 - val_loss: 0.0179\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0122 - val_loss: 0.0097\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0051 - val_loss: 0.0115\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0076 - val_loss: 0.0291\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0085 - val_loss: 0.0104\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0035 - val_loss: 0.0072\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 0.0087 - val_loss: 0.0316\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0049 - val_loss: 0.0085\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0052 - val_loss: 0.0178\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0056 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0040 - val_loss: 0.0182\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0063 - val_loss: 0.0085\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0026 - val_loss: 0.0266\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0047 - val_loss: 0.0089\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0032 - val_loss: 0.0212\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0025 - val_loss: 0.0352\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0059 - val_loss: 0.0078\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0021 - val_loss: 0.0234\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 5s 1ms/step - loss: 0.0517 - val_loss: 0.0125\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0094 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0056 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0029 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0013 - val_loss: 5.6304e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 5.9580e-04\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 6.2930e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 9.6004e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 9.8708e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 9.7349e-04 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 9.2553e-04 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 8.8039e-04 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 593us/step - loss: 8.4967e-04 - val_loss: 8.9510e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 594us/step - loss: 9.2146e-04 - val_loss: 7.1408e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 593us/step - loss: 8.4521e-04 - val_loss: 6.0055e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 8.5069e-04 - val_loss: 7.8793e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 8.1500e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 599us/step - loss: 8.0842e-04 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 8.7603e-04 - val_loss: 7.4318e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 8.5733e-04 - val_loss: 8.5064e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 8.2402e-04 - val_loss: 9.3778e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 8.6350e-04 - val_loss: 5.8188e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 5s 1ms/step - loss: 0.3290 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0295 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0021 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0015 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0013 - val_loss: 0.0045\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0019 - val_loss: 0.0087\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0016 - val_loss: 0.0051\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 8.3557e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0011 - val_loss: 7.1137e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0013 - val_loss: 7.0365e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 7.0935e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0011 - val_loss: 6.8051e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.4812e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 8.5048e-04 - val_loss: 7.7718e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 8.3224e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0013 - val_loss: 7.5797e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0012 - val_loss: 6.5007e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 8.9043e-04 - val_loss: 0.0011\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 5s 1ms/step - loss: 0.0439 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0072 - val_loss: 0.0114\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0095 - val_loss: 0.0131\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0078 - val_loss: 0.0154\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0080 - val_loss: 0.0115\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0060 - val_loss: 0.0065\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0046 - val_loss: 0.0119\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0107 - val_loss: 0.0124\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0047 - val_loss: 0.0150\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0071 - val_loss: 0.0068\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0042 - val_loss: 0.0084\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0051 - val_loss: 0.0149\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0068 - val_loss: 0.0113\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0072 - val_loss: 0.0147\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0057 - val_loss: 0.0084\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0035 - val_loss: 0.0088\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0038 - val_loss: 0.0083\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0042 - val_loss: 0.0139\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0029 - val_loss: 0.0075\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0042 - val_loss: 0.0116\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0040 - val_loss: 0.0114\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 4s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 388us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 5s 1ms/step - loss: 4.3954 - val_loss: 0.1061\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0788 - val_loss: 0.0459\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0680 - val_loss: 0.0350\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0678 - val_loss: 0.0255\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 381us/step - loss: 0.0670 - val_loss: 0.0224\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0626 - val_loss: 0.0055\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 388us/step - loss: 0.0562 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0574 - val_loss: 0.0218\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0653 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0472 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0092 - val_loss: 0.1015\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0357 - val_loss: 0.0062\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0062 - val_loss: 0.0157\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0063 - val_loss: 0.0318\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0147 - val_loss: 0.0094\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - ETA: 0s - loss: 0.004 - 1s 380us/step - loss: 0.0045 - val_loss: 0.0125\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0056 - val_loss: 0.0189\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0150 - val_loss: 0.0062\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0096 - val_loss: 0.0328\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0094 - val_loss: 0.0059\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 5s 1ms/step - loss: 0.0506 - val_loss: 7.0101e-04\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0021 - val_loss: 0.0224\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0112 - val_loss: 7.1475e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0014 - val_loss: 6.0502e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0015 - val_loss: 9.9534e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0030 - val_loss: 0.0068\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0025 - val_loss: 8.3232e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0015 - val_loss: 5.6022e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 386us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 386us/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0016 - val_loss: 9.7220e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 386us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0023 - val_loss: 5.4390e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0010 - val_loss: 4.2097e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 389us/step - loss: 9.6919e-04 - val_loss: 8.6853e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 386us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 5s 1ms/step - loss: 0.0437 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0127 - val_loss: 7.3576e-04\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0015 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 386us/step - loss: 0.0015 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0043 - val_loss: 0.0131\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 386us/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0025 - val_loss: 0.0110\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0020 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0027 - val_loss: 0.0087\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0037 - val_loss: 0.0054\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 388us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 388us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0031 - val_loss: 0.0064\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 8.7492e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 7.6245e-04 - val_loss: 4.0761e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0041 - val_loss: 4.4992e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 386us/step - loss: 0.0013 - val_loss: 5.0590e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 5s 1ms/step - loss: 0.0779 - val_loss: 0.0101\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 381us/step - loss: 0.0234 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 381us/step - loss: 0.0179 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: 0.0133 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: 0.0100 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 381us/step - loss: 0.0082 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 386us/step - loss: 0.0065 - val_loss: 8.8738e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0055 - val_loss: 9.2775e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: 0.0048 - val_loss: 8.6441e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 381us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 381us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 381us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 379us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 380us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 381us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 5s 1ms/step - loss: 0.0353 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: 0.0148 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: 0.0111 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0088 - val_loss: 8.3526e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 381us/step - loss: 0.0075 - val_loss: 6.8743e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0069 - val_loss: 6.8528e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0062 - val_loss: 7.8810e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 380us/step - loss: 0.0058 - val_loss: 6.3159e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 385us/step - loss: 0.0054 - val_loss: 7.9880e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: 0.0054 - val_loss: 9.4172e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 390us/step - loss: 0.0050 - val_loss: 9.9119e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0050 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 384us/step - loss: 0.0046 - val_loss: 8.9449e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 381us/step - loss: 0.0045 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 381us/step - loss: 0.0045 - val_loss: 8.6860e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 383us/step - loss: 0.0041 - val_loss: 8.8310e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 380us/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 382us/step - loss: 0.0043 - val_loss: 9.9938e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - ETA: 0s - loss: 0.004 - 1s 381us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 387us/step - loss: 0.0041 - val_loss: 8.1241e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 380us/step - loss: 0.0039 - val_loss: 9.6506e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 380us/step - loss: 0.0041 - val_loss: 7.2487e-04\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 6s 2ms/step - loss: 0.0614 - val_loss: 0.0130\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0093 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0046 - val_loss: 0.0128\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0024 - val_loss: 7.4337e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0011 - val_loss: 6.3126e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 9.9650e-04 - val_loss: 5.1513e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0010 - val_loss: 6.4582e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 9.7045e-04 - val_loss: 7.3027e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 9.6640e-04 - val_loss: 6.9853e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 9.2160e-04 - val_loss: 7.1597e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 9.2403e-04 - val_loss: 6.3374e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 8.8949e-04 - val_loss: 5.5265e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 8.8713e-04 - val_loss: 6.3886e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 8.9730e-04 - val_loss: 7.9607e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 9.0130e-04 - val_loss: 9.9027e-04\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 582us/step - loss: 8.5818e-04 - val_loss: 7.0591e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 7.7319e-04 - val_loss: 4.5916e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 8.5472e-04 - val_loss: 5.3973e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 8.7640e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 8.3102e-04 - val_loss: 6.4350e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 6s 2ms/step - loss: 0.0726 - val_loss: 0.0138\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0123 - val_loss: 0.0105\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0048 - val_loss: 0.0113\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 6.0659e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0014 - val_loss: 5.3371e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 8.6205e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 9.8973e-04 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 9.4018e-04 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 9.2108e-04 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 9.4763e-04 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 8.7807e-04 - val_loss: 9.7799e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 8.6175e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 8.8020e-04 - val_loss: 6.6744e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 8.8015e-04 - val_loss: 8.4310e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 8.7959e-04 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 8.4173e-04 - val_loss: 8.9538e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 8.6210e-04 - val_loss: 5.8443e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 8.9562e-04 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 8.4797e-04 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 7.9444e-04 - val_loss: 7.5879e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 6s 2ms/step - loss: 0.0675 - val_loss: 0.0151\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 509us/step - loss: 0.0147 - val_loss: 0.0156\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 508us/step - loss: 0.0061 - val_loss: 7.9990e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 0.0040 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 511us/step - loss: 0.0029 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 505us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 509us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 505us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 506us/step - loss: 0.0013 - val_loss: 7.4008e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 508us/step - loss: 0.0013 - val_loss: 6.0744e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 508us/step - loss: 0.0012 - val_loss: 6.2810e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 506us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 510us/step - loss: 0.0011 - val_loss: 9.5152e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 508us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 506us/step - loss: 0.0011 - val_loss: 9.1784e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 508us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 509us/step - loss: 0.0010 - val_loss: 7.5229e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 505us/step - loss: 0.0010 - val_loss: 7.5043e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 509us/step - loss: 0.0010 - val_loss: 7.4471e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 9.8884e-04 - val_loss: 7.7110e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 9.8264e-04 - val_loss: 8.9678e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 508us/step - loss: 9.7406e-04 - val_loss: 8.6207e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 508us/step - loss: 9.9011e-04 - val_loss: 9.3609e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 6s 2ms/step - loss: 1.3176 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 484us/step - loss: 0.0094 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0050 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 485us/step - loss: 0.0039 - val_loss: 7.8446e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0034 - val_loss: 7.8620e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 484us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 485us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0026 - val_loss: 5.0976e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0025 - val_loss: 6.2005e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 485us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0022 - val_loss: 6.1586e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 485us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0021 - val_loss: 7.2694e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 484us/step - loss: 0.0019 - val_loss: 9.5416e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 484us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 485us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 482us/step - loss: 0.0020 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0019 - val_loss: 6.9852e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 485us/step - loss: 0.0019 - val_loss: 7.2648e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 6s 2ms/step - loss: 1.7621 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 485us/step - loss: 0.0103 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0039 - val_loss: 9.5527e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0037 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 484us/step - loss: 0.0034 - val_loss: 9.6080e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 485us/step - loss: 0.0035 - val_loss: 8.9468e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0031 - val_loss: 9.9269e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0030 - val_loss: 8.4941e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0030 - val_loss: 8.8674e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0030 - val_loss: 8.3306e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 484us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0029 - val_loss: 8.3607e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0027 - val_loss: 9.7518e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0027 - val_loss: 8.5179e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 484us/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0026 - val_loss: 8.1746e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 484us/step - loss: 0.0026 - val_loss: 7.8327e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 485us/step - loss: 0.0027 - val_loss: 8.0939e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 482us/step - loss: 0.0025 - val_loss: 7.7206e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 6s 2ms/step - loss: 40.6041 - val_loss: 0.2712\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.1400 - val_loss: 0.0355\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0729 - val_loss: 0.0548\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0736 - val_loss: 0.0285\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0724 - val_loss: 0.0367\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0719 - val_loss: 0.0392\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0728 - val_loss: 0.0335\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0701 - val_loss: 0.0319\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0714 - val_loss: 0.0302\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0709 - val_loss: 0.0355\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0699 - val_loss: 0.0305\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0697 - val_loss: 0.0271\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0690 - val_loss: 0.0371\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0685 - val_loss: 0.0367\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0677 - val_loss: 0.0302\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0655 - val_loss: 0.0363\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0649 - val_loss: 0.0345\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0621 - val_loss: 0.0336\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0573 - val_loss: 0.0283\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0528 - val_loss: 0.0180\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0455 - val_loss: 0.0107\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0375 - val_loss: 0.0060\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0274 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0294 - val_loss: 0.0251\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 6s 2ms/step - loss: 2.2043 - val_loss: 0.0290\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0393 - val_loss: 0.0087\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0235 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0127 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0065 - val_loss: 8.1310e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0031 - val_loss: 9.8884e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 485us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0018 - val_loss: 9.3290e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0017 - val_loss: 8.7100e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0019 - val_loss: 8.1162e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0018 - val_loss: 9.0121e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 6s 2ms/step - loss: 0.9291 - val_loss: 0.0079\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0194 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0046 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0022 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0024 - val_loss: 0.0066\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0028 - val_loss: 0.0088\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0016 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0013 - val_loss: 9.2466e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0012 - val_loss: 7.3907e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 487us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 6s 2ms/step - loss: 1.5213 - val_loss: 0.0050\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0142 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0072 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0083 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0021 - val_loss: 0.0044\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0018 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 486us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 488us/step - loss: 0.0018 - val_loss: 0.0035\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 7s 2ms/step - loss: 0.0563 - val_loss: 0.0152\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0095 - val_loss: 0.0129\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0055 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0032 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0013 - val_loss: 9.3931e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 9.8889e-04 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 9.3955e-04 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 9.4876e-04 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 9.0255e-04 - val_loss: 6.2240e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 8.9962e-04 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 9.0758e-04 - val_loss: 6.0306e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 8.8843e-04 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 8.3121e-04 - val_loss: 5.9779e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 8.5904e-04 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 8.0318e-04 - val_loss: 7.4313e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 7.8033e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 7.6789e-04 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 7.4996e-04 - val_loss: 7.6050e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 7.2647e-04 - val_loss: 0.0016\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 7s 2ms/step - loss: 0.0576 - val_loss: 0.0146\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0097 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0043 - val_loss: 0.0135\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0023 - val_loss: 9.0032e-04\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0011 - val_loss: 6.3381e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0010 - val_loss: 5.9803e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 8.4089e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 9.9121e-04 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 9.7765e-04 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 9.6556e-04 - val_loss: 9.7397e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 9.0297e-04 - val_loss: 7.5303e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 9.1454e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 8.6874e-04 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 8.9397e-04 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.7993e-04 - val_loss: 7.3294e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.6429e-04 - val_loss: 0.0013\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 7s 2ms/step - loss: 0.0663 - val_loss: 0.0186\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0419 - val_loss: 0.0108\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0267 - val_loss: 0.0102\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0146 - val_loss: 0.0147\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0085 - val_loss: 0.0317\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0042 - val_loss: 0.0177\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0027 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0023 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0021 - val_loss: 0.0049\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 7.6225e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 9.8103e-04 - val_loss: 8.6127e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 9.6129e-04 - val_loss: 5.8314e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 9.2690e-04 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 8.7299e-04 - val_loss: 6.5990e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 8.5684e-04 - val_loss: 6.8910e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 8.0248e-04 - val_loss: 6.8278e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 8.0434e-04 - val_loss: 8.5759e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 7.6696e-04 - val_loss: 8.9439e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 7s 2ms/step - loss: 0.0734 - val_loss: 9.8605e-04\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0037 - val_loss: 0.0114\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0150 - val_loss: 0.0118\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0072 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0055 - val_loss: 0.0087\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0075 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0032 - val_loss: 4.9062e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0039 - val_loss: 0.0087\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0093 - val_loss: 0.0068\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0082 - val_loss: 0.0033\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0028 - val_loss: 7.6643e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0043 - val_loss: 0.0070\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0049 - val_loss: 0.0067\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0050 - val_loss: 0.0061\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0053 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 7s 2ms/step - loss: 0.0709 - val_loss: 8.0414e-04\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0082 - val_loss: 0.0114\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0099 - val_loss: 0.0130\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0071 - val_loss: 0.0137\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0094 - val_loss: 0.0082\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0080 - val_loss: 0.0185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0104 - val_loss: 0.0142\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0083 - val_loss: 0.0138\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0080 - val_loss: 0.0034\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0060 - val_loss: 0.0083\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0064 - val_loss: 0.0047\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0054 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0075 - val_loss: 0.0036\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 495us/step - loss: 0.0072 - val_loss: 0.0091\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0049 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0054 - val_loss: 0.0155\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0082 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0044 - val_loss: 0.0097\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 7s 2ms/step - loss: 0.0728 - val_loss: 0.0055\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0106 - val_loss: 0.0312\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0120 - val_loss: 0.0199\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0085 - val_loss: 0.0129\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0070 - val_loss: 0.0084\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0085 - val_loss: 0.0089\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 497us/step - loss: 0.0080 - val_loss: 0.0093\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0067 - val_loss: 0.0101\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0075 - val_loss: 0.0133\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0112 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0037 - val_loss: 0.0100\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0076 - val_loss: 0.0119\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0081 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0075 - val_loss: 0.0042\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0047 - val_loss: 0.0179\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0065 - val_loss: 0.0070\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0073 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0066 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 7s 2ms/step - loss: 0.1305 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0046 - val_loss: 7.2602e-04\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0036 - val_loss: 7.7379e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0032 - val_loss: 7.7285e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0037 - val_loss: 0.0047\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0077 - val_loss: 0.0194\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0060 - val_loss: 0.0091\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0069 - val_loss: 0.0216\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0119 - val_loss: 0.0117\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0094 - val_loss: 0.0055\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0057 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0058 - val_loss: 0.0082\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0108 - val_loss: 0.0091\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0093 - val_loss: 0.0140\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0095 - val_loss: 0.0043\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0065 - val_loss: 0.0103\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 495us/step - loss: 0.0074 - val_loss: 0.0121\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0066 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0040 - val_loss: 0.0202\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0089 - val_loss: 0.0049\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 8s 2ms/step - loss: 0.0779 - val_loss: 7.3208e-04\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 504us/step - loss: 0.0040 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 504us/step - loss: 0.0032 - val_loss: 7.6330e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 504us/step - loss: 0.0030 - val_loss: 6.4281e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 0.0031 - val_loss: 9.2925e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 502us/step - loss: 0.0108 - val_loss: 0.0270\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 505us/step - loss: 0.0109 - val_loss: 0.0107\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 0.0073 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 506us/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 504us/step - loss: 0.0082 - val_loss: 0.0139\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 503us/step - loss: 0.0088 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 504us/step - loss: 0.0067 - val_loss: 0.0093\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 504us/step - loss: 0.0081 - val_loss: 0.0197\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 504us/step - loss: 0.0096 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 505us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 504us/step - loss: 0.0057 - val_loss: 0.0104\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 503us/step - loss: 0.0095 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 502us/step - loss: 0.0063 - val_loss: 0.0063\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 503us/step - loss: 0.0062 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 503us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 502us/step - loss: 0.0034 - val_loss: 9.6459e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 506us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 504us/step - loss: 0.0059 - val_loss: 0.0115\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 502us/step - loss: 0.0083 - val_loss: 0.0101\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 8s 2ms/step - loss: 1.3662 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 506us/step - loss: 0.0065 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 0.0093 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 510us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 503us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 0.0019 - val_loss: 9.2012e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 509us/step - loss: 0.0019 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 509us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 505us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 506us/step - loss: 0.0017 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 511us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 0.0015 - val_loss: 8.6844e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 506us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 510us/step - loss: 0.0015 - val_loss: 7.2160e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 505us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 507us/step - loss: 0.0015 - val_loss: 9.8675e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 505us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 509us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 506us/step - loss: 0.0015 - val_loss: 7.2775e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 506us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 505us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 508us/step - loss: 0.0014 - val_loss: 8.1069e-04\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 8s 2ms/step - loss: 2.1131 - val_loss: 1.7797\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 1.1780 - val_loss: 1.2030\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.7902 - val_loss: 0.8739\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.5575 - val_loss: 0.6455\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.4002 - val_loss: 0.4819\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.2930 - val_loss: 0.3639\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.2189 - val_loss: 0.2787\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.1688 - val_loss: 0.2163\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.1346 - val_loss: 0.1703\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.1114 - val_loss: 0.1365\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0959 - val_loss: 0.1114\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0856 - val_loss: 0.0928\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0790 - val_loss: 0.0787\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0747 - val_loss: 0.0681\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0719 - val_loss: 0.0601\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0703 - val_loss: 0.0538\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0693 - val_loss: 0.0494\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0687 - val_loss: 0.0461\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0684 - val_loss: 0.0437\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0683 - val_loss: 0.0420\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0682 - val_loss: 0.0408\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0682 - val_loss: 0.0400\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0681 - val_loss: 0.0395\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0681 - val_loss: 0.0391\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 9s 2ms/step - loss: 0.1488 - val_loss: 0.0366\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0743 - val_loss: 0.0115\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0741 - val_loss: 0.0347\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0683 - val_loss: 0.0499\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0684 - val_loss: 0.0396\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0667 - val_loss: 0.0327\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0626 - val_loss: 0.0290\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0642 - val_loss: 0.0553\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0653 - val_loss: 0.0418\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0393 - val_loss: 0.0063\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0304 - val_loss: 0.0289\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0769 - val_loss: 0.0104\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0933 - val_loss: 0.0407\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0737 - val_loss: 0.0862\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0743 - val_loss: 0.0471\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0676 - val_loss: 0.0269\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0667 - val_loss: 0.0297\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0623 - val_loss: 0.0378\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0541 - val_loss: 0.0245\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0386 - val_loss: 0.0146\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0196 - val_loss: 0.0081\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0110 - val_loss: 0.0190\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0063 - val_loss: 0.0163\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0045 - val_loss: 0.0055\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 8s 2ms/step - loss: 0.0789 - val_loss: 0.0260\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0131 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0048 - val_loss: 0.0142\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0040 - val_loss: 9.1423e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0022 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0013 - val_loss: 9.8518e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 7.5730e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 7.4096e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0011 - val_loss: 7.8483e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 8.1208e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 7.4700e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0010 - val_loss: 9.2726e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0010 - val_loss: 7.1432e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 9.6634e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 9.2497e-04 - val_loss: 7.6156e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 8.7433e-04 - val_loss: 5.4031e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 9.1262e-04 - val_loss: 8.5490e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 9.3815e-04 - val_loss: 6.6471e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 9.1170e-04 - val_loss: 6.9081e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 8.5094e-04 - val_loss: 8.2466e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 9s 2ms/step - loss: 0.6179 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0065 - val_loss: 0.0388\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0111 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0028 - val_loss: 9.7708e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0023 - val_loss: 5.3209e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0036 - val_loss: 4.5480e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0019 - val_loss: 9.3622e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0017 - val_loss: 6.0595e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0026 - val_loss: 0.0043\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0020 - val_loss: 5.1146e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0018 - val_loss: 6.0907e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0017 - val_loss: 4.6540e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0016 - val_loss: 6.7538e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0037 - val_loss: 0.0051\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 7.3165e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0013 - val_loss: 7.0871e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 9s 2ms/step - loss: 2.8894 - val_loss: 0.0070\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0142 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0075 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0059 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0054 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0032 - val_loss: 9.0843e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0030 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 9s 2ms/step - loss: 12.0756 - val_loss: 0.1646\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0705 - val_loss: 0.0064\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0230 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0168 - val_loss: 0.0054\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0137 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0119 - val_loss: 0.0068\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0101 - val_loss: 0.0128\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0095 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0086 - val_loss: 0.0078\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0078 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0074 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0067 - val_loss: 0.0110\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0067 - val_loss: 0.0050\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0062 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0057 - val_loss: 0.0048\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0055 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0051 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: 0.0050 - val_loss: 0.0056\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 9s 2ms/step - loss: 7.2417 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0017 - val_loss: 0.0024\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 9s 2ms/step - loss: 5.3241 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0052 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 9s 3ms/step - loss: 7.3518 - val_loss: 0.0555\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0190 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0047 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0027 - val_loss: 9.9036e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0023 - val_loss: 8.9351e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0023 - val_loss: 8.4869e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0022 - val_loss: 7.7649e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0022 - val_loss: 9.5178e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 9s 3ms/step - loss: 0.0708 - val_loss: 0.0230\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0111 - val_loss: 0.0076\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0047 - val_loss: 0.0090\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0037 - val_loss: 6.6655e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0013 - val_loss: 8.0686e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 0.0012 - val_loss: 6.7397e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0012 - val_loss: 5.4950e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0012 - val_loss: 9.4577e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0010 - val_loss: 9.0989e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0010 - val_loss: 7.0082e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 9.8407e-04 - val_loss: 7.8953e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 9.1076e-04 - val_loss: 7.4281e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 9.2971e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 8.7449e-04 - val_loss: 9.8909e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 9.0411e-04 - val_loss: 9.8543e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 9.0326e-04 - val_loss: 7.7320e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 10s 3ms/step - loss: 0.0658 - val_loss: 0.0098\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0120 - val_loss: 0.0144\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0059 - val_loss: 0.0117\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0019 - val_loss: 6.2089e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0015 - val_loss: 5.9797e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 9.7908e-04 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 9.7071e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 9.4244e-04 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 9.0575e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.7959e-04 - val_loss: 9.3098e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 8.8684e-04 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.6019e-04 - val_loss: 7.6335e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 8.4895e-04 - val_loss: 8.6346e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.4447e-04 - val_loss: 8.0590e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 7.9115e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 8.0338e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 7.9835e-04 - val_loss: 7.4101e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 7.7110e-04 - val_loss: 6.6366e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 7.6707e-04 - val_loss: 5.6728e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 10s 3ms/step - loss: 0.0602 - val_loss: 0.0178\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0110 - val_loss: 0.0077\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0049 - val_loss: 0.0103\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0037 - val_loss: 5.4975e-04\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0018 - val_loss: 8.4854e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0011 - val_loss: 8.4257e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 9.6203e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 9.5972e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 9.0483e-04 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 9.1097e-04 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 9.2883e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 8.7146e-04 - val_loss: 0.0013\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 10s 3ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 10s 3ms/step - loss: 0.0686 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0074 - val_loss: 6.9249e-04\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0022 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0012 - val_loss: 9.7796e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 9.3382e-04 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 9.5062e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 9.2824e-04 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 9.6115e-04 - val_loss: 8.7787e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 9.4609e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 9.1189e-04 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 9.2901e-04 - val_loss: 0.0012\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 10s 3ms/step - loss: 0.0600 - val_loss: 7.7536e-04\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 9.7731e-04 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 8.8539e-04 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 8.6411e-04 - val_loss: 0.0010\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 564us/step - loss: 8.6943e-04 - val_loss: 7.4147e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 8.4709e-04 - val_loss: 7.6401e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 8.1009e-04 - val_loss: 8.0433e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 7.9261e-04 - val_loss: 8.4480e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 7.9040e-04 - val_loss: 8.2205e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 7.7273e-04 - val_loss: 8.0828e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 7.5293e-04 - val_loss: 7.5366e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 7.4957e-04 - val_loss: 9.0613e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 7.6768e-04 - val_loss: 8.7318e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 7.4743e-04 - val_loss: 7.9280e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 7.2510e-04 - val_loss: 6.1872e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 7.2408e-04 - val_loss: 5.7359e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 7.0465e-04 - val_loss: 6.3277e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 7.1777e-04 - val_loss: 5.9135e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 6.9667e-04 - val_loss: 7.2867e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 11s 3ms/step - loss: 0.1048 - val_loss: 0.0093\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0172 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0080 - val_loss: 0.0112\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0065 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0036 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0012 - val_loss: 8.3825e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 656us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 11s 3ms/step - loss: 0.0680 - val_loss: 0.0093\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0090 - val_loss: 0.0154\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0058 - val_loss: 9.1378e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0013 - val_loss: 9.8597e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0012 - val_loss: 8.7455e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0011 - val_loss: 9.4067e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0011 - val_loss: 9.3538e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0011 - val_loss: 7.7991e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0011 - val_loss: 9.7064e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 9.9446e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 9.7633e-04 - val_loss: 7.2782e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 11s 3ms/step - loss: 0.1613 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0138 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0083 - val_loss: 8.2008e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0043 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0027 - val_loss: 5.7875e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0017 - val_loss: 9.6829e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 11s 3ms/step - loss: 0.0578 - val_loss: 0.0155\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0102 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0050 - val_loss: 0.0113\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 593us/step - loss: 0.0012 - val_loss: 5.8589e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0012 - val_loss: 7.7240e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 7.2761e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0011 - val_loss: 9.9578e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 9.7428e-04 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0010 - val_loss: 7.0971e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 9.6587e-04 - val_loss: 8.3569e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 8.6503e-04 - val_loss: 9.4091e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.4744e-04 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 8.8720e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 8.2088e-04 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 8.2750e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 8.0798e-04 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 8.1134e-04 - val_loss: 0.0011\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 11s 3ms/step - loss: 0.1039 - val_loss: 0.0110\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0164 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 597us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0011 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 9.8109e-04 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 9.7416e-04 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 9.6815e-04 - val_loss: 0.0014\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 11s 3ms/step - loss: 0.1476 - val_loss: 0.1125\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 341us/step - loss: 0.0740 - val_loss: 0.0093\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 340us/step - loss: 0.0496 - val_loss: 0.0111\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 340us/step - loss: 0.0153 - val_loss: 0.0546\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 344us/step - loss: 0.0087 - val_loss: 0.0288\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 342us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 349us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 341us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 342us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 341us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 342us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 340us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 341us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 346us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 347us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 342us/step - loss: 0.0019 - val_loss: 9.2220e-04\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 1s 340us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 343us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 339us/step - loss: 0.0018 - val_loss: 9.7079e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 345us/step - loss: 0.0017 - val_loss: 9.2646e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 341us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 342us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 341us/step - loss: 0.0016 - val_loss: 9.4204e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 340us/step - loss: 0.0016 - val_loss: 9.4408e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 11s 3ms/step - loss: 0.6744 - val_loss: 0.5214\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 345us/step - loss: 0.2581 - val_loss: 0.2294\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 339us/step - loss: 0.1233 - val_loss: 0.1179\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 338us/step - loss: 0.0833 - val_loss: 0.0746\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 339us/step - loss: 0.0723 - val_loss: 0.0550\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 337us/step - loss: 0.0692 - val_loss: 0.0463\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 339us/step - loss: 0.0684 - val_loss: 0.0408\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 338us/step - loss: 0.0682 - val_loss: 0.0387\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 340us/step - loss: 0.0681 - val_loss: 0.0395\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 342us/step - loss: 0.0681 - val_loss: 0.0396\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 343us/step - loss: 0.0681 - val_loss: 0.0396\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 340us/step - loss: 0.0681 - val_loss: 0.0382\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 340us/step - loss: 0.0681 - val_loss: 0.0392\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 344us/step - loss: 0.0682 - val_loss: 0.0377\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 342us/step - loss: 0.0681 - val_loss: 0.0402\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 337us/step - loss: 0.0681 - val_loss: 0.0388\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 341us/step - loss: 0.0681 - val_loss: 0.0386\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 339us/step - loss: 0.0682 - val_loss: 0.0394\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 342us/step - loss: 0.0681 - val_loss: 0.0329\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 336us/step - loss: 0.0681 - val_loss: 0.0448\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 340us/step - loss: 0.0682 - val_loss: 0.0420\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 341us/step - loss: 0.0682 - val_loss: 0.0511\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 341us/step - loss: 0.0684 - val_loss: 0.0331\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 338us/step - loss: 0.0682 - val_loss: 0.0377\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 12s 3ms/step - loss: 0.5845 - val_loss: 0.0055\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0542 - val_loss: 0.0509\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0667 - val_loss: 0.0265\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0613 - val_loss: 0.0136\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 0.0450 - val_loss: 0.0401\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0472 - val_loss: 0.0286\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 594us/step - loss: 0.0384 - val_loss: 0.0357\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0370 - val_loss: 0.0390\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0330 - val_loss: 0.0560\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0400 - val_loss: 0.0598\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0281 - val_loss: 0.0478\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0206 - val_loss: 0.0490\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 593us/step - loss: 0.0232 - val_loss: 0.0394\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0173 - val_loss: 0.0471\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0266 - val_loss: 0.0591\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0193 - val_loss: 0.0324\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0142 - val_loss: 0.0389\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0171 - val_loss: 0.0492\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0184 - val_loss: 0.0333\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0135 - val_loss: 0.0270\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0167 - val_loss: 0.0533\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0193 - val_loss: 0.0300\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0116 - val_loss: 0.0393\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0159 - val_loss: 0.0422\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 12s 3ms/step - loss: 0.9232 - val_loss: 0.1299\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0667 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0473 - val_loss: 0.1267\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.1017 - val_loss: 0.0105\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 495us/step - loss: 0.0872 - val_loss: 0.0142\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0167 - val_loss: 0.0425\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0075 - val_loss: 0.0875\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0105 - val_loss: 0.0505\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0068 - val_loss: 0.0261\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0049 - val_loss: 0.0141\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0039 - val_loss: 0.0129\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0046 - val_loss: 0.0143\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0042 - val_loss: 0.0118\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 495us/step - loss: 0.0030 - val_loss: 0.0103\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0032 - val_loss: 0.0087\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 495us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0040 - val_loss: 0.0074\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0021 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0020 - val_loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0018 - val_loss: 9.0329e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 489us/step - loss: 0.0023 - val_loss: 0.0079\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 12s 3ms/step - loss: 1.0436 - val_loss: 0.0675\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0559 - val_loss: 0.0287\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0316 - val_loss: 0.0245\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 490us/step - loss: 0.0234 - val_loss: 0.0142\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0151 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0125 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0110 - val_loss: 0.0065\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0091 - val_loss: 0.0080\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0147 - val_loss: 0.0166\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0131 - val_loss: 0.0047\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0081 - val_loss: 0.0069\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0103 - val_loss: 0.0149\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0143 - val_loss: 0.0096\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0134 - val_loss: 0.0178\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0158 - val_loss: 0.0207\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0161 - val_loss: 0.0155\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0140 - val_loss: 0.0164\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0142 - val_loss: 0.0223\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0123 - val_loss: 0.0209\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 492us/step - loss: 0.0181 - val_loss: 0.0107\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 493us/step - loss: 0.0104 - val_loss: 0.0130\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0155 - val_loss: 0.0180\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 491us/step - loss: 0.0148 - val_loss: 0.0127\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 12s 3ms/step - loss: 0.0689 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 408us/step - loss: 0.0121 - val_loss: 0.0100\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 401us/step - loss: 0.0097 - val_loss: 0.0101\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 400us/step - loss: 0.0089 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 400us/step - loss: 0.0039 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 402us/step - loss: 0.0050 - val_loss: 0.0067\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 402us/step - loss: 0.0078 - val_loss: 0.0103\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 400us/step - loss: 0.0063 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 402us/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 401us/step - loss: 0.0069 - val_loss: 0.0117\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 400us/step - loss: 0.0060 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 399us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 407us/step - loss: 0.0045 - val_loss: 0.0075\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 404us/step - loss: 0.0048 - val_loss: 0.0117\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 401us/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 402us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 401us/step - loss: 0.0045 - val_loss: 0.0067\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 402us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 401us/step - loss: 0.0035 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 406us/step - loss: 0.0032 - val_loss: 0.0073\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 401us/step - loss: 0.0044 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 402us/step - loss: 0.0027 - val_loss: 0.0061\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 399us/step - loss: 0.0057 - val_loss: 0.0078\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 405us/step - loss: 0.0033 - val_loss: 0.0105\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 12s 3ms/step - loss: 0.0462 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 1s 402us/step - loss: 0.0067 - val_loss: 0.0218\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 1s 399us/step - loss: 0.0095 - val_loss: 0.0083\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 1s 400us/step - loss: 0.0047 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 1s 401us/step - loss: 0.0045 - val_loss: 0.0105\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 1s 401us/step - loss: 0.0064 - val_loss: 0.0125\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 1s 402us/step - loss: 0.0054 - val_loss: 0.0118\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 1s 398us/step - loss: 0.0059 - val_loss: 0.0095\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 1s 399us/step - loss: 0.0049 - val_loss: 0.0074\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 1s 398us/step - loss: 0.0057 - val_loss: 0.0089\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 1s 402us/step - loss: 0.0040 - val_loss: 0.0106\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 1s 399us/step - loss: 0.0050 - val_loss: 0.0075\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 1s 395us/step - loss: 0.0034 - val_loss: 0.0056\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 1s 401us/step - loss: 0.0035 - val_loss: 0.0089\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 1s 399us/step - loss: 0.0055 - val_loss: 0.0133\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 1s 398us/step - loss: 0.0047 - val_loss: 0.0117\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 1s 399us/step - loss: 0.0042 - val_loss: 0.0096\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 1s 399us/step - loss: 0.0045 - val_loss: 0.0077\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 1s 400us/step - loss: 0.0030 - val_loss: 0.0088\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 398us/step - loss: 0.0033 - val_loss: 0.0084\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 1s 401us/step - loss: 0.0033 - val_loss: 0.0109\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 1s 403us/step - loss: 0.0043 - val_loss: 0.0091\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 1s 399us/step - loss: 0.0042 - val_loss: 0.0088\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 1s 400us/step - loss: 0.0039 - val_loss: 0.0072\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 13s 4ms/step - loss: 0.0548 - val_loss: 0.0170\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0107 - val_loss: 0.0071\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0049 - val_loss: 0.0073\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0038 - val_loss: 7.5542e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0026 - val_loss: 0.0041\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0015 - val_loss: 9.4827e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0012 - val_loss: 6.4377e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 5.2220e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 6.8270e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 0.0010 - val_loss: 6.7246e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0010 - val_loss: 8.7652e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 9.3981e-04 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 9.5522e-04 - val_loss: 9.9479e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.9544e-04 - val_loss: 6.8422e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 9.3317e-04 - val_loss: 6.8475e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 9.1254e-04 - val_loss: 6.3453e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 8.9115e-04 - val_loss: 8.5178e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.5828e-04 - val_loss: 8.5277e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 8.4938e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 8.7200e-04 - val_loss: 8.5078e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 8.3206e-04 - val_loss: 6.6766e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 8.3237e-04 - val_loss: 6.7304e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 13s 4ms/step - loss: 0.0588 - val_loss: 0.0199\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0063 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 593us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0014 - val_loss: 7.7194e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0012 - val_loss: 5.7744e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 6.0016e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 7.0645e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 593us/step - loss: 0.0010 - val_loss: 7.8811e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 9.7723e-04 - val_loss: 7.3203e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 9.6706e-04 - val_loss: 9.7325e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 9.3104e-04 - val_loss: 8.4787e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 9.4596e-04 - val_loss: 9.0092e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 8.8893e-04 - val_loss: 8.9451e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 8.6543e-04 - val_loss: 7.7164e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 8.3942e-04 - val_loss: 9.5159e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 8.1081e-04 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.5042e-04 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 9.2203e-04 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 8.4505e-04 - val_loss: 5.4929e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 8.4014e-04 - val_loss: 5.2113e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 8.6265e-04 - val_loss: 0.0011\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 13s 4ms/step - loss: 0.0870 - val_loss: 0.0141\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 599us/step - loss: 0.0156 - val_loss: 0.0324\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 0.0105 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 598us/step - loss: 0.0078 - val_loss: 0.0109\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0072 - val_loss: 0.0109\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 600us/step - loss: 0.0067 - val_loss: 0.0057\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0048 - val_loss: 0.0049\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0056 - val_loss: 0.0125\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0045 - val_loss: 0.0098\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 598us/step - loss: 0.0037 - val_loss: 0.0060\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0043 - val_loss: 0.0067\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0054 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 599us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 599us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 611us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0032 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: 0.0040 - val_loss: 0.0046\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 14s 4ms/step - loss: 0.0347 - val_loss: 0.0146\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 433us/step - loss: 0.0064 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 432us/step - loss: 0.0062 - val_loss: 0.0055\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 429us/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 414us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 414us/step - loss: 0.0031 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 411us/step - loss: 0.0060 - val_loss: 0.0085\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 411us/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 410us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 412us/step - loss: 0.0039 - val_loss: 0.0046\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 418us/step - loss: 0.0055 - val_loss: 0.0122\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 410us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 412us/step - loss: 0.0046 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 412us/step - loss: 0.0033 - val_loss: 0.0050\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 409us/step - loss: 0.0038 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 414us/step - loss: 0.0027 - val_loss: 0.0072\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 411us/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 412us/step - loss: 0.0029 - val_loss: 0.0047\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 410us/step - loss: 0.0040 - val_loss: 0.0079\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 413us/step - loss: 0.0035 - val_loss: 8.2908e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 414us/step - loss: 0.0017 - val_loss: 7.4790e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 413us/step - loss: 0.0014 - val_loss: 9.0250e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 409us/step - loss: 0.0018 - val_loss: 0.0043\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 13s 4ms/step - loss: 0.1639 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 412us/step - loss: 0.0106 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 413us/step - loss: 0.0095 - val_loss: 0.0205\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 412us/step - loss: 0.0100 - val_loss: 0.0105\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 414us/step - loss: 0.0062 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 411us/step - loss: 0.0067 - val_loss: 0.0095\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 410us/step - loss: 0.0072 - val_loss: 0.0057\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 414us/step - loss: 0.0056 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 411us/step - loss: 0.0038 - val_loss: 8.6763e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 414us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 415us/step - loss: 0.0050 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 414us/step - loss: 0.0052 - val_loss: 0.0039\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 413us/step - loss: 0.0056 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 414us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 412us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 412us/step - loss: 0.0048 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 410us/step - loss: 0.0033 - val_loss: 7.5648e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 409us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 409us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 414us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 415us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 416us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 413us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 412us/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 14s 4ms/step - loss: 0.0679 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0103 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 443us/step - loss: 0.0063 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0071 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0044 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0051 - val_loss: 0.0077\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0047 - val_loss: 8.0831e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0050 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0062 - val_loss: 0.0057\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 444us/step - loss: 0.0043 - val_loss: 0.0073\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 442us/step - loss: 0.0054 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 443us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 448us/step - loss: 0.0060 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 444us/step - loss: 0.0034 - val_loss: 0.0049\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 444us/step - loss: 0.0044 - val_loss: 0.0057\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 444us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0036 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 14s 4ms/step - loss: 0.0566 - val_loss: 0.0086\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0071 - val_loss: 0.0138\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0074 - val_loss: 0.0172\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 526us/step - loss: 0.0056 - val_loss: 0.0073\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0025 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0024 - val_loss: 0.0123\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0120 - val_loss: 0.0067\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0028 - val_loss: 0.0062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0030 - val_loss: 0.0052\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0028 - val_loss: 0.0086\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0067 - val_loss: 0.0115\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0049 - val_loss: 0.0096\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0045 - val_loss: 0.0087\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0041 - val_loss: 0.0094\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0039 - val_loss: 0.0082\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0022 - val_loss: 0.0042\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0026 - val_loss: 0.0056\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0041 - val_loss: 0.0145\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0051 - val_loss: 0.0110\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0040 - val_loss: 0.0048\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0019 - val_loss: 0.0055\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0024 - val_loss: 0.0074\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 15s 4ms/step - loss: 0.0419 - val_loss: 0.0074\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0124 - val_loss: 0.0089\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0065 - val_loss: 0.0205\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 0.0088 - val_loss: 0.0091\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0045 - val_loss: 0.0125\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 0.0068 - val_loss: 0.0122\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 0.0061 - val_loss: 0.0156\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0056 - val_loss: 0.0064\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0035 - val_loss: 0.0137\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0064 - val_loss: 0.0128\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0057 - val_loss: 0.0181\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 0.0063 - val_loss: 0.0106\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0038 - val_loss: 0.0117\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 0.0042 - val_loss: 0.0133\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 0.0043 - val_loss: 0.0077\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0028 - val_loss: 0.0094\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 0.0027 - val_loss: 0.0108\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0051 - val_loss: 0.0082\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0024 - val_loss: 0.0142\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: 0.0046 - val_loss: 0.0101\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0034 - val_loss: 0.0076\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 0.0020 - val_loss: 0.0098\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0026 - val_loss: 0.0072\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 0.0022 - val_loss: 0.0094\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 14s 4ms/step - loss: 0.0697 - val_loss: 0.0039\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 495us/step - loss: 0.0170 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0058 - val_loss: 0.0311\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0102 - val_loss: 0.0094\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0090 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0083 - val_loss: 0.0189\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0112 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 497us/step - loss: 0.0015 - val_loss: 6.7096e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0101 - val_loss: 0.0049\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0039 - val_loss: 7.5669e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0060 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0054 - val_loss: 6.7881e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 500us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 495us/step - loss: 0.0096 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 499us/step - loss: 0.0012 - val_loss: 6.7659e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 496us/step - loss: 0.0054 - val_loss: 9.8733e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 495us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 497us/step - loss: 0.0044 - val_loss: 9.6041e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 494us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 498us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 499us/step - loss: 0.0053 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 497us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 498us/step - loss: 0.0022 - val_loss: 0.0078\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 498us/step - loss: 0.0045 - val_loss: 8.8676e-04\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 16s 4ms/step - loss: 0.1029 - val_loss: 0.0288\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0306 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 0.0090 - val_loss: 0.0140\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0053 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 600us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0014 - val_loss: 7.0731e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0013 - val_loss: 8.3683e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0013 - val_loss: 6.7450e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 0.0013 - val_loss: 7.3179e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 0.0011 - val_loss: 5.9198e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0012 - val_loss: 7.8772e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0010 - val_loss: 5.8783e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 0.0011 - val_loss: 6.0506e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0011 - val_loss: 5.2874e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 15s 4ms/step - loss: 0.0631 - val_loss: 0.0129\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 0.0156 - val_loss: 0.0134\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: 0.0063 - val_loss: 0.0084\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0028 - val_loss: 8.6822e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0016 - val_loss: 8.6315e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0014 - val_loss: 6.6274e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 9.9391e-04 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 9.3978e-04 - val_loss: 9.8721e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 9.1925e-04 - val_loss: 9.1894e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 9.2906e-04 - val_loss: 5.7169e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 9.7087e-04 - val_loss: 5.2051e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 9.7184e-04 - val_loss: 6.1164e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 8.9615e-04 - val_loss: 8.0428e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 8.5173e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 8.4080e-04 - val_loss: 6.5472e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 8.5169e-04 - val_loss: 8.7536e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 8.3469e-04 - val_loss: 7.7332e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 8.0661e-04 - val_loss: 6.1171e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 8.1643e-04 - val_loss: 9.9432e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 7.6821e-04 - val_loss: 9.1735e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 7.9214e-04 - val_loss: 0.0017\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 16s 4ms/step - loss: 0.0487 - val_loss: 0.0124\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0091 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 599us/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 599us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0013 - val_loss: 6.8384e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0012 - val_loss: 8.7359e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 9.5896e-04 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 8.9646e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 8.8087e-04 - val_loss: 8.0711e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 8.8817e-04 - val_loss: 9.9264e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 600us/step - loss: 8.5802e-04 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 599us/step - loss: 8.5866e-04 - val_loss: 7.9434e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 8.4143e-04 - val_loss: 7.8432e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: 8.2787e-04 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 8.2631e-04 - val_loss: 6.2446e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 7.8229e-04 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 7.9233e-04 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 8.0502e-04 - val_loss: 8.2785e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 600us/step - loss: 7.6520e-04 - val_loss: 6.9913e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 598us/step - loss: 7.3794e-04 - val_loss: 6.6185e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 16s 4ms/step - loss: 1516154.5840 - val_loss: 108.8248\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 36852.4354 - val_loss: 853.2997\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 599us/step - loss: 587.2401 - val_loss: 385.7169\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 266.2220 - val_loss: 231.3788\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 154.0337 - val_loss: 165.3513\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 124.2819 - val_loss: 130.5268\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 99.9961 - val_loss: 109.3844\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: 84.6000 - val_loss: 94.6759\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 75.2261 - val_loss: 83.6903\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 69.7436 - val_loss: 74.7869\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 65.3855 - val_loss: 67.2660\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 60.2048 - val_loss: 60.8918\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 56.3513 - val_loss: 55.4312\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 54.5357 - val_loss: 50.7065\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 49.0340 - val_loss: 46.4107\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 576us/step - loss: 46.7773 - val_loss: 42.7771\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 45.2671 - val_loss: 39.5644\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 42.8685 - val_loss: 36.6601\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 41.1054 - val_loss: 34.0220\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 41.3266 - val_loss: 31.5055\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 39.1966 - val_loss: 28.9974\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 36.1183 - val_loss: 26.1719\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 36.6083 - val_loss: 21.9451\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 33.0790 - val_loss: 13.8381\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 17s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 17s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 17s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 18s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 18s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 593us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 18s 5ms/step - loss: 0.0552 - val_loss: 0.0143\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0109 - val_loss: 6.9372e-04\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0056 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0016 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: 0.0010 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 9.7891e-04 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 9.3992e-04 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: 9.3553e-04 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 9.1252e-04 - val_loss: 9.9249e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 8.5371e-04 - val_loss: 8.2678e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 8.5436e-04 - val_loss: 9.9469e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: 8.2405e-04 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 8.0956e-04 - val_loss: 6.5096e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 8.3894e-04 - val_loss: 9.5578e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 8.0107e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 7.8062e-04 - val_loss: 5.9832e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: 7.5968e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 8.0022e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 7.9764e-04 - val_loss: 0.0012\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 18s 5ms/step - loss: 0.0512 - val_loss: 0.0162\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: 0.0100 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0047 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 0.0015 - val_loss: 6.8982e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0012 - val_loss: 5.4142e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0012 - val_loss: 5.4277e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0011 - val_loss: 6.2035e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0010 - val_loss: 6.2512e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 9.9375e-04 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 9.8392e-04 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 0.0010 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: 9.0524e-04 - val_loss: 8.0679e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: 8.6341e-04 - val_loss: 6.6562e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: 8.8214e-04 - val_loss: 7.1509e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 8.6153e-04 - val_loss: 6.6729e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 8.1870e-04 - val_loss: 8.1556e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 7.8980e-04 - val_loss: 7.9196e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: 7.5601e-04 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: 8.2960e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: 8.0699e-04 - val_loss: 4.6896e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 8.5222e-04 - val_loss: 0.0014\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 19s 5ms/step - loss: 0.0816 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0108 - val_loss: 0.0069\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0062 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0036 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 515us/step - loss: 0.0028 - val_loss: 5.9392e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 515us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0017 - val_loss: 9.9561e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0015 - val_loss: 9.5712e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0014 - val_loss: 9.4095e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0013 - val_loss: 7.9425e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0013 - val_loss: 5.9340e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0013 - val_loss: 7.3338e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0013 - val_loss: 6.2771e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0012 - val_loss: 7.7521e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0012 - val_loss: 7.5227e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0012 - val_loss: 7.3747e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0011 - val_loss: 8.9855e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 19s 5ms/step - loss: 0.0513 - val_loss: 0.0051\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0070 - val_loss: 5.5968e-04\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0035 - val_loss: 7.7107e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0019 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0015 - val_loss: 5.2611e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0013 - val_loss: 5.5925e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0012 - val_loss: 5.4377e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0011 - val_loss: 6.5095e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 515us/step - loss: 0.0011 - val_loss: 5.4654e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0011 - val_loss: 5.5762e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0010 - val_loss: 8.9851e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0010 - val_loss: 7.4527e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 9.9155e-04 - val_loss: 4.9546e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 9.8425e-04 - val_loss: 5.2635e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 9.1883e-04 - val_loss: 5.5083e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 8.8737e-04 - val_loss: 5.6765e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 8.5409e-04 - val_loss: 5.3959e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 8.8078e-04 - val_loss: 4.5715e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 8.7889e-04 - val_loss: 6.3533e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 8.0676e-04 - val_loss: 4.0071e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 8.9705e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 8.8352e-04 - val_loss: 5.4293e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 19s 5ms/step - loss: 0.0783 - val_loss: 0.0712\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0718 - val_loss: 0.0383\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0654 - val_loss: 0.0219\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 449us/step - loss: 0.0562 - val_loss: 0.0223\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0445 - val_loss: 0.0488\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0486 - val_loss: 0.0468\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0614 - val_loss: 0.0374\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0665 - val_loss: 0.0413\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 449us/step - loss: 0.0674 - val_loss: 0.0375\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0672 - val_loss: 0.0382\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0655 - val_loss: 0.0305\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0588 - val_loss: 0.0093\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0703 - val_loss: 0.0566\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 444us/step - loss: 0.0568 - val_loss: 0.0244\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0187 - val_loss: 0.0383\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0124 - val_loss: 0.0567\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0893 - val_loss: 0.0071\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 444us/step - loss: 0.0852 - val_loss: 0.1198\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 443us/step - loss: 0.0759 - val_loss: 0.0187\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 443us/step - loss: 0.0735 - val_loss: 0.0273\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0689 - val_loss: 0.0554\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0693 - val_loss: 0.0402\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 442us/step - loss: 0.0683 - val_loss: 0.0326\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0682 - val_loss: 0.0400\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 20s 5ms/step - loss: 2.2540 - val_loss: 2.1298\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 1.4310 - val_loss: 1.4004\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.9007 - val_loss: 0.9227\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.5640 - val_loss: 0.6027\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.3513 - val_loss: 0.3898\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.2204 - val_loss: 0.2514\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.1443 - val_loss: 0.1630\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.1025 - val_loss: 0.1081\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0816 - val_loss: 0.0749\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0726 - val_loss: 0.0558\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0692 - val_loss: 0.0452\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0683 - val_loss: 0.0394\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0681 - val_loss: 0.0368\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0682 - val_loss: 0.0359\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0682 - val_loss: 0.0359\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0682 - val_loss: 0.0364\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0682 - val_loss: 0.0370\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0682 - val_loss: 0.0379\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0681 - val_loss: 0.0379\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0681 - val_loss: 0.0382\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0681 - val_loss: 0.0384\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0681 - val_loss: 0.0386\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0681 - val_loss: 0.0386\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0681 - val_loss: 0.0387\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 21s 6ms/step - loss: 0.4476 - val_loss: 8.9818e-04\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 0.0059 - val_loss: 5.9939e-04\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0036 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: 0.0150 - val_loss: 0.0094\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0139 - val_loss: 0.0147\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0172 - val_loss: 0.0220\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0152 - val_loss: 0.0183\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 0.0207 - val_loss: 0.0503\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0210 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0039 - val_loss: 0.0365\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0182 - val_loss: 0.0104\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 0.0109 - val_loss: 0.0061\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0098 - val_loss: 0.0245\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0199 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0023 - val_loss: 4.9285e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0129 - val_loss: 0.0067\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0069 - val_loss: 4.2060e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0076 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0069 - val_loss: 0.0094\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0108 - val_loss: 4.4662e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0086 - val_loss: 8.1341e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0043 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0069 - val_loss: 0.0193\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 20s 6ms/step - loss: 0.1393 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0185 - val_loss: 0.0093\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0140 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0121 - val_loss: 0.0136\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0115 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0104 - val_loss: 0.0072\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0075 - val_loss: 0.0082\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0104 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0072 - val_loss: 0.0054\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0072 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0045 - val_loss: 0.0205\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0066 - val_loss: 9.5554e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0052 - val_loss: 0.0076\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0049 - val_loss: 0.0086\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0065 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0037 - val_loss: 0.0082\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0037 - val_loss: 0.0046\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 20s 5ms/step - loss: 0.1427 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0073 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0055 - val_loss: 0.0087\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0046 - val_loss: 0.0086\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0028 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0021 - val_loss: 0.0070\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0054 - val_loss: 0.0146\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0016 - val_loss: 0.0091\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0014 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0051\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0010 - val_loss: 5.8717e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0021 - val_loss: 7.5621e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 21s 6ms/step - loss: 0.5913 - val_loss: 0.0080\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 425us/step - loss: 0.0916 - val_loss: 0.0200\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 426us/step - loss: 0.0701 - val_loss: 0.0316\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 425us/step - loss: 0.0685 - val_loss: 0.0352\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 427us/step - loss: 0.0682 - val_loss: 0.0371\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 423us/step - loss: 0.0681 - val_loss: 0.0412\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 427us/step - loss: 0.0682 - val_loss: 0.0400\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 426us/step - loss: 0.0681 - val_loss: 0.0367\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 431us/step - loss: 0.0682 - val_loss: 0.0385\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 424us/step - loss: 0.0682 - val_loss: 0.0397\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 427us/step - loss: 0.0681 - val_loss: 0.0395\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 426us/step - loss: 0.0682 - val_loss: 0.0402\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 428us/step - loss: 0.0682 - val_loss: 0.0387\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 425us/step - loss: 0.0681 - val_loss: 0.0392\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 427us/step - loss: 0.0681 - val_loss: 0.0395\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 430us/step - loss: 0.0681 - val_loss: 0.0396\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 427us/step - loss: 0.0681 - val_loss: 0.0418\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 427us/step - loss: 0.0681 - val_loss: 0.0381\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 439us/step - loss: 0.0681 - val_loss: 0.0410\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 438us/step - loss: 0.0681 - val_loss: 0.0429\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 431us/step - loss: 0.0681 - val_loss: 0.0407\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 423us/step - loss: 0.0679 - val_loss: 0.0388\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 425us/step - loss: 0.0681 - val_loss: 0.0386\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 431us/step - loss: 0.0678 - val_loss: 0.0377\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 21s 6ms/step - loss: 0.0563 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0066 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0036 - val_loss: 5.1136e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0025 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0017 - val_loss: 5.9899e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0014 - val_loss: 5.4242e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0013 - val_loss: 9.2024e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0011 - val_loss: 9.5283e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0011 - val_loss: 9.7724e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 9.9749e-04 - val_loss: 9.6092e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 9.8722e-04 - val_loss: 5.6044e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 9.5752e-04 - val_loss: 4.0386e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 8.8553e-04 - val_loss: 5.3849e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 9.0773e-04 - val_loss: 7.5199e-04\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 521us/step - loss: 8.7308e-04 - val_loss: 4.1714e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 8.4422e-04 - val_loss: 4.1839e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 8.2048e-04 - val_loss: 5.2629e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 7.5509e-04 - val_loss: 4.0564e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 7.8497e-04 - val_loss: 3.7924e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 7.7521e-04 - val_loss: 4.7637e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 22s 6ms/step - loss: 2.2146 - val_loss: 0.0200\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.1654 - val_loss: 0.0359\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0878 - val_loss: 0.1017\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0724 - val_loss: 0.0176\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0742 - val_loss: 0.0281\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0685 - val_loss: 0.0545\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0695 - val_loss: 0.0429\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0681 - val_loss: 0.0326\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0682 - val_loss: 0.0393\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0679 - val_loss: 0.0410\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 526us/step - loss: 0.0675 - val_loss: 0.0366\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0661 - val_loss: 0.0352\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0641 - val_loss: 0.0309\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0680 - val_loss: 0.0395\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0658 - val_loss: 0.0380\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0581 - val_loss: 0.0216\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0428 - val_loss: 0.0058\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0250 - val_loss: 0.0488\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0256 - val_loss: 0.0974\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0173 - val_loss: 0.0449\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0133 - val_loss: 0.0497\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0119 - val_loss: 0.0326\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 526us/step - loss: 0.0089 - val_loss: 0.0462\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0075 - val_loss: 0.0296\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 22s 6ms/step - loss: 1.1877 - val_loss: 0.2283\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.2032 - val_loss: 0.0744\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0984 - val_loss: 0.1396\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0859 - val_loss: 0.0455\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0660 - val_loss: 0.0092\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0573 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0187 - val_loss: 0.0488\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0119 - val_loss: 0.0740\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0083 - val_loss: 0.0201\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0052 - val_loss: 0.0268\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0014 - val_loss: 8.2909e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0014 - val_loss: 9.1586e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0014 - val_loss: 9.5512e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 22s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 23s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 23s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 437us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 23s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 433us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 437us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 431us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 432us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 430us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 24s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 437us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 440us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 439us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 448us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 434us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 437us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 438us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 436us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 433us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 25s 7ms/step - loss: 0.0851 - val_loss: 0.0525\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0203 - val_loss: 0.0149\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0077 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0035 - val_loss: 7.7748e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0017 - val_loss: 5.9208e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0015 - val_loss: 6.6637e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0015 - val_loss: 5.7542e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0014 - val_loss: 7.2510e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0014 - val_loss: 5.8554e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0012 - val_loss: 6.2615e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0012 - val_loss: 7.2237e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0011 - val_loss: 8.0548e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0010 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 9.3206e-04 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 9.4503e-04 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 9.6236e-04 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 8.5453e-04 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 9.0570e-04 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 8.1534e-04 - val_loss: 0.0030\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 25s 7ms/step - loss: 0.0458 - val_loss: 0.0174\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0086 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0042 - val_loss: 9.0809e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0026 - val_loss: 0.0044\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0016 - val_loss: 7.7334e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0015 - val_loss: 7.8233e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0015 - val_loss: 6.5925e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0013 - val_loss: 5.6781e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0013 - val_loss: 5.0711e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0013 - val_loss: 4.6730e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0012 - val_loss: 5.6013e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0012 - val_loss: 6.3451e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0012 - val_loss: 6.7592e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0011 - val_loss: 5.9991e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0011 - val_loss: 6.4769e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 526us/step - loss: 0.0010 - val_loss: 9.4973e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0010 - val_loss: 8.9301e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 9.9512e-04 - val_loss: 5.2497e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 9.2019e-04 - val_loss: 6.2927e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 9.4335e-04 - val_loss: 8.2993e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 26s 7ms/step - loss: 0.0745 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0091 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0048 - val_loss: 5.9067e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0022 - val_loss: 6.2821e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0019 - val_loss: 9.0390e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 526us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0014 - val_loss: 5.2736e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0014 - val_loss: 7.2971e-04\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0013 - val_loss: 6.7290e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0012 - val_loss: 6.8460e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0012 - val_loss: 6.6587e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0012 - val_loss: 5.9076e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0011 - val_loss: 5.2210e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0011 - val_loss: 4.6488e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0011 - val_loss: 7.4703e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0010 - val_loss: 4.2469e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0010 - val_loss: 4.2590e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0010 - val_loss: 5.9039e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 25s 7ms/step - loss: 0.0511 - val_loss: 0.0198\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0088 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0043 - val_loss: 9.2660e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0030 - val_loss: 5.1686e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0018 - val_loss: 9.3268e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0016 - val_loss: 7.9683e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0017 - val_loss: 8.4165e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0016 - val_loss: 7.2745e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0015 - val_loss: 9.5218e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0014 - val_loss: 6.0746e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0014 - val_loss: 5.3974e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0014 - val_loss: 4.5619e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0013 - val_loss: 4.1859e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0014 - val_loss: 4.5705e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0013 - val_loss: 9.4965e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0012 - val_loss: 6.8499e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0012 - val_loss: 4.0910e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0011 - val_loss: 4.6519e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0011 - val_loss: 4.3589e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0011 - val_loss: 4.7328e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0010 - val_loss: 4.0591e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 26s 7ms/step - loss: 0.1079 - val_loss: 0.0344\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0230 - val_loss: 0.0244\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0096 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0035 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 8.0024e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0017 - val_loss: 6.7313e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0016 - val_loss: 8.4626e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0016 - val_loss: 7.5397e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0013 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0012 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0011 - val_loss: 0.0076\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0010 - val_loss: 0.0041\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 27s 7ms/step - loss: 0.1285 - val_loss: 0.0267\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0204 - val_loss: 0.0166\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0075 - val_loss: 9.8411e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0033 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 7.9872e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0013 - val_loss: 0.0043\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0014 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0012 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0011 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0010 - val_loss: 0.0058\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 26s 7ms/step - loss: 0.1206 - val_loss: 0.0176\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0196 - val_loss: 0.0171\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0042 - val_loss: 9.8527e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0018 - val_loss: 8.2161e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0016 - val_loss: 8.3745e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0013 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0012 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0012 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0012 - val_loss: 0.0043\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0011 - val_loss: 0.0047\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 27s 7ms/step - loss: 0.0887 - val_loss: 0.0565\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0198 - val_loss: 0.0083\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0075 - val_loss: 7.6408e-04\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0029 - val_loss: 6.4492e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0021 - val_loss: 9.8738e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0022 - val_loss: 8.6889e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0013 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 0.0056\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 0.0042\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 0.0093\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0013 - val_loss: 0.0070\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0011 - val_loss: 0.0053\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0011 - val_loss: 0.0050\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0010 - val_loss: 0.0076\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 27s 7ms/step - loss: 0.1026 - val_loss: 0.0087\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0195 - val_loss: 0.0260\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0153 - val_loss: 0.0117\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0127 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0072 - val_loss: 0.0119\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0108 - val_loss: 0.0120\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0081 - val_loss: 0.0083\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0068 - val_loss: 0.0114\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0072 - val_loss: 0.0128\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0055 - val_loss: 0.0062\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0054 - val_loss: 0.0075\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0046 - val_loss: 0.0044\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0040 - val_loss: 0.0152\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0077 - val_loss: 0.0074\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0043 - val_loss: 0.0094\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0053 - val_loss: 0.0085\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0045 - val_loss: 0.0072\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0044 - val_loss: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0046 - val_loss: 0.0066\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0040 - val_loss: 0.0085\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0047 - val_loss: 0.0071\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 28s 8ms/step - loss: 0.0801 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0095 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0064 - val_loss: 0.0140\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0036 - val_loss: 5.6322e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 0.0017 - val_loss: 7.0117e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 0.0014 - val_loss: 7.5748e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 0.0012 - val_loss: 9.7218e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0011 - val_loss: 6.2273e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 0.0011 - val_loss: 7.8629e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 0.0010 - val_loss: 9.1728e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0011 - val_loss: 7.4599e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 9.9151e-04 - val_loss: 6.4186e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 9.9685e-04 - val_loss: 6.2973e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 9.5730e-04 - val_loss: 7.7784e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: 8.9054e-04 - val_loss: 6.8064e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 8.8620e-04 - val_loss: 7.7934e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 8.5905e-04 - val_loss: 7.7458e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: 8.4895e-04 - val_loss: 8.7054e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 8.3812e-04 - val_loss: 5.3195e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 7.8996e-04 - val_loss: 4.9632e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 8.1225e-04 - val_loss: 4.7331e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 27s 7ms/step - loss: 0.0626 - val_loss: 0.0172\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0108 - val_loss: 8.6402e-04\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 513us/step - loss: 0.0023 - val_loss: 7.8405e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0020 - val_loss: 5.1074e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 515us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0015 - val_loss: 6.3020e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0015 - val_loss: 4.9167e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 513us/step - loss: 0.0015 - val_loss: 5.6483e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0014 - val_loss: 5.4732e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0013 - val_loss: 5.5569e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0013 - val_loss: 5.3851e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 514us/step - loss: 0.0013 - val_loss: 6.5748e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 515us/step - loss: 0.0012 - val_loss: 7.0735e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0012 - val_loss: 9.8285e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 515us/step - loss: 0.0012 - val_loss: 4.8612e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0012 - val_loss: 4.2590e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0011 - val_loss: 5.0172e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 515us/step - loss: 0.0011 - val_loss: 5.0851e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0011 - val_loss: 5.1669e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0012 - val_loss: 4.3015e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 28s 8ms/step - loss: 1.4644 - val_loss: 0.2795\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.1838 - val_loss: 0.1247\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.1111 - val_loss: 0.0894\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0695 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0650 - val_loss: 0.0233\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0297 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0083 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0038 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 515us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0030 - val_loss: 8.3663e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0029 - val_loss: 7.6297e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0028 - val_loss: 8.6303e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 523us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0027 - val_loss: 7.7199e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0024 - val_loss: 8.7696e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0024 - val_loss: 7.3521e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0021 - val_loss: 7.7100e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0021 - val_loss: 6.8439e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0021 - val_loss: 6.7153e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 28s 8ms/step - loss: 0.0955 - val_loss: 0.0813\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0686 - val_loss: 0.0320\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0622 - val_loss: 0.0306\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0538 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0742 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0390 - val_loss: 0.0223\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0258 - val_loss: 0.0772\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0191 - val_loss: 0.0270\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0064 - val_loss: 0.0280\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0084 - val_loss: 0.0383\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0112 - val_loss: 0.0496\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0091 - val_loss: 0.0298\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0083 - val_loss: 0.0408\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0091 - val_loss: 0.0386\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0083 - val_loss: 0.0318\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0088 - val_loss: 0.0291\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0086 - val_loss: 0.0298\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0064 - val_loss: 0.0279\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0066 - val_loss: 0.0400\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0106 - val_loss: 0.0339\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 522us/step - loss: 0.0083 - val_loss: 0.0356\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 517us/step - loss: 0.0091 - val_loss: 0.0310\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0068 - val_loss: 0.0233\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0050 - val_loss: 0.0190\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 29s 8ms/step - loss: 0.0819 - val_loss: 0.0314\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0603 - val_loss: 0.0224\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0552 - val_loss: 0.1495\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0681 - val_loss: 0.0293\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0528 - val_loss: 0.0480\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0244 - val_loss: 0.0101\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0177 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0097 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0077 - val_loss: 0.0076\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0125 - val_loss: 0.0076\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0131 - val_loss: 0.0060\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0112 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0079 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 520us/step - loss: 0.0104 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0098 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 516us/step - loss: 0.0112 - val_loss: 0.0083\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0089 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0069 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0123 - val_loss: 0.0081\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0114 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 521us/step - loss: 0.0063 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0064 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 518us/step - loss: 0.0098 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 519us/step - loss: 0.0069 - val_loss: 0.0019\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 28s 8ms/step - loss: 2.3428 - val_loss: 0.0254\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 442us/step - loss: 0.0619 - val_loss: 0.2918\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 444us/step - loss: 0.0824 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 443us/step - loss: 0.0258 - val_loss: 0.0404\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0648 - val_loss: 0.0116\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0297 - val_loss: 0.0081\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 444us/step - loss: 0.0304 - val_loss: 0.0119\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 444us/step - loss: 0.0298 - val_loss: 0.0120\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0316 - val_loss: 0.0125\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 442us/step - loss: 0.0344 - val_loss: 0.0226\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0216 - val_loss: 0.0112\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0260 - val_loss: 0.0203\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 444us/step - loss: 0.0263 - val_loss: 0.0097\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 442us/step - loss: 0.0267 - val_loss: 0.0348\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 443us/step - loss: 0.0277 - val_loss: 0.0086\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 449us/step - loss: 0.0174 - val_loss: 0.0042\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 442us/step - loss: 0.0174 - val_loss: 0.0212\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 444us/step - loss: 0.0229 - val_loss: 0.0138\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0190 - val_loss: 0.0243\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0224 - val_loss: 0.0160\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 445us/step - loss: 0.0198 - val_loss: 0.0187\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 442us/step - loss: 0.0183 - val_loss: 0.0121\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 442us/step - loss: 0.0150 - val_loss: 0.0133\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 446us/step - loss: 0.0141 - val_loss: 0.0208\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 31s 8ms/step - loss: 1.3770 - val_loss: 0.0275\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 454us/step - loss: 0.0727 - val_loss: 0.0507\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 449us/step - loss: 0.0498 - val_loss: 0.0408\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 454us/step - loss: 0.0370 - val_loss: 0.0109\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0332 - val_loss: 0.0279\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0310 - val_loss: 0.0141\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0248 - val_loss: 0.0103\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0223 - val_loss: 0.0101\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 456us/step - loss: 0.0202 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0137 - val_loss: 0.0111\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0238 - val_loss: 0.0215\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 449us/step - loss: 0.0195 - val_loss: 0.0072\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0131 - val_loss: 0.0208\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0192 - val_loss: 0.0242\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 450us/step - loss: 0.0194 - val_loss: 0.0111\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0152 - val_loss: 0.0095\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0113 - val_loss: 0.0096\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 458us/step - loss: 0.0174 - val_loss: 0.0178\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 455us/step - loss: 0.0166 - val_loss: 0.0245\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0151 - val_loss: 0.0062\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0127 - val_loss: 0.0068\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0115 - val_loss: 0.0186\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 29s 8ms/step - loss: 0.2493 - val_loss: 0.1175\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0783 - val_loss: 0.0552\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 457us/step - loss: 0.0690 - val_loss: 0.0435\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0684 - val_loss: 0.0406\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 456us/step - loss: 0.0683 - val_loss: 0.0387\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0683 - val_loss: 0.0388\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0683 - val_loss: 0.0411\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 457us/step - loss: 0.0683 - val_loss: 0.0371\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 453us/step - loss: 0.0683 - val_loss: 0.0357\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 449us/step - loss: 0.0683 - val_loss: 0.0390\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0683 - val_loss: 0.0390\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 458us/step - loss: 0.0683 - val_loss: 0.0391\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 453us/step - loss: 0.0683 - val_loss: 0.0408\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 449us/step - loss: 0.0683 - val_loss: 0.0386\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 453us/step - loss: 0.0683 - val_loss: 0.0405\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 454us/step - loss: 0.0683 - val_loss: 0.0413\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 453us/step - loss: 0.0683 - val_loss: 0.0381\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 453us/step - loss: 0.0683 - val_loss: 0.0361\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0683 - val_loss: 0.0380\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0683 - val_loss: 0.0389\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 456us/step - loss: 0.0683 - val_loss: 0.0371\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 455us/step - loss: 0.0683 - val_loss: 0.0380\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 450us/step - loss: 0.0683 - val_loss: 0.0403\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 453us/step - loss: 0.0683 - val_loss: 0.0363\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 30s 8ms/step - loss: 0.0945 - val_loss: 0.0398\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 450us/step - loss: 0.0425 - val_loss: 0.0203\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 454us/step - loss: 0.0372 - val_loss: 0.0158\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 462us/step - loss: 0.0335 - val_loss: 0.0130\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 458us/step - loss: 0.0306 - val_loss: 0.0123\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0276 - val_loss: 0.0105\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 456us/step - loss: 0.0247 - val_loss: 0.0088\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0219 - val_loss: 0.0074\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0193 - val_loss: 0.0059\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0170 - val_loss: 0.0051\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 458us/step - loss: 0.0148 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 454us/step - loss: 0.0130 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0114 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 450us/step - loss: 0.0101 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0088 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0080 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 454us/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 452us/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 453us/step - loss: 0.0059 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 454us/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 450us/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 451us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 450us/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 457us/step - loss: 0.0046 - val_loss: 0.0025\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 31s 8ms/step - loss: 0.2354 - val_loss: 0.0162\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0871 - val_loss: 0.0921\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0654 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0378 - val_loss: 0.0252\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0108 - val_loss: 0.0185\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0062 - val_loss: 0.0119\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0033 - val_loss: 0.0116\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: 0.0021 - val_loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0014 - val_loss: 8.0266e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0014 - val_loss: 7.4546e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0012 - val_loss: 6.8155e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0012 - val_loss: 9.7257e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 526us/step - loss: 0.0011 - val_loss: 6.2067e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 33s 9ms/step - loss: 0.0721 - val_loss: 0.0087\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0092 - val_loss: 0.0078\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: 0.0021 - val_loss: 5.2627e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0016 - val_loss: 7.3095e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 5.2016e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0013 - val_loss: 6.3664e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0013 - val_loss: 6.8358e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0012 - val_loss: 9.2739e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0011 - val_loss: 8.2004e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 526us/step - loss: 0.0011 - val_loss: 8.4929e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 9.9060e-04 - val_loss: 8.8667e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 9.9047e-04 - val_loss: 6.7845e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 9.4119e-04 - val_loss: 5.9886e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 526us/step - loss: 9.1525e-04 - val_loss: 6.8220e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 9.3783e-04 - val_loss: 5.1370e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 8.6902e-04 - val_loss: 4.7532e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 8.7472e-04 - val_loss: 4.7000e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 32s 9ms/step - loss: 1.1646 - val_loss: 0.1892\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.1291 - val_loss: 0.1737\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: 0.1007 - val_loss: 0.0315\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0724 - val_loss: 0.0124\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0593 - val_loss: 0.0384\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: 0.0361 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 526us/step - loss: 0.0082 - val_loss: 0.0150\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: 0.0057 - val_loss: 0.0104\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 526us/step - loss: 0.0040 - val_loss: 0.0063\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 524us/step - loss: 0.0019 - val_loss: 8.6387e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0018 - val_loss: 9.9936e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0017 - val_loss: 8.1127e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0018 - val_loss: 9.1258e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0016 - val_loss: 9.0587e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0016 - val_loss: 7.2293e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0015 - val_loss: 7.7281e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 527us/step - loss: 0.0016 - val_loss: 7.1516e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 33s 9ms/step - loss: 0.1076 - val_loss: 0.0148\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0421 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0078 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0022 - val_loss: 0.0103\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0011 - val_loss: 8.2085e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0010 - val_loss: 7.7827e-04\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 543us/step - loss: 9.5985e-04 - val_loss: 6.0337e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 9.6929e-04 - val_loss: 5.6426e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 9.3956e-04 - val_loss: 5.3616e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 9.5882e-04 - val_loss: 5.3094e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 8.8169e-04 - val_loss: 7.3584e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.5590e-04 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 9.1451e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 8.9892e-04 - val_loss: 6.8614e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 8.0422e-04 - val_loss: 5.2848e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 7.4820e-04 - val_loss: 7.5856e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 7.6739e-04 - val_loss: 4.5968e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 7.2208e-04 - val_loss: 4.5974e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 33s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 34s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 35s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 618us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 36s 10ms/step - loss: 0.0567 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 624us/step - loss: 0.0038 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 633us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 634us/step - loss: 0.0019 - val_loss: 9.4641e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 621us/step - loss: 0.0017 - val_loss: 8.3158e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 617us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: 0.0014 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: 0.0013 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: 0.0013 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: 0.0012 - val_loss: 0.0038\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: 0.0012 - val_loss: 0.0046\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: 0.0012 - val_loss: 0.0048\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: 0.0012 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: 0.0011 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 611us/step - loss: 0.0011 - val_loss: 0.0051\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: 0.0012 - val_loss: 0.0061\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: 0.0012 - val_loss: 0.0090\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: 0.0013 - val_loss: 0.0071\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: 0.0011 - val_loss: 0.0062\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 36s 10ms/step - loss: 2.0588 - val_loss: 0.0107\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 611us/step - loss: 0.0071 - val_loss: 0.0142\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: 0.0058 - val_loss: 0.0070\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 611us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: 0.0032 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: 0.0041 - val_loss: 0.0124\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: 0.0027 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 608us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: 0.0023 - val_loss: 6.7939e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: 0.0031 - val_loss: 6.9612e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: 0.0023 - val_loss: 8.7702e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: 0.0021 - val_loss: 6.9637e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: 0.0026 - val_loss: 8.5082e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 611us/step - loss: 0.0024 - val_loss: 6.9836e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: 0.0022 - val_loss: 6.9947e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 616us/step - loss: 0.0022 - val_loss: 6.2659e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: 0.0021 - val_loss: 6.2360e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: 0.0024 - val_loss: 6.4674e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: 0.0020 - val_loss: 6.7465e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 609us/step - loss: 0.0019 - val_loss: 9.4757e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 36s 10ms/step - loss: 1.8043 - val_loss: 0.1973\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 0.1657 - val_loss: 0.3508\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.1556 - val_loss: 0.0225\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0929 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0670 - val_loss: 0.0771\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0500 - val_loss: 0.0078\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0185 - val_loss: 0.0209\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0065 - val_loss: 0.0056\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0019 - val_loss: 8.7211e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0018 - val_loss: 9.0940e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0016 - val_loss: 8.4785e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0015 - val_loss: 9.5533e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0014 - val_loss: 7.4663e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0014 - val_loss: 7.6746e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0013 - val_loss: 8.8814e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0014 - val_loss: 7.8111e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0013 - val_loss: 7.1570e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0013 - val_loss: 7.1958e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0013 - val_loss: 8.0940e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 36s 10ms/step - loss: 0.3280 - val_loss: 0.0068\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0879 - val_loss: 0.1307\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0711 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0534 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: 0.0100 - val_loss: 0.0085\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0091 - val_loss: 0.0086\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 528us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0032 - val_loss: 0.0108\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0026 - val_loss: 0.0066\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 525us/step - loss: 0.0017 - val_loss: 9.1818e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0017 - val_loss: 8.6550e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0015 - val_loss: 7.8992e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0015 - val_loss: 8.7395e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0014 - val_loss: 6.8869e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0014 - val_loss: 7.5106e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 36s 10ms/step - loss: 2.1733 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0231 - val_loss: 0.0196\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0277 - val_loss: 0.0101\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0205 - val_loss: 0.0557\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0345 - val_loss: 0.0126\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0264 - val_loss: 0.0325\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0406 - val_loss: 0.0459\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0607 - val_loss: 0.0610\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0576 - val_loss: 0.0530\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0728 - val_loss: 0.0621\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0688 - val_loss: 0.0716\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0717 - val_loss: 0.0318\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 529us/step - loss: 0.0450 - val_loss: 0.0756\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0859 - val_loss: 0.1210\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0790 - val_loss: 0.0294\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0291 - val_loss: 0.0650\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0519 - val_loss: 0.0679\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: 0.0514 - val_loss: 0.0477\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0344 - val_loss: 0.0463\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0383 - val_loss: 0.0867\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: 0.0542 - val_loss: 0.0484\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: 0.0352 - val_loss: 0.0679\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0417 - val_loss: 0.0428\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0264 - val_loss: 0.0450\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 37s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 1s 168us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 37s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 37s 10ms/step - loss: 3.1097 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 419us/step - loss: 0.0125 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 418us/step - loss: 0.0078 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 419us/step - loss: 0.0058 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 420us/step - loss: 0.0049 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 415us/step - loss: 0.0046 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 419us/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 421us/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 418us/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 418us/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 416us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 416us/step - loss: 0.0037 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 418us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 421us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 431us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 434us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 416us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 419us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 418us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 420us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 414us/step - loss: 0.0030 - val_loss: 9.9374e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 421us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 425us/step - loss: 0.0030 - val_loss: 8.9996e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 436us/step - loss: 0.0030 - val_loss: 8.1754e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 39s 10ms/step - loss: 3.8723 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 419us/step - loss: 0.0111 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 416us/step - loss: 0.0047 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 435us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 437us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 429us/step - loss: 0.0030 - val_loss: 7.7556e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 436us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 432us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 447us/step - loss: 0.0028 - val_loss: 9.3949e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 426us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 416us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 422us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 419us/step - loss: 0.0025 - val_loss: 7.9842e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 419us/step - loss: 0.0025 - val_loss: 8.7686e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 419us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 420us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 423us/step - loss: 0.0023 - val_loss: 8.9919e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 421us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 419us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 420us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 420us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 420us/step - loss: 0.0021 - val_loss: 8.5339e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 418us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 417us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 39s 11ms/step - loss: 0.1140 - val_loss: 7.9326e-04\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 600us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 600us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 0.0021 - val_loss: 0.0058\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0112 - val_loss: 0.0112\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0071 - val_loss: 0.0100\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0065 - val_loss: 0.0150\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0085 - val_loss: 0.0114\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 610us/step - loss: 0.0032 - val_loss: 0.0112\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 0.0100 - val_loss: 0.0229\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 0.0097 - val_loss: 0.0090\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 0.0057 - val_loss: 0.0163\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0096 - val_loss: 0.0122\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0050 - val_loss: 0.0091\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0054 - val_loss: 0.0050\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: 0.0056 - val_loss: 0.0127\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 0.0070 - val_loss: 0.0116\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 603us/step - loss: 0.0061 - val_loss: 0.0281\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 39s 11ms/step - loss: 0.4195 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 0.0129 - val_loss: 0.0246\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0129 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0040 - val_loss: 0.0082\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0023 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0024 - val_loss: 9.1396e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0018 - val_loss: 8.9374e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0018 - val_loss: 9.1506e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0017 - val_loss: 6.3281e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0016 - val_loss: 6.3427e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0016 - val_loss: 6.4276e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0020 - val_loss: 9.7968e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0016 - val_loss: 8.2124e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0015 - val_loss: 7.5265e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0014 - val_loss: 6.3325e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 0.0016 - val_loss: 5.7874e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 0.0014 - val_loss: 6.2411e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 0.0015 - val_loss: 5.7815e-04\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 39s 11ms/step - loss: 0.1090 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0431 - val_loss: 0.0191\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0119 - val_loss: 0.0388\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0064 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 0.0012 - val_loss: 9.6269e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0011 - val_loss: 9.4040e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0011 - val_loss: 9.3065e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 9.9763e-04 - val_loss: 6.2581e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.9822e-04 - val_loss: 5.9997e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 9.7493e-04 - val_loss: 8.7101e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.6903e-04 - val_loss: 5.8356e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.2955e-04 - val_loss: 8.2783e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.7490e-04 - val_loss: 5.6616e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.2615e-04 - val_loss: 5.1464e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.9858e-04 - val_loss: 5.1176e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.2841e-04 - val_loss: 7.1710e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.1280e-04 - val_loss: 4.9916e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 40s 11ms/step - loss: 0.3850 - val_loss: 0.0332\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 0.1132 - val_loss: 0.1219\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0715 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 0.0573 - val_loss: 0.0072\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0095 - val_loss: 0.0073\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0076 - val_loss: 0.0206\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 0.0037 - val_loss: 0.0149\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 0.0017 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 0.0015 - val_loss: 9.5511e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 0.0013 - val_loss: 9.5441e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0012 - val_loss: 7.0714e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0013 - val_loss: 8.1750e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0012 - val_loss: 6.6848e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0012 - val_loss: 7.8858e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0011 - val_loss: 8.6520e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0011 - val_loss: 6.3002e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 40s 11ms/step - loss: 0.1365 - val_loss: 0.0097\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0545 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0115 - val_loss: 0.0412\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0037 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0024 - val_loss: 0.0046\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0015 - val_loss: 8.1232e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0013 - val_loss: 9.5450e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0012 - val_loss: 6.7558e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0011 - val_loss: 6.4533e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0010 - val_loss: 7.7380e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0010 - val_loss: 5.9472e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 9.8900e-04 - val_loss: 5.5541e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 9.6740e-04 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0011 - val_loss: 5.4866e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 9.9127e-04 - val_loss: 5.7018e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 8.7716e-04 - val_loss: 5.6297e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 8.1226e-04 - val_loss: 5.8928e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.4346e-04 - val_loss: 7.4188e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 8.4939e-04 - val_loss: 9.1735e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.8536e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 8.8569e-04 - val_loss: 4.9615e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 8.1514e-04 - val_loss: 6.7013e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 41s 11ms/step - loss: 0.9690 - val_loss: 0.8042\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.4189 - val_loss: 0.3543\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.1727 - val_loss: 0.1419\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0845 - val_loss: 0.0537\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0688 - val_loss: 0.0243\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0716 - val_loss: 0.0187\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0723 - val_loss: 0.0221\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 0.0701 - val_loss: 0.0302\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0684 - val_loss: 0.0376\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0682 - val_loss: 0.0420\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0682 - val_loss: 0.0419\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0682 - val_loss: 0.0403\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0681 - val_loss: 0.0387\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0681 - val_loss: 0.0377\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0681 - val_loss: 0.0377\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0681 - val_loss: 0.0379\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0681 - val_loss: 0.0379\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0681 - val_loss: 0.0381\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0681 - val_loss: 0.0379\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0681 - val_loss: 0.0381\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0681 - val_loss: 0.0384\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0681 - val_loss: 0.0380\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0681 - val_loss: 0.0386\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0681 - val_loss: 0.0390\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 42s 11ms/step - loss: 0.2434 - val_loss: 0.1120\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0736 - val_loss: 0.0120\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0840 - val_loss: 0.0104\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0750 - val_loss: 0.0333\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0690 - val_loss: 0.0564\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0699 - val_loss: 0.0488\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0684 - val_loss: 0.0360\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0684 - val_loss: 0.0329\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0682 - val_loss: 0.0391\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0682 - val_loss: 0.0411\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0681 - val_loss: 0.0377\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0682 - val_loss: 0.0362\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0680 - val_loss: 0.0399\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0679 - val_loss: 0.0398\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0674 - val_loss: 0.0393\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0666 - val_loss: 0.0348\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0682 - val_loss: 0.0391\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0681 - val_loss: 0.0403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0681 - val_loss: 0.0386\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0676 - val_loss: 0.0424\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0645 - val_loss: 0.0326\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0585 - val_loss: 0.0204\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0639 - val_loss: 0.0417\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0681 - val_loss: 0.0332\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 42s 11ms/step - loss: 0.0627 - val_loss: 0.0206\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0307 - val_loss: 0.0137\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0087 - val_loss: 0.0424\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 9.5892e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 9.8331e-04 - val_loss: 5.5290e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 9.1866e-04 - val_loss: 8.5344e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 8.0314e-04 - val_loss: 7.7218e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 8.2454e-04 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 8.4520e-04 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 8.7274e-04 - val_loss: 4.9038e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 8.3185e-04 - val_loss: 6.9285e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 8.0182e-04 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 6.7474e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 6.7204e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 6.9604e-04 - val_loss: 5.4689e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 6.2588e-04 - val_loss: 7.4253e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 8.4670e-04 - val_loss: 5.7186e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 7.6819e-04 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 7.6546e-04 - val_loss: 7.4221e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 42s 11ms/step - loss: 0.3152 - val_loss: 0.0569\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0805 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0882 - val_loss: 0.0252\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0695 - val_loss: 0.0656\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0711 - val_loss: 0.0454\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0684 - val_loss: 0.0280\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0687 - val_loss: 0.0354\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0679 - val_loss: 0.0428\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0677 - val_loss: 0.0396\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0662 - val_loss: 0.0342\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0642 - val_loss: 0.0379\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0595 - val_loss: 0.0285\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0468 - val_loss: 0.0099\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0412 - val_loss: 0.0066\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0771 - val_loss: 0.0750\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0709 - val_loss: 0.0308\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0684 - val_loss: 0.0321\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 0.0677 - val_loss: 0.0438\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0677 - val_loss: 0.0377\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0674 - val_loss: 0.0366\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0666 - val_loss: 0.0406\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0660 - val_loss: 0.0400\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0644 - val_loss: 0.0401\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0580 - val_loss: 0.0300\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 43s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 43s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 623us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 616us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 615us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 42s 11ms/step - loss: 1.7122 - val_loss: 0.3233\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.2103 - val_loss: 0.0370\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0826 - val_loss: 0.1196\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0788 - val_loss: 0.0323\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0647 - val_loss: 0.0126\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0565 - val_loss: 0.0202\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0307 - val_loss: 0.0092\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0068 - val_loss: 0.0115\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0058 - val_loss: 0.0150\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0035 - val_loss: 0.0079\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0016 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0014 - val_loss: 7.2292e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0015 - val_loss: 8.9185e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0014 - val_loss: 9.1145e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 6.7747e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0013 - val_loss: 6.9327e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0013 - val_loss: 6.5544e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 44s 12ms/step - loss: 0.2954 - val_loss: 0.1676\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.1131 - val_loss: 0.0188\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0717 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0160 - val_loss: 0.0378\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0106 - val_loss: 0.0051\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0023 - val_loss: 0.0055\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0016 - val_loss: 8.1971e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0015 - val_loss: 7.1378e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0014 - val_loss: 9.2882e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0014 - val_loss: 7.8764e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0013 - val_loss: 6.2689e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0011 - val_loss: 7.8161e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0011 - val_loss: 7.9386e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0010 - val_loss: 5.8644e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0010 - val_loss: 8.8182e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 44s 12ms/step - loss: 1.1503 - val_loss: 1.0111\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.5736 - val_loss: 0.5286\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.2793 - val_loss: 0.2684\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.1408 - val_loss: 0.1312\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0850 - val_loss: 0.0655\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0696 - val_loss: 0.0376\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0684 - val_loss: 0.0280\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0694 - val_loss: 0.0266\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0693 - val_loss: 0.0292\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0687 - val_loss: 0.0330\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0683 - val_loss: 0.0364\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0681 - val_loss: 0.0387\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0681 - val_loss: 0.0397\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0682 - val_loss: 0.0394\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0681 - val_loss: 0.0392\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0681 - val_loss: 0.0382\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0681 - val_loss: 0.0383\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0681 - val_loss: 0.0383\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0681 - val_loss: 0.0383\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0681 - val_loss: 0.0381\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0681 - val_loss: 0.0382\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0682 - val_loss: 0.0373\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0682 - val_loss: 0.0371\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0681 - val_loss: 0.0376\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 45s 12ms/step - loss: 0.1890 - val_loss: 0.0794\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0734 - val_loss: 0.0100\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0816 - val_loss: 0.0163\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0704 - val_loss: 0.0468\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0692 - val_loss: 0.0535\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0685 - val_loss: 0.0398\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0668 - val_loss: 0.0335\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0653 - val_loss: 0.0321\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0682 - val_loss: 0.0394\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0682 - val_loss: 0.0436\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0679 - val_loss: 0.0395\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0656 - val_loss: 0.0414\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0592 - val_loss: 0.0234\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0693 - val_loss: 0.0384\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0683 - val_loss: 0.0467\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0679 - val_loss: 0.0345\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0677 - val_loss: 0.0391\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0668 - val_loss: 0.0414\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0587 - val_loss: 0.0221\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0419 - val_loss: 0.0064\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0622 - val_loss: 0.0199\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0700 - val_loss: 0.0375\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0429 - val_loss: 0.0058\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0242 - val_loss: 0.0095\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 45s 12ms/step - loss: 1.0298 - val_loss: 0.9089\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.5037 - val_loss: 0.4543\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.2326 - val_loss: 0.2149\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.1154 - val_loss: 0.0983\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0755 - val_loss: 0.0489\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0683 - val_loss: 0.0305\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0693 - val_loss: 0.0256\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0697 - val_loss: 0.0268\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0692 - val_loss: 0.0303\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0686 - val_loss: 0.0340\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0682 - val_loss: 0.0375\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0682 - val_loss: 0.0395\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0682 - val_loss: 0.0402\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0682 - val_loss: 0.0398\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0681 - val_loss: 0.0392\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0681 - val_loss: 0.0389\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0681 - val_loss: 0.0385\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0681 - val_loss: 0.0381\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0681 - val_loss: 0.0379\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0681 - val_loss: 0.0381\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0681 - val_loss: 0.0382\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0681 - val_loss: 0.0390\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0681 - val_loss: 0.0383\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0681 - val_loss: 0.0375\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 46s 12ms/step - loss: 2.6149 - val_loss: 0.0038\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0146 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 46s 12ms/step - loss: 0.0867 - val_loss: 0.0126\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0316 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0215 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0150 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0111 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0079 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0062 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0051 - val_loss: 8.9486e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0044 - val_loss: 8.2437e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0039 - val_loss: 9.4322e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0036 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0032 - val_loss: 8.3930e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0032 - val_loss: 9.9502e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 535us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 534us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 47s 13ms/step - loss: 0.1401 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0152 - val_loss: 0.0165\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0031 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0021 - val_loss: 9.0902e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0018 - val_loss: 8.7141e-04\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 7.1718e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 6.8779e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 8.2124e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 6.8406e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0014 - val_loss: 7.0174e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0014 - val_loss: 6.9272e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0014 - val_loss: 6.8047e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 6.9273e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0014 - val_loss: 6.6436e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0014 - val_loss: 6.9243e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0014 - val_loss: 7.0592e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 0.0014 - val_loss: 6.6563e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0013 - val_loss: 7.1552e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0013 - val_loss: 6.6234e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 7.8828e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0013 - val_loss: 6.5527e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0013 - val_loss: 7.7298e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 7.8428e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 47s 13ms/step - loss: 0.3031 - val_loss: 0.0090\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0729 - val_loss: 0.0790\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 0.0800 - val_loss: 0.0900\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 0.0765 - val_loss: 0.0621\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0695 - val_loss: 0.0391\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0683 - val_loss: 0.0312\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0686 - val_loss: 0.0317\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0684 - val_loss: 0.0352\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0682 - val_loss: 0.0386\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0681 - val_loss: 0.0391\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0681 - val_loss: 0.0398\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0682 - val_loss: 0.0386\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 0.0681 - val_loss: 0.0383\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0681 - val_loss: 0.0385\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 0.0681 - val_loss: 0.0384\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0681 - val_loss: 0.0381\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0680 - val_loss: 0.0387\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0680 - val_loss: 0.0386\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0678 - val_loss: 0.0375\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 0.0676 - val_loss: 0.0360\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0672 - val_loss: 0.0361\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 0.0666 - val_loss: 0.0364\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 0.0659 - val_loss: 0.0361\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 0.0651 - val_loss: 0.0417\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 48s 13ms/step - loss: 0.3005 - val_loss: 0.0058\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0840 - val_loss: 0.1308\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0773 - val_loss: 0.0144\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0629 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0194 - val_loss: 0.0384\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0089 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0040 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0026 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0015 - val_loss: 9.4494e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0014 - val_loss: 8.6578e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0013 - val_loss: 9.4966e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 6.3844e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0011 - val_loss: 8.0663e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0011 - val_loss: 6.9317e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 9.9260e-04 - val_loss: 5.3829e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 50s 13ms/step - loss: 0.3970 - val_loss: 0.2010\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0882 - val_loss: 0.0063\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0668 - val_loss: 0.0739\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0455 - val_loss: 0.0187\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0147 - val_loss: 0.0087\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0051 - val_loss: 0.0176\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0040 - val_loss: 0.0121\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 536us/step - loss: 0.0024 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 538us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0012 - val_loss: 8.1195e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0012 - val_loss: 9.9109e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0011 - val_loss: 7.8818e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 0.0010 - val_loss: 8.0067e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0010 - val_loss: 9.6054e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 9.7644e-04 - val_loss: 7.4788e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 9.4027e-04 - val_loss: 8.8202e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 537us/step - loss: 9.4664e-04 - val_loss: 5.9185e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 539us/step - loss: 9.1029e-04 - val_loss: 5.3127e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 541us/step - loss: 9.6977e-04 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 9.8173e-04 - val_loss: 5.6826e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 9.1303e-04 - val_loss: 7.2065e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 49s 13ms/step - loss: 0.7822 - val_loss: 0.1180\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.1243 - val_loss: 0.1001\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0897 - val_loss: 0.0703\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0618 - val_loss: 0.0076\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0459 - val_loss: 0.0071\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0092 - val_loss: 0.0150\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0078 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0030 - val_loss: 9.6538e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0020 - val_loss: 8.2213e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0017 - val_loss: 7.4691e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0018 - val_loss: 9.4973e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0017 - val_loss: 7.9220e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0017 - val_loss: 9.8549e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 8.4080e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 51s 14ms/step - loss: 0.0747 - val_loss: 0.0137\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0094 - val_loss: 6.0641e-04\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0050 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0039 - val_loss: 5.7257e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0021 - val_loss: 7.1800e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 9.7074e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0015 - val_loss: 8.2678e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0014 - val_loss: 9.3233e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0014 - val_loss: 7.7558e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0013 - val_loss: 5.9875e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0012 - val_loss: 7.6222e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0013 - val_loss: 7.0046e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 9.3171e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 0.0012 - val_loss: 7.6770e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0011 - val_loss: 9.4146e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 8.1860e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 4.6266e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0010 - val_loss: 5.2201e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0010 - val_loss: 7.1494e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 51s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 51s 14ms/step - loss: 0.0512 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0075 - val_loss: 0.0086\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0089 - val_loss: 0.0091\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0058 - val_loss: 0.0096\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 542us/step - loss: 0.0074 - val_loss: 0.0095\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0060 - val_loss: 0.0112\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0072 - val_loss: 0.0178\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0058 - val_loss: 0.0072\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 0.0033 - val_loss: 0.0076\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0051 - val_loss: 0.0118\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0052 - val_loss: 0.0139\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0044 - val_loss: 0.0107\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0031 - val_loss: 0.0113\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0041 - val_loss: 0.0105\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0031 - val_loss: 0.0090\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 0.0035 - val_loss: 0.0123\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0038 - val_loss: 0.0103\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0024 - val_loss: 0.0059\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 0.0020 - val_loss: 0.0083\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 0.0022 - val_loss: 0.0073\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 0.0026 - val_loss: 0.0116\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0029 - val_loss: 0.0107\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 547us/step - loss: 0.0026 - val_loss: 0.0089\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 540us/step - loss: 0.0030 - val_loss: 0.0112\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 55s 15ms/step - loss: 0.0778 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 618us/step - loss: 0.0166 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 618us/step - loss: 0.0051 - val_loss: 0.0167\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 644us/step - loss: 0.0128 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 638us/step - loss: 0.0096 - val_loss: 0.0075\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 672us/step - loss: 0.0106 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 653us/step - loss: 0.0046 - val_loss: 0.0104\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 651us/step - loss: 0.0083 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 670us/step - loss: 0.0061 - val_loss: 0.0087\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 647us/step - loss: 0.0071 - val_loss: 7.6375e-04\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 641us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 627us/step - loss: 0.0077 - val_loss: 0.0050\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 627us/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 645us/step - loss: 0.0023 - val_loss: 0.0118\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 660us/step - loss: 0.0072 - val_loss: 5.5385e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 631us/step - loss: 0.0016 - val_loss: 0.0065\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 623us/step - loss: 0.0023 - val_loss: 5.4902e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 663us/step - loss: 0.0044 - val_loss: 0.0064\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 628us/step - loss: 0.0036 - val_loss: 5.9113e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 624us/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 621us/step - loss: 0.0052 - val_loss: 6.7918e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 620us/step - loss: 0.0015 - val_loss: 7.3543e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0040 - val_loss: 0.0129\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 53s 14ms/step - loss: 0.0507 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 630us/step - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0080 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0043 - val_loss: 9.3874e-04\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 621us/step - loss: 0.0071 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 618us/step - loss: 0.0061 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0073 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0062 - val_loss: 7.8153e-04\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 617us/step - loss: 0.0038 - val_loss: 7.2654e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 618us/step - loss: 0.0061 - val_loss: 0.0046\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0078 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 617us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0028 - val_loss: 8.2822e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 622us/step - loss: 0.0058 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 617us/step - loss: 0.0051 - val_loss: 6.8644e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 626us/step - loss: 0.0025 - val_loss: 6.3833e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 620us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 620us/step - loss: 0.0064 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 618us/step - loss: 0.0045 - val_loss: 7.4740e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 618us/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 618us/step - loss: 0.0031 - val_loss: 7.0666e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 623us/step - loss: 0.0029 - val_loss: 5.9322e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 628us/step - loss: 0.0028 - val_loss: 6.5382e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0023 - val_loss: 6.1775e-04\n",
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/24\n",
      "3690/3690 [==============================] - 54s 15ms/step - loss: 0.1210 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "3690/3690 [==============================] - 2s 622us/step - loss: 0.0139 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "3690/3690 [==============================] - 2s 623us/step - loss: 0.0084 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "3690/3690 [==============================] - 2s 616us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "3690/3690 [==============================] - 2s 624us/step - loss: 0.0021 - val_loss: 6.2774e-04\n",
      "Epoch 6/24\n",
      "3690/3690 [==============================] - 2s 622us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "3690/3690 [==============================] - 2s 621us/step - loss: 0.0016 - val_loss: 7.2756e-04\n",
      "Epoch 8/24\n",
      "3690/3690 [==============================] - 2s 626us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "3690/3690 [==============================] - 2s 618us/step - loss: 0.0015 - val_loss: 7.9881e-04\n",
      "Epoch 10/24\n",
      "3690/3690 [==============================] - 2s 623us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "3690/3690 [==============================] - 2s 621us/step - loss: 0.0014 - val_loss: 8.9277e-04\n",
      "Epoch 12/24\n",
      "3690/3690 [==============================] - 2s 625us/step - loss: 0.0015 - val_loss: 9.6037e-04\n",
      "Epoch 13/24\n",
      "3690/3690 [==============================] - 2s 621us/step - loss: 0.0014 - val_loss: 9.9092e-04\n",
      "Epoch 14/24\n",
      "3690/3690 [==============================] - 2s 620us/step - loss: 0.0014 - val_loss: 9.2724e-04\n",
      "Epoch 15/24\n",
      "3690/3690 [==============================] - 2s 622us/step - loss: 0.0013 - val_loss: 9.1581e-04\n",
      "Epoch 16/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0013 - val_loss: 8.4746e-04\n",
      "Epoch 17/24\n",
      "3690/3690 [==============================] - 2s 621us/step - loss: 0.0013 - val_loss: 9.3605e-04\n",
      "Epoch 18/24\n",
      "3690/3690 [==============================] - 2s 621us/step - loss: 0.0013 - val_loss: 7.8880e-04\n",
      "Epoch 19/24\n",
      "3690/3690 [==============================] - 2s 624us/step - loss: 0.0013 - val_loss: 8.1348e-04\n",
      "Epoch 20/24\n",
      "3690/3690 [==============================] - 2s 618us/step - loss: 0.0013 - val_loss: 8.6219e-04\n",
      "Epoch 21/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0012 - val_loss: 7.2438e-04\n",
      "Epoch 22/24\n",
      "3690/3690 [==============================] - 2s 619us/step - loss: 0.0012 - val_loss: 8.1535e-04\n",
      "Epoch 23/24\n",
      "3690/3690 [==============================] - 2s 620us/step - loss: 0.0012 - val_loss: 7.7297e-04\n",
      "Epoch 24/24\n",
      "3690/3690 [==============================] - 2s 621us/step - loss: 0.0012 - val_loss: 7.2289e-04\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0148102892562747,\n",
       " 0.002357694087550044,\n",
       " 0.0015180862974375486,\n",
       " 0.0032058616634458303,\n",
       " 0.010299623012542725,\n",
       " 0.004211158491671085,\n",
       " 0.0026668920181691647,\n",
       " 0.0010865309741348028,\n",
       " 0.0015870343195274472,\n",
       " 0.001020119059830904,\n",
       " 0.000820847402792424,\n",
       " 0.0007782719330862164,\n",
       " 0.0006033737445250154,\n",
       " 0.0005642649484798312,\n",
       " 0.0005361604853533208,\n",
       " 0.0005309363477863371,\n",
       " 0.0007358361035585403,\n",
       " 0.0013018675381317735,\n",
       " 0.0011685275239869952,\n",
       " 0.0006861375877633691,\n",
       " 0.0005284797516651452,\n",
       " 0.0007585635758005083,\n",
       " 0.0004596828075591475,\n",
       " 0.0004597422666847706]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "optimizer: adam\n",
      "shuffle: True\n",
      "dropout: 0.1\n",
      "full_density: True\n",
      "twice: True\n",
      "density: 230\n",
      "activation: softplus\n",
      "lstmsize: 150\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_140\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_278 (LSTM)              (None, 92, 150)           93600     \n",
      "_________________________________________________________________\n",
      "dropout_278 (Dropout)        (None, 92, 150)           0         \n",
      "_________________________________________________________________\n",
      "lstm_279 (LSTM)              (None, 150)               180600    \n",
      "_________________________________________________________________\n",
      "dropout_279 (Dropout)        (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_702 (Dense)            (None, 230)               34730     \n",
      "_________________________________________________________________\n",
      "dense_703 (Dense)            (None, 115)               26565     \n",
      "_________________________________________________________________\n",
      "dense_704 (Dense)            (None, 57)                6612      \n",
      "_________________________________________________________________\n",
      "dense_705 (Dense)            (None, 28)                1624      \n",
      "_________________________________________________________________\n",
      "dense_706 (Dense)            (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_707 (Dense)            (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 344,152\n",
      "Trainable params: 344,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3690 samples, validate on 410 samples\n",
      "Epoch 1/2000\n",
      "3690/3690 [==============================] - 58s 16ms/step - loss: 0.1711 - val_loss: 0.1110\n",
      "Epoch 2/2000\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 0.0828 - val_loss: 0.0038\n",
      "Epoch 3/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 0.0427 - val_loss: 0.0146\n",
      "Epoch 4/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0089 - val_loss: 0.0075\n",
      "Epoch 5/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 0.0061 - val_loss: 0.0011\n",
      "Epoch 6/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 7/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0023 - val_loss: 0.0074\n",
      "Epoch 8/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 9/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 10/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 11/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 12/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 13/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 14/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0012 - val_loss: 8.8368e-04\n",
      "Epoch 15/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 0.0011 - val_loss: 7.6415e-04\n",
      "Epoch 16/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0010 - val_loss: 9.5876e-04\n",
      "Epoch 17/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 0.0010 - val_loss: 9.2300e-04\n",
      "Epoch 18/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.9647e-04 - val_loss: 6.1302e-04\n",
      "Epoch 20/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.9846e-04 - val_loss: 0.0011\n",
      "Epoch 21/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 9.2000e-04 - val_loss: 5.7912e-04\n",
      "Epoch 22/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.8526e-04 - val_loss: 9.6260e-04\n",
      "Epoch 23/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.0014e-04 - val_loss: 5.6634e-04\n",
      "Epoch 24/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.0765e-04 - val_loss: 5.2765e-04\n",
      "Epoch 25/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 8.4646e-04 - val_loss: 5.9876e-04\n",
      "Epoch 26/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.0101e-04 - val_loss: 6.7024e-04\n",
      "Epoch 27/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.2226e-04 - val_loss: 8.8728e-04\n",
      "Epoch 28/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.5552e-04 - val_loss: 5.0892e-04\n",
      "Epoch 29/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.9672e-04 - val_loss: 9.0327e-04\n",
      "Epoch 30/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.0970e-04 - val_loss: 7.3791e-04\n",
      "Epoch 31/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.4899e-04 - val_loss: 5.9799e-04\n",
      "Epoch 32/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.5228e-04 - val_loss: 0.0010\n",
      "Epoch 33/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 7.8603e-04 - val_loss: 5.0177e-04\n",
      "Epoch 34/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.5130e-04 - val_loss: 5.5354e-04\n",
      "Epoch 35/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.0476e-04 - val_loss: 6.3547e-04\n",
      "Epoch 36/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.2822e-04 - val_loss: 4.9658e-04\n",
      "Epoch 37/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.9828e-04 - val_loss: 4.4044e-04\n",
      "Epoch 38/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.0986e-04 - val_loss: 8.9891e-04\n",
      "Epoch 39/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.2033e-04 - val_loss: 4.8896e-04\n",
      "Epoch 40/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.7064e-04 - val_loss: 4.2137e-04\n",
      "Epoch 41/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 6.6740e-04 - val_loss: 5.1079e-04\n",
      "Epoch 42/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.4321e-04 - val_loss: 5.2115e-04\n",
      "Epoch 43/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.7066e-04 - val_loss: 6.0602e-04\n",
      "Epoch 44/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.3142e-04 - val_loss: 7.6657e-04\n",
      "Epoch 45/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.6851e-04 - val_loss: 5.8569e-04\n",
      "Epoch 46/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.1323e-04 - val_loss: 4.1039e-04\n",
      "Epoch 47/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.2199e-04 - val_loss: 6.4851e-04\n",
      "Epoch 48/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.1185e-04 - val_loss: 6.7287e-04\n",
      "Epoch 49/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.1039e-04 - val_loss: 3.9537e-04\n",
      "Epoch 50/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.6587e-04 - val_loss: 7.4289e-04\n",
      "Epoch 51/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.0446e-04 - val_loss: 6.6609e-04\n",
      "Epoch 52/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.5612e-04 - val_loss: 6.9339e-04\n",
      "Epoch 53/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.0209e-04 - val_loss: 4.0988e-04\n",
      "Epoch 54/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7113e-04 - val_loss: 3.9752e-04\n",
      "Epoch 55/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.6491e-04 - val_loss: 4.8379e-04\n",
      "Epoch 56/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.9018e-04 - val_loss: 4.4978e-04\n",
      "Epoch 57/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.3440e-04 - val_loss: 3.8668e-04\n",
      "Epoch 58/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.5995e-04 - val_loss: 3.7448e-04\n",
      "Epoch 59/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 5.3726e-04 - val_loss: 3.8966e-04\n",
      "Epoch 60/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 5.3082e-04 - val_loss: 3.8601e-04\n",
      "Epoch 61/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.5781e-04 - val_loss: 3.7168e-04\n",
      "Epoch 62/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 5.5327e-04 - val_loss: 4.1906e-04\n",
      "Epoch 63/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 5.3306e-04 - val_loss: 3.8617e-04\n",
      "Epoch 64/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 5.2679e-04 - val_loss: 4.1283e-04\n",
      "Epoch 65/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.5425e-04 - val_loss: 3.9020e-04\n",
      "Epoch 66/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 5.4174e-04 - val_loss: 3.6627e-04\n",
      "Epoch 67/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 5.1263e-04 - val_loss: 3.7597e-04\n",
      "Epoch 68/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 5.0597e-04 - val_loss: 4.9600e-04\n",
      "Epoch 69/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 5.3854e-04 - val_loss: 5.4917e-04\n",
      "Epoch 70/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 4.9490e-04 - val_loss: 9.6532e-04\n",
      "Epoch 71/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 5.6851e-04 - val_loss: 0.0012\n",
      "Epoch 72/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.1623e-04 - val_loss: 6.0982e-04\n",
      "Epoch 73/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.0937e-04 - val_loss: 0.0011\n",
      "Epoch 74/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.5657e-04 - val_loss: 4.7827e-04\n",
      "Epoch 75/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 4.8382e-04 - val_loss: 5.4198e-04\n",
      "Epoch 76/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 4.9574e-04 - val_loss: 5.8765e-04\n",
      "Epoch 77/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 5.2985e-04 - val_loss: 5.6339e-04\n",
      "Epoch 78/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 4.6254e-04 - val_loss: 3.4603e-04\n",
      "Epoch 79/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 4.7055e-04 - val_loss: 3.3148e-04\n",
      "Epoch 80/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 4.8205e-04 - val_loss: 3.4193e-04\n",
      "Epoch 81/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 4.6590e-04 - val_loss: 3.5785e-04\n",
      "Epoch 82/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 4.6689e-04 - val_loss: 3.2811e-04\n",
      "Epoch 83/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 4.5657e-04 - val_loss: 4.5037e-04\n",
      "Epoch 84/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 4.4178e-04 - val_loss: 3.6446e-04\n",
      "Epoch 85/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 4.4032e-04 - val_loss: 3.8555e-04\n",
      "Epoch 86/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 4.3769e-04 - val_loss: 3.1245e-04\n",
      "Epoch 87/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 4.5641e-04 - val_loss: 3.2738e-04\n",
      "Epoch 88/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 4.3909e-04 - val_loss: 5.8699e-04\n",
      "Epoch 89/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 4.5092e-04 - val_loss: 3.9382e-04\n",
      "Epoch 90/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 4.2262e-04 - val_loss: 3.0703e-04\n",
      "Epoch 91/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 4.3034e-04 - val_loss: 3.0835e-04\n",
      "Epoch 92/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 4.4903e-04 - val_loss: 3.1302e-04\n",
      "Epoch 93/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 4.1759e-04 - val_loss: 5.7615e-04\n",
      "Epoch 94/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 4.4806e-04 - val_loss: 9.7502e-04\n",
      "Epoch 95/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 5.2483e-04 - val_loss: 6.5970e-04\n",
      "Epoch 96/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.1132e-04 - val_loss: 7.9903e-04\n",
      "Epoch 97/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 4.9043e-04 - val_loss: 5.6623e-04\n",
      "Epoch 98/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 4.2718e-04 - val_loss: 4.9629e-04\n",
      "Epoch 99/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 4.3280e-04 - val_loss: 3.7700e-04\n",
      "Epoch 100/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 4.2244e-04 - val_loss: 5.7185e-04\n",
      "Epoch 101/2000\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 4.5990e-04 - val_loss: 6.9350e-04\n",
      "Epoch 102/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 4.3121e-04 - val_loss: 5.9154e-04\n",
      "Epoch 103/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 4.3332e-04 - val_loss: 4.9836e-04\n",
      "Epoch 104/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 3.8062e-04 - val_loss: 4.6726e-04\n",
      "Epoch 105/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 4.0951e-04 - val_loss: 4.5994e-04\n",
      "Epoch 106/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 3.9692e-04 - val_loss: 3.2866e-04\n",
      "Epoch 107/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 3.6595e-04 - val_loss: 4.5177e-04\n",
      "Epoch 108/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 3.9423e-04 - val_loss: 3.4098e-04\n",
      "Epoch 109/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 3.8328e-04 - val_loss: 3.0920e-04\n",
      "Epoch 110/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 3.7962e-04 - val_loss: 3.5186e-04\n",
      "Epoch 111/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.7116e-04 - val_loss: 3.7089e-04\n",
      "Epoch 112/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 4.1292e-04 - val_loss: 2.7343e-04\n",
      "Epoch 113/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.7269e-04 - val_loss: 3.9236e-04\n",
      "Epoch 114/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 3.7088e-04 - val_loss: 2.5307e-04\n",
      "Epoch 115/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 3.7403e-04 - val_loss: 3.0943e-04\n",
      "Epoch 116/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 4.4523e-04 - val_loss: 3.4016e-04\n",
      "Epoch 117/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 4.0103e-04 - val_loss: 4.6817e-04\n",
      "Epoch 118/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 3.9421e-04 - val_loss: 2.5519e-04\n",
      "Epoch 119/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.6075e-04 - val_loss: 3.1510e-04\n",
      "Epoch 120/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 3.6384e-04 - val_loss: 3.0538e-04\n",
      "Epoch 121/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 3.5591e-04 - val_loss: 4.5751e-04\n",
      "Epoch 122/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 3.7941e-04 - val_loss: 3.8766e-04\n",
      "Epoch 123/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 3.8584e-04 - val_loss: 2.4080e-04\n",
      "Epoch 124/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.9297e-04 - val_loss: 2.7165e-04\n",
      "Epoch 125/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.6756e-04 - val_loss: 3.6823e-04\n",
      "Epoch 126/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 4.1935e-04 - val_loss: 2.3361e-04\n",
      "Epoch 127/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 3.6907e-04 - val_loss: 3.8256e-04\n",
      "Epoch 128/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 3.4280e-04 - val_loss: 3.8033e-04\n",
      "Epoch 129/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 3.4964e-04 - val_loss: 3.7940e-04\n",
      "Epoch 130/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.3293e-04 - val_loss: 2.5472e-04\n",
      "Epoch 131/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.3245e-04 - val_loss: 2.3521e-04\n",
      "Epoch 132/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 3.3621e-04 - val_loss: 2.6078e-04\n",
      "Epoch 133/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.4410e-04 - val_loss: 2.2535e-04\n",
      "Epoch 134/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.5254e-04 - val_loss: 3.3610e-04\n",
      "Epoch 135/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 3.4846e-04 - val_loss: 2.4139e-04\n",
      "Epoch 136/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 3.6323e-04 - val_loss: 2.2946e-04\n",
      "Epoch 137/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 3.5585e-04 - val_loss: 3.2902e-04\n",
      "Epoch 138/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 3.4858e-04 - val_loss: 2.2139e-04\n",
      "Epoch 139/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 3.0372e-04 - val_loss: 2.8339e-04\n",
      "Epoch 140/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.2402e-04 - val_loss: 2.5972e-04\n",
      "Epoch 141/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.3888e-04 - val_loss: 2.1668e-04\n",
      "Epoch 142/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 3.1194e-04 - val_loss: 3.0303e-04\n",
      "Epoch 143/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 3.4759e-04 - val_loss: 4.6044e-04\n",
      "Epoch 144/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 552us/step - loss: 4.3240e-04 - val_loss: 4.6960e-04\n",
      "Epoch 145/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 3.9534e-04 - val_loss: 7.5252e-04\n",
      "Epoch 146/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 4.2405e-04 - val_loss: 2.2773e-04\n",
      "Epoch 147/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 3.4598e-04 - val_loss: 4.5038e-04\n",
      "Epoch 148/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 4.6250e-04 - val_loss: 3.7434e-04\n",
      "Epoch 149/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 4.5489e-04 - val_loss: 2.0502e-04\n",
      "Epoch 150/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 3.4991e-04 - val_loss: 2.9565e-04\n",
      "Epoch 151/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 3.1886e-04 - val_loss: 2.0799e-04\n",
      "Epoch 152/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.8615e-04 - val_loss: 3.2030e-04\n",
      "Epoch 153/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 3.2831e-04 - val_loss: 1.9289e-04\n",
      "Epoch 154/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 3.0661e-04 - val_loss: 2.4584e-04\n",
      "Epoch 155/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 2.9309e-04 - val_loss: 2.9333e-04\n",
      "Epoch 156/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 3.4441e-04 - val_loss: 2.0264e-04\n",
      "Epoch 157/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 3.2580e-04 - val_loss: 2.2411e-04\n",
      "Epoch 158/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.9362e-04 - val_loss: 1.9915e-04\n",
      "Epoch 159/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.9270e-04 - val_loss: 6.0616e-04\n",
      "Epoch 160/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 3.5668e-04 - val_loss: 2.0328e-04\n",
      "Epoch 161/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 3.1760e-04 - val_loss: 2.4674e-04\n",
      "Epoch 162/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.8727e-04 - val_loss: 2.9061e-04\n",
      "Epoch 163/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 2.9045e-04 - val_loss: 1.8439e-04\n",
      "Epoch 164/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.8326e-04 - val_loss: 1.9008e-04\n",
      "Epoch 165/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 2.7557e-04 - val_loss: 2.9032e-04\n",
      "Epoch 166/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 2.6585e-04 - val_loss: 2.4633e-04\n",
      "Epoch 167/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.7197e-04 - val_loss: 2.3551e-04\n",
      "Epoch 168/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 2.6263e-04 - val_loss: 1.9402e-04\n",
      "Epoch 169/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 2.5849e-04 - val_loss: 2.8082e-04\n",
      "Epoch 170/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.6179e-04 - val_loss: 2.9618e-04\n",
      "Epoch 171/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 2.8445e-04 - val_loss: 1.7460e-04\n",
      "Epoch 172/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.7523e-04 - val_loss: 1.7165e-04\n",
      "Epoch 173/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 2.8166e-04 - val_loss: 2.7163e-04\n",
      "Epoch 174/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.6808e-04 - val_loss: 1.6374e-04\n",
      "Epoch 175/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 2.6774e-04 - val_loss: 3.5922e-04\n",
      "Epoch 176/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 4.4100e-04 - val_loss: 6.1373e-04\n",
      "Epoch 177/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 3.4479e-04 - val_loss: 2.3467e-04\n",
      "Epoch 178/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.9239e-04 - val_loss: 2.3137e-04\n",
      "Epoch 179/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 3.0997e-04 - val_loss: 4.2395e-04\n",
      "Epoch 180/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 3.1847e-04 - val_loss: 2.2233e-04\n",
      "Epoch 181/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 3.5683e-04 - val_loss: 1.7013e-04\n",
      "Epoch 182/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 2.6218e-04 - val_loss: 2.8138e-04\n",
      "Epoch 183/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 2.4781e-04 - val_loss: 1.8347e-04\n",
      "Epoch 184/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.4454e-04 - val_loss: 1.6259e-04\n",
      "Epoch 185/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 2.7235e-04 - val_loss: 1.9221e-04\n",
      "Epoch 186/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.9144e-04 - val_loss: 2.9159e-04\n",
      "Epoch 187/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.4093e-04 - val_loss: 2.4696e-04\n",
      "Epoch 188/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.7611e-04 - val_loss: 4.8167e-04\n",
      "Epoch 189/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 3.4329e-04 - val_loss: 2.1931e-04\n",
      "Epoch 190/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.6449e-04 - val_loss: 4.2731e-04\n",
      "Epoch 191/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.7708e-04 - val_loss: 1.6590e-04\n",
      "Epoch 192/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 2.2805e-04 - val_loss: 1.6794e-04\n",
      "Epoch 193/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 2.4521e-04 - val_loss: 3.3808e-04\n",
      "Epoch 194/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 2.7434e-04 - val_loss: 1.5169e-04\n",
      "Epoch 195/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.5530e-04 - val_loss: 1.4602e-04\n",
      "Epoch 196/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 2.3521e-04 - val_loss: 2.2111e-04\n",
      "Epoch 197/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.3339e-04 - val_loss: 1.4647e-04\n",
      "Epoch 198/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.2857e-04 - val_loss: 1.3979e-04\n",
      "Epoch 199/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 2.2444e-04 - val_loss: 1.5422e-04\n",
      "Epoch 200/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 2.1568e-04 - val_loss: 1.4935e-04\n",
      "Epoch 201/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.3332e-04 - val_loss: 1.3985e-04\n",
      "Epoch 202/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 2.2753e-04 - val_loss: 2.9342e-04\n",
      "Epoch 203/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.4518e-04 - val_loss: 1.5199e-04\n",
      "Epoch 204/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 2.1760e-04 - val_loss: 1.8997e-04\n",
      "Epoch 205/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 2.3329e-04 - val_loss: 1.4545e-04\n",
      "Epoch 206/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 2.1701e-04 - val_loss: 2.0471e-04\n",
      "Epoch 207/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.1026e-04 - val_loss: 1.2943e-04\n",
      "Epoch 208/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 2.1365e-04 - val_loss: 1.3605e-04\n",
      "Epoch 209/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.1572e-04 - val_loss: 2.7593e-04\n",
      "Epoch 210/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 2.2310e-04 - val_loss: 2.0110e-04\n",
      "Epoch 211/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 2.4462e-04 - val_loss: 4.0345e-04\n",
      "Epoch 212/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.6567e-04 - val_loss: 1.8753e-04\n",
      "Epoch 213/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.2919e-04 - val_loss: 2.0998e-04\n",
      "Epoch 214/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 2.3423e-04 - val_loss: 2.5854e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 215/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.6719e-04 - val_loss: 4.4685e-04\n",
      "Epoch 216/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 2.5530e-04 - val_loss: 1.3953e-04\n",
      "Epoch 217/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.3575e-04 - val_loss: 1.3119e-04\n",
      "Epoch 218/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 2.0796e-04 - val_loss: 3.2175e-04\n",
      "Epoch 219/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 2.3739e-04 - val_loss: 1.5252e-04\n",
      "Epoch 220/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.3628e-04 - val_loss: 6.0783e-04\n",
      "Epoch 221/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.3909e-04 - val_loss: 1.4834e-04\n",
      "Epoch 222/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.0424e-04 - val_loss: 1.2146e-04\n",
      "Epoch 223/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.0178e-04 - val_loss: 1.5356e-04\n",
      "Epoch 224/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.8718e-04 - val_loss: 1.2678e-04\n",
      "Epoch 225/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 1.8929e-04 - val_loss: 1.6048e-04\n",
      "Epoch 226/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 2.3603e-04 - val_loss: 1.1590e-04\n",
      "Epoch 227/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 2.1369e-04 - val_loss: 2.6688e-04\n",
      "Epoch 228/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 2.4984e-04 - val_loss: 4.3661e-04\n",
      "Epoch 229/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 2.4097e-04 - val_loss: 1.2742e-04\n",
      "Epoch 230/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 1.9775e-04 - val_loss: 2.2502e-04\n",
      "Epoch 231/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.8739e-04 - val_loss: 1.2338e-04\n",
      "Epoch 232/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.8238e-04 - val_loss: 2.6265e-04\n",
      "Epoch 233/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.2981e-04 - val_loss: 1.3186e-04\n",
      "Epoch 234/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.8339e-04 - val_loss: 1.7756e-04\n",
      "Epoch 235/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.7662e-04 - val_loss: 1.1044e-04\n",
      "Epoch 236/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.8344e-04 - val_loss: 1.1341e-04\n",
      "Epoch 237/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.8538e-04 - val_loss: 1.7787e-04\n",
      "Epoch 238/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.7056e-04 - val_loss: 1.0986e-04\n",
      "Epoch 239/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.7653e-04 - val_loss: 1.0453e-04\n",
      "Epoch 240/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.8660e-04 - val_loss: 2.1225e-04\n",
      "Epoch 241/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.4797e-04 - val_loss: 1.7890e-04\n",
      "Epoch 242/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.9089e-04 - val_loss: 3.0331e-04\n",
      "Epoch 243/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 2.1046e-04 - val_loss: 2.1433e-04\n",
      "Epoch 244/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 2.3325e-04 - val_loss: 2.0972e-04\n",
      "Epoch 245/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 2.5794e-04 - val_loss: 1.6919e-04\n",
      "Epoch 246/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.7575e-04 - val_loss: 1.0174e-04\n",
      "Epoch 247/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.7498e-04 - val_loss: 1.0340e-04\n",
      "Epoch 248/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.6890e-04 - val_loss: 1.7208e-04\n",
      "Epoch 249/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.7428e-04 - val_loss: 1.5382e-04\n",
      "Epoch 250/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.8467e-04 - val_loss: 1.8939e-04\n",
      "Epoch 251/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.7564e-04 - val_loss: 2.4713e-04\n",
      "Epoch 252/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.6582e-04 - val_loss: 1.0281e-04\n",
      "Epoch 253/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.7602e-04 - val_loss: 2.6252e-04\n",
      "Epoch 254/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.6996e-04 - val_loss: 1.0298e-04\n",
      "Epoch 255/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.6560e-04 - val_loss: 3.0415e-04\n",
      "Epoch 256/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.1780e-04 - val_loss: 1.8153e-04\n",
      "Epoch 257/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.0960e-04 - val_loss: 3.3625e-04\n",
      "Epoch 258/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.4013e-04 - val_loss: 1.6957e-04\n",
      "Epoch 259/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.8199e-04 - val_loss: 1.5913e-04\n",
      "Epoch 260/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.8879e-04 - val_loss: 1.7075e-04\n",
      "Epoch 261/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.0790e-04 - val_loss: 1.0136e-04\n",
      "Epoch 262/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.8242e-04 - val_loss: 1.5468e-04\n",
      "Epoch 263/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 1.4211e-04 - val_loss: 1.2288e-04\n",
      "Epoch 264/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 1.7555e-04 - val_loss: 1.1322e-04\n",
      "Epoch 265/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.6443e-04 - val_loss: 3.3332e-04\n",
      "Epoch 266/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 2.0312e-04 - val_loss: 8.9154e-05\n",
      "Epoch 267/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 1.9459e-04 - val_loss: 1.6075e-04\n",
      "Epoch 268/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 1.9630e-04 - val_loss: 8.9955e-05\n",
      "Epoch 269/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.5300e-04 - val_loss: 1.2555e-04\n",
      "Epoch 270/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 1.4715e-04 - val_loss: 8.7843e-05\n",
      "Epoch 271/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.3821e-04 - val_loss: 9.0898e-05\n",
      "Epoch 272/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 1.5538e-04 - val_loss: 9.8163e-05\n",
      "Epoch 273/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 1.6182e-04 - val_loss: 3.3825e-04\n",
      "Epoch 274/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 2.0861e-04 - val_loss: 1.4890e-04\n",
      "Epoch 275/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.0882e-04 - val_loss: 1.7911e-04\n",
      "Epoch 276/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.9550e-04 - val_loss: 1.3081e-04\n",
      "Epoch 277/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.6474e-04 - val_loss: 1.1769e-04\n",
      "Epoch 278/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.6997e-04 - val_loss: 1.8207e-04\n",
      "Epoch 279/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.7043e-04 - val_loss: 1.1932e-04\n",
      "Epoch 280/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.7233e-04 - val_loss: 8.5562e-05\n",
      "Epoch 281/2000\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 2.3901e-04 - val_loss: 9.3135e-05\n",
      "Epoch 282/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 1.7362e-04 - val_loss: 1.4573e-04\n",
      "Epoch 283/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.5886e-04 - val_loss: 2.0473e-04\n",
      "Epoch 284/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.6591e-04 - val_loss: 8.5181e-05\n",
      "Epoch 285/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.3936e-04 - val_loss: 1.0273e-04\n",
      "Epoch 286/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.5740e-04 - val_loss: 8.1718e-05\n",
      "Epoch 287/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.5367e-04 - val_loss: 1.6166e-04\n",
      "Epoch 288/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.7824e-04 - val_loss: 1.2730e-04\n",
      "Epoch 289/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.7190e-04 - val_loss: 4.8255e-04\n",
      "Epoch 290/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 2.5785e-04 - val_loss: 1.5256e-04\n",
      "Epoch 291/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.7798e-04 - val_loss: 1.1752e-04\n",
      "Epoch 292/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.5521e-04 - val_loss: 9.5720e-05\n",
      "Epoch 293/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.6505e-04 - val_loss: 2.8499e-04\n",
      "Epoch 294/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.7388e-04 - val_loss: 8.7172e-05\n",
      "Epoch 295/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.3170e-04 - val_loss: 7.9878e-05\n",
      "Epoch 296/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.2956e-04 - val_loss: 8.2635e-05\n",
      "Epoch 297/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.2758e-04 - val_loss: 2.4042e-04\n",
      "Epoch 298/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.7553e-04 - val_loss: 1.0859e-04\n",
      "Epoch 299/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.5849e-04 - val_loss: 7.9774e-05\n",
      "Epoch 300/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.4926e-04 - val_loss: 8.6528e-05\n",
      "Epoch 301/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.7019e-04 - val_loss: 7.7538e-05\n",
      "Epoch 302/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.3375e-04 - val_loss: 7.7197e-05\n",
      "Epoch 303/2000\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 1.3133e-04 - val_loss: 1.3095e-04\n",
      "Epoch 304/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.3305e-04 - val_loss: 7.9339e-05\n",
      "Epoch 305/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 1.3984e-04 - val_loss: 7.5594e-05\n",
      "Epoch 306/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 1.3669e-04 - val_loss: 8.7544e-05\n",
      "Epoch 307/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.4423e-04 - val_loss: 1.7125e-04\n",
      "Epoch 308/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 2.0712e-04 - val_loss: 1.0237e-04\n",
      "Epoch 309/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.2428e-04 - val_loss: 7.7306e-05\n",
      "Epoch 310/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.6148e-04 - val_loss: 2.5742e-04\n",
      "Epoch 311/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.8331e-04 - val_loss: 1.1954e-04\n",
      "Epoch 312/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.8691e-04 - val_loss: 1.1678e-04\n",
      "Epoch 313/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.5209e-04 - val_loss: 2.1648e-04\n",
      "Epoch 314/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.5778e-04 - val_loss: 1.9663e-04\n",
      "Epoch 315/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.7560e-04 - val_loss: 1.3433e-04\n",
      "Epoch 316/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 2.1366e-04 - val_loss: 1.1169e-04\n",
      "Epoch 317/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.5067e-04 - val_loss: 7.6505e-05\n",
      "Epoch 318/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.3705e-04 - val_loss: 7.7207e-05\n",
      "Epoch 319/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.4169e-04 - val_loss: 4.0005e-04\n",
      "Epoch 320/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 1.8772e-04 - val_loss: 1.1577e-04\n",
      "Epoch 321/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.3755e-04 - val_loss: 1.2242e-04\n",
      "Epoch 322/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.2156e-04 - val_loss: 8.2609e-05\n",
      "Epoch 323/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2522e-04 - val_loss: 4.3744e-04\n",
      "Epoch 324/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.8959e-04 - val_loss: 7.4496e-05\n",
      "Epoch 325/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.5662e-04 - val_loss: 9.8561e-05\n",
      "Epoch 326/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.3776e-04 - val_loss: 9.4991e-05\n",
      "Epoch 327/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.1749e-04 - val_loss: 5.2785e-04\n",
      "Epoch 328/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 2.0033e-04 - val_loss: 2.7549e-04\n",
      "Epoch 329/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.6848e-04 - val_loss: 1.7440e-04\n",
      "Epoch 330/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.5711e-04 - val_loss: 8.4687e-05\n",
      "Epoch 331/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.4262e-04 - val_loss: 7.3217e-05\n",
      "Epoch 332/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.4438e-04 - val_loss: 1.1561e-04\n",
      "Epoch 333/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.2655e-04 - val_loss: 7.1975e-05\n",
      "Epoch 334/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.3513e-04 - val_loss: 7.9310e-05\n",
      "Epoch 335/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.4589e-04 - val_loss: 1.1952e-04\n",
      "Epoch 336/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.3697e-04 - val_loss: 1.4018e-04\n",
      "Epoch 337/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.3052e-04 - val_loss: 7.3289e-05\n",
      "Epoch 338/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1740e-04 - val_loss: 1.5171e-04\n",
      "Epoch 339/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.4758e-04 - val_loss: 7.3054e-05\n",
      "Epoch 340/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2752e-04 - val_loss: 7.4972e-05\n",
      "Epoch 341/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.2036e-04 - val_loss: 7.3005e-05\n",
      "Epoch 342/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.4984e-04 - val_loss: 1.4617e-04\n",
      "Epoch 343/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.5349e-04 - val_loss: 1.0236e-04\n",
      "Epoch 344/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.5450e-04 - val_loss: 8.0253e-05\n",
      "Epoch 345/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1725e-04 - val_loss: 8.8391e-05\n",
      "Epoch 346/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1137e-04 - val_loss: 1.0981e-04\n",
      "Epoch 347/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2558e-04 - val_loss: 7.3510e-05\n",
      "Epoch 348/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1578e-04 - val_loss: 1.1851e-04\n",
      "Epoch 349/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.3211e-04 - val_loss: 2.3807e-04\n",
      "Epoch 350/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.7731e-04 - val_loss: 1.1157e-04\n",
      "Epoch 351/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.6598e-04 - val_loss: 7.3029e-05\n",
      "Epoch 352/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1835e-04 - val_loss: 8.0959e-05\n",
      "Epoch 353/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.2529e-04 - val_loss: 7.3943e-05\n",
      "Epoch 354/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1255e-04 - val_loss: 9.9128e-05\n",
      "Epoch 355/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.3326e-04 - val_loss: 1.0213e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 356/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1345e-04 - val_loss: 1.2769e-04\n",
      "Epoch 357/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.5940e-04 - val_loss: 2.4694e-04\n",
      "Epoch 358/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.2383e-04 - val_loss: 1.7556e-04\n",
      "Epoch 359/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.4747e-04 - val_loss: 1.4392e-04\n",
      "Epoch 360/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 2.1713e-04 - val_loss: 1.0438e-04\n",
      "Epoch 361/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 1.3283e-04 - val_loss: 1.3577e-04\n",
      "Epoch 362/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.2255e-04 - val_loss: 3.4175e-04\n",
      "Epoch 363/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.7184e-04 - val_loss: 2.1379e-04\n",
      "Epoch 364/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.5386e-04 - val_loss: 9.5817e-05\n",
      "Epoch 365/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.4763e-04 - val_loss: 1.6341e-04\n",
      "Epoch 366/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.0503e-04 - val_loss: 8.2191e-05\n",
      "Epoch 367/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.9769e-04 - val_loss: 1.0872e-04\n",
      "Epoch 368/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.9133e-04 - val_loss: 3.3191e-04\n",
      "Epoch 369/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 2.5384e-04 - val_loss: 8.9534e-05\n",
      "Epoch 370/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.3671e-04 - val_loss: 2.3190e-04\n",
      "Epoch 371/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.3923e-04 - val_loss: 7.8216e-05\n",
      "Epoch 372/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.2735e-04 - val_loss: 7.7881e-05\n",
      "Epoch 373/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.4002e-04 - val_loss: 1.0313e-04\n",
      "Epoch 374/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.5034e-04 - val_loss: 8.5121e-05\n",
      "Epoch 375/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.7696e-04 - val_loss: 2.7818e-04\n",
      "Epoch 376/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.6002e-04 - val_loss: 2.7879e-04\n",
      "Epoch 377/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.6718e-04 - val_loss: 1.8501e-04\n",
      "Epoch 378/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1961e-04 - val_loss: 7.0337e-05\n",
      "Epoch 379/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1221e-04 - val_loss: 1.0852e-04\n",
      "Epoch 380/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1742e-04 - val_loss: 8.4677e-05\n",
      "Epoch 381/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1203e-04 - val_loss: 7.3930e-05\n",
      "Epoch 382/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2711e-04 - val_loss: 3.5829e-04\n",
      "Epoch 383/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.6451e-04 - val_loss: 8.5749e-05\n",
      "Epoch 384/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.4762e-04 - val_loss: 7.2800e-05\n",
      "Epoch 385/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.2333e-04 - val_loss: 7.5946e-05\n",
      "Epoch 386/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0308e-04 - val_loss: 9.3030e-05\n",
      "Epoch 387/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.2998e-04 - val_loss: 1.4444e-04\n",
      "Epoch 388/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.4372e-04 - val_loss: 1.8308e-04\n",
      "Epoch 389/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.4470e-04 - val_loss: 1.8936e-04\n",
      "Epoch 390/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.1621e-04 - val_loss: 7.2622e-05\n",
      "Epoch 391/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1272e-04 - val_loss: 7.5986e-05\n",
      "Epoch 392/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0983e-04 - val_loss: 7.4933e-05\n",
      "Epoch 393/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1212e-04 - val_loss: 7.2609e-05\n",
      "Epoch 394/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.9731e-05 - val_loss: 7.4601e-05\n",
      "Epoch 395/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1847e-04 - val_loss: 2.2874e-04\n",
      "Epoch 396/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1924e-04 - val_loss: 1.1833e-04\n",
      "Epoch 397/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2341e-04 - val_loss: 1.5404e-04\n",
      "Epoch 398/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.0948e-04 - val_loss: 8.2172e-05\n",
      "Epoch 399/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.2725e-04 - val_loss: 6.9972e-05\n",
      "Epoch 400/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.6704e-04 - val_loss: 7.0551e-05\n",
      "Epoch 401/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.7520e-04 - val_loss: 1.5197e-04\n",
      "Epoch 402/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 2.2453e-04 - val_loss: 3.4156e-04\n",
      "Epoch 403/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.4922e-04 - val_loss: 9.3435e-05\n",
      "Epoch 404/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.2464e-04 - val_loss: 7.0889e-05\n",
      "Epoch 405/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2077e-04 - val_loss: 1.0478e-04\n",
      "Epoch 406/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2248e-04 - val_loss: 1.0575e-04\n",
      "Epoch 407/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.2458e-04 - val_loss: 6.9434e-05\n",
      "Epoch 408/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.2016e-04 - val_loss: 1.2877e-04\n",
      "Epoch 409/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.2946e-04 - val_loss: 7.7591e-05\n",
      "Epoch 410/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1081e-04 - val_loss: 6.9227e-05\n",
      "Epoch 411/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2921e-04 - val_loss: 1.8508e-04\n",
      "Epoch 412/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.2573e-04 - val_loss: 7.7351e-05\n",
      "Epoch 413/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.4109e-04 - val_loss: 7.0973e-05\n",
      "Epoch 414/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.0658e-04 - val_loss: 7.2613e-05\n",
      "Epoch 415/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1223e-04 - val_loss: 1.1492e-04\n",
      "Epoch 416/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.3148e-04 - val_loss: 7.0836e-05\n",
      "Epoch 417/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.2260e-04 - val_loss: 1.5089e-04\n",
      "Epoch 418/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1591e-04 - val_loss: 1.1457e-04\n",
      "Epoch 419/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.6322e-04 - val_loss: 1.9162e-04\n",
      "Epoch 420/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.4421e-04 - val_loss: 9.2237e-05\n",
      "Epoch 421/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0633e-04 - val_loss: 7.8188e-05\n",
      "Epoch 422/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.0914e-04 - val_loss: 1.0929e-04\n",
      "Epoch 423/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0774e-04 - val_loss: 1.8097e-04\n",
      "Epoch 424/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.2832e-04 - val_loss: 3.2525e-04\n",
      "Epoch 425/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.1541e-04 - val_loss: 3.6101e-04\n",
      "Epoch 426/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 552us/step - loss: 2.2435e-04 - val_loss: 5.8227e-04\n",
      "Epoch 427/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 2.4755e-04 - val_loss: 2.9883e-04\n",
      "Epoch 428/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.7045e-04 - val_loss: 1.1848e-04\n",
      "Epoch 429/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.1013e-04 - val_loss: 7.2201e-05\n",
      "Epoch 430/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.8537e-05 - val_loss: 1.0582e-04\n",
      "Epoch 431/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0301e-04 - val_loss: 7.4920e-05\n",
      "Epoch 432/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1013e-04 - val_loss: 8.7060e-05\n",
      "Epoch 433/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0576e-04 - val_loss: 1.3079e-04\n",
      "Epoch 434/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.5018e-04 - val_loss: 2.1882e-04\n",
      "Epoch 435/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 2.0150e-04 - val_loss: 4.9122e-04\n",
      "Epoch 436/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.3676e-04 - val_loss: 7.8953e-05\n",
      "Epoch 437/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.4546e-04 - val_loss: 1.1327e-04\n",
      "Epoch 438/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.5154e-04 - val_loss: 1.4852e-04\n",
      "Epoch 439/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.2915e-04 - val_loss: 7.4092e-05\n",
      "Epoch 440/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.1692e-04 - val_loss: 7.7698e-05\n",
      "Epoch 441/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 1.1411e-04 - val_loss: 8.9777e-05\n",
      "Epoch 442/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.1354e-04 - val_loss: 6.9170e-05\n",
      "Epoch 443/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 1.1583e-04 - val_loss: 1.3911e-04\n",
      "Epoch 444/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 1.0641e-04 - val_loss: 6.9010e-05\n",
      "Epoch 445/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 9.4772e-05 - val_loss: 6.8953e-05\n",
      "Epoch 446/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 1.0658e-04 - val_loss: 8.7864e-05\n",
      "Epoch 447/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 1.0622e-04 - val_loss: 7.1522e-05\n",
      "Epoch 448/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 9.8279e-05 - val_loss: 6.9779e-05\n",
      "Epoch 449/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.0056e-04 - val_loss: 1.3879e-04\n",
      "Epoch 450/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.4345e-04 - val_loss: 1.5828e-04\n",
      "Epoch 451/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.4262e-04 - val_loss: 2.7135e-04\n",
      "Epoch 452/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 1.4819e-04 - val_loss: 3.1099e-04\n",
      "Epoch 453/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 2.0552e-04 - val_loss: 2.3980e-04\n",
      "Epoch 454/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.4582e-04 - val_loss: 6.7654e-05\n",
      "Epoch 455/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.4319e-04 - val_loss: 6.8210e-05\n",
      "Epoch 456/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0767e-04 - val_loss: 7.0287e-05\n",
      "Epoch 457/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0655e-04 - val_loss: 7.7585e-05\n",
      "Epoch 458/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1375e-04 - val_loss: 1.7001e-04\n",
      "Epoch 459/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.2482e-04 - val_loss: 1.4270e-04\n",
      "Epoch 460/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0791e-04 - val_loss: 6.8989e-05\n",
      "Epoch 461/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1533e-04 - val_loss: 8.0808e-05\n",
      "Epoch 462/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1727e-04 - val_loss: 1.0619e-04\n",
      "Epoch 463/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.6318e-04 - val_loss: 1.2743e-04\n",
      "Epoch 464/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.3835e-04 - val_loss: 8.7525e-05\n",
      "Epoch 465/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2938e-04 - val_loss: 2.1945e-04\n",
      "Epoch 466/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.7263e-04 - val_loss: 7.4449e-05\n",
      "Epoch 467/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1608e-04 - val_loss: 6.7189e-05\n",
      "Epoch 468/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.9186e-05 - val_loss: 7.6435e-05\n",
      "Epoch 469/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1050e-04 - val_loss: 1.8724e-04\n",
      "Epoch 470/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 1.6018e-04 - val_loss: 2.7508e-04\n",
      "Epoch 471/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.3332e-04 - val_loss: 7.3406e-05\n",
      "Epoch 472/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.2130e-04 - val_loss: 6.9622e-05\n",
      "Epoch 473/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.0510e-04 - val_loss: 8.8893e-05\n",
      "Epoch 474/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.3039e-04 - val_loss: 2.9546e-04\n",
      "Epoch 475/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.5901e-04 - val_loss: 1.1869e-04\n",
      "Epoch 476/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.0973e-04 - val_loss: 6.9217e-05\n",
      "Epoch 477/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 9.9724e-05 - val_loss: 9.4522e-05\n",
      "Epoch 478/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 1.1076e-04 - val_loss: 7.0473e-05\n",
      "Epoch 479/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 1.0249e-04 - val_loss: 7.2639e-05\n",
      "Epoch 480/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 1.0866e-04 - val_loss: 7.0983e-05\n",
      "Epoch 481/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.3721e-05 - val_loss: 6.8466e-05\n",
      "Epoch 482/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 9.0795e-05 - val_loss: 6.9051e-05\n",
      "Epoch 483/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 1.0192e-04 - val_loss: 7.9271e-05\n",
      "Epoch 484/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 1.1253e-04 - val_loss: 7.1547e-05\n",
      "Epoch 485/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.2085e-04 - val_loss: 1.3540e-04\n",
      "Epoch 486/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.5585e-04 - val_loss: 3.6075e-04\n",
      "Epoch 487/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.8805e-04 - val_loss: 1.0757e-04\n",
      "Epoch 488/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.3959e-04 - val_loss: 1.1540e-04\n",
      "Epoch 489/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.5197e-04 - val_loss: 2.6158e-04\n",
      "Epoch 490/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.6686e-04 - val_loss: 1.1315e-04\n",
      "Epoch 491/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.5920e-04 - val_loss: 7.7856e-05\n",
      "Epoch 492/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.0692e-04 - val_loss: 7.0952e-05\n",
      "Epoch 493/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.0600e-04 - val_loss: 8.1308e-05\n",
      "Epoch 494/2000\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 1.3634e-04 - val_loss: 9.5201e-05\n",
      "Epoch 495/2000\n",
      "3690/3690 [==============================] - 2s 597us/step - loss: 1.2031e-04 - val_loss: 6.9715e-05\n",
      "Epoch 496/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 1.1087e-04 - val_loss: 2.8530e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 497/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 1.9616e-04 - val_loss: 1.9450e-04\n",
      "Epoch 498/2000\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 1.2068e-04 - val_loss: 7.6222e-05\n",
      "Epoch 499/2000\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 1.0662e-04 - val_loss: 1.1497e-04\n",
      "Epoch 500/2000\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 1.1202e-04 - val_loss: 7.0543e-05\n",
      "Epoch 501/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.1772e-04 - val_loss: 2.0628e-04\n",
      "Epoch 502/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.3991e-04 - val_loss: 1.3106e-04\n",
      "Epoch 503/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.7380e-04 - val_loss: 1.2906e-04\n",
      "Epoch 504/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.8438e-04 - val_loss: 1.1972e-04\n",
      "Epoch 505/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.5057e-04 - val_loss: 7.8788e-05\n",
      "Epoch 506/2000\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 1.1370e-04 - val_loss: 9.0082e-05\n",
      "Epoch 507/2000\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 9.5792e-05 - val_loss: 8.8447e-05\n",
      "Epoch 508/2000\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 1.0371e-04 - val_loss: 9.3555e-05\n",
      "Epoch 509/2000\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 1.1670e-04 - val_loss: 8.5353e-05\n",
      "Epoch 510/2000\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 1.0491e-04 - val_loss: 8.3995e-05\n",
      "Epoch 511/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 1.0623e-04 - val_loss: 1.0121e-04\n",
      "Epoch 512/2000\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 1.1267e-04 - val_loss: 1.7886e-04\n",
      "Epoch 513/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.4572e-04 - val_loss: 1.4005e-04\n",
      "Epoch 514/2000\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 9.4537e-05 - val_loss: 7.7234e-05\n",
      "Epoch 515/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.5119e-05 - val_loss: 7.2041e-05\n",
      "Epoch 516/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0875e-04 - val_loss: 7.1979e-05\n",
      "Epoch 517/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 9.6602e-05 - val_loss: 1.3058e-04\n",
      "Epoch 518/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0718e-04 - val_loss: 6.9904e-05\n",
      "Epoch 519/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0175e-04 - val_loss: 9.7587e-05\n",
      "Epoch 520/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.9197e-05 - val_loss: 7.0163e-05\n",
      "Epoch 521/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0548e-04 - val_loss: 7.2034e-05\n",
      "Epoch 522/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.5612e-04 - val_loss: 1.8173e-04\n",
      "Epoch 523/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2803e-04 - val_loss: 9.1308e-05\n",
      "Epoch 524/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1214e-04 - val_loss: 7.8986e-05\n",
      "Epoch 525/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.9312e-05 - val_loss: 1.2785e-04\n",
      "Epoch 526/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0080e-04 - val_loss: 1.0287e-04\n",
      "Epoch 527/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.0987e-04 - val_loss: 1.3185e-04\n",
      "Epoch 528/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.2165e-04 - val_loss: 7.2055e-05\n",
      "Epoch 529/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1332e-04 - val_loss: 7.6095e-05\n",
      "Epoch 530/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.7795e-04 - val_loss: 1.4902e-04\n",
      "Epoch 531/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.7216e-04 - val_loss: 8.2370e-05\n",
      "Epoch 532/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0429e-04 - val_loss: 7.8287e-05\n",
      "Epoch 533/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0819e-04 - val_loss: 7.6202e-05\n",
      "Epoch 534/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.0475e-05 - val_loss: 7.6160e-05\n",
      "Epoch 535/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.5640e-05 - val_loss: 7.5915e-05\n",
      "Epoch 536/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.8431e-05 - val_loss: 7.1551e-05\n",
      "Epoch 537/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.0694e-05 - val_loss: 4.7531e-04\n",
      "Epoch 538/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 2.2400e-04 - val_loss: 7.5944e-05\n",
      "Epoch 539/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.6531e-04 - val_loss: 2.7786e-04\n",
      "Epoch 540/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 2.4071e-04 - val_loss: 5.4743e-04\n",
      "Epoch 541/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 2.5230e-04 - val_loss: 2.1520e-04\n",
      "Epoch 542/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.4417e-04 - val_loss: 1.6906e-04\n",
      "Epoch 543/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.3564e-04 - val_loss: 7.5964e-05\n",
      "Epoch 544/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.0415e-04 - val_loss: 7.1832e-05\n",
      "Epoch 545/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.0253e-05 - val_loss: 1.0903e-04\n",
      "Epoch 546/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0965e-04 - val_loss: 6.9967e-05\n",
      "Epoch 547/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.9024e-05 - val_loss: 7.1803e-05\n",
      "Epoch 548/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0117e-04 - val_loss: 1.4342e-04\n",
      "Epoch 549/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1069e-04 - val_loss: 1.7088e-04\n",
      "Epoch 550/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1781e-04 - val_loss: 2.8448e-04\n",
      "Epoch 551/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.5152e-04 - val_loss: 7.3430e-05\n",
      "Epoch 552/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0007e-04 - val_loss: 6.8703e-05\n",
      "Epoch 553/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.0181e-04 - val_loss: 2.1316e-04\n",
      "Epoch 554/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.3290e-04 - val_loss: 8.7950e-05\n",
      "Epoch 555/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.9245e-05 - val_loss: 7.3968e-05\n",
      "Epoch 556/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.2192e-05 - val_loss: 9.0158e-05\n",
      "Epoch 557/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.1035e-04 - val_loss: 1.8008e-04\n",
      "Epoch 558/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.2354e-04 - val_loss: 7.0146e-05\n",
      "Epoch 559/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0367e-04 - val_loss: 9.1365e-05\n",
      "Epoch 560/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 9.9487e-05 - val_loss: 1.1674e-04\n",
      "Epoch 561/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.0397e-04 - val_loss: 6.7777e-05\n",
      "Epoch 562/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.0135e-04 - val_loss: 2.3850e-04\n",
      "Epoch 563/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.9587e-04 - val_loss: 1.7551e-04\n",
      "Epoch 564/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.7905e-04 - val_loss: 1.5755e-04\n",
      "Epoch 565/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.4787e-04 - val_loss: 3.3766e-04\n",
      "Epoch 566/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.2083e-04 - val_loss: 9.0255e-05\n",
      "Epoch 567/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.4456e-05 - val_loss: 7.2478e-05\n",
      "Epoch 568/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.6592e-05 - val_loss: 6.8543e-05\n",
      "Epoch 569/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 9.2457e-05 - val_loss: 7.0059e-05\n",
      "Epoch 570/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.4940e-05 - val_loss: 1.6933e-04\n",
      "Epoch 571/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.3727e-04 - val_loss: 9.0403e-05\n",
      "Epoch 572/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0323e-04 - val_loss: 7.2643e-05\n",
      "Epoch 573/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 9.7707e-05 - val_loss: 6.6193e-05\n",
      "Epoch 574/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.9393e-05 - val_loss: 9.1300e-05\n",
      "Epoch 575/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.3714e-05 - val_loss: 7.9454e-05\n",
      "Epoch 576/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.8672e-05 - val_loss: 9.9558e-05\n",
      "Epoch 577/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.0297e-04 - val_loss: 7.4659e-05\n",
      "Epoch 578/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.6606e-05 - val_loss: 8.1024e-05\n",
      "Epoch 579/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.6385e-05 - val_loss: 8.1437e-05\n",
      "Epoch 580/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.3867e-05 - val_loss: 6.8717e-05\n",
      "Epoch 581/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.1296e-04 - val_loss: 7.1733e-05\n",
      "Epoch 582/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 8.5073e-05 - val_loss: 9.0074e-05\n",
      "Epoch 583/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.7531e-05 - val_loss: 9.5103e-05\n",
      "Epoch 584/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.0190e-04 - val_loss: 6.6928e-05\n",
      "Epoch 585/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.8235e-05 - val_loss: 7.2379e-05\n",
      "Epoch 586/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.0518e-05 - val_loss: 1.2100e-04\n",
      "Epoch 587/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 1.0820e-04 - val_loss: 6.7691e-05\n",
      "Epoch 588/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.6101e-05 - val_loss: 1.0285e-04\n",
      "Epoch 589/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.3386e-04 - val_loss: 8.6842e-05\n",
      "Epoch 590/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.0354e-04 - val_loss: 8.0877e-05\n",
      "Epoch 591/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 9.7460e-05 - val_loss: 1.1127e-04\n",
      "Epoch 592/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.4797e-04 - val_loss: 7.9247e-05\n",
      "Epoch 593/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.8800e-05 - val_loss: 7.0734e-05\n",
      "Epoch 594/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.5890e-05 - val_loss: 6.9326e-05\n",
      "Epoch 595/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.1418e-05 - val_loss: 1.2685e-04\n",
      "Epoch 596/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.6496e-04 - val_loss: 1.0665e-04\n",
      "Epoch 597/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2524e-04 - val_loss: 4.4488e-04\n",
      "Epoch 598/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.8672e-04 - val_loss: 2.3704e-04\n",
      "Epoch 599/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 2.0044e-04 - val_loss: 1.3103e-04\n",
      "Epoch 600/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.9835e-04 - val_loss: 1.0453e-04\n",
      "Epoch 601/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1929e-04 - val_loss: 6.7572e-05\n",
      "Epoch 602/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 9.8523e-05 - val_loss: 7.5273e-05\n",
      "Epoch 603/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.8097e-05 - val_loss: 7.4159e-05\n",
      "Epoch 604/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.7285e-05 - val_loss: 7.4819e-05\n",
      "Epoch 605/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.7097e-05 - val_loss: 6.7916e-05\n",
      "Epoch 606/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.0344e-04 - val_loss: 9.5924e-05\n",
      "Epoch 607/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.3352e-04 - val_loss: 1.5838e-04\n",
      "Epoch 608/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.2303e-04 - val_loss: 9.3566e-05\n",
      "Epoch 609/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0339e-04 - val_loss: 7.2491e-05\n",
      "Epoch 610/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1292e-04 - val_loss: 8.5411e-05\n",
      "Epoch 611/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 9.6658e-05 - val_loss: 6.9936e-05\n",
      "Epoch 612/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.4935e-05 - val_loss: 2.1783e-04\n",
      "Epoch 613/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.2966e-04 - val_loss: 9.9316e-05\n",
      "Epoch 614/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.0340e-04 - val_loss: 9.6258e-05\n",
      "Epoch 615/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0517e-04 - val_loss: 6.6069e-05\n",
      "Epoch 616/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 9.9759e-05 - val_loss: 9.6657e-05\n",
      "Epoch 617/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.4781e-05 - val_loss: 8.7183e-05\n",
      "Epoch 618/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.4797e-05 - val_loss: 6.7063e-05\n",
      "Epoch 619/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.0319e-04 - val_loss: 6.6164e-05\n",
      "Epoch 620/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.0023e-04 - val_loss: 7.3801e-05\n",
      "Epoch 621/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.6327e-05 - val_loss: 6.8579e-05\n",
      "Epoch 622/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 8.4923e-05 - val_loss: 7.0633e-05\n",
      "Epoch 623/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 9.6549e-05 - val_loss: 7.7531e-05\n",
      "Epoch 624/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1091e-04 - val_loss: 4.1540e-04\n",
      "Epoch 625/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 2.6685e-04 - val_loss: 2.3460e-04\n",
      "Epoch 626/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 2.1085e-04 - val_loss: 6.9559e-05\n",
      "Epoch 627/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1980e-04 - val_loss: 3.0723e-04\n",
      "Epoch 628/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.3790e-04 - val_loss: 1.1125e-04\n",
      "Epoch 629/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1525e-04 - val_loss: 1.9080e-04\n",
      "Epoch 630/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.4307e-04 - val_loss: 7.5096e-05\n",
      "Epoch 631/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 1.2430e-04 - val_loss: 1.1548e-04\n",
      "Epoch 632/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.3886e-04 - val_loss: 1.6670e-04\n",
      "Epoch 633/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1645e-04 - val_loss: 6.8407e-05\n",
      "Epoch 634/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1054e-04 - val_loss: 8.5465e-05\n",
      "Epoch 635/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.6298e-05 - val_loss: 6.8153e-05\n",
      "Epoch 636/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.4704e-05 - val_loss: 1.1003e-04\n",
      "Epoch 637/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.1837e-04 - val_loss: 1.2236e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 638/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0532e-04 - val_loss: 1.3529e-04\n",
      "Epoch 639/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.4921e-04 - val_loss: 1.3840e-04\n",
      "Epoch 640/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.2087e-04 - val_loss: 1.0239e-04\n",
      "Epoch 641/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 9.4419e-05 - val_loss: 1.9568e-04\n",
      "Epoch 642/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.3849e-05 - val_loss: 6.8972e-05\n",
      "Epoch 643/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1774e-04 - val_loss: 9.2552e-05\n",
      "Epoch 644/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1919e-04 - val_loss: 1.1636e-04\n",
      "Epoch 645/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1892e-04 - val_loss: 2.8855e-04\n",
      "Epoch 646/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.6566e-04 - val_loss: 1.7027e-04\n",
      "Epoch 647/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.1696e-04 - val_loss: 7.7785e-05\n",
      "Epoch 648/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 1.0593e-04 - val_loss: 3.3007e-04\n",
      "Epoch 649/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.7302e-04 - val_loss: 7.3246e-05\n",
      "Epoch 650/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1498e-04 - val_loss: 1.7114e-04\n",
      "Epoch 651/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.3607e-04 - val_loss: 2.3267e-04\n",
      "Epoch 652/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1797e-04 - val_loss: 6.8009e-05\n",
      "Epoch 653/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.3829e-05 - val_loss: 7.5607e-05\n",
      "Epoch 654/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.5533e-05 - val_loss: 1.7580e-04\n",
      "Epoch 655/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.2400e-04 - val_loss: 2.3418e-04\n",
      "Epoch 656/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1355e-04 - val_loss: 1.9045e-04\n",
      "Epoch 657/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 9.9594e-05 - val_loss: 7.5684e-05\n",
      "Epoch 658/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.8668e-05 - val_loss: 6.9889e-05\n",
      "Epoch 659/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.8574e-05 - val_loss: 7.7262e-05\n",
      "Epoch 660/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.3213e-05 - val_loss: 1.7701e-04\n",
      "Epoch 661/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.8207e-05 - val_loss: 8.6174e-05\n",
      "Epoch 662/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.3261e-05 - val_loss: 6.9260e-05\n",
      "Epoch 663/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.1055e-05 - val_loss: 6.7876e-05\n",
      "Epoch 664/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.7024e-05 - val_loss: 9.7474e-05\n",
      "Epoch 665/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.6652e-05 - val_loss: 7.6261e-05\n",
      "Epoch 666/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0458e-04 - val_loss: 7.6950e-05\n",
      "Epoch 667/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.0361e-04 - val_loss: 6.8842e-05\n",
      "Epoch 668/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 1.0935e-04 - val_loss: 1.2719e-04\n",
      "Epoch 669/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0001e-04 - val_loss: 9.1912e-05\n",
      "Epoch 670/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.1149e-04 - val_loss: 7.8492e-05\n",
      "Epoch 671/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.0098e-04 - val_loss: 1.9462e-04\n",
      "Epoch 672/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.0442e-04 - val_loss: 7.8516e-05\n",
      "Epoch 673/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.0494e-05 - val_loss: 2.2298e-04\n",
      "Epoch 674/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 1.3432e-04 - val_loss: 1.0400e-04\n",
      "Epoch 675/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.5800e-04 - val_loss: 1.0657e-04\n",
      "Epoch 676/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.8284e-04 - val_loss: 3.2269e-04\n",
      "Epoch 677/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.9044e-04 - val_loss: 1.0014e-04\n",
      "Epoch 678/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1995e-04 - val_loss: 3.1591e-04\n",
      "Epoch 679/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1845e-04 - val_loss: 6.8542e-05\n",
      "Epoch 680/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0647e-04 - val_loss: 2.2999e-04\n",
      "Epoch 681/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 2.0769e-04 - val_loss: 1.1983e-04\n",
      "Epoch 682/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.2439e-05 - val_loss: 9.9373e-05\n",
      "Epoch 683/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.1374e-05 - val_loss: 1.1386e-04\n",
      "Epoch 684/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.1850e-04 - val_loss: 1.0468e-04\n",
      "Epoch 685/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.2902e-05 - val_loss: 1.2861e-04\n",
      "Epoch 686/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.0187e-04 - val_loss: 1.6044e-04\n",
      "Epoch 687/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.8787e-05 - val_loss: 1.0886e-04\n",
      "Epoch 688/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.2080e-04 - val_loss: 7.9494e-05\n",
      "Epoch 689/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1352e-04 - val_loss: 1.8670e-04\n",
      "Epoch 690/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0394e-04 - val_loss: 7.4623e-05\n",
      "Epoch 691/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.2619e-05 - val_loss: 7.0374e-05\n",
      "Epoch 692/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0342e-04 - val_loss: 9.4173e-05\n",
      "Epoch 693/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.6008e-05 - val_loss: 8.4079e-05\n",
      "Epoch 694/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.3514e-05 - val_loss: 1.1522e-04\n",
      "Epoch 695/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.1476e-05 - val_loss: 1.0467e-04\n",
      "Epoch 696/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.7528e-05 - val_loss: 7.4197e-05\n",
      "Epoch 697/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.5371e-05 - val_loss: 7.7865e-05\n",
      "Epoch 698/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1652e-04 - val_loss: 1.4530e-04\n",
      "Epoch 699/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0315e-04 - val_loss: 6.7702e-05\n",
      "Epoch 700/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.3267e-05 - val_loss: 8.2775e-05\n",
      "Epoch 701/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 8.2733e-05 - val_loss: 7.5253e-05\n",
      "Epoch 702/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 7.8709e-05 - val_loss: 1.0155e-04\n",
      "Epoch 703/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1230e-04 - val_loss: 1.3817e-04\n",
      "Epoch 704/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.2202e-04 - val_loss: 8.5084e-05\n",
      "Epoch 705/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.6613e-05 - val_loss: 9.2367e-05\n",
      "Epoch 706/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.3268e-05 - val_loss: 1.0332e-04\n",
      "Epoch 707/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.2323e-05 - val_loss: 7.8948e-05\n",
      "Epoch 708/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 559us/step - loss: 8.5268e-05 - val_loss: 9.5119e-05\n",
      "Epoch 709/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 1.0080e-04 - val_loss: 7.0835e-05\n",
      "Epoch 710/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.8718e-05 - val_loss: 1.7789e-04\n",
      "Epoch 711/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1193e-04 - val_loss: 3.2033e-04\n",
      "Epoch 712/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.3155e-04 - val_loss: 2.9053e-04\n",
      "Epoch 713/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.1408e-04 - val_loss: 6.8971e-05\n",
      "Epoch 714/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.3243e-04 - val_loss: 7.3562e-05\n",
      "Epoch 715/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1195e-04 - val_loss: 1.5936e-04\n",
      "Epoch 716/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.3339e-04 - val_loss: 9.3828e-05\n",
      "Epoch 717/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.3527e-04 - val_loss: 1.6400e-04\n",
      "Epoch 718/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0541e-04 - val_loss: 7.3855e-05\n",
      "Epoch 719/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.1381e-05 - val_loss: 2.5847e-04\n",
      "Epoch 720/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.6017e-04 - val_loss: 3.7106e-04\n",
      "Epoch 721/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.7536e-04 - val_loss: 7.0950e-05\n",
      "Epoch 722/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1781e-04 - val_loss: 1.3280e-04\n",
      "Epoch 723/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.1256e-05 - val_loss: 1.9049e-04\n",
      "Epoch 724/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.5013e-05 - val_loss: 1.5433e-04\n",
      "Epoch 725/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 9.3332e-05 - val_loss: 8.0243e-05\n",
      "Epoch 726/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.4619e-05 - val_loss: 9.1345e-05\n",
      "Epoch 727/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.1523e-05 - val_loss: 7.3085e-05\n",
      "Epoch 728/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.3054e-05 - val_loss: 8.4721e-05\n",
      "Epoch 729/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.4205e-05 - val_loss: 1.0688e-04\n",
      "Epoch 730/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0687e-04 - val_loss: 1.8083e-04\n",
      "Epoch 731/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0986e-04 - val_loss: 1.1021e-04\n",
      "Epoch 732/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1483e-04 - val_loss: 1.4213e-04\n",
      "Epoch 733/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.4949e-04 - val_loss: 2.0862e-04\n",
      "Epoch 734/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.5772e-04 - val_loss: 4.3140e-04\n",
      "Epoch 735/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.5591e-04 - val_loss: 1.1418e-04\n",
      "Epoch 736/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.2363e-04 - val_loss: 7.4134e-05\n",
      "Epoch 737/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.7390e-05 - val_loss: 1.2708e-04\n",
      "Epoch 738/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.9605e-05 - val_loss: 6.9896e-05\n",
      "Epoch 739/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.7507e-05 - val_loss: 8.7529e-05\n",
      "Epoch 740/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.7151e-05 - val_loss: 6.9678e-05\n",
      "Epoch 741/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.8307e-05 - val_loss: 1.3105e-04\n",
      "Epoch 742/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.1337e-04 - val_loss: 1.3008e-04\n",
      "Epoch 743/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 1.1492e-04 - val_loss: 8.3149e-05\n",
      "Epoch 744/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.1150e-04 - val_loss: 1.0475e-04\n",
      "Epoch 745/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.0292e-04 - val_loss: 7.2683e-05\n",
      "Epoch 746/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.1377e-05 - val_loss: 6.9793e-05\n",
      "Epoch 747/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.2836e-05 - val_loss: 1.0841e-04\n",
      "Epoch 748/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.6610e-05 - val_loss: 2.7046e-04\n",
      "Epoch 749/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.4182e-04 - val_loss: 7.0747e-05\n",
      "Epoch 750/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.8016e-05 - val_loss: 7.8303e-05\n",
      "Epoch 751/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.5815e-05 - val_loss: 7.1634e-05\n",
      "Epoch 752/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.3207e-05 - val_loss: 9.0835e-05\n",
      "Epoch 753/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.0666e-05 - val_loss: 7.1665e-05\n",
      "Epoch 754/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.1567e-05 - val_loss: 8.0891e-05\n",
      "Epoch 755/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.9131e-05 - val_loss: 7.7229e-05\n",
      "Epoch 756/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.4112e-05 - val_loss: 7.3764e-05\n",
      "Epoch 757/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.8390e-05 - val_loss: 9.9040e-05\n",
      "Epoch 758/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.1179e-05 - val_loss: 7.4837e-05\n",
      "Epoch 759/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.7637e-05 - val_loss: 1.2605e-04\n",
      "Epoch 760/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.6166e-05 - val_loss: 1.5935e-04\n",
      "Epoch 761/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.3808e-05 - val_loss: 7.7724e-05\n",
      "Epoch 762/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.4645e-05 - val_loss: 7.8131e-05\n",
      "Epoch 763/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.3379e-05 - val_loss: 7.2389e-05\n",
      "Epoch 764/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.1823e-05 - val_loss: 1.0899e-04\n",
      "Epoch 765/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.9860e-05 - val_loss: 1.0280e-04\n",
      "Epoch 766/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0204e-04 - val_loss: 1.2913e-04\n",
      "Epoch 767/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0648e-04 - val_loss: 9.1094e-05\n",
      "Epoch 768/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.6529e-05 - val_loss: 7.3368e-05\n",
      "Epoch 769/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.8571e-05 - val_loss: 1.3446e-04\n",
      "Epoch 770/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0311e-04 - val_loss: 7.8153e-05\n",
      "Epoch 771/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.4407e-05 - val_loss: 7.5714e-05\n",
      "Epoch 772/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.9227e-05 - val_loss: 1.0381e-04\n",
      "Epoch 773/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.7523e-05 - val_loss: 8.2010e-05\n",
      "Epoch 774/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.6296e-05 - val_loss: 1.0561e-04\n",
      "Epoch 775/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.1012e-05 - val_loss: 2.0630e-04\n",
      "Epoch 776/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1860e-04 - val_loss: 2.5856e-04\n",
      "Epoch 777/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.3935e-04 - val_loss: 7.8933e-05\n",
      "Epoch 778/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.2955e-04 - val_loss: 8.4264e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 779/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.1533e-05 - val_loss: 7.4566e-05\n",
      "Epoch 780/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.2454e-05 - val_loss: 1.4952e-04\n",
      "Epoch 781/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.4146e-05 - val_loss: 1.1868e-04\n",
      "Epoch 782/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.7172e-05 - val_loss: 2.7896e-04\n",
      "Epoch 783/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.0378e-04 - val_loss: 8.6418e-05\n",
      "Epoch 784/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.5998e-05 - val_loss: 1.4281e-04\n",
      "Epoch 785/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.0183e-05 - val_loss: 1.1248e-04\n",
      "Epoch 786/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.1398e-05 - val_loss: 2.5015e-04\n",
      "Epoch 787/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0713e-04 - val_loss: 8.3866e-05\n",
      "Epoch 788/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.0054e-04 - val_loss: 1.0846e-04\n",
      "Epoch 789/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.9872e-05 - val_loss: 1.4665e-04\n",
      "Epoch 790/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.3205e-05 - val_loss: 7.5102e-05\n",
      "Epoch 791/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.7038e-05 - val_loss: 7.3002e-05\n",
      "Epoch 792/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.5169e-05 - val_loss: 8.2460e-05\n",
      "Epoch 793/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.1943e-05 - val_loss: 8.6075e-05\n",
      "Epoch 794/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0548e-04 - val_loss: 1.1374e-04\n",
      "Epoch 795/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.0426e-04 - val_loss: 1.9251e-04\n",
      "Epoch 796/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2787e-04 - val_loss: 1.0959e-04\n",
      "Epoch 797/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.3504e-04 - val_loss: 1.0260e-04\n",
      "Epoch 798/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.4418e-04 - val_loss: 1.1948e-04\n",
      "Epoch 799/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.2127e-05 - val_loss: 7.4974e-05\n",
      "Epoch 800/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.7283e-05 - val_loss: 7.3590e-05\n",
      "Epoch 801/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 9.0784e-05 - val_loss: 1.3138e-04\n",
      "Epoch 802/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.3643e-04 - val_loss: 4.4374e-04\n",
      "Epoch 803/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.6019e-04 - val_loss: 2.9210e-04\n",
      "Epoch 804/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1519e-04 - val_loss: 9.1422e-05\n",
      "Epoch 805/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.8055e-05 - val_loss: 7.8617e-05\n",
      "Epoch 806/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.7257e-05 - val_loss: 8.3910e-05\n",
      "Epoch 807/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1326e-04 - val_loss: 7.1763e-05\n",
      "Epoch 808/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 1.1372e-04 - val_loss: 1.7466e-04\n",
      "Epoch 809/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.3725e-04 - val_loss: 7.2821e-05\n",
      "Epoch 810/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.2312e-04 - val_loss: 9.1023e-05\n",
      "Epoch 811/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.9695e-05 - val_loss: 7.2864e-05\n",
      "Epoch 812/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.4001e-05 - val_loss: 1.1501e-04\n",
      "Epoch 813/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.6467e-05 - val_loss: 7.7868e-05\n",
      "Epoch 814/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.8484e-05 - val_loss: 7.4768e-05\n",
      "Epoch 815/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.4504e-05 - val_loss: 7.3080e-05\n",
      "Epoch 816/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.1703e-05 - val_loss: 1.5097e-04\n",
      "Epoch 817/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0859e-04 - val_loss: 2.1467e-04\n",
      "Epoch 818/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.3769e-05 - val_loss: 1.0847e-04\n",
      "Epoch 819/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.4013e-05 - val_loss: 1.5267e-04\n",
      "Epoch 820/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.5878e-05 - val_loss: 1.8577e-04\n",
      "Epoch 821/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.1504e-05 - val_loss: 1.0634e-04\n",
      "Epoch 822/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1377e-04 - val_loss: 2.9831e-04\n",
      "Epoch 823/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.1630e-05 - val_loss: 9.4534e-05\n",
      "Epoch 824/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.8866e-05 - val_loss: 8.6744e-05\n",
      "Epoch 825/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.8074e-05 - val_loss: 7.5610e-05\n",
      "Epoch 826/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.9649e-05 - val_loss: 1.8086e-04\n",
      "Epoch 827/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 9.4754e-05 - val_loss: 1.6060e-04\n",
      "Epoch 828/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 9.5960e-05 - val_loss: 7.4012e-05\n",
      "Epoch 829/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 8.5646e-05 - val_loss: 1.0075e-04\n",
      "Epoch 830/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.8331e-05 - val_loss: 1.0632e-04\n",
      "Epoch 831/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.7369e-05 - val_loss: 2.3135e-04\n",
      "Epoch 832/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.9252e-05 - val_loss: 1.7194e-04\n",
      "Epoch 833/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.3787e-05 - val_loss: 8.6133e-05\n",
      "Epoch 834/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.0773e-04 - val_loss: 7.4625e-05\n",
      "Epoch 835/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.0059e-04 - val_loss: 7.6959e-05\n",
      "Epoch 836/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1000e-04 - val_loss: 2.7931e-04\n",
      "Epoch 837/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.5701e-04 - val_loss: 1.9208e-04\n",
      "Epoch 838/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.0637e-04 - val_loss: 9.3257e-05\n",
      "Epoch 839/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1427e-04 - val_loss: 1.1186e-04\n",
      "Epoch 840/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 1.1051e-04 - val_loss: 1.6062e-04\n",
      "Epoch 841/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1986e-04 - val_loss: 1.2490e-04\n",
      "Epoch 842/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.1680e-04 - val_loss: 8.4527e-05\n",
      "Epoch 843/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.1200e-05 - val_loss: 7.2013e-05\n",
      "Epoch 844/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.6031e-05 - val_loss: 1.6216e-04\n",
      "Epoch 845/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.5075e-05 - val_loss: 9.5160e-05\n",
      "Epoch 846/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.8495e-05 - val_loss: 7.4577e-05\n",
      "Epoch 847/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.1629e-05 - val_loss: 7.9861e-05\n",
      "Epoch 848/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.7864e-05 - val_loss: 1.7450e-04\n",
      "Epoch 849/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.4374e-05 - val_loss: 1.4567e-04\n",
      "Epoch 850/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 8.5597e-05 - val_loss: 9.6917e-05\n",
      "Epoch 851/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1642e-04 - val_loss: 7.5808e-05\n",
      "Epoch 852/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 8.0020e-05 - val_loss: 1.5406e-04\n",
      "Epoch 853/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.7890e-05 - val_loss: 1.4365e-04\n",
      "Epoch 854/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.2163e-05 - val_loss: 2.8249e-04\n",
      "Epoch 855/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.2296e-04 - val_loss: 8.0156e-05\n",
      "Epoch 856/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.2276e-04 - val_loss: 1.2771e-04\n",
      "Epoch 857/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.0625e-04 - val_loss: 7.0953e-05\n",
      "Epoch 858/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.9410e-05 - val_loss: 9.9677e-05\n",
      "Epoch 859/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.8877e-05 - val_loss: 1.4770e-04\n",
      "Epoch 860/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.7884e-05 - val_loss: 1.4205e-04\n",
      "Epoch 861/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.3751e-05 - val_loss: 7.8006e-05\n",
      "Epoch 862/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.6464e-05 - val_loss: 8.6514e-05\n",
      "Epoch 863/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.1929e-05 - val_loss: 1.0915e-04\n",
      "Epoch 864/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0801e-04 - val_loss: 1.7451e-04\n",
      "Epoch 865/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.5279e-05 - val_loss: 1.4906e-04\n",
      "Epoch 866/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.4293e-05 - val_loss: 7.6476e-05\n",
      "Epoch 867/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.7832e-05 - val_loss: 9.5785e-05\n",
      "Epoch 868/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.2594e-05 - val_loss: 7.7079e-05\n",
      "Epoch 869/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.5430e-05 - val_loss: 7.9906e-05\n",
      "Epoch 870/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.5590e-05 - val_loss: 8.4530e-05\n",
      "Epoch 871/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.6355e-05 - val_loss: 1.0996e-04\n",
      "Epoch 872/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.2052e-05 - val_loss: 1.5060e-04\n",
      "Epoch 873/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.3702e-05 - val_loss: 1.0901e-04\n",
      "Epoch 874/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.1617e-05 - val_loss: 7.4706e-05\n",
      "Epoch 875/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.7179e-05 - val_loss: 2.3320e-04\n",
      "Epoch 876/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1571e-04 - val_loss: 1.5394e-04\n",
      "Epoch 877/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0080e-04 - val_loss: 2.5614e-04\n",
      "Epoch 878/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.2424e-05 - val_loss: 1.6256e-04\n",
      "Epoch 879/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.1481e-05 - val_loss: 7.9597e-05\n",
      "Epoch 880/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.7423e-05 - val_loss: 7.2358e-05\n",
      "Epoch 881/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.4146e-05 - val_loss: 1.1347e-04\n",
      "Epoch 882/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.6003e-05 - val_loss: 1.2318e-04\n",
      "Epoch 883/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 1.0204e-04 - val_loss: 1.0734e-04\n",
      "Epoch 884/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 9.7901e-05 - val_loss: 7.5589e-05\n",
      "Epoch 885/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.8792e-05 - val_loss: 8.1062e-05\n",
      "Epoch 886/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.9503e-05 - val_loss: 7.2725e-05\n",
      "Epoch 887/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.9887e-05 - val_loss: 8.0575e-05\n",
      "Epoch 888/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.3608e-05 - val_loss: 1.1434e-04\n",
      "Epoch 889/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.7076e-05 - val_loss: 1.2158e-04\n",
      "Epoch 890/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.9170e-05 - val_loss: 1.6924e-04\n",
      "Epoch 891/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1620e-04 - val_loss: 8.0027e-05\n",
      "Epoch 892/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.7424e-05 - val_loss: 1.5510e-04\n",
      "Epoch 893/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.5070e-05 - val_loss: 1.4222e-04\n",
      "Epoch 894/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.9841e-05 - val_loss: 7.7163e-05\n",
      "Epoch 895/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.6744e-05 - val_loss: 1.1361e-04\n",
      "Epoch 896/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.0188e-05 - val_loss: 7.6505e-05\n",
      "Epoch 897/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.3621e-05 - val_loss: 9.9461e-05\n",
      "Epoch 898/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.7013e-05 - val_loss: 1.0582e-04\n",
      "Epoch 899/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.2810e-04 - val_loss: 8.2536e-05\n",
      "Epoch 900/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.8900e-05 - val_loss: 1.9352e-04\n",
      "Epoch 901/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0014e-04 - val_loss: 2.1309e-04\n",
      "Epoch 902/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 9.4536e-05 - val_loss: 1.3499e-04\n",
      "Epoch 903/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.7172e-05 - val_loss: 8.0081e-05\n",
      "Epoch 904/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.0022e-05 - val_loss: 7.7039e-05\n",
      "Epoch 905/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.4466e-05 - val_loss: 7.9422e-05\n",
      "Epoch 906/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.7053e-05 - val_loss: 8.0764e-05\n",
      "Epoch 907/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.1570e-05 - val_loss: 8.1390e-05\n",
      "Epoch 908/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.1755e-05 - val_loss: 9.2164e-05\n",
      "Epoch 909/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.2397e-05 - val_loss: 1.3107e-04\n",
      "Epoch 910/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.1556e-05 - val_loss: 8.1239e-05\n",
      "Epoch 911/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 9.8083e-05 - val_loss: 2.2384e-04\n",
      "Epoch 912/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.5740e-05 - val_loss: 1.3915e-04\n",
      "Epoch 913/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.4925e-05 - val_loss: 8.2580e-05\n",
      "Epoch 914/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.7184e-05 - val_loss: 1.4093e-04\n",
      "Epoch 915/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.2767e-05 - val_loss: 8.8404e-05\n",
      "Epoch 916/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.2890e-05 - val_loss: 7.7710e-05\n",
      "Epoch 917/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1374e-04 - val_loss: 3.2588e-04\n",
      "Epoch 918/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 1.4279e-04 - val_loss: 1.3177e-04\n",
      "Epoch 919/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.2782e-04 - val_loss: 4.4219e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 920/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.6778e-04 - val_loss: 1.1252e-04\n",
      "Epoch 921/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.4225e-04 - val_loss: 1.6727e-04\n",
      "Epoch 922/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.1224e-04 - val_loss: 7.3270e-05\n",
      "Epoch 923/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1105e-04 - val_loss: 8.0425e-05\n",
      "Epoch 924/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.4594e-05 - val_loss: 1.7612e-04\n",
      "Epoch 925/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.4176e-05 - val_loss: 7.5059e-05\n",
      "Epoch 926/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.7955e-05 - val_loss: 1.2518e-04\n",
      "Epoch 927/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.5214e-05 - val_loss: 2.3573e-04\n",
      "Epoch 928/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 9.3664e-05 - val_loss: 1.2578e-04\n",
      "Epoch 929/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.3713e-05 - val_loss: 7.9265e-05\n",
      "Epoch 930/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.7174e-05 - val_loss: 7.8552e-05\n",
      "Epoch 931/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.0909e-05 - val_loss: 1.1708e-04\n",
      "Epoch 932/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2701e-04 - val_loss: 3.2448e-04\n",
      "Epoch 933/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.6591e-04 - val_loss: 7.3903e-05\n",
      "Epoch 934/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.1397e-05 - val_loss: 1.9531e-04\n",
      "Epoch 935/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.0296e-04 - val_loss: 1.5067e-04\n",
      "Epoch 936/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.4614e-05 - val_loss: 1.3121e-04\n",
      "Epoch 937/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.6118e-05 - val_loss: 7.2033e-05\n",
      "Epoch 938/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2394e-04 - val_loss: 1.3121e-04\n",
      "Epoch 939/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0460e-04 - val_loss: 2.6713e-04\n",
      "Epoch 940/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.8039e-04 - val_loss: 8.1664e-05\n",
      "Epoch 941/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.3084e-04 - val_loss: 9.3791e-05\n",
      "Epoch 942/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2084e-04 - val_loss: 9.2761e-05\n",
      "Epoch 943/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 1.6495e-04 - val_loss: 7.9477e-05\n",
      "Epoch 944/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.2881e-04 - val_loss: 1.1521e-04\n",
      "Epoch 945/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 9.9234e-05 - val_loss: 7.9361e-05\n",
      "Epoch 946/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.6658e-05 - val_loss: 1.0996e-04\n",
      "Epoch 947/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.3409e-05 - val_loss: 1.0117e-04\n",
      "Epoch 948/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.9220e-05 - val_loss: 1.8708e-04\n",
      "Epoch 949/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.5700e-05 - val_loss: 1.6495e-04\n",
      "Epoch 950/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.1055e-04 - val_loss: 1.1429e-04\n",
      "Epoch 951/2000\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 1.0246e-04 - val_loss: 1.2737e-04\n",
      "Epoch 952/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.2218e-04 - val_loss: 2.6013e-04\n",
      "Epoch 953/2000\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 1.0278e-04 - val_loss: 1.0005e-04\n",
      "Epoch 954/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.9943e-05 - val_loss: 9.5683e-05\n",
      "Epoch 955/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 9.7173e-05 - val_loss: 1.9529e-04\n",
      "Epoch 956/2000\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 8.7992e-05 - val_loss: 7.3286e-05\n",
      "Epoch 957/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.2525e-05 - val_loss: 1.3744e-04\n",
      "Epoch 958/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.5146e-05 - val_loss: 1.1014e-04\n",
      "Epoch 959/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.6638e-05 - val_loss: 9.3284e-05\n",
      "Epoch 960/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.7263e-05 - val_loss: 1.2633e-04\n",
      "Epoch 961/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.6159e-05 - val_loss: 1.9001e-04\n",
      "Epoch 962/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 1.5137e-04 - val_loss: 8.5499e-05\n",
      "Epoch 963/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.0562e-05 - val_loss: 8.1517e-05\n",
      "Epoch 964/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.4763e-05 - val_loss: 1.2605e-04\n",
      "Epoch 965/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.4033e-05 - val_loss: 1.2649e-04\n",
      "Epoch 966/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.1360e-05 - val_loss: 7.8993e-05\n",
      "Epoch 967/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.3968e-05 - val_loss: 1.0013e-04\n",
      "Epoch 968/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.5308e-05 - val_loss: 7.3350e-05\n",
      "Epoch 969/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.3591e-05 - val_loss: 7.8402e-05\n",
      "Epoch 970/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 1.0278e-04 - val_loss: 1.3649e-04\n",
      "Epoch 971/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 7.9246e-05 - val_loss: 1.3908e-04\n",
      "Epoch 972/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.6577e-05 - val_loss: 9.3345e-05\n",
      "Epoch 973/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.8774e-05 - val_loss: 9.0612e-05\n",
      "Epoch 974/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.8013e-05 - val_loss: 9.7095e-05\n",
      "Epoch 975/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.7850e-05 - val_loss: 1.0982e-04\n",
      "Epoch 976/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.2361e-05 - val_loss: 4.9127e-04\n",
      "Epoch 977/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.2326e-04 - val_loss: 7.8613e-05\n",
      "Epoch 978/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.5777e-05 - val_loss: 1.0097e-04\n",
      "Epoch 979/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.4859e-05 - val_loss: 7.5598e-05\n",
      "Epoch 980/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 8.3083e-05 - val_loss: 1.3944e-04\n",
      "Epoch 981/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.0894e-05 - val_loss: 7.8208e-05\n",
      "Epoch 982/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.5403e-05 - val_loss: 7.2358e-05\n",
      "Epoch 983/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.9840e-05 - val_loss: 1.1536e-04\n",
      "Epoch 984/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.3031e-05 - val_loss: 9.0673e-05\n",
      "Epoch 985/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.0885e-05 - val_loss: 7.7359e-05\n",
      "Epoch 986/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 7.8229e-05 - val_loss: 8.3603e-05\n",
      "Epoch 987/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.8215e-05 - val_loss: 1.1265e-04\n",
      "Epoch 988/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.7327e-05 - val_loss: 7.6969e-05\n",
      "Epoch 989/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 8.1931e-05 - val_loss: 3.2984e-04\n",
      "Epoch 990/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.3473e-04 - val_loss: 8.0095e-05\n",
      "Epoch 991/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.2590e-05 - val_loss: 1.0010e-04\n",
      "Epoch 992/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.2488e-05 - val_loss: 1.1453e-04\n",
      "Epoch 993/2000\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 8.1769e-05 - val_loss: 7.8078e-05\n",
      "Epoch 994/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.8613e-05 - val_loss: 8.6110e-05\n",
      "Epoch 995/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.0773e-05 - val_loss: 1.3844e-04\n",
      "Epoch 996/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.7642e-05 - val_loss: 9.9055e-05\n",
      "Epoch 997/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.0269e-05 - val_loss: 9.7473e-05\n",
      "Epoch 998/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 1.0661e-04 - val_loss: 1.3920e-04\n",
      "Epoch 999/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 9.5014e-05 - val_loss: 2.0017e-04\n",
      "Epoch 1000/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.5245e-05 - val_loss: 8.0721e-05\n",
      "Epoch 1001/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.9145e-05 - val_loss: 1.9706e-04\n",
      "Epoch 1002/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 1.0259e-04 - val_loss: 7.8063e-05\n",
      "Epoch 1003/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.6597e-05 - val_loss: 8.9601e-05\n",
      "Epoch 1004/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.5634e-05 - val_loss: 3.9581e-04\n",
      "Epoch 1005/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 1.2299e-04 - val_loss: 9.2122e-05\n",
      "Epoch 1006/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 9.8772e-05 - val_loss: 9.2600e-05\n",
      "Epoch 1007/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.3912e-05 - val_loss: 1.2106e-04\n",
      "Epoch 1008/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.0502e-05 - val_loss: 8.3861e-05\n",
      "Epoch 1009/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.1094e-05 - val_loss: 1.8243e-04\n",
      "Epoch 1010/2000\n",
      "3690/3690 [==============================] - 2s 543us/step - loss: 8.4061e-05 - val_loss: 8.3536e-05\n",
      "Epoch 1011/2000\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 7.4048e-05 - val_loss: 7.7953e-05\n",
      "Epoch 1012/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.2238e-05 - val_loss: 1.1674e-04\n",
      "Epoch 1013/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.8059e-05 - val_loss: 8.4347e-05\n",
      "Epoch 1014/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.6331e-05 - val_loss: 1.5979e-04\n",
      "Epoch 1015/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.4079e-05 - val_loss: 8.5793e-05\n",
      "Epoch 1016/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.5806e-05 - val_loss: 8.3383e-05\n",
      "Epoch 1017/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 9.8611e-05 - val_loss: 1.1870e-04\n",
      "Epoch 1018/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.9641e-05 - val_loss: 1.4663e-04\n",
      "Epoch 1019/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 1.0855e-04 - val_loss: 9.2634e-05\n",
      "Epoch 1020/2000\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 9.0417e-05 - val_loss: 1.8201e-04\n",
      "Epoch 1021/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.3259e-05 - val_loss: 9.8026e-05\n",
      "Epoch 1022/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.5472e-05 - val_loss: 1.0928e-04\n",
      "Epoch 1023/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.2780e-05 - val_loss: 8.9017e-05\n",
      "Epoch 1024/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.6947e-05 - val_loss: 1.8705e-04\n",
      "Epoch 1025/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.0485e-05 - val_loss: 7.6398e-05\n",
      "Epoch 1026/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.4438e-05 - val_loss: 8.6732e-05\n",
      "Epoch 1027/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.1965e-05 - val_loss: 7.5212e-05\n",
      "Epoch 1028/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.5113e-05 - val_loss: 1.1024e-04\n",
      "Epoch 1029/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 8.3458e-05 - val_loss: 8.9482e-05\n",
      "Epoch 1030/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1086e-04 - val_loss: 8.4980e-05\n",
      "Epoch 1031/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.0691e-04 - val_loss: 2.1815e-04\n",
      "Epoch 1032/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 1.1806e-04 - val_loss: 9.9931e-05\n",
      "Epoch 1033/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 9.7767e-05 - val_loss: 1.1539e-04\n",
      "Epoch 1034/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.1742e-05 - val_loss: 8.7170e-05\n",
      "Epoch 1035/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.8524e-05 - val_loss: 9.2245e-05\n",
      "Epoch 1036/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.3896e-05 - val_loss: 1.2704e-04\n",
      "Epoch 1037/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 8.8811e-05 - val_loss: 8.2910e-05\n",
      "Epoch 1038/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.0609e-05 - val_loss: 8.2002e-05\n",
      "Epoch 1039/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.2928e-05 - val_loss: 1.3378e-04\n",
      "Epoch 1040/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.6999e-05 - val_loss: 1.1700e-04\n",
      "Epoch 1041/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.3033e-05 - val_loss: 7.5592e-05\n",
      "Epoch 1042/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.6723e-05 - val_loss: 7.9831e-05\n",
      "Epoch 1043/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.0251e-05 - val_loss: 1.1697e-04\n",
      "Epoch 1044/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 7.8858e-05 - val_loss: 8.3281e-05\n",
      "Epoch 1045/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.4982e-05 - val_loss: 1.3709e-04\n",
      "Epoch 1046/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.1278e-05 - val_loss: 7.9136e-05\n",
      "Epoch 1047/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 8.4865e-05 - val_loss: 1.0593e-04\n",
      "Epoch 1048/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.8221e-05 - val_loss: 7.5350e-05\n",
      "Epoch 1049/2000\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 7.7444e-05 - val_loss: 1.0899e-04\n",
      "Epoch 1050/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.5874e-05 - val_loss: 8.3375e-05\n",
      "Epoch 1051/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.5569e-05 - val_loss: 1.0397e-04\n",
      "Epoch 1052/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 9.0954e-05 - val_loss: 7.2885e-05\n",
      "Epoch 1053/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.8216e-05 - val_loss: 8.5201e-05\n",
      "Epoch 1054/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.2578e-05 - val_loss: 7.6788e-05\n",
      "Epoch 1055/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.3510e-05 - val_loss: 8.0142e-05\n",
      "Epoch 1056/2000\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 7.3987e-05 - val_loss: 7.7786e-05\n",
      "Epoch 1057/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.3482e-05 - val_loss: 2.3568e-04\n",
      "Epoch 1058/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 8.7148e-05 - val_loss: 1.3571e-04\n",
      "Epoch 1059/2000\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 7.6530e-05 - val_loss: 1.1275e-04\n",
      "Epoch 1060/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.8753e-05 - val_loss: 1.4953e-04\n",
      "Epoch 1061/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 1.0493e-04 - val_loss: 1.3995e-04\n",
      "Epoch 1062/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.4128e-05 - val_loss: 1.3859e-04\n",
      "Epoch 1063/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 1.1885e-04 - val_loss: 9.2374e-05\n",
      "Epoch 1064/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.2695e-05 - val_loss: 9.2757e-05\n",
      "Epoch 1065/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.2512e-05 - val_loss: 8.1703e-05\n",
      "Epoch 1066/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.4674e-05 - val_loss: 1.7003e-04\n",
      "Epoch 1067/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 9.0953e-05 - val_loss: 7.7709e-05\n",
      "Epoch 1068/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0007e-04 - val_loss: 1.2209e-04\n",
      "Epoch 1069/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 1.3252e-04 - val_loss: 2.8877e-04\n",
      "Epoch 1070/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.9283e-05 - val_loss: 8.5590e-05\n",
      "Epoch 1071/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.8345e-05 - val_loss: 7.7370e-05\n",
      "Epoch 1072/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.9625e-05 - val_loss: 1.2066e-04\n",
      "Epoch 1073/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.0316e-05 - val_loss: 8.4844e-05\n",
      "Epoch 1074/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 8.8608e-05 - val_loss: 9.9862e-05\n",
      "Epoch 1075/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.1774e-05 - val_loss: 1.3888e-04\n",
      "Epoch 1076/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.4258e-05 - val_loss: 2.1277e-04\n",
      "Epoch 1077/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.4216e-05 - val_loss: 8.3733e-05\n",
      "Epoch 1078/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.0476e-05 - val_loss: 8.1769e-05\n",
      "Epoch 1079/2000\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 7.1046e-05 - val_loss: 8.0701e-05\n",
      "Epoch 1080/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.4802e-05 - val_loss: 8.5886e-05\n",
      "Epoch 1081/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.5628e-05 - val_loss: 7.7200e-05\n",
      "Epoch 1082/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.1879e-05 - val_loss: 7.5063e-05\n",
      "Epoch 1083/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.1006e-05 - val_loss: 1.0678e-04\n",
      "Epoch 1084/2000\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 7.6849e-05 - val_loss: 9.0501e-05\n",
      "Epoch 1085/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 8.1819e-05 - val_loss: 1.2825e-04\n",
      "Epoch 1086/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.1802e-05 - val_loss: 8.2741e-05\n",
      "Epoch 1087/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.0983e-05 - val_loss: 1.2919e-04\n",
      "Epoch 1088/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 9.3836e-05 - val_loss: 8.4335e-05\n",
      "Epoch 1089/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.6096e-05 - val_loss: 1.7814e-04\n",
      "Epoch 1090/2000\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 8.6950e-05 - val_loss: 1.0912e-04\n",
      "Epoch 1091/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 6.7611e-05 - val_loss: 9.4937e-05\n",
      "Epoch 1092/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.3064e-05 - val_loss: 8.8710e-05\n",
      "Epoch 1093/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.3983e-05 - val_loss: 1.0291e-04\n",
      "Epoch 1094/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 9.6919e-05 - val_loss: 1.1213e-04\n",
      "Epoch 1095/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 1.3639e-04 - val_loss: 1.5293e-04\n",
      "Epoch 1096/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 9.3271e-05 - val_loss: 1.2171e-04\n",
      "Epoch 1097/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.6363e-05 - val_loss: 1.8028e-04\n",
      "Epoch 1098/2000\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 7.9764e-05 - val_loss: 7.9026e-05\n",
      "Epoch 1099/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 8.4986e-05 - val_loss: 1.1947e-04\n",
      "Epoch 1100/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.6219e-05 - val_loss: 1.1542e-04\n",
      "Epoch 1101/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 9.0041e-05 - val_loss: 9.7469e-05\n",
      "Epoch 1102/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.7726e-05 - val_loss: 1.0311e-04\n",
      "Epoch 1103/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.2755e-05 - val_loss: 1.0130e-04\n",
      "Epoch 1104/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 7.8744e-05 - val_loss: 1.1970e-04\n",
      "Epoch 1105/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.2684e-05 - val_loss: 1.3912e-04\n",
      "Epoch 1106/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 8.3949e-05 - val_loss: 2.4325e-04\n",
      "Epoch 1107/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 1.2163e-04 - val_loss: 7.7110e-05\n",
      "Epoch 1108/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 9.2614e-05 - val_loss: 8.1872e-05\n",
      "Epoch 1109/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.3684e-05 - val_loss: 9.3249e-05\n",
      "Epoch 1110/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.3909e-05 - val_loss: 7.2334e-05\n",
      "Epoch 1111/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.0352e-05 - val_loss: 7.5618e-05\n",
      "Epoch 1112/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.1200e-05 - val_loss: 7.5625e-05\n",
      "Epoch 1113/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 6.8977e-05 - val_loss: 1.5927e-04\n",
      "Epoch 1114/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.5010e-05 - val_loss: 1.3975e-04\n",
      "Epoch 1115/2000\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 6.7707e-05 - val_loss: 8.3925e-05\n",
      "Epoch 1116/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.4623e-05 - val_loss: 7.7801e-05\n",
      "Epoch 1117/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.7176e-05 - val_loss: 8.0813e-05\n",
      "Epoch 1118/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 6.8022e-05 - val_loss: 1.5492e-04\n",
      "Epoch 1119/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 8.7244e-05 - val_loss: 1.2069e-04\n",
      "Epoch 1120/2000\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 9.5822e-05 - val_loss: 1.0240e-04\n",
      "Epoch 1121/2000\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 7.9261e-05 - val_loss: 1.2426e-04\n",
      "Epoch 1122/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.0968e-05 - val_loss: 7.9088e-05\n",
      "Epoch 1123/2000\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 7.7491e-05 - val_loss: 1.7742e-04\n",
      "Epoch 1124/2000\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 9.4194e-05 - val_loss: 1.0124e-04\n",
      "Epoch 1125/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.8171e-05 - val_loss: 1.0017e-04\n",
      "Epoch 1126/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 1.0068e-04 - val_loss: 1.8591e-04\n",
      "Epoch 1127/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.7452e-05 - val_loss: 3.0770e-04\n",
      "Epoch 1128/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.4369e-05 - val_loss: 7.9859e-05\n",
      "Epoch 1129/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.3828e-05 - val_loss: 7.9151e-05\n",
      "Epoch 1130/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.0922e-05 - val_loss: 2.2136e-04\n",
      "Epoch 1131/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 9.1355e-05 - val_loss: 2.3350e-04\n",
      "Epoch 1132/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 1.3968e-04 - val_loss: 9.5450e-05\n",
      "Epoch 1133/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.3871e-05 - val_loss: 9.1858e-05\n",
      "Epoch 1134/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.0509e-05 - val_loss: 7.7801e-05\n",
      "Epoch 1135/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.6334e-05 - val_loss: 2.0835e-04\n",
      "Epoch 1136/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.9276e-05 - val_loss: 1.0697e-04\n",
      "Epoch 1137/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.8642e-05 - val_loss: 1.0989e-04\n",
      "Epoch 1138/2000\n",
      "3690/3690 [==============================] - 2s 544us/step - loss: 7.8944e-05 - val_loss: 9.2302e-05\n",
      "Epoch 1139/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.6462e-05 - val_loss: 7.9390e-05\n",
      "Epoch 1140/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 8.0972e-05 - val_loss: 2.1132e-04\n",
      "Epoch 1141/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.4530e-05 - val_loss: 8.5513e-05\n",
      "Epoch 1142/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.6779e-05 - val_loss: 8.7670e-05\n",
      "Epoch 1143/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.5454e-05 - val_loss: 1.3061e-04\n",
      "Epoch 1144/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.1750e-05 - val_loss: 9.1449e-05\n",
      "Epoch 1145/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 6.9543e-05 - val_loss: 1.1970e-04\n",
      "Epoch 1146/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.0554e-05 - val_loss: 7.8104e-05\n",
      "Epoch 1147/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.3806e-05 - val_loss: 1.3341e-04\n",
      "Epoch 1148/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.7029e-05 - val_loss: 1.2605e-04\n",
      "Epoch 1149/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.9350e-05 - val_loss: 9.5573e-05\n",
      "Epoch 1150/2000\n",
      "3690/3690 [==============================] - 2s 546us/step - loss: 7.5728e-05 - val_loss: 8.2637e-05\n",
      "Epoch 1151/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.9172e-05 - val_loss: 1.3452e-04\n",
      "Epoch 1152/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 8.0136e-05 - val_loss: 1.9496e-04\n",
      "Epoch 1153/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.9193e-05 - val_loss: 1.2021e-04\n",
      "Epoch 1154/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.7075e-05 - val_loss: 8.8126e-05\n",
      "Epoch 1155/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.4129e-05 - val_loss: 1.0758e-04\n",
      "Epoch 1156/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.5451e-05 - val_loss: 9.6436e-05\n",
      "Epoch 1157/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.9044e-05 - val_loss: 1.0271e-04\n",
      "Epoch 1158/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 6.9765e-05 - val_loss: 2.2558e-04\n",
      "Epoch 1159/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.3417e-05 - val_loss: 9.2342e-05\n",
      "Epoch 1160/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.3440e-05 - val_loss: 8.9077e-05\n",
      "Epoch 1161/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.9912e-05 - val_loss: 1.5737e-04\n",
      "Epoch 1162/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 9.7414e-05 - val_loss: 1.6364e-04\n",
      "Epoch 1163/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 8.1908e-05 - val_loss: 8.2235e-05\n",
      "Epoch 1164/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.7343e-05 - val_loss: 2.0387e-04\n",
      "Epoch 1165/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.6521e-05 - val_loss: 1.0482e-04\n",
      "Epoch 1166/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.9875e-05 - val_loss: 1.2449e-04\n",
      "Epoch 1167/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0087e-04 - val_loss: 1.7836e-04\n",
      "Epoch 1168/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 9.8481e-05 - val_loss: 1.5726e-04\n",
      "Epoch 1169/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.0153e-04 - val_loss: 3.5414e-04\n",
      "Epoch 1170/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 1.0166e-04 - val_loss: 8.3586e-05\n",
      "Epoch 1171/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.5356e-05 - val_loss: 8.2314e-05\n",
      "Epoch 1172/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.2221e-05 - val_loss: 1.2003e-04\n",
      "Epoch 1173/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 8.1965e-05 - val_loss: 9.7014e-05\n",
      "Epoch 1174/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.5341e-05 - val_loss: 1.5381e-04\n",
      "Epoch 1175/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 8.9321e-05 - val_loss: 7.6641e-05\n",
      "Epoch 1176/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.1759e-05 - val_loss: 8.1271e-05\n",
      "Epoch 1177/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.1127e-05 - val_loss: 1.9044e-04\n",
      "Epoch 1178/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.7620e-05 - val_loss: 7.1406e-05\n",
      "Epoch 1179/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 7.6508e-05 - val_loss: 1.8009e-04\n",
      "Epoch 1180/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 9.8459e-05 - val_loss: 9.9137e-05\n",
      "Epoch 1181/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 8.3183e-05 - val_loss: 1.1401e-04\n",
      "Epoch 1182/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.0410e-05 - val_loss: 8.7537e-05\n",
      "Epoch 1183/2000\n",
      "3690/3690 [==============================] - 2s 545us/step - loss: 7.4901e-05 - val_loss: 7.7916e-05\n",
      "Epoch 1184/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 7.4066e-05 - val_loss: 8.2229e-05\n",
      "Epoch 1185/2000\n",
      "3690/3690 [==============================] - 2s 547us/step - loss: 7.9628e-05 - val_loss: 7.9036e-05\n",
      "Epoch 1186/2000\n",
      "3690/3690 [==============================] - 2s 548us/step - loss: 7.3797e-05 - val_loss: 7.8125e-05\n",
      "Epoch 1187/2000\n",
      "3690/3690 [==============================] - 2s 666us/step - loss: 6.6185e-05 - val_loss: 9.6945e-05\n",
      "Epoch 1188/2000\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 6.7724e-05 - val_loss: 8.6283e-05\n",
      "Epoch 1189/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 6.7491e-05 - val_loss: 2.4596e-04\n",
      "Epoch 1190/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 9.0991e-05 - val_loss: 1.3046e-04\n",
      "Epoch 1191/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 7.3914e-05 - val_loss: 1.5772e-04\n",
      "Epoch 1192/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 9.0811e-05 - val_loss: 9.7735e-05\n",
      "Epoch 1193/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 8.0735e-05 - val_loss: 1.2569e-04\n",
      "Epoch 1194/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.6324e-05 - val_loss: 8.8173e-05\n",
      "Epoch 1195/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 6.6221e-05 - val_loss: 9.3388e-05\n",
      "Epoch 1196/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 7.3488e-05 - val_loss: 1.1931e-04\n",
      "Epoch 1197/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 7.2088e-05 - val_loss: 1.0380e-04\n",
      "Epoch 1198/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 6.8528e-05 - val_loss: 9.8713e-05\n",
      "Epoch 1199/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 8.0979e-05 - val_loss: 1.6679e-04\n",
      "Epoch 1200/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.1373e-05 - val_loss: 1.4379e-04\n",
      "Epoch 1201/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.7825e-05 - val_loss: 8.6851e-05\n",
      "Epoch 1202/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.8399e-05 - val_loss: 9.7539e-05\n",
      "Epoch 1203/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 8.0311e-05 - val_loss: 1.4151e-04\n",
      "Epoch 1204/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.2640e-05 - val_loss: 1.7538e-04\n",
      "Epoch 1205/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.7111e-05 - val_loss: 8.6110e-05\n",
      "Epoch 1206/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 7.1414e-05 - val_loss: 1.2771e-04\n",
      "Epoch 1207/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.3167e-05 - val_loss: 9.9679e-05\n",
      "Epoch 1208/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.9669e-05 - val_loss: 1.5762e-04\n",
      "Epoch 1209/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 9.8969e-05 - val_loss: 1.5579e-04\n",
      "Epoch 1210/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 8.5774e-05 - val_loss: 2.2922e-04\n",
      "Epoch 1211/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 8.2260e-05 - val_loss: 8.7971e-05\n",
      "Epoch 1212/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 7.3542e-05 - val_loss: 1.1461e-04\n",
      "Epoch 1213/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.7361e-05 - val_loss: 1.0587e-04\n",
      "Epoch 1214/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.6856e-05 - val_loss: 1.0183e-04\n",
      "Epoch 1215/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.7913e-05 - val_loss: 1.0311e-04\n",
      "Epoch 1216/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.6117e-05 - val_loss: 1.0612e-04\n",
      "Epoch 1217/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 6.5801e-05 - val_loss: 8.8961e-05\n",
      "Epoch 1218/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.8636e-05 - val_loss: 8.4973e-05\n",
      "Epoch 1219/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 9.9593e-05 - val_loss: 1.8027e-04\n",
      "Epoch 1220/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.4518e-05 - val_loss: 1.5620e-04\n",
      "Epoch 1221/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.0005e-04 - val_loss: 1.2160e-04\n",
      "Epoch 1222/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.2638e-05 - val_loss: 1.3949e-04\n",
      "Epoch 1223/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.4387e-05 - val_loss: 1.5256e-04\n",
      "Epoch 1224/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.7150e-05 - val_loss: 8.8347e-05\n",
      "Epoch 1225/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.0129e-05 - val_loss: 8.0024e-05\n",
      "Epoch 1226/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.4901e-05 - val_loss: 9.5225e-05\n",
      "Epoch 1227/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.8125e-05 - val_loss: 9.5950e-05\n",
      "Epoch 1228/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.1855e-05 - val_loss: 1.5560e-04\n",
      "Epoch 1229/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.3344e-05 - val_loss: 1.8744e-04\n",
      "Epoch 1230/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 8.4114e-05 - val_loss: 1.1013e-04\n",
      "Epoch 1231/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.9284e-05 - val_loss: 1.9808e-04\n",
      "Epoch 1232/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 8.0204e-05 - val_loss: 1.8067e-04\n",
      "Epoch 1233/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.0178e-05 - val_loss: 2.1597e-04\n",
      "Epoch 1234/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.8851e-05 - val_loss: 8.5640e-05\n",
      "Epoch 1235/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.5276e-05 - val_loss: 1.5007e-04\n",
      "Epoch 1236/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.8846e-05 - val_loss: 8.0546e-05\n",
      "Epoch 1237/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.7310e-05 - val_loss: 9.5050e-05\n",
      "Epoch 1238/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.4817e-05 - val_loss: 9.0261e-05\n",
      "Epoch 1239/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.8124e-05 - val_loss: 1.1952e-04\n",
      "Epoch 1240/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.7932e-05 - val_loss: 7.6345e-05\n",
      "Epoch 1241/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.8506e-05 - val_loss: 1.0274e-04\n",
      "Epoch 1242/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 8.7122e-05 - val_loss: 1.8273e-04\n",
      "Epoch 1243/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.5743e-05 - val_loss: 9.6485e-05\n",
      "Epoch 1244/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 7.4029e-05 - val_loss: 1.3697e-04\n",
      "Epoch 1245/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 8.1168e-05 - val_loss: 1.3575e-04\n",
      "Epoch 1246/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.1435e-04 - val_loss: 9.5778e-05\n",
      "Epoch 1247/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.5454e-05 - val_loss: 3.2826e-04\n",
      "Epoch 1248/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.9709e-05 - val_loss: 1.0656e-04\n",
      "Epoch 1249/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.9931e-05 - val_loss: 7.7794e-05\n",
      "Epoch 1250/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.0204e-04 - val_loss: 7.7722e-05\n",
      "Epoch 1251/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.2504e-05 - val_loss: 1.7959e-04\n",
      "Epoch 1252/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 9.3652e-05 - val_loss: 9.2782e-05\n",
      "Epoch 1253/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.5577e-05 - val_loss: 9.3619e-05\n",
      "Epoch 1254/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.2967e-05 - val_loss: 1.1028e-04\n",
      "Epoch 1255/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.8690e-05 - val_loss: 8.7686e-05\n",
      "Epoch 1256/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 7.9835e-05 - val_loss: 9.4056e-05\n",
      "Epoch 1257/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.5154e-05 - val_loss: 9.8041e-05\n",
      "Epoch 1258/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.4633e-05 - val_loss: 1.3235e-04\n",
      "Epoch 1259/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.5078e-05 - val_loss: 1.2837e-04\n",
      "Epoch 1260/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 1.1529e-04 - val_loss: 1.1945e-04\n",
      "Epoch 1261/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.0652e-04 - val_loss: 2.4546e-04\n",
      "Epoch 1262/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.5108e-05 - val_loss: 8.1927e-05\n",
      "Epoch 1263/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.9480e-05 - val_loss: 8.7314e-05\n",
      "Epoch 1264/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.9639e-05 - val_loss: 8.0803e-05\n",
      "Epoch 1265/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.5425e-05 - val_loss: 9.7908e-05\n",
      "Epoch 1266/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.9785e-05 - val_loss: 1.8162e-04\n",
      "Epoch 1267/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.7137e-05 - val_loss: 1.2754e-04\n",
      "Epoch 1268/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.5442e-05 - val_loss: 1.0791e-04\n",
      "Epoch 1269/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.5126e-05 - val_loss: 8.9404e-05\n",
      "Epoch 1270/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.5489e-05 - val_loss: 1.5787e-04\n",
      "Epoch 1271/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.8813e-05 - val_loss: 1.0733e-04\n",
      "Epoch 1272/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.4107e-05 - val_loss: 1.4625e-04\n",
      "Epoch 1273/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.0626e-05 - val_loss: 7.8477e-05\n",
      "Epoch 1274/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.4029e-05 - val_loss: 7.6970e-05\n",
      "Epoch 1275/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.6555e-05 - val_loss: 2.4364e-04\n",
      "Epoch 1276/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.0215e-05 - val_loss: 1.2407e-04\n",
      "Epoch 1277/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.8683e-05 - val_loss: 8.2712e-05\n",
      "Epoch 1278/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.6414e-05 - val_loss: 1.1160e-04\n",
      "Epoch 1279/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.7468e-05 - val_loss: 1.0615e-04\n",
      "Epoch 1280/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.4979e-05 - val_loss: 8.6039e-05\n",
      "Epoch 1281/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.0678e-05 - val_loss: 1.9989e-04\n",
      "Epoch 1282/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.3126e-05 - val_loss: 1.3621e-04\n",
      "Epoch 1283/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.6244e-05 - val_loss: 9.6771e-05\n",
      "Epoch 1284/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.1490e-05 - val_loss: 2.3252e-04\n",
      "Epoch 1285/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.1861e-05 - val_loss: 9.3389e-05\n",
      "Epoch 1286/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.1938e-05 - val_loss: 9.4135e-05\n",
      "Epoch 1287/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.0958e-05 - val_loss: 1.4556e-04\n",
      "Epoch 1288/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.0137e-05 - val_loss: 9.2650e-05\n",
      "Epoch 1289/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.1433e-05 - val_loss: 1.0284e-04\n",
      "Epoch 1290/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.1626e-05 - val_loss: 1.3808e-04\n",
      "Epoch 1291/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.5487e-05 - val_loss: 1.1032e-04\n",
      "Epoch 1292/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.8776e-05 - val_loss: 7.9147e-05\n",
      "Epoch 1293/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.3981e-05 - val_loss: 8.6608e-05\n",
      "Epoch 1294/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.6300e-05 - val_loss: 2.5210e-04\n",
      "Epoch 1295/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.9131e-05 - val_loss: 9.2439e-05\n",
      "Epoch 1296/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.6399e-05 - val_loss: 8.6882e-05\n",
      "Epoch 1297/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.8486e-05 - val_loss: 2.1891e-04\n",
      "Epoch 1298/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.6712e-05 - val_loss: 1.3358e-04\n",
      "Epoch 1299/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 6.7051e-05 - val_loss: 1.1351e-04\n",
      "Epoch 1300/2000\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 7.5777e-05 - val_loss: 1.0549e-04\n",
      "Epoch 1301/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.8472e-05 - val_loss: 1.0317e-04\n",
      "Epoch 1302/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 6.4864e-05 - val_loss: 1.5981e-04\n",
      "Epoch 1303/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 6.8354e-05 - val_loss: 9.5346e-05\n",
      "Epoch 1304/2000\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 7.5750e-05 - val_loss: 8.7025e-05\n",
      "Epoch 1305/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 7.4395e-05 - val_loss: 1.9829e-04\n",
      "Epoch 1306/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 1.1889e-04 - val_loss: 1.2510e-04\n",
      "Epoch 1307/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.6666e-05 - val_loss: 1.4021e-04\n",
      "Epoch 1308/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.8689e-05 - val_loss: 8.6056e-05\n",
      "Epoch 1309/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 8.8366e-05 - val_loss: 3.6662e-04\n",
      "Epoch 1310/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 9.1977e-05 - val_loss: 7.9622e-05\n",
      "Epoch 1311/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.0430e-05 - val_loss: 1.2947e-04\n",
      "Epoch 1312/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.7090e-05 - val_loss: 1.0431e-04\n",
      "Epoch 1313/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.4461e-05 - val_loss: 1.6125e-04\n",
      "Epoch 1314/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.8215e-05 - val_loss: 9.2272e-05\n",
      "Epoch 1315/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.0278e-05 - val_loss: 3.2934e-04\n",
      "Epoch 1316/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 1.0948e-04 - val_loss: 1.3681e-04\n",
      "Epoch 1317/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 1.1592e-04 - val_loss: 8.9343e-05\n",
      "Epoch 1318/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.3715e-05 - val_loss: 1.2174e-04\n",
      "Epoch 1319/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.0738e-05 - val_loss: 1.6560e-04\n",
      "Epoch 1320/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.2441e-05 - val_loss: 8.7768e-05\n",
      "Epoch 1321/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.7394e-05 - val_loss: 1.6436e-04\n",
      "Epoch 1322/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 9.8592e-05 - val_loss: 1.1408e-04\n",
      "Epoch 1323/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 1.1117e-04 - val_loss: 8.3073e-05\n",
      "Epoch 1324/2000\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 8.0687e-05 - val_loss: 1.7554e-04\n",
      "Epoch 1325/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.1697e-05 - val_loss: 9.5480e-05\n",
      "Epoch 1326/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.1073e-05 - val_loss: 9.5137e-05\n",
      "Epoch 1327/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.4287e-05 - val_loss: 1.4872e-04\n",
      "Epoch 1328/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 6.2251e-05 - val_loss: 8.0831e-05\n",
      "Epoch 1329/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.8759e-05 - val_loss: 1.5422e-04\n",
      "Epoch 1330/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.7256e-05 - val_loss: 1.3898e-04\n",
      "Epoch 1331/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.7219e-05 - val_loss: 8.7355e-05\n",
      "Epoch 1332/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.7897e-05 - val_loss: 1.8581e-04\n",
      "Epoch 1333/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.5759e-05 - val_loss: 9.8599e-05\n",
      "Epoch 1334/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.2317e-05 - val_loss: 1.3243e-04\n",
      "Epoch 1335/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.9129e-05 - val_loss: 1.2302e-04\n",
      "Epoch 1336/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.5108e-05 - val_loss: 1.1301e-04\n",
      "Epoch 1337/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 9.3515e-05 - val_loss: 2.1500e-04\n",
      "Epoch 1338/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.3443e-05 - val_loss: 7.8373e-05\n",
      "Epoch 1339/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.4068e-05 - val_loss: 1.6123e-04\n",
      "Epoch 1340/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.9645e-05 - val_loss: 9.0946e-05\n",
      "Epoch 1341/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 6.6406e-05 - val_loss: 1.1540e-04\n",
      "Epoch 1342/2000\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 6.1496e-05 - val_loss: 9.6194e-05\n",
      "Epoch 1343/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 6.8558e-05 - val_loss: 9.9975e-05\n",
      "Epoch 1344/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 6.8220e-05 - val_loss: 1.0467e-04\n",
      "Epoch 1345/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.2252e-05 - val_loss: 3.0295e-04\n",
      "Epoch 1346/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.8615e-05 - val_loss: 9.6933e-05\n",
      "Epoch 1347/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.9573e-05 - val_loss: 1.7492e-04\n",
      "Epoch 1348/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 1.0012e-04 - val_loss: 1.3694e-04\n",
      "Epoch 1349/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 9.3401e-05 - val_loss: 1.0330e-04\n",
      "Epoch 1350/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 6.9742e-05 - val_loss: 8.0461e-05\n",
      "Epoch 1351/2000\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: 6.4395e-05 - val_loss: 7.5743e-05\n",
      "Epoch 1352/2000\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 6.6038e-05 - val_loss: 8.3609e-05\n",
      "Epoch 1353/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 6.3769e-05 - val_loss: 1.4749e-04\n",
      "Epoch 1354/2000\n",
      "3690/3690 [==============================] - 3s 775us/step - loss: 6.7902e-05 - val_loss: 9.8056e-05\n",
      "Epoch 1355/2000\n",
      "3690/3690 [==============================] - 3s 820us/step - loss: 7.8056e-05 - val_loss: 1.0409e-04\n",
      "Epoch 1356/2000\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 7.0199e-05 - val_loss: 1.2877e-04\n",
      "Epoch 1357/2000\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 6.6132e-05 - val_loss: 9.0433e-05\n",
      "Epoch 1358/2000\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 6.9286e-05 - val_loss: 1.4298e-04\n",
      "Epoch 1359/2000\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 6.3225e-05 - val_loss: 1.0387e-04\n",
      "Epoch 1360/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 6.1514e-05 - val_loss: 9.2146e-05\n",
      "Epoch 1361/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 6.5553e-05 - val_loss: 1.0594e-04\n",
      "Epoch 1362/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 8.2886e-05 - val_loss: 1.1706e-04\n",
      "Epoch 1363/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 7.7623e-05 - val_loss: 1.2455e-04\n",
      "Epoch 1364/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 7.4197e-05 - val_loss: 8.7770e-05\n",
      "Epoch 1365/2000\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 7.0937e-05 - val_loss: 1.2975e-04\n",
      "Epoch 1366/2000\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 6.5181e-05 - val_loss: 1.2910e-04\n",
      "Epoch 1367/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 7.0470e-05 - val_loss: 8.3653e-05\n",
      "Epoch 1368/2000\n",
      "3690/3690 [==============================] - 2s 620us/step - loss: 7.6976e-05 - val_loss: 1.1377e-04\n",
      "Epoch 1369/2000\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 1.0362e-04 - val_loss: 2.1772e-04\n",
      "Epoch 1370/2000\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 7.8279e-05 - val_loss: 8.5551e-05\n",
      "Epoch 1371/2000\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 7.2287e-05 - val_loss: 9.6245e-05\n",
      "Epoch 1372/2000\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 7.0503e-05 - val_loss: 9.3043e-05\n",
      "Epoch 1373/2000\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 7.0788e-05 - val_loss: 1.7810e-04\n",
      "Epoch 1374/2000\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 6.3947e-05 - val_loss: 8.6856e-05\n",
      "Epoch 1375/2000\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 6.5533e-05 - val_loss: 1.0296e-04\n",
      "Epoch 1376/2000\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 6.8759e-05 - val_loss: 1.9690e-04\n",
      "Epoch 1377/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 7.3762e-05 - val_loss: 1.0199e-04\n",
      "Epoch 1378/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 7.4888e-05 - val_loss: 1.1746e-04\n",
      "Epoch 1379/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 6.7229e-05 - val_loss: 3.9323e-04\n",
      "Epoch 1380/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 7.7097e-05 - val_loss: 9.1482e-05\n",
      "Epoch 1381/2000\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 6.4493e-05 - val_loss: 9.7748e-05\n",
      "Epoch 1382/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 6.5028e-05 - val_loss: 1.6384e-04\n",
      "Epoch 1383/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.4541e-05 - val_loss: 9.1712e-05\n",
      "Epoch 1384/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.8035e-05 - val_loss: 1.1775e-04\n",
      "Epoch 1385/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 7.4477e-05 - val_loss: 1.7022e-04\n",
      "Epoch 1386/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.2032e-05 - val_loss: 3.3844e-04\n",
      "Epoch 1387/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.3572e-05 - val_loss: 9.7063e-05\n",
      "Epoch 1388/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 8.7549e-05 - val_loss: 9.5789e-05\n",
      "Epoch 1389/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.0734e-05 - val_loss: 1.1131e-04\n",
      "Epoch 1390/2000\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 6.8336e-05 - val_loss: 1.3166e-04\n",
      "Epoch 1391/2000\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 6.2530e-05 - val_loss: 1.5656e-04\n",
      "Epoch 1392/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 6.4992e-05 - val_loss: 1.1564e-04\n",
      "Epoch 1393/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.0033e-05 - val_loss: 1.6061e-04\n",
      "Epoch 1394/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.7523e-05 - val_loss: 1.2152e-04\n",
      "Epoch 1395/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.3468e-05 - val_loss: 1.6515e-04\n",
      "Epoch 1396/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.0850e-05 - val_loss: 8.5303e-05\n",
      "Epoch 1397/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 6.8927e-05 - val_loss: 1.1101e-04\n",
      "Epoch 1398/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 7.4152e-05 - val_loss: 1.3836e-04\n",
      "Epoch 1399/2000\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 7.0308e-05 - val_loss: 1.2738e-04\n",
      "Epoch 1400/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 7.1012e-05 - val_loss: 2.0051e-04\n",
      "Epoch 1401/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 6.9066e-05 - val_loss: 2.1393e-04\n",
      "Epoch 1402/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.7194e-05 - val_loss: 9.3070e-05\n",
      "Epoch 1403/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.8081e-05 - val_loss: 1.0538e-04\n",
      "Epoch 1404/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.4171e-05 - val_loss: 4.1244e-04\n",
      "Epoch 1405/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 8.2758e-05 - val_loss: 9.4077e-05\n",
      "Epoch 1406/2000\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 7.8853e-05 - val_loss: 1.0681e-04\n",
      "Epoch 1407/2000\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 6.5860e-05 - val_loss: 1.1652e-04\n",
      "Epoch 1408/2000\n",
      "3690/3690 [==============================] - 2s 600us/step - loss: 6.6073e-05 - val_loss: 1.2247e-04\n",
      "Epoch 1409/2000\n",
      "3690/3690 [==============================] - 2s 640us/step - loss: 6.7710e-05 - val_loss: 1.0633e-04\n",
      "Epoch 1410/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 641us/step - loss: 6.5532e-05 - val_loss: 1.6011e-04\n",
      "Epoch 1411/2000\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 7.4968e-05 - val_loss: 1.5463e-04\n",
      "Epoch 1412/2000\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: 7.5868e-05 - val_loss: 1.5138e-04\n",
      "Epoch 1413/2000\n",
      "3690/3690 [==============================] - 2s 593us/step - loss: 8.5954e-05 - val_loss: 1.0862e-04\n",
      "Epoch 1414/2000\n",
      "3690/3690 [==============================] - 2s 594us/step - loss: 8.8972e-05 - val_loss: 1.6384e-04\n",
      "Epoch 1415/2000\n",
      "3690/3690 [==============================] - 2s 588us/step - loss: 7.1575e-05 - val_loss: 9.2679e-05\n",
      "Epoch 1416/2000\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 6.3450e-05 - val_loss: 2.0523e-04\n",
      "Epoch 1417/2000\n",
      "3690/3690 [==============================] - 2s 604us/step - loss: 8.7649e-05 - val_loss: 1.3259e-04\n",
      "Epoch 1418/2000\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 1.1577e-04 - val_loss: 1.1139e-04\n",
      "Epoch 1419/2000\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 1.0236e-04 - val_loss: 3.2048e-04\n",
      "Epoch 1420/2000\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.2732e-05 - val_loss: 1.3967e-04\n",
      "Epoch 1421/2000\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 9.5735e-05 - val_loss: 1.7321e-04\n",
      "Epoch 1422/2000\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 8.1221e-05 - val_loss: 1.0427e-04\n",
      "Epoch 1423/2000\n",
      "3690/3690 [==============================] - 2s 614us/step - loss: 7.9779e-05 - val_loss: 2.1761e-04\n",
      "Epoch 1424/2000\n",
      "3690/3690 [==============================] - 2s 601us/step - loss: 7.2491e-05 - val_loss: 1.0878e-04\n",
      "Epoch 1425/2000\n",
      "3690/3690 [==============================] - 2s 598us/step - loss: 7.7501e-05 - val_loss: 9.7496e-05\n",
      "Epoch 1426/2000\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 7.2305e-05 - val_loss: 8.8251e-05\n",
      "Epoch 1427/2000\n",
      "3690/3690 [==============================] - 2s 616us/step - loss: 7.3451e-05 - val_loss: 1.1904e-04\n",
      "Epoch 1428/2000\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 6.4088e-05 - val_loss: 1.5923e-04\n",
      "Epoch 1429/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 6.7841e-05 - val_loss: 1.0079e-04\n",
      "Epoch 1430/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 6.5885e-05 - val_loss: 1.5997e-04\n",
      "Epoch 1431/2000\n",
      "3690/3690 [==============================] - 2s 600us/step - loss: 6.8691e-05 - val_loss: 1.5176e-04\n",
      "Epoch 1432/2000\n",
      "3690/3690 [==============================] - 2s 598us/step - loss: 7.2565e-05 - val_loss: 1.5686e-04\n",
      "Epoch 1433/2000\n",
      "3690/3690 [==============================] - 2s 598us/step - loss: 9.4362e-05 - val_loss: 2.3255e-04\n",
      "Epoch 1434/2000\n",
      "3690/3690 [==============================] - 2s 596us/step - loss: 7.7338e-05 - val_loss: 1.5302e-04\n",
      "Epoch 1435/2000\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: 7.0189e-05 - val_loss: 1.0351e-04\n",
      "Epoch 1436/2000\n",
      "3690/3690 [==============================] - 2s 675us/step - loss: 6.8278e-05 - val_loss: 1.5837e-04\n",
      "Epoch 1437/2000\n",
      "3690/3690 [==============================] - 2s 605us/step - loss: 6.3084e-05 - val_loss: 1.0129e-04\n",
      "Epoch 1438/2000\n",
      "3690/3690 [==============================] - 2s 593us/step - loss: 6.7874e-05 - val_loss: 2.2680e-04\n",
      "Epoch 1439/2000\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 7.4190e-05 - val_loss: 1.0308e-04\n",
      "Epoch 1440/2000\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 1.0027e-04 - val_loss: 1.1676e-04\n",
      "Epoch 1441/2000\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 1.0903e-04 - val_loss: 1.6247e-04\n",
      "Epoch 1442/2000\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 1.1233e-04 - val_loss: 1.2330e-04\n",
      "Epoch 1443/2000\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 8.2742e-05 - val_loss: 2.5884e-04\n",
      "Epoch 1444/2000\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 7.5320e-05 - val_loss: 1.8034e-04\n",
      "Epoch 1445/2000\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 9.3374e-05 - val_loss: 2.4859e-04\n",
      "Epoch 1446/2000\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 6.4347e-05 - val_loss: 1.3243e-04\n",
      "Epoch 1447/2000\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 6.9228e-05 - val_loss: 9.6600e-05\n",
      "Epoch 1448/2000\n",
      "3690/3690 [==============================] - 2s 616us/step - loss: 7.2269e-05 - val_loss: 1.0669e-04\n",
      "Epoch 1449/2000\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 8.5231e-05 - val_loss: 1.9307e-04\n",
      "Epoch 1450/2000\n",
      "3690/3690 [==============================] - 2s 626us/step - loss: 1.4120e-04 - val_loss: 1.3040e-04\n",
      "Epoch 1451/2000\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 1.2963e-04 - val_loss: 1.2022e-04\n",
      "Epoch 1452/2000\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 6.8114e-05 - val_loss: 1.4750e-04\n",
      "Epoch 1453/2000\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 6.7163e-05 - val_loss: 1.1774e-04\n",
      "Epoch 1454/2000\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 6.0939e-05 - val_loss: 1.6150e-04\n",
      "Epoch 1455/2000\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 6.4172e-05 - val_loss: 1.0170e-04\n",
      "Epoch 1456/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 7.8208e-05 - val_loss: 2.4865e-04\n",
      "Epoch 1457/2000\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 8.7427e-05 - val_loss: 1.1809e-04\n",
      "Epoch 1458/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 7.0213e-05 - val_loss: 1.8130e-04\n",
      "Epoch 1459/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 6.2443e-05 - val_loss: 1.0775e-04\n",
      "Epoch 1460/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 6.6763e-05 - val_loss: 9.7561e-05\n",
      "Epoch 1461/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 6.5548e-05 - val_loss: 3.6859e-04\n",
      "Epoch 1462/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 9.7887e-05 - val_loss: 1.2430e-04\n",
      "Epoch 1463/2000\n",
      "3690/3690 [==============================] - 2s 583us/step - loss: 8.6285e-05 - val_loss: 1.8327e-04\n",
      "Epoch 1464/2000\n",
      "3690/3690 [==============================] - 2s 615us/step - loss: 6.8839e-05 - val_loss: 1.1917e-04\n",
      "Epoch 1465/2000\n",
      "3690/3690 [==============================] - 2s 622us/step - loss: 7.4908e-05 - val_loss: 1.7902e-04\n",
      "Epoch 1466/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 7.2861e-05 - val_loss: 1.5682e-04\n",
      "Epoch 1467/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 6.4987e-05 - val_loss: 1.9625e-04\n",
      "Epoch 1468/2000\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 6.0464e-05 - val_loss: 1.2672e-04\n",
      "Epoch 1469/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 5.8208e-05 - val_loss: 1.2724e-04\n",
      "Epoch 1470/2000\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 6.0201e-05 - val_loss: 1.2406e-04\n",
      "Epoch 1471/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 6.4171e-05 - val_loss: 1.1000e-04\n",
      "Epoch 1472/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 7.7639e-05 - val_loss: 2.5582e-04\n",
      "Epoch 1473/2000\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 8.1789e-05 - val_loss: 1.6195e-04\n",
      "Epoch 1474/2000\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 7.5785e-05 - val_loss: 2.1753e-04\n",
      "Epoch 1475/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 6.7512e-05 - val_loss: 8.9643e-05\n",
      "Epoch 1476/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 6.6176e-05 - val_loss: 1.3552e-04\n",
      "Epoch 1477/2000\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 5.9881e-05 - val_loss: 1.9034e-04\n",
      "Epoch 1478/2000\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 6.5155e-05 - val_loss: 9.3962e-05\n",
      "Epoch 1479/2000\n",
      "3690/3690 [==============================] - 2s 613us/step - loss: 7.4864e-05 - val_loss: 1.1579e-04\n",
      "Epoch 1480/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 617us/step - loss: 6.7426e-05 - val_loss: 3.5438e-04\n",
      "Epoch 1481/2000\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 7.1577e-05 - val_loss: 1.1685e-04\n",
      "Epoch 1482/2000\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 6.7513e-05 - val_loss: 1.4165e-04\n",
      "Epoch 1483/2000\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 6.4105e-05 - val_loss: 2.1865e-04\n",
      "Epoch 1484/2000\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 6.2532e-05 - val_loss: 9.5172e-05\n",
      "Epoch 1485/2000\n",
      "3690/3690 [==============================] - 2s 586us/step - loss: 6.6311e-05 - val_loss: 1.1086e-04\n",
      "Epoch 1486/2000\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 6.5565e-05 - val_loss: 1.2651e-04\n",
      "Epoch 1487/2000\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 6.8848e-05 - val_loss: 2.2842e-04\n",
      "Epoch 1488/2000\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 7.2811e-05 - val_loss: 1.4372e-04\n",
      "Epoch 1489/2000\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 8.3377e-05 - val_loss: 3.1979e-04\n",
      "Epoch 1490/2000\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: 6.9855e-05 - val_loss: 1.1209e-04\n",
      "Epoch 1491/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 7.0475e-05 - val_loss: 3.5202e-04\n",
      "Epoch 1492/2000\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 7.1279e-05 - val_loss: 9.1698e-05\n",
      "Epoch 1493/2000\n",
      "3690/3690 [==============================] - 2s 600us/step - loss: 6.4308e-05 - val_loss: 1.7348e-04\n",
      "Epoch 1494/2000\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 7.6762e-05 - val_loss: 1.8322e-04\n",
      "Epoch 1495/2000\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 7.9396e-05 - val_loss: 1.2092e-04\n",
      "Epoch 1496/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 7.6021e-05 - val_loss: 1.0626e-04\n",
      "Epoch 1497/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 7.4308e-05 - val_loss: 1.4528e-04\n",
      "Epoch 1498/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 6.4272e-05 - val_loss: 1.4578e-04\n",
      "Epoch 1499/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 6.7854e-05 - val_loss: 1.2100e-04\n",
      "Epoch 1500/2000\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 7.1156e-05 - val_loss: 2.5276e-04\n",
      "Epoch 1501/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.6623e-05 - val_loss: 1.5212e-04\n",
      "Epoch 1502/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 6.3648e-05 - val_loss: 1.5421e-04\n",
      "Epoch 1503/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 6.5484e-05 - val_loss: 1.1863e-04\n",
      "Epoch 1504/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 8.9571e-05 - val_loss: 3.3554e-04\n",
      "Epoch 1505/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 8.8730e-05 - val_loss: 9.8061e-05\n",
      "Epoch 1506/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 7.4991e-05 - val_loss: 4.0632e-04\n",
      "Epoch 1507/2000\n",
      "3690/3690 [==============================] - 2s 606us/step - loss: 1.1730e-04 - val_loss: 1.3051e-04\n",
      "Epoch 1508/2000\n",
      "3690/3690 [==============================] - 2s 612us/step - loss: 1.2008e-04 - val_loss: 4.3117e-04\n",
      "Epoch 1509/2000\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 8.7466e-05 - val_loss: 1.4173e-04\n",
      "Epoch 1510/2000\n",
      "3690/3690 [==============================] - 2s 591us/step - loss: 8.6176e-05 - val_loss: 1.7382e-04\n",
      "Epoch 1511/2000\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 6.9679e-05 - val_loss: 3.5341e-04\n",
      "Epoch 1512/2000\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 9.7363e-05 - val_loss: 1.3515e-04\n",
      "Epoch 1513/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 8.2105e-05 - val_loss: 1.3858e-04\n",
      "Epoch 1514/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 6.8578e-05 - val_loss: 1.0786e-04\n",
      "Epoch 1515/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 6.8376e-05 - val_loss: 1.1193e-04\n",
      "Epoch 1516/2000\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 6.5930e-05 - val_loss: 1.3025e-04\n",
      "Epoch 1517/2000\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 6.4985e-05 - val_loss: 1.1430e-04\n",
      "Epoch 1518/2000\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 6.8442e-05 - val_loss: 2.4182e-04\n",
      "Epoch 1519/2000\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 6.9942e-05 - val_loss: 1.5563e-04\n",
      "Epoch 1520/2000\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 6.4224e-05 - val_loss: 1.3070e-04\n",
      "Epoch 1521/2000\n",
      "3690/3690 [==============================] - 2s 607us/step - loss: 6.1852e-05 - val_loss: 1.4452e-04\n",
      "Epoch 1522/2000\n",
      "3690/3690 [==============================] - 2s 616us/step - loss: 6.4812e-05 - val_loss: 1.5312e-04\n",
      "Epoch 1523/2000\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: 6.6740e-05 - val_loss: 4.9311e-04\n",
      "Epoch 1524/2000\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 7.7944e-05 - val_loss: 1.1475e-04\n",
      "Epoch 1525/2000\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 7.6448e-05 - val_loss: 1.1982e-04\n",
      "Epoch 1526/2000\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 6.2772e-05 - val_loss: 1.3970e-04\n",
      "Epoch 1527/2000\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 6.8170e-05 - val_loss: 1.6684e-04\n",
      "Epoch 1528/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 6.2756e-05 - val_loss: 1.4840e-04\n",
      "Epoch 1529/2000\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 6.1762e-05 - val_loss: 1.4603e-04\n",
      "Epoch 1530/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 6.3468e-05 - val_loss: 1.8331e-04\n",
      "Epoch 1531/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 6.4524e-05 - val_loss: 1.3056e-04\n",
      "Epoch 1532/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 6.1186e-05 - val_loss: 1.2858e-04\n",
      "Epoch 1533/2000\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 7.4752e-05 - val_loss: 1.5116e-04\n",
      "Epoch 1534/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 6.1228e-05 - val_loss: 2.1456e-04\n",
      "Epoch 1535/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 6.8049e-05 - val_loss: 1.0553e-04\n",
      "Epoch 1536/2000\n",
      "3690/3690 [==============================] - 2s 627us/step - loss: 6.4429e-05 - val_loss: 2.7732e-04\n",
      "Epoch 1537/2000\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 6.0682e-05 - val_loss: 1.1589e-04\n",
      "Epoch 1538/2000\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 7.0087e-05 - val_loss: 2.7210e-04\n",
      "Epoch 1539/2000\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 7.5473e-05 - val_loss: 1.5121e-04\n",
      "Epoch 1540/2000\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 7.0190e-05 - val_loss: 3.5523e-04\n",
      "Epoch 1541/2000\n",
      "3690/3690 [==============================] - 2s 575us/step - loss: 7.1356e-05 - val_loss: 1.7616e-04\n",
      "Epoch 1542/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 6.0250e-05 - val_loss: 1.2566e-04\n",
      "Epoch 1543/2000\n",
      "3690/3690 [==============================] - 2s 576us/step - loss: 6.2523e-05 - val_loss: 1.1557e-04\n",
      "Epoch 1544/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 6.5800e-05 - val_loss: 9.2050e-05\n",
      "Epoch 1545/2000\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 7.2856e-05 - val_loss: 1.0024e-04\n",
      "Epoch 1546/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 8.2821e-05 - val_loss: 2.9809e-04\n",
      "Epoch 1547/2000\n",
      "3690/3690 [==============================] - 2s 582us/step - loss: 7.5104e-05 - val_loss: 1.3005e-04\n",
      "Epoch 1548/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 7.5494e-05 - val_loss: 1.7330e-04\n",
      "Epoch 1549/2000\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 7.7357e-05 - val_loss: 1.5197e-04\n",
      "Epoch 1550/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 606us/step - loss: 9.4030e-05 - val_loss: 4.5891e-04\n",
      "Epoch 1551/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 8.4519e-05 - val_loss: 1.0652e-04\n",
      "Epoch 1552/2000\n",
      "3690/3690 [==============================] - 2s 577us/step - loss: 7.5432e-05 - val_loss: 1.1870e-04\n",
      "Epoch 1553/2000\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 6.5624e-05 - val_loss: 1.0958e-04\n",
      "Epoch 1554/2000\n",
      "3690/3690 [==============================] - 2s 579us/step - loss: 6.7656e-05 - val_loss: 3.4727e-04\n",
      "Epoch 1555/2000\n",
      "3690/3690 [==============================] - 2s 574us/step - loss: 7.0458e-05 - val_loss: 1.1643e-04\n",
      "Epoch 1556/2000\n",
      "3690/3690 [==============================] - 2s 590us/step - loss: 9.3343e-05 - val_loss: 1.5547e-04\n",
      "Epoch 1557/2000\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 7.0370e-05 - val_loss: 1.0098e-04\n",
      "Epoch 1558/2000\n",
      "3690/3690 [==============================] - 2s 578us/step - loss: 7.1226e-05 - val_loss: 4.4527e-04\n",
      "Epoch 1559/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 9.4540e-05 - val_loss: 1.1003e-04\n",
      "Epoch 1560/2000\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 7.8560e-05 - val_loss: 1.7406e-04\n",
      "Epoch 1561/2000\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 6.4194e-05 - val_loss: 1.1317e-04\n",
      "Epoch 1562/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 9.1689e-05 - val_loss: 2.5768e-04\n",
      "Epoch 1563/2000\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 7.2586e-05 - val_loss: 1.0499e-04\n",
      "Epoch 1564/2000\n",
      "3690/3690 [==============================] - 2s 584us/step - loss: 6.9352e-05 - val_loss: 1.8871e-04\n",
      "Epoch 1565/2000\n",
      "3690/3690 [==============================] - 2s 598us/step - loss: 6.8820e-05 - val_loss: 2.7032e-04\n",
      "Epoch 1566/2000\n",
      "3690/3690 [==============================] - 2s 573us/step - loss: 7.2180e-05 - val_loss: 1.0258e-04\n",
      "Epoch 1567/2000\n",
      "3690/3690 [==============================] - 2s 637us/step - loss: 6.5716e-05 - val_loss: 1.5184e-04\n",
      "Epoch 1568/2000\n",
      "3690/3690 [==============================] - 2s 596us/step - loss: 6.9099e-05 - val_loss: 1.2730e-04\n",
      "Epoch 1569/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 9.7734e-05 - val_loss: 4.5801e-04\n",
      "Epoch 1570/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 9.2973e-05 - val_loss: 1.0730e-04\n",
      "Epoch 1571/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.7309e-05 - val_loss: 2.1950e-04\n",
      "Epoch 1572/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.1737e-05 - val_loss: 1.1880e-04\n",
      "Epoch 1573/2000\n",
      "3690/3690 [==============================] - 2s 615us/step - loss: 7.1621e-05 - val_loss: 9.7745e-05\n",
      "Epoch 1574/2000\n",
      "3690/3690 [==============================] - 2s 581us/step - loss: 7.0086e-05 - val_loss: 2.4931e-04\n",
      "Epoch 1575/2000\n",
      "3690/3690 [==============================] - 2s 580us/step - loss: 7.3430e-05 - val_loss: 3.0347e-04\n",
      "Epoch 1576/2000\n",
      "3690/3690 [==============================] - 2s 592us/step - loss: 7.6454e-05 - val_loss: 1.8849e-04\n",
      "Epoch 1577/2000\n",
      "3690/3690 [==============================] - 2s 587us/step - loss: 8.3625e-05 - val_loss: 9.4859e-05\n",
      "Epoch 1578/2000\n",
      "3690/3690 [==============================] - 2s 593us/step - loss: 8.1015e-05 - val_loss: 2.9061e-04\n",
      "Epoch 1579/2000\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 8.2153e-05 - val_loss: 1.2996e-04\n",
      "Epoch 1580/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 6.2671e-05 - val_loss: 1.0738e-04\n",
      "Epoch 1581/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 6.1500e-05 - val_loss: 1.5256e-04\n",
      "Epoch 1582/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 6.2981e-05 - val_loss: 1.0511e-04\n",
      "Epoch 1583/2000\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 5.7981e-05 - val_loss: 9.3763e-05\n",
      "Epoch 1584/2000\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 6.8907e-05 - val_loss: 1.0304e-04\n",
      "Epoch 1585/2000\n",
      "3690/3690 [==============================] - 2s 602us/step - loss: 7.4807e-05 - val_loss: 2.2729e-04\n",
      "Epoch 1586/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 6.5769e-05 - val_loss: 1.2287e-04\n",
      "Epoch 1587/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.0935e-05 - val_loss: 1.0696e-04\n",
      "Epoch 1588/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 6.6575e-05 - val_loss: 9.2024e-05\n",
      "Epoch 1589/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 6.4638e-05 - val_loss: 1.2376e-04\n",
      "Epoch 1590/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 6.0347e-05 - val_loss: 1.3216e-04\n",
      "Epoch 1591/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.0831e-05 - val_loss: 1.3592e-04\n",
      "Epoch 1592/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.2045e-05 - val_loss: 1.5260e-04\n",
      "Epoch 1593/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 6.1956e-05 - val_loss: 1.0487e-04\n",
      "Epoch 1594/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.2901e-05 - val_loss: 1.8146e-04\n",
      "Epoch 1595/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.3526e-05 - val_loss: 1.9877e-04\n",
      "Epoch 1596/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.1701e-05 - val_loss: 1.3822e-04\n",
      "Epoch 1597/2000\n",
      "3690/3690 [==============================] - 2s 585us/step - loss: 6.5731e-05 - val_loss: 1.0773e-04\n",
      "Epoch 1598/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 8.5002e-05 - val_loss: 1.6560e-04\n",
      "Epoch 1599/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.1586e-05 - val_loss: 1.2153e-04\n",
      "Epoch 1600/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.0610e-05 - val_loss: 1.6836e-04\n",
      "Epoch 1601/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.4004e-05 - val_loss: 2.6400e-04\n",
      "Epoch 1602/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 8.7609e-05 - val_loss: 9.7159e-05\n",
      "Epoch 1603/2000\n",
      "3690/3690 [==============================] - 2s 572us/step - loss: 6.9113e-05 - val_loss: 1.8585e-04\n",
      "Epoch 1604/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 6.7852e-05 - val_loss: 1.4521e-04\n",
      "Epoch 1605/2000\n",
      "3690/3690 [==============================] - 2s 570us/step - loss: 8.7501e-05 - val_loss: 2.8730e-04\n",
      "Epoch 1606/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 8.7002e-05 - val_loss: 1.3808e-04\n",
      "Epoch 1607/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 6.8472e-05 - val_loss: 4.8429e-04\n",
      "Epoch 1608/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.6567e-05 - val_loss: 1.2676e-04\n",
      "Epoch 1609/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 8.4824e-05 - val_loss: 2.0609e-04\n",
      "Epoch 1610/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.5725e-05 - val_loss: 1.0668e-04\n",
      "Epoch 1611/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.3468e-05 - val_loss: 1.3929e-04\n",
      "Epoch 1612/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.5347e-05 - val_loss: 9.9452e-05\n",
      "Epoch 1613/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.4825e-05 - val_loss: 3.1321e-04\n",
      "Epoch 1614/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 8.0863e-05 - val_loss: 1.0568e-04\n",
      "Epoch 1615/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.7660e-05 - val_loss: 1.3004e-04\n",
      "Epoch 1616/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 5.8771e-05 - val_loss: 1.1812e-04\n",
      "Epoch 1617/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 6.6184e-05 - val_loss: 2.4041e-04\n",
      "Epoch 1618/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.1060e-05 - val_loss: 1.0408e-04\n",
      "Epoch 1619/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.6577e-05 - val_loss: 1.0939e-04\n",
      "Epoch 1620/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.0969e-05 - val_loss: 1.0652e-04\n",
      "Epoch 1621/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.8236e-05 - val_loss: 1.3435e-04\n",
      "Epoch 1622/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.6101e-05 - val_loss: 1.0816e-04\n",
      "Epoch 1623/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.5637e-05 - val_loss: 2.0144e-04\n",
      "Epoch 1624/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.4455e-05 - val_loss: 1.2902e-04\n",
      "Epoch 1625/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 6.7545e-05 - val_loss: 1.1238e-04\n",
      "Epoch 1626/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.4183e-05 - val_loss: 4.3876e-04\n",
      "Epoch 1627/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.1994e-05 - val_loss: 1.3472e-04\n",
      "Epoch 1628/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 8.2376e-05 - val_loss: 1.1062e-04\n",
      "Epoch 1629/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 8.9530e-05 - val_loss: 4.3000e-04\n",
      "Epoch 1630/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 9.0857e-05 - val_loss: 1.3586e-04\n",
      "Epoch 1631/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.3324e-05 - val_loss: 1.0217e-04\n",
      "Epoch 1632/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 7.6737e-05 - val_loss: 3.4236e-04\n",
      "Epoch 1633/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.4400e-05 - val_loss: 1.3457e-04\n",
      "Epoch 1634/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.6880e-05 - val_loss: 1.4430e-04\n",
      "Epoch 1635/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.6728e-05 - val_loss: 1.8320e-04\n",
      "Epoch 1636/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.1876e-05 - val_loss: 3.3544e-04\n",
      "Epoch 1637/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.7744e-05 - val_loss: 1.7269e-04\n",
      "Epoch 1638/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 7.8016e-05 - val_loss: 2.2473e-04\n",
      "Epoch 1639/2000\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 6.7153e-05 - val_loss: 1.8765e-04\n",
      "Epoch 1640/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 7.2610e-05 - val_loss: 1.0817e-04\n",
      "Epoch 1641/2000\n",
      "3690/3690 [==============================] - 2s 561us/step - loss: 6.2051e-05 - val_loss: 1.2718e-04\n",
      "Epoch 1642/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 6.0727e-05 - val_loss: 1.3568e-04\n",
      "Epoch 1643/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 6.3901e-05 - val_loss: 2.0781e-04\n",
      "Epoch 1644/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.3221e-05 - val_loss: 1.5747e-04\n",
      "Epoch 1645/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.1466e-05 - val_loss: 2.9524e-04\n",
      "Epoch 1646/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 6.8629e-05 - val_loss: 1.1055e-04\n",
      "Epoch 1647/2000\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 8.0075e-05 - val_loss: 1.3240e-04\n",
      "Epoch 1648/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.2478e-05 - val_loss: 2.6679e-04\n",
      "Epoch 1649/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.6866e-05 - val_loss: 1.5649e-04\n",
      "Epoch 1650/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.8280e-05 - val_loss: 9.9913e-05\n",
      "Epoch 1651/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.5801e-05 - val_loss: 2.7083e-04\n",
      "Epoch 1652/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 8.1256e-05 - val_loss: 1.6360e-04\n",
      "Epoch 1653/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.9248e-05 - val_loss: 1.9681e-04\n",
      "Epoch 1654/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 7.4105e-05 - val_loss: 1.4153e-04\n",
      "Epoch 1655/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.0308e-05 - val_loss: 1.9447e-04\n",
      "Epoch 1656/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.4296e-05 - val_loss: 1.1652e-04\n",
      "Epoch 1657/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.7533e-05 - val_loss: 2.3369e-04\n",
      "Epoch 1658/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.2733e-05 - val_loss: 1.9096e-04\n",
      "Epoch 1659/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 6.4057e-05 - val_loss: 1.4966e-04\n",
      "Epoch 1660/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.0866e-05 - val_loss: 1.0150e-04\n",
      "Epoch 1661/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.6987e-05 - val_loss: 1.4155e-04\n",
      "Epoch 1662/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.6822e-05 - val_loss: 1.1540e-04\n",
      "Epoch 1663/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.6764e-05 - val_loss: 1.1144e-04\n",
      "Epoch 1664/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.7244e-05 - val_loss: 2.4061e-04\n",
      "Epoch 1665/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.0890e-05 - val_loss: 2.1854e-04\n",
      "Epoch 1666/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.4955e-05 - val_loss: 1.1529e-04\n",
      "Epoch 1667/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.5463e-05 - val_loss: 2.5580e-04\n",
      "Epoch 1668/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.4935e-05 - val_loss: 1.3386e-04\n",
      "Epoch 1669/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.2075e-05 - val_loss: 1.3080e-04\n",
      "Epoch 1670/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.3724e-05 - val_loss: 2.1016e-04\n",
      "Epoch 1671/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.2712e-05 - val_loss: 1.0407e-04\n",
      "Epoch 1672/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.9632e-05 - val_loss: 2.0954e-04\n",
      "Epoch 1673/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.1624e-05 - val_loss: 1.3859e-04\n",
      "Epoch 1674/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.5259e-05 - val_loss: 1.7896e-04\n",
      "Epoch 1675/2000\n",
      "3690/3690 [==============================] - 2s 597us/step - loss: 6.6013e-05 - val_loss: 1.5611e-04\n",
      "Epoch 1676/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.4584e-05 - val_loss: 1.3588e-04\n",
      "Epoch 1677/2000\n",
      "3690/3690 [==============================] - 2s 566us/step - loss: 7.7614e-05 - val_loss: 1.9401e-04\n",
      "Epoch 1678/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.2768e-05 - val_loss: 2.2368e-04\n",
      "Epoch 1679/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.6861e-05 - val_loss: 2.5183e-04\n",
      "Epoch 1680/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.9117e-05 - val_loss: 1.4406e-04\n",
      "Epoch 1681/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.6232e-05 - val_loss: 2.7910e-04\n",
      "Epoch 1682/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.4114e-05 - val_loss: 1.6599e-04\n",
      "Epoch 1683/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 6.1625e-05 - val_loss: 2.1177e-04\n",
      "Epoch 1684/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.8911e-05 - val_loss: 2.0308e-04\n",
      "Epoch 1685/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 6.1527e-05 - val_loss: 1.2602e-04\n",
      "Epoch 1686/2000\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 6.4785e-05 - val_loss: 2.1161e-04\n",
      "Epoch 1687/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.7059e-05 - val_loss: 1.3142e-04\n",
      "Epoch 1688/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.3418e-05 - val_loss: 2.6821e-04\n",
      "Epoch 1689/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.1733e-05 - val_loss: 1.4070e-04\n",
      "Epoch 1690/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 560us/step - loss: 6.6306e-05 - val_loss: 2.7471e-04\n",
      "Epoch 1691/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 6.6360e-05 - val_loss: 1.3207e-04\n",
      "Epoch 1692/2000\n",
      "3690/3690 [==============================] - 2s 564us/step - loss: 8.1460e-05 - val_loss: 2.1865e-04\n",
      "Epoch 1693/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 8.5472e-05 - val_loss: 2.6910e-04\n",
      "Epoch 1694/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 6.1512e-05 - val_loss: 9.8684e-05\n",
      "Epoch 1695/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.8996e-05 - val_loss: 1.1523e-04\n",
      "Epoch 1696/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 6.8593e-05 - val_loss: 2.8270e-04\n",
      "Epoch 1697/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.4506e-05 - val_loss: 1.3304e-04\n",
      "Epoch 1698/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.6690e-05 - val_loss: 2.3575e-04\n",
      "Epoch 1699/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.9121e-05 - val_loss: 2.2712e-04\n",
      "Epoch 1700/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.2254e-05 - val_loss: 1.1549e-04\n",
      "Epoch 1701/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.7258e-05 - val_loss: 2.6034e-04\n",
      "Epoch 1702/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.6237e-05 - val_loss: 4.8164e-04\n",
      "Epoch 1703/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 7.4407e-05 - val_loss: 1.1670e-04\n",
      "Epoch 1704/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 6.5079e-05 - val_loss: 1.9397e-04\n",
      "Epoch 1705/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.2303e-05 - val_loss: 1.8036e-04\n",
      "Epoch 1706/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.2796e-05 - val_loss: 1.0621e-04\n",
      "Epoch 1707/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.3700e-05 - val_loss: 2.2121e-04\n",
      "Epoch 1708/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.3988e-05 - val_loss: 1.3428e-04\n",
      "Epoch 1709/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.8249e-05 - val_loss: 1.4101e-04\n",
      "Epoch 1710/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.9098e-05 - val_loss: 1.5437e-04\n",
      "Epoch 1711/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.4629e-05 - val_loss: 1.5231e-04\n",
      "Epoch 1712/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.3754e-05 - val_loss: 1.3215e-04\n",
      "Epoch 1713/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.4274e-05 - val_loss: 1.3753e-04\n",
      "Epoch 1714/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.7321e-05 - val_loss: 2.9482e-04\n",
      "Epoch 1715/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.4637e-05 - val_loss: 1.2172e-04\n",
      "Epoch 1716/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 5.9318e-05 - val_loss: 1.6558e-04\n",
      "Epoch 1717/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 5.8423e-05 - val_loss: 1.2218e-04\n",
      "Epoch 1718/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.9116e-05 - val_loss: 1.2910e-04\n",
      "Epoch 1719/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.4986e-05 - val_loss: 2.6331e-04\n",
      "Epoch 1720/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.3619e-05 - val_loss: 1.2674e-04\n",
      "Epoch 1721/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.6663e-05 - val_loss: 1.5789e-04\n",
      "Epoch 1722/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.1123e-05 - val_loss: 1.6819e-04\n",
      "Epoch 1723/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.4754e-05 - val_loss: 2.5944e-04\n",
      "Epoch 1724/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.1332e-05 - val_loss: 1.6017e-04\n",
      "Epoch 1725/2000\n",
      "3690/3690 [==============================] - 2s 549us/step - loss: 5.9512e-05 - val_loss: 1.0463e-04\n",
      "Epoch 1726/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.5434e-05 - val_loss: 1.1146e-04\n",
      "Epoch 1727/2000\n",
      "3690/3690 [==============================] - 2s 568us/step - loss: 8.1316e-05 - val_loss: 3.5240e-04\n",
      "Epoch 1728/2000\n",
      "3690/3690 [==============================] - 2s 610us/step - loss: 7.5814e-05 - val_loss: 1.9509e-04\n",
      "Epoch 1729/2000\n",
      "3690/3690 [==============================] - 2s 571us/step - loss: 7.5655e-05 - val_loss: 1.9446e-04\n",
      "Epoch 1730/2000\n",
      "3690/3690 [==============================] - 2s 589us/step - loss: 7.7905e-05 - val_loss: 1.3228e-04\n",
      "Epoch 1731/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 6.5556e-05 - val_loss: 1.1749e-04\n",
      "Epoch 1732/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.5149e-05 - val_loss: 1.1364e-04\n",
      "Epoch 1733/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 5.7712e-05 - val_loss: 2.1528e-04\n",
      "Epoch 1734/2000\n",
      "3690/3690 [==============================] - 2s 567us/step - loss: 6.5672e-05 - val_loss: 1.9390e-04\n",
      "Epoch 1735/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.2275e-05 - val_loss: 8.9526e-05\n",
      "Epoch 1736/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 5.9858e-05 - val_loss: 1.4419e-04\n",
      "Epoch 1737/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.0194e-05 - val_loss: 2.0418e-04\n",
      "Epoch 1738/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.2244e-05 - val_loss: 2.9938e-04\n",
      "Epoch 1739/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 8.2564e-05 - val_loss: 1.4450e-04\n",
      "Epoch 1740/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.2406e-05 - val_loss: 1.6021e-04\n",
      "Epoch 1741/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.1092e-05 - val_loss: 3.0160e-04\n",
      "Epoch 1742/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.3923e-05 - val_loss: 2.2156e-04\n",
      "Epoch 1743/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.1635e-05 - val_loss: 1.6843e-04\n",
      "Epoch 1744/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 1.1076e-04 - val_loss: 2.9222e-04\n",
      "Epoch 1745/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.8310e-05 - val_loss: 1.5186e-04\n",
      "Epoch 1746/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.9241e-05 - val_loss: 1.1034e-04\n",
      "Epoch 1747/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.6788e-05 - val_loss: 8.7409e-05\n",
      "Epoch 1748/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.0002e-05 - val_loss: 1.9199e-04\n",
      "Epoch 1749/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.1225e-05 - val_loss: 1.5067e-04\n",
      "Epoch 1750/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.1455e-05 - val_loss: 2.0232e-04\n",
      "Epoch 1751/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.1918e-05 - val_loss: 1.1448e-04\n",
      "Epoch 1752/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.4361e-05 - val_loss: 1.6220e-04\n",
      "Epoch 1753/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.9238e-05 - val_loss: 1.0771e-04\n",
      "Epoch 1754/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.0089e-05 - val_loss: 1.7067e-04\n",
      "Epoch 1755/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.6965e-05 - val_loss: 1.3331e-04\n",
      "Epoch 1756/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.2565e-05 - val_loss: 1.0580e-04\n",
      "Epoch 1757/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 6.3570e-05 - val_loss: 1.1079e-04\n",
      "Epoch 1758/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.5579e-05 - val_loss: 2.2532e-04\n",
      "Epoch 1759/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.6991e-05 - val_loss: 2.2590e-04\n",
      "Epoch 1760/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.2706e-05 - val_loss: 1.0090e-04\n",
      "Epoch 1761/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.7273e-05 - val_loss: 1.0334e-04\n",
      "Epoch 1762/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.3276e-05 - val_loss: 3.0741e-04\n",
      "Epoch 1763/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.1159e-05 - val_loss: 2.9543e-04\n",
      "Epoch 1764/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.2050e-05 - val_loss: 1.5420e-04\n",
      "Epoch 1765/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.4829e-05 - val_loss: 2.6610e-04\n",
      "Epoch 1766/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.8050e-05 - val_loss: 1.8015e-04\n",
      "Epoch 1767/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.7523e-05 - val_loss: 1.3378e-04\n",
      "Epoch 1768/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.7630e-05 - val_loss: 1.2158e-04\n",
      "Epoch 1769/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.7769e-05 - val_loss: 2.7736e-04\n",
      "Epoch 1770/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.7988e-05 - val_loss: 2.5116e-04\n",
      "Epoch 1771/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.1341e-05 - val_loss: 1.1282e-04\n",
      "Epoch 1772/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.9911e-05 - val_loss: 3.1353e-04\n",
      "Epoch 1773/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.6676e-05 - val_loss: 1.2585e-04\n",
      "Epoch 1774/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.8290e-05 - val_loss: 2.9559e-04\n",
      "Epoch 1775/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.1243e-05 - val_loss: 1.3082e-04\n",
      "Epoch 1776/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.7010e-05 - val_loss: 3.7222e-04\n",
      "Epoch 1777/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.8018e-05 - val_loss: 1.2929e-04\n",
      "Epoch 1778/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.1258e-05 - val_loss: 2.0042e-04\n",
      "Epoch 1779/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.8402e-05 - val_loss: 5.5167e-04\n",
      "Epoch 1780/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.1282e-05 - val_loss: 1.6334e-04\n",
      "Epoch 1781/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.4258e-05 - val_loss: 1.0417e-04\n",
      "Epoch 1782/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.1367e-05 - val_loss: 2.9267e-04\n",
      "Epoch 1783/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.9458e-05 - val_loss: 2.5263e-04\n",
      "Epoch 1784/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.1559e-05 - val_loss: 4.8955e-04\n",
      "Epoch 1785/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 7.6115e-05 - val_loss: 1.4782e-04\n",
      "Epoch 1786/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.4227e-05 - val_loss: 2.0364e-04\n",
      "Epoch 1787/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.2611e-05 - val_loss: 1.6499e-04\n",
      "Epoch 1788/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.9416e-05 - val_loss: 3.8634e-04\n",
      "Epoch 1789/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.1032e-05 - val_loss: 1.8471e-04\n",
      "Epoch 1790/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.9931e-05 - val_loss: 1.3643e-04\n",
      "Epoch 1791/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.5031e-05 - val_loss: 3.0182e-04\n",
      "Epoch 1792/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 5.7318e-05 - val_loss: 1.5032e-04\n",
      "Epoch 1793/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.1137e-05 - val_loss: 1.8930e-04\n",
      "Epoch 1794/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7602e-05 - val_loss: 1.7860e-04\n",
      "Epoch 1795/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.3195e-05 - val_loss: 1.2721e-04\n",
      "Epoch 1796/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.4559e-05 - val_loss: 1.6259e-04\n",
      "Epoch 1797/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.9115e-05 - val_loss: 1.1832e-04\n",
      "Epoch 1798/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.2900e-05 - val_loss: 3.2189e-04\n",
      "Epoch 1799/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.8891e-05 - val_loss: 1.2080e-04\n",
      "Epoch 1800/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.4744e-05 - val_loss: 1.6388e-04\n",
      "Epoch 1801/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 5.7553e-05 - val_loss: 2.0978e-04\n",
      "Epoch 1802/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.5950e-05 - val_loss: 1.2421e-04\n",
      "Epoch 1803/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 8.2687e-05 - val_loss: 2.3790e-04\n",
      "Epoch 1804/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.9445e-05 - val_loss: 1.2983e-04\n",
      "Epoch 1805/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.4995e-05 - val_loss: 3.6428e-04\n",
      "Epoch 1806/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.6904e-05 - val_loss: 1.0149e-04\n",
      "Epoch 1807/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.6102e-05 - val_loss: 1.5614e-04\n",
      "Epoch 1808/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.5070e-05 - val_loss: 2.4346e-04\n",
      "Epoch 1809/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 5.7233e-05 - val_loss: 2.0575e-04\n",
      "Epoch 1810/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.0847e-05 - val_loss: 1.2269e-04\n",
      "Epoch 1811/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.6438e-05 - val_loss: 1.5888e-04\n",
      "Epoch 1812/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.4963e-05 - val_loss: 1.1565e-04\n",
      "Epoch 1813/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7259e-05 - val_loss: 1.3905e-04\n",
      "Epoch 1814/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.1860e-05 - val_loss: 3.4860e-04\n",
      "Epoch 1815/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.4325e-05 - val_loss: 1.5437e-04\n",
      "Epoch 1816/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.2655e-05 - val_loss: 2.5219e-04\n",
      "Epoch 1817/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.0830e-05 - val_loss: 1.4680e-04\n",
      "Epoch 1818/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.4537e-05 - val_loss: 3.4106e-04\n",
      "Epoch 1819/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.0725e-05 - val_loss: 1.3291e-04\n",
      "Epoch 1820/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.1937e-05 - val_loss: 1.6805e-04\n",
      "Epoch 1821/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.9965e-05 - val_loss: 2.0570e-04\n",
      "Epoch 1822/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.7014e-05 - val_loss: 1.6140e-04\n",
      "Epoch 1823/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 5.6228e-05 - val_loss: 2.2518e-04\n",
      "Epoch 1824/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 5.6266e-05 - val_loss: 1.5195e-04\n",
      "Epoch 1825/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.5794e-05 - val_loss: 1.3915e-04\n",
      "Epoch 1826/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.7671e-05 - val_loss: 1.5026e-04\n",
      "Epoch 1827/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.6870e-05 - val_loss: 2.5203e-04\n",
      "Epoch 1828/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.9706e-05 - val_loss: 1.3804e-04\n",
      "Epoch 1829/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.1159e-05 - val_loss: 3.3021e-04\n",
      "Epoch 1830/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.2620e-05 - val_loss: 1.4966e-04\n",
      "Epoch 1831/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 8.1745e-05 - val_loss: 2.0538e-04\n",
      "Epoch 1832/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 8.1436e-05 - val_loss: 1.7806e-04\n",
      "Epoch 1833/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.4987e-05 - val_loss: 2.5670e-04\n",
      "Epoch 1834/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.4797e-05 - val_loss: 2.4003e-04\n",
      "Epoch 1835/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.7984e-05 - val_loss: 1.5367e-04\n",
      "Epoch 1836/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.4236e-05 - val_loss: 1.4932e-04\n",
      "Epoch 1837/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.9263e-05 - val_loss: 1.8342e-04\n",
      "Epoch 1838/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.2577e-05 - val_loss: 2.1620e-04\n",
      "Epoch 1839/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.5664e-05 - val_loss: 1.2434e-04\n",
      "Epoch 1840/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 7.7028e-05 - val_loss: 4.2746e-04\n",
      "Epoch 1841/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.8035e-05 - val_loss: 9.5957e-05\n",
      "Epoch 1842/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.2464e-05 - val_loss: 1.4584e-04\n",
      "Epoch 1843/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.0814e-05 - val_loss: 2.1660e-04\n",
      "Epoch 1844/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.2607e-05 - val_loss: 2.3133e-04\n",
      "Epoch 1845/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.2478e-05 - val_loss: 1.1856e-04\n",
      "Epoch 1846/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.5404e-05 - val_loss: 2.5152e-04\n",
      "Epoch 1847/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.0770e-05 - val_loss: 1.2078e-04\n",
      "Epoch 1848/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.1837e-05 - val_loss: 2.9269e-04\n",
      "Epoch 1849/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.8110e-05 - val_loss: 3.5449e-04\n",
      "Epoch 1850/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.4900e-05 - val_loss: 1.1975e-04\n",
      "Epoch 1851/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.5288e-05 - val_loss: 2.5706e-04\n",
      "Epoch 1852/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.8173e-05 - val_loss: 1.8371e-04\n",
      "Epoch 1853/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.7174e-05 - val_loss: 2.6817e-04\n",
      "Epoch 1854/2000\n",
      "3690/3690 [==============================] - 2s 565us/step - loss: 5.9124e-05 - val_loss: 1.5252e-04\n",
      "Epoch 1855/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.6236e-05 - val_loss: 1.8495e-04\n",
      "Epoch 1856/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.7873e-05 - val_loss: 2.3462e-04\n",
      "Epoch 1857/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.3856e-05 - val_loss: 2.4310e-04\n",
      "Epoch 1858/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7302e-05 - val_loss: 3.2161e-04\n",
      "Epoch 1859/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 5.7147e-05 - val_loss: 1.5055e-04\n",
      "Epoch 1860/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.5727e-05 - val_loss: 7.2543e-04\n",
      "Epoch 1861/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 1.2963e-04 - val_loss: 2.3835e-04\n",
      "Epoch 1862/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 8.7162e-05 - val_loss: 3.7640e-04\n",
      "Epoch 1863/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.8127e-05 - val_loss: 2.0155e-04\n",
      "Epoch 1864/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.1260e-05 - val_loss: 1.7395e-04\n",
      "Epoch 1865/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.1959e-05 - val_loss: 1.6886e-04\n",
      "Epoch 1866/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.1127e-05 - val_loss: 4.2676e-04\n",
      "Epoch 1867/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.0604e-05 - val_loss: 1.7924e-04\n",
      "Epoch 1868/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.1258e-05 - val_loss: 1.2012e-04\n",
      "Epoch 1869/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.8396e-05 - val_loss: 2.5768e-04\n",
      "Epoch 1870/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.8348e-05 - val_loss: 1.9527e-04\n",
      "Epoch 1871/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.6366e-05 - val_loss: 1.4627e-04\n",
      "Epoch 1872/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.8147e-05 - val_loss: 3.1556e-04\n",
      "Epoch 1873/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.0048e-05 - val_loss: 1.7634e-04\n",
      "Epoch 1874/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.8484e-05 - val_loss: 1.7541e-04\n",
      "Epoch 1875/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.0022e-05 - val_loss: 2.9621e-04\n",
      "Epoch 1876/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.6092e-05 - val_loss: 1.9865e-04\n",
      "Epoch 1877/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.9448e-05 - val_loss: 3.1767e-04\n",
      "Epoch 1878/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 5.7941e-05 - val_loss: 1.8646e-04\n",
      "Epoch 1879/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7267e-05 - val_loss: 1.1660e-04\n",
      "Epoch 1880/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.4542e-05 - val_loss: 2.0629e-04\n",
      "Epoch 1881/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.3266e-05 - val_loss: 2.1934e-04\n",
      "Epoch 1882/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.2671e-05 - val_loss: 2.9879e-04\n",
      "Epoch 1883/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.0703e-05 - val_loss: 1.7439e-04\n",
      "Epoch 1884/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.8741e-05 - val_loss: 1.2936e-04\n",
      "Epoch 1885/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 5.8403e-05 - val_loss: 2.8129e-04\n",
      "Epoch 1886/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 5.5827e-05 - val_loss: 2.0995e-04\n",
      "Epoch 1887/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7151e-05 - val_loss: 1.8339e-04\n",
      "Epoch 1888/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 5.5665e-05 - val_loss: 1.9557e-04\n",
      "Epoch 1889/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.8436e-05 - val_loss: 2.7884e-04\n",
      "Epoch 1890/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.0638e-05 - val_loss: 2.4465e-04\n",
      "Epoch 1891/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.1525e-05 - val_loss: 1.3441e-04\n",
      "Epoch 1892/2000\n",
      "3690/3690 [==============================] - 2s 550us/step - loss: 6.3816e-05 - val_loss: 1.5152e-04\n",
      "Epoch 1893/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 5.5273e-05 - val_loss: 1.6573e-04\n",
      "Epoch 1894/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7233e-05 - val_loss: 2.0728e-04\n",
      "Epoch 1895/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.4495e-05 - val_loss: 3.5132e-04\n",
      "Epoch 1896/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7574e-05 - val_loss: 2.4572e-04\n",
      "Epoch 1897/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.7778e-05 - val_loss: 2.2450e-04\n",
      "Epoch 1898/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.8418e-05 - val_loss: 1.6282e-04\n",
      "Epoch 1899/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.8713e-05 - val_loss: 3.5603e-04\n",
      "Epoch 1900/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.8251e-05 - val_loss: 1.3510e-04\n",
      "Epoch 1901/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 7.0945e-05 - val_loss: 2.1235e-04\n",
      "Epoch 1902/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.4663e-05 - val_loss: 2.8609e-04\n",
      "Epoch 1903/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.2409e-05 - val_loss: 1.7804e-04\n",
      "Epoch 1904/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.5012e-05 - val_loss: 4.0434e-04\n",
      "Epoch 1905/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.6018e-05 - val_loss: 1.4593e-04\n",
      "Epoch 1906/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.1242e-05 - val_loss: 3.2989e-04\n",
      "Epoch 1907/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.9151e-05 - val_loss: 1.4271e-04\n",
      "Epoch 1908/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.3664e-05 - val_loss: 1.5981e-04\n",
      "Epoch 1909/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.1589e-05 - val_loss: 3.0762e-04\n",
      "Epoch 1910/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.7045e-05 - val_loss: 1.2364e-04\n",
      "Epoch 1911/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.1859e-05 - val_loss: 2.2671e-04\n",
      "Epoch 1912/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.3565e-05 - val_loss: 2.0746e-04\n",
      "Epoch 1913/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.7540e-05 - val_loss: 3.1254e-04\n",
      "Epoch 1914/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.3635e-05 - val_loss: 1.5216e-04\n",
      "Epoch 1915/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.4314e-05 - val_loss: 3.7932e-04\n",
      "Epoch 1916/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.8647e-05 - val_loss: 2.7596e-04\n",
      "Epoch 1917/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 5.4398e-05 - val_loss: 4.6829e-04\n",
      "Epoch 1918/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.5066e-05 - val_loss: 1.6923e-04\n",
      "Epoch 1919/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.0554e-05 - val_loss: 4.5857e-04\n",
      "Epoch 1920/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.3038e-05 - val_loss: 1.2215e-04\n",
      "Epoch 1921/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.2726e-05 - val_loss: 3.4719e-04\n",
      "Epoch 1922/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.6867e-05 - val_loss: 1.5269e-04\n",
      "Epoch 1923/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.6873e-05 - val_loss: 2.7984e-04\n",
      "Epoch 1924/2000\n",
      "3690/3690 [==============================] - 2s 560us/step - loss: 5.6198e-05 - val_loss: 1.4159e-04\n",
      "Epoch 1925/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.3653e-05 - val_loss: 3.2505e-04\n",
      "Epoch 1926/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.1138e-05 - val_loss: 3.1765e-04\n",
      "Epoch 1927/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.8106e-05 - val_loss: 2.3863e-04\n",
      "Epoch 1928/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 6.2146e-05 - val_loss: 2.0157e-04\n",
      "Epoch 1929/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.0323e-05 - val_loss: 4.0691e-04\n",
      "Epoch 1930/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.0492e-05 - val_loss: 1.4899e-04\n",
      "Epoch 1931/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.0685e-05 - val_loss: 1.8753e-04\n",
      "Epoch 1932/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 5.5970e-05 - val_loss: 2.8436e-04\n",
      "Epoch 1933/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 6.5220e-05 - val_loss: 2.2326e-04\n",
      "Epoch 1934/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.8103e-05 - val_loss: 1.7965e-04\n",
      "Epoch 1935/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.9696e-05 - val_loss: 4.0055e-04\n",
      "Epoch 1936/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.5216e-05 - val_loss: 1.3836e-04\n",
      "Epoch 1937/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.7743e-05 - val_loss: 1.9388e-04\n",
      "Epoch 1938/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 5.6690e-05 - val_loss: 1.3697e-04\n",
      "Epoch 1939/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.0419e-05 - val_loss: 2.2605e-04\n",
      "Epoch 1940/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 5.4267e-05 - val_loss: 2.2789e-04\n",
      "Epoch 1941/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.2263e-05 - val_loss: 3.4972e-04\n",
      "Epoch 1942/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.1487e-05 - val_loss: 2.1799e-04\n",
      "Epoch 1943/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.9511e-05 - val_loss: 5.5007e-04\n",
      "Epoch 1944/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.6315e-05 - val_loss: 2.3997e-04\n",
      "Epoch 1945/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.0087e-05 - val_loss: 2.4568e-04\n",
      "Epoch 1946/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.8199e-05 - val_loss: 3.3829e-04\n",
      "Epoch 1947/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.6159e-05 - val_loss: 3.0253e-04\n",
      "Epoch 1948/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.0233e-05 - val_loss: 1.4564e-04\n",
      "Epoch 1949/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.9629e-05 - val_loss: 2.2765e-04\n",
      "Epoch 1950/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 5.9928e-05 - val_loss: 1.4298e-04\n",
      "Epoch 1951/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 5.6458e-05 - val_loss: 6.1577e-04\n",
      "Epoch 1952/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 7.6745e-05 - val_loss: 3.7028e-04\n",
      "Epoch 1953/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.8996e-05 - val_loss: 2.2262e-04\n",
      "Epoch 1954/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.4438e-05 - val_loss: 2.8960e-04\n",
      "Epoch 1955/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 5.4146e-05 - val_loss: 3.4700e-04\n",
      "Epoch 1956/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 5.9799e-05 - val_loss: 1.8563e-04\n",
      "Epoch 1957/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7460e-05 - val_loss: 2.1654e-04\n",
      "Epoch 1958/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.1862e-05 - val_loss: 3.6638e-04\n",
      "Epoch 1959/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.0076e-05 - val_loss: 2.0448e-04\n",
      "Epoch 1960/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 5.8664e-05 - val_loss: 2.4898e-04\n",
      "Epoch 1961/2000\n",
      "3690/3690 [==============================] - 2s 563us/step - loss: 5.7411e-05 - val_loss: 3.5984e-04\n",
      "Epoch 1962/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.5535e-05 - val_loss: 2.6487e-04\n",
      "Epoch 1963/2000\n",
      "3690/3690 [==============================] - 2s 569us/step - loss: 5.4752e-05 - val_loss: 3.6943e-04\n",
      "Epoch 1964/2000\n",
      "3690/3690 [==============================] - 2s 562us/step - loss: 5.6086e-05 - val_loss: 2.7379e-04\n",
      "Epoch 1965/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7763e-05 - val_loss: 5.3901e-04\n",
      "Epoch 1966/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.3996e-05 - val_loss: 1.5443e-04\n",
      "Epoch 1967/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.9474e-05 - val_loss: 1.8496e-04\n",
      "Epoch 1968/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.7543e-05 - val_loss: 2.3448e-04\n",
      "Epoch 1969/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.8607e-05 - val_loss: 3.2107e-04\n",
      "Epoch 1970/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.7481e-05 - val_loss: 2.1779e-04\n",
      "Epoch 1971/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 5.7722e-05 - val_loss: 3.8812e-04\n",
      "Epoch 1972/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.4016e-05 - val_loss: 2.1038e-04\n",
      "Epoch 1973/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.4980e-05 - val_loss: 1.6435e-04\n",
      "Epoch 1974/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 5.7087e-05 - val_loss: 3.6819e-04\n",
      "Epoch 1975/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.5345e-05 - val_loss: 2.4161e-04\n",
      "Epoch 1976/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.4430e-05 - val_loss: 1.5756e-04\n",
      "Epoch 1977/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 7.5446e-05 - val_loss: 4.5684e-04\n",
      "Epoch 1978/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.8836e-05 - val_loss: 1.9570e-04\n",
      "Epoch 1979/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.3090e-05 - val_loss: 2.3358e-04\n",
      "Epoch 1980/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.5861e-05 - val_loss: 2.0142e-04\n",
      "Epoch 1981/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.6956e-05 - val_loss: 1.4354e-04\n",
      "Epoch 1982/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7606e-05 - val_loss: 2.2305e-04\n",
      "Epoch 1983/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.9024e-05 - val_loss: 2.4123e-04\n",
      "Epoch 1984/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 5.3092e-05 - val_loss: 3.7646e-04\n",
      "Epoch 1985/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.6115e-05 - val_loss: 3.4432e-04\n",
      "Epoch 1986/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 5.6824e-05 - val_loss: 1.9135e-04\n",
      "Epoch 1987/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 6.1397e-05 - val_loss: 2.4777e-04\n",
      "Epoch 1988/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.6213e-05 - val_loss: 2.7940e-04\n",
      "Epoch 1989/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 6.2174e-05 - val_loss: 1.6615e-04\n",
      "Epoch 1990/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 9.1067e-05 - val_loss: 4.1152e-04\n",
      "Epoch 1991/2000\n",
      "3690/3690 [==============================] - 2s 559us/step - loss: 7.1701e-05 - val_loss: 1.6498e-04\n",
      "Epoch 1992/2000\n",
      "3690/3690 [==============================] - 2s 552us/step - loss: 7.4568e-05 - val_loss: 2.6060e-04\n",
      "Epoch 1993/2000\n",
      "3690/3690 [==============================] - 2s 554us/step - loss: 5.7870e-05 - val_loss: 4.6242e-04\n",
      "Epoch 1994/2000\n",
      "3690/3690 [==============================] - 2s 551us/step - loss: 5.9121e-05 - val_loss: 2.9297e-04\n",
      "Epoch 1995/2000\n",
      "3690/3690 [==============================] - 2s 558us/step - loss: 6.4634e-05 - val_loss: 2.7799e-04\n",
      "Epoch 1996/2000\n",
      "3690/3690 [==============================] - 2s 556us/step - loss: 6.4303e-05 - val_loss: 1.4654e-04\n",
      "Epoch 1997/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.5723e-05 - val_loss: 3.0840e-04\n",
      "Epoch 1998/2000\n",
      "3690/3690 [==============================] - 2s 557us/step - loss: 6.4816e-05 - val_loss: 1.8103e-04\n",
      "Epoch 1999/2000\n",
      "3690/3690 [==============================] - 2s 555us/step - loss: 6.4878e-05 - val_loss: 1.6865e-04\n",
      "Epoch 2000/2000\n",
      "3690/3690 [==============================] - 2s 553us/step - loss: 5.7982e-05 - val_loss: 2.7680e-04\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': 'adam',\n",
       " 'shuffle': True,\n",
       " 'dropout': 0.1,\n",
       " 'full_density': True,\n",
       " 'twice': True,\n",
       " 'density': 230,\n",
       " 'activation': 'softplus',\n",
       " 'lstmsize': 150,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x189c7cf7708>]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_362 (LSTM)              (None, 92, 150)           93600     \n",
      "_________________________________________________________________\n",
      "dropout_362 (Dropout)        (None, 92, 150)           0         \n",
      "_________________________________________________________________\n",
      "lstm_363 (LSTM)              (None, 150)               180600    \n",
      "_________________________________________________________________\n",
      "dropout_363 (Dropout)        (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "dense_931 (Dense)            (None, 230)               34730     \n",
      "_________________________________________________________________\n",
      "dense_932 (Dense)            (None, 115)               26565     \n",
      "_________________________________________________________________\n",
      "dense_933 (Dense)            (None, 57)                6612      \n",
      "_________________________________________________________________\n",
      "dense_934 (Dense)            (None, 28)                1624      \n",
      "_________________________________________________________________\n",
      "dense_935 (Dense)            (None, 14)                406       \n",
      "_________________________________________________________________\n",
      "dense_936 (Dense)            (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 344,152\n",
      "Trainable params: 344,152\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_MSE/IBM.(best_in_validation).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 2.21\n",
      "Medium error is 0.89\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((unscaled_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(unscaled_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 80.12%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 78.43%\n",
      "Accuracy for downward trend is: 82.75%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), unscaled_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
