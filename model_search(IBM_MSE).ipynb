{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from joblib import dump\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(len(data) * train_size)\n",
    "\n",
    "train = data.to_numpy()[:split]\n",
    "test = data.to_numpy()[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "normaliser = preprocessing.MinMaxScaler()\n",
    "train_norm = normaliser.fit_transform(train)\n",
    "test_norm = normaliser.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_train = np.array([train_norm[i : i + backlook].copy() for i in range(len(train) - backlook)])\n",
    "Y_train = np.array([train_norm[:,0][i + backlook].copy() for i in range(len(train) - backlook)])\n",
    "Y_train = np.expand_dims(Y_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised test chunks\n",
    "X_test = np.array([test_norm[i : i + backlook].copy() for i in range(len(test) - backlook)])\n",
    "Y_test = np.array([test_norm[:,0][i + backlook].copy() for i in range(len(test) - backlook)])\n",
    "Y_test = np.expand_dims(Y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3303677 ],\n",
       "       [0.32881229],\n",
       "       [0.33814471],\n",
       "       ...,\n",
       "       [0.52547751],\n",
       "       [0.51919368],\n",
       "       [0.53300566]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y raw data\n",
    "next_day_open_values = np.array([train[:,0][i + backlook].copy() for i in range(len(train) - backlook)])\n",
    "next_day_open_values = np.expand_dims(next_day_open_values, -1)\n",
    "\n",
    "# Y normaliser\n",
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "y_normaliser.fit_transform(next_day_open_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./normalisers/y_normaliser.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save scalers for future use\n",
    "dump(normaliser, './normalisers/x_normaliser.joblib')\n",
    "dump(y_normaliser, './normalisers/y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 746us/step - loss: 0.0276 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0264 - val_loss: 0.0494\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 0.0176 - val_loss: 7.9258e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 501us/step - loss: 0.0046 - val_loss: 0.0094\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0066 - val_loss: 0.0075\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0069 - val_loss: 0.0185\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0139 - val_loss: 0.0068\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0189 - val_loss: 0.0378\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 0.0400 - val_loss: 0.0051\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0198 - val_loss: 0.0209\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 0.0055 - val_loss: 0.0044\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0086 - val_loss: 7.2831e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0113 - val_loss: 0.0070\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.0243 - val_loss: 0.0061\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0102 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0126 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0069 - val_loss: 4.5529e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0096 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0051 - val_loss: 4.1893e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0067 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0036 - val_loss: 4.5676e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0043 - val_loss: 8.0899e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0028 - val_loss: 3.7788e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 689us/step - loss: 0.0379 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0508 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0306 - val_loss: 0.0245\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 0.0095 - val_loss: 0.0116\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 0.0091 - val_loss: 0.0187\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0118 - val_loss: 0.0096\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0175 - val_loss: 0.0420\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0471 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0249 - val_loss: 0.0194\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0323 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0154 - val_loss: 0.0059\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0278 - val_loss: 0.0083\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0093 - val_loss: 7.0754e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 0.0151 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0053 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0068 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 0.0031 - val_loss: 7.9820e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0038 - val_loss: 5.2346e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0030 - val_loss: 4.9854e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0043 - val_loss: 5.0924e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0036 - val_loss: 6.5052e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0065 - val_loss: 5.0039e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0057 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0120 - val_loss: 0.0013\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 755us/step - loss: 0.0445 - val_loss: 0.0087\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0441 - val_loss: 0.0270\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0301 - val_loss: 0.0070\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0128 - val_loss: 0.0232\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0189 - val_loss: 0.0184\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0249 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0026 - val_loss: 5.1250e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0028 - val_loss: 6.3737e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0029 - val_loss: 9.7356e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0035 - val_loss: 0.0061\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0026 - val_loss: 9.3392e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0033 - val_loss: 0.0057\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0022 - val_loss: 5.1995e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0022 - val_loss: 0.0034\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0015 - val_loss: 4.0392e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0015 - val_loss: 9.3981e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0014 - val_loss: 3.6712e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0014 - val_loss: 7.2029e-04\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0014 - val_loss: 7.0959e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 760us/step - loss: 0.0587 - val_loss: 0.0111\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0104 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0021 - val_loss: 6.2305e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0018 - val_loss: 4.7564e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0018 - val_loss: 6.6335e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0015 - val_loss: 8.2869e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0013 - val_loss: 7.6101e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0012 - val_loss: 7.7707e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 6.3097e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0012 - val_loss: 5.9729e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0011 - val_loss: 6.9487e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0011 - val_loss: 6.5005e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0011 - val_loss: 6.6131e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0010 - val_loss: 4.0195e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0010 - val_loss: 7.8032e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0010 - val_loss: 8.3734e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0010 - val_loss: 4.5961e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 778us/step - loss: 0.5567 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0661 - val_loss: 0.0999\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0645 - val_loss: 0.0148\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0556 - val_loss: 0.0185\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0278 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0067 - val_loss: 0.0157\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0045 - val_loss: 8.8998e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0028 - val_loss: 8.4270e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0026 - val_loss: 7.5391e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0023 - val_loss: 7.2569e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0022 - val_loss: 6.3901e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0022 - val_loss: 9.9643e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0021 - val_loss: 8.6546e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 6.5196e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 5.8846e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0017 - val_loss: 6.6266e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0018 - val_loss: 5.9779e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0017 - val_loss: 7.6765e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0016 - val_loss: 7.2290e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0016 - val_loss: 9.1519e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0016 - val_loss: 5.8966e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 8.6836e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 817us/step - loss: 0.1028 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0036 - val_loss: 0.0273\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0092 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0045 - val_loss: 0.0071\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0063 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0020 - val_loss: 0.0070\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0065 - val_loss: 0.0171\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0061 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0037 - val_loss: 0.0128\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0045 - val_loss: 5.1182e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0021 - val_loss: 3.6863e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 0.0099\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0032 - val_loss: 0.0059\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0027 - val_loss: 7.6761e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0014 - val_loss: 5.9371e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 818us/step - loss: 0.2017 - val_loss: 6.3079e-04\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0076 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0037 - val_loss: 9.7495e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0026 - val_loss: 4.6247e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0026 - val_loss: 5.1540e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0036 - val_loss: 4.3214e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0024 - val_loss: 3.9285e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0017 - val_loss: 3.9783e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0017 - val_loss: 3.8183e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0039 - val_loss: 0.0119\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0040 - val_loss: 3.8117e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0017 - val_loss: 3.7768e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0016 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0026 - val_loss: 4.2098e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 3.7195e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0014 - val_loss: 5.6704e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0016 - val_loss: 0.0061\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0046 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 849us/step - loss: 0.3391 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0088 - val_loss: 0.0107\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0044 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0066 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0027 - val_loss: 5.1826e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0042 - val_loss: 9.7475e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0022 - val_loss: 6.2953e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0071 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0016 - val_loss: 5.5418e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0015 - val_loss: 5.8356e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0015 - val_loss: 9.2320e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0052 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 5.1713e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0014 - val_loss: 6.2987e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0039 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0028 - val_loss: 9.7389e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 810us/step - loss: 0.0946 - val_loss: 0.0181\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0302 - val_loss: 0.0083\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0229 - val_loss: 0.0063\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0178 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0136 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0106 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0088 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0069 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0058 - val_loss: 8.4981e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0050 - val_loss: 7.7570e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0046 - val_loss: 7.1793e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0043 - val_loss: 6.9595e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0040 - val_loss: 6.9553e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0038 - val_loss: 8.5454e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0035 - val_loss: 7.9141e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0033 - val_loss: 7.8348e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0034 - val_loss: 8.3190e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0034 - val_loss: 6.7106e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0035 - val_loss: 7.5759e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0032 - val_loss: 8.7004e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 829us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 862us/step - loss: 0.3169 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0046 - val_loss: 5.6898e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0187 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0098 - val_loss: 0.0366\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0136 - val_loss: 0.0294\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0162 - val_loss: 0.0284\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0154 - val_loss: 0.0265\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0186 - val_loss: 5.1995e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0030 - val_loss: 0.0315\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0208 - val_loss: 0.0119\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0070 - val_loss: 0.0101\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0142 - val_loss: 0.0503\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0093 - val_loss: 0.0047\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0079 - val_loss: 0.0164\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0110 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0047 - val_loss: 0.0154\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0119 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0016 - val_loss: 0.0263\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0129 - val_loss: 4.3676e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0037 - val_loss: 0.0263\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0059 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0072 - val_loss: 0.0193\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0042 - val_loss: 3.4246e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0078 - val_loss: 0.0143\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 892us/step - loss: 0.0532 - val_loss: 0.0202\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0088 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0035 - val_loss: 4.8374e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0027 - val_loss: 4.3806e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0016 - val_loss: 7.7118e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0015 - val_loss: 7.3941e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 7.8498e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0013 - val_loss: 8.7542e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0013 - val_loss: 6.7840e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0013 - val_loss: 3.9794e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 4.0440e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 5.6937e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0012 - val_loss: 7.1423e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0012 - val_loss: 3.7418e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0011 - val_loss: 6.2148e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0010 - val_loss: 4.8078e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0010 - val_loss: 4.5654e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0011 - val_loss: 7.9498e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0010 - val_loss: 3.6444e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0010 - val_loss: 3.8204e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 906us/step - loss: 0.0532 - val_loss: 0.0202\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0092 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 6.4643e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0015 - val_loss: 5.0669e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0015 - val_loss: 5.6383e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 9.2794e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 7.1541e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0012 - val_loss: 4.9846e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0012 - val_loss: 4.0584e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 4.0542e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 4.5038e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0010 - val_loss: 5.7469e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0010 - val_loss: 3.8716e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0010 - val_loss: 3.8005e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0010 - val_loss: 4.2096e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0011 - val_loss: 3.7965e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 9.6854e-04 - val_loss: 3.8383e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 9.5349e-04 - val_loss: 4.8206e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 9.2236e-04 - val_loss: 4.4327e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 9.1675e-04 - val_loss: 3.9961e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 952us/step - loss: 0.1855 - val_loss: 0.0200\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0862 - val_loss: 0.0058\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0730 - val_loss: 0.0480\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0672 - val_loss: 0.0648\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0642 - val_loss: 0.0320\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0575 - val_loss: 0.0253\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0478 - val_loss: 0.0183\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0285 - val_loss: 0.0050\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0184 - val_loss: 0.0076\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0131 - val_loss: 0.0086\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0083 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0020 - val_loss: 7.8149e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0017 - val_loss: 7.8153e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0016 - val_loss: 9.4192e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0014 - val_loss: 5.8956e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0013 - val_loss: 5.4925e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0013 - val_loss: 5.7909e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0012 - val_loss: 6.6195e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0011 - val_loss: 5.2274e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0010 - val_loss: 7.3481e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 950us/step - loss: 0.0717 - val_loss: 0.0191\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0437 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0258 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0095 - val_loss: 0.0343\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0160 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0109 - val_loss: 0.0341\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0106 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0059 - val_loss: 0.0525\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0085 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0074 - val_loss: 0.0411\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0054 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0071 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0054 - val_loss: 0.0175\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0054 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0041 - val_loss: 0.0596\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0058 - val_loss: 8.9716e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0064 - val_loss: 0.0092\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0031 - val_loss: 0.0063\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0066 - val_loss: 0.0179\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0045 - val_loss: 6.2040e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0046 - val_loss: 0.0061\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0047 - val_loss: 0.0017\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 973us/step - loss: 0.0933 - val_loss: 0.0090\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0521 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0298 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0185 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0108 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0023 - val_loss: 6.5193e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0018 - val_loss: 7.2550e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0015 - val_loss: 8.4934e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0013 - val_loss: 6.0223e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0011 - val_loss: 5.5652e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0011 - val_loss: 5.2793e-04\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 533us/step - loss: 9.7400e-04 - val_loss: 5.1751e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 9.3833e-04 - val_loss: 9.7698e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0010 - val_loss: 4.9420e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 8.5496e-04 - val_loss: 4.6441e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 8.0711e-04 - val_loss: 4.8059e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 7.8787e-04 - val_loss: 4.5630e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 7.4658e-04 - val_loss: 4.8717e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 7.0966e-04 - val_loss: 4.5668e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 7.1804e-04 - val_loss: 4.2507e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 6.9693e-04 - val_loss: 4.7989e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 6.7826e-04 - val_loss: 4.7771e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 989us/step - loss: 2.8534 - val_loss: 2.4035\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 1.5666 - val_loss: 1.4950\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.9347 - val_loss: 0.9465\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.5565 - val_loss: 0.5923\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.3274 - val_loss: 0.3678\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.1964 - val_loss: 0.2299\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.1255 - val_loss: 0.1476\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0907 - val_loss: 0.0995\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0748 - val_loss: 0.0721\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0682 - val_loss: 0.0567\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0657 - val_loss: 0.0480\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0649 - val_loss: 0.0432\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0647 - val_loss: 0.0406\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0646 - val_loss: 0.0397\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0646 - val_loss: 0.0394\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0646 - val_loss: 0.0393\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0646 - val_loss: 0.0397\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0646 - val_loss: 0.0396\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0646 - val_loss: 0.0394\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0647 - val_loss: 0.0392\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0646 - val_loss: 0.0396\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0646 - val_loss: 0.0393\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0646 - val_loss: 0.0396\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0646 - val_loss: 0.0396\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 1ms/step - loss: 1.1243 - val_loss: 0.7640\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.3621 - val_loss: 0.2823\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.1302 - val_loss: 0.1029\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0711 - val_loss: 0.0407\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0655 - val_loss: 0.0239\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0672 - val_loss: 0.0235\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0665 - val_loss: 0.0287\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0652 - val_loss: 0.0352\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0647 - val_loss: 0.0396\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0647 - val_loss: 0.0419\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0647 - val_loss: 0.0421\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0646 - val_loss: 0.0392\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0647 - val_loss: 0.0384\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0646 - val_loss: 0.0396\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0646 - val_loss: 0.0406\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0647 - val_loss: 0.0410\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0646 - val_loss: 0.0403\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0647 - val_loss: 0.0390\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0388\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0647 - val_loss: 0.0386\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0647 - val_loss: 0.0379\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0647 - val_loss: 0.0394\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0646 - val_loss: 0.0400\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0646 - val_loss: 0.0398\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 1ms/step - loss: 0.1140 - val_loss: 0.0387\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0645 - val_loss: 0.0461\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0617 - val_loss: 0.0569\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0640 - val_loss: 0.0629\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0637 - val_loss: 0.0662\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0552 - val_loss: 0.0058\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0420 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0136 - val_loss: 0.0086\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0219 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0072 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.0152 - val_loss: 0.0089\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0080 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0040 - val_loss: 0.0333\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0187 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0024 - val_loss: 8.3542e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0021 - val_loss: 0.0162\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0222 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0015 - val_loss: 6.4799e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 7.3844e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 6.0049e-04\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 1ms/step - loss: 0.5952 - val_loss: 0.3813\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.1561 - val_loss: 0.0957\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0677 - val_loss: 0.0225\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0705 - val_loss: 0.0137\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0713 - val_loss: 0.0214\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0664 - val_loss: 0.0379\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0648 - val_loss: 0.0465\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0649 - val_loss: 0.0451\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0648 - val_loss: 0.0414\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0647 - val_loss: 0.0389\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0647 - val_loss: 0.0384\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0647 - val_loss: 0.0382\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0383\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0647 - val_loss: 0.0417\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0430\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0418\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0647 - val_loss: 0.0374\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0647 - val_loss: 0.0383\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0646 - val_loss: 0.0404\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0646 - val_loss: 0.0405\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0646 - val_loss: 0.0399\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0646 - val_loss: 0.0393\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0647 - val_loss: 0.0380\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0647 - val_loss: 0.0389\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.5600 - val_loss: 0.2078\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0819 - val_loss: 0.0095\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0901 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0816 - val_loss: 0.0216\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0651 - val_loss: 0.0544\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0669 - val_loss: 0.0589\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0657 - val_loss: 0.0413\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0647 - val_loss: 0.0339\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0650 - val_loss: 0.0354\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0647 - val_loss: 0.0412\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0647 - val_loss: 0.0434\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0647 - val_loss: 0.0403\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0647 - val_loss: 0.0368\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0647 - val_loss: 0.0393\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0646 - val_loss: 0.0422\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0415\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0647 - val_loss: 0.0379\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0647 - val_loss: 0.0401\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0646 - val_loss: 0.0394\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0647 - val_loss: 0.0416\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0647 - val_loss: 0.0401\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0646 - val_loss: 0.0393\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0647 - val_loss: 0.0394\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0647 - val_loss: 0.0368\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.0767 - val_loss: 0.0134\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0572\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0579 - val_loss: 0.0202\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0424 - val_loss: 0.0229\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0396 - val_loss: 0.0592\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0619 - val_loss: 0.0328\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0646 - val_loss: 0.0490\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0651 - val_loss: 0.0306\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0652 - val_loss: 0.0471\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0647 - val_loss: 0.0364\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0641 - val_loss: 0.0400\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0564 - val_loss: 0.0137\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0350 - val_loss: 0.0076\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0291 - val_loss: 0.0324\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0334 - val_loss: 0.0551\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0656 - val_loss: 0.0543\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0653 - val_loss: 0.0305\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0649 - val_loss: 0.0443\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0641 - val_loss: 0.0416\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0571 - val_loss: 0.0508\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0630 - val_loss: 0.1466\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0805 - val_loss: 0.0116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0696 - val_loss: 0.0601\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0669 - val_loss: 0.0373\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.1078 - val_loss: 0.0447\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0698 - val_loss: 0.0812\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0686 - val_loss: 0.0404\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0640 - val_loss: 0.0283\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0599 - val_loss: 0.0290\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0525 - val_loss: 0.0249\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0444 - val_loss: 0.0099\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0342 - val_loss: 0.0105\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0238 - val_loss: 0.0061\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0404 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0744 - val_loss: 0.0855\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0742 - val_loss: 0.0527\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0662 - val_loss: 0.0220\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0664 - val_loss: 0.0406\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0649 - val_loss: 0.0471\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0648 - val_loss: 0.0403\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0647 - val_loss: 0.0378\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0647 - val_loss: 0.0397\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0646 - val_loss: 0.0402\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0646 - val_loss: 0.0408\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0646 - val_loss: 0.0394\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0646 - val_loss: 0.0382\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0643 - val_loss: 0.0411\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0395 - val_loss: 0.0040\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.3603 - val_loss: 0.1681\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0853 - val_loss: 0.0597\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0655 - val_loss: 0.0462\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0648 - val_loss: 0.0411\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0647 - val_loss: 0.0379\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0650 - val_loss: 0.0321\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0646 - val_loss: 0.0221\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0560 - val_loss: 0.0077\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0296 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0195 - val_loss: 0.0133\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0144 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0134 - val_loss: 0.0229\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0111 - val_loss: 0.0124\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0092 - val_loss: 0.0442\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0094 - val_loss: 0.0074\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0112 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0087 - val_loss: 0.0147\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0049 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0084 - val_loss: 0.0077\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0057 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0053 - val_loss: 0.0115\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0068 - val_loss: 0.0249\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0061 - val_loss: 0.0036\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.8418 - val_loss: 0.5558\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.2661 - val_loss: 0.2453\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.1204 - val_loss: 0.1098\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0743 - val_loss: 0.0603\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0655 - val_loss: 0.0436\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0350\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0647 - val_loss: 0.0331\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0649 - val_loss: 0.0217\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0652 - val_loss: 0.0285\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0651 - val_loss: 0.0437\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0647 - val_loss: 0.0436\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0652 - val_loss: 0.0610\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0649 - val_loss: 0.0213\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0652 - val_loss: 0.0690\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0649 - val_loss: 0.0597\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0573 - val_loss: 0.0195\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0255 - val_loss: 0.0046\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0286 - val_loss: 0.0063\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0122 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0117 - val_loss: 0.0132\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0101 - val_loss: 0.0049\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0099 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0101 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0075 - val_loss: 0.0035\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 2.8117 - val_loss: 0.0056\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0059 - val_loss: 0.0029\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 592us/step - loss: 0.0075 - val_loss: 0.2941\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 0.0673 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0125 - val_loss: 0.1822\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0353 - val_loss: 0.0113\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0288 - val_loss: 0.1343\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.1356 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0020 - val_loss: 0.0054\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.0200 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0084 - val_loss: 0.0526\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0219 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0365 - val_loss: 0.0157\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0048 - val_loss: 0.0317\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0227 - val_loss: 0.0066\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0151 - val_loss: 0.0481\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.0183 - val_loss: 5.8400e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 0.0096 - val_loss: 0.0130\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 0.0166 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0084 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 0.0086 - val_loss: 0.0275\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0205 - val_loss: 0.0108\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 0.0057 - val_loss: 0.0095\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0081 - val_loss: 0.0021\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 3.8733 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0098 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0371 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.0072 - val_loss: 0.0354\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 0.0762 - val_loss: 0.0173\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 0.0308 - val_loss: 0.0823\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.1303 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0263 - val_loss: 0.0285\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 0.0331 - val_loss: 0.1352\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0880 - val_loss: 0.0083\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0121 - val_loss: 0.0440\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0184 - val_loss: 0.0054\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.0244 - val_loss: 0.0182\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0181 - val_loss: 0.0564\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0339 - val_loss: 0.0043\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0056 - val_loss: 0.0116\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0308 - val_loss: 0.0092\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0105 - val_loss: 0.0207\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0126 - val_loss: 0.0776\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 0.0185 - val_loss: 0.0132\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 0.0088 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0362 - val_loss: 0.0091\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0018 - val_loss: 6.4904e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 5.5497 - val_loss: 0.0058\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0227 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.1662 - val_loss: 0.0856\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0144 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0493 - val_loss: 0.2395\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 0.1294 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 0.0020 - val_loss: 0.0089\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.2348 - val_loss: 0.0903\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0435 - val_loss: 7.4447e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0316 - val_loss: 0.0292\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 0.0235 - val_loss: 0.0718\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0740 - val_loss: 0.0392\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0273 - val_loss: 0.0054\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0193 - val_loss: 0.0591\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.1046 - val_loss: 0.0851\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0507 - val_loss: 0.0211\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.0190 - val_loss: 0.0092\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0158 - val_loss: 0.0434\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0252 - val_loss: 0.0049\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0190 - val_loss: 0.1839\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0587 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0092 - val_loss: 0.0552\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0142 - val_loss: 0.0231\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.1127 - val_loss: 0.0085\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0131 - val_loss: 0.0131\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0063 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0031 - val_loss: 9.0075e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0018 - val_loss: 7.6380e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0017 - val_loss: 5.4384e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0015 - val_loss: 5.1515e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0014 - val_loss: 5.3786e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0013 - val_loss: 5.2746e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0013 - val_loss: 5.3025e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0013 - val_loss: 5.0562e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0013 - val_loss: 4.7754e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0012 - val_loss: 4.9794e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 5.0141e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0011 - val_loss: 6.7353e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 6.5215e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0012 - val_loss: 4.8282e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0012 - val_loss: 4.8230e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0011 - val_loss: 9.4465e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0010 - val_loss: 5.1361e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0010 - val_loss: 7.0512e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0010 - val_loss: 5.8825e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 1ms/step - loss: 2.5206 - val_loss: 0.1781\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 0.0702 - val_loss: 0.0133\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0423 - val_loss: 0.0380\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0323 - val_loss: 0.0886\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0369 - val_loss: 0.0317\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0385 - val_loss: 0.0187\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0328 - val_loss: 0.0308\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0346 - val_loss: 0.0471\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 590us/step - loss: 0.0858 - val_loss: 0.0093\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0157 - val_loss: 0.0412\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 0.0233 - val_loss: 0.0339\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0275 - val_loss: 0.0151\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0190 - val_loss: 0.0334\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0242 - val_loss: 0.0567\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0296 - val_loss: 0.0058\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0084 - val_loss: 0.0215\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0166 - val_loss: 0.0380\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0181 - val_loss: 0.0121\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0126 - val_loss: 0.0262\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 0.0189 - val_loss: 0.0090\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0100 - val_loss: 0.0139\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0144 - val_loss: 0.0098\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 0.0096 - val_loss: 0.0199\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 1ms/step - loss: 1.7142 - val_loss: 0.0097\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0082 - val_loss: 0.0060\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0057 - val_loss: 0.0083\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0052 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0107 - val_loss: 0.0271\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0108 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0115 - val_loss: 0.0362\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0147 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0112 - val_loss: 0.0314\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0164 - val_loss: 0.0088\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0126 - val_loss: 0.0184\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0171 - val_loss: 0.0111\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.3986 - val_loss: 0.0997\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0673 - val_loss: 0.0096\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0015 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0013 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0016 - val_loss: 6.4361e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0097 - val_loss: 0.0193\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0031 - val_loss: 7.9937e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0021 - val_loss: 0.0373\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0142 - val_loss: 8.0872e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 1ms/step - loss: 0.1273 - val_loss: 0.0145\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0107 - val_loss: 7.9497e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0045 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0030 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0022 - val_loss: 5.5502e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0013 - val_loss: 7.1410e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0011 - val_loss: 7.7063e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0011 - val_loss: 8.9926e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 9.9394e-04 - val_loss: 9.1579e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 9.8025e-04 - val_loss: 4.3750e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 9.6805e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 8.9736e-04 - val_loss: 7.7842e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 8.9255e-04 - val_loss: 4.1033e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 8.9003e-04 - val_loss: 7.0046e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 8.3257e-04 - val_loss: 5.0827e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 8.1474e-04 - val_loss: 6.7580e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 7.9388e-04 - val_loss: 4.8020e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 7.7709e-04 - val_loss: 5.3262e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 7.5281e-04 - val_loss: 5.4978e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 7.7433e-04 - val_loss: 3.9209e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 7.5202e-04 - val_loss: 5.3077e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 7.3472e-04 - val_loss: 6.6728e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 1ms/step - loss: 0.2093 - val_loss: 0.0082\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0143 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0072 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0031 - val_loss: 5.5451e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0019 - val_loss: 9.8990e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0015 - val_loss: 9.6123e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0014 - val_loss: 9.4767e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0013 - val_loss: 8.7764e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0013 - val_loss: 8.6144e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0012 - val_loss: 8.6060e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 8.3394e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0011 - val_loss: 8.1016e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0011 - val_loss: 6.8425e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0011 - val_loss: 8.0760e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0010 - val_loss: 6.2728e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0010 - val_loss: 7.8250e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0010 - val_loss: 6.1987e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 9.9197e-04 - val_loss: 6.7641e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 9.5614e-04 - val_loss: 5.5085e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 9.6954e-04 - val_loss: 6.4036e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.0859 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 1s 343us/step - loss: 0.0028 - val_loss: 0.0264\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 1s 347us/step - loss: 0.0089 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 1s 344us/step - loss: 0.0016 - val_loss: 4.3354e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 1s 350us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 1s 344us/step - loss: 0.0077 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 1s 345us/step - loss: 0.0035 - val_loss: 0.0059\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 1s 345us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 1s 344us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 1s 349us/step - loss: 0.0032 - val_loss: 0.0050\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 1s 352us/step - loss: 0.0042 - val_loss: 0.0129\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 1s 345us/step - loss: 0.0069 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 1s 345us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 1s 347us/step - loss: 0.0012 - val_loss: 4.3532e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 1s 343us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 1s 347us/step - loss: 0.0026 - val_loss: 0.0085\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 1s 344us/step - loss: 0.0085 - val_loss: 0.0041\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 1s 346us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 1s 349us/step - loss: 0.0026 - val_loss: 7.5206e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 1s 343us/step - loss: 9.5899e-04 - val_loss: 4.1339e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 1s 351us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 1s 348us/step - loss: 0.0035 - val_loss: 0.0102\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 1s 346us/step - loss: 0.0070 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 1s 347us/step - loss: 0.0014 - val_loss: 7.7891e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 1ms/step - loss: 0.0828 - val_loss: 0.0113\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0245 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0143 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0086 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0054 - val_loss: 8.9486e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0041 - val_loss: 7.7052e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0031 - val_loss: 7.7566e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0030 - val_loss: 6.8164e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 497us/step - loss: 0.0027 - val_loss: 9.7961e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 504us/step - loss: 0.0026 - val_loss: 7.6805e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0024 - val_loss: 9.0771e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0025 - val_loss: 7.9649e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0024 - val_loss: 8.3849e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0024 - val_loss: 8.2988e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 502us/step - loss: 0.0024 - val_loss: 9.1885e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 497us/step - loss: 0.0024 - val_loss: 6.4131e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0025 - val_loss: 8.3454e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0023 - val_loss: 7.5622e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0021 - val_loss: 7.2750e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.1172 - val_loss: 0.0252\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0374 - val_loss: 0.0125\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0301 - val_loss: 0.0108\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0240 - val_loss: 0.0100\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0194 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0155 - val_loss: 0.0046\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0124 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0097 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0076 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0062 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0049 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0040 - val_loss: 9.6170e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0035 - val_loss: 8.5622e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0030 - val_loss: 8.3739e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0028 - val_loss: 8.3314e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0026 - val_loss: 8.7027e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0024 - val_loss: 9.5075e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0023 - val_loss: 9.6323e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0022 - val_loss: 9.8859e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 1ms/step - loss: 0.1509 - val_loss: 0.0334\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0460 - val_loss: 0.0161\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0359 - val_loss: 0.0124\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0282 - val_loss: 0.0100\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0218 - val_loss: 0.0060\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0170 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0129 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0099 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0075 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0058 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0045 - val_loss: 9.8949e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0039 - val_loss: 9.2679e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0032 - val_loss: 9.0474e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0025 - val_loss: 9.7730e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 2ms/step - loss: 0.0990 - val_loss: 0.0145\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0234 - val_loss: 0.0063\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0064 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0040 - val_loss: 8.9476e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0023 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0016 - val_loss: 6.6179e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0014 - val_loss: 8.9873e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0013 - val_loss: 7.9128e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0011 - val_loss: 7.0007e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0011 - val_loss: 5.5634e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0011 - val_loss: 6.8272e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0011 - val_loss: 5.2694e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0010 - val_loss: 5.1587e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 9.3332e-04 - val_loss: 5.1667e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 9.2360e-04 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 9.3471e-04 - val_loss: 7.6939e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 8.9520e-04 - val_loss: 5.0174e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 8.3750e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 9.3049e-04 - val_loss: 0.0013\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 2ms/step - loss: 0.2278 - val_loss: 0.0595\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0719 - val_loss: 0.0067\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0769 - val_loss: 0.0250\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0650 - val_loss: 0.0585\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0665 - val_loss: 0.0471\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0646 - val_loss: 0.0348\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0645 - val_loss: 0.0378\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0634 - val_loss: 0.0433\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0617 - val_loss: 0.0367\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0631 - val_loss: 0.0390\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0597 - val_loss: 0.0330\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0483 - val_loss: 0.0152\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0351 - val_loss: 0.0064\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0358 - val_loss: 0.0045\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0186 - val_loss: 0.0958\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0673 - val_loss: 0.0187\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0595 - val_loss: 0.0062\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0305 - val_loss: 0.0129\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0869 - val_loss: 0.0481\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0560 - val_loss: 0.0263\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0429 - val_loss: 0.0140\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0337 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0255 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0150 - val_loss: 0.0209\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 1.6342 - val_loss: 1.1264\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.5767 - val_loss: 0.4721\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.2259 - val_loss: 0.2013\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.1021 - val_loss: 0.0851\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0683 - val_loss: 0.0405\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0652 - val_loss: 0.0266\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0664 - val_loss: 0.0255\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0661 - val_loss: 0.0293\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0653 - val_loss: 0.0342\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0648 - val_loss: 0.0386\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0646 - val_loss: 0.0404\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0647 - val_loss: 0.0411\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0647 - val_loss: 0.0410\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0647 - val_loss: 0.0415\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0403\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0380\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0647 - val_loss: 0.0379\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0394\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0646 - val_loss: 0.0404\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0646 - val_loss: 0.0408\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0646 - val_loss: 0.0399\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0646 - val_loss: 0.0392\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0383\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0393\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.0753 - val_loss: 0.0072\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0167 - val_loss: 0.0525\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0071 - val_loss: 0.0078\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0029 - val_loss: 7.8294e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0024 - val_loss: 9.2035e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0018 - val_loss: 7.7448e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0014 - val_loss: 7.0352e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0014 - val_loss: 5.9486e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0012 - val_loss: 5.9250e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0011 - val_loss: 5.8944e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0011 - val_loss: 5.8232e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0010 - val_loss: 5.5107e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0010 - val_loss: 5.1566e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 9.9058e-04 - val_loss: 5.2074e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 9.7245e-04 - val_loss: 5.4866e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 9.5820e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 9.5734e-04 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0011 - val_loss: 0.0029\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0012 - val_loss: 5.7206e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 8.8033e-04 - val_loss: 6.1770e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 1.0807 - val_loss: 0.0368\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.1022 - val_loss: 0.0827\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0726 - val_loss: 0.0461\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0644 - val_loss: 0.0249\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0603 - val_loss: 0.0371\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0465 - val_loss: 0.0123\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0186 - val_loss: 0.0106\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0061 - val_loss: 0.0233\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0022 - val_loss: 8.2386e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0020 - val_loss: 8.2065e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0019 - val_loss: 7.8211e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 7.5199e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0017 - val_loss: 7.4500e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0016 - val_loss: 7.4259e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0016 - val_loss: 9.5554e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0015 - val_loss: 7.6316e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0015 - val_loss: 8.0580e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0014 - val_loss: 8.1836e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0015 - val_loss: 7.4041e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.0731 - val_loss: 0.0192\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0198 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0062 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0037 - val_loss: 8.0604e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0022 - val_loss: 7.8021e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0016 - val_loss: 0.0033\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0013 - val_loss: 7.7512e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0011 - val_loss: 6.3243e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0010 - val_loss: 5.9082e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0011 - val_loss: 6.9970e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 9.4362e-04 - val_loss: 8.2450e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 9.2758e-04 - val_loss: 8.1678e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 8.8097e-04 - val_loss: 5.4193e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 8.9840e-04 - val_loss: 5.3535e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 8.8443e-04 - val_loss: 5.1960e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 7.8226e-04 - val_loss: 5.1932e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 8.3512e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 8.0273e-04 - val_loss: 6.1561e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 7.9262e-04 - val_loss: 7.2982e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 7.5085e-04 - val_loss: 4.9163e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.4567 - val_loss: 0.0079\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0604 - val_loss: 0.0742\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0594 - val_loss: 0.0259\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0525 - val_loss: 0.0150\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0432 - val_loss: 0.0098\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0232 - val_loss: 0.0050\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0055 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: 0.0043 - val_loss: 0.0055\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 462us/step - loss: 0.0021 - val_loss: 9.7297e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0020 - val_loss: 8.1172e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0018 - val_loss: 8.2300e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0017 - val_loss: 7.3878e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0016 - val_loss: 7.0969e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0016 - val_loss: 7.2908e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0017 - val_loss: 7.4392e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0015 - val_loss: 9.4827e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0015 - val_loss: 9.8202e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0015 - val_loss: 6.9549e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0015 - val_loss: 6.7035e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0014 - val_loss: 7.5068e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0014 - val_loss: 6.4361e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0015 - val_loss: 6.4769e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.1298 - val_loss: 0.0244\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0471 - val_loss: 0.0100\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0082 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0059 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0030 - val_loss: 8.1677e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0020 - val_loss: 8.4022e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0019 - val_loss: 9.0075e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0014 - val_loss: 6.2723e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0014 - val_loss: 6.0920e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0013 - val_loss: 6.8887e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0013 - val_loss: 9.3258e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0012 - val_loss: 8.7019e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0011 - val_loss: 5.7263e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0012 - val_loss: 5.6242e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0012 - val_loss: 5.7174e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0011 - val_loss: 6.4562e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0011 - val_loss: 8.2441e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0011 - val_loss: 5.4532e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0010 - val_loss: 5.2781e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.3053 - val_loss: 0.0824\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0679 - val_loss: 0.0233\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0611 - val_loss: 0.0479\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0563 - val_loss: 0.0216\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0382 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0023 - val_loss: 7.3975e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0022 - val_loss: 7.6036e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0021 - val_loss: 9.8896e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0019 - val_loss: 7.0350e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0019 - val_loss: 7.2408e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0017 - val_loss: 9.9934e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0017 - val_loss: 9.2956e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0016 - val_loss: 6.8876e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0017 - val_loss: 9.8287e-04\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 0.1046 - val_loss: 0.0138\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0560 - val_loss: 0.0232\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0428 - val_loss: 0.0059\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0229 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0136 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0068 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0039 - val_loss: 9.1087e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0029 - val_loss: 8.5269e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0023 - val_loss: 7.9773e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0017 - val_loss: 7.3629e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0015 - val_loss: 7.1964e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0014 - val_loss: 8.8354e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0012 - val_loss: 9.5307e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0012 - val_loss: 7.9448e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0010 - val_loss: 4.6810e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 9.7748e-04 - val_loss: 6.1236e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 9.1595e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 9.6448e-04 - val_loss: 8.9995e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 9.8312e-04 - val_loss: 6.6810e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 9.0014e-04 - val_loss: 4.5384e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 8.3444e-04 - val_loss: 9.4833e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 8.4586e-04 - val_loss: 5.8075e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 7.8900e-04 - val_loss: 4.4246e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 0.6931 - val_loss: 0.3108\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.1184 - val_loss: 0.0524\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0672 - val_loss: 0.0132\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0748 - val_loss: 0.0131\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0707 - val_loss: 0.0254\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0653 - val_loss: 0.0405\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0648 - val_loss: 0.0480\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0651 - val_loss: 0.0461\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0647 - val_loss: 0.0403\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0647 - val_loss: 0.0353\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0648 - val_loss: 0.0358\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0647 - val_loss: 0.0388\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0646 - val_loss: 0.0397\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0647 - val_loss: 0.0378\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0647 - val_loss: 0.0384\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0647 - val_loss: 0.0406\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0647 - val_loss: 0.0426\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0403\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0646 - val_loss: 0.0403\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0646 - val_loss: 0.0405\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0647 - val_loss: 0.0419\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0647 - val_loss: 0.0395\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0646 - val_loss: 0.0390\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0646 - val_loss: 0.0405\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 0.1041 - val_loss: 0.0753\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0665 - val_loss: 0.0291\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0651 - val_loss: 0.0457\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0622 - val_loss: 0.0313\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0407 - val_loss: 0.0045\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0233 - val_loss: 0.0113\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0175 - val_loss: 0.0347\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0073 - val_loss: 0.0152\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0013 - val_loss: 9.2022e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 9.8326e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0011 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0011 - val_loss: 8.4823e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0011 - val_loss: 7.5864e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0010 - val_loss: 8.3864e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 9.3125e-04 - val_loss: 6.5725e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 8.7820e-04 - val_loss: 5.9439e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 8.7931e-04 - val_loss: 5.7788e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 8.3997e-04 - val_loss: 5.5913e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 8.4136e-04 - val_loss: 5.2184e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 7.8381e-04 - val_loss: 6.2505e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 7.7834e-04 - val_loss: 6.0324e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 0.0456 - val_loss: 0.0128\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0077 - val_loss: 7.1330e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0011 - val_loss: 8.9167e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 9.3291e-04 - val_loss: 7.4346e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 9.2659e-04 - val_loss: 4.6678e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 9.6601e-04 - val_loss: 4.9834e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 9.8083e-04 - val_loss: 5.5818e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 9.2317e-04 - val_loss: 8.9232e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 8.9485e-04 - val_loss: 6.1358e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 8.8159e-04 - val_loss: 4.6023e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 8.5259e-04 - val_loss: 7.5099e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 8.1698e-04 - val_loss: 8.9659e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 8.0971e-04 - val_loss: 6.7362e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 7.7717e-04 - val_loss: 5.0140e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 7.5040e-04 - val_loss: 6.6966e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 7.7360e-04 - val_loss: 7.3909e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 7.6571e-04 - val_loss: 9.4991e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 8.0420e-04 - val_loss: 6.1628e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 7.3158e-04 - val_loss: 5.4743e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 0.0557 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0059 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0057 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0062 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0061 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0062 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0029 - val_loss: 8.0590e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0029 - val_loss: 7.9355e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0059 - val_loss: 0.0073\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0040 - val_loss: 0.0071\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0034 - val_loss: 6.4214e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0034 - val_loss: 0.0064\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0041 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0039 - val_loss: 0.0116\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0015 - val_loss: 6.0349e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0021 - val_loss: 6.1227e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 0.0431 - val_loss: 0.0545\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0133 - val_loss: 0.0161\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0058 - val_loss: 6.9930e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0038 - val_loss: 0.0117\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0031 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 0.0041 - val_loss: 5.6329e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0020 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0038 - val_loss: 0.0065\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0029 - val_loss: 0.0049\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 0.0025 - val_loss: 0.0061\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0019 - val_loss: 0.0050\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0024 - val_loss: 5.0629e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 7.8683e-04 - val_loss: 0.0030\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0037 - val_loss: 5.6326e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 401us/step - loss: 0.0018 - val_loss: 0.0055\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 9s 2ms/step - loss: 0.0493 - val_loss: 0.0047\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0067 - val_loss: 0.0148\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0036 - val_loss: 6.6988e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0044 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0028 - val_loss: 0.0070\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0041 - val_loss: 0.0101\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0030 - val_loss: 6.2722e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0013 - val_loss: 0.0065\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0028 - val_loss: 5.0202e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0023 - val_loss: 0.0116\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0011 - val_loss: 5.3842e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0016 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0022 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0016 - val_loss: 4.2509e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 9.7423e-04 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 9.7778e-04 - val_loss: 8.1505e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0016 - val_loss: 0.0049\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 9s 2ms/step - loss: 0.0474 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0040 - val_loss: 0.0186\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0077 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0041 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0031 - val_loss: 0.0067\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0033 - val_loss: 6.7415e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0021 - val_loss: 0.0148\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0032 - val_loss: 8.9742e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0016 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0017 - val_loss: 5.4522e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0014 - val_loss: 0.0036\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 8.5917e-04 - val_loss: 6.1874e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 8.5925e-04 - val_loss: 0.0052\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0032 - val_loss: 4.9321e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0011 - val_loss: 0.0046\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0019 - val_loss: 0.0042\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 9s 2ms/step - loss: 0.0389 - val_loss: 0.0713\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0131 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0031 - val_loss: 0.0098\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0057 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0023 - val_loss: 0.0074\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0012 - val_loss: 5.7018e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0027 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0027 - val_loss: 0.0050\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0020 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0012 - val_loss: 5.1895e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0021 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 8.5395e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 9.3333e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0025 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0017 - val_loss: 3.4998e-04\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 9s 2ms/step - loss: 0.0515 - val_loss: 8.5050e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0064 - val_loss: 0.0049\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0018 - val_loss: 4.4321e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0015 - val_loss: 5.0345e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0014 - val_loss: 8.7840e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0013 - val_loss: 5.4399e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0012 - val_loss: 5.1178e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0012 - val_loss: 5.6100e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0011 - val_loss: 7.1017e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0011 - val_loss: 7.4639e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0011 - val_loss: 4.9490e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 9.9876e-04 - val_loss: 4.0888e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0011 - val_loss: 4.2863e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 9.8487e-04 - val_loss: 3.7852e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 9.8061e-04 - val_loss: 3.9752e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 9.4404e-04 - val_loss: 3.7673e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 9.2113e-04 - val_loss: 3.6565e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 9.0293e-04 - val_loss: 3.6134e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 8.8582e-04 - val_loss: 3.7422e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 8.8618e-04 - val_loss: 5.6617e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 8.8441e-04 - val_loss: 3.5594e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 9s 2ms/step - loss: 0.0661 - val_loss: 0.0219\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0248 - val_loss: 0.0121\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0104 - val_loss: 0.0116\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0021 - val_loss: 9.0383e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0017 - val_loss: 7.6608e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0014 - val_loss: 9.3652e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0015 - val_loss: 0.0054\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0013 - val_loss: 6.5647e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 9.9194e-04 - val_loss: 7.7330e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 9.1668e-04 - val_loss: 7.6217e-04\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 539us/step - loss: 8.5905e-04 - val_loss: 6.6639e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 8.7571e-04 - val_loss: 5.4162e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 7.8230e-04 - val_loss: 5.8715e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 7.7630e-04 - val_loss: 6.7950e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 7.7168e-04 - val_loss: 6.3967e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 7.6121e-04 - val_loss: 4.9962e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 7.7515e-04 - val_loss: 4.7444e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 7.3522e-04 - val_loss: 9.0269e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 7.1618e-04 - val_loss: 5.5985e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 6.8161e-04 - val_loss: 4.4427e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 6.6487e-04 - val_loss: 5.5319e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 10s 2ms/step - loss: 0.0746 - val_loss: 0.0434\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0431 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0147 - val_loss: 0.0149\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 0.0071 - val_loss: 0.0079\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0016 - val_loss: 7.8661e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0014 - val_loss: 6.8046e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0012 - val_loss: 8.0506e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0010 - val_loss: 5.8585e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 9.2439e-04 - val_loss: 7.8556e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 8.1068e-04 - val_loss: 6.7302e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 8.0313e-04 - val_loss: 5.0540e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 7.5958e-04 - val_loss: 9.3456e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 8.1742e-04 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 9.2498e-04 - val_loss: 6.1667e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 8.2979e-04 - val_loss: 6.7719e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 7.8398e-04 - val_loss: 9.2032e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 587us/step - loss: 8.1137e-04 - val_loss: 7.1065e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 7.5248e-04 - val_loss: 9.4834e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 8.1957e-04 - val_loss: 4.8480e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 6.8135e-04 - val_loss: 5.2193e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 10s 2ms/step - loss: 0.3606 - val_loss: 0.2236\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0959 - val_loss: 0.0443\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0671 - val_loss: 0.0145\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0725 - val_loss: 0.0173\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 0.0678 - val_loss: 0.0319\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0648 - val_loss: 0.0455\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0650 - val_loss: 0.0471\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0649 - val_loss: 0.0426\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0647 - val_loss: 0.0397\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0646 - val_loss: 0.0395\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0646 - val_loss: 0.0392\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0646 - val_loss: 0.0375\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0647 - val_loss: 0.0376\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0647 - val_loss: 0.0402\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0646 - val_loss: 0.0412\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0647 - val_loss: 0.0393\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0646 - val_loss: 0.0395\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0646 - val_loss: 0.0407\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0647 - val_loss: 0.0377\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0647 - val_loss: 0.0390\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0646 - val_loss: 0.0406\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0646 - val_loss: 0.0402\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0646 - val_loss: 0.0421\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0647 - val_loss: 0.0422\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 10s 2ms/step - loss: 0.3224 - val_loss: 0.0152\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0534 - val_loss: 0.0466\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 0.0438 - val_loss: 0.0117\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0277 - val_loss: 0.0221\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0197 - val_loss: 0.0364\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0155 - val_loss: 0.0100\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0093 - val_loss: 0.0446\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0163 - val_loss: 8.3493e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0035 - val_loss: 0.0292\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0173 - val_loss: 0.0061\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0084 - val_loss: 0.0334\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0136 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0059 - val_loss: 0.0144\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0082 - val_loss: 0.0074\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 0.0115 - val_loss: 0.0238\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0025 - val_loss: 0.0070\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0058 - val_loss: 0.0214\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0119 - val_loss: 0.0202\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0081 - val_loss: 6.3688e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0019 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0072 - val_loss: 0.0233\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0083 - val_loss: 5.9941e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 10s 2ms/step - loss: 0.3117 - val_loss: 9.5403e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0029 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0135 - val_loss: 0.0103\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0102 - val_loss: 0.0286\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0134 - val_loss: 0.0217\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0171 - val_loss: 0.0556\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0245 - val_loss: 6.5144e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0045 - val_loss: 0.0418\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0150 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0090 - val_loss: 0.0249\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0208 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0047 - val_loss: 0.0169\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0065 - val_loss: 0.0097\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0092 - val_loss: 0.0173\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0088 - val_loss: 0.0063\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0079 - val_loss: 0.0191\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0070 - val_loss: 5.0701e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0065 - val_loss: 0.0251\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0071 - val_loss: 6.0105e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0045 - val_loss: 0.0179\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0088 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0033 - val_loss: 0.0086\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0055 - val_loss: 0.0116\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0058 - val_loss: 0.0065\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 10s 2ms/step - loss: 0.0682 - val_loss: 0.0306\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0549 - val_loss: 0.0336\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0301 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0168 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0104 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0083 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0065 - val_loss: 9.8528e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0067 - val_loss: 0.0205\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0052 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0060 - val_loss: 0.0171\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0047 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0047 - val_loss: 0.0129\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0044 - val_loss: 0.0155\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0042 - val_loss: 9.7793e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0050 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0027 - val_loss: 0.0047\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0046 - val_loss: 0.0091\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0038 - val_loss: 0.0112\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0034 - val_loss: 0.0120\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0040 - val_loss: 0.0210\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 10s 2ms/step - loss: 1.5861 - val_loss: 1.3120\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.7908 - val_loss: 0.8094\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.4662 - val_loss: 0.5110\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.2787 - val_loss: 0.3174\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.1683 - val_loss: 0.1950\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.1078 - val_loss: 0.1169\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0783 - val_loss: 0.0709\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0672 - val_loss: 0.0509\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0650 - val_loss: 0.0431\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0647 - val_loss: 0.0369\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0647 - val_loss: 0.0461\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0648 - val_loss: 0.0487\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0647 - val_loss: 0.0329\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0647 - val_loss: 0.0540\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0648 - val_loss: 0.0403\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0647 - val_loss: 0.0520\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0641 - val_loss: 0.0405\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0555 - val_loss: 0.0256\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0335 - val_loss: 0.0042\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0274 - val_loss: 0.0063\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0511 - val_loss: 0.0513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0674 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0295 - val_loss: 0.0058\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0158 - val_loss: 0.1793\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 10s 2ms/step - loss: 0.1218 - val_loss: 0.0328\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0501 - val_loss: 0.0255\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0396 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0208 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0180 - val_loss: 0.0066\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0140 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0120 - val_loss: 0.0508\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0117 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0116 - val_loss: 0.0163\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0093 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0087 - val_loss: 0.0451\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0083 - val_loss: 0.0045\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0081 - val_loss: 0.0129\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0077 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0080 - val_loss: 0.0100\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0065 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0071 - val_loss: 0.0229\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0065 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0073 - val_loss: 0.0312\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0054 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0072 - val_loss: 0.0046\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0053 - val_loss: 0.0142\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0063 - val_loss: 0.0010\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 11s 3ms/step - loss: 1.3357 - val_loss: 0.9837\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.4958 - val_loss: 0.4048\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.1857 - val_loss: 0.1557\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0839 - val_loss: 0.0589\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0653 - val_loss: 0.0283\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0668 - val_loss: 0.0223\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0673 - val_loss: 0.0254\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0659 - val_loss: 0.0314\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0649 - val_loss: 0.0378\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0647 - val_loss: 0.0421\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0424\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0647 - val_loss: 0.0416\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0647 - val_loss: 0.0412\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0647 - val_loss: 0.0404\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0646 - val_loss: 0.0408\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0646 - val_loss: 0.0411\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0646 - val_loss: 0.0399\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0647 - val_loss: 0.0380\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0385\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0646 - val_loss: 0.0401\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0646 - val_loss: 0.0417\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0647 - val_loss: 0.0425\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0410\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0646 - val_loss: 0.0401\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 11s 3ms/step - loss: 0.1836 - val_loss: 0.0505\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0717 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0746 - val_loss: 0.0291\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0658 - val_loss: 0.0586\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0656 - val_loss: 0.0398\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0646 - val_loss: 0.0330\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0645 - val_loss: 0.0383\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0641 - val_loss: 0.0405\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0634 - val_loss: 0.0379\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0613 - val_loss: 0.0385\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0572 - val_loss: 0.0549\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0510 - val_loss: 0.0196\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0342 - val_loss: 0.0140\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0195 - val_loss: 0.0065\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0152 - val_loss: 0.0279\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0129 - val_loss: 0.0192\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0129 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0083 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0051 - val_loss: 0.0252\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0056 - val_loss: 9.3800e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0037 - val_loss: 9.8016e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 11s 3ms/step - loss: 0.1146 - val_loss: 0.0070\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0144 - val_loss: 0.0116\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0025 - val_loss: 5.6627e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 8.1210e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0018 - val_loss: 5.0424e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0016 - val_loss: 5.1616e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0015 - val_loss: 4.2701e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - -1s -186us/step - loss: 0.0014 - val_loss: 4.7459e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0014 - val_loss: 4.8452e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0014 - val_loss: 5.6912e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0013 - val_loss: 4.6828e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0014 - val_loss: 4.5506e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0013 - val_loss: 4.0634e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0012 - val_loss: 4.4169e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0012 - val_loss: 4.3897e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0012 - val_loss: 3.9523e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 3.9324e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0011 - val_loss: 4.3948e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0012 - val_loss: 4.3294e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0011 - val_loss: 3.8725e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0011 - val_loss: 4.2038e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0012 - val_loss: 3.8856e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 11s 3ms/step - loss: 0.3055 - val_loss: 0.0447\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0393 - val_loss: 0.0390\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0172 - val_loss: 0.0137\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0033 - val_loss: 5.6090e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0027 - val_loss: 8.8712e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0025 - val_loss: 7.9661e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0024 - val_loss: 8.7144e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0021 - val_loss: 6.8757e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0021 - val_loss: 8.1098e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0021 - val_loss: 6.9720e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0020 - val_loss: 8.4455e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0018 - val_loss: 6.3283e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0018 - val_loss: 5.0674e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0017 - val_loss: 6.0518e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0018 - val_loss: 5.6017e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0017 - val_loss: 7.1276e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0016 - val_loss: 4.4613e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0016 - val_loss: 6.1206e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0016 - val_loss: 4.7679e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0016 - val_loss: 4.8253e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0015 - val_loss: 4.6874e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0015 - val_loss: 6.5987e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 11s 3ms/step - loss: 0.4289 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0061 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0201 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0021 - val_loss: 6.8079e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0048 - val_loss: 0.0241\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0090 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0020 - val_loss: 4.7658e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0065 - val_loss: 0.0114\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0049 - val_loss: 9.4556e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0015 - val_loss: 4.7108e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0017 - val_loss: 0.0047\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0027 - val_loss: 0.0055\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0018 - val_loss: 8.3308e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0023 - val_loss: 0.0042\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 11s 3ms/step - loss: 0.0568 - val_loss: 0.0116\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0064 - val_loss: 8.6592e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0080 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0016 - val_loss: 8.3685e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0050 - val_loss: 0.0108\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0030 - val_loss: 6.8996e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0026 - val_loss: 0.0086\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0033 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0016 - val_loss: 5.4757e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0022 - val_loss: 0.0134\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0030 - val_loss: 5.4635e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0016 - val_loss: 0.0095\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0019 - val_loss: 0.0087\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0021 - val_loss: 6.4927e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0010 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0017 - val_loss: 7.1380e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0020 - val_loss: 0.0108\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 12s 3ms/step - loss: 0.0451 - val_loss: 0.0164\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0104 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0058 - val_loss: 0.0138\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0051 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0038 - val_loss: 0.0174\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0074 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0041 - val_loss: 0.0081\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0034 - val_loss: 8.9013e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0037 - val_loss: 0.0082\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0020 - val_loss: 0.0044\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0038 - val_loss: 0.0102\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0024 - val_loss: 7.3726e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0017 - val_loss: 4.7178e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0022 - val_loss: 0.0090\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 9.9798e-04 - val_loss: 4.9924e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0019 - val_loss: 0.0056\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0021 - val_loss: 6.9976e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0011 - val_loss: 6.1115e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 12s 3ms/step - loss: 0.0544 - val_loss: 0.0408\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0190 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0037 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0063 - val_loss: 9.2245e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0079 - val_loss: 0.0104\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0043 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0019 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0021 - val_loss: 0.0048\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0018 - val_loss: 5.1252e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0022 - val_loss: 0.0197\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0052 - val_loss: 7.6367e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0023 - val_loss: 6.1828e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0020 - val_loss: 7.5387e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0015 - val_loss: 9.0890e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0015 - val_loss: 4.5003e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0012 - val_loss: 0.0051\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0028 - val_loss: 8.1293e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0014 - val_loss: 0.0068\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 12s 3ms/step - loss: 0.3155 - val_loss: 0.0171\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0721 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0797 - val_loss: 0.0151\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0108 - val_loss: 0.0861\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0650 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0375 - val_loss: 0.0449\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0136 - val_loss: 0.0631\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0401 - val_loss: 0.0195\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0343 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0181 - val_loss: 0.0561\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0211 - val_loss: 0.0348\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0204 - val_loss: 0.0443\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0187 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0210 - val_loss: 0.0243\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0178 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0132 - val_loss: 0.0585\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0117 - val_loss: 0.0042\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0148 - val_loss: 0.0227\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0131 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0130 - val_loss: 0.0231\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0106 - val_loss: 0.0076\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0115 - val_loss: 0.0225\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0086 - val_loss: 0.0070\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0093 - val_loss: 0.0275\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 13s 3ms/step - loss: 0.0598 - val_loss: 0.0202\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.0076 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 0.0033 - val_loss: 8.9584e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0020 - val_loss: 5.4479e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0018 - val_loss: 5.5665e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0015 - val_loss: 7.9708e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 0.0014 - val_loss: 6.8237e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0013 - val_loss: 8.0346e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0013 - val_loss: 7.2121e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0011 - val_loss: 3.7971e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0011 - val_loss: 4.5109e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0010 - val_loss: 3.6170e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 9.8433e-04 - val_loss: 3.8885e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 0.0010 - val_loss: 4.2899e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 9.5619e-04 - val_loss: 3.8904e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 9.1092e-04 - val_loss: 3.5878e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 8.7608e-04 - val_loss: 3.9746e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 8.6802e-04 - val_loss: 3.4884e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 8.1456e-04 - val_loss: 3.5825e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 8.1763e-04 - val_loss: 6.5137e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 8.1619e-04 - val_loss: 3.4806e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 7.8836e-04 - val_loss: 4.5555e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 7.8395e-04 - val_loss: 3.6975e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 7.5253e-04 - val_loss: 3.5636e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 14s 3ms/step - loss: 0.1592 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0125 - val_loss: 0.0099\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0070 - val_loss: 0.0083\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0033 - val_loss: 4.6925e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0020 - val_loss: 5.6279e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 9.1110e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 9.3380e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0017 - val_loss: 4.7540e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0016 - val_loss: 7.7332e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0015 - val_loss: 6.4389e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0014 - val_loss: 6.2386e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0014 - val_loss: 5.3342e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0013 - val_loss: 5.2623e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0013 - val_loss: 5.6567e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0013 - val_loss: 6.2565e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0012 - val_loss: 4.8800e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0013 - val_loss: 4.4593e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0012 - val_loss: 4.7068e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 5.8083e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0012 - val_loss: 7.0762e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 6.0983e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0011 - val_loss: 6.8055e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 13s 3ms/step - loss: 0.0845 - val_loss: 0.0197\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0148 - val_loss: 0.0105\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 0.0047 - val_loss: 0.0138\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0021 - val_loss: 5.2278e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0015 - val_loss: 5.4692e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0012 - val_loss: 5.8810e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0012 - val_loss: 6.1756e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0011 - val_loss: 6.3947e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0010 - val_loss: 9.2395e-04\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 486us/step - loss: 9.2754e-04 - val_loss: 8.8075e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 9.0538e-04 - val_loss: 7.3681e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 8.8540e-04 - val_loss: 5.5168e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 9.1696e-04 - val_loss: 6.2219e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 8.8932e-04 - val_loss: 8.0325e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 8.5915e-04 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 8.7928e-04 - val_loss: 7.9583e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 8.3022e-04 - val_loss: 7.6365e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 8.3419e-04 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 8.4985e-04 - val_loss: 7.1762e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 8.2425e-04 - val_loss: 6.0682e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 8.0623e-04 - val_loss: 9.6821e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 7.9493e-04 - val_loss: 5.0738e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 8.1173e-04 - val_loss: 5.1647e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 13s 3ms/step - loss: 0.0643 - val_loss: 0.0151\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 0.0131 - val_loss: 0.0075\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 0.0046 - val_loss: 0.0093\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 0.0020 - val_loss: 5.0863e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 0.0014 - val_loss: 5.3629e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 0.0012 - val_loss: 5.0638e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 0.0012 - val_loss: 5.1088e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 0.0011 - val_loss: 5.4039e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 0.0010 - val_loss: 5.4340e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 9.8485e-04 - val_loss: 5.0780e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 9.5103e-04 - val_loss: 5.9125e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 9.2665e-04 - val_loss: 7.9569e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 9.0179e-04 - val_loss: 6.6760e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 9.0224e-04 - val_loss: 4.9320e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 8.7348e-04 - val_loss: 4.9392e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 8.7331e-04 - val_loss: 5.1888e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 8.3173e-04 - val_loss: 9.3423e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 8.3193e-04 - val_loss: 7.4806e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 8.0144e-04 - val_loss: 5.9555e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 7.8170e-04 - val_loss: 4.7775e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 8.4089e-04 - val_loss: 6.8584e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 7.5732e-04 - val_loss: 6.9682e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 7.5654e-04 - val_loss: 6.9789e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 13s 3ms/step - loss: 0.0887 - val_loss: 0.0254\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0141 - val_loss: 0.0087\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0053 - val_loss: 7.5604e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0021 - val_loss: 9.1785e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0018 - val_loss: 8.4576e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0011 - val_loss: 8.9571e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0010 - val_loss: 5.7860e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0010 - val_loss: 5.5748e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 9.3239e-04 - val_loss: 5.0095e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 9.1770e-04 - val_loss: 5.5442e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 9.0220e-04 - val_loss: 4.7427e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 8.8731e-04 - val_loss: 4.4510e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 8.9532e-04 - val_loss: 7.5776e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 8.6371e-04 - val_loss: 7.2422e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 8.7480e-04 - val_loss: 6.6132e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 8.6678e-04 - val_loss: 4.0713e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 8.7310e-04 - val_loss: 4.8067e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 8.7128e-04 - val_loss: 5.5737e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 13s 3ms/step - loss: 0.1000 - val_loss: 0.0166\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0175 - val_loss: 0.0106\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0085 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0036 - val_loss: 6.2960e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0024 - val_loss: 6.7765e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0023 - val_loss: 5.9142e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0019 - val_loss: 8.0364e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0019 - val_loss: 6.0101e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0018 - val_loss: 5.4199e-04\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0017 - val_loss: 5.6277e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0016 - val_loss: 6.5947e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0016 - val_loss: 4.3095e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0016 - val_loss: 9.2046e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0016 - val_loss: 8.1217e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0014 - val_loss: 4.6911e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0014 - val_loss: 4.6503e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0013 - val_loss: 4.2694e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0014 - val_loss: 5.0544e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0013 - val_loss: 4.9065e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0012 - val_loss: 5.3675e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0013 - val_loss: 4.0169e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0012 - val_loss: 4.1264e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 13s 3ms/step - loss: 0.0920 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0128 - val_loss: 0.0098\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0068 - val_loss: 0.0083\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0042 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0025 - val_loss: 5.6130e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0022 - val_loss: 4.9927e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0021 - val_loss: 5.7964e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0019 - val_loss: 4.5823e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0018 - val_loss: 4.4945e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0016 - val_loss: 4.4545e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0016 - val_loss: 4.5928e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0015 - val_loss: 4.3765e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0015 - val_loss: 4.8666e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0015 - val_loss: 5.4906e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0015 - val_loss: 4.2365e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0014 - val_loss: 4.6142e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0014 - val_loss: 4.7557e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0013 - val_loss: 5.4795e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0012 - val_loss: 4.3331e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0013 - val_loss: 4.3088e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0013 - val_loss: 4.2518e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0012 - val_loss: 4.3226e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0012 - val_loss: 4.8992e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 15s 4ms/step - loss: 0.0801 - val_loss: 0.0247\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0126 - val_loss: 7.5693e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0019 - val_loss: 6.0021e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 7.3106e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0014 - val_loss: 9.5195e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 7.5332e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0013 - val_loss: 6.8454e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0012 - val_loss: 4.6373e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0012 - val_loss: 4.5031e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0011 - val_loss: 4.2358e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0011 - val_loss: 4.2836e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0011 - val_loss: 4.1714e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0010 - val_loss: 5.1651e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0011 - val_loss: 4.0904e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0010 - val_loss: 4.3779e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0010 - val_loss: 4.1020e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 9.7454e-04 - val_loss: 4.2752e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 9.3519e-04 - val_loss: 3.9788e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 9.3514e-04 - val_loss: 3.9714e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 9.1121e-04 - val_loss: 4.4718e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 15s 4ms/step - loss: 0.0795 - val_loss: 0.0162\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0106 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0018 - val_loss: 4.2571e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 4.2222e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0015 - val_loss: 4.0505e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0014 - val_loss: 4.6528e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0013 - val_loss: 4.6548e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0013 - val_loss: 3.9736e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0012 - val_loss: 3.9009e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0011 - val_loss: 3.9143e-04\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0011 - val_loss: 5.5192e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0012 - val_loss: 6.2680e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0011 - val_loss: 5.4218e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0011 - val_loss: 4.7248e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0010 - val_loss: 4.0444e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0011 - val_loss: 3.8586e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 9.7653e-04 - val_loss: 4.8769e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 9.5816e-04 - val_loss: 5.0137e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 9.0830e-04 - val_loss: 3.8755e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 9.1197e-04 - val_loss: 5.7639e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 8.8736e-04 - val_loss: 7.8162e-04\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 15s 4ms/step - loss: 0.0742 - val_loss: 0.0143\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0257 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0171 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0117 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0085 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0062 - val_loss: 9.5919e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0049 - val_loss: 8.6049e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0042 - val_loss: 8.2391e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0037 - val_loss: 9.9631e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 15s 4ms/step - loss: 0.0815 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0093 - val_loss: 0.0080\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0048 - val_loss: 7.4753e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0020 - val_loss: 8.2199e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0017 - val_loss: 5.2348e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0016 - val_loss: 4.9946e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0015 - val_loss: 4.8928e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0014 - val_loss: 8.3517e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0013 - val_loss: 9.6777e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0012 - val_loss: 7.1401e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0012 - val_loss: 6.1256e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0011 - val_loss: 5.2837e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0011 - val_loss: 5.0879e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0010 - val_loss: 6.6074e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0011 - val_loss: 6.8180e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 9.9728e-04 - val_loss: 5.6522e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0010 - val_loss: 3.8261e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0010 - val_loss: 4.8942e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 9.6758e-04 - val_loss: 3.7970e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 9.8514e-04 - val_loss: 3.7881e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 9.0555e-04 - val_loss: 5.6619e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 9.2088e-04 - val_loss: 3.9052e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 15s 4ms/step - loss: 0.0953 - val_loss: 0.0253\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 0.0144 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 0.0062 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 397us/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 394us/step - loss: 0.0033 - val_loss: 4.7461e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 393us/step - loss: 0.0027 - val_loss: 4.8851e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 0.0025 - val_loss: 6.3532e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 393us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 394us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 395us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 392us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 399us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 397us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 393us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 388us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 392us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 388us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 395us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 389us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 395us/step - loss: 0.0014 - val_loss: 8.5866e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 392us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 15s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 16s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 16s 4ms/step - loss: 0.0522 - val_loss: 0.0055\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0091 - val_loss: 0.0215\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0066 - val_loss: 7.7757e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0038 - val_loss: 0.0070\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0096 - val_loss: 0.0190\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0059 - val_loss: 0.0122\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0058 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0051 - val_loss: 0.0194\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0066 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0046 - val_loss: 0.0039\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0063 - val_loss: 0.0096\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0056 - val_loss: 0.0061\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0043 - val_loss: 0.0081\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0055 - val_loss: 0.0037\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0054 - val_loss: 0.0126\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0058 - val_loss: 8.7653e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0046 - val_loss: 0.0071\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0055 - val_loss: 0.0083\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 17s 4ms/step - loss: 0.0631 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0060 - val_loss: 0.0235\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0118 - val_loss: 0.0174\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0096 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0050 - val_loss: 0.0105\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0104 - val_loss: 0.0095\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0068 - val_loss: 0.0093\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0078 - val_loss: 0.0216\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0080 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0039 - val_loss: 0.0141\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0075 - val_loss: 0.0131\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0037 - val_loss: 0.0057\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0084 - val_loss: 0.0152\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0064 - val_loss: 0.0123\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0036 - val_loss: 0.0126\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0057 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0049 - val_loss: 0.0071\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0048 - val_loss: 0.0078\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0055 - val_loss: 0.0109\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0060 - val_loss: 6.3522e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 17s 4ms/step - loss: 0.8326 - val_loss: 0.0010\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0036 - val_loss: 9.5918e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0030 - val_loss: 9.4140e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 7.0467e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0292\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0216 - val_loss: 0.0117\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0094 - val_loss: 0.0072\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0127 - val_loss: 0.0348\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0159 - val_loss: 0.0401\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0169 - val_loss: 0.0166\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0125 - val_loss: 0.0268\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0209 - val_loss: 0.0267\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0163 - val_loss: 0.0210\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0120 - val_loss: 0.0288\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0219 - val_loss: 0.0294\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0522 - val_loss: 0.3515\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.2282 - val_loss: 0.1645\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0251 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0011 - val_loss: 8.6939e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0015 - val_loss: 0.0052\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 17s 4ms/step - loss: 3.5713 - val_loss: 3.2124\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 2.1961 - val_loss: 2.1031\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 1.4088 - val_loss: 1.4680\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.9688 - val_loss: 1.0907\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.7073 - val_loss: 0.8456\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.5377 - val_loss: 0.6732\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.4196 - val_loss: 0.5453\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.3337 - val_loss: 0.4493\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.2709 - val_loss: 0.3742\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.2232 - val_loss: 0.3127\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.1856 - val_loss: 0.2629\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.1564 - val_loss: 0.2226\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.1340 - val_loss: 0.1886\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.1161 - val_loss: 0.1608\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.1024 - val_loss: 0.1369\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0915 - val_loss: 0.1161\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0830 - val_loss: 0.1001\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0771 - val_loss: 0.0868\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0728 - val_loss: 0.0754\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0696 - val_loss: 0.0661\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0675 - val_loss: 0.0589\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0662 - val_loss: 0.0526\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0654 - val_loss: 0.0466\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0649 - val_loss: 0.0450\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 17s 4ms/step - loss: 0.0944 - val_loss: 0.0102\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0096 - val_loss: 5.2908e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0026 - val_loss: 5.0698e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0019 - val_loss: 7.1765e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0015 - val_loss: 7.6564e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0014 - val_loss: 6.4309e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 0.0012 - val_loss: 5.4017e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0012 - val_loss: 4.6426e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0012 - val_loss: 5.2986e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0011 - val_loss: 3.8297e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 0.0011 - val_loss: 5.0510e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0011 - val_loss: 5.0752e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 0.0010 - val_loss: 4.4254e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 9.7049e-04 - val_loss: 5.3270e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 9.4505e-04 - val_loss: 4.8866e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 9.8310e-04 - val_loss: 3.6486e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 9.0918e-04 - val_loss: 3.6766e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 9.0455e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 9.7246e-04 - val_loss: 4.3109e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 8.7555e-04 - val_loss: 4.8142e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 9.4013e-04 - val_loss: 7.3615e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 8.1565e-04 - val_loss: 3.5056e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 18s 4ms/step - loss: 0.0838 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0112 - val_loss: 0.0117\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0023 - val_loss: 4.8319e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 5.0931e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0014 - val_loss: 6.5049e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0013 - val_loss: 7.0962e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0013 - val_loss: 6.4036e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0012 - val_loss: 4.3658e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0012 - val_loss: 3.8741e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0011 - val_loss: 4.3675e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 4.0946e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0011 - val_loss: 4.4816e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 3.9866e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0010 - val_loss: 3.7790e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0010 - val_loss: 3.8792e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 9.8703e-04 - val_loss: 4.4620e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 9.8622e-04 - val_loss: 7.1636e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 9.7879e-04 - val_loss: 5.8570e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 9.3533e-04 - val_loss: 4.0952e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 9.0499e-04 - val_loss: 3.9699e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 18s 4ms/step - loss: 0.0554 - val_loss: 0.0182\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0089 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0024 - val_loss: 5.9236e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0014 - val_loss: 9.4526e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0013 - val_loss: 5.2467e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 4.0575e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0011 - val_loss: 4.1436e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0010 - val_loss: 4.6530e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 9.9523e-04 - val_loss: 4.8452e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 9.6194e-04 - val_loss: 3.7199e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 9.4853e-04 - val_loss: 3.4998e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 9.0279e-04 - val_loss: 3.5732e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 8.8448e-04 - val_loss: 4.6123e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 9.1050e-04 - val_loss: 3.6103e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 8.8206e-04 - val_loss: 4.3701e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 9.5731e-04 - val_loss: 4.6740e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 8.3881e-04 - val_loss: 4.7203e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 8.9696e-04 - val_loss: 3.7433e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 8.0934e-04 - val_loss: 3.5402e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 7.8152e-04 - val_loss: 3.8065e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 19s 5ms/step - loss: 0.0653 - val_loss: 0.0010\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0097 - val_loss: 0.0071\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0054 - val_loss: 4.9796e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0034 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.0025 - val_loss: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0022 - val_loss: 7.7310e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 0.0018 - val_loss: 8.3709e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0018 - val_loss: 6.6414e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0015 - val_loss: 7.0719e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0015 - val_loss: 5.9241e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0014 - val_loss: 6.9354e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 9.4350e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0013 - val_loss: 7.5945e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 0.0012 - val_loss: 4.7351e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.0012 - val_loss: 4.0412e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0011 - val_loss: 4.6841e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0011 - val_loss: 5.9876e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0011 - val_loss: 4.1358e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0011 - val_loss: 4.3280e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 0.0011 - val_loss: 7.2029e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 9.8941e-04 - val_loss: 4.0291e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0010 - val_loss: 7.0527e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 9.8301e-04 - val_loss: 4.0827e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 9.3656e-04 - val_loss: 5.5237e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 21s 5ms/step - loss: 0.0947 - val_loss: 0.0347\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0112 - val_loss: 0.0131\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0059 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 0.0026 - val_loss: 6.7338e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0021 - val_loss: 5.7307e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0019 - val_loss: 5.1095e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0017 - val_loss: 7.6422e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0013 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0012 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0011 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 0.0011 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 0.0011 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0010 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 9.5741e-04 - val_loss: 0.0037\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 9.8260e-04 - val_loss: 0.0081\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 20s 5ms/step - loss: 0.0951 - val_loss: 0.0743\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 0.0161 - val_loss: 0.0107\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0140 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 0.0148 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0096 - val_loss: 0.0164\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0106 - val_loss: 0.0186\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0108 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 655us/step - loss: 0.0093 - val_loss: 0.0177\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0075 - val_loss: 0.0169\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 657us/step - loss: 0.0085 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 657us/step - loss: 0.0061 - val_loss: 0.0076\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 659us/step - loss: 0.0099 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 665us/step - loss: 0.0047 - val_loss: 0.0064\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 667us/step - loss: 0.0074 - val_loss: 0.0056\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 663us/step - loss: 0.0059 - val_loss: 5.5041e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 655us/step - loss: 0.0062 - val_loss: 0.0156\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 657us/step - loss: 0.0052 - val_loss: 0.0049\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 669us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 671us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 695us/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 669us/step - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 656us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 663us/step - loss: 0.0058 - val_loss: 6.8205e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 20s 5ms/step - loss: 1.0169 - val_loss: 0.0948\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: 0.2014 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 456us/step - loss: 0.0849 - val_loss: 0.0217\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0660 - val_loss: 0.0372\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0647 - val_loss: 0.0352\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 0.0647 - val_loss: 0.0322\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0648 - val_loss: 0.0350\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 501us/step - loss: 0.0647 - val_loss: 0.0305\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 0.0653 - val_loss: 0.0272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0653 - val_loss: 0.0263\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0653 - val_loss: 0.0581\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0656 - val_loss: 0.0589\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 0.0654 - val_loss: 0.0760\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0623 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 497us/step - loss: 0.0433 - val_loss: 0.0099\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0224 - val_loss: 0.0297\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 0.0180 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0131 - val_loss: 0.0071\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 497us/step - loss: 0.0092 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0106 - val_loss: 0.0134\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0092 - val_loss: 0.0064\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0067 - val_loss: 0.0275\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0081 - val_loss: 0.0100\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0071 - val_loss: 0.0109\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 22s 5ms/step - loss: 0.0671 - val_loss: 0.0146\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 0.0462 - val_loss: 0.0111\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0262 - val_loss: 0.0119\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 0.0139 - val_loss: 0.0156\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 497us/step - loss: 0.0121 - val_loss: 0.0322\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0102 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 504us/step - loss: 0.0074 - val_loss: 0.0199\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0080 - val_loss: 0.0117\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0065 - val_loss: 0.0104\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0085 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0042 - val_loss: 0.0293\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0067 - val_loss: 0.0196\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0066 - val_loss: 0.0140\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0050 - val_loss: 0.0200\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0047 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0061 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0033 - val_loss: 0.0120\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0040 - val_loss: 0.0112\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0040 - val_loss: 0.0104\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0050 - val_loss: 0.0074\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 22s 5ms/step - loss: 0.4918 - val_loss: 0.2136\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0890 - val_loss: 0.0362\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 460us/step - loss: 0.0663 - val_loss: 0.0237\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0661 - val_loss: 0.0314\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 464us/step - loss: 0.0648 - val_loss: 0.0398\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0647 - val_loss: 0.0436\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: 0.0647 - val_loss: 0.0390\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 465us/step - loss: 0.0647 - val_loss: 0.0408\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 465us/step - loss: 0.0647 - val_loss: 0.0397\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0647 - val_loss: 0.0373\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.0647 - val_loss: 0.0408\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 465us/step - loss: 0.0647 - val_loss: 0.0386\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 466us/step - loss: 0.0647 - val_loss: 0.0350\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 466us/step - loss: 0.0647 - val_loss: 0.0416\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 463us/step - loss: 0.0647 - val_loss: 0.0406\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0647 - val_loss: 0.0384\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 464us/step - loss: 0.0647 - val_loss: 0.0410\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 463us/step - loss: 0.0647 - val_loss: 0.0390\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 464us/step - loss: 0.0647 - val_loss: 0.0420\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 465us/step - loss: 0.0647 - val_loss: 0.0333\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0647 - val_loss: 0.0491\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 466us/step - loss: 0.0648 - val_loss: 0.0401\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 466us/step - loss: 0.0647 - val_loss: 0.0386\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: 0.0647 - val_loss: 0.0424\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 22s 5ms/step - loss: 0.0971 - val_loss: 0.0101\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0115 - val_loss: 0.0099\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0047 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 5.0508e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0013 - val_loss: 5.9729e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0012 - val_loss: 8.0311e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0011 - val_loss: 6.2866e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0011 - val_loss: 7.4160e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0011 - val_loss: 6.9809e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0011 - val_loss: 7.1856e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0011 - val_loss: 7.0561e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0010 - val_loss: 5.3893e-04\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0010 - val_loss: 7.8699e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 9.5410e-04 - val_loss: 4.9017e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 9.4849e-04 - val_loss: 6.8829e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 9.2152e-04 - val_loss: 5.3493e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 9.4264e-04 - val_loss: 6.2948e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 9.1739e-04 - val_loss: 5.1880e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 8.9641e-04 - val_loss: 6.4909e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 8.8631e-04 - val_loss: 4.8104e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 8.7409e-04 - val_loss: 5.8856e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 8.7717e-04 - val_loss: 4.9229e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 8.5149e-04 - val_loss: 4.8959e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 21s 5ms/step - loss: 0.0519 - val_loss: 0.0147\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0063 - val_loss: 0.0095\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0025 - val_loss: 4.5424e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0017 - val_loss: 4.2215e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0015 - val_loss: 4.1921e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0013 - val_loss: 4.6917e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0011 - val_loss: 4.1924e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0012 - val_loss: 6.5216e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0011 - val_loss: 7.5056e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0010 - val_loss: 3.7955e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0010 - val_loss: 3.7522e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0010 - val_loss: 4.0600e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 9.6807e-04 - val_loss: 3.5923e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 9.5143e-04 - val_loss: 6.2297e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 9.2278e-04 - val_loss: 4.7050e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 8.9756e-04 - val_loss: 4.3356e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 8.1619e-04 - val_loss: 3.5367e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 8.7579e-04 - val_loss: 3.5095e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 8.3710e-04 - val_loss: 5.8086e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 8.0182e-04 - val_loss: 4.5894e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 8.4018e-04 - val_loss: 3.8256e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 7.6494e-04 - val_loss: 3.5168e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.7586e-04 - val_loss: 3.9960e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 23s 6ms/step - loss: 0.0950 - val_loss: 0.0182\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0121 - val_loss: 7.1781e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0030 - val_loss: 7.1970e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0016 - val_loss: 6.3305e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0014 - val_loss: 5.6102e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0014 - val_loss: 4.9615e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0013 - val_loss: 6.1582e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0012 - val_loss: 5.2735e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0011 - val_loss: 4.5237e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0011 - val_loss: 6.2925e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0011 - val_loss: 5.6418e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0010 - val_loss: 4.4163e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.4754e-04 - val_loss: 4.3148e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 9.4963e-04 - val_loss: 5.3415e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 9.0962e-04 - val_loss: 6.9028e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 9.5164e-04 - val_loss: 3.5739e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 9.4505e-04 - val_loss: 3.5898e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 8.4014e-04 - val_loss: 5.3638e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 8.8467e-04 - val_loss: 3.8607e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 8.9130e-04 - val_loss: 3.5223e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 7.9942e-04 - val_loss: 3.5829e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 23s 5ms/step - loss: 0.1190 - val_loss: 0.0135\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 461us/step - loss: 0.0114 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 458us/step - loss: 0.0063 - val_loss: 0.0095\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 456us/step - loss: 0.0040 - val_loss: 7.4653e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 460us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 461us/step - loss: 0.0022 - val_loss: 5.5283e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 452us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 459us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0017 - val_loss: 5.6392e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 456us/step - loss: 0.0015 - val_loss: 6.4392e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0016 - val_loss: 5.5918e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 455us/step - loss: 0.0015 - val_loss: 6.7679e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0014 - val_loss: 6.2051e-04\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0014 - val_loss: 9.2464e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0014 - val_loss: 8.9555e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0014 - val_loss: 7.0618e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 456us/step - loss: 0.0013 - val_loss: 4.9857e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0013 - val_loss: 5.8359e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0012 - val_loss: 6.5546e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 455us/step - loss: 0.0012 - val_loss: 4.5396e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 458us/step - loss: 0.0011 - val_loss: 4.1276e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 457us/step - loss: 0.0012 - val_loss: 3.9461e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 464us/step - loss: 0.0011 - val_loss: 4.3346e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 24s 6ms/step - loss: 0.0603 - val_loss: 0.0179\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0094 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0047 - val_loss: 0.0082\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0023 - val_loss: 5.3627e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 458us/step - loss: 0.0016 - val_loss: 9.5350e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.0015 - val_loss: 8.5104e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0014 - val_loss: 9.0885e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 460us/step - loss: 0.0013 - val_loss: 9.2338e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0013 - val_loss: 9.7352e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0012 - val_loss: 5.2545e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 455us/step - loss: 0.0012 - val_loss: 4.1057e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 458us/step - loss: 0.0011 - val_loss: 5.7669e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 455us/step - loss: 0.0011 - val_loss: 6.3307e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 452us/step - loss: 0.0011 - val_loss: 6.3368e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0010 - val_loss: 8.6338e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 455us/step - loss: 0.0010 - val_loss: 6.0111e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 9.6700e-04 - val_loss: 4.1984e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 452us/step - loss: 9.6237e-04 - val_loss: 4.8501e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 9.0231e-04 - val_loss: 4.3626e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 9.0146e-04 - val_loss: 3.9930e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 25s 6ms/step - loss: 0.0496 - val_loss: 0.0094\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0078 - val_loss: 5.8156e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0034 - val_loss: 8.1854e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0025 - val_loss: 4.8080e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0021 - val_loss: 8.9471e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 0.0014 - val_loss: 6.4352e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 0.0013 - val_loss: 5.1481e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 0.0012 - val_loss: 5.2051e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 0.0012 - val_loss: 3.8417e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0012 - val_loss: 3.9882e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 5.0768e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0011 - val_loss: 4.6215e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 9.2506e-04 - val_loss: 4.2676e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 9.6163e-04 - val_loss: 4.1364e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 9.6868e-04 - val_loss: 7.9439e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 9.1924e-04 - val_loss: 4.2159e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 9.5570e-04 - val_loss: 3.8718e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 9.1212e-04 - val_loss: 7.4690e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 8.6338e-04 - val_loss: 6.5967e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 8.8287e-04 - val_loss: 4.2064e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 8.0883e-04 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 9.5117e-04 - val_loss: 5.8805e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 9.1247e-04 - val_loss: 0.0015\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 23s 6ms/step - loss: 0.0853 - val_loss: 0.0255\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0293 - val_loss: 0.0120\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0232 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0187 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0147 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0116 - val_loss: 0.0035\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0090 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0070 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0055 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0045 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0035 - val_loss: 8.5540e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0030 - val_loss: 7.7610e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0025 - val_loss: 7.4446e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0021 - val_loss: 7.5198e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0020 - val_loss: 7.4140e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0020 - val_loss: 7.6827e-04\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0018 - val_loss: 7.8333e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 8.1055e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0017 - val_loss: 8.8992e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0017 - val_loss: 9.6610e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0017 - val_loss: 8.0893e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0017 - val_loss: 9.5190e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0016 - val_loss: 8.8777e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0017 - val_loss: 9.1062e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 22s 5ms/step - loss: 1.5898 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0045 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0023 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0018 - val_loss: 8.9595e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 509us/step - loss: 0.0018 - val_loss: 8.5903e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 505us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0018 - val_loss: 9.6729e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0017 - val_loss: 8.7438e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 0.0016 - val_loss: 9.7186e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 504us/step - loss: 0.0016 - val_loss: 8.0620e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 0.0016 - val_loss: 8.6798e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 0.0016 - val_loss: 8.1744e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 510us/step - loss: 0.0015 - val_loss: 8.1478e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 0.0015 - val_loss: 8.0305e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 0.0015 - val_loss: 7.8068e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0015 - val_loss: 9.6749e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 23s 5ms/step - loss: 0.0773 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0070 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0016 - val_loss: 7.9038e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0013 - val_loss: 6.7586e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 0.0011 - val_loss: 4.7953e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0036 - val_loss: 0.0069\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0036 - val_loss: 0.0078\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0026 - val_loss: 0.0046\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 0.0025 - val_loss: 7.0721e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0020 - val_loss: 0.0066\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 0.0042 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 0.0011 - val_loss: 7.2917e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0019 - val_loss: 0.0078\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0030 - val_loss: 5.6918e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 8.5780e-04 - val_loss: 7.5131e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 8.1708e-04 - val_loss: 3.6302e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 9.9817e-04 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0037 - val_loss: 0.0094\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 24s 6ms/step - loss: 0.0707 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0019 - val_loss: 5.2643e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0097 - val_loss: 0.0196\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0102 - val_loss: 0.0072\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0054 - val_loss: 0.0243\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0106 - val_loss: 0.0054\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0060 - val_loss: 0.0121\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0077 - val_loss: 0.0083\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0063 - val_loss: 0.0060\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0066 - val_loss: 0.0108\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0088 - val_loss: 0.0073\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0053 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0070 - val_loss: 0.0041\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0041 - val_loss: 0.0173\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0085 - val_loss: 0.0083\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0069 - val_loss: 0.0087\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0070 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0046 - val_loss: 0.0047\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0048 - val_loss: 0.0068\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0062 - val_loss: 0.0083\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0054 - val_loss: 0.0041\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 24s 6ms/step - loss: 0.0612 - val_loss: 0.0243\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0107 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0028 - val_loss: 5.2421e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0014 - val_loss: 6.5007e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0013 - val_loss: 5.5005e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0013 - val_loss: 4.6711e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0013 - val_loss: 4.3391e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0012 - val_loss: 4.2771e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0011 - val_loss: 3.8950e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0011 - val_loss: 4.0717e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0012 - val_loss: 3.7856e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0010 - val_loss: 4.0188e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0010 - val_loss: 3.9490e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 9.6547e-04 - val_loss: 3.7973e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 9.6181e-04 - val_loss: 3.9451e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 9.1262e-04 - val_loss: 3.6747e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 9.7160e-04 - val_loss: 4.4535e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 9.0954e-04 - val_loss: 4.9403e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 8.8203e-04 - val_loss: 4.0549e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 9.2618e-04 - val_loss: 3.9624e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 8.6367e-04 - val_loss: 0.0010\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 25s 6ms/step - loss: 0.0620 - val_loss: 0.0159\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0084 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0039 - val_loss: 6.6423e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0026 - val_loss: 6.8689e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0020 - val_loss: 5.3335e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0017 - val_loss: 9.9861e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0013 - val_loss: 8.5554e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0012 - val_loss: 6.0777e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0011 - val_loss: 6.0809e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0011 - val_loss: 7.4526e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0011 - val_loss: 8.1326e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0011 - val_loss: 5.1629e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0010 - val_loss: 4.3303e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 9.4203e-04 - val_loss: 3.7808e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 9.0375e-04 - val_loss: 4.2670e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 9.5580e-04 - val_loss: 5.4618e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 8.8675e-04 - val_loss: 4.2432e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 8.9899e-04 - val_loss: 4.4200e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 8.2820e-04 - val_loss: 4.0426e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 8.6108e-04 - val_loss: 3.6621e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 8.0843e-04 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 9.0742e-04 - val_loss: 4.7483e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 8.3384e-04 - val_loss: 7.3599e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 25s 6ms/step - loss: 0.0416 - val_loss: 0.0181\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0084 - val_loss: 4.9891e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0016 - val_loss: 8.1838e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0014 - val_loss: 5.9708e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0013 - val_loss: 6.3798e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0012 - val_loss: 5.4834e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0012 - val_loss: 6.7792e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0011 - val_loss: 4.5864e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0011 - val_loss: 3.7711e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0011 - val_loss: 4.7496e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0010 - val_loss: 3.7340e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0010 - val_loss: 7.2358e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0011 - val_loss: 4.0202e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 9.3957e-04 - val_loss: 3.8873e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 9.4442e-04 - val_loss: 5.5557e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 9.0884e-04 - val_loss: 4.5823e-04\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 449us/step - loss: 9.7353e-04 - val_loss: 3.9540e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 9.6230e-04 - val_loss: 6.6260e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 8.8581e-04 - val_loss: 3.5845e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 25s 6ms/step - loss: 0.1034 - val_loss: 0.0209\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0150 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0022 - val_loss: 4.8823e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0019 - val_loss: 4.7788e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0017 - val_loss: 4.6741e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0017 - val_loss: 4.7131e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0016 - val_loss: 5.0035e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0016 - val_loss: 5.2016e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0015 - val_loss: 5.5498e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0015 - val_loss: 7.8482e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0015 - val_loss: 5.3768e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0014 - val_loss: 4.3829e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0013 - val_loss: 4.3831e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0012 - val_loss: 5.6640e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0012 - val_loss: 6.6757e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0013 - val_loss: 5.0874e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0012 - val_loss: 8.9887e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0012 - val_loss: 8.4453e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0012 - val_loss: 5.8770e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 397us/step - loss: 0.0011 - val_loss: 5.7103e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0011 - val_loss: 4.9026e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 25s 6ms/step - loss: 0.1971 - val_loss: 0.0104\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0239 - val_loss: 0.0162\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0103 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0037 - val_loss: 9.8292e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 0.0022 - val_loss: 4.5338e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0022 - val_loss: 4.1146e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0019 - val_loss: 4.4155e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0019 - val_loss: 6.6808e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0018 - val_loss: 4.5381e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0016 - val_loss: 4.0499e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0015 - val_loss: 4.0849e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 0.0016 - val_loss: 3.9126e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0015 - val_loss: 4.1163e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0014 - val_loss: 4.2049e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0014 - val_loss: 3.9707e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0013 - val_loss: 3.9846e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0013 - val_loss: 4.0317e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0013 - val_loss: 4.0713e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0012 - val_loss: 4.1483e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 401us/step - loss: 0.0013 - val_loss: 4.1857e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0013 - val_loss: 4.5157e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 25s 6ms/step - loss: 0.1941 - val_loss: 0.0645\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0307 - val_loss: 0.0136\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0088 - val_loss: 5.7535e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0046 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 401us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0017 - val_loss: 5.2766e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0015 - val_loss: 4.5705e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 400us/step - loss: 0.0014 - val_loss: 8.0945e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0013 - val_loss: 4.9261e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 0.0012 - val_loss: 5.7799e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0012 - val_loss: 4.3540e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0012 - val_loss: 5.6995e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0012 - val_loss: 4.3736e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 0.0011 - val_loss: 4.4497e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0011 - val_loss: 4.3503e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 399us/step - loss: 0.0011 - val_loss: 4.2469e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0010 - val_loss: 4.9133e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0010 - val_loss: 4.2517e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0010 - val_loss: 4.1451e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 9.9259e-04 - val_loss: 4.1062e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 9.7916e-04 - val_loss: 4.2010e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 9.4691e-04 - val_loss: 4.0999e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 403us/step - loss: 9.1249e-04 - val_loss: 4.2367e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 25s 6ms/step - loss: 0.0554 - val_loss: 0.0274\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0101 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0027 - val_loss: 9.9803e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0014 - val_loss: 5.6336e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 0.0013 - val_loss: 6.1145e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0013 - val_loss: 7.7102e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0012 - val_loss: 7.7678e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 0.0012 - val_loss: 4.5714e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0011 - val_loss: 5.8153e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0010 - val_loss: 5.0422e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0010 - val_loss: 5.2608e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 9.7316e-04 - val_loss: 4.4589e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 9.9216e-04 - val_loss: 4.4570e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0010 - val_loss: 4.2715e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 9.6039e-04 - val_loss: 4.5288e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 9.5360e-04 - val_loss: 4.3140e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 8.8518e-04 - val_loss: 4.9796e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 8.5249e-04 - val_loss: 4.0899e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 8.5415e-04 - val_loss: 4.0405e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 8.6495e-04 - val_loss: 9.0252e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 9.6654e-04 - val_loss: 4.0013e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 26s 6ms/step - loss: 0.1031 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0134 - val_loss: 0.0078\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 399us/step - loss: 0.0073 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0037 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0027 - val_loss: 6.8297e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0020 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0018 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0018 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0017 - val_loss: 0.0043\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0018 - val_loss: 0.0050\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 0.0016 - val_loss: 0.0045\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 0.0015 - val_loss: 0.0035\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 27s 7ms/step - loss: 0.1116 - val_loss: 7.1868e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0039 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0038 - val_loss: 4.3947e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0034 - val_loss: 5.6087e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0013 - val_loss: 7.0994e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0037 - val_loss: 4.1617e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0014 - val_loss: 4.2148e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0012 - val_loss: 7.7278e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0024 - val_loss: 0.0128\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0041 - val_loss: 9.5481e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0013 - val_loss: 4.1870e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0014 - val_loss: 4.8890e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0010 - val_loss: 7.7991e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0019 - val_loss: 0.0156\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0053 - val_loss: 6.8013e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0011 - val_loss: 7.2790e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0018 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0032 - val_loss: 6.7799e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 27s 7ms/step - loss: 0.0416 - val_loss: 0.0128\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0074 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0033 - val_loss: 5.5292e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0022 - val_loss: 5.5318e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0017 - val_loss: 5.2766e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0014 - val_loss: 4.4224e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0014 - val_loss: 6.1122e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0012 - val_loss: 5.0140e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0011 - val_loss: 3.7726e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0011 - val_loss: 3.7323e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 9.8291e-04 - val_loss: 3.5180e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 9.6080e-04 - val_loss: 4.5756e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 9.4658e-04 - val_loss: 4.8942e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 9.2908e-04 - val_loss: 3.7094e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 8.8994e-04 - val_loss: 4.6530e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 8.6819e-04 - val_loss: 4.1779e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 8.3238e-04 - val_loss: 3.3855e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 8.5470e-04 - val_loss: 3.5112e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 8.0806e-04 - val_loss: 4.7734e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 7.9090e-04 - val_loss: 3.3385e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 7.8541e-04 - val_loss: 4.5719e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 8.1160e-04 - val_loss: 5.3930e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 8.7612e-04 - val_loss: 3.3283e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 7.9939e-04 - val_loss: 4.0169e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 28s 7ms/step - loss: 0.0518 - val_loss: 0.0164\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0084 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0020 - val_loss: 8.2651e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0016 - val_loss: 7.4817e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0014 - val_loss: 6.6359e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0012 - val_loss: 5.3020e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0012 - val_loss: 4.7948e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0011 - val_loss: 4.4049e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0011 - val_loss: 4.2479e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 5.7332e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0011 - val_loss: 4.9512e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0010 - val_loss: 4.2434e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 9.6269e-04 - val_loss: 6.4708e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 9.4683e-04 - val_loss: 5.1150e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 8.8722e-04 - val_loss: 4.6657e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 8.7557e-04 - val_loss: 4.3859e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 8.4983e-04 - val_loss: 5.3584e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 8.4170e-04 - val_loss: 4.4795e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 8.5707e-04 - val_loss: 7.1170e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 8.5508e-04 - val_loss: 5.4759e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 7.9190e-04 - val_loss: 4.9027e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 28s 7ms/step - loss: 0.2477 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0787 - val_loss: 0.0528\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0695 - val_loss: 0.0857\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0718 - val_loss: 0.0636\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0657 - val_loss: 0.0386\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0649 - val_loss: 0.0316\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0651 - val_loss: 0.0363\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0646 - val_loss: 0.0432\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0648 - val_loss: 0.0446\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0647 - val_loss: 0.0419\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0397\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0646 - val_loss: 0.0393\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0646 - val_loss: 0.0392\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0647 - val_loss: 0.0394\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0381\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0390\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0646 - val_loss: 0.0426\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0647 - val_loss: 0.0395\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0646 - val_loss: 0.0428\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0646 - val_loss: 0.0399\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0643 - val_loss: 0.0387\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0630 - val_loss: 0.0363\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0607 - val_loss: 0.0308\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0538 - val_loss: 0.0189\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 29s 7ms/step - loss: 0.0563 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0085 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0049 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0024 - val_loss: 5.0624e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0017 - val_loss: 8.6232e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 4.7455e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0016 - val_loss: 6.5585e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0016 - val_loss: 8.9119e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0015 - val_loss: 5.8055e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0015 - val_loss: 4.0183e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0014 - val_loss: 4.4701e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0013 - val_loss: 4.5944e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0013 - val_loss: 4.7219e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0012 - val_loss: 4.3253e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0012 - val_loss: 4.4511e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0011 - val_loss: 4.4739e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0011 - val_loss: 6.5162e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0011 - val_loss: 9.4294e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0011 - val_loss: 4.2145e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0010 - val_loss: 9.2595e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0011 - val_loss: 4.1819e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 29s 7ms/step - loss: 0.1100 - val_loss: 0.0278\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0127 - val_loss: 7.0482e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0032 - val_loss: 5.8657e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0021 - val_loss: 7.8279e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0018 - val_loss: 4.7159e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0015 - val_loss: 6.5861e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0014 - val_loss: 4.4717e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0013 - val_loss: 8.4312e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0012 - val_loss: 7.3928e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0012 - val_loss: 5.2130e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0011 - val_loss: 4.5409e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0011 - val_loss: 4.2572e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0010 - val_loss: 4.3119e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0010 - val_loss: 4.4854e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0010 - val_loss: 4.4283e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0010 - val_loss: 5.1818e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 9.1879e-04 - val_loss: 5.2646e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 9.2033e-04 - val_loss: 4.5285e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 9.1214e-04 - val_loss: 3.6075e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 9.3215e-04 - val_loss: 3.6330e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 30s 7ms/step - loss: 0.0391 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0065 - val_loss: 5.6075e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0032 - val_loss: 8.7743e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0017 - val_loss: 5.1125e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0014 - val_loss: 5.2641e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0013 - val_loss: 7.1096e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0012 - val_loss: 5.0760e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0011 - val_loss: 5.4973e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0011 - val_loss: 6.5693e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0011 - val_loss: 6.7645e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0010 - val_loss: 6.0289e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0010 - val_loss: 4.3696e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 9.7869e-04 - val_loss: 4.3093e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 9.2729e-04 - val_loss: 6.0471e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 9.1883e-04 - val_loss: 4.9036e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 8.8173e-04 - val_loss: 5.5698e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 8.5857e-04 - val_loss: 3.7519e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 8.8232e-04 - val_loss: 4.0635e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 8.2029e-04 - val_loss: 3.6198e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 8.2288e-04 - val_loss: 5.4982e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 8.2642e-04 - val_loss: 3.5585e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 8.2513e-04 - val_loss: 5.3324e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 29s 7ms/step - loss: 0.0440 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0023 - val_loss: 8.5693e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0019 - val_loss: 4.4216e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0018 - val_loss: 7.7518e-04\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0016 - val_loss: 5.7518e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0015 - val_loss: 4.1005e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0014 - val_loss: 5.2951e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0014 - val_loss: 7.4097e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0013 - val_loss: 5.1579e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0013 - val_loss: 4.0350e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0013 - val_loss: 3.9773e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0013 - val_loss: 3.8109e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0013 - val_loss: 3.8248e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 3.7265e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0011 - val_loss: 3.7759e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0012 - val_loss: 5.4606e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0012 - val_loss: 4.5715e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0011 - val_loss: 4.2916e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0011 - val_loss: 4.8331e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 9.9340e-04 - val_loss: 4.8749e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0010 - val_loss: 5.5996e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0010 - val_loss: 4.1260e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 30s 7ms/step - loss: 0.0674 - val_loss: 0.0310\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0111 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0047 - val_loss: 5.4902e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0030 - val_loss: 5.5399e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0020 - val_loss: 4.2984e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 0.0019 - val_loss: 5.9171e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0017 - val_loss: 8.5336e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0016 - val_loss: 5.3232e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0015 - val_loss: 4.9126e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0015 - val_loss: 4.5133e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0015 - val_loss: 4.0007e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0013 - val_loss: 4.0848e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0013 - val_loss: 4.9461e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0012 - val_loss: 4.5905e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0012 - val_loss: 5.4515e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0012 - val_loss: 5.3295e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0012 - val_loss: 4.5273e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0012 - val_loss: 3.9590e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0011 - val_loss: 3.9023e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0011 - val_loss: 3.9266e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0011 - val_loss: 7.6517e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0012 - val_loss: 7.1033e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0011 - val_loss: 3.6966e-04\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 30s 7ms/step - loss: 0.0859 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0104 - val_loss: 0.0125\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 452us/step - loss: 0.0059 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 455us/step - loss: 0.0029 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0025 - val_loss: 5.2227e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 452us/step - loss: 0.0019 - val_loss: 6.5122e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0017 - val_loss: 9.2258e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0016 - val_loss: 7.4236e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 457us/step - loss: 0.0015 - val_loss: 8.2739e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0014 - val_loss: 5.4476e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0014 - val_loss: 5.0529e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 455us/step - loss: 0.0014 - val_loss: 4.9075e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0014 - val_loss: 5.2357e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0013 - val_loss: 4.6838e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 452us/step - loss: 0.0013 - val_loss: 4.4131e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0012 - val_loss: 5.7986e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0012 - val_loss: 6.2239e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0012 - val_loss: 4.9286e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0011 - val_loss: 3.8797e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0011 - val_loss: 4.9261e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0011 - val_loss: 5.8856e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0010 - val_loss: 4.8498e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 9.9204e-04 - val_loss: 5.9114e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 9.9580e-04 - val_loss: 4.2163e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 31s 8ms/step - loss: 0.0454 - val_loss: 0.0149\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0069 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0034 - val_loss: 4.7029e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0020 - val_loss: 6.8921e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0018 - val_loss: 4.4648e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0015 - val_loss: 8.9348e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0012 - val_loss: 9.3913e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0012 - val_loss: 8.6744e-04\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0012 - val_loss: 6.0471e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0011 - val_loss: 6.0947e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0011 - val_loss: 5.2527e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0010 - val_loss: 4.1810e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 9.6199e-04 - val_loss: 4.2099e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 9.3809e-04 - val_loss: 3.5439e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 9.5752e-04 - val_loss: 3.5355e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 9.2853e-04 - val_loss: 4.4103e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 9.3794e-04 - val_loss: 5.6737e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 7.9602e-04 - val_loss: 3.5038e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 8.5916e-04 - val_loss: 4.2480e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 8.6858e-04 - val_loss: 4.4570e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 8.2608e-04 - val_loss: 3.4601e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 7.9038e-04 - val_loss: 4.0185e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 7.9580e-04 - val_loss: 3.5492e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 7.6280e-04 - val_loss: 3.4347e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 31s 8ms/step - loss: 0.1032 - val_loss: 0.0141\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0134 - val_loss: 0.0099\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0064 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0034 - val_loss: 7.3747e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0025 - val_loss: 5.3269e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0023 - val_loss: 6.6570e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0019 - val_loss: 6.6357e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0019 - val_loss: 9.9860e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0018 - val_loss: 6.7142e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0019 - val_loss: 7.2722e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0018 - val_loss: 6.7212e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0018 - val_loss: 7.0560e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0018 - val_loss: 8.2134e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0017 - val_loss: 5.6213e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0017 - val_loss: 7.4541e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0017 - val_loss: 5.5183e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0017 - val_loss: 8.9534e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0015 - val_loss: 5.0968e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0016 - val_loss: 7.7624e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0016 - val_loss: 5.4359e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0015 - val_loss: 5.9749e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 33s 8ms/step - loss: 0.2187 - val_loss: 0.0411\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0170 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0074 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0043 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0038 - val_loss: 7.1459e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0021 - val_loss: 8.4596e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0020 - val_loss: 9.0740e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0019 - val_loss: 9.2048e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0019 - val_loss: 9.5478e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0018 - val_loss: 8.4516e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0018 - val_loss: 9.6386e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0017 - val_loss: 6.5697e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0017 - val_loss: 9.4212e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0017 - val_loss: 7.0485e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0017 - val_loss: 7.8985e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0016 - val_loss: 6.7306e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 33s 8ms/step - loss: 1.2372 - val_loss: 0.0181\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0484 - val_loss: 0.0078\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0217 - val_loss: 9.0422e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0083 - val_loss: 0.0089\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0058 - val_loss: 8.6810e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0051 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0044 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0038 - val_loss: 7.4756e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0038 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0035 - val_loss: 7.7434e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0035 - val_loss: 8.9286e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0032 - val_loss: 8.5176e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0031 - val_loss: 7.6285e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0032 - val_loss: 8.9486e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0030 - val_loss: 7.2909e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0029 - val_loss: 7.6773e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0028 - val_loss: 6.7538e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0029 - val_loss: 8.3164e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0027 - val_loss: 6.5610e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0027 - val_loss: 6.3137e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0027 - val_loss: 6.6502e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0027 - val_loss: 5.7451e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 34s 8ms/step - loss: 0.5127 - val_loss: 0.0612\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0212 - val_loss: 0.0120\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0083 - val_loss: 4.8119e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0051 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0037 - val_loss: 4.4934e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0031 - val_loss: 9.4280e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0028 - val_loss: 4.3725e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0026 - val_loss: 5.7612e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0026 - val_loss: 4.2396e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0024 - val_loss: 5.0205e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0025 - val_loss: 4.3170e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0023 - val_loss: 5.0679e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0023 - val_loss: 5.4333e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0023 - val_loss: 4.6923e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0022 - val_loss: 5.1691e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0021 - val_loss: 5.6906e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0021 - val_loss: 4.7282e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0021 - val_loss: 5.1111e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0021 - val_loss: 5.3321e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0020 - val_loss: 4.8407e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0020 - val_loss: 6.4824e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0020 - val_loss: 5.4298e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0019 - val_loss: 6.2423e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0021 - val_loss: 5.4932e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 35s 8ms/step - loss: 2.9808 - val_loss: 0.1825\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0791 - val_loss: 0.0390\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0239 - val_loss: 0.0089\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0111 - val_loss: 0.0076\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0074 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0056 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0050 - val_loss: 7.3846e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0047 - val_loss: 7.8420e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0042 - val_loss: 8.4276e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0044 - val_loss: 7.4190e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0039 - val_loss: 6.6477e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0040 - val_loss: 6.6847e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0038 - val_loss: 6.5312e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0036 - val_loss: 6.8351e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0036 - val_loss: 6.6532e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0037 - val_loss: 6.4107e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0032 - val_loss: 7.4811e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0033 - val_loss: 6.7678e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0033 - val_loss: 7.2796e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0033 - val_loss: 6.5727e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0032 - val_loss: 7.2111e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 0.0031 - val_loss: 7.1509e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0030 - val_loss: 6.8425e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 34s 8ms/step - loss: 0.0962 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0079 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0046 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0022 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0017 - val_loss: 6.0796e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0023 - val_loss: 0.0059\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0055 - val_loss: 0.0189\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0055 - val_loss: 9.4319e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0013 - val_loss: 8.5509e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 9.1797e-04 - val_loss: 7.2168e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0035 - val_loss: 0.0122\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0017 - val_loss: 3.5757e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 8.6654e-04 - val_loss: 3.5919e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 35s 8ms/step - loss: 0.0664 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0088 - val_loss: 0.0155\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0089 - val_loss: 0.0173\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0068 - val_loss: 0.0079\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0086 - val_loss: 0.0121\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0069 - val_loss: 0.0122\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0078 - val_loss: 0.0146\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0069 - val_loss: 0.0110\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0084 - val_loss: 0.0092\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0076 - val_loss: 0.0130\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0085 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0049 - val_loss: 0.0131\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0074 - val_loss: 0.0078\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0075 - val_loss: 0.0152\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0078 - val_loss: 0.0081\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0064 - val_loss: 0.0082\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0052 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0045 - val_loss: 0.0102\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0073 - val_loss: 0.0179\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0089 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0028 - val_loss: 0.0068\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0059 - val_loss: 0.0042\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 36s 9ms/step - loss: 0.0326 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0064 - val_loss: 7.0372e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0042 - val_loss: 6.2581e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0020 - val_loss: 5.9043e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0013 - val_loss: 6.3291e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0012 - val_loss: 4.7166e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0010 - val_loss: 7.9025e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 9.8529e-04 - val_loss: 6.4939e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 9.9274e-04 - val_loss: 5.1428e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 9.5179e-04 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 9.8309e-04 - val_loss: 4.3733e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 9.5769e-04 - val_loss: 7.1595e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 8.7921e-04 - val_loss: 7.8202e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 8.3718e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 9.1991e-04 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 8.0711e-04 - val_loss: 4.6652e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 7.9458e-04 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 8.7813e-04 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.7560e-04 - val_loss: 3.9890e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 37s 9ms/step - loss: 0.0852 - val_loss: 0.0069\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0090 - val_loss: 0.0056\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0049 - val_loss: 0.0089\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0029 - val_loss: 8.0871e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0020 - val_loss: 5.3794e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0014 - val_loss: 7.2209e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0012 - val_loss: 4.1240e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0012 - val_loss: 5.0734e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0011 - val_loss: 5.0945e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0011 - val_loss: 5.6244e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0010 - val_loss: 5.3343e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 9.6487e-04 - val_loss: 3.7152e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 9.5642e-04 - val_loss: 3.7582e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 9.4513e-04 - val_loss: 3.6864e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 9.2512e-04 - val_loss: 5.2933e-04\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 610us/step - loss: 8.7917e-04 - val_loss: 5.9768e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 8.8440e-04 - val_loss: 4.7825e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 8.6560e-04 - val_loss: 3.7711e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 8.3223e-04 - val_loss: 5.4816e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 8.5910e-04 - val_loss: 4.0740e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 7.8341e-04 - val_loss: 3.5454e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 8.0497e-04 - val_loss: 3.4796e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 37s 9ms/step - loss: 0.0487 - val_loss: 0.0127\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0067 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0028 - val_loss: 5.5331e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0016 - val_loss: 4.8920e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0013 - val_loss: 5.2388e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0012 - val_loss: 7.5257e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0011 - val_loss: 8.2118e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 9.4348e-04 - val_loss: 8.9354e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 9.0972e-04 - val_loss: 7.9151e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 8.3943e-04 - val_loss: 7.6435e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 8.6974e-04 - val_loss: 4.1753e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 8.1620e-04 - val_loss: 3.7924e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.8169e-04 - val_loss: 4.5768e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 8.2290e-04 - val_loss: 3.8217e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 7.3977e-04 - val_loss: 3.9600e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 7.1990e-04 - val_loss: 3.7960e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 6.4408e-04 - val_loss: 4.0549e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 6.6763e-04 - val_loss: 4.3113e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 6.8918e-04 - val_loss: 3.6423e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 6.3739e-04 - val_loss: 3.5113e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 6.2056e-04 - val_loss: 4.2777e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 6.1805e-04 - val_loss: 3.7358e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 6.2893e-04 - val_loss: 3.4804e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 6.5237e-04 - val_loss: 3.4189e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 36s 9ms/step - loss: 0.0450 - val_loss: 0.0160\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0065 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0020 - val_loss: 4.2819e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0015 - val_loss: 4.5773e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0013 - val_loss: 4.8091e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0012 - val_loss: 7.0691e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0011 - val_loss: 3.9839e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0010 - val_loss: 3.4246e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 9.5291e-04 - val_loss: 3.3811e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 9.9301e-04 - val_loss: 4.6420e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 9.2495e-04 - val_loss: 3.3506e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 9.3211e-04 - val_loss: 6.0575e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 9.8102e-04 - val_loss: 3.6745e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 8.3265e-04 - val_loss: 3.2200e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 7.9836e-04 - val_loss: 4.8781e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 7.9244e-04 - val_loss: 3.2385e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.7751e-04 - val_loss: 3.4358e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 7.8622e-04 - val_loss: 3.2313e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.3694e-04 - val_loss: 7.5150e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 7.9181e-04 - val_loss: 3.1222e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 7.3080e-04 - val_loss: 3.0955e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 7.3075e-04 - val_loss: 3.0978e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 7.6397e-04 - val_loss: 4.4298e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 37s 9ms/step - loss: 0.0591 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 0.0091 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 0.0047 - val_loss: 9.0944e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 0.0032 - val_loss: 6.0435e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 590us/step - loss: 0.0016 - val_loss: 7.8882e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 0.0012 - val_loss: 7.9967e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0011 - val_loss: 5.8326e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 9.4683e-04 - val_loss: 6.9913e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 9.2805e-04 - val_loss: 8.2500e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 9.1126e-04 - val_loss: 5.5518e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 8.7104e-04 - val_loss: 6.5639e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 8.7197e-04 - val_loss: 6.4207e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 8.6821e-04 - val_loss: 6.4611e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 8.0243e-04 - val_loss: 5.6268e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 8.1700e-04 - val_loss: 8.1750e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 8.4239e-04 - val_loss: 5.8348e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 7.7832e-04 - val_loss: 5.6255e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 590us/step - loss: 7.7419e-04 - val_loss: 4.5068e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 590us/step - loss: 8.0385e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 7.6413e-04 - val_loss: 4.6936e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 7.5113e-04 - val_loss: 7.4603e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 7.1988e-04 - val_loss: 4.3769e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 7.0238e-04 - val_loss: 5.2458e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 37s 9ms/step - loss: 0.1784 - val_loss: 0.0420\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0701 - val_loss: 0.0197\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0356 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0075 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0036 - val_loss: 6.9890e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0025 - val_loss: 9.4990e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0019 - val_loss: 6.6205e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0018 - val_loss: 6.2581e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0016 - val_loss: 6.2122e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0014 - val_loss: 6.5616e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0014 - val_loss: 5.6429e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0013 - val_loss: 8.3527e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0013 - val_loss: 6.2978e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0012 - val_loss: 5.8612e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0013 - val_loss: 5.9877e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0011 - val_loss: 6.1966e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0011 - val_loss: 5.7856e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0012 - val_loss: 8.4476e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0010 - val_loss: 5.8654e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 9.2696e-04 - val_loss: 6.0403e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 9.2732e-04 - val_loss: 5.5753e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 9.1822e-04 - val_loss: 0.0012\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 38s 9ms/step - loss: 0.0812 - val_loss: 0.0091\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0206 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0102 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0055 - val_loss: 0.0074\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0031 - val_loss: 9.0401e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0026 - val_loss: 8.7480e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0020 - val_loss: 6.7573e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0019 - val_loss: 6.7609e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 460us/step - loss: 0.0018 - val_loss: 7.2061e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 455us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0017 - val_loss: 6.3315e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0016 - val_loss: 6.9581e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0015 - val_loss: 6.1584e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0014 - val_loss: 6.2616e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0014 - val_loss: 6.2333e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0014 - val_loss: 6.0564e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0013 - val_loss: 5.6595e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0011 - val_loss: 8.1979e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0012 - val_loss: 7.1563e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 38s 9ms/step - loss: 0.1830 - val_loss: 0.0203\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0722 - val_loss: 0.0560\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0209 - val_loss: 0.1332\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0418 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0112 - val_loss: 0.0258\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0127 - val_loss: 0.0161\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0213 - val_loss: 0.0216\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0164 - val_loss: 0.0291\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0119 - val_loss: 0.0076\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0129 - val_loss: 0.0340\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0133 - val_loss: 0.0081\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0072 - val_loss: 0.0120\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0096 - val_loss: 0.0163\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0090 - val_loss: 0.0122\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0120 - val_loss: 0.0063\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0059 - val_loss: 0.0084\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0089 - val_loss: 0.0125\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0078 - val_loss: 0.0116\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0072 - val_loss: 0.0073\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 458us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 38s 9ms/step - loss: 0.1751 - val_loss: 0.0543\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0650 - val_loss: 0.0684\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0650 - val_loss: 0.0249\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0645 - val_loss: 0.0495\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0640 - val_loss: 0.0797\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0647 - val_loss: 0.0438\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0635 - val_loss: 0.0411\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0632 - val_loss: 0.0442\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0629 - val_loss: 0.0520\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0626 - val_loss: 0.0585\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 459us/step - loss: 0.0629 - val_loss: 0.0391\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 456us/step - loss: 0.0620 - val_loss: 0.0658\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 456us/step - loss: 0.0621 - val_loss: 0.0626\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0620 - val_loss: 0.0384\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0612 - val_loss: 0.0330\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0608 - val_loss: 0.0403\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0606 - val_loss: 0.0474\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0602 - val_loss: 0.0294\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0597 - val_loss: 0.0500\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0598 - val_loss: 0.0399\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0596 - val_loss: 0.0188\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0590 - val_loss: 0.0097\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0597 - val_loss: 0.0144\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0585 - val_loss: 0.0431\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 39s 9ms/step - loss: 0.0484 - val_loss: 0.0156\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0055 - val_loss: 0.0085\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0014 - val_loss: 5.4294e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0011 - val_loss: 5.4349e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 9.5363e-04 - val_loss: 5.6688e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 8.7541e-04 - val_loss: 6.8908e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 8.5360e-04 - val_loss: 9.5081e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 8.0310e-04 - val_loss: 6.3993e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 7.3414e-04 - val_loss: 3.6070e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 7.6078e-04 - val_loss: 3.4921e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 7.1048e-04 - val_loss: 4.8323e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 6.9711e-04 - val_loss: 3.7552e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 6.5070e-04 - val_loss: 8.4499e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.0358e-04 - val_loss: 3.4529e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 6.5047e-04 - val_loss: 3.8668e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 6.2087e-04 - val_loss: 3.7827e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 6.2499e-04 - val_loss: 4.8189e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 5.9214e-04 - val_loss: 3.8054e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 6.2494e-04 - val_loss: 5.4557e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 6.1087e-04 - val_loss: 3.7100e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 6.2697e-04 - val_loss: 4.6781e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 6.5391e-04 - val_loss: 6.5379e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 40s 10ms/step - loss: 0.0643 - val_loss: 0.0160\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0090 - val_loss: 8.5706e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0023 - val_loss: 4.8342e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0013 - val_loss: 9.6841e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0012 - val_loss: 5.8092e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0010 - val_loss: 6.1280e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 9.3028e-04 - val_loss: 7.8310e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 9.1963e-04 - val_loss: 5.9184e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 8.5024e-04 - val_loss: 4.4760e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 8.2114e-04 - val_loss: 3.8950e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 7.9201e-04 - val_loss: 4.3405e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 7.5012e-04 - val_loss: 5.2980e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 7.4760e-04 - val_loss: 5.5245e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 7.4885e-04 - val_loss: 4.0503e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 7.2930e-04 - val_loss: 3.7853e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.4769e-04 - val_loss: 3.7427e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 6.9929e-04 - val_loss: 6.6644e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 7.4353e-04 - val_loss: 3.5292e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 7.1501e-04 - val_loss: 3.4874e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 6.6384e-04 - val_loss: 3.5880e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 6.4053e-04 - val_loss: 3.8057e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 617us/step - loss: 6.7519e-04 - val_loss: 4.9805e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 42s 10ms/step - loss: 8.9143 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0045 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0037 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 41s 10ms/step - loss: 9.3344 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0024 - val_loss: 9.3648e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0025 - val_loss: 8.8796e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0024 - val_loss: 8.3487e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0023 - val_loss: 8.4828e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 0.0022 - val_loss: 8.3315e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0021 - val_loss: 7.6288e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0021 - val_loss: 7.9545e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 42s 10ms/step - loss: 22.2362 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0093 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0066 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0058 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0047 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0031 - val_loss: 8.8497e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0031 - val_loss: 9.7817e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 41s 10ms/step - loss: 4.5827 - val_loss: 0.0090\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0071 - val_loss: 8.5778e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0036 - val_loss: 7.9099e-04\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0026 - val_loss: 6.2650e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0027 - val_loss: 7.9456e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0026 - val_loss: 8.5632e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0023 - val_loss: 7.9556e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0023 - val_loss: 8.0827e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0022 - val_loss: 9.5586e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0021 - val_loss: 7.3735e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 42s 10ms/step - loss: 0.8115 - val_loss: 0.0010\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0086 - val_loss: 0.0410\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0105 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0028 - val_loss: 0.0080\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0090 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0017 - val_loss: 7.6771e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0077 - val_loss: 0.0113\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0026 - val_loss: 8.0528e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0011 - val_loss: 9.8655e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0010 - val_loss: 5.0203e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0027 - val_loss: 0.0192\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0080 - val_loss: 7.4453e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0011 - val_loss: 6.8460e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 6.1112e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0013 - val_loss: 0.0050\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0019 - val_loss: 0.0060\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0025 - val_loss: 4.4562e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 42s 10ms/step - loss: 3.6414 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0046 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0031 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0027 - val_loss: 9.9242e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0025 - val_loss: 9.5988e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0023 - val_loss: 9.7869e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0024 - val_loss: 9.9534e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0023 - val_loss: 9.7340e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0022 - val_loss: 9.2958e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0022 - val_loss: 9.3528e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0021 - val_loss: 9.7617e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0022 - val_loss: 8.8526e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 43s 10ms/step - loss: 3.6854 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0034 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0027 - val_loss: 9.9801e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0024 - val_loss: 9.5877e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0021 - val_loss: 9.6427e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0022 - val_loss: 9.5985e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0021 - val_loss: 8.7012e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 44s 11ms/step - loss: 0.0866 - val_loss: 0.0172\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0101 - val_loss: 7.7896e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0030 - val_loss: 5.1879e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0020 - val_loss: 4.8742e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0014 - val_loss: 7.0226e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0013 - val_loss: 6.1752e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0013 - val_loss: 6.3327e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0012 - val_loss: 6.6893e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0012 - val_loss: 6.0082e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0011 - val_loss: 5.7684e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0011 - val_loss: 5.7014e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0010 - val_loss: 5.1932e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 9.8343e-04 - val_loss: 4.2069e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 9.6812e-04 - val_loss: 3.7853e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 9.6069e-04 - val_loss: 3.9074e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 9.2632e-04 - val_loss: 4.7481e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 8.9925e-04 - val_loss: 6.4926e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 9.4311e-04 - val_loss: 4.7796e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 8.8555e-04 - val_loss: 4.8945e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 8.5382e-04 - val_loss: 5.5147e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 45s 11ms/step - loss: 0.0666 - val_loss: 0.0154\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0092 - val_loss: 5.5046e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0024 - val_loss: 6.6259e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0011 - val_loss: 5.8194e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.7257e-04 - val_loss: 5.6511e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 8.8715e-04 - val_loss: 4.0526e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 8.2597e-04 - val_loss: 4.2556e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 7.7385e-04 - val_loss: 4.4290e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 7.5900e-04 - val_loss: 3.5536e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 7.3533e-04 - val_loss: 3.5047e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 7.2480e-04 - val_loss: 4.2978e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 7.2363e-04 - val_loss: 4.9528e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 6.9861e-04 - val_loss: 4.4114e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 6.7995e-04 - val_loss: 3.5397e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 6.5515e-04 - val_loss: 3.6012e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 6.4446e-04 - val_loss: 3.4158e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 6.3873e-04 - val_loss: 3.4765e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 6.3648e-04 - val_loss: 3.3750e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 6.2929e-04 - val_loss: 3.4599e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 6.0543e-04 - val_loss: 4.1607e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 6.0454e-04 - val_loss: 3.4536e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 43s 10ms/step - loss: 0.1835 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0466 - val_loss: 0.0317\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0381 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0093 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0053 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0029 - val_loss: 7.2221e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0018 - val_loss: 7.0910e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0016 - val_loss: 5.9020e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0015 - val_loss: 6.1417e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0013 - val_loss: 8.8706e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0012 - val_loss: 7.0281e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0013 - val_loss: 6.3177e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0012 - val_loss: 5.6933e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0012 - val_loss: 7.2424e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0011 - val_loss: 5.9871e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0011 - val_loss: 6.7667e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0012 - val_loss: 9.2507e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0012 - val_loss: 6.3849e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0011 - val_loss: 4.9251e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0010 - val_loss: 9.1041e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 9.8752e-04 - val_loss: 5.9912e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 49s 12ms/step - loss: 2.6379 - val_loss: 0.0753\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.1320 - val_loss: 0.1695\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0778 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0724 - val_loss: 0.0581\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0627 - val_loss: 0.0347\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0487 - val_loss: 0.0091\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0282 - val_loss: 0.0132\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0193 - val_loss: 0.0409\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0193 - val_loss: 0.0278\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0120 - val_loss: 0.0124\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0093 - val_loss: 0.0179\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0102 - val_loss: 0.0181\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0108 - val_loss: 0.0173\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0151 - val_loss: 0.0069\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0132 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0085 - val_loss: 0.0210\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0059 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0044 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0033 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0031 - val_loss: 9.4699e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0030 - val_loss: 9.4179e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0028 - val_loss: 8.5670e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 44s 11ms/step - loss: 0.6303 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0479 - val_loss: 0.0474\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0494 - val_loss: 0.0111\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 0.0347 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0075 - val_loss: 0.0107\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0063 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 0.0024 - val_loss: 6.9796e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 0.0022 - val_loss: 6.9232e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0021 - val_loss: 6.8602e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0020 - val_loss: 6.9700e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0018 - val_loss: 9.3104e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0019 - val_loss: 6.3345e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0018 - val_loss: 6.9135e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 660us/step - loss: 0.0017 - val_loss: 6.4630e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 653us/step - loss: 0.0017 - val_loss: 6.5532e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 671us/step - loss: 0.0015 - val_loss: 6.6282e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 658us/step - loss: 0.0016 - val_loss: 8.1696e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0015 - val_loss: 9.1351e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0015 - val_loss: 5.6412e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0014 - val_loss: 6.8559e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0014 - val_loss: 5.5170e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 47s 11ms/step - loss: 1.2085 - val_loss: 0.0540\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0721 - val_loss: 0.0817\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0570 - val_loss: 0.0173\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0502 - val_loss: 0.0113\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0369 - val_loss: 0.0127\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0151 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0058 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0035 - val_loss: 8.1711e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0021 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0020 - val_loss: 9.4149e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0018 - val_loss: 7.6995e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0018 - val_loss: 7.5282e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0018 - val_loss: 7.7982e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: 0.0017 - val_loss: 6.9348e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 0.0017 - val_loss: 6.2676e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 0.0016 - val_loss: 6.1864e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0016 - val_loss: 5.9576e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: 0.0015 - val_loss: 7.4329e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0015 - val_loss: 7.1501e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 45s 11ms/step - loss: 1.0424 - val_loss: 0.1993\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.1518 - val_loss: 0.2016\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.1165 - val_loss: 0.0568\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0705 - val_loss: 0.0071\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0602 - val_loss: 0.0475\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0425 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0138 - val_loss: 0.0117\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0080 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0041 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0028 - val_loss: 7.8140e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0027 - val_loss: 7.9367e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0024 - val_loss: 7.0246e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0022 - val_loss: 6.9979e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0022 - val_loss: 7.8166e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0022 - val_loss: 7.4690e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0020 - val_loss: 7.8796e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 47s 11ms/step - loss: 0.0523 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0091 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0043 - val_loss: 0.0070\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0015 - val_loss: 8.6259e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0015 - val_loss: 7.9215e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0014 - val_loss: 7.5103e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0013 - val_loss: 6.5543e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0012 - val_loss: 9.4701e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0012 - val_loss: 8.6535e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0011 - val_loss: 9.5575e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0011 - val_loss: 6.6150e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 9.9695e-04 - val_loss: 8.3869e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 9.4306e-04 - val_loss: 0.0010\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 48s 12ms/step - loss: 0.0567 - val_loss: 0.0293\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0138 - val_loss: 8.9730e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0122 - val_loss: 0.0131\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0089 - val_loss: 0.0093\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0108 - val_loss: 0.0076\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: 0.0070 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 463us/step - loss: 0.0069 - val_loss: 0.0350\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0090 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0062 - val_loss: 0.0086\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0073 - val_loss: 0.0072\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0037 - val_loss: 0.0217\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0048 - val_loss: 0.0126\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0050 - val_loss: 0.0137\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0043 - val_loss: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0044 - val_loss: 0.0191\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0041 - val_loss: 5.4414e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0034 - val_loss: 5.4425e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0040 - val_loss: 0.0122\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0044 - val_loss: 0.0089\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 50s 12ms/step - loss: 0.0572 - val_loss: 8.9554e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 0.0022 - val_loss: 7.0903e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0031 - val_loss: 0.0163\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0097 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0050 - val_loss: 0.0099\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0065 - val_loss: 0.0101\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0066 - val_loss: 0.0105\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0042 - val_loss: 0.0031\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0040 - val_loss: 0.0083\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0051 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0061 - val_loss: 0.0077\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0046 - val_loss: 0.0050\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0041 - val_loss: 0.0080\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0045 - val_loss: 0.0077\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0041 - val_loss: 0.0061\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 50s 12ms/step - loss: 0.0574 - val_loss: 0.0135\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0073 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0031 - val_loss: 4.7114e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0018 - val_loss: 7.6994e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0015 - val_loss: 4.7871e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0012 - val_loss: 7.0691e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0011 - val_loss: 7.7422e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 9.2163e-04 - val_loss: 5.2383e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.7100e-04 - val_loss: 4.3291e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 8.4138e-04 - val_loss: 4.2411e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 7.8435e-04 - val_loss: 3.8524e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 7.9526e-04 - val_loss: 5.1362e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 7.6559e-04 - val_loss: 4.5322e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 6.9446e-04 - val_loss: 3.6546e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 7.2568e-04 - val_loss: 4.7535e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 6.9174e-04 - val_loss: 3.7207e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 6.4842e-04 - val_loss: 3.6484e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 6.5919e-04 - val_loss: 3.5250e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 6.2654e-04 - val_loss: 5.0168e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 6.3035e-04 - val_loss: 3.4565e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 6.3614e-04 - val_loss: 4.3204e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 5.6834e-04 - val_loss: 3.6188e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 6.1977e-04 - val_loss: 3.5484e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 6.0988e-04 - val_loss: 6.4008e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 50s 12ms/step - loss: 0.0961 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0079 - val_loss: 6.7837e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 0.0040 - val_loss: 5.4243e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0014 - val_loss: 6.5825e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0012 - val_loss: 6.3352e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0012 - val_loss: 9.0658e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0012 - val_loss: 6.3549e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0011 - val_loss: 8.2928e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0011 - val_loss: 6.5143e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0010 - val_loss: 6.5455e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 9.7587e-04 - val_loss: 6.7402e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 9.7290e-04 - val_loss: 5.5734e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 9.3774e-04 - val_loss: 5.4118e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 9.3737e-04 - val_loss: 6.0900e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.4237e-04 - val_loss: 4.2882e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 8.7394e-04 - val_loss: 5.4394e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.8568e-04 - val_loss: 5.2709e-04\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 624us/step - loss: 9.1182e-04 - val_loss: 4.1607e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 9.0295e-04 - val_loss: 4.6157e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 8.7764e-04 - val_loss: 4.2799e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 8.7332e-04 - val_loss: 6.0433e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 8.5641e-04 - val_loss: 3.9538e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 51s 12ms/step - loss: 0.1036 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0098 - val_loss: 7.3963e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0016 - val_loss: 4.8320e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0014 - val_loss: 8.2328e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0014 - val_loss: 7.3500e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0012 - val_loss: 6.5202e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0012 - val_loss: 7.9782e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0012 - val_loss: 7.0934e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0012 - val_loss: 7.0151e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0011 - val_loss: 6.9741e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0010 - val_loss: 6.1641e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0010 - val_loss: 6.8177e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0011 - val_loss: 6.4114e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0010 - val_loss: 6.0591e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0010 - val_loss: 6.5858e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0010 - val_loss: 5.0382e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 9.8745e-04 - val_loss: 6.3039e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 9.3128e-04 - val_loss: 5.5979e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 9.6366e-04 - val_loss: 5.1119e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 9.4029e-04 - val_loss: 5.0110e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 52s 13ms/step - loss: 0.0461 - val_loss: 0.0064\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 0.0052 - val_loss: 9.1766e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0022 - val_loss: 5.0194e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0013 - val_loss: 6.4687e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0012 - val_loss: 8.0984e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0011 - val_loss: 9.0659e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0011 - val_loss: 6.2766e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.8786e-04 - val_loss: 8.3442e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.3367e-04 - val_loss: 5.3144e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 9.1390e-04 - val_loss: 7.0878e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.0947e-04 - val_loss: 6.5700e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 8.7790e-04 - val_loss: 5.3899e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 8.0576e-04 - val_loss: 4.8902e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 8.2591e-04 - val_loss: 4.7717e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 8.2112e-04 - val_loss: 5.5652e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 7.8433e-04 - val_loss: 5.1718e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 8.0210e-04 - val_loss: 4.7946e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.9137e-04 - val_loss: 4.2914e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.9179e-04 - val_loss: 4.4679e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.9668e-04 - val_loss: 4.2957e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 7.9346e-04 - val_loss: 5.2791e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 7.7191e-04 - val_loss: 4.5422e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 7.6319e-04 - val_loss: 4.4122e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 52s 12ms/step - loss: 0.0604 - val_loss: 0.0048\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0071 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0032 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0019 - val_loss: 4.7338e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 0.0014 - val_loss: 5.8708e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0012 - val_loss: 5.9887e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0011 - val_loss: 7.5903e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0011 - val_loss: 6.5100e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.9259e-04 - val_loss: 6.2698e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 9.7860e-04 - val_loss: 6.9823e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 9.7340e-04 - val_loss: 5.0294e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 9.4126e-04 - val_loss: 6.6195e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 9.2093e-04 - val_loss: 4.5522e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 8.8742e-04 - val_loss: 6.3903e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 8.8274e-04 - val_loss: 5.0676e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 8.8232e-04 - val_loss: 4.7725e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 8.0395e-04 - val_loss: 4.2603e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 8.8179e-04 - val_loss: 4.7366e-04\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 625us/step - loss: 8.2097e-04 - val_loss: 4.3534e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 8.3235e-04 - val_loss: 4.4248e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 8.3343e-04 - val_loss: 4.1332e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.1711e-04 - val_loss: 4.1578e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 53s 13ms/step - loss: 0.6481 - val_loss: 0.0943\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0355 - val_loss: 0.0224\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0151 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 0.0088 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0058 - val_loss: 8.5599e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0044 - val_loss: 8.0145e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0038 - val_loss: 9.5344e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 0.0033 - val_loss: 7.2566e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0032 - val_loss: 8.7350e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0031 - val_loss: 6.6979e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0030 - val_loss: 7.4547e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0030 - val_loss: 6.4881e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0028 - val_loss: 5.2589e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0026 - val_loss: 6.1943e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 0.0028 - val_loss: 4.8116e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0026 - val_loss: 6.1846e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0026 - val_loss: 6.1615e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0025 - val_loss: 4.8634e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0023 - val_loss: 5.4162e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 0.0024 - val_loss: 5.2271e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0023 - val_loss: 5.8813e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0023 - val_loss: 5.3290e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 52s 12ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 53s 13ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 54s 13ms/step - loss: 0.4178 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0089 - val_loss: 0.0054\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0109 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0021 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0012 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0017 - val_loss: 8.0146e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0011 - val_loss: 6.4678e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0013 - val_loss: 0.0054\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0017 - val_loss: 6.2635e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0010 - val_loss: 6.2757e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 9.8749e-04 - val_loss: 6.6167e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0011 - val_loss: 6.1770e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0011 - val_loss: 6.4379e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 9.6306e-04 - val_loss: 6.1251e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0012 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 54s 13ms/step - loss: 0.0537 - val_loss: 0.0118\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 0.0075 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0028 - val_loss: 8.2384e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0018 - val_loss: 4.8759e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0014 - val_loss: 6.5447e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0010 - val_loss: 7.3969e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.2002e-04 - val_loss: 4.0420e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 9.7808e-04 - val_loss: 4.0019e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.0668e-04 - val_loss: 4.3325e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 8.8381e-04 - val_loss: 4.1492e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.5978e-04 - val_loss: 4.1896e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.2702e-04 - val_loss: 3.9540e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.2021e-04 - val_loss: 3.7223e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 6.9274e-04 - val_loss: 3.7015e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.1796e-04 - val_loss: 3.6574e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 7.1507e-04 - val_loss: 6.2340e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.0754e-04 - val_loss: 3.6772e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 6.2898e-04 - val_loss: 3.5688e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 6.8113e-04 - val_loss: 4.4474e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 6.6147e-04 - val_loss: 3.5000e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 6.4098e-04 - val_loss: 3.9448e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 6.3321e-04 - val_loss: 3.8265e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 5.9771e-04 - val_loss: 3.4173e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 55s 13ms/step - loss: 0.0994 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0130 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0066 - val_loss: 0.0351\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0113 - val_loss: 0.0526\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0097 - val_loss: 8.9206e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 0.0124 - val_loss: 0.0187\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0108 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0023 - val_loss: 0.0443\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0145 - val_loss: 6.0563e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0021 - val_loss: 0.0307\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0124 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0023 - val_loss: 0.0071\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 0.0107 - val_loss: 0.0078\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 0.0041 - val_loss: 0.0088\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0064 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0044 - val_loss: 0.0245\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 0.0083 - val_loss: 5.4801e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0025 - val_loss: 0.0085\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0057 - val_loss: 0.0065\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 0.0037 - val_loss: 0.0067\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 0.0056 - val_loss: 0.0050\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 0.0030 - val_loss: 0.0100\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0041 - val_loss: 0.0092\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0051 - val_loss: 0.0017\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 55s 13ms/step - loss: 0.3500 - val_loss: 0.0219\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0665 - val_loss: 0.0063\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0512 - val_loss: 0.0115\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0104 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0607 - val_loss: 0.0065\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0224 - val_loss: 0.0687\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0157 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0354 - val_loss: 0.0222\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0187 - val_loss: 0.0211\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0107 - val_loss: 0.0893\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0203 - val_loss: 0.0142\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0207 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0185 - val_loss: 0.0105\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0155 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0055 - val_loss: 0.1072\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0132 - val_loss: 0.0077\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0155 - val_loss: 0.0099\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0136 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0031 - val_loss: 0.0203\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0153 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0124 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0038 - val_loss: 0.0749\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0101 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0109 - val_loss: 0.0046\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 56s 14ms/step - loss: 0.1840 - val_loss: 0.2694\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0493 - val_loss: 0.3619\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0438 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0536 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0047 - val_loss: 0.0456\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0519 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0088 - val_loss: 0.1769\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0260 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0305 - val_loss: 0.0198\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0125 - val_loss: 0.0277\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0128 - val_loss: 0.0597\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0194 - val_loss: 0.0177\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0160 - val_loss: 0.0401\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0134 - val_loss: 0.0029\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0132 - val_loss: 0.0430\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0115 - val_loss: 0.0081\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0096 - val_loss: 0.0553\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0097 - val_loss: 0.0064\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0111 - val_loss: 0.0205\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0090 - val_loss: 0.0109\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0079 - val_loss: 0.0402\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0081 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0105 - val_loss: 0.0221\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0059 - val_loss: 0.0019\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 57s 14ms/step - loss: 9793086371297783276785710923776.0000 - val_loss: 1173235649476626292945190912.0000\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: nan - val_loss: nan    \n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 57s 14ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 569us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 58s 14ms/step - loss: 0.3242 - val_loss: 9.0720e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0133 - val_loss: 0.0240\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 455us/step - loss: 0.0076 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 0.0189 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0079 - val_loss: 0.0121\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0138 - val_loss: 0.0258\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 452us/step - loss: 0.0160 - val_loss: 0.0256\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0080 - val_loss: 0.0173\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0132 - val_loss: 0.0525\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 452us/step - loss: 0.0175 - val_loss: 0.0072\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 457us/step - loss: 0.0066 - val_loss: 0.0089\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0079 - val_loss: 0.0381\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 455us/step - loss: 0.0185 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0037 - val_loss: 0.0219\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0066 - val_loss: 6.0246e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0091 - val_loss: 0.0531\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 454us/step - loss: 0.0069 - val_loss: 0.0048\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0059 - val_loss: 0.0127\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0076 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0044 - val_loss: 0.0101\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0086 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 452us/step - loss: 0.0038 - val_loss: 0.0261\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0078 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0029 - val_loss: 0.0092\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 57s 14ms/step - loss: 0.4797 - val_loss: 7.3363e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0032 - val_loss: 5.6036e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0021 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0133 - val_loss: 0.0073\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0073 - val_loss: 0.0168\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0154 - val_loss: 0.0169\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0174 - val_loss: 0.0341\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0414 - val_loss: 0.0038\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0022 - val_loss: 0.0058\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0108 - val_loss: 0.0220\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0101 - val_loss: 0.0196\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0165 - val_loss: 0.0245\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0071 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0080 - val_loss: 0.0139\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0165 - val_loss: 0.0118\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0044 - val_loss: 0.0084\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0100 - val_loss: 0.0135\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0055 - val_loss: 0.0180\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0085 - val_loss: 0.0069\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0089 - val_loss: 0.0189\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0050 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0072 - val_loss: 0.0172\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0055 - val_loss: 8.8394e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0054 - val_loss: 0.0132\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.011760824359953403,\n",
       " 0.0010467785177752376,\n",
       " 0.0008238441660068929,\n",
       " 0.0004875925078522414,\n",
       " 0.000654468487482518,\n",
       " 0.0010377895087003708,\n",
       " 0.0007396942237392068,\n",
       " 0.00040419920696876943,\n",
       " 0.00040018995059654117,\n",
       " 0.00043325370643287897,\n",
       " 0.00041491902084089816,\n",
       " 0.00041895636240951717,\n",
       " 0.0003953985287807882,\n",
       " 0.0003722345572896302,\n",
       " 0.00037015380803495646,\n",
       " 0.0003657426277641207,\n",
       " 0.0006233969470486045,\n",
       " 0.00036772401654161513,\n",
       " 0.00035688388743437827,\n",
       " 0.000444739154772833,\n",
       " 0.00035000190837308764,\n",
       " 0.0003944780910387635,\n",
       " 0.0003826497995760292,\n",
       " 0.00034172768937423825]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "lstmsize: 178\n",
      "density: 164\n",
      "twice: True\n",
      "dropout: 0.1\n",
      "full_density: True\n",
      "activation: elu\n",
      "shuffle: True\n",
      "optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_347 (LSTM)              (None, 92, 178)           131008    \n",
      "_________________________________________________________________\n",
      "dropout_347 (Dropout)        (None, 92, 178)           0         \n",
      "_________________________________________________________________\n",
      "lstm_348 (LSTM)              (None, 178)               254184    \n",
      "_________________________________________________________________\n",
      "dropout_348 (Dropout)        (None, 178)               0         \n",
      "_________________________________________________________________\n",
      "dense_829 (Dense)            (None, 164)               29356     \n",
      "_________________________________________________________________\n",
      "dense_830 (Dense)            (None, 82)                13530     \n",
      "_________________________________________________________________\n",
      "dense_831 (Dense)            (None, 41)                3403      \n",
      "_________________________________________________________________\n",
      "dense_832 (Dense)            (None, 20)                840       \n",
      "_________________________________________________________________\n",
      "dense_833 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 432,342\n",
      "Trainable params: 432,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/2000\n",
      "4143/4143 [==============================] - 60s 14ms/step - loss: 0.1360 - val_loss: 0.0091\n",
      "Epoch 2/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 0.0145 - val_loss: 0.0167\n",
      "Epoch 3/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 0.0068 - val_loss: 0.0060\n",
      "Epoch 4/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 0.0030 - val_loss: 8.2698e-04\n",
      "Epoch 5/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 0.0020 - val_loss: 5.2827e-04\n",
      "Epoch 6/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 7/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 0.0014 - val_loss: 6.5619e-04\n",
      "Epoch 8/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 0.0012 - val_loss: 7.9526e-04\n",
      "Epoch 9/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 0.0011 - val_loss: 8.5943e-04\n",
      "Epoch 10/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 0.0011 - val_loss: 8.6510e-04\n",
      "Epoch 11/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.8670e-04 - val_loss: 7.5536e-04\n",
      "Epoch 12/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.5415e-04 - val_loss: 4.0525e-04\n",
      "Epoch 13/2000\n",
      "4143/4143 [==============================] - 3s 647us/step - loss: 9.2883e-04 - val_loss: 6.3838e-04\n",
      "Epoch 14/2000\n",
      "4143/4143 [==============================] - 3s 655us/step - loss: 8.8626e-04 - val_loss: 5.2224e-04\n",
      "Epoch 15/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.6221e-04 - val_loss: 7.0805e-04\n",
      "Epoch 16/2000\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 8.3313e-04 - val_loss: 7.7872e-04\n",
      "Epoch 17/2000\n",
      "4143/4143 [==============================] - 3s 649us/step - loss: 8.1111e-04 - val_loss: 5.1691e-04\n",
      "Epoch 18/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.4163e-04 - val_loss: 5.2842e-04\n",
      "Epoch 19/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.1711e-04 - val_loss: 5.3557e-04\n",
      "Epoch 20/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.3718e-04 - val_loss: 4.5162e-04\n",
      "Epoch 21/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 7.1730e-04 - val_loss: 3.7423e-04\n",
      "Epoch 22/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 6.9676e-04 - val_loss: 3.9293e-04\n",
      "Epoch 23/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 6.5739e-04 - val_loss: 3.5655e-04\n",
      "Epoch 24/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 6.7516e-04 - val_loss: 3.7531e-04\n",
      "Epoch 25/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 6.9110e-04 - val_loss: 3.7035e-04\n",
      "Epoch 26/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 6.6887e-04 - val_loss: 4.0328e-04\n",
      "Epoch 27/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 6.3702e-04 - val_loss: 3.4598e-04\n",
      "Epoch 28/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 6.6374e-04 - val_loss: 3.6261e-04\n",
      "Epoch 29/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 6.4966e-04 - val_loss: 4.4007e-04\n",
      "Epoch 30/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 6.6741e-04 - val_loss: 3.4319e-04\n",
      "Epoch 31/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 6.4290e-04 - val_loss: 3.3738e-04\n",
      "Epoch 32/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 6.1684e-04 - val_loss: 3.3676e-04\n",
      "Epoch 33/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 6.2260e-04 - val_loss: 4.5097e-04\n",
      "Epoch 34/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 6.2061e-04 - val_loss: 4.4235e-04\n",
      "Epoch 35/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 5.9711e-04 - val_loss: 3.3559e-04\n",
      "Epoch 36/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 5.9626e-04 - val_loss: 3.5199e-04\n",
      "Epoch 37/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 5.7144e-04 - val_loss: 3.2920e-04\n",
      "Epoch 38/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 6.0334e-04 - val_loss: 3.3335e-04\n",
      "Epoch 39/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 5.5563e-04 - val_loss: 3.2388e-04\n",
      "Epoch 40/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 5.8792e-04 - val_loss: 3.3320e-04\n",
      "Epoch 41/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 5.6400e-04 - val_loss: 3.5491e-04\n",
      "Epoch 42/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 5.7309e-04 - val_loss: 4.1453e-04\n",
      "Epoch 43/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 6.3151e-04 - val_loss: 4.8196e-04\n",
      "Epoch 44/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 5.8932e-04 - val_loss: 3.2122e-04\n",
      "Epoch 45/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 5.8123e-04 - val_loss: 3.2042e-04\n",
      "Epoch 46/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 5.5863e-04 - val_loss: 5.2565e-04\n",
      "Epoch 47/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 5.8663e-04 - val_loss: 3.1400e-04\n",
      "Epoch 48/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 5.3152e-04 - val_loss: 3.1664e-04\n",
      "Epoch 49/2000\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 5.3970e-04 - val_loss: 3.4243e-04\n",
      "Epoch 50/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 5.4984e-04 - val_loss: 3.9318e-04\n",
      "Epoch 51/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 5.4518e-04 - val_loss: 3.0453e-04\n",
      "Epoch 52/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 5.3774e-04 - val_loss: 3.0282e-04\n",
      "Epoch 53/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 5.2737e-04 - val_loss: 3.7186e-04\n",
      "Epoch 54/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 5.1479e-04 - val_loss: 3.1293e-04\n",
      "Epoch 55/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 5.0243e-04 - val_loss: 3.7436e-04\n",
      "Epoch 56/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 5.0870e-04 - val_loss: 2.9854e-04\n",
      "Epoch 57/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 5.1413e-04 - val_loss: 5.1700e-04\n",
      "Epoch 58/2000\n",
      "4143/4143 [==============================] - 3s 656us/step - loss: 5.4519e-04 - val_loss: 3.0168e-04\n",
      "Epoch 59/2000\n",
      "4143/4143 [==============================] - 3s 646us/step - loss: 5.1893e-04 - val_loss: 3.0738e-04\n",
      "Epoch 60/2000\n",
      "4143/4143 [==============================] - 3s 647us/step - loss: 5.2101e-04 - val_loss: 4.8799e-04\n",
      "Epoch 61/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 5.0116e-04 - val_loss: 3.1375e-04\n",
      "Epoch 62/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 4.9819e-04 - val_loss: 2.8941e-04\n",
      "Epoch 63/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 5.3314e-04 - val_loss: 3.0719e-04\n",
      "Epoch 64/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 4.8834e-04 - val_loss: 2.8776e-04\n",
      "Epoch 65/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 5.0134e-04 - val_loss: 3.3435e-04\n",
      "Epoch 66/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 4.8903e-04 - val_loss: 3.0888e-04\n",
      "Epoch 67/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 4.8130e-04 - val_loss: 2.8851e-04\n",
      "Epoch 68/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 4.9185e-04 - val_loss: 2.8982e-04\n",
      "Epoch 69/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 4.6098e-04 - val_loss: 3.2224e-04\n",
      "Epoch 70/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 4.6994e-04 - val_loss: 2.9351e-04\n",
      "Epoch 71/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 4.4900e-04 - val_loss: 2.8045e-04\n",
      "Epoch 72/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 637us/step - loss: 4.6527e-04 - val_loss: 5.0119e-04\n",
      "Epoch 73/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 4.9159e-04 - val_loss: 2.8479e-04\n",
      "Epoch 74/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 5.0887e-04 - val_loss: 2.9427e-04\n",
      "Epoch 75/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 4.5084e-04 - val_loss: 2.7426e-04\n",
      "Epoch 76/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 4.6143e-04 - val_loss: 2.7768e-04\n",
      "Epoch 77/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 4.5356e-04 - val_loss: 2.7608e-04\n",
      "Epoch 78/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 4.7372e-04 - val_loss: 2.7079e-04\n",
      "Epoch 79/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 4.5241e-04 - val_loss: 4.6177e-04\n",
      "Epoch 80/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 5.2092e-04 - val_loss: 6.7990e-04\n",
      "Epoch 81/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 5.3510e-04 - val_loss: 4.5479e-04\n",
      "Epoch 82/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 5.1632e-04 - val_loss: 4.2249e-04\n",
      "Epoch 83/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 4.8658e-04 - val_loss: 3.0518e-04\n",
      "Epoch 84/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 5.5283e-04 - val_loss: 4.5407e-04\n",
      "Epoch 85/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 4.7594e-04 - val_loss: 3.0028e-04\n",
      "Epoch 86/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 4.5732e-04 - val_loss: 2.6377e-04\n",
      "Epoch 87/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 4.1839e-04 - val_loss: 2.7766e-04\n",
      "Epoch 88/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 4.7492e-04 - val_loss: 4.5571e-04\n",
      "Epoch 89/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 4.4993e-04 - val_loss: 2.6167e-04\n",
      "Epoch 90/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 4.2931e-04 - val_loss: 2.9342e-04\n",
      "Epoch 91/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 4.3605e-04 - val_loss: 2.7626e-04\n",
      "Epoch 92/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 4.2879e-04 - val_loss: 5.0779e-04\n",
      "Epoch 93/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 4.6987e-04 - val_loss: 2.5394e-04\n",
      "Epoch 94/2000\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 4.2469e-04 - val_loss: 2.6124e-04\n",
      "Epoch 95/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 4.3926e-04 - val_loss: 2.5581e-04\n",
      "Epoch 96/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 4.1735e-04 - val_loss: 2.9803e-04\n",
      "Epoch 97/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 4.4357e-04 - val_loss: 2.5368e-04\n",
      "Epoch 98/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 4.1150e-04 - val_loss: 3.4367e-04\n",
      "Epoch 99/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 4.2436e-04 - val_loss: 2.5482e-04\n",
      "Epoch 100/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 4.3440e-04 - val_loss: 4.3423e-04\n",
      "Epoch 101/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 4.4515e-04 - val_loss: 6.8252e-04\n",
      "Epoch 102/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 4.9781e-04 - val_loss: 4.1876e-04\n",
      "Epoch 103/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 4.4030e-04 - val_loss: 2.4129e-04\n",
      "Epoch 104/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 4.3744e-04 - val_loss: 2.6266e-04\n",
      "Epoch 105/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 4.0858e-04 - val_loss: 2.4825e-04\n",
      "Epoch 106/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 3.8224e-04 - val_loss: 5.2203e-04\n",
      "Epoch 107/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 4.1512e-04 - val_loss: 3.2863e-04\n",
      "Epoch 108/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 4.2810e-04 - val_loss: 3.8252e-04\n",
      "Epoch 109/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 4.4711e-04 - val_loss: 4.7436e-04\n",
      "Epoch 110/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 4.3032e-04 - val_loss: 2.3951e-04\n",
      "Epoch 111/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 3.8307e-04 - val_loss: 4.5037e-04\n",
      "Epoch 112/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 4.6170e-04 - val_loss: 2.3957e-04\n",
      "Epoch 113/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 4.3911e-04 - val_loss: 4.5958e-04\n",
      "Epoch 114/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 4.4925e-04 - val_loss: 7.1210e-04\n",
      "Epoch 115/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 4.6952e-04 - val_loss: 2.5321e-04\n",
      "Epoch 116/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 4.0634e-04 - val_loss: 2.2980e-04\n",
      "Epoch 117/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 3.7373e-04 - val_loss: 2.9019e-04\n",
      "Epoch 118/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 3.7529e-04 - val_loss: 2.5752e-04\n",
      "Epoch 119/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 3.7182e-04 - val_loss: 2.6816e-04\n",
      "Epoch 120/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 3.5117e-04 - val_loss: 2.3271e-04\n",
      "Epoch 121/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 3.7910e-04 - val_loss: 2.3692e-04\n",
      "Epoch 122/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 3.8572e-04 - val_loss: 2.2750e-04\n",
      "Epoch 123/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 3.6664e-04 - val_loss: 2.4834e-04\n",
      "Epoch 124/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 3.5645e-04 - val_loss: 2.2933e-04\n",
      "Epoch 125/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 3.6529e-04 - val_loss: 2.4381e-04\n",
      "Epoch 126/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 3.5425e-04 - val_loss: 2.2087e-04\n",
      "Epoch 127/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 3.5382e-04 - val_loss: 3.3419e-04\n",
      "Epoch 128/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 4.0840e-04 - val_loss: 3.2970e-04\n",
      "Epoch 129/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 4.2234e-04 - val_loss: 2.1867e-04\n",
      "Epoch 130/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 3.6506e-04 - val_loss: 2.1486e-04\n",
      "Epoch 131/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 3.6364e-04 - val_loss: 2.1404e-04\n",
      "Epoch 132/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 3.4997e-04 - val_loss: 2.1568e-04\n",
      "Epoch 133/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 3.6778e-04 - val_loss: 5.7584e-04\n",
      "Epoch 134/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 4.3292e-04 - val_loss: 2.5592e-04\n",
      "Epoch 135/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 3.3923e-04 - val_loss: 2.3469e-04\n",
      "Epoch 136/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 3.5569e-04 - val_loss: 3.9096e-04\n",
      "Epoch 137/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 3.9172e-04 - val_loss: 2.4981e-04\n",
      "Epoch 138/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 3.9535e-04 - val_loss: 3.4803e-04\n",
      "Epoch 139/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 3.9835e-04 - val_loss: 2.9455e-04\n",
      "Epoch 140/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 4.2067e-04 - val_loss: 2.5495e-04\n",
      "Epoch 141/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 3.8326e-04 - val_loss: 2.0608e-04\n",
      "Epoch 142/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 3.3978e-04 - val_loss: 2.3434e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 3.3692e-04 - val_loss: 3.0357e-04\n",
      "Epoch 144/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 3.3834e-04 - val_loss: 2.1838e-04\n",
      "Epoch 145/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 3.2900e-04 - val_loss: 2.2273e-04\n",
      "Epoch 146/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 3.5322e-04 - val_loss: 2.6867e-04\n",
      "Epoch 147/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 3.4970e-04 - val_loss: 2.0106e-04\n",
      "Epoch 148/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 3.4185e-04 - val_loss: 2.3274e-04\n",
      "Epoch 149/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 3.3533e-04 - val_loss: 3.3087e-04\n",
      "Epoch 150/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 3.7422e-04 - val_loss: 2.5264e-04\n",
      "Epoch 151/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 3.6861e-04 - val_loss: 2.2766e-04\n",
      "Epoch 152/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 3.2625e-04 - val_loss: 1.9832e-04\n",
      "Epoch 153/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 3.2279e-04 - val_loss: 2.0048e-04\n",
      "Epoch 154/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 3.2616e-04 - val_loss: 2.0437e-04\n",
      "Epoch 155/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 3.1603e-04 - val_loss: 2.4849e-04\n",
      "Epoch 156/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 3.3259e-04 - val_loss: 2.2403e-04\n",
      "Epoch 157/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 3.2129e-04 - val_loss: 1.9326e-04\n",
      "Epoch 158/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 3.3209e-04 - val_loss: 1.9900e-04\n",
      "Epoch 159/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 3.2721e-04 - val_loss: 2.2682e-04\n",
      "Epoch 160/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 3.0892e-04 - val_loss: 1.9329e-04\n",
      "Epoch 161/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 3.0267e-04 - val_loss: 2.1543e-04\n",
      "Epoch 162/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 3.1104e-04 - val_loss: 2.0573e-04\n",
      "Epoch 163/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 3.0645e-04 - val_loss: 2.7162e-04\n",
      "Epoch 164/2000\n",
      "4143/4143 [==============================] - 3s 648us/step - loss: 3.1641e-04 - val_loss: 3.7529e-04\n",
      "Epoch 165/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 3.4187e-04 - val_loss: 2.6263e-04\n",
      "Epoch 166/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 3.1082e-04 - val_loss: 2.1394e-04\n",
      "Epoch 167/2000\n",
      "4143/4143 [==============================] - 3s 646us/step - loss: 3.1926e-04 - val_loss: 2.6577e-04\n",
      "Epoch 168/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 3.4393e-04 - val_loss: 2.5454e-04\n",
      "Epoch 169/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 3.4216e-04 - val_loss: 2.0743e-04\n",
      "Epoch 170/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 3.2670e-04 - val_loss: 1.9643e-04\n",
      "Epoch 171/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 3.2675e-04 - val_loss: 1.8344e-04\n",
      "Epoch 172/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 3.3910e-04 - val_loss: 2.9469e-04\n",
      "Epoch 173/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 3.4780e-04 - val_loss: 2.6785e-04\n",
      "Epoch 174/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 3.0549e-04 - val_loss: 1.8098e-04\n",
      "Epoch 175/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 3.0940e-04 - val_loss: 2.3449e-04\n",
      "Epoch 176/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 3.0757e-04 - val_loss: 2.5436e-04\n",
      "Epoch 177/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 3.2546e-04 - val_loss: 2.2178e-04\n",
      "Epoch 178/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 3.0893e-04 - val_loss: 1.8434e-04\n",
      "Epoch 179/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.8433e-04 - val_loss: 1.7678e-04\n",
      "Epoch 180/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.8560e-04 - val_loss: 1.7656e-04\n",
      "Epoch 181/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.9030e-04 - val_loss: 2.1152e-04\n",
      "Epoch 182/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 3.2018e-04 - val_loss: 1.9483e-04\n",
      "Epoch 183/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.8487e-04 - val_loss: 1.8432e-04\n",
      "Epoch 184/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 3.0728e-04 - val_loss: 1.8787e-04\n",
      "Epoch 185/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.8988e-04 - val_loss: 3.8151e-04\n",
      "Epoch 186/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 3.2289e-04 - val_loss: 1.8384e-04\n",
      "Epoch 187/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 3.0541e-04 - val_loss: 3.6433e-04\n",
      "Epoch 188/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 3.9639e-04 - val_loss: 4.1098e-04\n",
      "Epoch 189/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 3.7208e-04 - val_loss: 1.7398e-04\n",
      "Epoch 190/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 3.1398e-04 - val_loss: 2.4867e-04\n",
      "Epoch 191/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 3.3252e-04 - val_loss: 1.9728e-04\n",
      "Epoch 192/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 3.2021e-04 - val_loss: 2.6034e-04\n",
      "Epoch 193/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 3.2866e-04 - val_loss: 1.7257e-04\n",
      "Epoch 194/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.7714e-04 - val_loss: 2.4223e-04\n",
      "Epoch 195/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.7263e-04 - val_loss: 4.9632e-04\n",
      "Epoch 196/2000\n",
      "4143/4143 [==============================] - 3s 656us/step - loss: 3.3734e-04 - val_loss: 5.5318e-04\n",
      "Epoch 197/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 3.2978e-04 - val_loss: 1.6722e-04\n",
      "Epoch 198/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.7687e-04 - val_loss: 1.8097e-04\n",
      "Epoch 199/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.8265e-04 - val_loss: 1.7185e-04\n",
      "Epoch 200/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.8046e-04 - val_loss: 2.3035e-04\n",
      "Epoch 201/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 3.1113e-04 - val_loss: 1.9125e-04\n",
      "Epoch 202/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 2.8941e-04 - val_loss: 2.0748e-04\n",
      "Epoch 203/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.9254e-04 - val_loss: 2.4571e-04\n",
      "Epoch 204/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.8122e-04 - val_loss: 2.5314e-04\n",
      "Epoch 205/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.8570e-04 - val_loss: 1.6144e-04\n",
      "Epoch 206/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 2.6614e-04 - val_loss: 1.8721e-04\n",
      "Epoch 207/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.6511e-04 - val_loss: 3.0592e-04\n",
      "Epoch 208/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 2.7905e-04 - val_loss: 1.7139e-04\n",
      "Epoch 209/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.7672e-04 - val_loss: 1.6300e-04\n",
      "Epoch 210/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.5819e-04 - val_loss: 2.9287e-04\n",
      "Epoch 211/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.8528e-04 - val_loss: 1.7374e-04\n",
      "Epoch 212/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.5960e-04 - val_loss: 1.7994e-04\n",
      "Epoch 213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 633us/step - loss: 2.7594e-04 - val_loss: 2.0244e-04\n",
      "Epoch 214/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.9756e-04 - val_loss: 2.5443e-04\n",
      "Epoch 215/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.8942e-04 - val_loss: 1.5319e-04\n",
      "Epoch 216/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.5755e-04 - val_loss: 3.0148e-04\n",
      "Epoch 217/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.7632e-04 - val_loss: 3.1003e-04\n",
      "Epoch 218/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.9044e-04 - val_loss: 1.5153e-04\n",
      "Epoch 219/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.8605e-04 - val_loss: 1.5523e-04\n",
      "Epoch 220/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.5511e-04 - val_loss: 1.6148e-04\n",
      "Epoch 221/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.5941e-04 - val_loss: 3.8335e-04\n",
      "Epoch 222/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.7813e-04 - val_loss: 2.5095e-04\n",
      "Epoch 223/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.7374e-04 - val_loss: 1.5517e-04\n",
      "Epoch 224/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.6223e-04 - val_loss: 1.5699e-04\n",
      "Epoch 225/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 2.4603e-04 - val_loss: 1.5396e-04\n",
      "Epoch 226/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.4755e-04 - val_loss: 2.5849e-04\n",
      "Epoch 227/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 3.0563e-04 - val_loss: 1.7897e-04\n",
      "Epoch 228/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.7241e-04 - val_loss: 2.6908e-04\n",
      "Epoch 229/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 2.5379e-04 - val_loss: 3.6756e-04\n",
      "Epoch 230/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 2.9626e-04 - val_loss: 1.4671e-04\n",
      "Epoch 231/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.7306e-04 - val_loss: 2.2130e-04\n",
      "Epoch 232/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.6944e-04 - val_loss: 1.5294e-04\n",
      "Epoch 233/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.5224e-04 - val_loss: 2.8551e-04\n",
      "Epoch 234/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 2.6121e-04 - val_loss: 1.6754e-04\n",
      "Epoch 235/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.6491e-04 - val_loss: 1.9816e-04\n",
      "Epoch 236/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.8008e-04 - val_loss: 1.9662e-04\n",
      "Epoch 237/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.5356e-04 - val_loss: 3.4019e-04\n",
      "Epoch 238/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.8620e-04 - val_loss: 1.6290e-04\n",
      "Epoch 239/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.4815e-04 - val_loss: 1.7395e-04\n",
      "Epoch 240/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.6238e-04 - val_loss: 1.9658e-04\n",
      "Epoch 241/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 2.7395e-04 - val_loss: 2.2278e-04\n",
      "Epoch 242/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 2.9148e-04 - val_loss: 2.6140e-04\n",
      "Epoch 243/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 2.7132e-04 - val_loss: 1.4687e-04\n",
      "Epoch 244/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.7828e-04 - val_loss: 1.5754e-04\n",
      "Epoch 245/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 2.4129e-04 - val_loss: 1.5060e-04\n",
      "Epoch 246/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.3528e-04 - val_loss: 1.3733e-04\n",
      "Epoch 247/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 2.3552e-04 - val_loss: 1.4243e-04\n",
      "Epoch 248/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.2667e-04 - val_loss: 1.5852e-04\n",
      "Epoch 249/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.2930e-04 - val_loss: 3.4262e-04\n",
      "Epoch 250/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.9255e-04 - val_loss: 1.8046e-04\n",
      "Epoch 251/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 2.8589e-04 - val_loss: 1.8505e-04\n",
      "Epoch 252/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.8434e-04 - val_loss: 3.6463e-04\n",
      "Epoch 253/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.6173e-04 - val_loss: 1.7782e-04\n",
      "Epoch 254/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.2963e-04 - val_loss: 1.4105e-04\n",
      "Epoch 255/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 2.4968e-04 - val_loss: 1.3256e-04\n",
      "Epoch 256/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 2.3347e-04 - val_loss: 1.3163e-04\n",
      "Epoch 257/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.2299e-04 - val_loss: 1.3886e-04\n",
      "Epoch 258/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 2.2328e-04 - val_loss: 2.4789e-04\n",
      "Epoch 259/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.2627e-04 - val_loss: 2.1015e-04\n",
      "Epoch 260/2000\n",
      "4143/4143 [==============================] - 3s 649us/step - loss: 2.5232e-04 - val_loss: 2.0585e-04\n",
      "Epoch 261/2000\n",
      "4143/4143 [==============================] - 3s 671us/step - loss: 2.6002e-04 - val_loss: 3.5250e-04\n",
      "Epoch 262/2000\n",
      "4143/4143 [==============================] - 3s 652us/step - loss: 2.6154e-04 - val_loss: 1.3325e-04\n",
      "Epoch 263/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.2870e-04 - val_loss: 1.3352e-04\n",
      "Epoch 264/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.1868e-04 - val_loss: 1.2783e-04\n",
      "Epoch 265/2000\n",
      "4143/4143 [==============================] - 3s 654us/step - loss: 2.1660e-04 - val_loss: 1.5497e-04\n",
      "Epoch 266/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.1572e-04 - val_loss: 2.3630e-04\n",
      "Epoch 267/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 2.3908e-04 - val_loss: 1.3242e-04\n",
      "Epoch 268/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 2.2908e-04 - val_loss: 2.3744e-04\n",
      "Epoch 269/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.5331e-04 - val_loss: 2.4882e-04\n",
      "Epoch 270/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.4406e-04 - val_loss: 1.5494e-04\n",
      "Epoch 271/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.4886e-04 - val_loss: 1.2961e-04\n",
      "Epoch 272/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 2.2030e-04 - val_loss: 1.2840e-04\n",
      "Epoch 273/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.1499e-04 - val_loss: 1.3025e-04\n",
      "Epoch 274/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.1573e-04 - val_loss: 1.8674e-04\n",
      "Epoch 275/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 2.1719e-04 - val_loss: 1.2387e-04\n",
      "Epoch 276/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.0688e-04 - val_loss: 1.3541e-04\n",
      "Epoch 277/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 2.1251e-04 - val_loss: 1.4096e-04\n",
      "Epoch 278/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 2.1496e-04 - val_loss: 1.2888e-04\n",
      "Epoch 279/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.1376e-04 - val_loss: 1.2167e-04\n",
      "Epoch 280/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.1497e-04 - val_loss: 1.4008e-04\n",
      "Epoch 281/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.3801e-04 - val_loss: 2.0881e-04\n",
      "Epoch 282/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 2.1819e-04 - val_loss: 1.1834e-04\n",
      "Epoch 283/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 2.2796e-04 - val_loss: 2.1201e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.2138e-04 - val_loss: 1.6771e-04\n",
      "Epoch 285/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 2.0943e-04 - val_loss: 2.4984e-04\n",
      "Epoch 286/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.2792e-04 - val_loss: 1.7554e-04\n",
      "Epoch 287/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 2.2432e-04 - val_loss: 1.4670e-04\n",
      "Epoch 288/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 2.0746e-04 - val_loss: 1.1923e-04\n",
      "Epoch 289/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.0767e-04 - val_loss: 1.3463e-04\n",
      "Epoch 290/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.0733e-04 - val_loss: 1.7008e-04\n",
      "Epoch 291/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.2008e-04 - val_loss: 1.2258e-04\n",
      "Epoch 292/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 2.0677e-04 - val_loss: 2.1349e-04\n",
      "Epoch 293/2000\n",
      "4143/4143 [==============================] - 3s 649us/step - loss: 2.1301e-04 - val_loss: 1.2077e-04\n",
      "Epoch 294/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.2715e-04 - val_loss: 1.5528e-04\n",
      "Epoch 295/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.2583e-04 - val_loss: 1.1779e-04\n",
      "Epoch 296/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.9579e-04 - val_loss: 1.5052e-04\n",
      "Epoch 297/2000\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 2.1512e-04 - val_loss: 1.3943e-04\n",
      "Epoch 298/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.0104e-04 - val_loss: 2.4330e-04\n",
      "Epoch 299/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.4006e-04 - val_loss: 1.1581e-04\n",
      "Epoch 300/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.2768e-04 - val_loss: 1.3719e-04\n",
      "Epoch 301/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.2076e-04 - val_loss: 1.2012e-04\n",
      "Epoch 302/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.1224e-04 - val_loss: 1.1424e-04\n",
      "Epoch 303/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.0179e-04 - val_loss: 1.0961e-04\n",
      "Epoch 304/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.9327e-04 - val_loss: 1.1236e-04\n",
      "Epoch 305/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.9451e-04 - val_loss: 1.1632e-04\n",
      "Epoch 306/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.0577e-04 - val_loss: 1.0786e-04\n",
      "Epoch 307/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.8066e-04 - val_loss: 1.3829e-04\n",
      "Epoch 308/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.9949e-04 - val_loss: 1.6379e-04\n",
      "Epoch 309/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 2.0025e-04 - val_loss: 1.5218e-04\n",
      "Epoch 310/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.0751e-04 - val_loss: 1.1676e-04\n",
      "Epoch 311/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.0010e-04 - val_loss: 1.5797e-04\n",
      "Epoch 312/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.1321e-04 - val_loss: 1.7473e-04\n",
      "Epoch 313/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.2533e-04 - val_loss: 2.4508e-04\n",
      "Epoch 314/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 2.0695e-04 - val_loss: 1.7019e-04\n",
      "Epoch 315/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.0837e-04 - val_loss: 1.2511e-04\n",
      "Epoch 316/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.9481e-04 - val_loss: 1.1930e-04\n",
      "Epoch 317/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.7473e-04 - val_loss: 1.4491e-04\n",
      "Epoch 318/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.8760e-04 - val_loss: 1.0361e-04\n",
      "Epoch 319/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.8055e-04 - val_loss: 1.1947e-04\n",
      "Epoch 320/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.4357e-04 - val_loss: 2.5946e-04\n",
      "Epoch 321/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.7842e-04 - val_loss: 2.0427e-04\n",
      "Epoch 322/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 2.2628e-04 - val_loss: 1.0184e-04\n",
      "Epoch 323/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.8594e-04 - val_loss: 1.0402e-04\n",
      "Epoch 324/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.8909e-04 - val_loss: 1.2096e-04\n",
      "Epoch 325/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.9611e-04 - val_loss: 1.8169e-04\n",
      "Epoch 326/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.9042e-04 - val_loss: 1.4922e-04\n",
      "Epoch 327/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.9714e-04 - val_loss: 2.0149e-04\n",
      "Epoch 328/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.0279e-04 - val_loss: 1.1416e-04\n",
      "Epoch 329/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.8651e-04 - val_loss: 1.6605e-04\n",
      "Epoch 330/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.0569e-04 - val_loss: 1.1240e-04\n",
      "Epoch 331/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 1.7584e-04 - val_loss: 1.2037e-04\n",
      "Epoch 332/2000\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 1.8541e-04 - val_loss: 1.0975e-04\n",
      "Epoch 333/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.8246e-04 - val_loss: 2.6508e-04\n",
      "Epoch 334/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 2.2485e-04 - val_loss: 1.2208e-04\n",
      "Epoch 335/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.8006e-04 - val_loss: 1.1338e-04\n",
      "Epoch 336/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.8907e-04 - val_loss: 9.6710e-05\n",
      "Epoch 337/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.7978e-04 - val_loss: 9.8697e-05\n",
      "Epoch 338/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 1.7929e-04 - val_loss: 1.4759e-04\n",
      "Epoch 339/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.8706e-04 - val_loss: 1.0566e-04\n",
      "Epoch 340/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.8085e-04 - val_loss: 1.0924e-04\n",
      "Epoch 341/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.8456e-04 - val_loss: 1.2268e-04\n",
      "Epoch 342/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.9937e-04 - val_loss: 1.2858e-04\n",
      "Epoch 343/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.8654e-04 - val_loss: 1.0793e-04\n",
      "Epoch 344/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.7951e-04 - val_loss: 9.4476e-05\n",
      "Epoch 345/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.7505e-04 - val_loss: 1.1024e-04\n",
      "Epoch 346/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.8411e-04 - val_loss: 1.2119e-04\n",
      "Epoch 347/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.7785e-04 - val_loss: 1.1502e-04\n",
      "Epoch 348/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.7527e-04 - val_loss: 1.1238e-04\n",
      "Epoch 349/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.6926e-04 - val_loss: 1.2911e-04\n",
      "Epoch 350/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 2.1669e-04 - val_loss: 1.4679e-04\n",
      "Epoch 351/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.0306e-04 - val_loss: 9.0682e-05\n",
      "Epoch 352/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.8188e-04 - val_loss: 1.4956e-04\n",
      "Epoch 353/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.8810e-04 - val_loss: 1.1642e-04\n",
      "Epoch 354/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.8276e-04 - val_loss: 1.0179e-04\n",
      "Epoch 355/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.8210e-04 - val_loss: 2.4217e-04\n",
      "Epoch 356/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.3347e-04 - val_loss: 1.8625e-04\n",
      "Epoch 357/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.2668e-04 - val_loss: 1.2248e-04\n",
      "Epoch 358/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.8394e-04 - val_loss: 1.2216e-04\n",
      "Epoch 359/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.0354e-04 - val_loss: 1.9477e-04\n",
      "Epoch 360/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.1968e-04 - val_loss: 4.6184e-04\n",
      "Epoch 361/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 2.7351e-04 - val_loss: 2.3865e-04\n",
      "Epoch 362/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.3967e-04 - val_loss: 1.1363e-04\n",
      "Epoch 363/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.7499e-04 - val_loss: 1.8616e-04\n",
      "Epoch 364/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.9711e-04 - val_loss: 8.7234e-05\n",
      "Epoch 365/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.7999e-04 - val_loss: 9.8955e-05\n",
      "Epoch 366/2000\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 1.6531e-04 - val_loss: 1.0779e-04\n",
      "Epoch 367/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.5910e-04 - val_loss: 1.3308e-04\n",
      "Epoch 368/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.5900e-04 - val_loss: 8.6514e-05\n",
      "Epoch 369/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.6367e-04 - val_loss: 1.5141e-04\n",
      "Epoch 370/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.8277e-04 - val_loss: 1.4043e-04\n",
      "Epoch 371/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 2.1385e-04 - val_loss: 1.0645e-04\n",
      "Epoch 372/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.7101e-04 - val_loss: 2.1235e-04\n",
      "Epoch 373/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.0691e-04 - val_loss: 2.6764e-04\n",
      "Epoch 374/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.1496e-04 - val_loss: 9.0251e-05\n",
      "Epoch 375/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.1591e-04 - val_loss: 8.5391e-05\n",
      "Epoch 376/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.0108e-04 - val_loss: 2.5797e-04\n",
      "Epoch 377/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.0924e-04 - val_loss: 8.9086e-05\n",
      "Epoch 378/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.6586e-04 - val_loss: 2.1601e-04\n",
      "Epoch 379/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 2.1476e-04 - val_loss: 2.2958e-04\n",
      "Epoch 380/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.0328e-04 - val_loss: 1.2219e-04\n",
      "Epoch 381/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 2.0237e-04 - val_loss: 1.5925e-04\n",
      "Epoch 382/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.9297e-04 - val_loss: 2.0147e-04\n",
      "Epoch 383/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.2240e-04 - val_loss: 1.6131e-04\n",
      "Epoch 384/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.1435e-04 - val_loss: 4.0854e-04\n",
      "Epoch 385/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 3.0658e-04 - val_loss: 3.0538e-04\n",
      "Epoch 386/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.3276e-04 - val_loss: 1.0495e-04\n",
      "Epoch 387/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.7359e-04 - val_loss: 2.2906e-04\n",
      "Epoch 388/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.1149e-04 - val_loss: 1.1591e-04\n",
      "Epoch 389/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.7028e-04 - val_loss: 8.7276e-05\n",
      "Epoch 390/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.6007e-04 - val_loss: 8.9714e-05\n",
      "Epoch 391/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.5058e-04 - val_loss: 9.1452e-05\n",
      "Epoch 392/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 1.5273e-04 - val_loss: 2.0216e-04\n",
      "Epoch 393/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.1520e-04 - val_loss: 2.0188e-04\n",
      "Epoch 394/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.8526e-04 - val_loss: 1.4275e-04\n",
      "Epoch 395/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.7715e-04 - val_loss: 2.1191e-04\n",
      "Epoch 396/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.9481e-04 - val_loss: 2.0223e-04\n",
      "Epoch 397/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.1875e-04 - val_loss: 2.3682e-04\n",
      "Epoch 398/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 1.8910e-04 - val_loss: 1.6583e-04\n",
      "Epoch 399/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.0340e-04 - val_loss: 9.9005e-05\n",
      "Epoch 400/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.4834e-04 - val_loss: 9.0488e-05\n",
      "Epoch 401/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.5600e-04 - val_loss: 1.2079e-04\n",
      "Epoch 402/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.7277e-04 - val_loss: 2.2155e-04\n",
      "Epoch 403/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.0514e-04 - val_loss: 1.0893e-04\n",
      "Epoch 404/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.5810e-04 - val_loss: 8.9565e-05\n",
      "Epoch 405/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.6470e-04 - val_loss: 7.4751e-05\n",
      "Epoch 406/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.5634e-04 - val_loss: 7.5291e-05\n",
      "Epoch 407/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.5213e-04 - val_loss: 1.2768e-04\n",
      "Epoch 408/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.8640e-04 - val_loss: 1.7753e-04\n",
      "Epoch 409/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.9350e-04 - val_loss: 8.8529e-05\n",
      "Epoch 410/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.8033e-04 - val_loss: 7.5017e-05\n",
      "Epoch 411/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.6270e-04 - val_loss: 7.9583e-05\n",
      "Epoch 412/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.5738e-04 - val_loss: 1.2195e-04\n",
      "Epoch 413/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.7041e-04 - val_loss: 1.4190e-04\n",
      "Epoch 414/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.6883e-04 - val_loss: 2.8271e-04\n",
      "Epoch 415/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.8796e-04 - val_loss: 1.3954e-04\n",
      "Epoch 416/2000\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 1.7798e-04 - val_loss: 1.7618e-04\n",
      "Epoch 417/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.7417e-04 - val_loss: 7.8551e-05\n",
      "Epoch 418/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4979e-04 - val_loss: 1.5122e-04\n",
      "Epoch 419/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.6551e-04 - val_loss: 1.2981e-04\n",
      "Epoch 420/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.5770e-04 - val_loss: 9.2654e-05\n",
      "Epoch 421/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.5429e-04 - val_loss: 7.7562e-05\n",
      "Epoch 422/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 1.4950e-04 - val_loss: 1.0585e-04\n",
      "Epoch 423/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.7461e-04 - val_loss: 2.4442e-04\n",
      "Epoch 424/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.7251e-04 - val_loss: 1.4094e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.5933e-04 - val_loss: 1.1159e-04\n",
      "Epoch 426/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.7514e-04 - val_loss: 7.5728e-05\n",
      "Epoch 427/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.5640e-04 - val_loss: 1.3280e-04\n",
      "Epoch 428/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.6953e-04 - val_loss: 6.8677e-05\n",
      "Epoch 429/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 1.5687e-04 - val_loss: 9.4197e-05\n",
      "Epoch 430/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.7401e-04 - val_loss: 9.9226e-05\n",
      "Epoch 431/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.5365e-04 - val_loss: 1.4582e-04\n",
      "Epoch 432/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4763e-04 - val_loss: 9.3061e-05\n",
      "Epoch 433/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.4527e-04 - val_loss: 7.0464e-05\n",
      "Epoch 434/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 1.4324e-04 - val_loss: 9.4156e-05\n",
      "Epoch 435/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.4672e-04 - val_loss: 8.2933e-05\n",
      "Epoch 436/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.4998e-04 - val_loss: 6.8349e-05\n",
      "Epoch 437/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.6244e-04 - val_loss: 1.0887e-04\n",
      "Epoch 438/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 1.4772e-04 - val_loss: 6.7506e-05\n",
      "Epoch 439/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.4680e-04 - val_loss: 6.8174e-05\n",
      "Epoch 440/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.4338e-04 - val_loss: 8.6338e-05\n",
      "Epoch 441/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.5531e-04 - val_loss: 6.7302e-05\n",
      "Epoch 442/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.6699e-04 - val_loss: 6.7226e-05\n",
      "Epoch 443/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.2664e-04 - val_loss: 2.6981e-04\n",
      "Epoch 444/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.0492e-04 - val_loss: 2.8732e-04\n",
      "Epoch 445/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.0339e-04 - val_loss: 1.8390e-04\n",
      "Epoch 446/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.6968e-04 - val_loss: 1.3482e-04\n",
      "Epoch 447/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.6004e-04 - val_loss: 8.9551e-05\n",
      "Epoch 448/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.6999e-04 - val_loss: 7.7763e-05\n",
      "Epoch 449/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4755e-04 - val_loss: 5.0344e-04\n",
      "Epoch 450/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 3.1877e-04 - val_loss: 4.2117e-04\n",
      "Epoch 451/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.3730e-04 - val_loss: 2.6836e-04\n",
      "Epoch 452/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 2.3664e-04 - val_loss: 1.3403e-04\n",
      "Epoch 453/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.6937e-04 - val_loss: 6.6241e-05\n",
      "Epoch 454/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4714e-04 - val_loss: 6.5387e-05\n",
      "Epoch 455/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.3677e-04 - val_loss: 8.1081e-05\n",
      "Epoch 456/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 1.3766e-04 - val_loss: 8.7509e-05\n",
      "Epoch 457/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4018e-04 - val_loss: 6.0041e-04\n",
      "Epoch 458/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.8705e-04 - val_loss: 3.4645e-04\n",
      "Epoch 459/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.0038e-04 - val_loss: 6.6770e-05\n",
      "Epoch 460/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.4810e-04 - val_loss: 2.2330e-04\n",
      "Epoch 461/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 1.7875e-04 - val_loss: 1.4156e-04\n",
      "Epoch 462/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.7043e-04 - val_loss: 1.0794e-04\n",
      "Epoch 463/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.5912e-04 - val_loss: 7.1105e-05\n",
      "Epoch 464/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.3998e-04 - val_loss: 6.7326e-05\n",
      "Epoch 465/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.3507e-04 - val_loss: 1.0534e-04\n",
      "Epoch 466/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.5097e-04 - val_loss: 7.1981e-05\n",
      "Epoch 467/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.3997e-04 - val_loss: 1.6071e-04\n",
      "Epoch 468/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.8220e-04 - val_loss: 2.1521e-04\n",
      "Epoch 469/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.8198e-04 - val_loss: 7.9078e-05\n",
      "Epoch 470/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.5180e-04 - val_loss: 1.3441e-04\n",
      "Epoch 471/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.5606e-04 - val_loss: 3.4898e-04\n",
      "Epoch 472/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.1515e-04 - val_loss: 1.3483e-04\n",
      "Epoch 473/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.4304e-04 - val_loss: 1.8033e-04\n",
      "Epoch 474/2000\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 1.6357e-04 - val_loss: 1.5103e-04\n",
      "Epoch 475/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.5763e-04 - val_loss: 1.2608e-04\n",
      "Epoch 476/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.7956e-04 - val_loss: 3.3180e-04\n",
      "Epoch 477/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 2.0381e-04 - val_loss: 9.7725e-05\n",
      "Epoch 478/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.4082e-04 - val_loss: 9.3157e-05\n",
      "Epoch 479/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.4268e-04 - val_loss: 6.0394e-05\n",
      "Epoch 480/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.4491e-04 - val_loss: 6.6049e-05\n",
      "Epoch 481/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.3719e-04 - val_loss: 6.1401e-05\n",
      "Epoch 482/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.3140e-04 - val_loss: 6.3623e-05\n",
      "Epoch 483/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.4087e-04 - val_loss: 5.8917e-05\n",
      "Epoch 484/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2886e-04 - val_loss: 6.8131e-05\n",
      "Epoch 485/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.4187e-04 - val_loss: 6.9675e-05\n",
      "Epoch 486/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.4021e-04 - val_loss: 6.4221e-05\n",
      "Epoch 487/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3943e-04 - val_loss: 1.2369e-04\n",
      "Epoch 488/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.5386e-04 - val_loss: 1.9414e-04\n",
      "Epoch 489/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.6983e-04 - val_loss: 2.1137e-04\n",
      "Epoch 490/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.6613e-04 - val_loss: 6.6419e-05\n",
      "Epoch 491/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.5518e-04 - val_loss: 9.1552e-05\n",
      "Epoch 492/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.4682e-04 - val_loss: 1.4797e-04\n",
      "Epoch 493/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.5556e-04 - val_loss: 5.9037e-05\n",
      "Epoch 494/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2522e-04 - val_loss: 7.3380e-05\n",
      "Epoch 495/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2812e-04 - val_loss: 1.2168e-04\n",
      "Epoch 496/2000\n",
      "4143/4143 [==============================] - 3s 648us/step - loss: 1.3758e-04 - val_loss: 8.2102e-05\n",
      "Epoch 497/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.5554e-04 - val_loss: 7.1354e-05\n",
      "Epoch 498/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.2782e-04 - val_loss: 5.9698e-05\n",
      "Epoch 499/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.3299e-04 - val_loss: 9.4909e-05\n",
      "Epoch 500/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.3142e-04 - val_loss: 6.7652e-05\n",
      "Epoch 501/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.4763e-04 - val_loss: 1.4573e-04\n",
      "Epoch 502/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.5447e-04 - val_loss: 5.7192e-05\n",
      "Epoch 503/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.2897e-04 - val_loss: 6.9864e-05\n",
      "Epoch 504/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4053e-04 - val_loss: 7.5804e-05\n",
      "Epoch 505/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.3097e-04 - val_loss: 8.9764e-05\n",
      "Epoch 506/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.4235e-04 - val_loss: 1.9578e-04\n",
      "Epoch 507/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.7738e-04 - val_loss: 5.7992e-05\n",
      "Epoch 508/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.4323e-04 - val_loss: 6.4757e-05\n",
      "Epoch 509/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.3532e-04 - val_loss: 8.6043e-05\n",
      "Epoch 510/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.5006e-04 - val_loss: 1.3605e-04\n",
      "Epoch 511/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.8010e-04 - val_loss: 6.2893e-05\n",
      "Epoch 512/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.3557e-04 - val_loss: 5.9441e-05\n",
      "Epoch 513/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.3866e-04 - val_loss: 9.6931e-05\n",
      "Epoch 514/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.5602e-04 - val_loss: 9.6678e-05\n",
      "Epoch 515/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.6084e-04 - val_loss: 6.7634e-05\n",
      "Epoch 516/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.4595e-04 - val_loss: 5.6195e-05\n",
      "Epoch 517/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.3326e-04 - val_loss: 2.5263e-04\n",
      "Epoch 518/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.6192e-04 - val_loss: 1.1320e-04\n",
      "Epoch 519/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 1.6432e-04 - val_loss: 6.0391e-05\n",
      "Epoch 520/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.5915e-04 - val_loss: 5.5737e-05\n",
      "Epoch 521/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.3991e-04 - val_loss: 1.0444e-04\n",
      "Epoch 522/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.3946e-04 - val_loss: 1.0323e-04\n",
      "Epoch 523/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.3550e-04 - val_loss: 1.9043e-04\n",
      "Epoch 524/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.6206e-04 - val_loss: 6.8732e-05\n",
      "Epoch 525/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.3385e-04 - val_loss: 6.0072e-05\n",
      "Epoch 526/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4469e-04 - val_loss: 1.6322e-04\n",
      "Epoch 527/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.5724e-04 - val_loss: 5.7100e-05\n",
      "Epoch 528/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2560e-04 - val_loss: 8.5146e-05\n",
      "Epoch 529/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2894e-04 - val_loss: 6.4905e-05\n",
      "Epoch 530/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2336e-04 - val_loss: 5.9950e-05\n",
      "Epoch 531/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2332e-04 - val_loss: 7.1129e-05\n",
      "Epoch 532/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2921e-04 - val_loss: 1.2523e-04\n",
      "Epoch 533/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4745e-04 - val_loss: 6.0301e-05\n",
      "Epoch 534/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.4661e-04 - val_loss: 1.6514e-04\n",
      "Epoch 535/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4502e-04 - val_loss: 5.6752e-05\n",
      "Epoch 536/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4459e-04 - val_loss: 6.0116e-05\n",
      "Epoch 537/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.2653e-04 - val_loss: 1.0657e-04\n",
      "Epoch 538/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.4334e-04 - val_loss: 6.2710e-05\n",
      "Epoch 539/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.5009e-04 - val_loss: 1.9945e-04\n",
      "Epoch 540/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.7966e-04 - val_loss: 7.2668e-05\n",
      "Epoch 541/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.7458e-04 - val_loss: 1.2177e-04\n",
      "Epoch 542/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.3159e-04 - val_loss: 5.3948e-05\n",
      "Epoch 543/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.1750e-04 - val_loss: 1.7904e-04\n",
      "Epoch 544/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.7547e-04 - val_loss: 9.4035e-05\n",
      "Epoch 545/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.5484e-04 - val_loss: 5.5299e-05\n",
      "Epoch 546/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.3922e-04 - val_loss: 6.8368e-05\n",
      "Epoch 547/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.3917e-04 - val_loss: 1.0022e-04\n",
      "Epoch 548/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.7086e-04 - val_loss: 1.6191e-04\n",
      "Epoch 549/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 1.6555e-04 - val_loss: 5.5631e-05\n",
      "Epoch 550/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.3368e-04 - val_loss: 5.7982e-05\n",
      "Epoch 551/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2712e-04 - val_loss: 5.5953e-05\n",
      "Epoch 552/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2892e-04 - val_loss: 1.2931e-04\n",
      "Epoch 553/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4576e-04 - val_loss: 2.6850e-04\n",
      "Epoch 554/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.8647e-04 - val_loss: 1.0322e-04\n",
      "Epoch 555/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.6472e-04 - val_loss: 7.0807e-05\n",
      "Epoch 556/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4889e-04 - val_loss: 3.8840e-04\n",
      "Epoch 557/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.1671e-04 - val_loss: 2.9244e-04\n",
      "Epoch 558/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.1263e-04 - val_loss: 1.5749e-04\n",
      "Epoch 559/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 2.0001e-04 - val_loss: 9.2471e-05\n",
      "Epoch 560/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.5146e-04 - val_loss: 9.7519e-05\n",
      "Epoch 561/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.3605e-04 - val_loss: 2.2667e-04\n",
      "Epoch 562/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.4234e-04 - val_loss: 9.3368e-05\n",
      "Epoch 563/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.3081e-04 - val_loss: 1.0558e-04\n",
      "Epoch 564/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2871e-04 - val_loss: 6.5843e-05\n",
      "Epoch 565/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.2201e-04 - val_loss: 9.5700e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 566/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2076e-04 - val_loss: 1.2309e-04\n",
      "Epoch 567/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.3010e-04 - val_loss: 7.6633e-05\n",
      "Epoch 568/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.3711e-04 - val_loss: 1.6107e-04\n",
      "Epoch 569/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.6893e-04 - val_loss: 1.0583e-04\n",
      "Epoch 570/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.6838e-04 - val_loss: 8.9442e-05\n",
      "Epoch 571/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4911e-04 - val_loss: 7.7826e-05\n",
      "Epoch 572/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.3321e-04 - val_loss: 1.0397e-04\n",
      "Epoch 573/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.4254e-04 - val_loss: 5.7498e-05\n",
      "Epoch 574/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.3592e-04 - val_loss: 5.7343e-05\n",
      "Epoch 575/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.3819e-04 - val_loss: 1.5094e-04\n",
      "Epoch 576/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.5208e-04 - val_loss: 1.4354e-04\n",
      "Epoch 577/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.6180e-04 - val_loss: 5.8087e-05\n",
      "Epoch 578/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.3964e-04 - val_loss: 7.8467e-05\n",
      "Epoch 579/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3014e-04 - val_loss: 7.5042e-05\n",
      "Epoch 580/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 1.3562e-04 - val_loss: 1.6986e-04\n",
      "Epoch 581/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.7840e-04 - val_loss: 6.2071e-05\n",
      "Epoch 582/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.3570e-04 - val_loss: 9.5601e-05\n",
      "Epoch 583/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.3552e-04 - val_loss: 8.0936e-05\n",
      "Epoch 584/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2194e-04 - val_loss: 5.7010e-05\n",
      "Epoch 585/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2383e-04 - val_loss: 7.0506e-05\n",
      "Epoch 586/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2106e-04 - val_loss: 8.0439e-05\n",
      "Epoch 587/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3112e-04 - val_loss: 4.6487e-04\n",
      "Epoch 588/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.3632e-04 - val_loss: 9.1565e-05\n",
      "Epoch 589/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4752e-04 - val_loss: 6.2485e-05\n",
      "Epoch 590/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3517e-04 - val_loss: 1.0937e-04\n",
      "Epoch 591/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4319e-04 - val_loss: 2.6735e-04\n",
      "Epoch 592/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 2.0297e-04 - val_loss: 6.8783e-05\n",
      "Epoch 593/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.7099e-04 - val_loss: 2.0784e-04\n",
      "Epoch 594/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.7303e-04 - val_loss: 5.3232e-04\n",
      "Epoch 595/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 2.2233e-04 - val_loss: 7.0507e-05\n",
      "Epoch 596/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.4021e-04 - val_loss: 8.6478e-05\n",
      "Epoch 597/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3850e-04 - val_loss: 2.0415e-04\n",
      "Epoch 598/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.6200e-04 - val_loss: 1.1303e-04\n",
      "Epoch 599/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.3066e-04 - val_loss: 5.8368e-05\n",
      "Epoch 600/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2836e-04 - val_loss: 5.3558e-05\n",
      "Epoch 601/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2793e-04 - val_loss: 3.2977e-04\n",
      "Epoch 602/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.7834e-04 - val_loss: 8.2271e-05\n",
      "Epoch 603/2000\n",
      "4143/4143 [==============================] - 3s 646us/step - loss: 1.2587e-04 - val_loss: 1.5757e-04\n",
      "Epoch 604/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.6349e-04 - val_loss: 5.2391e-05\n",
      "Epoch 605/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3376e-04 - val_loss: 6.4641e-05\n",
      "Epoch 606/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.3421e-04 - val_loss: 8.8352e-05\n",
      "Epoch 607/2000\n",
      "4143/4143 [==============================] - 3s 646us/step - loss: 1.3401e-04 - val_loss: 5.5110e-05\n",
      "Epoch 608/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2065e-04 - val_loss: 5.5055e-05\n",
      "Epoch 609/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2240e-04 - val_loss: 1.7654e-04\n",
      "Epoch 610/2000\n",
      "4143/4143 [==============================] - 3s 646us/step - loss: 1.5344e-04 - val_loss: 5.2604e-05\n",
      "Epoch 611/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3055e-04 - val_loss: 5.1949e-05\n",
      "Epoch 612/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2081e-04 - val_loss: 5.4548e-05\n",
      "Epoch 613/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3030e-04 - val_loss: 6.1685e-05\n",
      "Epoch 614/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.2458e-04 - val_loss: 5.7231e-05\n",
      "Epoch 615/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2173e-04 - val_loss: 6.8990e-05\n",
      "Epoch 616/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.2356e-04 - val_loss: 5.5752e-05\n",
      "Epoch 617/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2477e-04 - val_loss: 5.2300e-05\n",
      "Epoch 618/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.2081e-04 - val_loss: 1.4065e-04\n",
      "Epoch 619/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.3390e-04 - val_loss: 5.2184e-05\n",
      "Epoch 620/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2363e-04 - val_loss: 1.4264e-04\n",
      "Epoch 621/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.4749e-04 - val_loss: 1.3683e-04\n",
      "Epoch 622/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.6402e-04 - val_loss: 2.7492e-04\n",
      "Epoch 623/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.3837e-04 - val_loss: 1.5228e-04\n",
      "Epoch 624/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.3181e-04 - val_loss: 1.1752e-04\n",
      "Epoch 625/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.7112e-04 - val_loss: 1.7343e-04\n",
      "Epoch 626/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.6894e-04 - val_loss: 1.4409e-04\n",
      "Epoch 627/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4980e-04 - val_loss: 9.9063e-05\n",
      "Epoch 628/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2830e-04 - val_loss: 5.5709e-05\n",
      "Epoch 629/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2762e-04 - val_loss: 1.8271e-04\n",
      "Epoch 630/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.4329e-04 - val_loss: 1.4327e-04\n",
      "Epoch 631/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.3831e-04 - val_loss: 1.6037e-04\n",
      "Epoch 632/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.4589e-04 - val_loss: 6.5177e-05\n",
      "Epoch 633/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2269e-04 - val_loss: 1.0526e-04\n",
      "Epoch 634/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.5440e-04 - val_loss: 5.3366e-05\n",
      "Epoch 635/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4130e-04 - val_loss: 5.8830e-05\n",
      "Epoch 636/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.3599e-04 - val_loss: 1.5228e-04\n",
      "Epoch 637/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.5176e-04 - val_loss: 6.3381e-05\n",
      "Epoch 638/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.4350e-04 - val_loss: 8.3711e-05\n",
      "Epoch 639/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.7009e-04 - val_loss: 5.7657e-05\n",
      "Epoch 640/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2626e-04 - val_loss: 7.2323e-05\n",
      "Epoch 641/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2251e-04 - val_loss: 9.0707e-05\n",
      "Epoch 642/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.3085e-04 - val_loss: 8.8354e-05\n",
      "Epoch 643/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2446e-04 - val_loss: 6.1653e-05\n",
      "Epoch 644/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2323e-04 - val_loss: 1.3748e-04\n",
      "Epoch 645/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.5220e-04 - val_loss: 1.4042e-04\n",
      "Epoch 646/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.3308e-04 - val_loss: 1.7577e-04\n",
      "Epoch 647/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.5816e-04 - val_loss: 1.3933e-04\n",
      "Epoch 648/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.2968e-04 - val_loss: 7.9073e-05\n",
      "Epoch 649/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.2590e-04 - val_loss: 1.3519e-04\n",
      "Epoch 650/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.3900e-04 - val_loss: 9.6578e-05\n",
      "Epoch 651/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.2594e-04 - val_loss: 6.8865e-05\n",
      "Epoch 652/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.2172e-04 - val_loss: 5.5510e-05\n",
      "Epoch 653/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.1957e-04 - val_loss: 7.8907e-05\n",
      "Epoch 654/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.2100e-04 - val_loss: 9.7514e-05\n",
      "Epoch 655/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2752e-04 - val_loss: 1.3408e-04\n",
      "Epoch 656/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.3850e-04 - val_loss: 1.1162e-04\n",
      "Epoch 657/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.3686e-04 - val_loss: 1.5619e-04\n",
      "Epoch 658/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.6689e-04 - val_loss: 6.5073e-05\n",
      "Epoch 659/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.4736e-04 - val_loss: 8.0688e-05\n",
      "Epoch 660/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.0932e-04 - val_loss: 2.7108e-04\n",
      "Epoch 661/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.7407e-04 - val_loss: 9.2579e-05\n",
      "Epoch 662/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.3364e-04 - val_loss: 5.1799e-05\n",
      "Epoch 663/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1813e-04 - val_loss: 1.0962e-04\n",
      "Epoch 664/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.3673e-04 - val_loss: 6.2708e-05\n",
      "Epoch 665/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1535e-04 - val_loss: 5.1912e-05\n",
      "Epoch 666/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1483e-04 - val_loss: 1.5353e-04\n",
      "Epoch 667/2000\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 1.3550e-04 - val_loss: 1.7984e-04\n",
      "Epoch 668/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.4374e-04 - val_loss: 7.6070e-05\n",
      "Epoch 669/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.1253e-04 - val_loss: 5.3548e-05\n",
      "Epoch 670/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.1514e-04 - val_loss: 2.3062e-04\n",
      "Epoch 671/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.6166e-04 - val_loss: 1.1881e-04\n",
      "Epoch 672/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.7100e-04 - val_loss: 7.9646e-05\n",
      "Epoch 673/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.8755e-04 - val_loss: 6.1159e-05\n",
      "Epoch 674/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4157e-04 - val_loss: 5.1253e-05\n",
      "Epoch 675/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.3553e-04 - val_loss: 5.4914e-05\n",
      "Epoch 676/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.4011e-04 - val_loss: 1.5110e-04\n",
      "Epoch 677/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.6881e-04 - val_loss: 2.5719e-04\n",
      "Epoch 678/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.5276e-04 - val_loss: 1.6271e-04\n",
      "Epoch 679/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.4944e-04 - val_loss: 1.9717e-04\n",
      "Epoch 680/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4708e-04 - val_loss: 4.5121e-04\n",
      "Epoch 681/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 2.2737e-04 - val_loss: 2.2563e-04\n",
      "Epoch 682/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.3958e-04 - val_loss: 1.9267e-04\n",
      "Epoch 683/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.4849e-04 - val_loss: 2.5314e-04\n",
      "Epoch 684/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.6068e-04 - val_loss: 1.4249e-04\n",
      "Epoch 685/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.7752e-04 - val_loss: 2.3612e-04\n",
      "Epoch 686/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.7767e-04 - val_loss: 1.0171e-04\n",
      "Epoch 687/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.3839e-04 - val_loss: 3.5165e-04\n",
      "Epoch 688/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.8738e-04 - val_loss: 5.0824e-04\n",
      "Epoch 689/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.2817e-04 - val_loss: 4.6413e-04\n",
      "Epoch 690/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.2096e-04 - val_loss: 6.4417e-05\n",
      "Epoch 691/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4767e-04 - val_loss: 6.5780e-05\n",
      "Epoch 692/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.4391e-04 - val_loss: 5.3053e-05\n",
      "Epoch 693/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.5964e-04 - val_loss: 1.4200e-04\n",
      "Epoch 694/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.6696e-04 - val_loss: 2.6895e-04\n",
      "Epoch 695/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.6845e-04 - val_loss: 1.3006e-04\n",
      "Epoch 696/2000\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 1.2530e-04 - val_loss: 6.7571e-05\n",
      "Epoch 697/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1787e-04 - val_loss: 6.5547e-05\n",
      "Epoch 698/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2525e-04 - val_loss: 5.3288e-05\n",
      "Epoch 699/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1956e-04 - val_loss: 5.4469e-05\n",
      "Epoch 700/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1711e-04 - val_loss: 9.4540e-05\n",
      "Epoch 701/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2304e-04 - val_loss: 7.3311e-05\n",
      "Epoch 702/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 1.1854e-04 - val_loss: 4.9911e-05\n",
      "Epoch 703/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.1098e-04 - val_loss: 8.7361e-05\n",
      "Epoch 704/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.2250e-04 - val_loss: 1.1368e-04\n",
      "Epoch 705/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.3676e-04 - val_loss: 8.9769e-05\n",
      "Epoch 706/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4123e-04 - val_loss: 5.1424e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 707/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.1533e-04 - val_loss: 6.0259e-05\n",
      "Epoch 708/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.1417e-04 - val_loss: 6.8130e-05\n",
      "Epoch 709/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2468e-04 - val_loss: 5.3785e-05\n",
      "Epoch 710/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1587e-04 - val_loss: 1.3148e-04\n",
      "Epoch 711/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4562e-04 - val_loss: 2.6597e-04\n",
      "Epoch 712/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.5382e-04 - val_loss: 6.0645e-05\n",
      "Epoch 713/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.2322e-04 - val_loss: 8.8780e-05\n",
      "Epoch 714/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.2354e-04 - val_loss: 1.2849e-04\n",
      "Epoch 715/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2580e-04 - val_loss: 2.2796e-04\n",
      "Epoch 716/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.4732e-04 - val_loss: 1.2199e-04\n",
      "Epoch 717/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1918e-04 - val_loss: 7.0044e-05\n",
      "Epoch 718/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2504e-04 - val_loss: 5.0812e-05\n",
      "Epoch 719/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.0702e-04 - val_loss: 1.4024e-04\n",
      "Epoch 720/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.5515e-04 - val_loss: 6.3890e-05\n",
      "Epoch 721/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2848e-04 - val_loss: 1.2792e-04\n",
      "Epoch 722/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.3019e-04 - val_loss: 9.6192e-05\n",
      "Epoch 723/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2974e-04 - val_loss: 5.7838e-05\n",
      "Epoch 724/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.1972e-04 - val_loss: 1.4494e-04\n",
      "Epoch 725/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.2629e-04 - val_loss: 6.4919e-05\n",
      "Epoch 726/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.1452e-04 - val_loss: 8.4666e-05\n",
      "Epoch 727/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.3313e-04 - val_loss: 5.0212e-05\n",
      "Epoch 728/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2143e-04 - val_loss: 5.6842e-05\n",
      "Epoch 729/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.1574e-04 - val_loss: 5.0435e-05\n",
      "Epoch 730/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 1.1694e-04 - val_loss: 1.1086e-04\n",
      "Epoch 731/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2558e-04 - val_loss: 5.0107e-05\n",
      "Epoch 732/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1301e-04 - val_loss: 5.0930e-05\n",
      "Epoch 733/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1398e-04 - val_loss: 1.2579e-04\n",
      "Epoch 734/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2163e-04 - val_loss: 8.0166e-05\n",
      "Epoch 735/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2584e-04 - val_loss: 5.3691e-05\n",
      "Epoch 736/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0769e-04 - val_loss: 5.6306e-05\n",
      "Epoch 737/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1190e-04 - val_loss: 7.0936e-05\n",
      "Epoch 738/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0909e-04 - val_loss: 9.8908e-05\n",
      "Epoch 739/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2200e-04 - val_loss: 5.8192e-05\n",
      "Epoch 740/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.5727e-04 - val_loss: 7.2490e-04\n",
      "Epoch 741/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.6520e-04 - val_loss: 1.6756e-04\n",
      "Epoch 742/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.5484e-04 - val_loss: 5.0805e-05\n",
      "Epoch 743/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.2466e-04 - val_loss: 7.2486e-05\n",
      "Epoch 744/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.1990e-04 - val_loss: 1.1242e-04\n",
      "Epoch 745/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.2859e-04 - val_loss: 1.1065e-04\n",
      "Epoch 746/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2620e-04 - val_loss: 5.7701e-05\n",
      "Epoch 747/2000\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 1.1629e-04 - val_loss: 1.7047e-04\n",
      "Epoch 748/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3981e-04 - val_loss: 5.1446e-05\n",
      "Epoch 749/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.1499e-04 - val_loss: 1.1677e-04\n",
      "Epoch 750/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.5205e-04 - val_loss: 7.7279e-05\n",
      "Epoch 751/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2439e-04 - val_loss: 6.6792e-05\n",
      "Epoch 752/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.3708e-04 - val_loss: 5.5992e-05\n",
      "Epoch 753/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.2756e-04 - val_loss: 6.1078e-05\n",
      "Epoch 754/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 1.0645e-04 - val_loss: 6.2832e-05\n",
      "Epoch 755/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.1045e-04 - val_loss: 2.4684e-04\n",
      "Epoch 756/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.5131e-04 - val_loss: 1.7971e-04\n",
      "Epoch 757/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.5029e-04 - val_loss: 6.3169e-05\n",
      "Epoch 758/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2659e-04 - val_loss: 6.1583e-05\n",
      "Epoch 759/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 1.1706e-04 - val_loss: 5.8648e-05\n",
      "Epoch 760/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1666e-04 - val_loss: 6.4197e-05\n",
      "Epoch 761/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.1215e-04 - val_loss: 4.5826e-04\n",
      "Epoch 762/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 2.7723e-04 - val_loss: 6.5162e-05\n",
      "Epoch 763/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.4527e-04 - val_loss: 5.2403e-05\n",
      "Epoch 764/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2529e-04 - val_loss: 5.2657e-05\n",
      "Epoch 765/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.0989e-04 - val_loss: 5.4579e-05\n",
      "Epoch 766/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.0698e-04 - val_loss: 8.6778e-05\n",
      "Epoch 767/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1091e-04 - val_loss: 1.4035e-04\n",
      "Epoch 768/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.3893e-04 - val_loss: 1.0261e-04\n",
      "Epoch 769/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.2660e-04 - val_loss: 9.6862e-05\n",
      "Epoch 770/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1732e-04 - val_loss: 8.6048e-05\n",
      "Epoch 771/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1461e-04 - val_loss: 5.0715e-05\n",
      "Epoch 772/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.1749e-04 - val_loss: 1.2245e-04\n",
      "Epoch 773/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2943e-04 - val_loss: 6.4130e-05\n",
      "Epoch 774/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.0939e-04 - val_loss: 6.0331e-05\n",
      "Epoch 775/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.0591e-04 - val_loss: 9.5463e-05\n",
      "Epoch 776/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.3477e-04 - val_loss: 6.3528e-05\n",
      "Epoch 777/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4241e-04 - val_loss: 1.3967e-04\n",
      "Epoch 778/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2055e-04 - val_loss: 6.1273e-05\n",
      "Epoch 779/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1260e-04 - val_loss: 6.7612e-05\n",
      "Epoch 780/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1544e-04 - val_loss: 1.2011e-04\n",
      "Epoch 781/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.3939e-04 - val_loss: 6.1998e-05\n",
      "Epoch 782/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2572e-04 - val_loss: 5.0384e-05\n",
      "Epoch 783/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.3383e-04 - val_loss: 9.1379e-05\n",
      "Epoch 784/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.3535e-04 - val_loss: 8.4020e-05\n",
      "Epoch 785/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.3930e-04 - val_loss: 2.4170e-04\n",
      "Epoch 786/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.5803e-04 - val_loss: 1.3252e-04\n",
      "Epoch 787/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.6058e-04 - val_loss: 1.3430e-04\n",
      "Epoch 788/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1783e-04 - val_loss: 1.3150e-04\n",
      "Epoch 789/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.2587e-04 - val_loss: 6.8287e-05\n",
      "Epoch 790/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2938e-04 - val_loss: 5.0435e-05\n",
      "Epoch 791/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2085e-04 - val_loss: 9.3787e-05\n",
      "Epoch 792/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 1.1978e-04 - val_loss: 5.1177e-05\n",
      "Epoch 793/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.2633e-04 - val_loss: 5.3640e-05\n",
      "Epoch 794/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1033e-04 - val_loss: 1.3138e-04\n",
      "Epoch 795/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.1731e-04 - val_loss: 1.1904e-04\n",
      "Epoch 796/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.1837e-04 - val_loss: 1.4074e-04\n",
      "Epoch 797/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.7530e-04 - val_loss: 2.6004e-04\n",
      "Epoch 798/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.8866e-04 - val_loss: 4.5653e-04\n",
      "Epoch 799/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.5695e-04 - val_loss: 5.0331e-04\n",
      "Epoch 800/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 2.4123e-04 - val_loss: 2.9677e-04\n",
      "Epoch 801/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.5675e-04 - val_loss: 2.8629e-04\n",
      "Epoch 802/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 2.0290e-04 - val_loss: 3.6713e-04\n",
      "Epoch 803/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.9243e-04 - val_loss: 2.3525e-04\n",
      "Epoch 804/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 1.6621e-04 - val_loss: 6.7800e-05\n",
      "Epoch 805/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2603e-04 - val_loss: 1.9938e-04\n",
      "Epoch 806/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.6056e-04 - val_loss: 1.7162e-04\n",
      "Epoch 807/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.4691e-04 - val_loss: 1.2519e-04\n",
      "Epoch 808/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.5881e-04 - val_loss: 5.5980e-05\n",
      "Epoch 809/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.3276e-04 - val_loss: 5.3951e-05\n",
      "Epoch 810/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1443e-04 - val_loss: 5.0151e-05\n",
      "Epoch 811/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0967e-04 - val_loss: 5.1914e-05\n",
      "Epoch 812/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0744e-04 - val_loss: 5.1467e-05\n",
      "Epoch 813/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0556e-04 - val_loss: 5.2874e-05\n",
      "Epoch 814/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0767e-04 - val_loss: 7.6985e-05\n",
      "Epoch 815/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1205e-04 - val_loss: 4.9235e-05\n",
      "Epoch 816/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.3205e-04 - val_loss: 8.5269e-05\n",
      "Epoch 817/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1361e-04 - val_loss: 5.0110e-05\n",
      "Epoch 818/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0266e-04 - val_loss: 7.3495e-05\n",
      "Epoch 819/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2624e-04 - val_loss: 5.0053e-05\n",
      "Epoch 820/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1992e-04 - val_loss: 9.2005e-05\n",
      "Epoch 821/2000\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 1.2228e-04 - val_loss: 1.0120e-04\n",
      "Epoch 822/2000\n",
      "4143/4143 [==============================] - 3s 652us/step - loss: 1.1757e-04 - val_loss: 1.3559e-04\n",
      "Epoch 823/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 1.5303e-04 - val_loss: 5.7213e-05\n",
      "Epoch 824/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0593e-04 - val_loss: 7.6998e-05\n",
      "Epoch 825/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1282e-04 - val_loss: 5.2906e-05\n",
      "Epoch 826/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0097e-04 - val_loss: 1.0294e-04\n",
      "Epoch 827/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1696e-04 - val_loss: 5.4226e-05\n",
      "Epoch 828/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.1980e-04 - val_loss: 5.4967e-05\n",
      "Epoch 829/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.1685e-04 - val_loss: 2.4432e-04\n",
      "Epoch 830/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.6651e-04 - val_loss: 3.9754e-04\n",
      "Epoch 831/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.9601e-04 - val_loss: 1.4057e-04\n",
      "Epoch 832/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.4251e-04 - val_loss: 9.2412e-05\n",
      "Epoch 833/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2376e-04 - val_loss: 5.0074e-05\n",
      "Epoch 834/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.0849e-04 - val_loss: 1.9816e-04\n",
      "Epoch 835/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.3898e-04 - val_loss: 1.0492e-04\n",
      "Epoch 836/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.4373e-04 - val_loss: 2.9142e-04\n",
      "Epoch 837/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.6714e-04 - val_loss: 2.0665e-04\n",
      "Epoch 838/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.8681e-04 - val_loss: 3.8364e-04\n",
      "Epoch 839/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.7012e-04 - val_loss: 7.7906e-05\n",
      "Epoch 840/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0655e-04 - val_loss: 6.5096e-05\n",
      "Epoch 841/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0442e-04 - val_loss: 5.3626e-05\n",
      "Epoch 842/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0426e-04 - val_loss: 5.4543e-05\n",
      "Epoch 843/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0108e-04 - val_loss: 7.7348e-05\n",
      "Epoch 844/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0827e-04 - val_loss: 7.8012e-05\n",
      "Epoch 845/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2905e-04 - val_loss: 2.0235e-04\n",
      "Epoch 846/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.7217e-04 - val_loss: 1.1885e-04\n",
      "Epoch 847/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.4533e-04 - val_loss: 6.8642e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0904e-04 - val_loss: 5.2640e-05\n",
      "Epoch 849/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0912e-04 - val_loss: 6.0722e-05\n",
      "Epoch 850/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.1687e-04 - val_loss: 2.1942e-04\n",
      "Epoch 851/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.6298e-04 - val_loss: 5.7847e-05\n",
      "Epoch 852/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1167e-04 - val_loss: 6.8083e-05\n",
      "Epoch 853/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0556e-04 - val_loss: 5.8511e-05\n",
      "Epoch 854/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.9797e-05 - val_loss: 4.9604e-05\n",
      "Epoch 855/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0037e-04 - val_loss: 9.9291e-05\n",
      "Epoch 856/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2080e-04 - val_loss: 6.5736e-05\n",
      "Epoch 857/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0831e-04 - val_loss: 5.6942e-05\n",
      "Epoch 858/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.1197e-04 - val_loss: 2.7926e-04\n",
      "Epoch 859/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.5683e-04 - val_loss: 1.2607e-04\n",
      "Epoch 860/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.4159e-04 - val_loss: 1.4998e-04\n",
      "Epoch 861/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.3010e-04 - val_loss: 1.6772e-04\n",
      "Epoch 862/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2947e-04 - val_loss: 1.0193e-04\n",
      "Epoch 863/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1597e-04 - val_loss: 5.8439e-05\n",
      "Epoch 864/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0077e-04 - val_loss: 5.0109e-05\n",
      "Epoch 865/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1061e-04 - val_loss: 5.8658e-05\n",
      "Epoch 866/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1652e-04 - val_loss: 4.2399e-04\n",
      "Epoch 867/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.9466e-04 - val_loss: 1.6416e-04\n",
      "Epoch 868/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 1.6155e-04 - val_loss: 9.1216e-05\n",
      "Epoch 869/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3226e-04 - val_loss: 5.2827e-05\n",
      "Epoch 870/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0181e-04 - val_loss: 6.0630e-05\n",
      "Epoch 871/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.0811e-04 - val_loss: 1.7927e-04\n",
      "Epoch 872/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2346e-04 - val_loss: 9.0793e-05\n",
      "Epoch 873/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1068e-04 - val_loss: 8.1879e-05\n",
      "Epoch 874/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0674e-04 - val_loss: 5.1628e-05\n",
      "Epoch 875/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0792e-04 - val_loss: 7.1936e-05\n",
      "Epoch 876/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0453e-04 - val_loss: 4.9497e-05\n",
      "Epoch 877/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.1830e-04 - val_loss: 5.0889e-05\n",
      "Epoch 878/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1649e-04 - val_loss: 4.9724e-05\n",
      "Epoch 879/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.1882e-04 - val_loss: 4.8171e-05\n",
      "Epoch 880/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0904e-04 - val_loss: 2.2893e-04\n",
      "Epoch 881/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.8180e-04 - val_loss: 4.9236e-05\n",
      "Epoch 882/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2350e-04 - val_loss: 1.0089e-04\n",
      "Epoch 883/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.2385e-04 - val_loss: 5.2885e-05\n",
      "Epoch 884/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1545e-04 - val_loss: 5.8298e-05\n",
      "Epoch 885/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.1083e-04 - val_loss: 8.5091e-05\n",
      "Epoch 886/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1973e-04 - val_loss: 4.8584e-05\n",
      "Epoch 887/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0346e-04 - val_loss: 4.9228e-05\n",
      "Epoch 888/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0527e-04 - val_loss: 3.3828e-04\n",
      "Epoch 889/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 2.0144e-04 - val_loss: 1.4646e-04\n",
      "Epoch 890/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.5243e-04 - val_loss: 4.9539e-05\n",
      "Epoch 891/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0709e-04 - val_loss: 5.1004e-05\n",
      "Epoch 892/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0546e-04 - val_loss: 7.1543e-05\n",
      "Epoch 893/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1189e-04 - val_loss: 1.0204e-04\n",
      "Epoch 894/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1538e-04 - val_loss: 7.5407e-05\n",
      "Epoch 895/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 9.9108e-05 - val_loss: 4.9634e-05\n",
      "Epoch 896/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0916e-04 - val_loss: 5.3260e-05\n",
      "Epoch 897/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2579e-04 - val_loss: 8.1387e-05\n",
      "Epoch 898/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4282e-04 - val_loss: 1.3162e-04\n",
      "Epoch 899/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.6723e-04 - val_loss: 7.1757e-05\n",
      "Epoch 900/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.4940e-04 - val_loss: 5.5464e-05\n",
      "Epoch 901/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2709e-04 - val_loss: 4.9852e-05\n",
      "Epoch 902/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2195e-04 - val_loss: 9.7111e-05\n",
      "Epoch 903/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0869e-04 - val_loss: 5.4115e-05\n",
      "Epoch 904/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.7156e-05 - val_loss: 1.3677e-04\n",
      "Epoch 905/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.1378e-04 - val_loss: 1.4837e-04\n",
      "Epoch 906/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.3016e-04 - val_loss: 8.5464e-05\n",
      "Epoch 907/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2309e-04 - val_loss: 3.3749e-04\n",
      "Epoch 908/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.7106e-04 - val_loss: 6.0381e-05\n",
      "Epoch 909/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1535e-04 - val_loss: 4.9105e-05\n",
      "Epoch 910/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0556e-04 - val_loss: 5.9021e-05\n",
      "Epoch 911/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.0975e-04 - val_loss: 7.9181e-05\n",
      "Epoch 912/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.4141e-04 - val_loss: 1.6540e-04\n",
      "Epoch 913/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.5124e-04 - val_loss: 1.6882e-04\n",
      "Epoch 914/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.6841e-04 - val_loss: 4.8019e-05\n",
      "Epoch 915/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 1.1922e-04 - val_loss: 1.1292e-04\n",
      "Epoch 916/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1755e-04 - val_loss: 1.2370e-04\n",
      "Epoch 917/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.1212e-04 - val_loss: 7.9943e-05\n",
      "Epoch 918/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.0923e-04 - val_loss: 1.5989e-04\n",
      "Epoch 919/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1521e-04 - val_loss: 6.4751e-05\n",
      "Epoch 920/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1533e-04 - val_loss: 5.1749e-05\n",
      "Epoch 921/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0235e-04 - val_loss: 2.8464e-04\n",
      "Epoch 922/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.5320e-04 - val_loss: 1.2113e-04\n",
      "Epoch 923/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2603e-04 - val_loss: 1.2816e-04\n",
      "Epoch 924/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1643e-04 - val_loss: 8.1470e-05\n",
      "Epoch 925/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.1935e-04 - val_loss: 6.8087e-05\n",
      "Epoch 926/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.1104e-04 - val_loss: 9.1602e-05\n",
      "Epoch 927/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1084e-04 - val_loss: 4.8279e-05\n",
      "Epoch 928/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0316e-04 - val_loss: 5.9852e-05\n",
      "Epoch 929/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.2058e-04 - val_loss: 6.3223e-05\n",
      "Epoch 930/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0665e-04 - val_loss: 5.1636e-05\n",
      "Epoch 931/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 9.4489e-05 - val_loss: 5.8104e-05\n",
      "Epoch 932/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.8389e-05 - val_loss: 6.2894e-05\n",
      "Epoch 933/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.2232e-04 - val_loss: 2.8636e-04\n",
      "Epoch 934/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 2.0363e-04 - val_loss: 6.2697e-05\n",
      "Epoch 935/2000\n",
      "4143/4143 [==============================] - 3s 652us/step - loss: 1.3708e-04 - val_loss: 6.4487e-05\n",
      "Epoch 936/2000\n",
      "4143/4143 [==============================] - 3s 647us/step - loss: 1.0968e-04 - val_loss: 7.7571e-05\n",
      "Epoch 937/2000\n",
      "4143/4143 [==============================] - 3s 649us/step - loss: 1.0513e-04 - val_loss: 3.1715e-04\n",
      "Epoch 938/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.8644e-04 - val_loss: 6.0875e-05\n",
      "Epoch 939/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3112e-04 - val_loss: 6.5897e-05\n",
      "Epoch 940/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.2758e-04 - val_loss: 9.1586e-05\n",
      "Epoch 941/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1502e-04 - val_loss: 6.8297e-05\n",
      "Epoch 942/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0256e-04 - val_loss: 1.4757e-04\n",
      "Epoch 943/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1977e-04 - val_loss: 4.9826e-05\n",
      "Epoch 944/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0172e-04 - val_loss: 5.1521e-05\n",
      "Epoch 945/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0023e-04 - val_loss: 9.6026e-05\n",
      "Epoch 946/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.1084e-04 - val_loss: 5.2527e-05\n",
      "Epoch 947/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 9.8277e-05 - val_loss: 7.4707e-05\n",
      "Epoch 948/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.7078e-05 - val_loss: 8.4244e-05\n",
      "Epoch 949/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2395e-04 - val_loss: 1.4904e-04\n",
      "Epoch 950/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2485e-04 - val_loss: 5.8169e-05\n",
      "Epoch 951/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1249e-04 - val_loss: 7.1803e-05\n",
      "Epoch 952/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.0350e-04 - val_loss: 8.5585e-05\n",
      "Epoch 953/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0854e-04 - val_loss: 5.1032e-05\n",
      "Epoch 954/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.0158e-05 - val_loss: 5.6694e-05\n",
      "Epoch 955/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.6826e-05 - val_loss: 1.9294e-04\n",
      "Epoch 956/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.5397e-04 - val_loss: 5.4033e-05\n",
      "Epoch 957/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0867e-04 - val_loss: 5.5985e-05\n",
      "Epoch 958/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0190e-04 - val_loss: 1.0319e-04\n",
      "Epoch 959/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2340e-04 - val_loss: 5.8797e-05\n",
      "Epoch 960/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.0052e-04 - val_loss: 4.9314e-05\n",
      "Epoch 961/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.9656e-05 - val_loss: 8.2784e-05\n",
      "Epoch 962/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0730e-04 - val_loss: 4.8118e-05\n",
      "Epoch 963/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.5796e-05 - val_loss: 5.2905e-05\n",
      "Epoch 964/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.8629e-05 - val_loss: 5.2649e-05\n",
      "Epoch 965/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.7172e-05 - val_loss: 6.2260e-05\n",
      "Epoch 966/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.8289e-05 - val_loss: 8.1463e-05\n",
      "Epoch 967/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.0148e-04 - val_loss: 5.9028e-05\n",
      "Epoch 968/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.2406e-04 - val_loss: 3.2578e-04\n",
      "Epoch 969/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.6044e-04 - val_loss: 1.0762e-04\n",
      "Epoch 970/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.5957e-04 - val_loss: 5.6141e-05\n",
      "Epoch 971/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.9109e-04 - val_loss: 1.7188e-04\n",
      "Epoch 972/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.7620e-04 - val_loss: 1.2119e-04\n",
      "Epoch 973/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2848e-04 - val_loss: 9.0658e-05\n",
      "Epoch 974/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0731e-04 - val_loss: 6.9158e-05\n",
      "Epoch 975/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.0504e-04 - val_loss: 5.0764e-05\n",
      "Epoch 976/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1377e-04 - val_loss: 4.8260e-05\n",
      "Epoch 977/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0749e-04 - val_loss: 6.8299e-05\n",
      "Epoch 978/2000\n",
      "4143/4143 [==============================] - 3s 649us/step - loss: 1.0235e-04 - val_loss: 5.7172e-05\n",
      "Epoch 979/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.9937e-05 - val_loss: 4.9780e-05\n",
      "Epoch 980/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 9.9068e-05 - val_loss: 4.8478e-05\n",
      "Epoch 981/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.2491e-04 - val_loss: 1.6669e-04\n",
      "Epoch 982/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.1233e-04 - val_loss: 6.1924e-05\n",
      "Epoch 983/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.1426e-05 - val_loss: 9.9345e-05\n",
      "Epoch 984/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1497e-04 - val_loss: 5.4391e-05\n",
      "Epoch 985/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 9.5112e-05 - val_loss: 5.9460e-04\n",
      "Epoch 986/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 2.5010e-04 - val_loss: 2.5513e-04\n",
      "Epoch 987/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.6800e-04 - val_loss: 7.0333e-05\n",
      "Epoch 988/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1232e-04 - val_loss: 1.4781e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.5530e-04 - val_loss: 2.1446e-04\n",
      "Epoch 990/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.4466e-04 - val_loss: 1.9304e-04\n",
      "Epoch 991/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.5676e-04 - val_loss: 5.2308e-04\n",
      "Epoch 992/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 1.9335e-04 - val_loss: 2.0000e-04\n",
      "Epoch 993/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.3867e-04 - val_loss: 5.0275e-05\n",
      "Epoch 994/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.9888e-05 - val_loss: 6.2934e-05\n",
      "Epoch 995/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.3699e-05 - val_loss: 5.9484e-05\n",
      "Epoch 996/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.8228e-05 - val_loss: 1.0109e-04\n",
      "Epoch 997/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.1090e-04 - val_loss: 1.1827e-04\n",
      "Epoch 998/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0039e-04 - val_loss: 5.3732e-05\n",
      "Epoch 999/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0228e-04 - val_loss: 1.0367e-04\n",
      "Epoch 1000/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0975e-04 - val_loss: 5.7220e-05\n",
      "Epoch 1001/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.1266e-04 - val_loss: 4.8296e-05\n",
      "Epoch 1002/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 9.5147e-05 - val_loss: 6.0268e-05\n",
      "Epoch 1003/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.9159e-05 - val_loss: 1.0702e-04\n",
      "Epoch 1004/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0353e-04 - val_loss: 6.1256e-05\n",
      "Epoch 1005/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.9257e-05 - val_loss: 1.6286e-04\n",
      "Epoch 1006/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1734e-04 - val_loss: 6.1099e-05\n",
      "Epoch 1007/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1031e-04 - val_loss: 9.2058e-05\n",
      "Epoch 1008/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1157e-04 - val_loss: 6.9435e-05\n",
      "Epoch 1009/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1355e-04 - val_loss: 9.3841e-05\n",
      "Epoch 1010/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0781e-04 - val_loss: 5.4081e-05\n",
      "Epoch 1011/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1049e-04 - val_loss: 7.3187e-05\n",
      "Epoch 1012/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.5278e-05 - val_loss: 8.1913e-05\n",
      "Epoch 1013/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.1219e-04 - val_loss: 4.9531e-05\n",
      "Epoch 1014/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2742e-04 - val_loss: 7.5271e-05\n",
      "Epoch 1015/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.0732e-04 - val_loss: 8.9409e-05\n",
      "Epoch 1016/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2688e-04 - val_loss: 7.6769e-05\n",
      "Epoch 1017/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.1163e-04 - val_loss: 1.4488e-04\n",
      "Epoch 1018/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.4102e-04 - val_loss: 1.4499e-04\n",
      "Epoch 1019/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.3713e-04 - val_loss: 8.2704e-05\n",
      "Epoch 1020/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.1302e-04 - val_loss: 9.3123e-05\n",
      "Epoch 1021/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.3256e-04 - val_loss: 7.6797e-05\n",
      "Epoch 1022/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0686e-04 - val_loss: 5.9473e-05\n",
      "Epoch 1023/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0087e-04 - val_loss: 1.1072e-04\n",
      "Epoch 1024/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2722e-04 - val_loss: 2.0778e-04\n",
      "Epoch 1025/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2558e-04 - val_loss: 5.4720e-05\n",
      "Epoch 1026/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 9.5039e-05 - val_loss: 8.1488e-05\n",
      "Epoch 1027/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.8233e-05 - val_loss: 4.7564e-05\n",
      "Epoch 1028/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.6856e-05 - val_loss: 5.7375e-05\n",
      "Epoch 1029/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.1678e-05 - val_loss: 9.1802e-05\n",
      "Epoch 1030/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0344e-04 - val_loss: 4.9531e-05\n",
      "Epoch 1031/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.2537e-05 - val_loss: 6.6427e-05\n",
      "Epoch 1032/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.2234e-05 - val_loss: 7.4788e-05\n",
      "Epoch 1033/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0502e-04 - val_loss: 5.0241e-05\n",
      "Epoch 1034/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.3105e-05 - val_loss: 8.0732e-05\n",
      "Epoch 1035/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.2030e-04 - val_loss: 9.7840e-05\n",
      "Epoch 1036/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1357e-04 - val_loss: 5.3990e-05\n",
      "Epoch 1037/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 1.1018e-04 - val_loss: 1.3487e-04\n",
      "Epoch 1038/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.1405e-04 - val_loss: 5.5388e-05\n",
      "Epoch 1039/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.0233e-04 - val_loss: 5.3953e-05\n",
      "Epoch 1040/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0478e-04 - val_loss: 5.2691e-05\n",
      "Epoch 1041/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.2300e-05 - val_loss: 5.4803e-05\n",
      "Epoch 1042/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.3220e-05 - val_loss: 9.1499e-05\n",
      "Epoch 1043/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.6139e-05 - val_loss: 4.8615e-05\n",
      "Epoch 1044/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.8222e-05 - val_loss: 5.2372e-05\n",
      "Epoch 1045/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.1469e-05 - val_loss: 7.2266e-05\n",
      "Epoch 1046/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.1315e-04 - val_loss: 1.4137e-04\n",
      "Epoch 1047/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.5252e-04 - val_loss: 2.7930e-04\n",
      "Epoch 1048/2000\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 1.4342e-04 - val_loss: 8.8860e-05\n",
      "Epoch 1049/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1300e-04 - val_loss: 6.3669e-05\n",
      "Epoch 1050/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2384e-04 - val_loss: 1.0257e-04\n",
      "Epoch 1051/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.4890e-04 - val_loss: 1.7177e-04\n",
      "Epoch 1052/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.4416e-04 - val_loss: 1.5519e-04\n",
      "Epoch 1053/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1976e-04 - val_loss: 5.5900e-05\n",
      "Epoch 1054/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0069e-04 - val_loss: 6.0230e-05\n",
      "Epoch 1055/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.9332e-05 - val_loss: 5.3201e-05\n",
      "Epoch 1056/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0070e-04 - val_loss: 4.7606e-05\n",
      "Epoch 1057/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.2362e-05 - val_loss: 5.2930e-05\n",
      "Epoch 1058/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.9588e-05 - val_loss: 1.1051e-04\n",
      "Epoch 1059/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.2227e-04 - val_loss: 1.5423e-04\n",
      "Epoch 1060/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2989e-04 - val_loss: 5.1266e-05\n",
      "Epoch 1061/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0067e-04 - val_loss: 1.3972e-04\n",
      "Epoch 1062/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2258e-04 - val_loss: 9.2405e-05\n",
      "Epoch 1063/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0259e-04 - val_loss: 5.4017e-05\n",
      "Epoch 1064/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.1162e-04 - val_loss: 1.9550e-04\n",
      "Epoch 1065/2000\n",
      "4143/4143 [==============================] - 3s 655us/step - loss: 1.5219e-04 - val_loss: 1.1263e-04\n",
      "Epoch 1066/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1533e-04 - val_loss: 3.3542e-04\n",
      "Epoch 1067/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3981e-04 - val_loss: 3.0335e-04\n",
      "Epoch 1068/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.6563e-04 - val_loss: 7.3048e-04\n",
      "Epoch 1069/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 2.0354e-04 - val_loss: 8.7058e-05\n",
      "Epoch 1070/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1951e-04 - val_loss: 8.4999e-05\n",
      "Epoch 1071/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 9.4888e-05 - val_loss: 8.6679e-05\n",
      "Epoch 1072/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0924e-04 - val_loss: 4.7890e-05\n",
      "Epoch 1073/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.1602e-05 - val_loss: 5.3895e-05\n",
      "Epoch 1074/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.6021e-05 - val_loss: 4.9469e-05\n",
      "Epoch 1075/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.4393e-05 - val_loss: 4.8751e-05\n",
      "Epoch 1076/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.7533e-05 - val_loss: 5.6331e-05\n",
      "Epoch 1077/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.8359e-05 - val_loss: 6.1177e-05\n",
      "Epoch 1078/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.6151e-05 - val_loss: 5.0224e-05\n",
      "Epoch 1079/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.6806e-05 - val_loss: 8.9013e-05\n",
      "Epoch 1080/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.0097e-04 - val_loss: 6.2689e-05\n",
      "Epoch 1081/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0297e-04 - val_loss: 5.7979e-05\n",
      "Epoch 1082/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.0032e-05 - val_loss: 4.7869e-05\n",
      "Epoch 1083/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1541e-04 - val_loss: 8.6729e-05\n",
      "Epoch 1084/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.2944e-04 - val_loss: 4.8880e-05\n",
      "Epoch 1085/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.0121e-04 - val_loss: 1.9817e-04\n",
      "Epoch 1086/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.3171e-04 - val_loss: 5.5978e-05\n",
      "Epoch 1087/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 9.9661e-05 - val_loss: 5.0004e-05\n",
      "Epoch 1088/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.5207e-05 - val_loss: 1.9605e-04\n",
      "Epoch 1089/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.5855e-04 - val_loss: 1.7996e-04\n",
      "Epoch 1090/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2036e-04 - val_loss: 5.3873e-05\n",
      "Epoch 1091/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.5736e-05 - val_loss: 4.7535e-05\n",
      "Epoch 1092/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.2244e-05 - val_loss: 8.8024e-05\n",
      "Epoch 1093/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.0740e-04 - val_loss: 7.9648e-05\n",
      "Epoch 1094/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.7200e-05 - val_loss: 4.8013e-05\n",
      "Epoch 1095/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.3541e-05 - val_loss: 6.5798e-05\n",
      "Epoch 1096/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.5835e-05 - val_loss: 4.8240e-05\n",
      "Epoch 1097/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.4624e-05 - val_loss: 1.1943e-04\n",
      "Epoch 1098/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.0863e-04 - val_loss: 5.2965e-05\n",
      "Epoch 1099/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.9352e-05 - val_loss: 7.7592e-05\n",
      "Epoch 1100/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.0477e-04 - val_loss: 5.6999e-05\n",
      "Epoch 1101/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 9.2047e-05 - val_loss: 5.0044e-05\n",
      "Epoch 1102/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0468e-04 - val_loss: 1.0707e-04\n",
      "Epoch 1103/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.3086e-05 - val_loss: 5.4131e-05\n",
      "Epoch 1104/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 9.2810e-05 - val_loss: 5.8328e-05\n",
      "Epoch 1105/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0086e-04 - val_loss: 6.2136e-05\n",
      "Epoch 1106/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.2111e-04 - val_loss: 5.7422e-05\n",
      "Epoch 1107/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.1205e-04 - val_loss: 6.9058e-05\n",
      "Epoch 1108/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2426e-04 - val_loss: 2.1952e-04\n",
      "Epoch 1109/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1708e-04 - val_loss: 7.6972e-05\n",
      "Epoch 1110/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.0097e-04 - val_loss: 7.4118e-05\n",
      "Epoch 1111/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.4165e-05 - val_loss: 8.1490e-05\n",
      "Epoch 1112/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.0628e-04 - val_loss: 2.4316e-04\n",
      "Epoch 1113/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.8615e-04 - val_loss: 1.0113e-04\n",
      "Epoch 1114/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1859e-04 - val_loss: 6.8549e-05\n",
      "Epoch 1115/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0394e-04 - val_loss: 4.8706e-05\n",
      "Epoch 1116/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.6194e-05 - val_loss: 4.8147e-05\n",
      "Epoch 1117/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.6199e-05 - val_loss: 5.8047e-05\n",
      "Epoch 1118/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.3840e-05 - val_loss: 7.9659e-05\n",
      "Epoch 1119/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0656e-04 - val_loss: 7.4922e-05\n",
      "Epoch 1120/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.7816e-05 - val_loss: 6.7442e-05\n",
      "Epoch 1121/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.8861e-05 - val_loss: 4.8499e-05\n",
      "Epoch 1122/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.3466e-05 - val_loss: 7.8764e-05\n",
      "Epoch 1123/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.1934e-04 - val_loss: 5.1837e-05\n",
      "Epoch 1124/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2746e-04 - val_loss: 2.3535e-04\n",
      "Epoch 1125/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.3805e-04 - val_loss: 1.9360e-04\n",
      "Epoch 1126/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3642e-04 - val_loss: 3.8237e-04\n",
      "Epoch 1127/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.7567e-04 - val_loss: 1.2420e-04\n",
      "Epoch 1128/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1143e-04 - val_loss: 2.2781e-04\n",
      "Epoch 1129/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.6435e-04 - val_loss: 1.9133e-04\n",
      "Epoch 1130/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.4173e-04 - val_loss: 7.1820e-05\n",
      "Epoch 1131/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.0251e-04 - val_loss: 6.0582e-05\n",
      "Epoch 1132/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.6441e-05 - val_loss: 6.5101e-05\n",
      "Epoch 1133/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 9.2114e-05 - val_loss: 5.3094e-05\n",
      "Epoch 1134/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.2730e-05 - val_loss: 5.7426e-05\n",
      "Epoch 1135/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.2655e-05 - val_loss: 5.8289e-05\n",
      "Epoch 1136/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.7469e-05 - val_loss: 5.5098e-05\n",
      "Epoch 1137/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.7336e-05 - val_loss: 7.9338e-05\n",
      "Epoch 1138/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0269e-04 - val_loss: 1.0000e-04\n",
      "Epoch 1139/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.0019e-04 - val_loss: 6.1849e-05\n",
      "Epoch 1140/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.0388e-05 - val_loss: 5.9725e-05\n",
      "Epoch 1141/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.3425e-05 - val_loss: 8.1288e-05\n",
      "Epoch 1142/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.0834e-05 - val_loss: 4.9886e-05\n",
      "Epoch 1143/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 9.2973e-05 - val_loss: 6.2006e-05\n",
      "Epoch 1144/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0170e-04 - val_loss: 5.2261e-05\n",
      "Epoch 1145/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.5217e-05 - val_loss: 8.3075e-05\n",
      "Epoch 1146/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.5505e-05 - val_loss: 8.1596e-05\n",
      "Epoch 1147/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.5262e-05 - val_loss: 1.2810e-04\n",
      "Epoch 1148/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.2933e-04 - val_loss: 4.9145e-05\n",
      "Epoch 1149/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0883e-04 - val_loss: 5.0920e-05\n",
      "Epoch 1150/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.1060e-04 - val_loss: 4.9329e-05\n",
      "Epoch 1151/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.0437e-04 - val_loss: 4.9941e-05\n",
      "Epoch 1152/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.1250e-05 - val_loss: 4.8865e-05\n",
      "Epoch 1153/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 8.8614e-05 - val_loss: 5.9665e-05\n",
      "Epoch 1154/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.3184e-05 - val_loss: 7.6164e-05\n",
      "Epoch 1155/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0209e-04 - val_loss: 1.1051e-04\n",
      "Epoch 1156/2000\n",
      "4143/4143 [==============================] - 3s 647us/step - loss: 9.8710e-05 - val_loss: 6.4967e-05\n",
      "Epoch 1157/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 9.3394e-05 - val_loss: 9.4148e-05\n",
      "Epoch 1158/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.1204e-04 - val_loss: 4.9508e-05\n",
      "Epoch 1159/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.5999e-05 - val_loss: 1.2280e-04\n",
      "Epoch 1160/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.6382e-05 - val_loss: 4.8291e-05\n",
      "Epoch 1161/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.7624e-05 - val_loss: 1.2147e-04\n",
      "Epoch 1162/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.8435e-05 - val_loss: 5.2381e-05\n",
      "Epoch 1163/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.2190e-05 - val_loss: 6.4168e-05\n",
      "Epoch 1164/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.6220e-05 - val_loss: 4.8999e-05\n",
      "Epoch 1165/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.7071e-05 - val_loss: 8.8209e-05\n",
      "Epoch 1166/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.6425e-05 - val_loss: 5.9902e-05\n",
      "Epoch 1167/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.6826e-05 - val_loss: 4.9144e-05\n",
      "Epoch 1168/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.6781e-05 - val_loss: 4.9047e-05\n",
      "Epoch 1169/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.6132e-05 - val_loss: 6.3381e-05\n",
      "Epoch 1170/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.1696e-05 - val_loss: 8.5967e-05\n",
      "Epoch 1171/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.5539e-05 - val_loss: 5.5521e-05\n",
      "Epoch 1172/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.0106e-04 - val_loss: 4.9011e-05\n",
      "Epoch 1173/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1534e-04 - val_loss: 9.9751e-05\n",
      "Epoch 1174/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0068e-04 - val_loss: 5.7494e-05\n",
      "Epoch 1175/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.3944e-05 - val_loss: 9.9937e-05\n",
      "Epoch 1176/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0766e-04 - val_loss: 2.1007e-04\n",
      "Epoch 1177/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2034e-04 - val_loss: 8.6138e-05\n",
      "Epoch 1178/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.4319e-05 - val_loss: 7.8834e-05\n",
      "Epoch 1179/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.3750e-05 - val_loss: 1.0808e-04\n",
      "Epoch 1180/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.7482e-05 - val_loss: 4.9229e-05\n",
      "Epoch 1181/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.1383e-05 - val_loss: 5.5684e-05\n",
      "Epoch 1182/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 9.4388e-05 - val_loss: 6.4398e-05\n",
      "Epoch 1183/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0101e-04 - val_loss: 4.8231e-05\n",
      "Epoch 1184/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 1.0556e-04 - val_loss: 4.7578e-05\n",
      "Epoch 1185/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.4820e-05 - val_loss: 4.8174e-05\n",
      "Epoch 1186/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.3884e-05 - val_loss: 5.3595e-05\n",
      "Epoch 1187/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.7893e-05 - val_loss: 8.4681e-05\n",
      "Epoch 1188/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 9.8787e-05 - val_loss: 1.7563e-04\n",
      "Epoch 1189/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.4147e-04 - val_loss: 2.7132e-04\n",
      "Epoch 1190/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.4705e-04 - val_loss: 2.5943e-04\n",
      "Epoch 1191/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.5481e-04 - val_loss: 7.6971e-05\n",
      "Epoch 1192/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1432e-04 - val_loss: 5.4836e-05\n",
      "Epoch 1193/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.5132e-05 - val_loss: 4.9991e-05\n",
      "Epoch 1194/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.8285e-05 - val_loss: 6.1977e-05\n",
      "Epoch 1195/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.4282e-05 - val_loss: 5.5230e-05\n",
      "Epoch 1196/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.5042e-05 - val_loss: 1.2334e-04\n",
      "Epoch 1197/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 1.0365e-04 - val_loss: 1.5353e-04\n",
      "Epoch 1198/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.4355e-04 - val_loss: 5.9136e-05\n",
      "Epoch 1199/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.2298e-04 - val_loss: 6.9479e-05\n",
      "Epoch 1200/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.1369e-04 - val_loss: 6.1063e-05\n",
      "Epoch 1201/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 9.2350e-05 - val_loss: 1.3774e-04\n",
      "Epoch 1202/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0471e-04 - val_loss: 5.8546e-05\n",
      "Epoch 1203/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.5570e-05 - val_loss: 4.9743e-05\n",
      "Epoch 1204/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.7894e-05 - val_loss: 5.1329e-05\n",
      "Epoch 1205/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.8715e-05 - val_loss: 5.0179e-05\n",
      "Epoch 1206/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.7115e-05 - val_loss: 6.7732e-05\n",
      "Epoch 1207/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 9.0122e-05 - val_loss: 4.8825e-05\n",
      "Epoch 1208/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.2620e-05 - val_loss: 6.4135e-05\n",
      "Epoch 1209/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.3023e-05 - val_loss: 7.5369e-05\n",
      "Epoch 1210/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.3552e-05 - val_loss: 9.8027e-05\n",
      "Epoch 1211/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.0929e-04 - val_loss: 5.3756e-05\n",
      "Epoch 1212/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.4317e-05 - val_loss: 4.9831e-05\n",
      "Epoch 1213/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.0920e-05 - val_loss: 5.0038e-05\n",
      "Epoch 1214/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.0025e-05 - val_loss: 6.7713e-05\n",
      "Epoch 1215/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.7196e-05 - val_loss: 6.5371e-05\n",
      "Epoch 1216/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.1562e-05 - val_loss: 5.6877e-05\n",
      "Epoch 1217/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.1775e-05 - val_loss: 8.2480e-05\n",
      "Epoch 1218/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.1738e-04 - val_loss: 5.4989e-05\n",
      "Epoch 1219/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.7380e-05 - val_loss: 5.5484e-05\n",
      "Epoch 1220/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.3739e-05 - val_loss: 8.4385e-05\n",
      "Epoch 1221/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.9711e-05 - val_loss: 4.7747e-05\n",
      "Epoch 1222/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 9.0846e-05 - val_loss: 7.0638e-05\n",
      "Epoch 1223/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.4594e-05 - val_loss: 5.8593e-05\n",
      "Epoch 1224/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.5007e-05 - val_loss: 6.6284e-05\n",
      "Epoch 1225/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0122e-04 - val_loss: 5.1705e-05\n",
      "Epoch 1226/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.6468e-05 - val_loss: 1.2867e-04\n",
      "Epoch 1227/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 9.8907e-05 - val_loss: 5.9517e-05\n",
      "Epoch 1228/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 9.1889e-05 - val_loss: 7.8435e-05\n",
      "Epoch 1229/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 9.8267e-05 - val_loss: 9.6762e-05\n",
      "Epoch 1230/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.9892e-05 - val_loss: 6.5665e-05\n",
      "Epoch 1231/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.3345e-05 - val_loss: 5.3591e-05\n",
      "Epoch 1232/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.1392e-05 - val_loss: 9.8494e-05\n",
      "Epoch 1233/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.9171e-05 - val_loss: 6.7346e-05\n",
      "Epoch 1234/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0561e-04 - val_loss: 5.0628e-05\n",
      "Epoch 1235/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.6581e-05 - val_loss: 5.3789e-05\n",
      "Epoch 1236/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.7088e-05 - val_loss: 5.7299e-05\n",
      "Epoch 1237/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.5240e-05 - val_loss: 1.3246e-04\n",
      "Epoch 1238/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 1.2374e-04 - val_loss: 2.3998e-04\n",
      "Epoch 1239/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1154e-04 - val_loss: 7.3324e-05\n",
      "Epoch 1240/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.0530e-04 - val_loss: 9.3112e-05\n",
      "Epoch 1241/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.8626e-05 - val_loss: 4.3255e-04\n",
      "Epoch 1242/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.6760e-04 - val_loss: 4.7963e-05\n",
      "Epoch 1243/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.7718e-05 - val_loss: 1.9017e-04\n",
      "Epoch 1244/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.3455e-04 - val_loss: 5.0532e-05\n",
      "Epoch 1245/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0563e-04 - val_loss: 1.1551e-04\n",
      "Epoch 1246/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.3101e-04 - val_loss: 7.1804e-05\n",
      "Epoch 1247/2000\n",
      "4143/4143 [==============================] - 3s 647us/step - loss: 1.3451e-04 - val_loss: 4.0568e-04\n",
      "Epoch 1248/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.5886e-04 - val_loss: 1.6015e-04\n",
      "Epoch 1249/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.0381e-04 - val_loss: 5.6047e-05\n",
      "Epoch 1250/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.2611e-05 - val_loss: 6.9732e-05\n",
      "Epoch 1251/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.0223e-05 - val_loss: 8.7262e-05\n",
      "Epoch 1252/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 1.1923e-04 - val_loss: 1.5064e-04\n",
      "Epoch 1253/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.9667e-05 - val_loss: 5.0956e-05\n",
      "Epoch 1254/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.1881e-05 - val_loss: 6.0805e-05\n",
      "Epoch 1255/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.5160e-05 - val_loss: 4.8330e-05\n",
      "Epoch 1256/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.1632e-05 - val_loss: 4.8423e-05\n",
      "Epoch 1257/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 8.3730e-05 - val_loss: 6.2602e-05\n",
      "Epoch 1258/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 9.3351e-05 - val_loss: 5.0464e-05\n",
      "Epoch 1259/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.7518e-05 - val_loss: 8.2618e-05\n",
      "Epoch 1260/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 8.1479e-05 - val_loss: 7.6641e-05\n",
      "Epoch 1261/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 9.5977e-05 - val_loss: 7.8989e-05\n",
      "Epoch 1262/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.1716e-04 - val_loss: 7.5649e-05\n",
      "Epoch 1263/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0513e-04 - val_loss: 7.4303e-05\n",
      "Epoch 1264/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 1.0678e-04 - val_loss: 5.6432e-05\n",
      "Epoch 1265/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.9025e-05 - val_loss: 1.0354e-04\n",
      "Epoch 1266/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0606e-04 - val_loss: 4.9990e-05\n",
      "Epoch 1267/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 8.6281e-05 - val_loss: 6.9148e-05\n",
      "Epoch 1268/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.0129e-05 - val_loss: 5.8142e-05\n",
      "Epoch 1269/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.7694e-05 - val_loss: 4.0549e-04\n",
      "Epoch 1270/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.4049e-04 - val_loss: 3.5651e-04\n",
      "Epoch 1271/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 2.1012e-04 - val_loss: 1.9270e-04\n",
      "Epoch 1272/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3050e-04 - val_loss: 6.4325e-05\n",
      "Epoch 1273/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 8.6734e-05 - val_loss: 6.4272e-05\n",
      "Epoch 1274/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.4789e-05 - val_loss: 4.9166e-05\n",
      "Epoch 1275/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.6364e-05 - val_loss: 5.5319e-05\n",
      "Epoch 1276/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.5986e-05 - val_loss: 7.7362e-05\n",
      "Epoch 1277/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.0334e-05 - val_loss: 4.9204e-05\n",
      "Epoch 1278/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.7607e-05 - val_loss: 4.9443e-05\n",
      "Epoch 1279/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.2152e-05 - val_loss: 7.1824e-05\n",
      "Epoch 1280/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 8.4273e-05 - val_loss: 8.8617e-05\n",
      "Epoch 1281/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.7062e-05 - val_loss: 5.7606e-05\n",
      "Epoch 1282/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.9688e-05 - val_loss: 1.6425e-04\n",
      "Epoch 1283/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.5006e-04 - val_loss: 9.0689e-05\n",
      "Epoch 1284/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.1370e-04 - val_loss: 4.9393e-05\n",
      "Epoch 1285/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.2673e-05 - val_loss: 8.2794e-05\n",
      "Epoch 1286/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.7926e-05 - val_loss: 1.9974e-04\n",
      "Epoch 1287/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3231e-04 - val_loss: 7.7596e-05\n",
      "Epoch 1288/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.8157e-05 - val_loss: 5.6883e-05\n",
      "Epoch 1289/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.5348e-05 - val_loss: 4.9369e-05\n",
      "Epoch 1290/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 8.8481e-05 - val_loss: 1.0355e-04\n",
      "Epoch 1291/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0142e-04 - val_loss: 4.9863e-05\n",
      "Epoch 1292/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.1166e-05 - val_loss: 5.6923e-05\n",
      "Epoch 1293/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.4901e-05 - val_loss: 5.0912e-05\n",
      "Epoch 1294/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.7283e-05 - val_loss: 2.3294e-04\n",
      "Epoch 1295/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.1548e-04 - val_loss: 5.2322e-05\n",
      "Epoch 1296/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0352e-04 - val_loss: 1.6037e-04\n",
      "Epoch 1297/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1998e-04 - val_loss: 5.2091e-05\n",
      "Epoch 1298/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.3622e-05 - val_loss: 6.6383e-05\n",
      "Epoch 1299/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0258e-04 - val_loss: 9.5930e-05\n",
      "Epoch 1300/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.3016e-05 - val_loss: 1.0319e-04\n",
      "Epoch 1301/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.1936e-05 - val_loss: 5.4456e-05\n",
      "Epoch 1302/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.9841e-05 - val_loss: 5.1233e-05\n",
      "Epoch 1303/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.9315e-05 - val_loss: 9.0079e-05\n",
      "Epoch 1304/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0030e-04 - val_loss: 1.0850e-04\n",
      "Epoch 1305/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.3376e-04 - val_loss: 2.8169e-04\n",
      "Epoch 1306/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.3477e-04 - val_loss: 6.3381e-05\n",
      "Epoch 1307/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 9.6080e-05 - val_loss: 8.6480e-05\n",
      "Epoch 1308/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0690e-04 - val_loss: 1.2245e-04\n",
      "Epoch 1309/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 1.0759e-04 - val_loss: 1.1169e-04\n",
      "Epoch 1310/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.1200e-04 - val_loss: 1.2949e-04\n",
      "Epoch 1311/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 8.6564e-05 - val_loss: 1.1414e-04\n",
      "Epoch 1312/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0128e-04 - val_loss: 5.1059e-05\n",
      "Epoch 1313/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.7660e-05 - val_loss: 1.0826e-04\n",
      "Epoch 1314/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.2505e-05 - val_loss: 1.5718e-04\n",
      "Epoch 1315/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2808e-04 - val_loss: 5.6304e-05\n",
      "Epoch 1316/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0122e-04 - val_loss: 8.1117e-05\n",
      "Epoch 1317/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.2201e-05 - val_loss: 4.9800e-05\n",
      "Epoch 1318/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0912e-04 - val_loss: 1.9134e-04\n",
      "Epoch 1319/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2471e-04 - val_loss: 6.5132e-05\n",
      "Epoch 1320/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.6725e-05 - val_loss: 4.8403e-05\n",
      "Epoch 1321/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.5134e-05 - val_loss: 2.4031e-04\n",
      "Epoch 1322/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.1319e-04 - val_loss: 1.4630e-04\n",
      "Epoch 1323/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1514e-04 - val_loss: 9.9554e-05\n",
      "Epoch 1324/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.1249e-05 - val_loss: 5.1788e-05\n",
      "Epoch 1325/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 1.0015e-04 - val_loss: 1.0515e-04\n",
      "Epoch 1326/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 9.5911e-05 - val_loss: 4.8805e-05\n",
      "Epoch 1327/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.6006e-05 - val_loss: 2.4286e-04\n",
      "Epoch 1328/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.2140e-04 - val_loss: 1.8470e-04\n",
      "Epoch 1329/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.1490e-04 - val_loss: 8.3835e-05\n",
      "Epoch 1330/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0185e-04 - val_loss: 6.8059e-05\n",
      "Epoch 1331/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.1049e-05 - val_loss: 5.1237e-05\n",
      "Epoch 1332/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.3474e-05 - val_loss: 6.3573e-05\n",
      "Epoch 1333/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.0203e-05 - val_loss: 5.8130e-05\n",
      "Epoch 1334/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.1760e-05 - val_loss: 7.3079e-05\n",
      "Epoch 1335/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.3194e-05 - val_loss: 1.0100e-04\n",
      "Epoch 1336/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.8530e-05 - val_loss: 4.9322e-05\n",
      "Epoch 1337/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 7.6684e-05 - val_loss: 1.8608e-04\n",
      "Epoch 1338/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0407e-04 - val_loss: 6.7560e-05\n",
      "Epoch 1339/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.1373e-05 - val_loss: 1.6672e-04\n",
      "Epoch 1340/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.5700e-05 - val_loss: 4.8649e-05\n",
      "Epoch 1341/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.1244e-05 - val_loss: 7.8686e-05\n",
      "Epoch 1342/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.3603e-05 - val_loss: 8.9535e-05\n",
      "Epoch 1343/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.4574e-05 - val_loss: 4.8584e-05\n",
      "Epoch 1344/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.1499e-05 - val_loss: 6.1972e-05\n",
      "Epoch 1345/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.7117e-05 - val_loss: 4.9592e-05\n",
      "Epoch 1346/2000\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 8.7712e-05 - val_loss: 2.1033e-04\n",
      "Epoch 1347/2000\n",
      "4143/4143 [==============================] - 3s 723us/step - loss: 1.0793e-04 - val_loss: 2.6453e-04\n",
      "Epoch 1348/2000\n",
      "4143/4143 [==============================] - 3s 659us/step - loss: 1.6099e-04 - val_loss: 1.9746e-04\n",
      "Epoch 1349/2000\n",
      "4143/4143 [==============================] - 3s 672us/step - loss: 1.2572e-04 - val_loss: 6.6031e-05\n",
      "Epoch 1350/2000\n",
      "4143/4143 [==============================] - 3s 676us/step - loss: 1.1238e-04 - val_loss: 5.0106e-05\n",
      "Epoch 1351/2000\n",
      "4143/4143 [==============================] - 3s 682us/step - loss: 9.8502e-05 - val_loss: 1.1033e-04\n",
      "Epoch 1352/2000\n",
      "4143/4143 [==============================] - 3s 670us/step - loss: 9.3952e-05 - val_loss: 5.4522e-05\n",
      "Epoch 1353/2000\n",
      "4143/4143 [==============================] - 3s 673us/step - loss: 8.2748e-05 - val_loss: 5.0338e-05\n",
      "Epoch 1354/2000\n",
      "4143/4143 [==============================] - 3s 671us/step - loss: 8.1311e-05 - val_loss: 6.2292e-05\n",
      "Epoch 1355/2000\n",
      "4143/4143 [==============================] - 3s 661us/step - loss: 7.8254e-05 - val_loss: 5.9185e-05\n",
      "Epoch 1356/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 8.1812e-05 - val_loss: 4.9848e-05\n",
      "Epoch 1357/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.7213e-05 - val_loss: 1.0781e-04\n",
      "Epoch 1358/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.5542e-05 - val_loss: 9.7683e-05\n",
      "Epoch 1359/2000\n",
      "4143/4143 [==============================] - 3s 656us/step - loss: 8.5346e-05 - val_loss: 1.2774e-04\n",
      "Epoch 1360/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.1721e-04 - val_loss: 6.1478e-05\n",
      "Epoch 1361/2000\n",
      "4143/4143 [==============================] - 3s 646us/step - loss: 8.5775e-05 - val_loss: 2.0725e-04\n",
      "Epoch 1362/2000\n",
      "4143/4143 [==============================] - 3s 656us/step - loss: 2.0212e-04 - val_loss: 9.8363e-05\n",
      "Epoch 1363/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.2035e-04 - val_loss: 8.9469e-05\n",
      "Epoch 1364/2000\n",
      "4143/4143 [==============================] - 3s 661us/step - loss: 9.1268e-05 - val_loss: 4.9831e-05\n",
      "Epoch 1365/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.6901e-05 - val_loss: 1.6563e-04\n",
      "Epoch 1366/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.0501e-04 - val_loss: 5.2899e-05\n",
      "Epoch 1367/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 9.9706e-05 - val_loss: 9.8245e-05\n",
      "Epoch 1368/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.1282e-04 - val_loss: 1.8009e-04\n",
      "Epoch 1369/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1471e-04 - val_loss: 8.7936e-05\n",
      "Epoch 1370/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.1268e-04 - val_loss: 1.5453e-04\n",
      "Epoch 1371/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0344e-04 - val_loss: 1.3185e-04\n",
      "Epoch 1372/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.2933e-05 - val_loss: 9.3567e-05\n",
      "Epoch 1373/2000\n",
      "4143/4143 [==============================] - 3s 663us/step - loss: 8.2499e-05 - val_loss: 9.0001e-05\n",
      "Epoch 1374/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.8141e-05 - val_loss: 5.3750e-05\n",
      "Epoch 1375/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.1416e-05 - val_loss: 1.1914e-04\n",
      "Epoch 1376/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 8.0156e-05 - val_loss: 9.0158e-05\n",
      "Epoch 1377/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.0422e-05 - val_loss: 5.1910e-05\n",
      "Epoch 1378/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.2661e-05 - val_loss: 2.0640e-04\n",
      "Epoch 1379/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.2626e-04 - val_loss: 5.8191e-05\n",
      "Epoch 1380/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.3559e-05 - val_loss: 5.1788e-05\n",
      "Epoch 1381/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.4372e-05 - val_loss: 5.3175e-05\n",
      "Epoch 1382/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.5655e-05 - val_loss: 6.0934e-05\n",
      "Epoch 1383/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0186e-04 - val_loss: 1.7609e-04\n",
      "Epoch 1384/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.1882e-05 - val_loss: 7.4837e-05\n",
      "Epoch 1385/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.9397e-05 - val_loss: 6.9402e-05\n",
      "Epoch 1386/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 8.6293e-05 - val_loss: 5.7566e-05\n",
      "Epoch 1387/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.4794e-05 - val_loss: 5.2303e-05\n",
      "Epoch 1388/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.1662e-05 - val_loss: 7.5925e-05\n",
      "Epoch 1389/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.4267e-05 - val_loss: 4.8450e-05\n",
      "Epoch 1390/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.1050e-05 - val_loss: 7.0976e-05\n",
      "Epoch 1391/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.9078e-05 - val_loss: 5.8351e-05\n",
      "Epoch 1392/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 8.0596e-05 - val_loss: 8.3457e-05\n",
      "Epoch 1393/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 8.2364e-05 - val_loss: 5.1137e-05\n",
      "Epoch 1394/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.8808e-05 - val_loss: 4.8436e-05\n",
      "Epoch 1395/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 8.4749e-05 - val_loss: 1.7088e-04\n",
      "Epoch 1396/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.8149e-05 - val_loss: 5.1143e-05\n",
      "Epoch 1397/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 8.4542e-05 - val_loss: 1.2364e-04\n",
      "Epoch 1398/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.0005e-04 - val_loss: 5.5385e-05\n",
      "Epoch 1399/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.3110e-05 - val_loss: 1.2780e-04\n",
      "Epoch 1400/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.2637e-05 - val_loss: 5.5188e-05\n",
      "Epoch 1401/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.4337e-05 - val_loss: 6.0440e-05\n",
      "Epoch 1402/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.7447e-05 - val_loss: 6.5413e-05\n",
      "Epoch 1403/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.7375e-05 - val_loss: 1.9202e-04\n",
      "Epoch 1404/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1148e-04 - val_loss: 6.7681e-05\n",
      "Epoch 1405/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.7171e-05 - val_loss: 1.3512e-04\n",
      "Epoch 1406/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 9.1193e-05 - val_loss: 1.3206e-04\n",
      "Epoch 1407/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1517e-04 - val_loss: 1.3745e-04\n",
      "Epoch 1408/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.5038e-05 - val_loss: 6.7514e-05\n",
      "Epoch 1409/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.2024e-05 - val_loss: 8.3731e-05\n",
      "Epoch 1410/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.4704e-05 - val_loss: 5.4224e-05\n",
      "Epoch 1411/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.6658e-05 - val_loss: 1.0681e-04\n",
      "Epoch 1412/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.9577e-05 - val_loss: 1.7927e-04\n",
      "Epoch 1413/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 1.0847e-04 - val_loss: 5.0429e-05\n",
      "Epoch 1414/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.9250e-05 - val_loss: 7.5576e-05\n",
      "Epoch 1415/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0126e-04 - val_loss: 5.9226e-05\n",
      "Epoch 1416/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.7398e-05 - val_loss: 4.9739e-05\n",
      "Epoch 1417/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 8.7908e-05 - val_loss: 5.4393e-05\n",
      "Epoch 1418/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.5891e-05 - val_loss: 1.3057e-04\n",
      "Epoch 1419/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.9261e-05 - val_loss: 9.0666e-05\n",
      "Epoch 1420/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.8312e-05 - val_loss: 5.4727e-05\n",
      "Epoch 1421/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.9093e-05 - val_loss: 2.7352e-04\n",
      "Epoch 1422/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.0042e-04 - val_loss: 5.7942e-05\n",
      "Epoch 1423/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.6465e-05 - val_loss: 1.2232e-04\n",
      "Epoch 1424/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.8748e-05 - val_loss: 5.7931e-05\n",
      "Epoch 1425/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.9825e-05 - val_loss: 5.7454e-05\n",
      "Epoch 1426/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.3304e-05 - val_loss: 8.8766e-05\n",
      "Epoch 1427/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.1300e-05 - val_loss: 5.0042e-05\n",
      "Epoch 1428/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 8.6548e-05 - val_loss: 5.4846e-05\n",
      "Epoch 1429/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 7.2852e-05 - val_loss: 6.3814e-05\n",
      "Epoch 1430/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.6378e-05 - val_loss: 6.7677e-05\n",
      "Epoch 1431/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.0468e-05 - val_loss: 5.4076e-05\n",
      "Epoch 1432/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.2952e-05 - val_loss: 7.2921e-05\n",
      "Epoch 1433/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.9926e-05 - val_loss: 5.9710e-05\n",
      "Epoch 1434/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0466e-04 - val_loss: 7.5113e-05\n",
      "Epoch 1435/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.5198e-05 - val_loss: 6.2409e-05\n",
      "Epoch 1436/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.9458e-05 - val_loss: 4.9378e-05\n",
      "Epoch 1437/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.4651e-05 - val_loss: 1.3656e-04\n",
      "Epoch 1438/2000\n",
      "4143/4143 [==============================] - 3s 647us/step - loss: 8.0012e-05 - val_loss: 5.0798e-05\n",
      "Epoch 1439/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.8162e-05 - val_loss: 6.7844e-05\n",
      "Epoch 1440/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 8.6668e-05 - val_loss: 5.1091e-05\n",
      "Epoch 1441/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.0046e-05 - val_loss: 4.9831e-05\n",
      "Epoch 1442/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.6432e-05 - val_loss: 2.0341e-04\n",
      "Epoch 1443/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.6217e-05 - val_loss: 6.0270e-05\n",
      "Epoch 1444/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 7.6246e-05 - val_loss: 5.1449e-05\n",
      "Epoch 1445/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.0603e-05 - val_loss: 6.0667e-05\n",
      "Epoch 1446/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 7.5397e-05 - val_loss: 6.3193e-05\n",
      "Epoch 1447/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.2905e-05 - val_loss: 5.2221e-05\n",
      "Epoch 1448/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.4746e-05 - val_loss: 6.0264e-05\n",
      "Epoch 1449/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.7685e-05 - val_loss: 8.7099e-05\n",
      "Epoch 1450/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0507e-04 - val_loss: 5.8201e-05\n",
      "Epoch 1451/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.9505e-05 - val_loss: 8.6651e-05\n",
      "Epoch 1452/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.5487e-05 - val_loss: 8.2861e-05\n",
      "Epoch 1453/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.7417e-05 - val_loss: 8.4223e-05\n",
      "Epoch 1454/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.9663e-05 - val_loss: 5.5488e-05\n",
      "Epoch 1455/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.0767e-05 - val_loss: 1.2975e-04\n",
      "Epoch 1456/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.2454e-04 - val_loss: 6.3766e-05\n",
      "Epoch 1457/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1651e-04 - val_loss: 2.2321e-04\n",
      "Epoch 1458/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1781e-04 - val_loss: 6.9577e-05\n",
      "Epoch 1459/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.9788e-05 - val_loss: 6.3366e-05\n",
      "Epoch 1460/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.1606e-05 - val_loss: 5.3440e-05\n",
      "Epoch 1461/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.1270e-05 - val_loss: 1.1671e-04\n",
      "Epoch 1462/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.6600e-05 - val_loss: 7.0348e-05\n",
      "Epoch 1463/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.2047e-04 - val_loss: 2.0798e-04\n",
      "Epoch 1464/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0115e-04 - val_loss: 4.9427e-05\n",
      "Epoch 1465/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.0336e-05 - val_loss: 3.5283e-04\n",
      "Epoch 1466/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.4377e-04 - val_loss: 7.9076e-05\n",
      "Epoch 1467/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.6634e-05 - val_loss: 5.2575e-05\n",
      "Epoch 1468/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.7345e-05 - val_loss: 1.3505e-04\n",
      "Epoch 1469/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.0738e-04 - val_loss: 8.3510e-05\n",
      "Epoch 1470/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.2304e-05 - val_loss: 1.7245e-04\n",
      "Epoch 1471/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0841e-04 - val_loss: 4.9258e-05\n",
      "Epoch 1472/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.6149e-05 - val_loss: 1.2529e-04\n",
      "Epoch 1473/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.1436e-05 - val_loss: 5.1660e-05\n",
      "Epoch 1474/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.1982e-05 - val_loss: 9.8935e-05\n",
      "Epoch 1475/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.1306e-05 - val_loss: 6.2719e-05\n",
      "Epoch 1476/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 7.3996e-05 - val_loss: 5.1156e-05\n",
      "Epoch 1477/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.4347e-05 - val_loss: 8.8751e-05\n",
      "Epoch 1478/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.2236e-04 - val_loss: 1.6400e-04\n",
      "Epoch 1479/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2039e-04 - val_loss: 9.5827e-05\n",
      "Epoch 1480/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 8.8181e-05 - val_loss: 4.9578e-05\n",
      "Epoch 1481/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 7.8227e-05 - val_loss: 1.8126e-04\n",
      "Epoch 1482/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 9.7555e-05 - val_loss: 6.0121e-05\n",
      "Epoch 1483/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.2222e-05 - val_loss: 7.4296e-05\n",
      "Epoch 1484/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.9954e-05 - val_loss: 6.4279e-05\n",
      "Epoch 1485/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.5111e-05 - val_loss: 1.2335e-04\n",
      "Epoch 1486/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0801e-04 - val_loss: 5.4665e-05\n",
      "Epoch 1487/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.8466e-05 - val_loss: 4.9818e-05\n",
      "Epoch 1488/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.8306e-05 - val_loss: 5.4184e-05\n",
      "Epoch 1489/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.0198e-05 - val_loss: 5.0686e-05\n",
      "Epoch 1490/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.9641e-05 - val_loss: 5.3417e-05\n",
      "Epoch 1491/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 7.9929e-05 - val_loss: 1.2816e-04\n",
      "Epoch 1492/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.8799e-05 - val_loss: 5.5011e-05\n",
      "Epoch 1493/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.8859e-05 - val_loss: 7.4519e-05\n",
      "Epoch 1494/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.0455e-04 - val_loss: 8.3547e-05\n",
      "Epoch 1495/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.7343e-05 - val_loss: 9.3356e-05\n",
      "Epoch 1496/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.8035e-05 - val_loss: 6.1632e-05\n",
      "Epoch 1497/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.1188e-05 - val_loss: 5.3207e-05\n",
      "Epoch 1498/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0221e-04 - val_loss: 5.0784e-05\n",
      "Epoch 1499/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.0378e-04 - val_loss: 9.9922e-05\n",
      "Epoch 1500/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0512e-04 - val_loss: 5.0584e-05\n",
      "Epoch 1501/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.7621e-05 - val_loss: 7.1575e-05\n",
      "Epoch 1502/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.3867e-05 - val_loss: 3.4834e-04\n",
      "Epoch 1503/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 1.0548e-04 - val_loss: 1.5341e-04\n",
      "Epoch 1504/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.9342e-05 - val_loss: 7.9198e-05\n",
      "Epoch 1505/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.7196e-05 - val_loss: 9.7249e-05\n",
      "Epoch 1506/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.8277e-05 - val_loss: 6.9966e-05\n",
      "Epoch 1507/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 8.2706e-05 - val_loss: 5.2573e-05\n",
      "Epoch 1508/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.2657e-05 - val_loss: 9.3401e-05\n",
      "Epoch 1509/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.6574e-05 - val_loss: 5.5568e-05\n",
      "Epoch 1510/2000\n",
      "4143/4143 [==============================] - 3s 671us/step - loss: 8.3699e-05 - val_loss: 1.3681e-04\n",
      "Epoch 1511/2000\n",
      "4143/4143 [==============================] - 3s 650us/step - loss: 8.8540e-05 - val_loss: 5.6528e-05\n",
      "Epoch 1512/2000\n",
      "4143/4143 [==============================] - 3s 650us/step - loss: 7.7308e-05 - val_loss: 5.2350e-05\n",
      "Epoch 1513/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 7.2518e-05 - val_loss: 5.5938e-05\n",
      "Epoch 1514/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.4336e-05 - val_loss: 1.3819e-04\n",
      "Epoch 1515/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.3562e-05 - val_loss: 7.2258e-05\n",
      "Epoch 1516/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0413e-04 - val_loss: 1.2406e-04\n",
      "Epoch 1517/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.5262e-05 - val_loss: 6.0397e-05\n",
      "Epoch 1518/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.1666e-05 - val_loss: 5.6056e-05\n",
      "Epoch 1519/2000\n",
      "4143/4143 [==============================] - 3s 646us/step - loss: 8.9042e-05 - val_loss: 1.9991e-04\n",
      "Epoch 1520/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1051e-04 - val_loss: 8.7043e-05\n",
      "Epoch 1521/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0536e-04 - val_loss: 7.1068e-05\n",
      "Epoch 1522/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.8131e-05 - val_loss: 1.0115e-04\n",
      "Epoch 1523/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0112e-04 - val_loss: 2.2890e-04\n",
      "Epoch 1524/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.7925e-05 - val_loss: 6.5762e-05\n",
      "Epoch 1525/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.7942e-05 - val_loss: 7.9653e-05\n",
      "Epoch 1526/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.0535e-05 - val_loss: 8.2966e-05\n",
      "Epoch 1527/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 8.9129e-05 - val_loss: 5.1021e-05\n",
      "Epoch 1528/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.5419e-05 - val_loss: 6.9802e-05\n",
      "Epoch 1529/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.9693e-05 - val_loss: 7.3968e-05\n",
      "Epoch 1530/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.8747e-05 - val_loss: 4.9123e-05\n",
      "Epoch 1531/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 8.5620e-05 - val_loss: 1.7518e-04\n",
      "Epoch 1532/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.0468e-05 - val_loss: 5.3415e-05\n",
      "Epoch 1533/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.1089e-05 - val_loss: 1.3065e-04\n",
      "Epoch 1534/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.8963e-05 - val_loss: 8.4026e-05\n",
      "Epoch 1535/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.0546e-05 - val_loss: 1.1230e-04\n",
      "Epoch 1536/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 1.2796e-04 - val_loss: 8.9172e-05\n",
      "Epoch 1537/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0837e-04 - val_loss: 5.1863e-05\n",
      "Epoch 1538/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.4469e-05 - val_loss: 9.3191e-05\n",
      "Epoch 1539/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0644e-04 - val_loss: 7.9719e-05\n",
      "Epoch 1540/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.7108e-05 - val_loss: 6.2429e-05\n",
      "Epoch 1541/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0564e-04 - val_loss: 1.3136e-04\n",
      "Epoch 1542/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.0628e-05 - val_loss: 8.0088e-05\n",
      "Epoch 1543/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.4130e-05 - val_loss: 8.5104e-05\n",
      "Epoch 1544/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.0941e-04 - val_loss: 1.3829e-04\n",
      "Epoch 1545/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.6315e-05 - val_loss: 1.1222e-04\n",
      "Epoch 1546/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.3008e-04 - val_loss: 1.0976e-04\n",
      "Epoch 1547/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.9967e-05 - val_loss: 5.5934e-05\n",
      "Epoch 1548/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 8.8397e-05 - val_loss: 2.3376e-04\n",
      "Epoch 1549/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 641us/step - loss: 1.0224e-04 - val_loss: 5.0741e-05\n",
      "Epoch 1550/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.6220e-05 - val_loss: 5.5774e-05\n",
      "Epoch 1551/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.4646e-05 - val_loss: 7.7205e-05\n",
      "Epoch 1552/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 8.1691e-05 - val_loss: 6.1929e-05\n",
      "Epoch 1553/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.3269e-05 - val_loss: 1.4706e-04\n",
      "Epoch 1554/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.5736e-05 - val_loss: 5.0109e-05\n",
      "Epoch 1555/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.1334e-05 - val_loss: 6.3803e-05\n",
      "Epoch 1556/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.4590e-05 - val_loss: 1.1609e-04\n",
      "Epoch 1557/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.9728e-05 - val_loss: 4.8269e-05\n",
      "Epoch 1558/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.8418e-05 - val_loss: 2.6877e-04\n",
      "Epoch 1559/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1418e-04 - val_loss: 7.5703e-05\n",
      "Epoch 1560/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 9.6797e-05 - val_loss: 6.8508e-05\n",
      "Epoch 1561/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.5491e-05 - val_loss: 6.2178e-05\n",
      "Epoch 1562/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.0935e-05 - val_loss: 9.5277e-05\n",
      "Epoch 1563/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.0013e-04 - val_loss: 2.0430e-04\n",
      "Epoch 1564/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 1.0820e-04 - val_loss: 5.5429e-05\n",
      "Epoch 1565/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 9.0436e-05 - val_loss: 5.2310e-05\n",
      "Epoch 1566/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.2742e-05 - val_loss: 1.3685e-04\n",
      "Epoch 1567/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.0789e-04 - val_loss: 5.2538e-05\n",
      "Epoch 1568/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.8582e-05 - val_loss: 5.7221e-05\n",
      "Epoch 1569/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 8.4215e-05 - val_loss: 7.0486e-05\n",
      "Epoch 1570/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.2970e-05 - val_loss: 1.1730e-04\n",
      "Epoch 1571/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1844e-04 - val_loss: 1.3337e-04\n",
      "Epoch 1572/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.2539e-05 - val_loss: 5.1995e-05\n",
      "Epoch 1573/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.8390e-05 - val_loss: 1.6488e-04\n",
      "Epoch 1574/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.7483e-05 - val_loss: 5.7924e-05\n",
      "Epoch 1575/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 7.5081e-05 - val_loss: 6.0805e-05\n",
      "Epoch 1576/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.4616e-05 - val_loss: 6.9884e-05\n",
      "Epoch 1577/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.0746e-05 - val_loss: 1.1409e-04\n",
      "Epoch 1578/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.5341e-05 - val_loss: 8.9751e-05\n",
      "Epoch 1579/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.4762e-05 - val_loss: 2.4234e-04\n",
      "Epoch 1580/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 1.3177e-04 - val_loss: 8.4709e-05\n",
      "Epoch 1581/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 8.6392e-05 - val_loss: 4.3295e-04\n",
      "Epoch 1582/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.2316e-04 - val_loss: 8.3195e-05\n",
      "Epoch 1583/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.8602e-05 - val_loss: 5.2328e-05\n",
      "Epoch 1584/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 1.1082e-04 - val_loss: 2.0568e-04\n",
      "Epoch 1585/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0507e-04 - val_loss: 8.4549e-05\n",
      "Epoch 1586/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.6937e-05 - val_loss: 4.8412e-05\n",
      "Epoch 1587/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.7816e-05 - val_loss: 1.5733e-04\n",
      "Epoch 1588/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.8959e-05 - val_loss: 1.1864e-04\n",
      "Epoch 1589/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.4566e-05 - val_loss: 5.2045e-05\n",
      "Epoch 1590/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.9600e-05 - val_loss: 1.0109e-04\n",
      "Epoch 1591/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.0008e-05 - val_loss: 7.3189e-05\n",
      "Epoch 1592/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.8439e-05 - val_loss: 2.0528e-04\n",
      "Epoch 1593/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.0938e-04 - val_loss: 1.2181e-04\n",
      "Epoch 1594/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.1743e-05 - val_loss: 9.9916e-05\n",
      "Epoch 1595/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.5838e-05 - val_loss: 5.8005e-05\n",
      "Epoch 1596/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.0819e-05 - val_loss: 5.2670e-05\n",
      "Epoch 1597/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.4981e-05 - val_loss: 1.7919e-04\n",
      "Epoch 1598/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 8.9197e-05 - val_loss: 6.3178e-05\n",
      "Epoch 1599/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.2681e-05 - val_loss: 1.6977e-04\n",
      "Epoch 1600/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.9489e-05 - val_loss: 5.9090e-05\n",
      "Epoch 1601/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.8825e-05 - val_loss: 3.1094e-04\n",
      "Epoch 1602/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.9283e-05 - val_loss: 5.0923e-05\n",
      "Epoch 1603/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.7515e-05 - val_loss: 1.2957e-04\n",
      "Epoch 1604/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.3918e-05 - val_loss: 5.6124e-05\n",
      "Epoch 1605/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.3097e-05 - val_loss: 1.2238e-04\n",
      "Epoch 1606/2000\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 8.8776e-05 - val_loss: 5.6880e-05\n",
      "Epoch 1607/2000\n",
      "4143/4143 [==============================] - 3s 646us/step - loss: 9.3337e-05 - val_loss: 1.4782e-04\n",
      "Epoch 1608/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 9.3610e-05 - val_loss: 5.1738e-05\n",
      "Epoch 1609/2000\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 8.2744e-05 - val_loss: 5.8327e-05\n",
      "Epoch 1610/2000\n",
      "4143/4143 [==============================] - 3s 649us/step - loss: 7.5573e-05 - val_loss: 6.7508e-05\n",
      "Epoch 1611/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.0347e-05 - val_loss: 6.0663e-05\n",
      "Epoch 1612/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.5845e-05 - val_loss: 2.1765e-04\n",
      "Epoch 1613/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.8530e-05 - val_loss: 5.2780e-05\n",
      "Epoch 1614/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.0518e-05 - val_loss: 3.4817e-04\n",
      "Epoch 1615/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.2086e-04 - val_loss: 5.5401e-05\n",
      "Epoch 1616/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 9.8962e-05 - val_loss: 9.2394e-05\n",
      "Epoch 1617/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.6789e-05 - val_loss: 1.8219e-04\n",
      "Epoch 1618/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1482e-04 - val_loss: 1.2434e-04\n",
      "Epoch 1619/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.5139e-05 - val_loss: 5.4392e-05\n",
      "Epoch 1620/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.7612e-05 - val_loss: 2.4608e-04\n",
      "Epoch 1621/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.2386e-04 - val_loss: 1.0043e-04\n",
      "Epoch 1622/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1319e-04 - val_loss: 1.2217e-04\n",
      "Epoch 1623/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0014e-04 - val_loss: 1.1477e-04\n",
      "Epoch 1624/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.9043e-05 - val_loss: 5.6333e-05\n",
      "Epoch 1625/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.9997e-05 - val_loss: 8.1717e-05\n",
      "Epoch 1626/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.0945e-05 - val_loss: 9.8918e-05\n",
      "Epoch 1627/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.7123e-05 - val_loss: 9.1292e-05\n",
      "Epoch 1628/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.6308e-05 - val_loss: 6.0679e-05\n",
      "Epoch 1629/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.8558e-05 - val_loss: 1.4572e-04\n",
      "Epoch 1630/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.3615e-05 - val_loss: 9.3491e-05\n",
      "Epoch 1631/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.6548e-05 - val_loss: 6.6807e-05\n",
      "Epoch 1632/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.1938e-05 - val_loss: 2.5846e-04\n",
      "Epoch 1633/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0244e-04 - val_loss: 5.2838e-05\n",
      "Epoch 1634/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.4119e-05 - val_loss: 9.4783e-05\n",
      "Epoch 1635/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.6151e-05 - val_loss: 9.5999e-05\n",
      "Epoch 1636/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.8485e-05 - val_loss: 6.4149e-05\n",
      "Epoch 1637/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.0416e-05 - val_loss: 5.6701e-05\n",
      "Epoch 1638/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.3968e-05 - val_loss: 1.6049e-04\n",
      "Epoch 1639/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.6635e-05 - val_loss: 5.2392e-05\n",
      "Epoch 1640/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.8636e-05 - val_loss: 7.4736e-05\n",
      "Epoch 1641/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 9.1033e-05 - val_loss: 6.0130e-05\n",
      "Epoch 1642/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.0245e-05 - val_loss: 7.3669e-05\n",
      "Epoch 1643/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.3876e-05 - val_loss: 1.1405e-04\n",
      "Epoch 1644/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.0726e-05 - val_loss: 1.0496e-04\n",
      "Epoch 1645/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.2069e-05 - val_loss: 1.3217e-04\n",
      "Epoch 1646/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.3149e-05 - val_loss: 6.2516e-05\n",
      "Epoch 1647/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.6340e-05 - val_loss: 5.4248e-05\n",
      "Epoch 1648/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.3433e-05 - val_loss: 1.9807e-04\n",
      "Epoch 1649/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.6157e-05 - val_loss: 7.0651e-05\n",
      "Epoch 1650/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.7459e-05 - val_loss: 7.2015e-05\n",
      "Epoch 1651/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.6255e-05 - val_loss: 5.0490e-05\n",
      "Epoch 1652/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.9229e-05 - val_loss: 6.1586e-05\n",
      "Epoch 1653/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.1170e-05 - val_loss: 1.1644e-04\n",
      "Epoch 1654/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.9239e-05 - val_loss: 5.3952e-05\n",
      "Epoch 1655/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 8.0267e-05 - val_loss: 5.4789e-05\n",
      "Epoch 1656/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.8662e-05 - val_loss: 5.0809e-05\n",
      "Epoch 1657/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.4403e-05 - val_loss: 9.8210e-05\n",
      "Epoch 1658/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.1997e-05 - val_loss: 5.3821e-05\n",
      "Epoch 1659/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.0529e-05 - val_loss: 1.1975e-04\n",
      "Epoch 1660/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.0211e-05 - val_loss: 1.8510e-04\n",
      "Epoch 1661/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.7559e-05 - val_loss: 4.9172e-05\n",
      "Epoch 1662/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.6516e-05 - val_loss: 1.6256e-04\n",
      "Epoch 1663/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.6545e-05 - val_loss: 6.5638e-05\n",
      "Epoch 1664/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.5836e-05 - val_loss: 1.5575e-04\n",
      "Epoch 1665/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 8.5050e-05 - val_loss: 4.9393e-05\n",
      "Epoch 1666/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.2402e-04 - val_loss: 1.7840e-04\n",
      "Epoch 1667/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.3497e-05 - val_loss: 5.7276e-05\n",
      "Epoch 1668/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.2379e-05 - val_loss: 6.9143e-05\n",
      "Epoch 1669/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.7420e-05 - val_loss: 9.2796e-05\n",
      "Epoch 1670/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 7.7530e-05 - val_loss: 1.3019e-04\n",
      "Epoch 1671/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.7593e-05 - val_loss: 5.4492e-05\n",
      "Epoch 1672/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 7.5767e-05 - val_loss: 8.4288e-05\n",
      "Epoch 1673/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.2830e-05 - val_loss: 1.2832e-04\n",
      "Epoch 1674/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.7014e-05 - val_loss: 1.2851e-04\n",
      "Epoch 1675/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.2863e-05 - val_loss: 6.5679e-05\n",
      "Epoch 1676/2000\n",
      "4143/4143 [==============================] - 3s 650us/step - loss: 8.0612e-05 - val_loss: 3.6792e-04\n",
      "Epoch 1677/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.2441e-04 - val_loss: 5.4632e-05\n",
      "Epoch 1678/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.9930e-05 - val_loss: 1.6286e-04\n",
      "Epoch 1679/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.1679e-05 - val_loss: 5.0044e-05\n",
      "Epoch 1680/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.7534e-05 - val_loss: 1.0795e-04\n",
      "Epoch 1681/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.2596e-05 - val_loss: 5.9536e-05\n",
      "Epoch 1682/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.8085e-05 - val_loss: 6.4622e-05\n",
      "Epoch 1683/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.2962e-05 - val_loss: 2.9849e-04\n",
      "Epoch 1684/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.1530e-05 - val_loss: 5.0482e-05\n",
      "Epoch 1685/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.3474e-05 - val_loss: 1.5270e-04\n",
      "Epoch 1686/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.1324e-05 - val_loss: 6.2728e-05\n",
      "Epoch 1687/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.4605e-05 - val_loss: 6.8350e-05\n",
      "Epoch 1688/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 7.2106e-05 - val_loss: 1.1297e-04\n",
      "Epoch 1689/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.3146e-05 - val_loss: 6.1972e-05\n",
      "Epoch 1690/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.0417e-05 - val_loss: 1.5095e-04\n",
      "Epoch 1691/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.4828e-05 - val_loss: 9.1144e-05\n",
      "Epoch 1692/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 8.6541e-05 - val_loss: 8.8512e-05\n",
      "Epoch 1693/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.6697e-05 - val_loss: 7.0660e-05\n",
      "Epoch 1694/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.3956e-05 - val_loss: 6.2558e-05\n",
      "Epoch 1695/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.1929e-05 - val_loss: 1.3984e-04\n",
      "Epoch 1696/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.8755e-05 - val_loss: 6.3197e-05\n",
      "Epoch 1697/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.2480e-05 - val_loss: 9.9496e-05\n",
      "Epoch 1698/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.3851e-05 - val_loss: 1.4312e-04\n",
      "Epoch 1699/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.7795e-05 - val_loss: 7.6878e-05\n",
      "Epoch 1700/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.7636e-05 - val_loss: 9.9313e-05\n",
      "Epoch 1701/2000\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 7.4624e-05 - val_loss: 7.1200e-05\n",
      "Epoch 1702/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.2430e-05 - val_loss: 5.7954e-05\n",
      "Epoch 1703/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.8600e-05 - val_loss: 1.2112e-04\n",
      "Epoch 1704/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.5951e-05 - val_loss: 5.3361e-05\n",
      "Epoch 1705/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.8716e-05 - val_loss: 1.9549e-04\n",
      "Epoch 1706/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.1342e-05 - val_loss: 6.1254e-05\n",
      "Epoch 1707/2000\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 7.8970e-05 - val_loss: 5.5159e-05\n",
      "Epoch 1708/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.4228e-05 - val_loss: 1.1533e-04\n",
      "Epoch 1709/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.6084e-05 - val_loss: 2.1178e-04\n",
      "Epoch 1710/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.7342e-05 - val_loss: 5.7244e-05\n",
      "Epoch 1711/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.7882e-05 - val_loss: 1.8478e-04\n",
      "Epoch 1712/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.3463e-05 - val_loss: 7.1868e-05\n",
      "Epoch 1713/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.8176e-05 - val_loss: 1.5484e-04\n",
      "Epoch 1714/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.5301e-05 - val_loss: 5.5900e-05\n",
      "Epoch 1715/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 9.0888e-05 - val_loss: 1.3830e-04\n",
      "Epoch 1716/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1712e-04 - val_loss: 6.6496e-05\n",
      "Epoch 1717/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 1.0285e-04 - val_loss: 1.0934e-04\n",
      "Epoch 1718/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.0471e-04 - val_loss: 1.5270e-04\n",
      "Epoch 1719/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.5721e-05 - val_loss: 7.7226e-05\n",
      "Epoch 1720/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.7143e-05 - val_loss: 8.0277e-05\n",
      "Epoch 1721/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.5061e-05 - val_loss: 5.2291e-05\n",
      "Epoch 1722/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.1927e-04 - val_loss: 8.7734e-05\n",
      "Epoch 1723/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.7601e-05 - val_loss: 8.2514e-05\n",
      "Epoch 1724/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.0052e-05 - val_loss: 2.0616e-04\n",
      "Epoch 1725/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.4088e-05 - val_loss: 6.5452e-05\n",
      "Epoch 1726/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.6074e-05 - val_loss: 1.2013e-04\n",
      "Epoch 1727/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.0670e-05 - val_loss: 7.4621e-05\n",
      "Epoch 1728/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 7.2151e-05 - val_loss: 6.3026e-05\n",
      "Epoch 1729/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 7.4385e-05 - val_loss: 1.6496e-04\n",
      "Epoch 1730/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.1191e-05 - val_loss: 5.2717e-05\n",
      "Epoch 1731/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.7220e-05 - val_loss: 2.1226e-04\n",
      "Epoch 1732/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.6810e-05 - val_loss: 6.7105e-05\n",
      "Epoch 1733/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.5645e-05 - val_loss: 9.1139e-05\n",
      "Epoch 1734/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 6.9810e-05 - val_loss: 1.7011e-04\n",
      "Epoch 1735/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.3350e-05 - val_loss: 5.0762e-05\n",
      "Epoch 1736/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.9176e-05 - val_loss: 1.5019e-04\n",
      "Epoch 1737/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.8450e-05 - val_loss: 6.6516e-05\n",
      "Epoch 1738/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 7.9685e-05 - val_loss: 9.1245e-05\n",
      "Epoch 1739/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.4273e-05 - val_loss: 6.6610e-05\n",
      "Epoch 1740/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.2795e-05 - val_loss: 1.2691e-04\n",
      "Epoch 1741/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.2507e-05 - val_loss: 4.9523e-05\n",
      "Epoch 1742/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.9906e-05 - val_loss: 6.3602e-05\n",
      "Epoch 1743/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 7.6826e-05 - val_loss: 1.6957e-04\n",
      "Epoch 1744/2000\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 8.7944e-05 - val_loss: 1.1416e-04\n",
      "Epoch 1745/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.8388e-05 - val_loss: 5.8434e-05\n",
      "Epoch 1746/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.1590e-05 - val_loss: 1.0927e-04\n",
      "Epoch 1747/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.1623e-04 - val_loss: 1.1360e-04\n",
      "Epoch 1748/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.0706e-05 - val_loss: 7.9047e-05\n",
      "Epoch 1749/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.9778e-05 - val_loss: 5.1858e-05\n",
      "Epoch 1750/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.4173e-05 - val_loss: 2.1964e-04\n",
      "Epoch 1751/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.3755e-05 - val_loss: 7.5556e-05\n",
      "Epoch 1752/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.0805e-05 - val_loss: 1.2794e-04\n",
      "Epoch 1753/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.3868e-05 - val_loss: 4.9952e-05\n",
      "Epoch 1754/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.4943e-05 - val_loss: 2.2131e-04\n",
      "Epoch 1755/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.1123e-05 - val_loss: 6.0863e-05\n",
      "Epoch 1756/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 1.1126e-04 - val_loss: 2.6662e-04\n",
      "Epoch 1757/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1628e-04 - val_loss: 5.5575e-05\n",
      "Epoch 1758/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.8680e-05 - val_loss: 1.1308e-04\n",
      "Epoch 1759/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.4990e-05 - val_loss: 1.0375e-04\n",
      "Epoch 1760/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 6.9749e-05 - val_loss: 6.1101e-05\n",
      "Epoch 1761/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.4381e-05 - val_loss: 5.5918e-05\n",
      "Epoch 1762/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.6719e-05 - val_loss: 1.4943e-04\n",
      "Epoch 1763/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.5332e-05 - val_loss: 9.9818e-05\n",
      "Epoch 1764/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.1897e-05 - val_loss: 1.3736e-04\n",
      "Epoch 1765/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.6635e-05 - val_loss: 6.1752e-05\n",
      "Epoch 1766/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 8.8895e-05 - val_loss: 6.6904e-05\n",
      "Epoch 1767/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 8.2893e-05 - val_loss: 7.4059e-05\n",
      "Epoch 1768/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.3682e-05 - val_loss: 1.8465e-04\n",
      "Epoch 1769/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.3080e-05 - val_loss: 8.1110e-05\n",
      "Epoch 1770/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 9.1671e-05 - val_loss: 5.0477e-05\n",
      "Epoch 1771/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 9.1909e-05 - val_loss: 1.7981e-04\n",
      "Epoch 1772/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.2675e-05 - val_loss: 2.0200e-04\n",
      "Epoch 1773/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.3767e-04 - val_loss: 2.3090e-04\n",
      "Epoch 1774/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 1.0199e-04 - val_loss: 5.6267e-05\n",
      "Epoch 1775/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.0906e-05 - val_loss: 6.1924e-05\n",
      "Epoch 1776/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.8755e-05 - val_loss: 2.3602e-04\n",
      "Epoch 1777/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0900e-04 - val_loss: 1.8385e-04\n",
      "Epoch 1778/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.3722e-04 - val_loss: 3.5014e-04\n",
      "Epoch 1779/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.0916e-04 - val_loss: 5.4346e-05\n",
      "Epoch 1780/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.9158e-05 - val_loss: 1.1714e-04\n",
      "Epoch 1781/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 7.7759e-05 - val_loss: 1.1803e-04\n",
      "Epoch 1782/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 8.2146e-05 - val_loss: 7.0475e-05\n",
      "Epoch 1783/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.7132e-05 - val_loss: 6.6765e-05\n",
      "Epoch 1784/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.0353e-05 - val_loss: 1.1185e-04\n",
      "Epoch 1785/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.0701e-05 - val_loss: 7.4648e-05\n",
      "Epoch 1786/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.2606e-05 - val_loss: 6.3836e-05\n",
      "Epoch 1787/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.2293e-05 - val_loss: 5.8371e-05\n",
      "Epoch 1788/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.5548e-05 - val_loss: 2.8926e-04\n",
      "Epoch 1789/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 1.1684e-04 - val_loss: 1.6302e-04\n",
      "Epoch 1790/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.4133e-04 - val_loss: 1.4441e-04\n",
      "Epoch 1791/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.6646e-05 - val_loss: 9.0321e-05\n",
      "Epoch 1792/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 8.0137e-05 - val_loss: 2.0371e-04\n",
      "Epoch 1793/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.7282e-05 - val_loss: 6.4958e-05\n",
      "Epoch 1794/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.4445e-05 - val_loss: 8.8227e-05\n",
      "Epoch 1795/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.2918e-05 - val_loss: 6.8534e-05\n",
      "Epoch 1796/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.6726e-05 - val_loss: 5.2421e-05\n",
      "Epoch 1797/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.3508e-05 - val_loss: 8.0433e-05\n",
      "Epoch 1798/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 7.2259e-05 - val_loss: 7.0977e-05\n",
      "Epoch 1799/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.4790e-05 - val_loss: 5.4326e-05\n",
      "Epoch 1800/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.8067e-05 - val_loss: 1.1759e-04\n",
      "Epoch 1801/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.1741e-05 - val_loss: 5.9481e-05\n",
      "Epoch 1802/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.7061e-05 - val_loss: 2.0357e-04\n",
      "Epoch 1803/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.3942e-05 - val_loss: 5.0622e-05\n",
      "Epoch 1804/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.2122e-05 - val_loss: 1.5799e-04\n",
      "Epoch 1805/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.8731e-05 - val_loss: 1.4032e-04\n",
      "Epoch 1806/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.0513e-05 - val_loss: 5.6055e-05\n",
      "Epoch 1807/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.5817e-05 - val_loss: 7.5924e-05\n",
      "Epoch 1808/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 7.1839e-05 - val_loss: 2.6346e-04\n",
      "Epoch 1809/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0685e-04 - val_loss: 4.8000e-05\n",
      "Epoch 1810/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.1175e-05 - val_loss: 8.2747e-05\n",
      "Epoch 1811/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.3809e-05 - val_loss: 1.2567e-04\n",
      "Epoch 1812/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.5051e-05 - val_loss: 5.2509e-05\n",
      "Epoch 1813/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 1.0419e-04 - val_loss: 1.1487e-04\n",
      "Epoch 1814/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.9741e-05 - val_loss: 5.6225e-05\n",
      "Epoch 1815/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.7371e-05 - val_loss: 2.5444e-04\n",
      "Epoch 1816/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 8.8442e-05 - val_loss: 5.4062e-05\n",
      "Epoch 1817/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.6145e-05 - val_loss: 5.1716e-05\n",
      "Epoch 1818/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.8109e-05 - val_loss: 2.4182e-04\n",
      "Epoch 1819/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.8211e-05 - val_loss: 5.3851e-05\n",
      "Epoch 1820/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.0300e-05 - val_loss: 1.0363e-04\n",
      "Epoch 1821/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.3284e-05 - val_loss: 1.7150e-04\n",
      "Epoch 1822/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 8.4876e-05 - val_loss: 1.0003e-04\n",
      "Epoch 1823/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.7443e-05 - val_loss: 6.8025e-05\n",
      "Epoch 1824/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 8.0904e-05 - val_loss: 5.2723e-05\n",
      "Epoch 1825/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.3548e-05 - val_loss: 1.9627e-04\n",
      "Epoch 1826/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.6931e-05 - val_loss: 6.8616e-05\n",
      "Epoch 1827/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.2551e-05 - val_loss: 7.3353e-05\n",
      "Epoch 1828/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 1.1610e-04 - val_loss: 5.1909e-05\n",
      "Epoch 1829/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 634us/step - loss: 9.5614e-05 - val_loss: 9.1995e-05\n",
      "Epoch 1830/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.8446e-05 - val_loss: 9.5972e-05\n",
      "Epoch 1831/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.7180e-05 - val_loss: 9.5340e-05\n",
      "Epoch 1832/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 7.5827e-05 - val_loss: 5.1988e-05\n",
      "Epoch 1833/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 8.5423e-05 - val_loss: 1.6665e-04\n",
      "Epoch 1834/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.1375e-05 - val_loss: 5.2996e-05\n",
      "Epoch 1835/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.2192e-05 - val_loss: 1.5550e-04\n",
      "Epoch 1836/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.6926e-05 - val_loss: 7.2833e-05\n",
      "Epoch 1837/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.4456e-05 - val_loss: 6.6099e-05\n",
      "Epoch 1838/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.3948e-05 - val_loss: 1.1744e-04\n",
      "Epoch 1839/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.5077e-05 - val_loss: 5.0703e-05\n",
      "Epoch 1840/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 7.7542e-05 - val_loss: 1.6782e-04\n",
      "Epoch 1841/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 7.3125e-05 - val_loss: 8.0855e-05\n",
      "Epoch 1842/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.3060e-05 - val_loss: 5.1826e-05\n",
      "Epoch 1843/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.5845e-05 - val_loss: 1.8724e-04\n",
      "Epoch 1844/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.7517e-05 - val_loss: 1.1087e-04\n",
      "Epoch 1845/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.8829e-05 - val_loss: 9.0861e-05\n",
      "Epoch 1846/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.2337e-05 - val_loss: 6.5575e-05\n",
      "Epoch 1847/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.2070e-05 - val_loss: 7.0584e-05\n",
      "Epoch 1848/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.7619e-05 - val_loss: 2.1282e-04\n",
      "Epoch 1849/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.5473e-05 - val_loss: 5.4716e-05\n",
      "Epoch 1850/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.8922e-05 - val_loss: 1.9049e-04\n",
      "Epoch 1851/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.4533e-05 - val_loss: 6.9345e-05\n",
      "Epoch 1852/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 8.1304e-05 - val_loss: 4.5401e-04\n",
      "Epoch 1853/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 1.2163e-04 - val_loss: 6.1464e-05\n",
      "Epoch 1854/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.1860e-05 - val_loss: 1.6490e-04\n",
      "Epoch 1855/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.7492e-05 - val_loss: 9.9520e-05\n",
      "Epoch 1856/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.2104e-05 - val_loss: 5.2336e-05\n",
      "Epoch 1857/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.8660e-05 - val_loss: 1.3427e-04\n",
      "Epoch 1858/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.6714e-05 - val_loss: 4.3120e-04\n",
      "Epoch 1859/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.1567e-04 - val_loss: 7.4970e-05\n",
      "Epoch 1860/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 9.5685e-05 - val_loss: 6.3813e-05\n",
      "Epoch 1861/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.3159e-05 - val_loss: 1.0359e-04\n",
      "Epoch 1862/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 9.2961e-05 - val_loss: 1.1422e-04\n",
      "Epoch 1863/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.9089e-05 - val_loss: 6.7458e-05\n",
      "Epoch 1864/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 6.9744e-05 - val_loss: 6.9586e-05\n",
      "Epoch 1865/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 7.7530e-05 - val_loss: 8.6041e-05\n",
      "Epoch 1866/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.4349e-05 - val_loss: 5.5013e-05\n",
      "Epoch 1867/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.0327e-05 - val_loss: 2.1378e-04\n",
      "Epoch 1868/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.7449e-05 - val_loss: 5.8486e-05\n",
      "Epoch 1869/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 6.9214e-05 - val_loss: 1.5637e-04\n",
      "Epoch 1870/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.1726e-05 - val_loss: 6.3682e-05\n",
      "Epoch 1871/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.1499e-05 - val_loss: 6.9132e-05\n",
      "Epoch 1872/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 7.4255e-05 - val_loss: 1.4339e-04\n",
      "Epoch 1873/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.8331e-05 - val_loss: 7.5767e-05\n",
      "Epoch 1874/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 7.8730e-05 - val_loss: 1.3931e-04\n",
      "Epoch 1875/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.2795e-05 - val_loss: 1.1466e-04\n",
      "Epoch 1876/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.4688e-05 - val_loss: 1.0069e-04\n",
      "Epoch 1877/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.3143e-05 - val_loss: 1.4476e-04\n",
      "Epoch 1878/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 7.2532e-05 - val_loss: 2.0295e-04\n",
      "Epoch 1879/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 8.2577e-05 - val_loss: 5.6564e-05\n",
      "Epoch 1880/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.2693e-05 - val_loss: 7.3072e-05\n",
      "Epoch 1881/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.1527e-05 - val_loss: 7.9287e-05\n",
      "Epoch 1882/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.1173e-05 - val_loss: 1.4352e-04\n",
      "Epoch 1883/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.9300e-05 - val_loss: 6.0806e-05\n",
      "Epoch 1884/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.7977e-05 - val_loss: 1.5861e-04\n",
      "Epoch 1885/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.7845e-05 - val_loss: 6.0026e-05\n",
      "Epoch 1886/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.9029e-05 - val_loss: 1.9446e-04\n",
      "Epoch 1887/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 8.0562e-05 - val_loss: 5.7056e-05\n",
      "Epoch 1888/2000\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 7.0216e-05 - val_loss: 6.0429e-05\n",
      "Epoch 1889/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.2774e-05 - val_loss: 9.5180e-05\n",
      "Epoch 1890/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.2312e-05 - val_loss: 2.3847e-04\n",
      "Epoch 1891/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 8.7983e-05 - val_loss: 6.2941e-05\n",
      "Epoch 1892/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 8.5505e-05 - val_loss: 1.2024e-04\n",
      "Epoch 1893/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.4011e-05 - val_loss: 1.0490e-04\n",
      "Epoch 1894/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 7.1972e-05 - val_loss: 1.7910e-04\n",
      "Epoch 1895/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.6740e-05 - val_loss: 5.9192e-05\n",
      "Epoch 1896/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.3850e-05 - val_loss: 1.3539e-04\n",
      "Epoch 1897/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.2349e-05 - val_loss: 7.3977e-05\n",
      "Epoch 1898/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.1127e-04 - val_loss: 1.2594e-04\n",
      "Epoch 1899/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 637us/step - loss: 9.7965e-05 - val_loss: 1.9023e-04\n",
      "Epoch 1900/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 9.3013e-05 - val_loss: 8.5312e-05\n",
      "Epoch 1901/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.5131e-05 - val_loss: 1.0917e-04\n",
      "Epoch 1902/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.5772e-05 - val_loss: 1.0692e-04\n",
      "Epoch 1903/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.5354e-05 - val_loss: 7.4078e-05\n",
      "Epoch 1904/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 8.1532e-05 - val_loss: 1.3199e-04\n",
      "Epoch 1905/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 7.4863e-05 - val_loss: 6.1245e-05\n",
      "Epoch 1906/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 7.7626e-05 - val_loss: 2.5641e-04\n",
      "Epoch 1907/2000\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 8.7309e-05 - val_loss: 5.0701e-05\n",
      "Epoch 1908/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.2973e-05 - val_loss: 5.8377e-05\n",
      "Epoch 1909/2000\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 7.6811e-05 - val_loss: 3.3262e-04\n",
      "Epoch 1910/2000\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 9.6430e-05 - val_loss: 5.3358e-05\n",
      "Epoch 1911/2000\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 8.2225e-05 - val_loss: 7.7360e-05\n",
      "Epoch 1912/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 6.9472e-05 - val_loss: 7.2539e-05\n",
      "Epoch 1913/2000\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 7.6139e-05 - val_loss: 1.5764e-04\n",
      "Epoch 1914/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.6013e-05 - val_loss: 5.9583e-05\n",
      "Epoch 1915/2000\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.9635e-05 - val_loss: 1.6553e-04\n",
      "Epoch 1916/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.6546e-05 - val_loss: 2.1753e-04\n",
      "Epoch 1917/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 8.4797e-05 - val_loss: 5.4835e-05\n",
      "Epoch 1918/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.9595e-05 - val_loss: 9.9713e-05\n",
      "Epoch 1919/2000\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 7.6197e-05 - val_loss: 7.7675e-05\n",
      "Epoch 1920/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.9862e-05 - val_loss: 1.8159e-04\n",
      "Epoch 1921/2000\n",
      "4143/4143 [==============================] - 3s 651us/step - loss: 8.5090e-05 - val_loss: 1.4375e-04\n",
      "Epoch 1922/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.8227e-05 - val_loss: 5.5127e-05\n",
      "Epoch 1923/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.0655e-05 - val_loss: 6.7142e-05\n",
      "Epoch 1924/2000\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 7.7226e-05 - val_loss: 2.3895e-04\n",
      "Epoch 1925/2000\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 8.3413e-05 - val_loss: 5.6005e-05\n",
      "Epoch 1926/2000\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 7.3709e-05 - val_loss: 1.1328e-04\n",
      "Epoch 1927/2000\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 7.1951e-05 - val_loss: 7.7041e-05\n",
      "Epoch 1928/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.4124e-05 - val_loss: 1.8817e-04\n",
      "Epoch 1929/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 7.6173e-05 - val_loss: 1.1242e-04\n",
      "Epoch 1930/2000\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 7.1171e-05 - val_loss: 1.3472e-04\n",
      "Epoch 1931/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 7.2114e-05 - val_loss: 6.3881e-05\n",
      "Epoch 1932/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.3094e-05 - val_loss: 4.7349e-04\n",
      "Epoch 1933/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 1.2834e-04 - val_loss: 8.5953e-05\n",
      "Epoch 1934/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 1.1007e-04 - val_loss: 1.2236e-04\n",
      "Epoch 1935/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.6261e-05 - val_loss: 1.6351e-04\n",
      "Epoch 1936/2000\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 7.3797e-05 - val_loss: 5.3484e-05\n",
      "Epoch 1937/2000\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 7.5652e-05 - val_loss: 1.0152e-04\n",
      "Epoch 1938/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 6.7858e-05 - val_loss: 2.9879e-04\n",
      "Epoch 1939/2000\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 1.0535e-04 - val_loss: 8.1462e-05\n",
      "Epoch 1940/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 9.6473e-05 - val_loss: 2.8595e-04\n",
      "Epoch 1941/2000\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 9.7854e-05 - val_loss: 5.9136e-05\n",
      "Epoch 1942/2000\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 8.4325e-05 - val_loss: 5.7654e-05\n",
      "Epoch 1943/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 7.9046e-05 - val_loss: 2.5026e-04\n",
      "Epoch 1944/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 9.0604e-05 - val_loss: 7.5904e-05\n",
      "Epoch 1945/2000\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 6.9383e-05 - val_loss: 9.0238e-05\n",
      "Epoch 1946/2000\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 7.6706e-05 - val_loss: 5.8614e-05\n",
      "Epoch 1947/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.8201e-05 - val_loss: 4.2333e-04\n",
      "Epoch 1948/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 1.1480e-04 - val_loss: 4.8172e-05\n",
      "Epoch 1949/2000\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 8.8205e-05 - val_loss: 1.9262e-04\n",
      "Epoch 1950/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 9.3614e-05 - val_loss: 1.1498e-04\n",
      "Epoch 1951/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 9.9364e-05 - val_loss: 6.2527e-05\n",
      "Epoch 1952/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 8.3821e-05 - val_loss: 6.7352e-05\n",
      "Epoch 1953/2000\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 7.8723e-05 - val_loss: 1.6794e-04\n",
      "Epoch 1954/2000\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 7.8769e-05 - val_loss: 5.6998e-05\n",
      "Epoch 1955/2000\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 8.0185e-05 - val_loss: 1.7804e-04\n",
      "Epoch 1956/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 8.5359e-05 - val_loss: 8.8759e-05\n",
      "Epoch 1957/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 8.2973e-05 - val_loss: 7.3694e-05\n",
      "Epoch 1958/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 6.9530e-05 - val_loss: 8.2266e-05\n",
      "Epoch 1959/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 7.6426e-05 - val_loss: 2.0558e-04\n",
      "Epoch 1960/2000\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 7.6036e-05 - val_loss: 1.2195e-04\n",
      "Epoch 1961/2000\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 8.0467e-05 - val_loss: 1.4455e-04\n",
      "Epoch 1962/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 7.6706e-05 - val_loss: 5.0864e-05\n",
      "Epoch 1963/2000\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 8.3582e-05 - val_loss: 1.7235e-04\n",
      "Epoch 1964/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 7.7836e-05 - val_loss: 6.5045e-05\n",
      "Epoch 1965/2000\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 7.9699e-05 - val_loss: 5.3255e-05\n",
      "Epoch 1966/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 8.4485e-05 - val_loss: 1.5999e-04\n",
      "Epoch 1967/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.8600e-05 - val_loss: 5.8399e-05\n",
      "Epoch 1968/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 8.2710e-05 - val_loss: 1.6597e-04\n",
      "Epoch 1969/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.5882e-05 - val_loss: 5.4529e-05\n",
      "Epoch 1970/2000\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 9.0697e-05 - val_loss: 1.5414e-04\n",
      "Epoch 1971/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.6515e-05 - val_loss: 1.3740e-04\n",
      "Epoch 1972/2000\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 8.9552e-05 - val_loss: 1.2854e-04\n",
      "Epoch 1973/2000\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 8.2013e-05 - val_loss: 1.0231e-04\n",
      "Epoch 1974/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 7.9922e-05 - val_loss: 7.8939e-05\n",
      "Epoch 1975/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 1.1201e-04 - val_loss: 1.4439e-04\n",
      "Epoch 1976/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 9.8226e-05 - val_loss: 1.4243e-04\n",
      "Epoch 1977/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 8.0785e-05 - val_loss: 1.7797e-04\n",
      "Epoch 1978/2000\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 8.3196e-05 - val_loss: 5.7450e-05\n",
      "Epoch 1979/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 8.4713e-05 - val_loss: 8.7375e-05\n",
      "Epoch 1980/2000\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 7.7761e-05 - val_loss: 1.0119e-04\n",
      "Epoch 1981/2000\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 9.1575e-05 - val_loss: 6.5793e-05\n",
      "Epoch 1982/2000\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 8.3916e-05 - val_loss: 9.2119e-05\n",
      "Epoch 1983/2000\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 7.7787e-05 - val_loss: 5.9067e-05\n",
      "Epoch 1984/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 8.0711e-05 - val_loss: 7.7478e-05\n",
      "Epoch 1985/2000\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 6.8688e-05 - val_loss: 1.3046e-04\n",
      "Epoch 1986/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 7.4239e-05 - val_loss: 1.1157e-04\n",
      "Epoch 1987/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 6.7357e-05 - val_loss: 1.8835e-04\n",
      "Epoch 1988/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 7.0594e-05 - val_loss: 6.5273e-05\n",
      "Epoch 1989/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 7.3628e-05 - val_loss: 1.8253e-04\n",
      "Epoch 1990/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.3717e-05 - val_loss: 1.0828e-04\n",
      "Epoch 1991/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 7.7477e-05 - val_loss: 1.3340e-04\n",
      "Epoch 1992/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 7.4393e-05 - val_loss: 6.6865e-05\n",
      "Epoch 1993/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 7.2809e-05 - val_loss: 1.2785e-04\n",
      "Epoch 1994/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 6.7457e-05 - val_loss: 3.9330e-04\n",
      "Epoch 1995/2000\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 9.4694e-05 - val_loss: 5.6162e-05\n",
      "Epoch 1996/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 8.0127e-05 - val_loss: 2.4259e-04\n",
      "Epoch 1997/2000\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 8.8647e-05 - val_loss: 1.0775e-04\n",
      "Epoch 1998/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 7.8926e-05 - val_loss: 5.4426e-05\n",
      "Epoch 1999/2000\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 7.8086e-05 - val_loss: 2.6986e-04\n",
      "Epoch 2000/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 8.1343e-05 - val_loss: 5.2548e-05\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstmsize': 178,\n",
       " 'density': 164,\n",
       " 'twice': True,\n",
       " 'dropout': 0.1,\n",
       " 'full_density': True,\n",
       " 'activation': 'elu',\n",
       " 'shuffle': True,\n",
       " 'optimizer': 'adam',\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x1d0456f2f08>]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_363 (LSTM)              (None, 92, 178)           131008    \n",
      "_________________________________________________________________\n",
      "dropout_363 (Dropout)        (None, 92, 178)           0         \n",
      "_________________________________________________________________\n",
      "lstm_364 (LSTM)              (None, 178)               254184    \n",
      "_________________________________________________________________\n",
      "dropout_364 (Dropout)        (None, 178)               0         \n",
      "_________________________________________________________________\n",
      "dense_870 (Dense)            (None, 164)               29356     \n",
      "_________________________________________________________________\n",
      "dense_871 (Dense)            (None, 82)                13530     \n",
      "_________________________________________________________________\n",
      "dense_872 (Dense)            (None, 41)                3403      \n",
      "_________________________________________________________________\n",
      "dense_873 (Dense)            (None, 20)                840       \n",
      "_________________________________________________________________\n",
      "dense_874 (Dense)            (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 432,342\n",
      "Trainable params: 432,342\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_MSE/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 2.94\n",
      "Medium error is 1.03\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 80.00%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 83.41%\n",
      "Accuracy for downward trend is: 77.25%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), true_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
