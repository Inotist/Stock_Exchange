{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from joblib import dump\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(len(data) * train_size)\n",
    "\n",
    "train = data.to_numpy()[:split]\n",
    "test = data.to_numpy()[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "normaliser = preprocessing.MinMaxScaler()\n",
    "train_norm = normaliser.fit_transform(train)\n",
    "test_norm = normaliser.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_train = np.array([train_norm[i : i + backlook].copy() for i in range(len(train) - backlook)])\n",
    "Y_train = np.array([train_norm[:,3][i + backlook].copy() for i in range(len(train) - backlook)])\n",
    "Y_train = np.expand_dims(Y_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised test chunks\n",
    "X_test = np.array([test_norm[i : i + backlook].copy() for i in range(len(test) - backlook)])\n",
    "Y_test = np.array([test_norm[:,3][i + backlook].copy() for i in range(len(test) - backlook)])\n",
    "Y_test = np.expand_dims(Y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33316742],\n",
       "       [0.32308841],\n",
       "       [0.33553164],\n",
       "       ...,\n",
       "       [0.5127232 ],\n",
       "       [0.52865053],\n",
       "       [0.52653518]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Y raw data\n",
    "next_day_open_values = np.array([train[:,3][i + backlook].copy() for i in range(len(train) - backlook)])\n",
    "next_day_open_values = np.expand_dims(next_day_open_values, -1)\n",
    "\n",
    "# Y normaliser\n",
    "y_normaliser = preprocessing.MinMaxScaler()\n",
    "y_normaliser.fit_transform(next_day_open_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./normalisers/y_normaliser.joblib']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save scalers for future use\n",
    "dump(normaliser, './normalisers/x_normaliser.joblib')\n",
    "dump(y_normaliser, './normalisers/y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 735us/step - loss: 0.0634 - val_loss: 0.0079\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0045 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0013 - val_loss: 7.1330e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 9.8912e-04 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 8.1646e-04 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 7.3967e-04 - val_loss: 9.1729e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 7.0070e-04 - val_loss: 7.3772e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.6042e-04 - val_loss: 7.3913e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 6.5143e-04 - val_loss: 8.1054e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.4696e-04 - val_loss: 6.5642e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.1688e-04 - val_loss: 4.9839e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 5.9225e-04 - val_loss: 7.1655e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.1085e-04 - val_loss: 6.4676e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 6.0782e-04 - val_loss: 4.9946e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 6.0261e-04 - val_loss: 7.4950e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 5.8341e-04 - val_loss: 4.6893e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 5.4235e-04 - val_loss: 5.0677e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 5.6224e-04 - val_loss: 5.0334e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 5.2863e-04 - val_loss: 5.6058e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 5.2183e-04 - val_loss: 4.8043e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 5.1006e-04 - val_loss: 4.4020e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 4.9349e-04 - val_loss: 4.4747e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 5.0027e-04 - val_loss: 4.5966e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0756 - val_loss: 0.0330\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0088 - val_loss: 6.5210e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0029 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0018 - val_loss: 5.9059e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0010 - val_loss: 5.9156e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 9.3951e-04 - val_loss: 9.6042e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 7.5729e-04 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 7.2115e-04 - val_loss: 6.7026e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 6.8427e-04 - val_loss: 6.1643e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 6.6435e-04 - val_loss: 6.1546e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.4928e-04 - val_loss: 7.9838e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.3513e-04 - val_loss: 5.8975e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 6.0658e-04 - val_loss: 5.1014e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 5.8857e-04 - val_loss: 4.7584e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 5.7853e-04 - val_loss: 5.2465e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 5.5256e-04 - val_loss: 4.6295e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 5.3903e-04 - val_loss: 4.3949e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 5.3618e-04 - val_loss: 5.9238e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 5.2237e-04 - val_loss: 4.4624e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 5.0775e-04 - val_loss: 4.2091e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 4.9344e-04 - val_loss: 4.3879e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 4.7691e-04 - val_loss: 4.1107e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 4.7229e-04 - val_loss: 4.0454e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 4.7697e-04 - val_loss: 8.9672e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 0.0547 - val_loss: 0.0024\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0031 - val_loss: 7.0051e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 0.0010 - val_loss: 5.6012e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 7.7179e-04 - val_loss: 9.4121e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 6.9468e-04 - val_loss: 7.9668e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.7578e-04 - val_loss: 6.4127e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.7893e-04 - val_loss: 5.1093e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 6.5038e-04 - val_loss: 5.2322e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.3946e-04 - val_loss: 5.2800e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 6.1817e-04 - val_loss: 5.0897e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.1552e-04 - val_loss: 5.2957e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 5.9844e-04 - val_loss: 5.0081e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 5.7706e-04 - val_loss: 4.8268e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 5.7352e-04 - val_loss: 5.0416e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 5.6578e-04 - val_loss: 6.3682e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 5.6108e-04 - val_loss: 4.8561e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 5.4146e-04 - val_loss: 4.7269e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 5.2741e-04 - val_loss: 4.6828e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 5.2531e-04 - val_loss: 5.1930e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 5.2010e-04 - val_loss: 4.6965e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 5.3594e-04 - val_loss: 4.5649e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 5.1477e-04 - val_loss: 4.4169e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 5.0015e-04 - val_loss: 4.2937e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 0.0539 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0025 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0012 - val_loss: 7.4891e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 9.2802e-04 - val_loss: 5.9856e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 8.1907e-04 - val_loss: 9.8655e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 7.6285e-04 - val_loss: 8.1223e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 7.5180e-04 - val_loss: 5.8911e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 7.4299e-04 - val_loss: 6.9711e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 7.2515e-04 - val_loss: 8.3645e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 7.1162e-04 - val_loss: 6.4210e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 6.9811e-04 - val_loss: 6.1474e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.8850e-04 - val_loss: 6.2534e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.7656e-04 - val_loss: 6.9056e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 6.7950e-04 - val_loss: 6.0889e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 6.6778e-04 - val_loss: 5.3961e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 6.5715e-04 - val_loss: 5.2404e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 6.5337e-04 - val_loss: 5.5055e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.3665e-04 - val_loss: 6.0289e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.2672e-04 - val_loss: 5.2299e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.2020e-04 - val_loss: 5.0867e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.2578e-04 - val_loss: 5.0619e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.0838e-04 - val_loss: 5.4848e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 5.9476e-04 - val_loss: 5.2321e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 650us/step - loss: 0.0691 - val_loss: 0.0181\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.0074 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0028 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0014 - val_loss: 6.3727e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0010 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 8.6535e-04 - val_loss: 5.4156e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 8.0359e-04 - val_loss: 9.9801e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 7.6592e-04 - val_loss: 6.4960e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 7.4638e-04 - val_loss: 7.6898e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 7.3200e-04 - val_loss: 6.7160e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 7.1494e-04 - val_loss: 7.3756e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 7.0398e-04 - val_loss: 6.7720e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 6.9235e-04 - val_loss: 7.1332e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 6.8315e-04 - val_loss: 6.6617e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 6.7418e-04 - val_loss: 6.9008e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.6531e-04 - val_loss: 6.8103e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.5739e-04 - val_loss: 6.4081e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 6.4768e-04 - val_loss: 6.2611e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.4034e-04 - val_loss: 6.4668e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 6.3486e-04 - val_loss: 6.0050e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.2759e-04 - val_loss: 6.3870e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 6.2266e-04 - val_loss: 6.0330e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.1622e-04 - val_loss: 6.2988e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 6.1397e-04 - val_loss: 5.7976e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 704us/step - loss: 0.0792 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0084 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0048 - val_loss: 5.6080e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0022 - val_loss: 5.3285e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0021 - val_loss: 6.3528e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0019 - val_loss: 5.3619e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0019 - val_loss: 6.9354e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0018 - val_loss: 5.9286e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0018 - val_loss: 5.4055e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0017 - val_loss: 5.4311e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0017 - val_loss: 5.3061e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0017 - val_loss: 4.9131e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0017 - val_loss: 5.6798e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0016 - val_loss: 4.8567e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0015 - val_loss: 5.6766e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0016 - val_loss: 5.3892e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0015 - val_loss: 4.8348e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0016 - val_loss: 5.5270e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 0.0015 - val_loss: 4.7053e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 4.8874e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0015 - val_loss: 4.7900e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0015 - val_loss: 4.8788e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 764us/step - loss: 0.3459 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0183 - val_loss: 6.9437e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0086 - val_loss: 8.9956e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0039 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0028 - val_loss: 6.3582e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0023 - val_loss: 8.2427e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0021 - val_loss: 8.3684e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0021 - val_loss: 8.7611e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0020 - val_loss: 9.3043e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0019 - val_loss: 9.9313e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0020 - val_loss: 9.8311e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0019 - val_loss: 9.0753e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0019 - val_loss: 6.8865e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0018 - val_loss: 7.6783e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0018 - val_loss: 8.2220e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0017 - val_loss: 8.8186e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0017 - val_loss: 8.3146e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0017 - val_loss: 8.3355e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 776us/step - loss: 0.3679 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0152 - val_loss: 8.1097e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0079 - val_loss: 9.6250e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0042 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0033 - val_loss: 5.7369e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0027 - val_loss: 6.5988e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0025 - val_loss: 9.2856e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0026 - val_loss: 8.9300e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0024 - val_loss: 9.6086e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0023 - val_loss: 7.7041e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0023 - val_loss: 9.0248e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0022 - val_loss: 7.8579e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0022 - val_loss: 7.9667e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0021 - val_loss: 8.4183e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 510us/step - loss: 0.0021 - val_loss: 7.9967e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0020 - val_loss: 6.5241e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0020 - val_loss: 8.3494e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0021 - val_loss: 8.3540e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0021 - val_loss: 6.9256e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0018 - val_loss: 6.6445e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0019 - val_loss: 7.7474e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 758us/step - loss: 0.1338 - val_loss: 0.0445\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0545 - val_loss: 0.0284\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0525 - val_loss: 0.0236\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0506 - val_loss: 0.0333\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 510us/step - loss: 0.0491 - val_loss: 0.0316\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0476 - val_loss: 0.0218\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0459 - val_loss: 0.0199\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0438 - val_loss: 0.0209\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0420 - val_loss: 0.0183\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0406 - val_loss: 0.0257\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0386 - val_loss: 0.0283\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0373 - val_loss: 0.0135\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0355 - val_loss: 0.0140\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0338 - val_loss: 0.0119\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0322 - val_loss: 0.0185\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0301 - val_loss: 0.0154\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0287 - val_loss: 0.0149\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0268 - val_loss: 0.0134\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0250 - val_loss: 0.0105\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 509us/step - loss: 0.0235 - val_loss: 0.0129\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0220 - val_loss: 0.0106\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0203 - val_loss: 0.0077\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0188 - val_loss: 0.0069\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0172 - val_loss: 0.0073\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 767us/step - loss: 0.0655 - val_loss: 0.0386\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0629 - val_loss: 0.0395\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 510us/step - loss: 0.0605 - val_loss: 0.0304\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0581 - val_loss: 0.0216\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0561 - val_loss: 0.0514\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0540 - val_loss: 0.0332\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0517 - val_loss: 0.0200\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0493 - val_loss: 0.0228\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0472 - val_loss: 0.0307\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0451 - val_loss: 0.0295\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0432 - val_loss: 0.0204\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0411 - val_loss: 0.0145\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0392 - val_loss: 0.0234\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0370 - val_loss: 0.0198\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0353 - val_loss: 0.0217\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0332 - val_loss: 0.0166\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0313 - val_loss: 0.0155\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0295 - val_loss: 0.0146\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0277 - val_loss: 0.0127\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0259 - val_loss: 0.0216\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0239 - val_loss: 0.0158\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0225 - val_loss: 0.0126\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0207 - val_loss: 0.0149\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0193 - val_loss: 0.0090\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 788us/step - loss: 0.0725 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0013 - val_loss: 5.8920e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 9.1688e-04 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 7.8348e-04 - val_loss: 9.2637e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 7.5334e-04 - val_loss: 6.8775e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 7.2404e-04 - val_loss: 5.9186e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 7.0638e-04 - val_loss: 5.8550e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 6.9530e-04 - val_loss: 6.8793e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 6.9012e-04 - val_loss: 6.8727e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 6.7747e-04 - val_loss: 6.5912e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 6.7489e-04 - val_loss: 6.3323e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 6.5577e-04 - val_loss: 6.3614e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 6.5350e-04 - val_loss: 5.7460e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 6.3979e-04 - val_loss: 5.8513e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 6.3433e-04 - val_loss: 6.0281e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 6.1516e-04 - val_loss: 5.3501e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 5.8823e-04 - val_loss: 5.1504e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 5.7434e-04 - val_loss: 4.8670e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 5.7217e-04 - val_loss: 4.7531e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 5.6067e-04 - val_loss: 4.9973e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 5.3240e-04 - val_loss: 5.0150e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 5.1936e-04 - val_loss: 4.8300e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 758us/step - loss: 0.0352 - val_loss: 0.0046\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 9.8968e-04 - val_loss: 5.9239e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 7.8279e-04 - val_loss: 7.2531e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 6.8670e-04 - val_loss: 9.1130e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.7246e-04 - val_loss: 5.9517e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 6.4240e-04 - val_loss: 6.0039e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.2889e-04 - val_loss: 6.2363e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.1901e-04 - val_loss: 6.4937e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 6.1292e-04 - val_loss: 5.6595e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 6.0205e-04 - val_loss: 5.2382e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 5.9868e-04 - val_loss: 6.0316e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 5.8618e-04 - val_loss: 5.7486e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 5.7570e-04 - val_loss: 5.9173e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 5.6715e-04 - val_loss: 5.0389e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 5.5186e-04 - val_loss: 4.6854e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 5.5814e-04 - val_loss: 4.6447e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 5.6734e-04 - val_loss: 4.7902e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 5.5264e-04 - val_loss: 4.5827e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 5.3483e-04 - val_loss: 4.6167e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 5.2468e-04 - val_loss: 4.7139e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 5.1476e-04 - val_loss: 4.8427e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 5.0879e-04 - val_loss: 4.5206e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 774us/step - loss: 0.0749 - val_loss: 0.0075\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0071 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0015 - val_loss: 8.7069e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 9.4664e-04 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 7.7080e-04 - val_loss: 5.6305e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 7.0955e-04 - val_loss: 8.4091e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 6.8039e-04 - val_loss: 6.0852e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 6.6821e-04 - val_loss: 6.5701e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 6.5720e-04 - val_loss: 6.4439e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 6.5484e-04 - val_loss: 5.9442e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.4956e-04 - val_loss: 6.6178e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.3985e-04 - val_loss: 6.0402e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 6.3366e-04 - val_loss: 6.3641e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 6.3273e-04 - val_loss: 6.2066e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 6.3226e-04 - val_loss: 5.6182e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 6.1753e-04 - val_loss: 5.9530e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 6.1317e-04 - val_loss: 6.3017e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 6.0794e-04 - val_loss: 6.2670e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 6.0321e-04 - val_loss: 5.2780e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 5.9650e-04 - val_loss: 5.6497e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 5.8967e-04 - val_loss: 5.0244e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 5.9017e-04 - val_loss: 5.8543e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 5.8330e-04 - val_loss: 5.4933e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 733us/step - loss: 0.0939 - val_loss: 0.0295\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0262 - val_loss: 0.0090\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0199 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0168 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0145 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0123 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0105 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0095 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0080 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0070 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0065 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0060 - val_loss: 9.9422e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0056 - val_loss: 8.2429e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0053 - val_loss: 8.0395e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0050 - val_loss: 8.0055e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0047 - val_loss: 8.3378e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0045 - val_loss: 8.0748e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0045 - val_loss: 8.8580e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0043 - val_loss: 8.4247e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0042 - val_loss: 8.4208e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0040 - val_loss: 8.7200e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0039 - val_loss: 8.3831e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0039 - val_loss: 8.9759e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0037 - val_loss: 9.4287e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 772us/step - loss: 0.0572 - val_loss: 0.0088\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0217 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0144 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0096 - val_loss: 9.2247e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0077 - val_loss: 8.2225e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0062 - val_loss: 7.7442e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0062 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0055 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0051 - val_loss: 9.6501e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0052 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0050 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0045 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0039 - val_loss: 9.6880e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 3s 791us/step - loss: 0.9112 - val_loss: 0.0127\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0118 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0028 - val_loss: 0.0054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0045 - val_loss: 9.5024e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0016 - val_loss: 8.3303e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0017 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0017 - val_loss: 8.7241e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0015 - val_loss: 8.2672e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0014 - val_loss: 8.8621e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0015 - val_loss: 8.0295e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0014 - val_loss: 8.0494e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0013 - val_loss: 7.9274e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0014 - val_loss: 7.8772e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0013 - val_loss: 9.5339e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0013 - val_loss: 9.7418e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0013 - val_loss: 7.6230e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0013 - val_loss: 8.2844e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0013 - val_loss: 8.3731e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 913us/step - loss: 1.1852 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0126 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0018 - val_loss: 9.1602e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0016 - val_loss: 8.6614e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0015 - val_loss: 8.4358e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0016 - val_loss: 9.6966e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0015 - val_loss: 8.5557e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0015 - val_loss: 0.0027\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 940us/step - loss: 0.1923 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0057 - val_loss: 0.0186\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0065 - val_loss: 0.0301\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0120 - val_loss: 0.0071\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0153 - val_loss: 0.0122\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0109 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0136 - val_loss: 0.0079\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0191 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0061 - val_loss: 0.0197\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0089 - val_loss: 0.0206\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0159 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0015 - val_loss: 0.0305\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0144 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0016 - val_loss: 0.0381\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0119 - val_loss: 8.0503e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0052 - val_loss: 0.0158\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0107 - val_loss: 6.5074e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0024 - val_loss: 0.0120\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0064 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0057 - val_loss: 0.0230\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0064 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0040 - val_loss: 0.0104\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0050 - val_loss: 8.7752e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0054 - val_loss: 0.0188\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 959us/step - loss: 0.1007 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0143 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0036 - val_loss: 0.0360\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0115 - val_loss: 0.0233\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 0.0126 - val_loss: 0.0320\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0098 - val_loss: 0.0081\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0133 - val_loss: 0.0162\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0070 - val_loss: 0.0167\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0090 - val_loss: 0.0141\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0091 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0047 - val_loss: 0.0331\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0112 - val_loss: 8.0342e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0042 - val_loss: 0.0300\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0072 - val_loss: 5.1002e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 0.0051 - val_loss: 0.0204\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 0.0048 - val_loss: 7.4507e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0068 - val_loss: 0.0177\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0032 - val_loss: 9.3620e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0066 - val_loss: 0.0100\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0060 - val_loss: 0.0228\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0045 - val_loss: 0.0160\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 876us/step - loss: 0.0780 - val_loss: 0.0089\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0077 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 8.2710e-04 - val_loss: 5.5145e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 7.5617e-04 - val_loss: 9.3207e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 7.1931e-04 - val_loss: 6.2929e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 6.9425e-04 - val_loss: 6.6793e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.8815e-04 - val_loss: 6.6039e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.8078e-04 - val_loss: 6.8871e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.7848e-04 - val_loss: 6.0625e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.7315e-04 - val_loss: 6.7520e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 6.6969e-04 - val_loss: 6.2237e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.6435e-04 - val_loss: 7.1933e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.7818e-04 - val_loss: 5.4122e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.6577e-04 - val_loss: 6.6642e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.5109e-04 - val_loss: 6.0898e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 6.4232e-04 - val_loss: 5.9917e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.3796e-04 - val_loss: 6.0210e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.3279e-04 - val_loss: 5.5455e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 6.3292e-04 - val_loss: 6.3992e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.2584e-04 - val_loss: 6.0288e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.2001e-04 - val_loss: 5.3408e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 903us/step - loss: 0.0836 - val_loss: 0.0209\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0078 - val_loss: 6.8354e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0035 - val_loss: 6.2901e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0016 - val_loss: 6.0497e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 9.6616e-04 - val_loss: 8.7803e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 7.7825e-04 - val_loss: 5.7821e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 7.3586e-04 - val_loss: 8.0922e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.9932e-04 - val_loss: 6.2361e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 6.8844e-04 - val_loss: 6.3342e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 6.7824e-04 - val_loss: 7.0846e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 6.7786e-04 - val_loss: 5.6142e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 6.6946e-04 - val_loss: 7.0464e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.5389e-04 - val_loss: 5.7108e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.4463e-04 - val_loss: 5.9056e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.4436e-04 - val_loss: 5.3609e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.3624e-04 - val_loss: 5.7160e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 6.2452e-04 - val_loss: 5.7067e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.1897e-04 - val_loss: 5.2698e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.1687e-04 - val_loss: 5.4486e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.0528e-04 - val_loss: 5.4223e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 5.9519e-04 - val_loss: 5.2767e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 5.8784e-04 - val_loss: 5.3739e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 5.8043e-04 - val_loss: 5.5451e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 5.8092e-04 - val_loss: 6.1216e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 951us/step - loss: 0.0974 - val_loss: 0.0354\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 0.0147 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0020 - val_loss: 9.8991e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 9.6858e-04 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 8.5939e-04 - val_loss: 7.7923e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 8.1680e-04 - val_loss: 7.7154e-04\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 477us/step - loss: 7.9977e-04 - val_loss: 9.5113e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 7.6807e-04 - val_loss: 8.5873e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 7.4159e-04 - val_loss: 6.9773e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 7.2481e-04 - val_loss: 7.2135e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 7.0303e-04 - val_loss: 6.7617e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.6636e-04 - val_loss: 6.4693e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 6.4058e-04 - val_loss: 6.2092e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.2111e-04 - val_loss: 6.5227e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 6.0276e-04 - val_loss: 5.9101e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 5.8511e-04 - val_loss: 5.3619e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 5.7403e-04 - val_loss: 7.7151e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 6.0273e-04 - val_loss: 5.1597e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 5.5113e-04 - val_loss: 5.7243e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 5.4433e-04 - val_loss: 5.0613e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 5.2966e-04 - val_loss: 5.5675e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 5.7697e-04 - val_loss: 5.3592e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 987us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: nan - val_loss: nan\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 964us/step - loss: 0.3526 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0017 - val_loss: 7.0571e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0090 - val_loss: 0.0388\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0083 - val_loss: 7.0020e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0021 - val_loss: 0.0077\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0121 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0037 - val_loss: 0.0097\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0121 - val_loss: 0.0088\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0076 - val_loss: 0.0101\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0078 - val_loss: 0.0264\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0162 - val_loss: 0.0159\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0106 - val_loss: 7.0439e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 0.0025 - val_loss: 0.0144\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0217 - val_loss: 0.1804\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.1224 - val_loss: 0.1628\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0200 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 9.7902e-04 - val_loss: 5.8961e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 9.8649e-04 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 7.9548e-04 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 8.5045e-04 - val_loss: 9.0587e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0061 - val_loss: 0.0225\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0044 - val_loss: 5.5784e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0011 - val_loss: 0.0052\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 982us/step - loss: 1.4609 - val_loss: 9.4959e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 8.1867e-04 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 7.9801e-04 - val_loss: 4.8320e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 8.6032e-04 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0064 - val_loss: 0.0777\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0570 - val_loss: 0.0075\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0010 - val_loss: 6.2892e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0148 - val_loss: 0.0883\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0422 - val_loss: 0.0092\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 7.0231e-04 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0011 - val_loss: 0.0169\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.1817 - val_loss: 0.2768\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.1141 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 8.4456e-04 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 7.9184e-04 - val_loss: 5.6884e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0011 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0057 - val_loss: 0.0109\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0036 - val_loss: 0.0072\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 989us/step - loss: 0.0864 - val_loss: 8.7506e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0012 - val_loss: 6.6638e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0028 - val_loss: 0.0162\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0086 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0031 - val_loss: 0.0088\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0063 - val_loss: 0.0067\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0056 - val_loss: 0.0135\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0073 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0044 - val_loss: 0.0111\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0071 - val_loss: 0.0085\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0067 - val_loss: 0.0137\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0054 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0037 - val_loss: 0.0098\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0055 - val_loss: 0.0117\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0036 - val_loss: 0.0072\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0049 - val_loss: 0.0135\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0052 - val_loss: 0.0047\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0042 - val_loss: 0.0091\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 1ms/step - loss: 0.3245 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0011 - val_loss: 9.2273e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 9.2219e-04 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 8.3166e-04 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 8.0961e-04 - val_loss: 9.2564e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 9.5623e-04 - val_loss: 0.0060\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0156 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0011 - val_loss: 5.5350e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 9.1530e-04 - val_loss: 0.0059\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0298 - val_loss: 0.0450\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0090 - val_loss: 8.6067e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 8.5907e-04 - val_loss: 5.7021e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0012 - val_loss: 0.0088\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0092 - val_loss: 0.0191\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0101 - val_loss: 0.0136\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0034 - val_loss: 6.7889e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0013 - val_loss: 0.0065\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0119 - val_loss: 0.0442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0360 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 8.8760e-04 - val_loss: 9.3758e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 6.6164e-04 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 6.3712e-04 - val_loss: 8.7493e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 6.3741e-04 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0026 - val_loss: 0.0105\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 4s 1ms/step - loss: 0.0759 - val_loss: 0.0225\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0082 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0035 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0011 - val_loss: 5.9335e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 9.2935e-04 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 8.6127e-04 - val_loss: 6.9152e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 8.1779e-04 - val_loss: 8.7490e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 7.9553e-04 - val_loss: 7.6484e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 7.8214e-04 - val_loss: 7.8078e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 7.7290e-04 - val_loss: 7.5202e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 7.6379e-04 - val_loss: 7.0560e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 7.5867e-04 - val_loss: 7.9357e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 7.5648e-04 - val_loss: 6.8080e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 7.4490e-04 - val_loss: 7.3979e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 7.3388e-04 - val_loss: 7.0163e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 7.3008e-04 - val_loss: 6.8061e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 7.2136e-04 - val_loss: 7.2034e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 7.1368e-04 - val_loss: 6.5330e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 7.0198e-04 - val_loss: 6.7681e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.9002e-04 - val_loss: 6.7253e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 6.8455e-04 - val_loss: 5.5402e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.8220e-04 - val_loss: 6.5827e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 6.6369e-04 - val_loss: 6.6814e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.0584 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0050 - val_loss: 8.6405e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0014 - val_loss: 5.7027e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 9.7019e-04 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 8.1978e-04 - val_loss: 5.9256e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 7.4278e-04 - val_loss: 8.4104e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 7.0050e-04 - val_loss: 6.2175e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 6.8552e-04 - val_loss: 7.3690e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.7320e-04 - val_loss: 6.0972e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 6.6912e-04 - val_loss: 6.6830e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 6.5724e-04 - val_loss: 6.5799e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 6.4904e-04 - val_loss: 5.9899e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.3886e-04 - val_loss: 6.2222e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 6.2952e-04 - val_loss: 6.1615e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 6.1927e-04 - val_loss: 5.4549e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 6.1094e-04 - val_loss: 6.1247e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 6.0150e-04 - val_loss: 5.8567e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 5.8992e-04 - val_loss: 5.3694e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 5.7925e-04 - val_loss: 5.3042e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 5.6853e-04 - val_loss: 4.8966e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 5.6538e-04 - val_loss: 4.7950e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 5.6552e-04 - val_loss: 5.3367e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 5.4575e-04 - val_loss: 5.3081e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.5785 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 0.0444 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0223 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 0.0116 - val_loss: 0.0069\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 0.0074 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0049 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0014 - val_loss: 8.0382e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0012 - val_loss: 8.5894e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0011 - val_loss: 6.9008e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 9.7941e-04 - val_loss: 6.7788e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 9.1334e-04 - val_loss: 6.9397e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 8.6847e-04 - val_loss: 7.1145e-04\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 474us/step - loss: 8.4270e-04 - val_loss: 7.1789e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 8.1701e-04 - val_loss: 7.3230e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 7.9994e-04 - val_loss: 7.1470e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 7.8499e-04 - val_loss: 7.0233e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 7.7271e-04 - val_loss: 7.1065e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.0864 - val_loss: 0.0391\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0540 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0294 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0232 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 0.0092 - val_loss: 0.0265\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0095 - val_loss: 0.0205\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0102 - val_loss: 0.0220\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 0.0086 - val_loss: 0.0053\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 0.0093 - val_loss: 0.0123\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0086 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0044 - val_loss: 0.0238\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0056 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0055 - val_loss: 0.0108\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0035 - val_loss: 0.0069\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 0.0056 - val_loss: 0.0220\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0042 - val_loss: 0.0068\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0041 - val_loss: 0.0190\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0045 - val_loss: 0.0094\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0034 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 0.0040 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.0571 - val_loss: 0.0126\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 369us/step - loss: 0.0285 - val_loss: 0.0051\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 373us/step - loss: 0.0111 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 369us/step - loss: 0.0114 - val_loss: 0.0118\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 373us/step - loss: 0.0073 - val_loss: 0.0103\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 371us/step - loss: 0.0062 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 377us/step - loss: 0.0073 - val_loss: 0.0153\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 370us/step - loss: 0.0049 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 374us/step - loss: 0.0061 - val_loss: 0.0113\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 372us/step - loss: 0.0038 - val_loss: 0.0048\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 372us/step - loss: 0.0055 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 371us/step - loss: 0.0038 - val_loss: 0.0115\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 373us/step - loss: 0.0048 - val_loss: 8.2589e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 376us/step - loss: 0.0036 - val_loss: 0.0097\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 373us/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 378us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 384us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 386us/step - loss: 0.0041 - val_loss: 0.0084\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 370us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 373us/step - loss: 0.0033 - val_loss: 0.0111\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 371us/step - loss: 0.0028 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 374us/step - loss: 0.0036 - val_loss: 7.9463e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 374us/step - loss: 0.0021 - val_loss: 0.0381\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 369us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.0808 - val_loss: 0.0496\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0653 - val_loss: 0.0553\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0662 - val_loss: 0.0405\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0662 - val_loss: 0.0461\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0646 - val_loss: 0.0276\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0643 - val_loss: 0.0443\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0639 - val_loss: 0.0496\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0639 - val_loss: 0.0237\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0643 - val_loss: 0.0432\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0576 - val_loss: 0.0762\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0646 - val_loss: 0.0165\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0501 - val_loss: 0.0119\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0600 - val_loss: 0.0173\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0420 - val_loss: 0.0483\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0616 - val_loss: 0.0533\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0489 - val_loss: 0.0030\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0123 - val_loss: 0.0043\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0103 - val_loss: 0.0200\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0086 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0077 - val_loss: 0.0245\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0067 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0083 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0033 - val_loss: 7.4796e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0046 - val_loss: 0.0215\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.1691 - val_loss: 0.0407\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0688 - val_loss: 0.0121\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0721 - val_loss: 0.0217\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0659 - val_loss: 0.0399\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0649 - val_loss: 0.0479\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0651 - val_loss: 0.0423\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0647 - val_loss: 0.0382\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0646 - val_loss: 0.0387\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0644 - val_loss: 0.0394\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0640 - val_loss: 0.0384\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0629 - val_loss: 0.0378\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0613 - val_loss: 0.0366\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0576 - val_loss: 0.0288\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0556 - val_loss: 0.0214\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0459 - val_loss: 0.0174\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0370 - val_loss: 0.0097\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0328 - val_loss: 0.0053\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0750 - val_loss: 0.0123\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0673 - val_loss: 0.0478\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0657 - val_loss: 0.0487\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0645 - val_loss: 0.0356\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0640 - val_loss: 0.0379\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0616 - val_loss: 0.0400\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0485 - val_loss: 0.0246\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 1ms/step - loss: 0.1110 - val_loss: 0.0179\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0716 - val_loss: 0.0203\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 0.0658 - val_loss: 0.0443\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0647 - val_loss: 0.0434\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0627 - val_loss: 0.0347\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0570 - val_loss: 0.0286\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 0.0441 - val_loss: 0.0157\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 0.0319 - val_loss: 0.0061\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0194 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 0.0130 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0082 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0059 - val_loss: 0.0046\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 590us/step - loss: 0.0036 - val_loss: 0.0070\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0041 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0030 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 587us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 587us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 24.8063 - val_loss: 0.4529\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 372us/step - loss: 0.5770 - val_loss: 0.2515\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 376us/step - loss: 0.2853 - val_loss: 0.1077\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 372us/step - loss: 0.1747 - val_loss: 0.0379\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 370us/step - loss: 0.1565 - val_loss: 0.0473\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 374us/step - loss: 0.1306 - val_loss: 0.0692\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 370us/step - loss: 0.1173 - val_loss: 0.0715\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 371us/step - loss: 0.1109 - val_loss: 0.0611\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 373us/step - loss: 0.0996 - val_loss: 0.0521\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 381us/step - loss: 0.0886 - val_loss: 0.0477\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 369us/step - loss: 0.0807 - val_loss: 0.0447\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 374us/step - loss: 0.0789 - val_loss: 0.0416\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 371us/step - loss: 0.0709 - val_loss: 0.0364\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 370us/step - loss: 0.0654 - val_loss: 0.0277\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 372us/step - loss: 0.0624 - val_loss: 0.0271\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 371us/step - loss: 0.0562 - val_loss: 0.0263\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 376us/step - loss: 0.0538 - val_loss: 0.0227\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 373us/step - loss: 0.0485 - val_loss: 0.0180\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 376us/step - loss: 0.0456 - val_loss: 0.0136\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 373us/step - loss: 0.0441 - val_loss: 0.0118\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 379us/step - loss: 0.0423 - val_loss: 0.0114\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 370us/step - loss: 0.0386 - val_loss: 0.0127\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 374us/step - loss: 0.0355 - val_loss: 0.0090\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 371us/step - loss: 0.0343 - val_loss: 0.0087\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 1.3397 - val_loss: 0.0090\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0991 - val_loss: 0.0372\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0195 - val_loss: 0.0324\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0077 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 0.0045 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0025 - val_loss: 9.0097e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0013 - val_loss: 9.7737e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0011 - val_loss: 8.9301e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 0.0010 - val_loss: 7.9658e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0010 - val_loss: 8.1283e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 9.6459e-04 - val_loss: 9.7661e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 9.5341e-04 - val_loss: 8.6479e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 9.1861e-04 - val_loss: 9.1299e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 8.8576e-04 - val_loss: 7.1795e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 8.7742e-04 - val_loss: 7.4286e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 8.5845e-04 - val_loss: 7.2494e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 5s 1ms/step - loss: 0.0792 - val_loss: 0.0110\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0074 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 0.0016 - val_loss: 9.2037e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 8.1793e-04 - val_loss: 5.5493e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 7.4121e-04 - val_loss: 8.3145e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 6.9439e-04 - val_loss: 7.4717e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 6.8835e-04 - val_loss: 6.2544e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 6.7177e-04 - val_loss: 6.5744e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 6.6226e-04 - val_loss: 7.4004e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 6.5545e-04 - val_loss: 6.4707e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 6.4215e-04 - val_loss: 5.6027e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 6.3813e-04 - val_loss: 6.1882e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 6.2640e-04 - val_loss: 5.8395e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 6.1539e-04 - val_loss: 5.8539e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 6.0551e-04 - val_loss: 5.2135e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 6.0272e-04 - val_loss: 5.7141e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 5.8920e-04 - val_loss: 5.0004e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 5.8826e-04 - val_loss: 5.4236e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 5.7307e-04 - val_loss: 5.4039e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 5.6668e-04 - val_loss: 5.4357e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 5.6047e-04 - val_loss: 5.2381e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 5.5463e-04 - val_loss: 5.1153e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 1ms/step - loss: 1.2291 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0065 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0059 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0050 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0050 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 0.0046 - val_loss: 0.0100\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 505us/step - loss: 0.0040 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0036 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0036 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 501us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 497us/step - loss: 0.0032 - val_loss: 9.7569e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 501us/step - loss: 0.0031 - val_loss: 9.4430e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 503us/step - loss: 0.0028 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 497us/step - loss: 0.0026 - val_loss: 0.0031\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 1ms/step - loss: 0.0948 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 502us/step - loss: 0.0056 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0046 - val_loss: 0.0055\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0028 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 503us/step - loss: 0.0041 - val_loss: 7.4509e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0039 - val_loss: 6.5130e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0024 - val_loss: 0.0107\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 504us/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0018 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0038 - val_loss: 0.0041\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0025 - val_loss: 5.3949e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0018 - val_loss: 0.0083\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0032 - val_loss: 6.2616e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 502us/step - loss: 0.0022 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 502us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 502us/step - loss: 0.0026 - val_loss: 0.0035\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 501us/step - loss: 0.0025 - val_loss: 5.1619e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0013 - val_loss: 4.6187e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 503us/step - loss: 0.0030 - val_loss: 0.0170\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 0.0036 - val_loss: 8.1683e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 2ms/step - loss: 0.0519 - val_loss: 0.0284\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0101 - val_loss: 7.6882e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0094 - val_loss: 0.0242\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0065 - val_loss: 8.1272e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0031 - val_loss: 0.0178\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0065 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0036 - val_loss: 0.0070\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0043 - val_loss: 7.1090e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0018 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0060 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0024 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0019 - val_loss: 6.8360e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0020 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0020 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0028 - val_loss: 8.8120e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0024 - val_loss: 0.0097\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0063 - val_loss: 4.7242e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0012 - val_loss: 5.0130e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 2ms/step - loss: 0.0838 - val_loss: 0.0052\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0060 - val_loss: 0.0110\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0041 - val_loss: 7.7288e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0017 - val_loss: 5.7315e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0011 - val_loss: 6.0740e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0019 - val_loss: 5.6578e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0027 - val_loss: 0.0073\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0039 - val_loss: 7.1761e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0028 - val_loss: 5.9150e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0022 - val_loss: 0.0047\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0014 - val_loss: 6.1275e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 9.7619e-04 - val_loss: 0.0021\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 2ms/step - loss: 0.0607 - val_loss: 0.3840\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0878 - val_loss: 0.0135\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0105 - val_loss: 8.0743e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0241 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0057 - val_loss: 0.0164\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0141 - val_loss: 0.0230\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0141 - val_loss: 0.0036\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0061 - val_loss: 0.0249\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0167 - val_loss: 0.0068\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0092 - val_loss: 0.0163\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0120 - val_loss: 0.0125\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0094 - val_loss: 0.0080\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0068 - val_loss: 0.0103\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0102 - val_loss: 0.0147\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0122 - val_loss: 0.0184\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0128 - val_loss: 0.0206\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0131 - val_loss: 0.0053\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0055 - val_loss: 0.0116\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0088 - val_loss: 0.0116\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0104 - val_loss: 0.0136\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0107 - val_loss: 0.0111\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0124 - val_loss: 0.0147\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0114 - val_loss: 0.0097\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0116 - val_loss: 0.0133\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.9595 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0092 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0074 - val_loss: 0.0047\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0097 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0059 - val_loss: 0.0102\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0077 - val_loss: 0.0100\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0087 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0037 - val_loss: 9.2058e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0066 - val_loss: 0.0180\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0092 - val_loss: 6.4754e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0039 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0035 - val_loss: 5.8182e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0030 - val_loss: 0.0066\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0088 - val_loss: 0.0076\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0049 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0040 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0053 - val_loss: 0.0120\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0080 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0023 - val_loss: 0.0041\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0041 - val_loss: 0.0068\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 6s 1ms/step - loss: 0.5903 - val_loss: 0.0083\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 389us/step - loss: 0.0110 - val_loss: 0.0077\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 380us/step - loss: 0.0058 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 382us/step - loss: 0.0089 - val_loss: 0.0052\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 380us/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 385us/step - loss: 0.0076 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 386us/step - loss: 0.0037 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 383us/step - loss: 0.0044 - val_loss: 0.0081\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 381us/step - loss: 0.0082 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 382us/step - loss: 0.0037 - val_loss: 0.0053\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 382us/step - loss: 0.0045 - val_loss: 0.0093\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 0.0067 - val_loss: 0.0037\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 381us/step - loss: 0.0030 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 386us/step - loss: 0.0051 - val_loss: 0.0118\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 0.0069 - val_loss: 0.0070\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 381us/step - loss: 0.0050 - val_loss: 0.0076\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 381us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 379us/step - loss: 0.0021 - val_loss: 8.2410e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 387us/step - loss: 0.0018 - val_loss: 7.6554e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 380us/step - loss: 0.0030 - val_loss: 0.0102\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 386us/step - loss: 0.0083 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 388us/step - loss: 0.0041 - val_loss: 0.0111\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 381us/step - loss: 0.0051 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 382us/step - loss: 0.0028 - val_loss: 0.0105\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.1186 - val_loss: 0.0235\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0164 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 0.0038 - val_loss: 0.0101\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 0.0021 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 0.0010 - val_loss: 7.4083e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 9.0038e-04 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 8.4077e-04 - val_loss: 9.0027e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 505us/step - loss: 7.9440e-04 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 7.7939e-04 - val_loss: 8.9155e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 509us/step - loss: 7.5410e-04 - val_loss: 6.4961e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 504us/step - loss: 7.4172e-04 - val_loss: 6.4796e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 6.9783e-04 - val_loss: 6.3135e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 6.7546e-04 - val_loss: 5.6611e-04\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 506us/step - loss: 6.6606e-04 - val_loss: 9.2062e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 6.7446e-04 - val_loss: 7.4573e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 7.2747e-04 - val_loss: 9.9894e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 6.8169e-04 - val_loss: 5.3461e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 6.1019e-04 - val_loss: 8.8019e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 509us/step - loss: 6.4031e-04 - val_loss: 5.4415e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 509us/step - loss: 5.8063e-04 - val_loss: 6.8925e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 504us/step - loss: 5.6726e-04 - val_loss: 5.9542e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 5.3422e-04 - val_loss: 4.8331e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 5.3218e-04 - val_loss: 5.1122e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.0808 - val_loss: 0.0270\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0087 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0035 - val_loss: 8.5293e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 0.0017 - val_loss: 6.0395e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 9.1108e-04 - val_loss: 6.4998e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 7.9802e-04 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 7.4982e-04 - val_loss: 6.9194e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 7.2666e-04 - val_loss: 8.1317e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 7.1506e-04 - val_loss: 6.7527e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 7.0520e-04 - val_loss: 7.2054e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 6.9287e-04 - val_loss: 6.9828e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 6.8209e-04 - val_loss: 6.4755e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 6.6864e-04 - val_loss: 7.1539e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 6.5510e-04 - val_loss: 6.4639e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 6.4238e-04 - val_loss: 6.6451e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 6.3087e-04 - val_loss: 6.4006e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 6.2071e-04 - val_loss: 6.6853e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 6.1427e-04 - val_loss: 6.1749e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 5.9789e-04 - val_loss: 5.4801e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 5.8566e-04 - val_loss: 5.2810e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 5.7195e-04 - val_loss: 4.8057e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 5.5861e-04 - val_loss: 4.8347e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 5.4223e-04 - val_loss: 4.8577e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.0751 - val_loss: 0.0095\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 0.0077 - val_loss: 0.0063\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0016 - val_loss: 4.8208e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 9.5332e-04 - val_loss: 6.4166e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 7.5627e-04 - val_loss: 8.7027e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 6.9008e-04 - val_loss: 5.2347e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 6.7294e-04 - val_loss: 7.5995e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 6.5532e-04 - val_loss: 5.5458e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 6.4494e-04 - val_loss: 6.2889e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 6.3882e-04 - val_loss: 5.9451e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 6.3012e-04 - val_loss: 6.0818e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 6.3002e-04 - val_loss: 5.8321e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 6.2049e-04 - val_loss: 5.8148e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 6.1379e-04 - val_loss: 5.8970e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 6.0826e-04 - val_loss: 5.6423e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 6.0491e-04 - val_loss: 5.7747e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 5.9927e-04 - val_loss: 5.5376e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 5.9489e-04 - val_loss: 5.6775e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 5.9237e-04 - val_loss: 5.4801e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 5.8698e-04 - val_loss: 5.2993e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 5.8380e-04 - val_loss: 5.6273e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 5.8032e-04 - val_loss: 5.4126e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 5.7780e-04 - val_loss: 5.2641e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.0669 - val_loss: 0.0118\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 0.0011 - val_loss: 7.7620e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 8.4740e-04 - val_loss: 5.0186e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 7.5910e-04 - val_loss: 8.8190e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 7.0214e-04 - val_loss: 5.0112e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 6.7039e-04 - val_loss: 6.9056e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 6.5418e-04 - val_loss: 5.3787e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 6.3977e-04 - val_loss: 6.1136e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 6.3411e-04 - val_loss: 5.4549e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 6.2848e-04 - val_loss: 5.7974e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 6.2408e-04 - val_loss: 5.5631e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 6.2055e-04 - val_loss: 5.2915e-04\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 480us/step - loss: 6.1494e-04 - val_loss: 5.5596e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 6.0936e-04 - val_loss: 5.1783e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 6.0602e-04 - val_loss: 5.4829e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 6.0311e-04 - val_loss: 5.1727e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 5.9820e-04 - val_loss: 5.1623e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 5.9548e-04 - val_loss: 5.3126e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 5.9169e-04 - val_loss: 5.0792e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 478us/step - loss: 5.8923e-04 - val_loss: 5.3256e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 5.8527e-04 - val_loss: 4.9808e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 5.8261e-04 - val_loss: 5.0199e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 26.5675 - val_loss: 0.0065\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 0.0138 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0116 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 0.0101 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0098 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 0.0091 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.0086 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0081 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0077 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0073 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0070 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0073 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 0.0068 - val_loss: 0.0044\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 0.0066 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0064 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 587us/step - loss: 0.0064 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 0.0059 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 0.0059 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0055 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0056 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 7.4052 - val_loss: 0.0058\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 644us/step - loss: 0.0232 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0188 - val_loss: 0.0059\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0170 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 0.0163 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0147 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 0.0144 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 649us/step - loss: 0.0132 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 651us/step - loss: 0.0130 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0126 - val_loss: 0.0055\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0124 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0127 - val_loss: 0.0045\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0117 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0107 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0110 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0112 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0112 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0102 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0100 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0097 - val_loss: 0.0042\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0098 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0091 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0089 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0091 - val_loss: 0.0035\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 7.9385 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0110 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0086 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0071 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0062 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0059 - val_loss: 7.6890e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0052 - val_loss: 9.2303e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0048 - val_loss: 8.9496e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0045 - val_loss: 7.4091e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0043 - val_loss: 7.1144e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0040 - val_loss: 6.6052e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0039 - val_loss: 6.5171e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0038 - val_loss: 7.0460e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0035 - val_loss: 8.0066e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0037 - val_loss: 6.4767e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0033 - val_loss: 6.1907e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0034 - val_loss: 6.4841e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0033 - val_loss: 6.6322e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0032 - val_loss: 6.0479e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0030 - val_loss: 6.1106e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0033 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0030 - val_loss: 6.4762e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0030 - val_loss: 6.7137e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0028 - val_loss: 6.3998e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 9.3405 - val_loss: 0.0121\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 0.0238 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0076 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0048 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0045 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0041 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 0.0037 - val_loss: 0.0040\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 0.0037 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0031 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 12.4461 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 0.0109 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0091 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 0.0081 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0076 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 0.0074 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 632us/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0065 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0062 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0059 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0057 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 0.0057 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0053 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0053 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0050 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 619us/step - loss: 0.0049 - val_loss: 8.8664e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0050 - val_loss: 9.2111e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0047 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 0.0047 - val_loss: 7.7970e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 0.0046 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 0.0044 - val_loss: 9.1773e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 0.0043 - val_loss: 8.1976e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 0.0041 - val_loss: 7.5777e-04\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 0.0536 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0058 - val_loss: 0.0088\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 0.0013 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 505us/step - loss: 0.0011 - val_loss: 4.9061e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 504us/step - loss: 7.6314e-04 - val_loss: 5.4097e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 7.4520e-04 - val_loss: 5.7978e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 505us/step - loss: 6.4448e-04 - val_loss: 7.6777e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 6.0454e-04 - val_loss: 5.9559e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 5.6753e-04 - val_loss: 5.9441e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 5.6465e-04 - val_loss: 4.7606e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 505us/step - loss: 5.3557e-04 - val_loss: 4.6337e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 505us/step - loss: 5.2502e-04 - val_loss: 4.4954e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 5.1791e-04 - val_loss: 4.3896e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 505us/step - loss: 5.0725e-04 - val_loss: 4.5717e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 505us/step - loss: 5.0090e-04 - val_loss: 4.4301e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 4.9497e-04 - val_loss: 4.6376e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 4.9327e-04 - val_loss: 4.4159e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 4.8406e-04 - val_loss: 4.6067e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 4.8941e-04 - val_loss: 4.7639e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 4.8098e-04 - val_loss: 5.3073e-04\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 483us/step - loss: 4.9297e-04 - val_loss: 4.2799e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 4.7918e-04 - val_loss: 4.1646e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 4.6571e-04 - val_loss: 4.2329e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 0.0655 - val_loss: 0.0139\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 0.0075 - val_loss: 7.6397e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 0.0038 - val_loss: 6.8847e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 0.0016 - val_loss: 5.8637e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 9.6951e-04 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 8.1201e-04 - val_loss: 5.6590e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 7.4397e-04 - val_loss: 8.6295e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 6.9660e-04 - val_loss: 6.1862e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 483us/step - loss: 6.7523e-04 - val_loss: 6.3841e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 6.6230e-04 - val_loss: 6.2987e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 6.5607e-04 - val_loss: 6.3950e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 6.4864e-04 - val_loss: 6.3472e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 482us/step - loss: 6.4270e-04 - val_loss: 5.8785e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 6.3589e-04 - val_loss: 6.1115e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 481us/step - loss: 6.2680e-04 - val_loss: 5.4181e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 6.1907e-04 - val_loss: 5.7002e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 480us/step - loss: 6.1030e-04 - val_loss: 5.2664e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 6.0308e-04 - val_loss: 5.2958e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 6.0470e-04 - val_loss: 5.3651e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 5.9746e-04 - val_loss: 5.7274e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 504us/step - loss: 5.8570e-04 - val_loss: 5.2984e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 5.8025e-04 - val_loss: 4.9644e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 502us/step - loss: 5.7865e-04 - val_loss: 5.0963e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 501us/step - loss: 5.7591e-04 - val_loss: 5.8083e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 0.0368 - val_loss: 0.0041\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0019 - val_loss: 8.3097e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 9.9007e-04 - val_loss: 4.9382e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 8.0357e-04 - val_loss: 4.8626e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 6.9664e-04 - val_loss: 4.7430e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 6.6846e-04 - val_loss: 4.6596e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 6.3332e-04 - val_loss: 4.7104e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 6.1294e-04 - val_loss: 5.2972e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 5.9770e-04 - val_loss: 5.7943e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 5.9491e-04 - val_loss: 5.9028e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 6.0076e-04 - val_loss: 5.8900e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 5.9102e-04 - val_loss: 4.8331e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 5.6452e-04 - val_loss: 4.8385e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 5.6203e-04 - val_loss: 4.8587e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 5.5606e-04 - val_loss: 4.7374e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 5.4856e-04 - val_loss: 4.6854e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 5.4282e-04 - val_loss: 4.6375e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 501us/step - loss: 5.3994e-04 - val_loss: 4.8184e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 5.3792e-04 - val_loss: 4.7265e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 5.3371e-04 - val_loss: 4.5045e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 5.2749e-04 - val_loss: 4.4634e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 5.2433e-04 - val_loss: 4.8770e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 5.4654e-04 - val_loss: 4.9910e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 5.3211e-04 - val_loss: 4.5388e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.0592 - val_loss: 0.0109\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 386us/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 399us/step - loss: 0.0019 - val_loss: 9.1980e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 378us/step - loss: 0.0014 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 378us/step - loss: 0.0011 - val_loss: 5.0923e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 374us/step - loss: 9.5739e-04 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 381us/step - loss: 8.6674e-04 - val_loss: 6.2178e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 373us/step - loss: 8.1290e-04 - val_loss: 8.9011e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 379us/step - loss: 7.7332e-04 - val_loss: 8.2327e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 374us/step - loss: 7.4497e-04 - val_loss: 7.3415e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 376us/step - loss: 7.2452e-04 - val_loss: 7.7693e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 379us/step - loss: 7.0448e-04 - val_loss: 6.8897e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 380us/step - loss: 6.8690e-04 - val_loss: 7.1104e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 382us/step - loss: 6.7131e-04 - val_loss: 6.5135e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 374us/step - loss: 6.5860e-04 - val_loss: 6.6185e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 376us/step - loss: 6.4679e-04 - val_loss: 6.4577e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 378us/step - loss: 6.3399e-04 - val_loss: 5.9339e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 380us/step - loss: 6.2369e-04 - val_loss: 6.2159e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 378us/step - loss: 6.1438e-04 - val_loss: 6.1232e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 375us/step - loss: 6.0621e-04 - val_loss: 5.7545e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 382us/step - loss: 5.9778e-04 - val_loss: 5.8554e-04\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 376us/step - loss: 5.9045e-04 - val_loss: 5.5874e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 376us/step - loss: 5.8451e-04 - val_loss: 5.1085e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 379us/step - loss: 5.7968e-04 - val_loss: 5.6032e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 7s 2ms/step - loss: 0.8711 - val_loss: 0.0265\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 1s 341us/step - loss: 0.0162 - val_loss: 0.0359\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 1s 340us/step - loss: 0.0140 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 1s 338us/step - loss: 0.0029 - val_loss: 8.8498e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 1s 338us/step - loss: 0.0022 - val_loss: 0.0106\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 1s 342us/step - loss: 0.0041 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 1s 344us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 1s 346us/step - loss: 0.0012 - val_loss: 7.6998e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 1s 338us/step - loss: 0.0010 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 1s 347us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 1s 337us/step - loss: 0.0019 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 1s 349us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 1s 342us/step - loss: 0.0014 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 1s 339us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 1s 339us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 1s 339us/step - loss: 0.0011 - val_loss: 9.6083e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 1s 338us/step - loss: 8.9187e-04 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 1s 341us/step - loss: 8.1358e-04 - val_loss: 9.4318e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 1s 342us/step - loss: 7.2248e-04 - val_loss: 7.8964e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 1s 343us/step - loss: 7.8370e-04 - val_loss: 8.7755e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 1s 337us/step - loss: 7.0537e-04 - val_loss: 6.2838e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 1s 341us/step - loss: 6.8857e-04 - val_loss: 8.5932e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 1s 348us/step - loss: 7.6941e-04 - val_loss: 5.8811e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 1s 340us/step - loss: 6.9832e-04 - val_loss: 6.4564e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 1.0508 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 1s 340us/step - loss: 0.0089 - val_loss: 8.6041e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 1s 339us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 1s 341us/step - loss: 0.0014 - val_loss: 8.8906e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 1s 341us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 1s 340us/step - loss: 0.0012 - val_loss: 7.2221e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 1s 343us/step - loss: 0.0012 - val_loss: 7.3115e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 1s 339us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 1s 350us/step - loss: 0.0010 - val_loss: 8.3269e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 1s 352us/step - loss: 9.7665e-04 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 1s 339us/step - loss: 9.2218e-04 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 1s 344us/step - loss: 8.7355e-04 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 1s 339us/step - loss: 8.3507e-04 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 1s 349us/step - loss: 7.9708e-04 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 1s 339us/step - loss: 7.6442e-04 - val_loss: 9.5953e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 1s 340us/step - loss: 7.3246e-04 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 1s 344us/step - loss: 7.3122e-04 - val_loss: 7.2777e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 1s 340us/step - loss: 6.8198e-04 - val_loss: 8.0305e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 1s 344us/step - loss: 6.5817e-04 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 1s 339us/step - loss: 6.5933e-04 - val_loss: 6.7046e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 1s 346us/step - loss: 6.2379e-04 - val_loss: 7.1471e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 1s 339us/step - loss: 6.0986e-04 - val_loss: 6.5701e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 1s 338us/step - loss: 6.0085e-04 - val_loss: 8.1461e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 1s 344us/step - loss: 6.0790e-04 - val_loss: 6.5626e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 8s 2ms/step - loss: 0.0702 - val_loss: 0.0298\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0135 - val_loss: 0.0136\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0071 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0065 - val_loss: 0.0149\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0098 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0041 - val_loss: 0.0107\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0063 - val_loss: 0.0096\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0066 - val_loss: 0.0051\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0054 - val_loss: 0.0122\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0064 - val_loss: 0.0099\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0067 - val_loss: 0.0066\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0060 - val_loss: 0.0136\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0070 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0041 - val_loss: 0.0112\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0060 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0036 - val_loss: 0.0073\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0071 - val_loss: 0.0087\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0047 - val_loss: 0.0229\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0071 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0029 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0022 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0047 - val_loss: 0.0108\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 9s 2ms/step - loss: 0.0582 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0076 - val_loss: 0.0165\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0064 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0066 - val_loss: 0.0122\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0054 - val_loss: 8.8108e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0039 - val_loss: 0.0065\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0064 - val_loss: 0.0063\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0036 - val_loss: 7.8820e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0052 - val_loss: 0.0118\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0058 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0048 - val_loss: 0.0050\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0041 - val_loss: 8.2705e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0045 - val_loss: 0.0080\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0043 - val_loss: 0.0040\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0029 - val_loss: 9.5357e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0041 - val_loss: 0.0178\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0039 - val_loss: 0.0069\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0025 - val_loss: 6.1971e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 9s 2ms/step - loss: 0.1078 - val_loss: 0.0165\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0467 - val_loss: 0.0097\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 510us/step - loss: 0.0598 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0102 - val_loss: 0.0593\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0388 - val_loss: 0.0169\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0151 - val_loss: 0.0076\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 0.0132 - val_loss: 0.0167\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0095 - val_loss: 0.0062\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0125 - val_loss: 0.0221\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0109 - val_loss: 0.0064\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0093 - val_loss: 0.0434\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0166 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0073 - val_loss: 0.0194\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0096 - val_loss: 0.0035\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0134 - val_loss: 0.0201\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0091 - val_loss: 0.0052\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0111 - val_loss: 0.0173\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 510us/step - loss: 0.0073 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0069 - val_loss: 0.0320\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0145 - val_loss: 0.0066\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0091 - val_loss: 0.0224\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0068 - val_loss: 9.6802e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0052 - val_loss: 0.0224\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0122 - val_loss: 0.0072\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 9s 2ms/step - loss: 0.0622 - val_loss: 0.0109\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0214 - val_loss: 0.0072\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0152 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0106 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0074 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0051 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 0.0036 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0026 - val_loss: 8.9701e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0020 - val_loss: 8.1239e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0016 - val_loss: 7.9153e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 0.0014 - val_loss: 7.9246e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0013 - val_loss: 8.8041e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0012 - val_loss: 9.7613e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0012 - val_loss: 8.5664e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0012 - val_loss: 9.4825e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0011 - val_loss: 9.5591e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 0.0011 - val_loss: 9.2075e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0011 - val_loss: 9.9174e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 484us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 10s 2ms/step - loss: 0.0449 - val_loss: 6.0304e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0022 - val_loss: 7.8527e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 9.8581e-04 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 7.8606e-04 - val_loss: 8.7230e-04\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 487us/step - loss: 6.3833e-04 - val_loss: 5.6010e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 6.1620e-04 - val_loss: 4.5252e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 5.8208e-04 - val_loss: 4.6505e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 5.7084e-04 - val_loss: 4.9161e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 5.6746e-04 - val_loss: 4.7311e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 5.6266e-04 - val_loss: 5.0729e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 485us/step - loss: 5.6130e-04 - val_loss: 4.5137e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 5.5608e-04 - val_loss: 4.4533e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 5.6020e-04 - val_loss: 4.7217e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 5.5476e-04 - val_loss: 4.8867e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 5.4765e-04 - val_loss: 4.5649e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 5.4361e-04 - val_loss: 4.4185e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 5.4313e-04 - val_loss: 4.4475e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 5.3812e-04 - val_loss: 4.4090e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 5.3834e-04 - val_loss: 4.5880e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 5.3075e-04 - val_loss: 4.3951e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 5.2724e-04 - val_loss: 4.3648e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 5.3881e-04 - val_loss: 4.7441e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 5.2518e-04 - val_loss: 4.6144e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 5.2563e-04 - val_loss: 4.4824e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 10s 2ms/step - loss: 0.0497 - val_loss: 0.0078\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0055 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0039 - val_loss: 0.0219\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0076 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0046 - val_loss: 0.0072\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0048 - val_loss: 0.0099\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0030 - val_loss: 0.0069\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0034 - val_loss: 0.0035\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0037 - val_loss: 0.0042\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 0.0033 - val_loss: 0.0079\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0046 - val_loss: 0.0070\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0042 - val_loss: 0.0074\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0033 - val_loss: 0.0088\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0010 - val_loss: 5.9414e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0021 - val_loss: 0.0059\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0049 - val_loss: 0.0100\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0033 - val_loss: 0.0097\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 9s 2ms/step - loss: 0.0518 - val_loss: 0.0108\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0056 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0029 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0075 - val_loss: 0.0120\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 486us/step - loss: 0.0051 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0041 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0025 - val_loss: 0.0161\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0067 - val_loss: 0.0030\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0027 - val_loss: 0.0044\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0029 - val_loss: 0.0087\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0047 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0020 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0037 - val_loss: 0.0166\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0060 - val_loss: 0.0046\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0026 - val_loss: 0.0086\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0036 - val_loss: 0.0054\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0014 - val_loss: 0.0058\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 10s 2ms/step - loss: 0.0439 - val_loss: 0.0147\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0049 - val_loss: 0.0126\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0064 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0024 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0024 - val_loss: 0.0048\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0052 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0037 - val_loss: 0.0076\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0049 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0016 - val_loss: 0.0086\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0042 - val_loss: 0.0104\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0054 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0019 - val_loss: 0.0058\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0038 - val_loss: 0.0121\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 492us/step - loss: 0.0053 - val_loss: 0.0070\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0015 - val_loss: 0.0055\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0020 - val_loss: 0.0126\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 8.9349e-04 - val_loss: 5.2378e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0010 - val_loss: 0.0032\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 11s 3ms/step - loss: 0.0398 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0089 - val_loss: 0.0149\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0076 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0054 - val_loss: 0.0077\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0032 - val_loss: 0.0088\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0080 - val_loss: 0.0123\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0061 - val_loss: 0.0070\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0066 - val_loss: 0.0046\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0032 - val_loss: 0.0062\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0076 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0011 - val_loss: 5.4534e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0017 - val_loss: 0.0207\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0112 - val_loss: 0.0067\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0066 - val_loss: 0.0104\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0064 - val_loss: 0.0128\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0057 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0029 - val_loss: 0.0063\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0056 - val_loss: 0.0135\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0060 - val_loss: 0.0093\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0041 - val_loss: 0.0112\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0057 - val_loss: 0.0049\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 11s 3ms/step - loss: 0.0556 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0027 - val_loss: 0.0067\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0053 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0082 - val_loss: 0.0179\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0075 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0033 - val_loss: 0.0064\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0078 - val_loss: 0.0263\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0070 - val_loss: 0.0146\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0086 - val_loss: 0.0057\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0068 - val_loss: 0.0118\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0067 - val_loss: 0.0070\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0052 - val_loss: 0.0093\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0067 - val_loss: 0.0103\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0052 - val_loss: 0.0080\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0055 - val_loss: 0.0092\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0050 - val_loss: 0.0054\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0048 - val_loss: 0.0062\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0055 - val_loss: 0.0075\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0060 - val_loss: 0.0121\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0060 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0044 - val_loss: 0.0134\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0052 - val_loss: 0.0055\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 11s 3ms/step - loss: 0.1312 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0030 - val_loss: 7.2109e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0026 - val_loss: 7.0768e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0025 - val_loss: 6.9725e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0123 - val_loss: 0.0068\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0071 - val_loss: 0.0169\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0091 - val_loss: 0.0073\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0096 - val_loss: 0.0045\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0042 - val_loss: 0.0127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0116 - val_loss: 0.0139\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0096 - val_loss: 0.0090\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0073 - val_loss: 0.0060\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0067 - val_loss: 0.0059\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0063 - val_loss: 0.0100\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0095 - val_loss: 0.0181\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0084 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0052 - val_loss: 0.0185\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0085 - val_loss: 0.0101\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0074 - val_loss: 0.0093\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0069 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 12s 3ms/step - loss: 1.1513 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0029 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0027 - val_loss: 8.5213e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0025 - val_loss: 8.4017e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0025 - val_loss: 0.0053\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0025 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 6.7927e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0016 - val_loss: 7.2761e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0017 - val_loss: 6.6911e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 11s 3ms/step - loss: 0.0578 - val_loss: 7.7840e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0075 - val_loss: 0.0071\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0035 - val_loss: 5.0712e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0017 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 8.4958e-04 - val_loss: 4.6316e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 7.4174e-04 - val_loss: 5.5702e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 6.6803e-04 - val_loss: 6.8374e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 6.1127e-04 - val_loss: 6.4275e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 5.7842e-04 - val_loss: 6.3034e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 5.5712e-04 - val_loss: 6.8437e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 5.4046e-04 - val_loss: 5.3496e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 5.1231e-04 - val_loss: 4.7127e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 5.0068e-04 - val_loss: 4.1282e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 5.0071e-04 - val_loss: 4.1353e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 4.8646e-04 - val_loss: 4.4883e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 4.7554e-04 - val_loss: 4.5081e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 4.7012e-04 - val_loss: 4.2420e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 4.5817e-04 - val_loss: 4.0046e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 4.5669e-04 - val_loss: 4.4366e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 4.5762e-04 - val_loss: 4.5975e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 4.8222e-04 - val_loss: 4.1081e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 4.5882e-04 - val_loss: 4.0847e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 4.4550e-04 - val_loss: 3.9379e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 12s 3ms/step - loss: 0.0717 - val_loss: 9.9213e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0083 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0044 - val_loss: 6.0285e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0010 - val_loss: 5.3790e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 8.4089e-04 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 7.9071e-04 - val_loss: 6.0461e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 7.6031e-04 - val_loss: 8.8483e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 7.3417e-04 - val_loss: 7.1480e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 7.1853e-04 - val_loss: 7.5101e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 7.0990e-04 - val_loss: 7.0854e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 7.0251e-04 - val_loss: 6.9597e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 6.9259e-04 - val_loss: 7.1047e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 6.8656e-04 - val_loss: 6.7830e-04\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 509us/step - loss: 6.7812e-04 - val_loss: 7.0204e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 6.7182e-04 - val_loss: 6.6213e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 6.6550e-04 - val_loss: 6.7654e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 6.5927e-04 - val_loss: 6.3232e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 510us/step - loss: 6.5310e-04 - val_loss: 6.3146e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 6.4679e-04 - val_loss: 6.2557e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 6.4140e-04 - val_loss: 6.2006e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 6.3651e-04 - val_loss: 6.1444e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 6.3240e-04 - val_loss: 6.0228e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 6.2670e-04 - val_loss: 5.9464e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 12s 3ms/step - loss: 0.0623 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0065 - val_loss: 5.8788e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0036 - val_loss: 9.4139e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0017 - val_loss: 4.8497e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0014 - val_loss: 5.7154e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0014 - val_loss: 7.2277e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0014 - val_loss: 7.0853e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0014 - val_loss: 5.6952e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0014 - val_loss: 6.3910e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0013 - val_loss: 6.4375e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0013 - val_loss: 5.7975e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0013 - val_loss: 6.6302e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0013 - val_loss: 5.4839e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 6.6281e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 5.9605e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 6.1777e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 5.7753e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0012 - val_loss: 5.3778e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0011 - val_loss: 5.2002e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0012 - val_loss: 5.5953e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 5.0879e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0011 - val_loss: 5.8228e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 12s 3ms/step - loss: 0.0674 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0072 - val_loss: 6.5233e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0039 - val_loss: 8.3503e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0017 - val_loss: 5.3685e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0015 - val_loss: 6.5795e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 7.9344e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0014 - val_loss: 8.4297e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0014 - val_loss: 7.4603e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0013 - val_loss: 6.8205e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0013 - val_loss: 7.5919e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0013 - val_loss: 6.8040e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0013 - val_loss: 6.7448e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0012 - val_loss: 7.1974e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0012 - val_loss: 5.8186e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0012 - val_loss: 6.5283e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0012 - val_loss: 6.4475e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0012 - val_loss: 6.6293e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0012 - val_loss: 5.7918e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0011 - val_loss: 6.4466e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0012 - val_loss: 6.1740e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0011 - val_loss: 5.6988e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0011 - val_loss: 5.9966e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 12s 3ms/step - loss: 0.0427 - val_loss: 0.0127\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0050 - val_loss: 6.5235e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0023 - val_loss: 5.8588e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0017 - val_loss: 5.7366e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0014 - val_loss: 9.9976e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0013 - val_loss: 7.7904e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0014 - val_loss: 7.2930e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0013 - val_loss: 7.6865e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0012 - val_loss: 7.5223e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 6.3730e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0012 - val_loss: 6.1545e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0012 - val_loss: 6.4733e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0012 - val_loss: 6.5838e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0011 - val_loss: 5.7179e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0011 - val_loss: 6.3657e-04\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0011 - val_loss: 6.2858e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0011 - val_loss: 5.4323e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0011 - val_loss: 5.3020e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0011 - val_loss: 5.3261e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0010 - val_loss: 5.5286e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 9.9540e-04 - val_loss: 5.7858e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0010 - val_loss: 4.9648e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 9.8627e-04 - val_loss: 5.7820e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 13s 3ms/step - loss: 0.0541 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0072 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0021 - val_loss: 6.2879e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 8.6650e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0014 - val_loss: 8.9455e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0013 - val_loss: 7.8305e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0014 - val_loss: 7.4422e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0012 - val_loss: 7.7690e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0013 - val_loss: 7.9585e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0012 - val_loss: 7.4319e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0011 - val_loss: 6.3815e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0012 - val_loss: 8.4098e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0012 - val_loss: 6.0425e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0011 - val_loss: 6.9472e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0011 - val_loss: 5.8978e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0011 - val_loss: 6.2247e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0010 - val_loss: 5.8049e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0010 - val_loss: 6.0485e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0010 - val_loss: 5.3772e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0011 - val_loss: 5.8066e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0010 - val_loss: 5.3863e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 9.7750e-04 - val_loss: 5.0518e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 12s 3ms/step - loss: 0.0888 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0077 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0018 - val_loss: 5.8109e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0016 - val_loss: 9.4655e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0015 - val_loss: 9.5425e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0014 - val_loss: 9.4537e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0015 - val_loss: 9.8170e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0013 - val_loss: 7.6324e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0013 - val_loss: 9.0944e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0013 - val_loss: 8.9404e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0013 - val_loss: 7.1651e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0012 - val_loss: 8.2492e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 8.1331e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0012 - val_loss: 7.7063e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0012 - val_loss: 7.0292e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 7.8895e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 6.8516e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0011 - val_loss: 6.9452e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0011 - val_loss: 7.0876e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 13s 3ms/step - loss: 0.0699 - val_loss: 0.0253\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0100 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0013 - val_loss: 5.4959e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0011 - val_loss: 5.6690e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 9.5098e-04 - val_loss: 6.4503e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 9.2148e-04 - val_loss: 7.1667e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 8.8696e-04 - val_loss: 6.7842e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 8.6714e-04 - val_loss: 6.8916e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 8.5512e-04 - val_loss: 7.0257e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 8.3286e-04 - val_loss: 6.6902e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 7.9359e-04 - val_loss: 5.6481e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 7.8654e-04 - val_loss: 5.4007e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 7.9103e-04 - val_loss: 6.5600e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 7.7549e-04 - val_loss: 5.1055e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 7.5426e-04 - val_loss: 0.0011\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 536us/step - loss: 8.0968e-04 - val_loss: 7.6726e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 7.5517e-04 - val_loss: 4.8016e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 8.1996e-04 - val_loss: 7.8385e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 7.5934e-04 - val_loss: 6.7908e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 7.4717e-04 - val_loss: 4.7301e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 7.4436e-04 - val_loss: 5.2780e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 13s 3ms/step - loss: 0.0512 - val_loss: 0.0483\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0115 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0102 - val_loss: 0.0114\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0082 - val_loss: 0.0085\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0061 - val_loss: 0.0107\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0083 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0049 - val_loss: 0.0093\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0080 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0027 - val_loss: 0.0117\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0086 - val_loss: 7.0913e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0017 - val_loss: 0.0400\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0068 - val_loss: 5.7987e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0041 - val_loss: 0.0168\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0044 - val_loss: 8.3277e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 536us/step - loss: 0.0036 - val_loss: 0.0123\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0042 - val_loss: 6.3748e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0030 - val_loss: 0.0208\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0047 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0012 - val_loss: 0.0086\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0027 - val_loss: 5.3337e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0033 - val_loss: 0.0083\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0027 - val_loss: 5.0466e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0022 - val_loss: 0.0075\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 13s 3ms/step - loss: 0.0479 - val_loss: 0.0366\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0156 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0039 - val_loss: 0.0238\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0109 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0024 - val_loss: 0.0138\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0044 - val_loss: 0.0150\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0039 - val_loss: 0.0089\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0018 - val_loss: 9.5256e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0042 - val_loss: 0.0181\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0041 - val_loss: 5.3292e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0015 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0034 - val_loss: 0.0061\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0022 - val_loss: 4.7910e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0017 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0026 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0013 - val_loss: 4.5277e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0018 - val_loss: 0.0152\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 14s 3ms/step - loss: 0.0519 - val_loss: 0.0132\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0061 - val_loss: 8.8929e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0022 - val_loss: 8.6049e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0015 - val_loss: 5.5769e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0011 - val_loss: 7.9894e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 8.5827e-04 - val_loss: 9.6163e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 7.5315e-04 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 7.0130e-04 - val_loss: 8.8865e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 6.4837e-04 - val_loss: 7.6411e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 6.0070e-04 - val_loss: 6.6658e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 5.7144e-04 - val_loss: 5.2340e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 5.4687e-04 - val_loss: 4.7770e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 5.2910e-04 - val_loss: 5.6395e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 5.4047e-04 - val_loss: 5.5522e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 5.1444e-04 - val_loss: 4.4234e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 5.1730e-04 - val_loss: 4.4340e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 4.9958e-04 - val_loss: 4.5543e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 4.9422e-04 - val_loss: 4.4513e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 4.9067e-04 - val_loss: 4.7776e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 5.2334e-04 - val_loss: 4.8226e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 4.8424e-04 - val_loss: 4.1640e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 4.6980e-04 - val_loss: 4.6185e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 4.6141e-04 - val_loss: 4.2564e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 4.6337e-04 - val_loss: 5.1440e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 14s 3ms/step - loss: 0.0598 - val_loss: 0.0213\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 0.0083 - val_loss: 0.0090\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 641us/step - loss: 0.0040 - val_loss: 5.9102e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 0.0022 - val_loss: 8.6207e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 637us/step - loss: 0.0012 - val_loss: 7.1041e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 642us/step - loss: 0.0010 - val_loss: 6.5147e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 640us/step - loss: 0.0010 - val_loss: 5.2091e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 639us/step - loss: 9.1448e-04 - val_loss: 4.7622e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 9.0943e-04 - val_loss: 8.6461e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 9.0300e-04 - val_loss: 6.2471e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 8.5357e-04 - val_loss: 4.8798e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 645us/step - loss: 8.8019e-04 - val_loss: 4.4306e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 7.9937e-04 - val_loss: 5.9962e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 630us/step - loss: 8.0784e-04 - val_loss: 4.2002e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 8.1034e-04 - val_loss: 4.2071e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.4918e-04 - val_loss: 5.2933e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.5536e-04 - val_loss: 4.2142e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 643us/step - loss: 7.1765e-04 - val_loss: 5.4315e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 634us/step - loss: 7.3832e-04 - val_loss: 4.2242e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 638us/step - loss: 7.3899e-04 - val_loss: 4.3143e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 7.4253e-04 - val_loss: 9.9257e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 14s 3ms/step - loss: 0.0666 - val_loss: 8.2982e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0099 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0046 - val_loss: 6.4642e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0025 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0014 - val_loss: 5.0053e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0012 - val_loss: 7.7775e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0011 - val_loss: 7.9377e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0011 - val_loss: 7.1351e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0011 - val_loss: 6.2608e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 9.9140e-04 - val_loss: 6.8875e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 9.6685e-04 - val_loss: 5.5277e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 9.2486e-04 - val_loss: 6.1207e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 9.1177e-04 - val_loss: 4.7237e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 9.1924e-04 - val_loss: 4.9221e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 8.3018e-04 - val_loss: 4.4703e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 8.4339e-04 - val_loss: 4.5509e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 8.3924e-04 - val_loss: 4.7044e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 7.9302e-04 - val_loss: 4.3401e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 8.4441e-04 - val_loss: 4.3832e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 7.8352e-04 - val_loss: 4.4518e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 7.9367e-04 - val_loss: 4.6060e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 7.9347e-04 - val_loss: 4.2227e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 7.6430e-04 - val_loss: 4.4973e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 15s 4ms/step - loss: 0.0407 - val_loss: 0.0184\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0067 - val_loss: 0.0097\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0034 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0019 - val_loss: 5.9302e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0014 - val_loss: 5.0772e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0013 - val_loss: 6.8528e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0011 - val_loss: 6.9010e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0010 - val_loss: 5.4640e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0010 - val_loss: 5.5729e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 9.5657e-04 - val_loss: 4.7167e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 9.1894e-04 - val_loss: 4.8013e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 8.9784e-04 - val_loss: 6.4630e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 8.6412e-04 - val_loss: 6.1788e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 8.8158e-04 - val_loss: 5.7575e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 8.2415e-04 - val_loss: 6.3253e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 8.5676e-04 - val_loss: 4.4143e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 8.2024e-04 - val_loss: 5.5019e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 8.2382e-04 - val_loss: 4.6656e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 8.0352e-04 - val_loss: 4.6029e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 8.0050e-04 - val_loss: 8.7008e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 8.5486e-04 - val_loss: 4.1813e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 7.6937e-04 - val_loss: 5.1123e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 7.2878e-04 - val_loss: 4.4580e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 7.7331e-04 - val_loss: 4.4691e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 15s 4ms/step - loss: 0.0726 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0093 - val_loss: 0.0091\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0044 - val_loss: 7.0945e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0025 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0020 - val_loss: 8.4359e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0015 - val_loss: 5.3767e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0015 - val_loss: 5.7545e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0011 - val_loss: 9.6951e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0010 - val_loss: 6.3699e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 9.7459e-04 - val_loss: 5.8674e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 9.5870e-04 - val_loss: 7.0391e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 9.3923e-04 - val_loss: 5.1185e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 9.6278e-04 - val_loss: 4.8706e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 9.3291e-04 - val_loss: 4.6742e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 8.5392e-04 - val_loss: 5.8967e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 8.8981e-04 - val_loss: 8.0428e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 9.3920e-04 - val_loss: 4.5012e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 9.6152e-04 - val_loss: 6.2531e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 9.1697e-04 - val_loss: 6.6853e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 8.7122e-04 - val_loss: 5.3348e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 8.2273e-04 - val_loss: 4.7740e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 8.2828e-04 - val_loss: 6.1537e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 15s 4ms/step - loss: 0.7436 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0092 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0039 - val_loss: 6.8189e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0024 - val_loss: 5.4696e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0020 - val_loss: 7.4572e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0020 - val_loss: 8.2509e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0020 - val_loss: 6.6240e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0018 - val_loss: 5.1807e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0019 - val_loss: 7.9226e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0018 - val_loss: 5.8346e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0017 - val_loss: 8.7094e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0017 - val_loss: 9.4153e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0017 - val_loss: 6.4514e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0017 - val_loss: 5.0593e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0017 - val_loss: 5.5678e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0016 - val_loss: 6.8682e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0016 - val_loss: 5.0617e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0016 - val_loss: 5.3420e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0015 - val_loss: 5.1276e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0016 - val_loss: 7.5871e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0015 - val_loss: 5.8123e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0015 - val_loss: 7.3177e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0015 - val_loss: 6.5759e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 15s 4ms/step - loss: 2.8644 - val_loss: 0.0511\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0597 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0362 - val_loss: 0.0145\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0222 - val_loss: 0.0077\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0065 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0091 - val_loss: 0.0217\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0080 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 0.0086 - val_loss: 0.0035\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0030 - val_loss: 0.0065\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0037 - val_loss: 0.0115\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0024 - val_loss: 9.0528e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0027 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0026 - val_loss: 9.6113e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0023 - val_loss: 9.1612e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 15s 4ms/step - loss: 5.5708 - val_loss: 0.0313\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0542 - val_loss: 0.0112\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0406 - val_loss: 0.0069\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0136 - val_loss: 0.0163\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0217 - val_loss: 0.0069\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0049 - val_loss: 0.0031\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0042 - val_loss: 0.0141\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0055 - val_loss: 0.0098\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0039 - val_loss: 0.0140\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0050 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0055 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0026 - val_loss: 9.8574e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 0.0025 - val_loss: 9.3949e-04\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 15s 4ms/step - loss: 0.0452 - val_loss: 0.0213\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0079 - val_loss: 8.0380e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0018 - val_loss: 6.3932e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 8.8185e-04 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 8.0332e-04 - val_loss: 6.5909e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 6.9907e-04 - val_loss: 4.9381e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 6.6932e-04 - val_loss: 4.9569e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 6.4199e-04 - val_loss: 5.5426e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 5.8824e-04 - val_loss: 6.1130e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 5.6922e-04 - val_loss: 5.6776e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 5.5132e-04 - val_loss: 5.6424e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 5.3826e-04 - val_loss: 4.9817e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 5.3252e-04 - val_loss: 4.8339e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 5.2728e-04 - val_loss: 4.7076e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 5.3095e-04 - val_loss: 5.7784e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 5.7959e-04 - val_loss: 4.6686e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 5.2105e-04 - val_loss: 4.9170e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 4.9474e-04 - val_loss: 5.7603e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 5.0843e-04 - val_loss: 4.4079e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 4.9143e-04 - val_loss: 4.2978e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 4.8239e-04 - val_loss: 4.2331e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 4.8305e-04 - val_loss: 4.1941e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 16s 4ms/step - loss: 0.0346 - val_loss: 0.0075\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0064 - val_loss: 9.8927e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0022 - val_loss: 9.6984e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 9.1585e-04 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 7.9010e-04 - val_loss: 9.1620e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 7.2382e-04 - val_loss: 7.0414e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 6.6790e-04 - val_loss: 5.2609e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 6.0570e-04 - val_loss: 6.3649e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 5.7630e-04 - val_loss: 6.1341e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 5.5455e-04 - val_loss: 4.8391e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 5.3927e-04 - val_loss: 4.7661e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 5.3182e-04 - val_loss: 5.1791e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 5.0931e-04 - val_loss: 4.5545e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 5.0135e-04 - val_loss: 4.3581e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 4.9790e-04 - val_loss: 4.4790e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 4.9029e-04 - val_loss: 4.8344e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 5.1219e-04 - val_loss: 4.3093e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 4.8032e-04 - val_loss: 4.2003e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 4.7804e-04 - val_loss: 4.2807e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 4.9449e-04 - val_loss: 4.1055e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 4.6267e-04 - val_loss: 4.3003e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 4.5332e-04 - val_loss: 4.5499e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 16s 4ms/step - loss: 0.0673 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0066 - val_loss: 0.0019\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0035 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0020 - val_loss: 7.1224e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 9.5828e-04 - val_loss: 9.5432e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 9.2029e-04 - val_loss: 9.9107e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 8.8446e-04 - val_loss: 8.6735e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 8.5244e-04 - val_loss: 8.9945e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 8.2722e-04 - val_loss: 8.2799e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 8.0431e-04 - val_loss: 9.0630e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 7.8402e-04 - val_loss: 7.7956e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 7.6252e-04 - val_loss: 7.8967e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 7.4465e-04 - val_loss: 7.7641e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 7.2713e-04 - val_loss: 7.0742e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 7.1140e-04 - val_loss: 6.7949e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 7.0191e-04 - val_loss: 7.7735e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 6.8895e-04 - val_loss: 6.5288e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 6.7014e-04 - val_loss: 6.8483e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 6.5954e-04 - val_loss: 6.3800e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 6.4849e-04 - val_loss: 6.3310e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 16s 4ms/step - loss: 0.0741 - val_loss: 0.0077\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0060 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0011 - val_loss: 5.6274e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 9.4678e-04 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 8.1959e-04 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 7.6881e-04 - val_loss: 5.8326e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 7.2698e-04 - val_loss: 7.8994e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 6.9504e-04 - val_loss: 6.2237e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 6.7022e-04 - val_loss: 6.3200e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 6.5581e-04 - val_loss: 6.0884e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 6.4585e-04 - val_loss: 6.4710e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 6.3600e-04 - val_loss: 6.1959e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 6.2916e-04 - val_loss: 5.5493e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 6.1804e-04 - val_loss: 5.6242e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 6.1235e-04 - val_loss: 5.1603e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 6.0911e-04 - val_loss: 5.1024e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 6.1147e-04 - val_loss: 4.9822e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 6.2777e-04 - val_loss: 6.0612e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 5.9804e-04 - val_loss: 5.7827e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 5.8779e-04 - val_loss: 5.0489e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 5.8040e-04 - val_loss: 4.9638e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 5.7516e-04 - val_loss: 4.9213e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 16s 4ms/step - loss: 0.0646 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0080 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0035 - val_loss: 0.0039\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0018 - val_loss: 6.7120e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0012 - val_loss: 9.0901e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0010 - val_loss: 9.5270e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 9.6976e-04 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 9.2553e-04 - val_loss: 9.4355e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 8.8704e-04 - val_loss: 9.0035e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 8.5599e-04 - val_loss: 9.4018e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 8.2216e-04 - val_loss: 8.5159e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 7.9283e-04 - val_loss: 8.1538e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 7.6683e-04 - val_loss: 7.5522e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 7.4249e-04 - val_loss: 7.6985e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 7.2080e-04 - val_loss: 7.3438e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 7.0244e-04 - val_loss: 7.3132e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 6.8410e-04 - val_loss: 6.7288e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 6.6876e-04 - val_loss: 6.9000e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 6.5343e-04 - val_loss: 7.3897e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 6.4734e-04 - val_loss: 5.9951e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 6.2567e-04 - val_loss: 6.4353e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 6.1306e-04 - val_loss: 5.7045e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 16s 4ms/step - loss: 18566061.7469 - val_loss: 506.4147\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 1040.3709 - val_loss: 10.8076\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 419.3996 - val_loss: 241.6118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 352.1249 - val_loss: 177.4652\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 267.6964 - val_loss: 97.3579\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 226.5467 - val_loss: 62.3005\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 207.0816 - val_loss: 46.7381\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 191.2594 - val_loss: 35.5735\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 171.9282 - val_loss: 16.8770\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 151.4811 - val_loss: 8.4308\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 131.7682 - val_loss: 25.9787\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 113.1780 - val_loss: 19.3835\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 97.5183 - val_loss: 36.5763\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 85.8628 - val_loss: 35.3676\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 77.2788 - val_loss: 42.4709\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 71.7516 - val_loss: 53.6619\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 68.0714 - val_loss: 58.2144\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 65.4686 - val_loss: 53.3973\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 63.5612 - val_loss: 50.3941\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 62.1103 - val_loss: 59.5878\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 60.6129 - val_loss: 60.0850\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 59.4100 - val_loss: 59.8389\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 58.2425 - val_loss: 53.4690\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 57.2372 - val_loss: 61.4471\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 18s 4ms/step - loss: 0.4321 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0084 - val_loss: 9.7132e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0022 - val_loss: 9.6824e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 9.1640e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0014 - val_loss: 0.0052\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0018 - val_loss: 9.3961e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0015 - val_loss: 8.6749e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0012 - val_loss: 7.4830e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0011 - val_loss: 7.2709e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0010 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0011 - val_loss: 8.2702e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 8.8086e-04 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 9.0650e-04 - val_loss: 7.1134e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 8.5669e-04 - val_loss: 8.7883e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 8.1081e-04 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 9.0070e-04 - val_loss: 6.9464e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 9.3039e-04 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0010 - val_loss: 7.9192e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 18s 4ms/step - loss: 0.2868 - val_loss: 0.0085\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0091 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0098 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0026 - val_loss: 0.0107\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0021 - val_loss: 0.0073\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0020 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0019 - val_loss: 8.3253e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0017 - val_loss: 9.9561e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0019 - val_loss: 0.0062\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0024 - val_loss: 6.9308e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0017 - val_loss: 6.7586e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0017 - val_loss: 0.0050\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0015 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 18s 4ms/step - loss: 2.8994 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0083 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0063 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0057 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0054 - val_loss: 0.0012\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0050 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0044 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0035 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0033 - val_loss: 0.0014\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 18s 4ms/step - loss: 0.2669 - val_loss: 0.1016\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.1003 - val_loss: 0.0193\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0662 - val_loss: 0.0187\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0211 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0079 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0019 - val_loss: 8.5883e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0013 - val_loss: 7.5626e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 9.9401e-04 - val_loss: 9.2489e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 9.8698e-04 - val_loss: 7.1847e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 9.1344e-04 - val_loss: 8.3393e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 8.8744e-04 - val_loss: 6.2574e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 8.6557e-04 - val_loss: 6.1514e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 8.3790e-04 - val_loss: 7.3670e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 8.0618e-04 - val_loss: 6.0063e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 7.8250e-04 - val_loss: 7.3336e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 7.7677e-04 - val_loss: 8.7427e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 7.6361e-04 - val_loss: 8.0541e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 7.6401e-04 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 7.8036e-04 - val_loss: 7.3555e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 7.1639e-04 - val_loss: 5.4093e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 6.9192e-04 - val_loss: 7.2933e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 18s 4ms/step - loss: 0.0498 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0061 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0011 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 8.3853e-04 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 7.4889e-04 - val_loss: 5.5478e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 6.4593e-04 - val_loss: 5.1959e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 6.0268e-04 - val_loss: 4.6384e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 5.8284e-04 - val_loss: 4.5134e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 5.5562e-04 - val_loss: 4.4516e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 5.4021e-04 - val_loss: 4.4771e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 5.2264e-04 - val_loss: 4.4619e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 5.0867e-04 - val_loss: 4.3475e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 5.0220e-04 - val_loss: 4.3372e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 4.8970e-04 - val_loss: 4.3121e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 4.9547e-04 - val_loss: 4.2617e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 4.7891e-04 - val_loss: 4.7592e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 4.8442e-04 - val_loss: 4.3029e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 5.1175e-04 - val_loss: 4.2759e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 4.7561e-04 - val_loss: 4.2680e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 4.6033e-04 - val_loss: 4.2117e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 4.6396e-04 - val_loss: 3.9843e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 453us/step - loss: 4.5448e-04 - val_loss: 3.9571e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 19s 5ms/step - loss: 0.0518 - val_loss: 0.0204\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0092 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0034 - val_loss: 6.6823e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0017 - val_loss: 9.2640e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0013 - val_loss: 5.6608e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 9.0202e-04 - val_loss: 7.1745e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 7.8449e-04 - val_loss: 7.9531e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 6.8728e-04 - val_loss: 6.4457e-04\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 525us/step - loss: 6.3202e-04 - val_loss: 4.7299e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 5.9301e-04 - val_loss: 4.5832e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 5.7508e-04 - val_loss: 4.5258e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 5.2896e-04 - val_loss: 4.5312e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 5.1630e-04 - val_loss: 4.7889e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 5.0614e-04 - val_loss: 4.7354e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 4.9956e-04 - val_loss: 4.4011e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 4.9419e-04 - val_loss: 5.5753e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 5.1535e-04 - val_loss: 4.3967e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 5.0538e-04 - val_loss: 4.2412e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 4.7547e-04 - val_loss: 4.7031e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 4.7763e-04 - val_loss: 4.1578e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 4.7156e-04 - val_loss: 4.1517e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 4.8758e-04 - val_loss: 5.5300e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 4.9793e-04 - val_loss: 4.1713e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 4.6465e-04 - val_loss: 4.2314e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 19s 5ms/step - loss: 0.0649 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0082 - val_loss: 8.9879e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 7.9997e-04 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 6.2715e-04 - val_loss: 5.5312e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 5.4066e-04 - val_loss: 5.0928e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 5.2766e-04 - val_loss: 4.5694e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 5.2313e-04 - val_loss: 4.6416e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 5.1054e-04 - val_loss: 5.4223e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 5.0663e-04 - val_loss: 4.4561e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 5.2158e-04 - val_loss: 6.6739e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 5.0599e-04 - val_loss: 4.3900e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 5.1273e-04 - val_loss: 4.8475e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 5.0688e-04 - val_loss: 5.7668e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 4.8488e-04 - val_loss: 5.1169e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 4.7687e-04 - val_loss: 6.1746e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 4.8106e-04 - val_loss: 5.7448e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 5.3664e-04 - val_loss: 4.2704e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 4.9753e-04 - val_loss: 9.2483e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 5.3550e-04 - val_loss: 3.9720e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 4.8114e-04 - val_loss: 4.6312e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 20s 5ms/step - loss: 0.5781 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0049 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0040 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0034 - val_loss: 7.5339e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0036 - val_loss: 7.2130e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0033 - val_loss: 8.3505e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0084 - val_loss: 0.0887\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0190 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0033 - val_loss: 0.0137\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0140 - val_loss: 0.0425\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 509us/step - loss: 0.0149 - val_loss: 0.0211\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0102 - val_loss: 0.0069\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0109 - val_loss: 0.0277\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0129 - val_loss: 0.0073\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 494us/step - loss: 0.0112 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0034 - val_loss: 0.0131\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0350 - val_loss: 0.3483\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.1202 - val_loss: 5.9124e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0017 - val_loss: 7.6983e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 490us/step - loss: 0.0013 - val_loss: 5.3354e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 491us/step - loss: 0.0014 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 487us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 489us/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 18s 4ms/step - loss: 0.6868 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0025 - val_loss: 9.2487e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0231 - val_loss: 0.0071\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0070 - val_loss: 0.0515\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0173 - val_loss: 0.0094\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0239 - val_loss: 0.2676\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0531 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0153 - val_loss: 0.0190\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0092 - val_loss: 0.0082\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0289 - val_loss: 6.7959e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0102 - val_loss: 0.0105\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0083 - val_loss: 0.0232\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0136 - val_loss: 0.0396\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0150 - val_loss: 0.0353\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0054 - val_loss: 0.0072\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0059 - val_loss: 0.0056\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0104 - val_loss: 0.0141\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0060 - val_loss: 0.0115\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0082 - val_loss: 0.0128\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0090 - val_loss: 0.0138\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0038 - val_loss: 0.0033\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 18s 4ms/step - loss: 0.8933 - val_loss: 9.9284e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0034 - val_loss: 6.6929e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0142 - val_loss: 0.0173\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0055 - val_loss: 0.0100\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0203 - val_loss: 0.0093\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0132 - val_loss: 0.0342\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0639 - val_loss: 9.7784e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0157 - val_loss: 0.0116\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0126 - val_loss: 0.0275\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0594 - val_loss: 8.7811e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0022 - val_loss: 0.0136\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0086 - val_loss: 0.0146\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0083 - val_loss: 0.0184\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0110 - val_loss: 0.0301\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0118 - val_loss: 0.0076\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0064 - val_loss: 0.0159\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0167 - val_loss: 0.0055\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0046 - val_loss: 0.0069\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0099 - val_loss: 0.0091\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0056 - val_loss: 0.0114\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0095 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0017 - val_loss: 0.0772\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0157 - val_loss: 5.0846e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 19s 5ms/step - loss: 0.7073 - val_loss: 9.8239e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0045 - val_loss: 8.3928e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0059 - val_loss: 0.0236\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0108 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0186 - val_loss: 0.0243\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0105 - val_loss: 0.0198\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0430 - val_loss: 0.0391\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0081 - val_loss: 8.3500e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0155 - val_loss: 0.0137\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0199 - val_loss: 0.0633\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0120 - val_loss: 0.0123\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0113 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0116 - val_loss: 0.0239\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 450us/step - loss: 0.0226 - val_loss: 0.0056\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0040 - val_loss: 0.0323\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0094 - val_loss: 0.0129\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0084 - val_loss: 0.0413\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0195 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0024 - val_loss: 0.0289\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0076 - val_loss: 0.0067\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0096 - val_loss: 0.0135\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0116 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0036 - val_loss: 0.0170\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0065 - val_loss: 0.0193\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 19s 5ms/step - loss: 0.6278 - val_loss: 0.0379\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 449us/step - loss: 0.0820 - val_loss: 0.1091\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0917 - val_loss: 0.0280\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0896 - val_loss: 0.0564\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0605 - val_loss: 0.0746\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0547 - val_loss: 0.1357\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0530 - val_loss: 0.0692\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0576 - val_loss: 0.0186\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0486 - val_loss: 0.0743\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0314 - val_loss: 0.0410\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0413 - val_loss: 0.0581\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0362 - val_loss: 0.0244\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0246 - val_loss: 0.1039\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0313 - val_loss: 0.0026\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0300 - val_loss: 0.0405\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0219 - val_loss: 0.0158\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0203 - val_loss: 0.0188\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0208 - val_loss: 0.0062\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0191 - val_loss: 0.0330\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 444us/step - loss: 0.0193 - val_loss: 0.0095\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 443us/step - loss: 0.0134 - val_loss: 0.0296\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0196 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0156 - val_loss: 0.0380\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0121 - val_loss: 0.0137\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 19s 5ms/step - loss: 0.0596 - val_loss: 0.0098\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 0.0085 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 399us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 395us/step - loss: 0.0012 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 398us/step - loss: 0.0010 - val_loss: 5.3948e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 398us/step - loss: 7.8755e-04 - val_loss: 5.2094e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 7.5909e-04 - val_loss: 6.2085e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 6.7517e-04 - val_loss: 6.5281e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 398us/step - loss: 6.3813e-04 - val_loss: 6.8162e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 395us/step - loss: 6.1095e-04 - val_loss: 8.2876e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 398us/step - loss: 6.1128e-04 - val_loss: 8.4036e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 397us/step - loss: 6.0414e-04 - val_loss: 7.2511e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 400us/step - loss: 5.8393e-04 - val_loss: 7.2198e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 401us/step - loss: 5.6080e-04 - val_loss: 6.6320e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 398us/step - loss: 5.3526e-04 - val_loss: 5.2901e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 5.2114e-04 - val_loss: 4.4127e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 5.1633e-04 - val_loss: 4.4017e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 401us/step - loss: 4.9782e-04 - val_loss: 4.3306e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 400us/step - loss: 4.9625e-04 - val_loss: 4.4054e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 400us/step - loss: 4.9154e-04 - val_loss: 4.3665e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 397us/step - loss: 5.0819e-04 - val_loss: 4.2503e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 399us/step - loss: 4.8854e-04 - val_loss: 6.4225e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 399us/step - loss: 5.0456e-04 - val_loss: 4.2026e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 19s 5ms/step - loss: 0.0368 - val_loss: 0.0137\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 395us/step - loss: 0.0070 - val_loss: 8.7364e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 394us/step - loss: 0.0017 - val_loss: 5.7675e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 397us/step - loss: 8.6474e-04 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 393us/step - loss: 7.4348e-04 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 7.1188e-04 - val_loss: 8.7302e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 479us/step - loss: 6.6085e-04 - val_loss: 7.4321e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 5.9697e-04 - val_loss: 6.9141e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 5.6548e-04 - val_loss: 5.5238e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 5.4350e-04 - val_loss: 5.2260e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 5.3025e-04 - val_loss: 5.6144e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 397us/step - loss: 5.2052e-04 - val_loss: 4.7537e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 5.1135e-04 - val_loss: 4.6491e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 5.0916e-04 - val_loss: 4.3365e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 5.1844e-04 - val_loss: 4.9600e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - -1s -317us/step - loss: 4.9670e-04 - val_loss: 4.7869e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 393us/step - loss: 5.2040e-04 - val_loss: 5.4814e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 395us/step - loss: 5.0081e-04 - val_loss: 5.0182e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 394us/step - loss: 5.0711e-04 - val_loss: 5.0295e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 395us/step - loss: 4.6734e-04 - val_loss: 4.2245e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 4.6075e-04 - val_loss: 4.4548e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 395us/step - loss: 4.6867e-04 - val_loss: 4.0500e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 20s 5ms/step - loss: 0.0608 - val_loss: 0.0054\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0105 - val_loss: 0.0065\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0025 - val_loss: 7.9395e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0021 - val_loss: 9.0112e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0018 - val_loss: 9.9782e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0017 - val_loss: 9.5900e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0016 - val_loss: 9.7011e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0015 - val_loss: 6.2847e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0015 - val_loss: 6.5525e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0014 - val_loss: 7.8951e-04\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0013 - val_loss: 5.9584e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0012 - val_loss: 8.0022e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0012 - val_loss: 6.4600e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0011 - val_loss: 7.3253e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0011 - val_loss: 8.0843e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0011 - val_loss: 8.3304e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 20s 5ms/step - loss: 0.1354 - val_loss: 0.0160\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 504us/step - loss: 0.0130 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 496us/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 497us/step - loss: 0.0042 - val_loss: 9.8850e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 498us/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 493us/step - loss: 0.0025 - val_loss: 5.5714e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 501us/step - loss: 0.0022 - val_loss: 8.8477e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 501us/step - loss: 0.0020 - val_loss: 8.2844e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0020 - val_loss: 9.0709e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0019 - val_loss: 5.3996e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0018 - val_loss: 6.5018e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0019 - val_loss: 8.0411e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 501us/step - loss: 0.0018 - val_loss: 6.3092e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0016 - val_loss: 5.3616e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 0.0016 - val_loss: 5.9663e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 502us/step - loss: 0.0016 - val_loss: 5.4019e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 495us/step - loss: 0.0016 - val_loss: 6.7788e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0015 - val_loss: 9.2389e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 497us/step - loss: 0.0015 - val_loss: 6.6867e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0014 - val_loss: 6.8803e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 500us/step - loss: 0.0014 - val_loss: 6.2938e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 499us/step - loss: 0.0014 - val_loss: 5.4776e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 21s 5ms/step - loss: 0.0831 - val_loss: 0.0192\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0116 - val_loss: 9.5450e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0061 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0039 - val_loss: 5.4756e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0025 - val_loss: 9.6328e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0021 - val_loss: 7.3385e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0021 - val_loss: 6.5552e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0020 - val_loss: 8.3563e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0020 - val_loss: 7.8394e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0017 - val_loss: 9.6956e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0016 - val_loss: 9.3816e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0016 - val_loss: 8.0722e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0015 - val_loss: 5.1633e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0015 - val_loss: 4.8306e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0015 - val_loss: 7.1868e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0015 - val_loss: 6.5169e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0014 - val_loss: 5.4668e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0014 - val_loss: 4.7848e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 20s 5ms/step - loss: 0.0634 - val_loss: 0.0214\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0114 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0059 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0035 - val_loss: 7.6121e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0027 - val_loss: 8.2036e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0019 - val_loss: 7.0875e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0018 - val_loss: 5.9403e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0018 - val_loss: 9.1175e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0016 - val_loss: 6.3729e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0016 - val_loss: 5.0081e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0014 - val_loss: 5.8841e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0014 - val_loss: 6.0741e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0014 - val_loss: 5.5422e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0014 - val_loss: 4.9067e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0014 - val_loss: 4.8611e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0013 - val_loss: 5.3083e-04\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0012 - val_loss: 5.5067e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 0.0013 - val_loss: 5.1741e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0012 - val_loss: 5.7456e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0011 - val_loss: 7.8317e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0012 - val_loss: 5.6090e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0012 - val_loss: 5.8950e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 22s 5ms/step - loss: 1.0499 - val_loss: 0.1158\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.1125 - val_loss: 0.0568\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0722 - val_loss: 0.0775\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0628 - val_loss: 0.0199\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0578 - val_loss: 0.0182\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0370 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0085 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0022 - val_loss: 9.1178e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0021 - val_loss: 9.1228e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0020 - val_loss: 8.2975e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0019 - val_loss: 8.0606e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0018 - val_loss: 7.6252e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0018 - val_loss: 7.5299e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0016 - val_loss: 9.9173e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 22s 5ms/step - loss: 0.1509 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0126 - val_loss: 0.0056\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0073 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0016 - val_loss: 9.5260e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0015 - val_loss: 9.7962e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0013 - val_loss: 9.0302e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0013 - val_loss: 9.1507e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0012 - val_loss: 9.7638e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0012 - val_loss: 9.6074e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0012 - val_loss: 9.0571e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 516us/step - loss: 0.0011 - val_loss: 8.5798e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0012 - val_loss: 7.8154e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0012 - val_loss: 8.5122e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0011 - val_loss: 7.1037e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 515us/step - loss: 0.0011 - val_loss: 8.2002e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0011 - val_loss: 7.5185e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 22s 5ms/step - loss: 0.0958 - val_loss: 0.0257\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 1s 361us/step - loss: 0.0126 - val_loss: 0.0068\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 1s 357us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 371us/step - loss: 0.0035 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 1s 357us/step - loss: 0.0027 - val_loss: 6.0900e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 1s 357us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 1s 357us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 1s 360us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 1s 356us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 1s 361us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 1s 360us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 366us/step - loss: 0.0017 - val_loss: 9.9227e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 1s 360us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 1s 360us/step - loss: 0.0017 - val_loss: 9.6003e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 1s 358us/step - loss: 0.0017 - val_loss: 9.7341e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 364us/step - loss: 0.0015 - val_loss: 9.0390e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 1s 360us/step - loss: 0.0014 - val_loss: 9.5848e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 364us/step - loss: 0.0015 - val_loss: 7.8282e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 1s 358us/step - loss: 0.0014 - val_loss: 8.8379e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 365us/step - loss: 0.0015 - val_loss: 8.5078e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 1s 360us/step - loss: 0.0014 - val_loss: 7.4894e-04\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 363us/step - loss: 0.0013 - val_loss: 8.8343e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 363us/step - loss: 0.0013 - val_loss: 6.8521e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 1s 362us/step - loss: 0.0013 - val_loss: 7.3732e-04\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 22s 5ms/step - loss: 0.0637 - val_loss: 0.0108\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 0.0065 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 388us/step - loss: 0.0016 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 386us/step - loss: 9.9477e-04 - val_loss: 5.6293e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 8.4292e-04 - val_loss: 6.0815e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 7.6177e-04 - val_loss: 6.6885e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 388us/step - loss: 6.9748e-04 - val_loss: 6.5796e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 392us/step - loss: 6.5950e-04 - val_loss: 6.6708e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 6.3155e-04 - val_loss: 6.6234e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 387us/step - loss: 6.0865e-04 - val_loss: 5.7270e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 5.7884e-04 - val_loss: 5.0229e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 5.6252e-04 - val_loss: 5.3098e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 5.5068e-04 - val_loss: 4.8861e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 388us/step - loss: 5.3770e-04 - val_loss: 5.0990e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 387us/step - loss: 5.3064e-04 - val_loss: 4.6018e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 397us/step - loss: 5.2284e-04 - val_loss: 5.5491e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 389us/step - loss: 5.2881e-04 - val_loss: 4.6793e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 387us/step - loss: 5.0555e-04 - val_loss: 4.5120e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 4.9980e-04 - val_loss: 4.4359e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 385us/step - loss: 4.9951e-04 - val_loss: 5.4474e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 393us/step - loss: 5.2178e-04 - val_loss: 4.3666e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 392us/step - loss: 4.9053e-04 - val_loss: 4.3753e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 23s 5ms/step - loss: 0.0580 - val_loss: 0.0117\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0079 - val_loss: 0.0046\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0042 - val_loss: 0.0081\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 0.0013 - val_loss: 5.1841e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 398us/step - loss: 9.5342e-04 - val_loss: 8.1991e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 401us/step - loss: 8.0028e-04 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 7.3241e-04 - val_loss: 9.4351e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 401us/step - loss: 6.6807e-04 - val_loss: 6.9050e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 6.1940e-04 - val_loss: 5.9872e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 401us/step - loss: 5.8801e-04 - val_loss: 4.8357e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 5.5195e-04 - val_loss: 4.4997e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 5.3520e-04 - val_loss: 4.5011e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 399us/step - loss: 5.1715e-04 - val_loss: 4.4816e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 398us/step - loss: 5.1100e-04 - val_loss: 5.1097e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 5.2280e-04 - val_loss: 5.7202e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 4.9857e-04 - val_loss: 5.1047e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 401us/step - loss: 4.8706e-04 - val_loss: 4.2955e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 4.8270e-04 - val_loss: 4.6711e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 4.8669e-04 - val_loss: 4.3289e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 399us/step - loss: 4.6890e-04 - val_loss: 4.0871e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 4.6403e-04 - val_loss: 4.3154e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 4.6102e-04 - val_loss: 4.0064e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 4.5721e-04 - val_loss: 3.9798e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 23s 6ms/step - loss: 0.1301 - val_loss: 0.0078\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0126 - val_loss: 9.9752e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0034 - val_loss: 7.4602e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0022 - val_loss: 9.0863e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 8.6509e-04 - val_loss: 9.1093e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 8.5520e-04 - val_loss: 6.5307e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 8.2665e-04 - val_loss: 6.0918e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 8.0239e-04 - val_loss: 6.3842e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 7.5226e-04 - val_loss: 7.3317e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 7.4142e-04 - val_loss: 8.2783e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 7.2973e-04 - val_loss: 8.9522e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 7.3603e-04 - val_loss: 5.7677e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 7.2938e-04 - val_loss: 5.9263e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 6.9483e-04 - val_loss: 7.8435e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 6.8153e-04 - val_loss: 5.9954e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 6.5321e-04 - val_loss: 5.9781e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 6.9882e-04 - val_loss: 9.8785e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 7.2269e-04 - val_loss: 5.7222e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 6.9958e-04 - val_loss: 9.6833e-04\n",
      "Epoch 22/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 575us/step - loss: 7.2985e-04 - val_loss: 5.3601e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 6.1943e-04 - val_loss: 5.7909e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 6.1706e-04 - val_loss: 6.3226e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 24s 6ms/step - loss: 0.0826 - val_loss: 0.0033\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0095 - val_loss: 0.0094\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0066 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0056 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0032 - val_loss: 0.0089\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0059 - val_loss: 0.0065\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0035 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0021 - val_loss: 0.0077\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0020 - val_loss: 0.0075\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0036 - val_loss: 0.0098\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0046 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0013 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0038 - val_loss: 0.0094\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0029 - val_loss: 0.0330\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0072 - val_loss: 4.9130e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 6.0728e-04 - val_loss: 6.6245e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 5.6451e-04 - val_loss: 4.7037e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 9.4375e-04 - val_loss: 6.1289e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0016 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 25s 6ms/step - loss: 0.1462 - val_loss: 0.0078\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0134 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0020 - val_loss: 0.0314\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0048 - val_loss: 0.0105\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0050 - val_loss: 0.0078\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0040 - val_loss: 0.0085\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0037 - val_loss: 0.0078\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0047 - val_loss: 0.0094\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0030 - val_loss: 0.0138\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0011 - val_loss: 6.5152e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0011 - val_loss: 0.0109\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0027 - val_loss: 0.0060\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0020 - val_loss: 4.9921e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 8.4190e-04 - val_loss: 0.0036\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 25s 6ms/step - loss: 0.0970 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0120 - val_loss: 0.0217\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0080 - val_loss: 0.0273\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0032 - val_loss: 0.0188\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0030 - val_loss: 0.0104\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0025 - val_loss: 0.0071\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0036 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0026 - val_loss: 0.0142\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0021 - val_loss: 0.0061\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 9.5400e-04 - val_loss: 4.8666e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 6.3367e-04 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0037 - val_loss: 0.0173\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 0.0089 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0014 - val_loss: 6.9674e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 0.0024 - val_loss: 0.0047\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 25s 6ms/step - loss: 0.0768 - val_loss: 0.0227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0153 - val_loss: 0.0248\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0077 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0060 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0038 - val_loss: 0.0160\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0062 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0035 - val_loss: 6.9527e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0032 - val_loss: 0.0112\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0041 - val_loss: 9.8119e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0017 - val_loss: 0.0052\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0047 - val_loss: 0.0089\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0045 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0023 - val_loss: 8.4564e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0013 - val_loss: 8.6474e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0020 - val_loss: 0.0071\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0045 - val_loss: 0.0091\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0036 - val_loss: 0.0092\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0026 - val_loss: 9.9769e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 25s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 26s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 26s 6ms/step - loss: 1.0444 - val_loss: 0.4110\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.1321 - val_loss: 0.0261\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0818 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0939 - val_loss: 0.0085\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0716 - val_loss: 0.0352\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0655 - val_loss: 0.0579\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0665 - val_loss: 0.0521\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0652 - val_loss: 0.0383\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0648 - val_loss: 0.0349\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0648 - val_loss: 0.0377\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0647 - val_loss: 0.0407\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0647 - val_loss: 0.0398\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0647 - val_loss: 0.0398\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0647 - val_loss: 0.0398\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0647 - val_loss: 0.0372\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0647 - val_loss: 0.0387\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0647 - val_loss: 0.0389\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0415\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0409\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0393\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0647 - val_loss: 0.0392\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0403\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0647 - val_loss: 0.0396\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0647 - val_loss: 0.0386\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 26s 6ms/step - loss: 0.0671 - val_loss: 8.0196e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0067 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 0.0017 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 404us/step - loss: 0.0014 - val_loss: 5.4475e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 9.7806e-04 - val_loss: 5.6897e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 8.7903e-04 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 7.6748e-04 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 7.0014e-04 - val_loss: 7.7001e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 403us/step - loss: 6.5778e-04 - val_loss: 6.2309e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 401us/step - loss: 6.1614e-04 - val_loss: 6.2186e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 5.9155e-04 - val_loss: 5.0725e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 5.7357e-04 - val_loss: 4.8503e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 5.6108e-04 - val_loss: 4.5349e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 5.5297e-04 - val_loss: 4.5978e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 5.4357e-04 - val_loss: 5.9034e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 5.4076e-04 - val_loss: 5.3192e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 5.3123e-04 - val_loss: 4.4477e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 5.2198e-04 - val_loss: 4.6999e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 5.1910e-04 - val_loss: 4.3665e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 5.3098e-04 - val_loss: 4.3765e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 5.1362e-04 - val_loss: 5.2335e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 5.1243e-04 - val_loss: 4.2704e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 402us/step - loss: 4.9148e-04 - val_loss: 4.2883e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 27s 6ms/step - loss: 0.0937 - val_loss: 0.0179\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0102 - val_loss: 0.0070\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0039 - val_loss: 0.0063\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0022 - val_loss: 5.8460e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0013 - val_loss: 7.1706e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0011 - val_loss: 8.8838e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 9.4327e-04 - val_loss: 9.2926e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 8.8760e-04 - val_loss: 8.2840e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 8.3844e-04 - val_loss: 8.2302e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 7.9286e-04 - val_loss: 7.8661e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 7.5450e-04 - val_loss: 7.5212e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 7.2116e-04 - val_loss: 6.8843e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 6.9263e-04 - val_loss: 6.6412e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 6.6534e-04 - val_loss: 6.1404e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 6.4232e-04 - val_loss: 6.5086e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 6.2059e-04 - val_loss: 5.7886e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 6.0177e-04 - val_loss: 5.6447e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 5.8565e-04 - val_loss: 4.9597e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 5.7944e-04 - val_loss: 6.4411e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 5.6902e-04 - val_loss: 5.0200e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 5.5691e-04 - val_loss: 4.5216e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 27s 7ms/step - loss: 0.0524 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0054 - val_loss: 8.0011e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0026 - val_loss: 8.2413e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 9.5499e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0011 - val_loss: 6.2416e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0010 - val_loss: 7.7001e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 9.6319e-04 - val_loss: 8.3368e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 9.4873e-04 - val_loss: 8.4244e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 9.0142e-04 - val_loss: 7.6534e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 8.7527e-04 - val_loss: 6.4694e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 8.7350e-04 - val_loss: 7.6617e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 8.7234e-04 - val_loss: 7.6361e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 8.4148e-04 - val_loss: 6.9380e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 8.2771e-04 - val_loss: 6.9413e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 8.2060e-04 - val_loss: 6.7449e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 8.2325e-04 - val_loss: 8.0252e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 7.8773e-04 - val_loss: 8.7672e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 8.3256e-04 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 8.1290e-04 - val_loss: 6.8091e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 8.0508e-04 - val_loss: 5.0213e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 8.3081e-04 - val_loss: 5.6085e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 7.9382e-04 - val_loss: 7.3567e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 7.5394e-04 - val_loss: 7.8246e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 7.8855e-04 - val_loss: 0.0015\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 28s 7ms/step - loss: 0.0582 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 0.0064 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0012 - val_loss: 7.9762e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 0.0011 - val_loss: 7.3505e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0011 - val_loss: 9.3978e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0010 - val_loss: 9.6873e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 9.9611e-04 - val_loss: 9.7406e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 9.9025e-04 - val_loss: 8.2224e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 9.7980e-04 - val_loss: 7.0545e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 9.7670e-04 - val_loss: 6.9107e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 9.0472e-04 - val_loss: 7.3101e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 8.9556e-04 - val_loss: 8.1097e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 9.4447e-04 - val_loss: 5.9644e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 9.4606e-04 - val_loss: 5.9203e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 9.1907e-04 - val_loss: 6.5189e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 9.0303e-04 - val_loss: 7.4531e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 8.9618e-04 - val_loss: 8.2342e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 8.7817e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 8.6237e-04 - val_loss: 6.9003e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 28s 7ms/step - loss: 0.0572 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 517us/step - loss: 0.0072 - val_loss: 0.0119\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 509us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 0.0015 - val_loss: 9.8808e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 507us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0012 - val_loss: 8.1351e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 509us/step - loss: 0.0012 - val_loss: 7.8835e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 511us/step - loss: 0.0012 - val_loss: 6.7825e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 0.0013 - val_loss: 7.5828e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0011 - val_loss: 8.3199e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 505us/step - loss: 0.0011 - val_loss: 8.5824e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 518us/step - loss: 0.0011 - val_loss: 7.3112e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 505us/step - loss: 0.0011 - val_loss: 7.1571e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 512us/step - loss: 0.0011 - val_loss: 6.4927e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 506us/step - loss: 0.0011 - val_loss: 6.7631e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 514us/step - loss: 0.0010 - val_loss: 8.1300e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 508us/step - loss: 9.7016e-04 - val_loss: 6.3712e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 513us/step - loss: 0.0012 - val_loss: 7.3403e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 509us/step - loss: 9.8112e-04 - val_loss: 7.0584e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 28s 7ms/step - loss: 0.0585 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 0.0059 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0015 - val_loss: 9.2966e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0013 - val_loss: 7.6090e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0013 - val_loss: 7.4032e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0013 - val_loss: 7.4233e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0012 - val_loss: 8.1524e-04\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 519us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0012 - val_loss: 9.8725e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 520us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0011 - val_loss: 7.1212e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0010 - val_loss: 9.2670e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0010 - val_loss: 5.9944e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0010 - val_loss: 7.9215e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 29s 7ms/step - loss: 0.1163 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0103 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 534us/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0024 - val_loss: 8.6285e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 535us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0015 - val_loss: 8.7103e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 8.4885e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0013 - val_loss: 9.7093e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0013 - val_loss: 8.2035e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0013 - val_loss: 7.1324e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0013 - val_loss: 9.6023e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0012 - val_loss: 7.5586e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0012 - val_loss: 7.7042e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0012 - val_loss: 8.8265e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 533us/step - loss: 0.0012 - val_loss: 6.3547e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0012 - val_loss: 8.0356e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 524us/step - loss: 0.0011 - val_loss: 6.3717e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0011 - val_loss: 7.7791e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 538us/step - loss: 0.0011 - val_loss: 6.1040e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 532us/step - loss: 0.0011 - val_loss: 7.1444e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 0.0011 - val_loss: 6.8314e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 29s 7ms/step - loss: 0.0681 - val_loss: 0.0412\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0646 - val_loss: 0.0321\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0647 - val_loss: 0.0360\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0646 - val_loss: 0.0460\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0644 - val_loss: 0.0452\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0645 - val_loss: 0.0504\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 445us/step - loss: 0.0645 - val_loss: 0.0514\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 448us/step - loss: 0.0644 - val_loss: 0.0305\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0643 - val_loss: 0.0531\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0643 - val_loss: 0.0278\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0642 - val_loss: 0.0315\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0640 - val_loss: 0.0515\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0641 - val_loss: 0.0331\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0637 - val_loss: 0.0279\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0637 - val_loss: 0.0618\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0634 - val_loss: 0.0524\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0630 - val_loss: 0.0614\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0631 - val_loss: 0.0221\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0625 - val_loss: 0.0449\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0616 - val_loss: 0.0308\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0606 - val_loss: 0.0181\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0597 - val_loss: 0.0470\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0566 - val_loss: 0.0355\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 0.0514 - val_loss: 0.0415\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 29s 7ms/step - loss: 0.0352 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0054 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0024 - val_loss: 5.2655e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0015 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 8.3955e-04 - val_loss: 5.3583e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 6.9064e-04 - val_loss: 5.0338e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 6.3649e-04 - val_loss: 6.2257e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 5.9755e-04 - val_loss: 5.3651e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 5.7105e-04 - val_loss: 6.8696e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 5.6956e-04 - val_loss: 6.7334e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 5.5219e-04 - val_loss: 5.3634e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 5.3496e-04 - val_loss: 5.0443e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 5.2336e-04 - val_loss: 4.5215e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 5.0565e-04 - val_loss: 4.3972e-04\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 415us/step - loss: 5.0010e-04 - val_loss: 4.3539e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 5.0470e-04 - val_loss: 4.8285e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 4.8662e-04 - val_loss: 4.2976e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 4.8350e-04 - val_loss: 4.2550e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 4.8532e-04 - val_loss: 4.2080e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 4.6923e-04 - val_loss: 4.4518e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 4.7315e-04 - val_loss: 4.1183e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 4.6212e-04 - val_loss: 4.0654e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 4.5139e-04 - val_loss: 4.6706e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 30s 7ms/step - loss: 0.0601 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0038 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0016 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0011 - val_loss: 5.2085e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 8.3405e-04 - val_loss: 4.9935e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 7.5710e-04 - val_loss: 7.4891e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 6.7714e-04 - val_loss: 7.8345e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 6.4368e-04 - val_loss: 7.8007e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 6.2247e-04 - val_loss: 5.9547e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 6.0071e-04 - val_loss: 5.5872e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 5.9158e-04 - val_loss: 5.2533e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 5.6900e-04 - val_loss: 5.2121e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 5.5209e-04 - val_loss: 5.3192e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 5.4342e-04 - val_loss: 4.7357e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 5.3245e-04 - val_loss: 4.5613e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 5.2368e-04 - val_loss: 4.5123e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 5.1595e-04 - val_loss: 4.6364e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 5.0894e-04 - val_loss: 4.4906e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 5.0231e-04 - val_loss: 4.4349e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 4.9777e-04 - val_loss: 4.3307e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 4.9084e-04 - val_loss: 4.9016e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 4.9695e-04 - val_loss: 5.0005e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 4.8450e-04 - val_loss: 4.2135e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 29s 7ms/step - loss: 0.0576 - val_loss: 7.9060e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0046 - val_loss: 6.5941e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0059 - val_loss: 0.0075\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0088 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0107 - val_loss: 0.0152\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0113 - val_loss: 0.0092\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0091 - val_loss: 0.0108\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0085 - val_loss: 0.0036\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0053 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0049 - val_loss: 0.0164\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0118 - val_loss: 0.0111\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0081 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0035 - val_loss: 0.0070\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0106 - val_loss: 0.0126\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0091 - val_loss: 0.0054\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0052 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 423us/step - loss: 0.0069 - val_loss: 0.0104\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0082 - val_loss: 0.0126\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0059 - val_loss: 0.0125\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0045 - val_loss: 0.0073\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 30s 7ms/step - loss: 0.0585 - val_loss: 0.0169\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0104 - val_loss: 0.0055\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0056 - val_loss: 0.0053\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0041 - val_loss: 8.2497e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0022 - val_loss: 8.2994e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0021 - val_loss: 7.8947e-04\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0020 - val_loss: 8.4627e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0020 - val_loss: 5.9858e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0020 - val_loss: 5.4690e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0019 - val_loss: 7.9015e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0018 - val_loss: 7.7503e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0017 - val_loss: 6.4693e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 30s 7ms/step - loss: 0.0963 - val_loss: 0.0193\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0120 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0032 - val_loss: 5.7898e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0029 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0026 - val_loss: 9.4431e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0019 - val_loss: 8.7216e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0018 - val_loss: 9.5094e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0017 - val_loss: 8.6610e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0017 - val_loss: 8.8470e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0016 - val_loss: 8.8832e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0016 - val_loss: 8.8469e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0015 - val_loss: 8.6200e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0016 - val_loss: 7.3320e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 31s 8ms/step - loss: 0.1435 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0134 - val_loss: 0.0073\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0079 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0040 - val_loss: 5.7674e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0024 - val_loss: 7.8441e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0022 - val_loss: 8.7234e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0021 - val_loss: 8.8866e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0021 - val_loss: 9.5168e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0021 - val_loss: 9.2269e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0020 - val_loss: 9.1214e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0020 - val_loss: 9.0556e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0019 - val_loss: 7.9488e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0019 - val_loss: 9.0327e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0018 - val_loss: 8.0478e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0018 - val_loss: 7.7862e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0018 - val_loss: 6.3612e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0017 - val_loss: 7.9685e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0018 - val_loss: 7.0428e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 32s 8ms/step - loss: 0.1352 - val_loss: 0.0019\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0128 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0078 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0042 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0032 - val_loss: 5.2676e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0027 - val_loss: 7.9483e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0027 - val_loss: 8.3777e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0026 - val_loss: 8.7153e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0025 - val_loss: 6.6609e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0024 - val_loss: 9.3801e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0025 - val_loss: 8.3576e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0024 - val_loss: 8.2841e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 6.6373e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0023 - val_loss: 7.8977e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0023 - val_loss: 7.4674e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0023 - val_loss: 7.5998e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 6.8006e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0021 - val_loss: 6.7765e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0020 - val_loss: 6.6675e-04\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0021 - val_loss: 7.2811e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0021 - val_loss: 6.7711e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0021 - val_loss: 6.8802e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0020 - val_loss: 7.3699e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 32s 8ms/step - loss: 0.1991 - val_loss: 0.0073\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0117 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0074 - val_loss: 7.3477e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0026 - val_loss: 5.4309e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0021 - val_loss: 8.8888e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 9.0183e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0019 - val_loss: 9.9623e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0019 - val_loss: 9.6586e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0017 - val_loss: 8.1949e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0018 - val_loss: 9.6637e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0016 - val_loss: 8.8363e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0016 - val_loss: 9.3774e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0016 - val_loss: 8.4920e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0016 - val_loss: 8.2201e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0015 - val_loss: 8.7836e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0016 - val_loss: 8.6570e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0015 - val_loss: 8.6551e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 33s 8ms/step - loss: 0.0700 - val_loss: 0.0154\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0086 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0034 - val_loss: 7.3313e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0021 - val_loss: 5.5182e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0017 - val_loss: 7.0858e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0016 - val_loss: 8.4885e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0015 - val_loss: 8.2411e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0015 - val_loss: 9.4413e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0015 - val_loss: 7.6779e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0015 - val_loss: 8.4265e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0014 - val_loss: 6.6708e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0014 - val_loss: 7.9857e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0013 - val_loss: 7.2476e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0014 - val_loss: 7.3100e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0013 - val_loss: 7.0671e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0013 - val_loss: 6.0584e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0013 - val_loss: 6.4224e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0013 - val_loss: 7.4769e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0013 - val_loss: 6.6439e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 552us/step - loss: 0.0012 - val_loss: 7.1794e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0012 - val_loss: 6.2023e-04\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 33s 8ms/step - loss: 0.0667 - val_loss: 0.0088\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0055 - val_loss: 5.9639e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0023 - val_loss: 5.5420e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0015 - val_loss: 7.1001e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0014 - val_loss: 9.1676e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 525us/step - loss: 0.0012 - val_loss: 8.6904e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0011 - val_loss: 6.0992e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 0.0011 - val_loss: 6.7742e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 530us/step - loss: 0.0011 - val_loss: 6.8011e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 0.0010 - val_loss: 7.2152e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 0.0010 - val_loss: 5.8772e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0011 - val_loss: 6.2374e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 522us/step - loss: 0.0011 - val_loss: 5.4203e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 531us/step - loss: 0.0010 - val_loss: 6.1009e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 0.0010 - val_loss: 6.8830e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 523us/step - loss: 9.7183e-04 - val_loss: 5.7184e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 529us/step - loss: 9.7606e-04 - val_loss: 5.0472e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 528us/step - loss: 9.9055e-04 - val_loss: 5.8458e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 527us/step - loss: 9.3130e-04 - val_loss: 5.7894e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 521us/step - loss: 9.3959e-04 - val_loss: 5.2411e-04\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 524us/step - loss: 9.4390e-04 - val_loss: 6.0292e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 526us/step - loss: 8.9295e-04 - val_loss: 5.6653e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 33s 8ms/step - loss: 0.0476 - val_loss: 0.0089\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 0.0074 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0011 - val_loss: 7.6656e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 8.9133e-04 - val_loss: 6.1164e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 7.6658e-04 - val_loss: 5.6977e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 7.0435e-04 - val_loss: 6.1990e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 6.4314e-04 - val_loss: 6.9882e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 6.1779e-04 - val_loss: 6.8213e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 5.9243e-04 - val_loss: 5.4533e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 5.5157e-04 - val_loss: 4.6720e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 5.5445e-04 - val_loss: 4.6933e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 5.3194e-04 - val_loss: 4.5691e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 5.1867e-04 - val_loss: 5.2352e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 5.2548e-04 - val_loss: 4.6359e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 5.0536e-04 - val_loss: 4.6464e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 5.0071e-04 - val_loss: 4.4040e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 5.0934e-04 - val_loss: 4.5224e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 4.9162e-04 - val_loss: 4.3341e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 4.9064e-04 - val_loss: 4.3526e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 4.8717e-04 - val_loss: 4.3351e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 4.8141e-04 - val_loss: 4.3119e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 34s 8ms/step - loss: 0.0541 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0076 - val_loss: 0.0026\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0049 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0028 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0012 - val_loss: 8.4090e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 8.3724e-04 - val_loss: 6.3748e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 6.1284e-04 - val_loss: 5.4386e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 5.4829e-04 - val_loss: 4.8295e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 5.6553e-04 - val_loss: 4.6686e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 5.3325e-04 - val_loss: 5.0953e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 5.2735e-04 - val_loss: 4.8415e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 5.2509e-04 - val_loss: 5.5530e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 5.1579e-04 - val_loss: 4.6479e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 5.1299e-04 - val_loss: 5.8785e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 5.0065e-04 - val_loss: 4.8847e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 5.0755e-04 - val_loss: 4.3041e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 4.8706e-04 - val_loss: 9.4249e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 5.5127e-04 - val_loss: 4.1516e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 4.9097e-04 - val_loss: 6.0230e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 4.7355e-04 - val_loss: 4.0604e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 4.6573e-04 - val_loss: 5.2556e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 4.5945e-04 - val_loss: 4.0904e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 4.5181e-04 - val_loss: 3.9149e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 34s 8ms/step - loss: 0.1348 - val_loss: 0.0694\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 451us/step - loss: 0.0569 - val_loss: 0.0370\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 0.0493 - val_loss: 0.0278\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0447 - val_loss: 0.0237\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0406 - val_loss: 0.0224\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0366 - val_loss: 0.0203\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0328 - val_loss: 0.0174\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0292 - val_loss: 0.0169\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0256 - val_loss: 0.0138\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0223 - val_loss: 0.0131\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0191 - val_loss: 0.0104\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0163 - val_loss: 0.0082\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0138 - val_loss: 0.0059\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0115 - val_loss: 0.0044\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0097 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0081 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0069 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0034 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 0.0031 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 34s 8ms/step - loss: 0.0812 - val_loss: 0.0328\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 0.0414 - val_loss: 0.0262\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0365 - val_loss: 0.0199\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0317 - val_loss: 0.0153\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0269 - val_loss: 0.0132\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0222 - val_loss: 0.0097\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0179 - val_loss: 0.0092\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0142 - val_loss: 0.0069\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0113 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0090 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0073 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0051 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0032 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 35s 8ms/step - loss: 0.2553 - val_loss: 0.1792\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 0.0922 - val_loss: 0.0761\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0680 - val_loss: 0.0526\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0652 - val_loss: 0.0452\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0648 - val_loss: 0.0421\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0647 - val_loss: 0.0432\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0647 - val_loss: 0.0384\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0647 - val_loss: 0.0390\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0647 - val_loss: 0.0405\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0647 - val_loss: 0.0394\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0647 - val_loss: 0.0413\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 0.0647 - val_loss: 0.0417\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 0.0647 - val_loss: 0.0407\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0647 - val_loss: 0.0403\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0647 - val_loss: 0.0417\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0647 - val_loss: 0.0412\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0647 - val_loss: 0.0430\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 0.0647 - val_loss: 0.0411\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 0.0647 - val_loss: 0.0416\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 0.0647 - val_loss: 0.0417\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0647 - val_loss: 0.0424\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 0.0647 - val_loss: 0.0432\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 0.0647 - val_loss: 0.0416\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: 0.0647 - val_loss: 0.0392\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 36s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 36s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: nan - val_loss: nan\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 37s 9ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 599us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 37s 9ms/step - loss: 0.1202 - val_loss: 0.0174\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0477 - val_loss: 0.0080\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0315 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0220 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0148 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0116 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0091 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0075 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0069 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 0.0068 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0063 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0057 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0059 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0057 - val_loss: 0.0044\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 0.0053 - val_loss: 0.0049\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0052 - val_loss: 0.0042\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0052 - val_loss: 0.0027\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0049 - val_loss: 0.0040\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 0.0048 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0045 - val_loss: 0.0037\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 36s 9ms/step - loss: 0.0763 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0082 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 0.0036 - val_loss: 5.7952e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0023 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 0.0015 - val_loss: 9.7439e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 0.0011 - val_loss: 5.1252e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 9.5157e-04 - val_loss: 7.4687e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 8.4025e-04 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 7.4777e-04 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 6.7774e-04 - val_loss: 8.2376e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 6.3064e-04 - val_loss: 5.7728e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 440us/step - loss: 5.8869e-04 - val_loss: 5.4179e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 5.6002e-04 - val_loss: 6.1093e-04\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 432us/step - loss: 5.5152e-04 - val_loss: 6.0154e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 5.2718e-04 - val_loss: 5.4404e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 5.1783e-04 - val_loss: 5.0319e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 5.0195e-04 - val_loss: 4.5802e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 4.9395e-04 - val_loss: 4.2989e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 4.8412e-04 - val_loss: 4.3849e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 4.8291e-04 - val_loss: 4.4230e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 442us/step - loss: 4.7477e-04 - val_loss: 4.1626e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 4.7683e-04 - val_loss: 4.1090e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 4.7181e-04 - val_loss: 4.9708e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 4.6796e-04 - val_loss: 4.0591e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 37s 9ms/step - loss: 0.0696 - val_loss: 0.0076\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0084 - val_loss: 0.0071\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 0.0045 - val_loss: 0.0075\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0014 - val_loss: 5.5604e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0010 - val_loss: 7.4755e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 8.3918e-04 - val_loss: 9.3213e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 7.3648e-04 - val_loss: 8.7280e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 6.6521e-04 - val_loss: 6.8701e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 6.1594e-04 - val_loss: 6.0868e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 5.7839e-04 - val_loss: 5.3845e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 429us/step - loss: 5.4786e-04 - val_loss: 7.0835e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 5.4888e-04 - val_loss: 5.9401e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 5.1326e-04 - val_loss: 5.8851e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 5.0635e-04 - val_loss: 5.8851e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 4.9332e-04 - val_loss: 5.3747e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 4.8509e-04 - val_loss: 4.2235e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 4.8828e-04 - val_loss: 4.3987e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 4.8620e-04 - val_loss: 4.1567e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 426us/step - loss: 4.7061e-04 - val_loss: 4.5677e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 425us/step - loss: 4.6161e-04 - val_loss: 4.1380e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 4.5687e-04 - val_loss: 4.0696e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 4.5133e-04 - val_loss: 4.2760e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 4.4788e-04 - val_loss: 4.3998e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 37s 9ms/step - loss: 0.0611 - val_loss: 0.0077\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0086 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 455us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 447us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0010 - val_loss: 8.5543e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 8.2978e-04 - val_loss: 4.7054e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 7.0723e-04 - val_loss: 4.5951e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 6.6653e-04 - val_loss: 5.0058e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 6.3590e-04 - val_loss: 5.4616e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 6.2636e-04 - val_loss: 5.5054e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 5.8948e-04 - val_loss: 5.5263e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 5.6396e-04 - val_loss: 4.5918e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 439us/step - loss: 5.6720e-04 - val_loss: 4.3765e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 5.4981e-04 - val_loss: 4.3072e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 5.2873e-04 - val_loss: 4.3131e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 5.1704e-04 - val_loss: 4.3600e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 4.9731e-04 - val_loss: 4.4363e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 4.8964e-04 - val_loss: 5.4869e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 5.0384e-04 - val_loss: 5.6867e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 4.9622e-04 - val_loss: 4.4802e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 437us/step - loss: 4.7502e-04 - val_loss: 4.1925e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 4.8721e-04 - val_loss: 4.2516e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 4.6333e-04 - val_loss: 4.4826e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 38s 9ms/step - loss: 0.0738 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 0.0032 - val_loss: 5.4971e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 441us/step - loss: 0.0019 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 9.8272e-04 - val_loss: 7.1712e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 8.0146e-04 - val_loss: 5.4182e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 7.4516e-04 - val_loss: 5.4939e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 6.7880e-04 - val_loss: 5.0521e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 6.3464e-04 - val_loss: 4.8925e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 6.0158e-04 - val_loss: 5.2026e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 5.6125e-04 - val_loss: 5.5695e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 438us/step - loss: 5.4921e-04 - val_loss: 6.9781e-04\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 435us/step - loss: 5.4444e-04 - val_loss: 6.1961e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 5.2198e-04 - val_loss: 5.3070e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 5.0557e-04 - val_loss: 4.2802e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 430us/step - loss: 5.0746e-04 - val_loss: 4.3409e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 4.9351e-04 - val_loss: 4.9450e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 4.8892e-04 - val_loss: 5.0194e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 435us/step - loss: 4.8278e-04 - val_loss: 4.1766e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 432us/step - loss: 4.7466e-04 - val_loss: 4.1358e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 436us/step - loss: 4.6738e-04 - val_loss: 4.1172e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 433us/step - loss: 4.6468e-04 - val_loss: 4.4561e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 434us/step - loss: 4.6812e-04 - val_loss: 4.0629e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 40s 10ms/step - loss: 0.0468 - val_loss: 0.0207\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0063 - val_loss: 0.0085\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 597us/step - loss: 0.0030 - val_loss: 9.0585e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 0.0015 - val_loss: 8.2681e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 590us/step - loss: 0.0012 - val_loss: 5.0768e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 8.8731e-04 - val_loss: 6.6138e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 7.2538e-04 - val_loss: 7.0665e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 629us/step - loss: 6.3090e-04 - val_loss: 6.7734e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 5.7903e-04 - val_loss: 6.4573e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 5.4634e-04 - val_loss: 5.6933e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 5.1892e-04 - val_loss: 5.0605e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 5.0209e-04 - val_loss: 4.4623e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 4.8909e-04 - val_loss: 4.3143e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 4.8038e-04 - val_loss: 4.2038e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 4.8192e-04 - val_loss: 4.8891e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 4.8058e-04 - val_loss: 4.8295e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 4.7560e-04 - val_loss: 4.1437e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 4.6201e-04 - val_loss: 4.3403e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 4.5538e-04 - val_loss: 5.2976e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 5.7174e-04 - val_loss: 7.9682e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 5.3509e-04 - val_loss: 4.2606e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 4.5340e-04 - val_loss: 4.2578e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 4.5090e-04 - val_loss: 5.1271e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 4.7142e-04 - val_loss: 3.8594e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 39s 10ms/step - loss: 0.0882 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0081 - val_loss: 0.0108\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0020 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0014 - val_loss: 6.4660e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 9.5789e-04 - val_loss: 5.0329e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 8.4872e-04 - val_loss: 6.2496e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 7.4125e-04 - val_loss: 7.6973e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 6.8988e-04 - val_loss: 7.7301e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 6.4361e-04 - val_loss: 5.7707e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 6.1277e-04 - val_loss: 5.4976e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 5.9466e-04 - val_loss: 5.0473e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 5.8111e-04 - val_loss: 5.0487e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 5.4884e-04 - val_loss: 6.2587e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 5.4501e-04 - val_loss: 6.4870e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 5.4076e-04 - val_loss: 4.6908e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 5.1460e-04 - val_loss: 4.4322e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 5.0858e-04 - val_loss: 4.6477e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 5.0077e-04 - val_loss: 4.3984e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 4.9651e-04 - val_loss: 4.5461e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 4.9408e-04 - val_loss: 4.7507e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 4.8883e-04 - val_loss: 4.3713e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 5.0380e-04 - val_loss: 4.2769e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 4.8544e-04 - val_loss: 5.6233e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 41s 10ms/step - loss: 0.0583 - val_loss: 0.0112\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0100 - val_loss: 7.9476e-04\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 587us/step - loss: 0.0020 - val_loss: 6.0085e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 6.0155e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0017 - val_loss: 5.9669e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0017 - val_loss: 5.2964e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 4.6732e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 4.7407e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 0.0015 - val_loss: 4.7847e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 0.0015 - val_loss: 4.6056e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 7.1514e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 6.1053e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0013 - val_loss: 4.5681e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0013 - val_loss: 4.7011e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 6.4228e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 0.0012 - val_loss: 5.3115e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0012 - val_loss: 4.8093e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 9.7696e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0011 - val_loss: 4.5567e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 41s 10ms/step - loss: 0.1968 - val_loss: 0.0533\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0725 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0768 - val_loss: 0.0276\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 0.0651 - val_loss: 0.0601\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0665 - val_loss: 0.0464\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0648 - val_loss: 0.0309\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0649 - val_loss: 0.0382\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0641 - val_loss: 0.0438\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0625 - val_loss: 0.0341\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0637 - val_loss: 0.0345\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 590us/step - loss: 0.0647 - val_loss: 0.0434\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0648 - val_loss: 0.0409\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 0.0644 - val_loss: 0.0346\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 0.0601 - val_loss: 0.0624\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 0.0506 - val_loss: 0.0679\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 0.0418 - val_loss: 0.0075\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0508 - val_loss: 0.0282\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0391 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 0.0252 - val_loss: 0.0138\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0196 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 582us/step - loss: 0.0116 - val_loss: 0.0132\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0091 - val_loss: 0.0053\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 0.0064 - val_loss: 0.0048\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 41s 10ms/step - loss: 0.0878 - val_loss: 0.0114\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 0.0310 - val_loss: 0.0144\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 0.0086 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0021 - val_loss: 9.0440e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 421us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 0.0011 - val_loss: 7.6613e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 9.7472e-04 - val_loss: 7.8172e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 9.0645e-04 - val_loss: 6.4413e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 8.6955e-04 - val_loss: 7.2216e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 428us/step - loss: 8.4159e-04 - val_loss: 9.7710e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 8.7319e-04 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 427us/step - loss: 8.8371e-04 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 0.0010 - val_loss: 6.5083e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 8.6467e-04 - val_loss: 6.6617e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 8.4124e-04 - val_loss: 6.0772e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 7.9196e-04 - val_loss: 5.4907e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 7.2536e-04 - val_loss: 5.6239e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 6.8749e-04 - val_loss: 5.5014e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 422us/step - loss: 6.6847e-04 - val_loss: 5.4587e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 424us/step - loss: 6.5301e-04 - val_loss: 5.2150e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 420us/step - loss: 6.4989e-04 - val_loss: 6.0978e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 6.8697e-04 - val_loss: 5.0082e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 42s 10ms/step - loss: 0.0612 - val_loss: 0.0079\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0092 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0011 - val_loss: 9.2645e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 8.3292e-04 - val_loss: 7.5876e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 7.1097e-04 - val_loss: 6.5090e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 6.3824e-04 - val_loss: 4.9308e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 5.9650e-04 - val_loss: 5.2629e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 5.5441e-04 - val_loss: 4.9972e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 5.3629e-04 - val_loss: 4.9665e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 5.1266e-04 - val_loss: 4.7625e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 5.0474e-04 - val_loss: 4.5604e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 4.9344e-04 - val_loss: 4.4230e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 4.8892e-04 - val_loss: 5.1953e-04\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 565us/step - loss: 4.9810e-04 - val_loss: 4.3571e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 4.8933e-04 - val_loss: 4.2931e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 4.7403e-04 - val_loss: 4.4128e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 4.7266e-04 - val_loss: 4.2316e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 4.6445e-04 - val_loss: 4.7153e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 4.7970e-04 - val_loss: 4.3958e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 4.6593e-04 - val_loss: 4.1908e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 4.6478e-04 - val_loss: 4.1037e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 41s 10ms/step - loss: 0.0743 - val_loss: 0.0348\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 0.0125 - val_loss: 0.0111\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 399us/step - loss: 0.0019 - val_loss: 0.0040\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 399us/step - loss: 0.0012 - val_loss: 5.0051e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 388us/step - loss: 9.5169e-04 - val_loss: 8.4561e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 8.1320e-04 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 387us/step - loss: 7.6561e-04 - val_loss: 5.2068e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 388us/step - loss: 7.0212e-04 - val_loss: 8.6613e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 6.6521e-04 - val_loss: 6.5003e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 387us/step - loss: 6.3314e-04 - val_loss: 6.1926e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 392us/step - loss: 6.1326e-04 - val_loss: 5.2495e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 393us/step - loss: 5.9758e-04 - val_loss: 5.3982e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 5.9108e-04 - val_loss: 7.4763e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 5.8525e-04 - val_loss: 5.6211e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 5.5726e-04 - val_loss: 4.6690e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 389us/step - loss: 5.5385e-04 - val_loss: 5.2754e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 393us/step - loss: 5.3709e-04 - val_loss: 5.0349e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 5.2879e-04 - val_loss: 4.9526e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 5.2268e-04 - val_loss: 5.4452e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 5.2343e-04 - val_loss: 4.8564e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 388us/step - loss: 5.1125e-04 - val_loss: 4.4639e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 394us/step - loss: 5.1304e-04 - val_loss: 4.6120e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 5.0231e-04 - val_loss: 4.8263e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 43s 10ms/step - loss: 0.0637 - val_loss: 0.0357\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 393us/step - loss: 0.0111 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 0.0034 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 392us/step - loss: 0.0020 - val_loss: 6.5896e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 388us/step - loss: 8.6738e-04 - val_loss: 7.4172e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 7.7428e-04 - val_loss: 5.9189e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 7.0891e-04 - val_loss: 6.6747e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 398us/step - loss: 6.5662e-04 - val_loss: 6.4475e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 389us/step - loss: 6.2214e-04 - val_loss: 5.5887e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 394us/step - loss: 5.9603e-04 - val_loss: 5.5131e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 389us/step - loss: 5.7839e-04 - val_loss: 5.4326e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 5.6286e-04 - val_loss: 5.0726e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 393us/step - loss: 5.5142e-04 - val_loss: 4.6970e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 394us/step - loss: 5.5152e-04 - val_loss: 4.6135e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 393us/step - loss: 5.3352e-04 - val_loss: 5.2546e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 394us/step - loss: 5.2667e-04 - val_loss: 4.5369e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 398us/step - loss: 5.2290e-04 - val_loss: 4.4987e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 396us/step - loss: 5.1336e-04 - val_loss: 4.5221e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 391us/step - loss: 5.0633e-04 - val_loss: 4.4461e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 5.1079e-04 - val_loss: 4.4924e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 394us/step - loss: 5.1063e-04 - val_loss: 4.5527e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 390us/step - loss: 4.8807e-04 - val_loss: 4.3113e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 43s 10ms/step - loss: 0.0871 - val_loss: 9.9727e-04\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0122 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0080 - val_loss: 0.0114\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0104 - val_loss: 0.0097\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0100 - val_loss: 0.0097\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0102 - val_loss: 0.0177\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.0070 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0088 - val_loss: 0.0123\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0082 - val_loss: 5.6881e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 0.0066 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0066 - val_loss: 0.0115\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0047 - val_loss: 0.0087\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0097 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0026 - val_loss: 0.0278\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0053 - val_loss: 0.0276\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0055 - val_loss: 5.2326e-04\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0042 - val_loss: 0.0109\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 0.0042 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.0051 - val_loss: 0.0125\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 477us/step - loss: 0.0046 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0026 - val_loss: 0.0154\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 43s 10ms/step - loss: 1.9445 - val_loss: 1.5407\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.9376 - val_loss: 0.9240\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.5362 - val_loss: 0.5679\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.3093 - val_loss: 0.3433\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.1789 - val_loss: 0.1976\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 474us/step - loss: 0.1075 - val_loss: 0.1109\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0762 - val_loss: 0.0690\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 0.0669 - val_loss: 0.0466\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 0.0648 - val_loss: 0.0441\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0648 - val_loss: 0.0341\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0648 - val_loss: 0.0441\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 0.0647 - val_loss: 0.0466\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0648 - val_loss: 0.0356\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 466us/step - loss: 0.0649 - val_loss: 0.0550\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0651 - val_loss: 0.0441\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: 0.0648 - val_loss: 0.0278\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0649 - val_loss: 0.0583\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 466us/step - loss: 0.0650 - val_loss: 0.0351\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.0539 - val_loss: 0.0088\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.0321 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 476us/step - loss: 0.0182 - val_loss: 0.0076\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 0.0174 - val_loss: 0.0127\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0096 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0111 - val_loss: 0.0187\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 43s 10ms/step - loss: 0.1136 - val_loss: 0.0758\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.0672 - val_loss: 0.0434\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: 0.0647 - val_loss: 0.0373\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0646 - val_loss: 0.0399\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0646 - val_loss: 0.0389\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 473us/step - loss: 0.0646 - val_loss: 0.0387\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 465us/step - loss: 0.0646 - val_loss: 0.0385\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.0646 - val_loss: 0.0403\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0646 - val_loss: 0.0388\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0646 - val_loss: 0.0421\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 466us/step - loss: 0.0646 - val_loss: 0.0392\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0646 - val_loss: 0.0439\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 475us/step - loss: 0.0647 - val_loss: 0.0390\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0646 - val_loss: 0.0395\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: 0.0646 - val_loss: 0.0357\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0647 - val_loss: 0.0420\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: 0.0646 - val_loss: 0.0370\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 465us/step - loss: 0.0646 - val_loss: 0.0400\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 465us/step - loss: 0.0646 - val_loss: 0.0394\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 472us/step - loss: 0.0646 - val_loss: 0.0405\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: 0.0646 - val_loss: 0.0380\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.0646 - val_loss: 0.0403\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: 0.0646 - val_loss: 0.0379\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: 0.0646 - val_loss: 0.0394\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 45s 11ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 488us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 466us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 465us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 466us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 465us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 465us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 462us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 464us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 461us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 471us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 469us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 467us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 463us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 470us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 468us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 472us/step - loss: nan - val_loss: nan\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 43s 10ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 3s 609us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 3s 610us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 3s 608us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 46s 11ms/step - loss: 0.0430 - val_loss: 0.0166\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0026 - val_loss: 4.9366e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 8.1486e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0010 - val_loss: 4.8364e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 7.9596e-04 - val_loss: 6.0216e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 6.8023e-04 - val_loss: 6.7338e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 5.8846e-04 - val_loss: 6.2393e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 5.6058e-04 - val_loss: 6.4122e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 5.4910e-04 - val_loss: 5.5878e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 5.2958e-04 - val_loss: 4.3703e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 5.2570e-04 - val_loss: 4.4101e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 5.1752e-04 - val_loss: 5.1265e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 5.1081e-04 - val_loss: 4.3880e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 4.9546e-04 - val_loss: 4.6203e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 4.9401e-04 - val_loss: 4.2524e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 4.7819e-04 - val_loss: 5.3844e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 4.7903e-04 - val_loss: 4.1147e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 4.6483e-04 - val_loss: 4.0516e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 542us/step - loss: 4.4885e-04 - val_loss: 4.0064e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 4.5791e-04 - val_loss: 5.1849e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 4.7035e-04 - val_loss: 4.0968e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 4.5063e-04 - val_loss: 3.8728e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 4.5288e-04 - val_loss: 5.4745e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 45s 11ms/step - loss: 0.0669 - val_loss: 0.0111\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 0.0096 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 0.0021 - val_loss: 5.1463e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 9.6707e-04 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 8.2910e-04 - val_loss: 9.2816e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 6.9176e-04 - val_loss: 6.0535e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 6.3901e-04 - val_loss: 4.5603e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 5.6747e-04 - val_loss: 4.6553e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 5.3293e-04 - val_loss: 4.1866e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 5.3286e-04 - val_loss: 4.1697e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 4.9892e-04 - val_loss: 4.3862e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 4.7632e-04 - val_loss: 4.1322e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 4.6833e-04 - val_loss: 4.0733e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 4.6274e-04 - val_loss: 4.2852e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 4.5589e-04 - val_loss: 4.0456e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 4.5250e-04 - val_loss: 4.0106e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 4.4761e-04 - val_loss: 4.5336e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 4.5190e-04 - val_loss: 4.4223e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 4.5263e-04 - val_loss: 3.9186e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 4.3777e-04 - val_loss: 4.0123e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 4.4245e-04 - val_loss: 4.0608e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 4.3156e-04 - val_loss: 3.9832e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 47s 11ms/step - loss: 0.0533 - val_loss: 0.0173\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 590us/step - loss: 0.0054 - val_loss: 0.0125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0018 - val_loss: 9.2626e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 0.0010 - val_loss: 5.5221e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 7.9258e-04 - val_loss: 4.7228e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 6.9878e-04 - val_loss: 5.0536e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 6.0508e-04 - val_loss: 5.8334e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 5.7248e-04 - val_loss: 4.8641e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 5.3523e-04 - val_loss: 4.7282e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 5.2050e-04 - val_loss: 4.3725e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 5.2726e-04 - val_loss: 4.3029e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 5.0856e-04 - val_loss: 4.4438e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 4.9343e-04 - val_loss: 4.4882e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 4.8623e-04 - val_loss: 4.4923e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 4.8300e-04 - val_loss: 4.1479e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 4.7434e-04 - val_loss: 5.0323e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 4.8360e-04 - val_loss: 4.2064e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 4.6645e-04 - val_loss: 4.0458e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 4.6699e-04 - val_loss: 4.0748e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 4.6141e-04 - val_loss: 4.1248e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 587us/step - loss: 4.5783e-04 - val_loss: 4.9563e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 4.5342e-04 - val_loss: 3.9348e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 4.6554e-04 - val_loss: 3.9848e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 45s 11ms/step - loss: 0.0512 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0066 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 0.0027 - val_loss: 6.3628e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 0.0018 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 9.6800e-04 - val_loss: 4.9686e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 8.1367e-04 - val_loss: 5.6815e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 7.1350e-04 - val_loss: 7.6089e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 6.5846e-04 - val_loss: 9.3426e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 6.3920e-04 - val_loss: 6.1004e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 5.9696e-04 - val_loss: 5.6220e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 5.7205e-04 - val_loss: 5.9030e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 5.6246e-04 - val_loss: 6.5516e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 5.5293e-04 - val_loss: 5.5212e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 5.2918e-04 - val_loss: 5.3897e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 5.2439e-04 - val_loss: 4.5143e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 5.0775e-04 - val_loss: 4.5932e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 5.1140e-04 - val_loss: 5.7548e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 5.0674e-04 - val_loss: 4.3730e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 4.8969e-04 - val_loss: 4.2628e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 4.9925e-04 - val_loss: 5.0609e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 5.0872e-04 - val_loss: 4.2539e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 4.9330e-04 - val_loss: 4.1967e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 4.7371e-04 - val_loss: 4.1252e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 47s 11ms/step - loss: 0.0600 - val_loss: 0.0061\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 0.0017 - val_loss: 8.7313e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 0.0011 - val_loss: 5.2750e-04\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 405us/step - loss: 8.5828e-04 - val_loss: 5.1796e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 7.7579e-04 - val_loss: 7.8320e-04\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 6.6942e-04 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 418us/step - loss: 6.4486e-04 - val_loss: 7.3831e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 6.2303e-04 - val_loss: 6.6838e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 5.9829e-04 - val_loss: 5.2154e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 5.7907e-04 - val_loss: 5.0258e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 5.6605e-04 - val_loss: 4.6219e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 5.5796e-04 - val_loss: 4.7253e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 5.4820e-04 - val_loss: 4.7529e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 5.4491e-04 - val_loss: 4.5544e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 5.4161e-04 - val_loss: 4.4530e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 5.4279e-04 - val_loss: 4.8235e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 407us/step - loss: 5.3110e-04 - val_loss: 4.5279e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 5.2028e-04 - val_loss: 4.4349e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 5.1977e-04 - val_loss: 4.4068e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 5.1352e-04 - val_loss: 4.3776e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 406us/step - loss: 5.1869e-04 - val_loss: 4.5410e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 5.3669e-04 - val_loss: 4.4034e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 5.1711e-04 - val_loss: 4.3617e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 46s 11ms/step - loss: 0.0673 - val_loss: 0.0204\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 0.0086 - val_loss: 0.0055\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 410us/step - loss: 0.0028 - val_loss: 9.7943e-04\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 0.0013 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 0.0011 - val_loss: 8.1785e-04\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 9.5957e-04 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 8.8147e-04 - val_loss: 9.1367e-04\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 8.2812e-04 - val_loss: 8.1402e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 410us/step - loss: 7.8110e-04 - val_loss: 8.3560e-04\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 7.4986e-04 - val_loss: 7.7519e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 7.3052e-04 - val_loss: 7.8974e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 408us/step - loss: 7.1263e-04 - val_loss: 7.1372e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 416us/step - loss: 6.9791e-04 - val_loss: 7.3412e-04\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 409us/step - loss: 6.8391e-04 - val_loss: 7.4289e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 415us/step - loss: 6.7723e-04 - val_loss: 6.1216e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 446us/step - loss: 6.6510e-04 - val_loss: 6.8329e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 431us/step - loss: 6.5491e-04 - val_loss: 6.7664e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 419us/step - loss: 6.4885e-04 - val_loss: 5.9120e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 413us/step - loss: 6.4093e-04 - val_loss: 6.9423e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 412us/step - loss: 6.3660e-04 - val_loss: 5.9070e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 6.2919e-04 - val_loss: 5.9950e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 411us/step - loss: 6.2256e-04 - val_loss: 5.9334e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 417us/step - loss: 6.1709e-04 - val_loss: 5.6224e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 414us/step - loss: 6.1300e-04 - val_loss: 5.7931e-04\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 49s 12ms/step - loss: 0.0654 - val_loss: 0.0435\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0578 - val_loss: 0.0229\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0418 - val_loss: 0.0088\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0225 - val_loss: 0.0100\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0231 - val_loss: 0.0828\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0322 - val_loss: 0.0756\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0364 - val_loss: 0.0738\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0312 - val_loss: 0.0510\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 548us/step - loss: 0.0185 - val_loss: 0.0213\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 0.0167 - val_loss: 0.0264\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0164 - val_loss: 0.0178\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 555us/step - loss: 0.0162 - val_loss: 0.0212\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0162 - val_loss: 0.0220\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0162 - val_loss: 0.0213\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0161 - val_loss: 0.0225\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 556us/step - loss: 0.0161 - val_loss: 0.0221\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 0.0157 - val_loss: 0.0207\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 551us/step - loss: 0.0148 - val_loss: 0.0199\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0167 - val_loss: 0.0112\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 550us/step - loss: 0.0194 - val_loss: 0.0069\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 549us/step - loss: 0.0198 - val_loss: 0.0064\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 553us/step - loss: 0.0197 - val_loss: 0.0052\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0170 - val_loss: 0.0068\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 554us/step - loss: 0.0122 - val_loss: 0.0074\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 48s 12ms/step - loss: 1.2275 - val_loss: 0.6026\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.2318 - val_loss: 0.1277\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0733 - val_loss: 0.0322\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0674 - val_loss: 0.0165\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0709 - val_loss: 0.0176\n",
      "Epoch 6/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0687 - val_loss: 0.0243\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0660 - val_loss: 0.0320\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0649 - val_loss: 0.0390\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 546us/step - loss: 0.0647 - val_loss: 0.0418\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0647 - val_loss: 0.0414\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0647 - val_loss: 0.0412\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0403\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0647 - val_loss: 0.0393\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 539us/step - loss: 0.0647 - val_loss: 0.0393\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0400\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 547us/step - loss: 0.0647 - val_loss: 0.0403\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 541us/step - loss: 0.0647 - val_loss: 0.0401\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0647 - val_loss: 0.0401\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0647 - val_loss: 0.0407\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 544us/step - loss: 0.0647 - val_loss: 0.0413\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 540us/step - loss: 0.0647 - val_loss: 0.0416\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 537us/step - loss: 0.0647 - val_loss: 0.0406\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 543us/step - loss: 0.0647 - val_loss: 0.0397\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 545us/step - loss: 0.0647 - val_loss: 0.0389\n",
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/24\n",
      "4143/4143 [==============================] - 50s 12ms/step - loss: 0.0775 - val_loss: 0.0171\n",
      "Epoch 2/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0608 - val_loss: 0.0204\n",
      "Epoch 3/24\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0389 - val_loss: 0.0083\n",
      "Epoch 4/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 0.0208 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0104 - val_loss: 0.0027\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 564us/step - loss: 0.0049 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0021 - val_loss: 8.4112e-04\n",
      "Epoch 9/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0016 - val_loss: 6.9461e-04\n",
      "Epoch 11/24\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 0.0013 - val_loss: 6.8612e-04\n",
      "Epoch 12/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 0.0013 - val_loss: 6.0955e-04\n",
      "Epoch 13/24\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 0.0011 - val_loss: 7.8087e-04\n",
      "Epoch 15/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 0.0011 - val_loss: 7.2782e-04\n",
      "Epoch 16/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 9.7459e-04 - val_loss: 6.1461e-04\n",
      "Epoch 17/24\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 9.4553e-04 - val_loss: 6.3063e-04\n",
      "Epoch 18/24\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 8.9016e-04 - val_loss: 9.5216e-04\n",
      "Epoch 19/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 9.2666e-04 - val_loss: 6.5760e-04\n",
      "Epoch 20/24\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 9.0594e-04 - val_loss: 6.8028e-04\n",
      "Epoch 21/24\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 8.9488e-04 - val_loss: 5.4346e-04\n",
      "Epoch 22/24\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 8.3713e-04 - val_loss: 5.3836e-04\n",
      "Epoch 23/24\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 9.1133e-04 - val_loss: 9.2313e-04\n",
      "Epoch 24/24\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 8.4824e-04 - val_loss: 5.2156e-04\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.011100241914391518,\n",
       " 0.0010743837337940931,\n",
       " 0.001818343997001648,\n",
       " 0.0005146319745108485,\n",
       " 0.0019472717540338635,\n",
       " 0.0017510500038042665,\n",
       " 0.0009281559032388031,\n",
       " 0.0006053462857380509,\n",
       " 0.0004560344386845827,\n",
       " 0.00046552595449611545,\n",
       " 0.00041865697130560875,\n",
       " 0.00041696810512803495,\n",
       " 0.00043861972517333925,\n",
       " 0.00041321778553538024,\n",
       " 0.0004073278687428683,\n",
       " 0.0004285174945835024,\n",
       " 0.00040456451824866235,\n",
       " 0.00040106126107275486,\n",
       " 0.00045335679897107184,\n",
       " 0.00044223296572454274,\n",
       " 0.0003918643342331052,\n",
       " 0.0004012266581412405,\n",
       " 0.0004060838546138257,\n",
       " 0.000398316333303228]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "lstmsize: 162\n",
      "twice: True\n",
      "shuffle: True\n",
      "optimizer: adam\n",
      "activation: elu\n",
      "density: 188\n",
      "full_density: True\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_174\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_347 (LSTM)              (None, 92, 162)           108864    \n",
      "_________________________________________________________________\n",
      "lstm_348 (LSTM)              (None, 162)               210600    \n",
      "_________________________________________________________________\n",
      "dense_740 (Dense)            (None, 188)               30644     \n",
      "_________________________________________________________________\n",
      "dense_741 (Dense)            (None, 94)                17766     \n",
      "_________________________________________________________________\n",
      "dense_742 (Dense)            (None, 47)                4465      \n",
      "_________________________________________________________________\n",
      "dense_743 (Dense)            (None, 23)                1104      \n",
      "_________________________________________________________________\n",
      "dense_744 (Dense)            (None, 1)                 24        \n",
      "=================================================================\n",
      "Total params: 373,467\n",
      "Trainable params: 373,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4143 samples, validate on 461 samples\n",
      "Epoch 1/2000\n",
      "4143/4143 [==============================] - 50s 12ms/step - loss: 0.0430 - val_loss: 0.0201\n",
      "Epoch 2/2000\n",
      "4143/4143 [==============================] - 2s 590us/step - loss: 0.0057 - val_loss: 0.0116\n",
      "Epoch 3/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 4/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 0.0015 - val_loss: 5.7558e-04\n",
      "Epoch 5/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 9.6447e-04 - val_loss: 4.7755e-04\n",
      "Epoch 6/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 8.1864e-04 - val_loss: 4.7758e-04\n",
      "Epoch 7/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 7.0433e-04 - val_loss: 4.5196e-04\n",
      "Epoch 8/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 5.9725e-04 - val_loss: 4.4620e-04\n",
      "Epoch 9/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 5.3540e-04 - val_loss: 4.3236e-04\n",
      "Epoch 10/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 5.1197e-04 - val_loss: 4.3124e-04\n",
      "Epoch 11/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 4.9394e-04 - val_loss: 4.7572e-04\n",
      "Epoch 12/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 4.9604e-04 - val_loss: 4.2396e-04\n",
      "Epoch 13/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 4.9497e-04 - val_loss: 4.2325e-04\n",
      "Epoch 14/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 4.8268e-04 - val_loss: 4.5794e-04\n",
      "Epoch 15/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 4.7445e-04 - val_loss: 4.1514e-04\n",
      "Epoch 16/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 4.6350e-04 - val_loss: 4.6604e-04\n",
      "Epoch 17/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 4.6381e-04 - val_loss: 4.1506e-04\n",
      "Epoch 18/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 4.5655e-04 - val_loss: 4.1031e-04\n",
      "Epoch 19/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 4.5178e-04 - val_loss: 4.0302e-04\n",
      "Epoch 20/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 4.5289e-04 - val_loss: 4.0669e-04\n",
      "Epoch 21/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 4.3928e-04 - val_loss: 3.9854e-04\n",
      "Epoch 22/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 4.4341e-04 - val_loss: 3.8681e-04\n",
      "Epoch 23/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 4.4022e-04 - val_loss: 3.9441e-04\n",
      "Epoch 24/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 4.3687e-04 - val_loss: 3.9080e-04\n",
      "Epoch 25/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 4.2936e-04 - val_loss: 4.0255e-04\n",
      "Epoch 26/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 4.3696e-04 - val_loss: 4.1392e-04\n",
      "Epoch 27/2000\n",
      "4143/4143 [==============================] - 2s 587us/step - loss: 4.4462e-04 - val_loss: 3.7290e-04\n",
      "Epoch 28/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 4.2097e-04 - val_loss: 4.0903e-04\n",
      "Epoch 29/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 4.3043e-04 - val_loss: 3.7342e-04\n",
      "Epoch 30/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 4.3017e-04 - val_loss: 4.1152e-04\n",
      "Epoch 31/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 4.1490e-04 - val_loss: 4.0239e-04\n",
      "Epoch 32/2000\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 4.1877e-04 - val_loss: 5.4155e-04\n",
      "Epoch 33/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 4.6810e-04 - val_loss: 3.5571e-04\n",
      "Epoch 34/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 3.9866e-04 - val_loss: 4.4916e-04\n",
      "Epoch 35/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 4.2013e-04 - val_loss: 3.4866e-04\n",
      "Epoch 36/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 3.9204e-04 - val_loss: 3.4451e-04\n",
      "Epoch 37/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 3.8698e-04 - val_loss: 3.5342e-04\n",
      "Epoch 38/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 3.9464e-04 - val_loss: 3.4775e-04\n",
      "Epoch 39/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 3.7726e-04 - val_loss: 3.3727e-04\n",
      "Epoch 40/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 3.7798e-04 - val_loss: 8.5929e-04\n",
      "Epoch 41/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 5.2996e-04 - val_loss: 3.5360e-04\n",
      "Epoch 42/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 3.7910e-04 - val_loss: 3.3526e-04\n",
      "Epoch 43/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 3.8306e-04 - val_loss: 3.5070e-04\n",
      "Epoch 44/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 3.9443e-04 - val_loss: 5.2018e-04\n",
      "Epoch 45/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 4.4886e-04 - val_loss: 7.7503e-04\n",
      "Epoch 46/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 5.1719e-04 - val_loss: 3.3482e-04\n",
      "Epoch 47/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 4.2825e-04 - val_loss: 3.4058e-04\n",
      "Epoch 48/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 3.8108e-04 - val_loss: 3.2130e-04\n",
      "Epoch 49/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 3.7024e-04 - val_loss: 3.3231e-04\n",
      "Epoch 50/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 3.5874e-04 - val_loss: 3.4921e-04\n",
      "Epoch 51/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 3.5978e-04 - val_loss: 3.2737e-04\n",
      "Epoch 52/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 3.5535e-04 - val_loss: 3.1255e-04\n",
      "Epoch 53/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 3.5800e-04 - val_loss: 4.9896e-04\n",
      "Epoch 54/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 3.7224e-04 - val_loss: 3.2835e-04\n",
      "Epoch 55/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 3.4808e-04 - val_loss: 4.7659e-04\n",
      "Epoch 56/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 3.8545e-04 - val_loss: 3.1615e-04\n",
      "Epoch 57/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 3.5151e-04 - val_loss: 6.1948e-04\n",
      "Epoch 58/2000\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 4.3879e-04 - val_loss: 2.9823e-04\n",
      "Epoch 59/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 3.3835e-04 - val_loss: 3.9785e-04\n",
      "Epoch 60/2000\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 3.5988e-04 - val_loss: 2.9447e-04\n",
      "Epoch 61/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 3.4591e-04 - val_loss: 3.6072e-04\n",
      "Epoch 62/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 3.4275e-04 - val_loss: 3.2300e-04\n",
      "Epoch 63/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 3.5404e-04 - val_loss: 4.1916e-04\n",
      "Epoch 64/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 3.6907e-04 - val_loss: 5.4111e-04\n",
      "Epoch 65/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 4.2654e-04 - val_loss: 6.3814e-04\n",
      "Epoch 66/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 3.8775e-04 - val_loss: 4.8277e-04\n",
      "Epoch 67/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 3.7191e-04 - val_loss: 3.1524e-04\n",
      "Epoch 68/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 3.2344e-04 - val_loss: 3.3513e-04\n",
      "Epoch 69/2000\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 3.3893e-04 - val_loss: 3.3383e-04\n",
      "Epoch 70/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 3.3276e-04 - val_loss: 3.2582e-04\n",
      "Epoch 71/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 3.2189e-04 - val_loss: 2.9639e-04\n",
      "Epoch 72/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 564us/step - loss: 3.3309e-04 - val_loss: 3.1692e-04\n",
      "Epoch 73/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 3.2575e-04 - val_loss: 3.6364e-04\n",
      "Epoch 74/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 3.3967e-04 - val_loss: 2.9568e-04\n",
      "Epoch 75/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 3.1553e-04 - val_loss: 2.7437e-04\n",
      "Epoch 76/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 3.4687e-04 - val_loss: 2.7462e-04\n",
      "Epoch 77/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 3.5140e-04 - val_loss: 3.0402e-04\n",
      "Epoch 78/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 3.6931e-04 - val_loss: 2.8200e-04\n",
      "Epoch 79/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 3.6328e-04 - val_loss: 2.6495e-04\n",
      "Epoch 80/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 3.0038e-04 - val_loss: 6.6209e-04\n",
      "Epoch 81/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 3.7521e-04 - val_loss: 2.5853e-04\n",
      "Epoch 82/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.9634e-04 - val_loss: 2.5713e-04\n",
      "Epoch 83/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 2.9532e-04 - val_loss: 4.4946e-04\n",
      "Epoch 84/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 3.4847e-04 - val_loss: 2.8377e-04\n",
      "Epoch 85/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 3.0205e-04 - val_loss: 3.0743e-04\n",
      "Epoch 86/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 3.0907e-04 - val_loss: 3.1888e-04\n",
      "Epoch 87/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 3.1901e-04 - val_loss: 3.2286e-04\n",
      "Epoch 88/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 3.0472e-04 - val_loss: 8.1838e-04\n",
      "Epoch 89/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 3.8750e-04 - val_loss: 2.5117e-04\n",
      "Epoch 90/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 2.8396e-04 - val_loss: 2.4915e-04\n",
      "Epoch 91/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 2.9621e-04 - val_loss: 2.4353e-04\n",
      "Epoch 92/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 3.2040e-04 - val_loss: 4.0237e-04\n",
      "Epoch 93/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 3.0268e-04 - val_loss: 4.7796e-04\n",
      "Epoch 94/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 3.4531e-04 - val_loss: 6.1867e-04\n",
      "Epoch 95/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 3.3592e-04 - val_loss: 9.3402e-04\n",
      "Epoch 96/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 5.0642e-04 - val_loss: 3.1375e-04\n",
      "Epoch 97/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 3.3848e-04 - val_loss: 5.2751e-04\n",
      "Epoch 98/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 3.9566e-04 - val_loss: 5.4234e-04\n",
      "Epoch 99/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 3.1321e-04 - val_loss: 2.3196e-04\n",
      "Epoch 100/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 2.7852e-04 - val_loss: 3.5563e-04\n",
      "Epoch 101/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 2.9947e-04 - val_loss: 3.2568e-04\n",
      "Epoch 102/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 3.0984e-04 - val_loss: 2.4124e-04\n",
      "Epoch 103/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.6655e-04 - val_loss: 2.3479e-04\n",
      "Epoch 104/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.6190e-04 - val_loss: 2.8246e-04\n",
      "Epoch 105/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 2.7071e-04 - val_loss: 2.4209e-04\n",
      "Epoch 106/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 2.5876e-04 - val_loss: 2.9464e-04\n",
      "Epoch 107/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.7052e-04 - val_loss: 2.4965e-04\n",
      "Epoch 108/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.6104e-04 - val_loss: 2.9307e-04\n",
      "Epoch 109/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.7118e-04 - val_loss: 2.1756e-04\n",
      "Epoch 110/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 2.5570e-04 - val_loss: 2.2356e-04\n",
      "Epoch 111/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.5653e-04 - val_loss: 2.4109e-04\n",
      "Epoch 112/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.6900e-04 - val_loss: 2.0974e-04\n",
      "Epoch 113/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 3.1319e-04 - val_loss: 7.1015e-04\n",
      "Epoch 114/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 3.3079e-04 - val_loss: 2.0889e-04\n",
      "Epoch 115/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.8312e-04 - val_loss: 2.5119e-04\n",
      "Epoch 116/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 2.6728e-04 - val_loss: 2.3099e-04\n",
      "Epoch 117/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 2.6563e-04 - val_loss: 2.4177e-04\n",
      "Epoch 118/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 2.6038e-04 - val_loss: 2.3492e-04\n",
      "Epoch 119/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.7669e-04 - val_loss: 2.3652e-04\n",
      "Epoch 120/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.3984e-04 - val_loss: 2.0619e-04\n",
      "Epoch 121/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 2.3599e-04 - val_loss: 2.3269e-04\n",
      "Epoch 122/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 2.3787e-04 - val_loss: 1.9535e-04\n",
      "Epoch 123/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 2.3972e-04 - val_loss: 1.9966e-04\n",
      "Epoch 124/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 2.3276e-04 - val_loss: 3.3565e-04\n",
      "Epoch 125/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.7208e-04 - val_loss: 5.7602e-04\n",
      "Epoch 126/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 3.1404e-04 - val_loss: 5.6614e-04\n",
      "Epoch 127/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 3.7092e-04 - val_loss: 2.4163e-04\n",
      "Epoch 128/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 2.8591e-04 - val_loss: 2.5164e-04\n",
      "Epoch 129/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.5043e-04 - val_loss: 2.0891e-04\n",
      "Epoch 130/2000\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 2.4396e-04 - val_loss: 6.6454e-04\n",
      "Epoch 131/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 3.3818e-04 - val_loss: 1.9616e-04\n",
      "Epoch 132/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.5769e-04 - val_loss: 5.0665e-04\n",
      "Epoch 133/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 3.0729e-04 - val_loss: 1.8927e-04\n",
      "Epoch 134/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 2.4577e-04 - val_loss: 2.1733e-04\n",
      "Epoch 135/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.2516e-04 - val_loss: 3.0300e-04\n",
      "Epoch 136/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 2.2831e-04 - val_loss: 2.0318e-04\n",
      "Epoch 137/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 2.2613e-04 - val_loss: 1.8651e-04\n",
      "Epoch 138/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 2.1764e-04 - val_loss: 1.8091e-04\n",
      "Epoch 139/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 2.1600e-04 - val_loss: 1.9277e-04\n",
      "Epoch 140/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 2.0694e-04 - val_loss: 2.0285e-04\n",
      "Epoch 141/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 2.5506e-04 - val_loss: 1.8724e-04\n",
      "Epoch 142/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.1456e-04 - val_loss: 2.1175e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.0874e-04 - val_loss: 1.7148e-04\n",
      "Epoch 144/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 2.0624e-04 - val_loss: 2.2017e-04\n",
      "Epoch 145/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.1362e-04 - val_loss: 2.1270e-04\n",
      "Epoch 146/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.0348e-04 - val_loss: 1.7293e-04\n",
      "Epoch 147/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.9576e-04 - val_loss: 1.8439e-04\n",
      "Epoch 148/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.3187e-04 - val_loss: 5.1378e-04\n",
      "Epoch 149/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 3.3725e-04 - val_loss: 4.2965e-04\n",
      "Epoch 150/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.5920e-04 - val_loss: 1.6744e-04\n",
      "Epoch 151/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 2.0981e-04 - val_loss: 2.6300e-04\n",
      "Epoch 152/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.1197e-04 - val_loss: 1.6488e-04\n",
      "Epoch 153/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.9354e-04 - val_loss: 1.8803e-04\n",
      "Epoch 154/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.8829e-04 - val_loss: 1.6322e-04\n",
      "Epoch 155/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.8811e-04 - val_loss: 1.5921e-04\n",
      "Epoch 156/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.8826e-04 - val_loss: 1.5994e-04\n",
      "Epoch 157/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.9294e-04 - val_loss: 1.9493e-04\n",
      "Epoch 158/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.9067e-04 - val_loss: 1.6810e-04\n",
      "Epoch 159/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.8343e-04 - val_loss: 1.6176e-04\n",
      "Epoch 160/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.9567e-04 - val_loss: 2.3083e-04\n",
      "Epoch 161/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.9089e-04 - val_loss: 1.6562e-04\n",
      "Epoch 162/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.0837e-04 - val_loss: 1.6933e-04\n",
      "Epoch 163/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.8095e-04 - val_loss: 1.6776e-04\n",
      "Epoch 164/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.8169e-04 - val_loss: 2.6771e-04\n",
      "Epoch 165/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.0432e-04 - val_loss: 3.1450e-04\n",
      "Epoch 166/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.9612e-04 - val_loss: 1.5473e-04\n",
      "Epoch 167/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.9287e-04 - val_loss: 1.5189e-04\n",
      "Epoch 168/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7337e-04 - val_loss: 2.0209e-04\n",
      "Epoch 169/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 2.2443e-04 - val_loss: 1.5521e-04\n",
      "Epoch 170/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 2.0884e-04 - val_loss: 1.6889e-04\n",
      "Epoch 171/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.8945e-04 - val_loss: 1.9358e-04\n",
      "Epoch 172/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.1900e-04 - val_loss: 1.4761e-04\n",
      "Epoch 173/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.8142e-04 - val_loss: 1.8777e-04\n",
      "Epoch 174/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.9327e-04 - val_loss: 3.0452e-04\n",
      "Epoch 175/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.7207e-04 - val_loss: 1.9965e-04\n",
      "Epoch 176/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.9905e-04 - val_loss: 3.3857e-04\n",
      "Epoch 177/2000\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 2.0343e-04 - val_loss: 2.5170e-04\n",
      "Epoch 178/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 2.2420e-04 - val_loss: 4.1381e-04\n",
      "Epoch 179/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 2.3287e-04 - val_loss: 4.6054e-04\n",
      "Epoch 180/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 3.0620e-04 - val_loss: 1.9910e-04\n",
      "Epoch 181/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7386e-04 - val_loss: 2.7809e-04\n",
      "Epoch 182/2000\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 2.3642e-04 - val_loss: 3.6842e-04\n",
      "Epoch 183/2000\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 2.2984e-04 - val_loss: 6.1648e-04\n",
      "Epoch 184/2000\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 2.7849e-04 - val_loss: 1.4897e-04\n",
      "Epoch 185/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 2.6743e-04 - val_loss: 2.5053e-04\n",
      "Epoch 186/2000\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 1.9081e-04 - val_loss: 1.7590e-04\n",
      "Epoch 187/2000\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 1.7501e-04 - val_loss: 1.5482e-04\n",
      "Epoch 188/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.7176e-04 - val_loss: 2.4458e-04\n",
      "Epoch 189/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.9134e-04 - val_loss: 1.3923e-04\n",
      "Epoch 190/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7062e-04 - val_loss: 1.3815e-04\n",
      "Epoch 191/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.6444e-04 - val_loss: 1.4575e-04\n",
      "Epoch 192/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.8683e-04 - val_loss: 1.3852e-04\n",
      "Epoch 193/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6755e-04 - val_loss: 1.5340e-04\n",
      "Epoch 194/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6066e-04 - val_loss: 2.1927e-04\n",
      "Epoch 195/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.7222e-04 - val_loss: 1.7177e-04\n",
      "Epoch 196/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6725e-04 - val_loss: 1.3635e-04\n",
      "Epoch 197/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5502e-04 - val_loss: 1.4172e-04\n",
      "Epoch 198/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6083e-04 - val_loss: 1.3916e-04\n",
      "Epoch 199/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5522e-04 - val_loss: 1.5327e-04\n",
      "Epoch 200/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5480e-04 - val_loss: 1.3525e-04\n",
      "Epoch 201/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6101e-04 - val_loss: 1.5960e-04\n",
      "Epoch 202/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6597e-04 - val_loss: 1.3567e-04\n",
      "Epoch 203/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6483e-04 - val_loss: 2.7447e-04\n",
      "Epoch 204/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.9950e-04 - val_loss: 1.4144e-04\n",
      "Epoch 205/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5549e-04 - val_loss: 1.4539e-04\n",
      "Epoch 206/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6986e-04 - val_loss: 6.3336e-04\n",
      "Epoch 207/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.3716e-04 - val_loss: 4.7987e-04\n",
      "Epoch 208/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.2058e-04 - val_loss: 1.3425e-04\n",
      "Epoch 209/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6462e-04 - val_loss: 3.0056e-04\n",
      "Epoch 210/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.0314e-04 - val_loss: 2.0269e-04\n",
      "Epoch 211/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 2.0535e-04 - val_loss: 3.2310e-04\n",
      "Epoch 212/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 2.3478e-04 - val_loss: 2.4525e-04\n",
      "Epoch 213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.8960e-04 - val_loss: 2.1595e-04\n",
      "Epoch 214/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.8817e-04 - val_loss: 1.8590e-04\n",
      "Epoch 215/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.8644e-04 - val_loss: 5.8069e-04\n",
      "Epoch 216/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.9699e-04 - val_loss: 6.5525e-04\n",
      "Epoch 217/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 3.2300e-04 - val_loss: 1.4591e-04\n",
      "Epoch 218/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7933e-04 - val_loss: 1.5509e-04\n",
      "Epoch 219/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5757e-04 - val_loss: 2.6050e-04\n",
      "Epoch 220/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.6560e-04 - val_loss: 1.3461e-04\n",
      "Epoch 221/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6736e-04 - val_loss: 1.5189e-04\n",
      "Epoch 222/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6362e-04 - val_loss: 1.5083e-04\n",
      "Epoch 223/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6871e-04 - val_loss: 1.7021e-04\n",
      "Epoch 224/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.5472e-04 - val_loss: 2.5726e-04\n",
      "Epoch 225/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.8128e-04 - val_loss: 2.3274e-04\n",
      "Epoch 226/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6825e-04 - val_loss: 1.3393e-04\n",
      "Epoch 227/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5703e-04 - val_loss: 1.7659e-04\n",
      "Epoch 228/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7204e-04 - val_loss: 2.9357e-04\n",
      "Epoch 229/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7128e-04 - val_loss: 1.3610e-04\n",
      "Epoch 230/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5375e-04 - val_loss: 1.6618e-04\n",
      "Epoch 231/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7524e-04 - val_loss: 1.8031e-04\n",
      "Epoch 232/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7345e-04 - val_loss: 2.1206e-04\n",
      "Epoch 233/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7416e-04 - val_loss: 1.4073e-04\n",
      "Epoch 234/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.8103e-04 - val_loss: 1.3287e-04\n",
      "Epoch 235/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5781e-04 - val_loss: 1.3804e-04\n",
      "Epoch 236/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4731e-04 - val_loss: 2.2242e-04\n",
      "Epoch 237/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.7914e-04 - val_loss: 2.1885e-04\n",
      "Epoch 238/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.7042e-04 - val_loss: 1.3537e-04\n",
      "Epoch 239/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4869e-04 - val_loss: 1.7959e-04\n",
      "Epoch 240/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5470e-04 - val_loss: 2.0805e-04\n",
      "Epoch 241/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5850e-04 - val_loss: 1.5347e-04\n",
      "Epoch 242/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5870e-04 - val_loss: 1.5421e-04\n",
      "Epoch 243/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.8676e-04 - val_loss: 1.3302e-04\n",
      "Epoch 244/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.7296e-04 - val_loss: 1.4555e-04\n",
      "Epoch 245/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6237e-04 - val_loss: 3.6619e-04\n",
      "Epoch 246/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.6400e-04 - val_loss: 1.7347e-04\n",
      "Epoch 247/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7070e-04 - val_loss: 1.3985e-04\n",
      "Epoch 248/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.7848e-04 - val_loss: 1.3682e-04\n",
      "Epoch 249/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6643e-04 - val_loss: 1.9635e-04\n",
      "Epoch 250/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7465e-04 - val_loss: 1.5045e-04\n",
      "Epoch 251/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6945e-04 - val_loss: 1.7240e-04\n",
      "Epoch 252/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.5852e-04 - val_loss: 3.6870e-04\n",
      "Epoch 253/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 2.3144e-04 - val_loss: 2.8899e-04\n",
      "Epoch 254/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.8918e-04 - val_loss: 1.3378e-04\n",
      "Epoch 255/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6411e-04 - val_loss: 2.0574e-04\n",
      "Epoch 256/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6279e-04 - val_loss: 3.1065e-04\n",
      "Epoch 257/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 2.6381e-04 - val_loss: 3.8793e-04\n",
      "Epoch 258/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.2136e-04 - val_loss: 1.7197e-04\n",
      "Epoch 259/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.3306e-04 - val_loss: 2.3157e-04\n",
      "Epoch 260/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.8398e-04 - val_loss: 1.3678e-04\n",
      "Epoch 261/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6358e-04 - val_loss: 3.2613e-04\n",
      "Epoch 262/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 2.3684e-04 - val_loss: 2.0425e-04\n",
      "Epoch 263/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.9263e-04 - val_loss: 1.5711e-04\n",
      "Epoch 264/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.6084e-04 - val_loss: 2.2356e-04\n",
      "Epoch 265/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.7275e-04 - val_loss: 1.4186e-04\n",
      "Epoch 266/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.7040e-04 - val_loss: 1.6663e-04\n",
      "Epoch 267/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.8451e-04 - val_loss: 2.2884e-04\n",
      "Epoch 268/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.9624e-04 - val_loss: 2.9231e-04\n",
      "Epoch 269/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7984e-04 - val_loss: 1.3821e-04\n",
      "Epoch 270/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.5543e-04 - val_loss: 2.5179e-04\n",
      "Epoch 271/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.8341e-04 - val_loss: 1.7377e-04\n",
      "Epoch 272/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.9073e-04 - val_loss: 2.0332e-04\n",
      "Epoch 273/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5444e-04 - val_loss: 1.5482e-04\n",
      "Epoch 274/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5037e-04 - val_loss: 1.4198e-04\n",
      "Epoch 275/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4851e-04 - val_loss: 1.3711e-04\n",
      "Epoch 276/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5140e-04 - val_loss: 2.3346e-04\n",
      "Epoch 277/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6678e-04 - val_loss: 1.4581e-04\n",
      "Epoch 278/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.9478e-04 - val_loss: 2.9715e-04\n",
      "Epoch 279/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 2.0643e-04 - val_loss: 1.5732e-04\n",
      "Epoch 280/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 2.0229e-04 - val_loss: 2.7300e-04\n",
      "Epoch 281/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.9466e-04 - val_loss: 1.4269e-04\n",
      "Epoch 282/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6570e-04 - val_loss: 1.5836e-04\n",
      "Epoch 283/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5094e-04 - val_loss: 1.5258e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6681e-04 - val_loss: 1.3234e-04\n",
      "Epoch 285/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5076e-04 - val_loss: 1.3160e-04\n",
      "Epoch 286/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4849e-04 - val_loss: 1.5448e-04\n",
      "Epoch 287/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4900e-04 - val_loss: 1.5088e-04\n",
      "Epoch 288/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.5031e-04 - val_loss: 1.8872e-04\n",
      "Epoch 289/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6599e-04 - val_loss: 1.3271e-04\n",
      "Epoch 290/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6423e-04 - val_loss: 1.3270e-04\n",
      "Epoch 291/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4562e-04 - val_loss: 1.3666e-04\n",
      "Epoch 292/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4339e-04 - val_loss: 1.9612e-04\n",
      "Epoch 293/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6561e-04 - val_loss: 1.5176e-04\n",
      "Epoch 294/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5211e-04 - val_loss: 1.4299e-04\n",
      "Epoch 295/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4536e-04 - val_loss: 1.3897e-04\n",
      "Epoch 296/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.6222e-04 - val_loss: 1.5047e-04\n",
      "Epoch 297/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7965e-04 - val_loss: 1.3728e-04\n",
      "Epoch 298/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6984e-04 - val_loss: 1.7026e-04\n",
      "Epoch 299/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.7123e-04 - val_loss: 2.3924e-04\n",
      "Epoch 300/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.9243e-04 - val_loss: 5.0918e-04\n",
      "Epoch 301/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 2.4919e-04 - val_loss: 1.7030e-04\n",
      "Epoch 302/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6796e-04 - val_loss: 3.3529e-04\n",
      "Epoch 303/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.0963e-04 - val_loss: 2.0110e-04\n",
      "Epoch 304/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 2.1248e-04 - val_loss: 1.6761e-04\n",
      "Epoch 305/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.8613e-04 - val_loss: 1.6610e-04\n",
      "Epoch 306/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5344e-04 - val_loss: 2.1210e-04\n",
      "Epoch 307/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6391e-04 - val_loss: 1.5982e-04\n",
      "Epoch 308/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6238e-04 - val_loss: 1.3431e-04\n",
      "Epoch 309/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6194e-04 - val_loss: 1.3295e-04\n",
      "Epoch 310/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4671e-04 - val_loss: 1.3837e-04\n",
      "Epoch 311/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.6038e-04 - val_loss: 1.6970e-04\n",
      "Epoch 312/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6088e-04 - val_loss: 1.9347e-04\n",
      "Epoch 313/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6205e-04 - val_loss: 4.3306e-04\n",
      "Epoch 314/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.2400e-04 - val_loss: 1.6630e-04\n",
      "Epoch 315/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.8932e-04 - val_loss: 2.2586e-04\n",
      "Epoch 316/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6904e-04 - val_loss: 1.4191e-04\n",
      "Epoch 317/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4991e-04 - val_loss: 1.3679e-04\n",
      "Epoch 318/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5547e-04 - val_loss: 1.3299e-04\n",
      "Epoch 319/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7361e-04 - val_loss: 1.3580e-04\n",
      "Epoch 320/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5216e-04 - val_loss: 1.4353e-04\n",
      "Epoch 321/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5666e-04 - val_loss: 2.1936e-04\n",
      "Epoch 322/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.9908e-04 - val_loss: 3.3054e-04\n",
      "Epoch 323/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6378e-04 - val_loss: 1.3712e-04\n",
      "Epoch 324/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5790e-04 - val_loss: 1.3421e-04\n",
      "Epoch 325/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4500e-04 - val_loss: 1.3766e-04\n",
      "Epoch 326/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5993e-04 - val_loss: 1.5351e-04\n",
      "Epoch 327/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.6400e-04 - val_loss: 1.8283e-04\n",
      "Epoch 328/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7631e-04 - val_loss: 4.8678e-04\n",
      "Epoch 329/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 2.4521e-04 - val_loss: 1.5151e-04\n",
      "Epoch 330/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5484e-04 - val_loss: 1.9477e-04\n",
      "Epoch 331/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.7614e-04 - val_loss: 1.3357e-04\n",
      "Epoch 332/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6827e-04 - val_loss: 1.4523e-04\n",
      "Epoch 333/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4569e-04 - val_loss: 1.5780e-04\n",
      "Epoch 334/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.6301e-04 - val_loss: 2.6911e-04\n",
      "Epoch 335/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6148e-04 - val_loss: 1.7936e-04\n",
      "Epoch 336/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6674e-04 - val_loss: 6.4088e-04\n",
      "Epoch 337/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.6986e-04 - val_loss: 1.7652e-04\n",
      "Epoch 338/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.8130e-04 - val_loss: 1.3250e-04\n",
      "Epoch 339/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4667e-04 - val_loss: 1.6289e-04\n",
      "Epoch 340/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.6141e-04 - val_loss: 1.5444e-04\n",
      "Epoch 341/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5423e-04 - val_loss: 1.7585e-04\n",
      "Epoch 342/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5932e-04 - val_loss: 1.4427e-04\n",
      "Epoch 343/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5888e-04 - val_loss: 2.0853e-04\n",
      "Epoch 344/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7492e-04 - val_loss: 1.4050e-04\n",
      "Epoch 345/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6542e-04 - val_loss: 1.9174e-04\n",
      "Epoch 346/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6168e-04 - val_loss: 1.3216e-04\n",
      "Epoch 347/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.6927e-04 - val_loss: 3.9804e-04\n",
      "Epoch 348/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 2.1736e-04 - val_loss: 1.3497e-04\n",
      "Epoch 349/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6415e-04 - val_loss: 2.8886e-04\n",
      "Epoch 350/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6617e-04 - val_loss: 1.3381e-04\n",
      "Epoch 351/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5712e-04 - val_loss: 1.8392e-04\n",
      "Epoch 352/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6092e-04 - val_loss: 1.3488e-04\n",
      "Epoch 353/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4419e-04 - val_loss: 1.3869e-04\n",
      "Epoch 354/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.5046e-04 - val_loss: 2.4775e-04\n",
      "Epoch 355/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.8777e-04 - val_loss: 1.4543e-04\n",
      "Epoch 356/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.7557e-04 - val_loss: 1.8464e-04\n",
      "Epoch 357/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6230e-04 - val_loss: 1.5139e-04\n",
      "Epoch 358/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.8022e-04 - val_loss: 1.5722e-04\n",
      "Epoch 359/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.8611e-04 - val_loss: 1.7083e-04\n",
      "Epoch 360/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6168e-04 - val_loss: 1.7558e-04\n",
      "Epoch 361/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.8462e-04 - val_loss: 1.3224e-04\n",
      "Epoch 362/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.7567e-04 - val_loss: 1.6817e-04\n",
      "Epoch 363/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.7261e-04 - val_loss: 1.3212e-04\n",
      "Epoch 364/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5598e-04 - val_loss: 1.4625e-04\n",
      "Epoch 365/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4969e-04 - val_loss: 3.2512e-04\n",
      "Epoch 366/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.9625e-04 - val_loss: 2.0777e-04\n",
      "Epoch 367/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.8720e-04 - val_loss: 2.4823e-04\n",
      "Epoch 368/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.8160e-04 - val_loss: 1.5145e-04\n",
      "Epoch 369/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5414e-04 - val_loss: 1.3870e-04\n",
      "Epoch 370/2000\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 1.5394e-04 - val_loss: 1.5082e-04\n",
      "Epoch 371/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4957e-04 - val_loss: 1.4829e-04\n",
      "Epoch 372/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5130e-04 - val_loss: 1.3329e-04\n",
      "Epoch 373/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4275e-04 - val_loss: 1.7639e-04\n",
      "Epoch 374/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5518e-04 - val_loss: 1.3560e-04\n",
      "Epoch 375/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.7071e-04 - val_loss: 1.3170e-04\n",
      "Epoch 376/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5369e-04 - val_loss: 1.3184e-04\n",
      "Epoch 377/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4593e-04 - val_loss: 3.0643e-04\n",
      "Epoch 378/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 2.1383e-04 - val_loss: 1.6447e-04\n",
      "Epoch 379/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6730e-04 - val_loss: 1.4933e-04\n",
      "Epoch 380/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6529e-04 - val_loss: 4.7467e-04\n",
      "Epoch 381/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 2.5351e-04 - val_loss: 3.1635e-04\n",
      "Epoch 382/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7944e-04 - val_loss: 2.4345e-04\n",
      "Epoch 383/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.9783e-04 - val_loss: 1.3419e-04\n",
      "Epoch 384/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.8430e-04 - val_loss: 1.6579e-04\n",
      "Epoch 385/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4856e-04 - val_loss: 1.5117e-04\n",
      "Epoch 386/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5343e-04 - val_loss: 2.1174e-04\n",
      "Epoch 387/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.5751e-04 - val_loss: 1.4761e-04\n",
      "Epoch 388/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6826e-04 - val_loss: 2.0126e-04\n",
      "Epoch 389/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6955e-04 - val_loss: 1.3204e-04\n",
      "Epoch 390/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4686e-04 - val_loss: 1.3814e-04\n",
      "Epoch 391/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5508e-04 - val_loss: 1.3943e-04\n",
      "Epoch 392/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4386e-04 - val_loss: 1.4576e-04\n",
      "Epoch 393/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5344e-04 - val_loss: 2.0669e-04\n",
      "Epoch 394/2000\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 2.0091e-04 - val_loss: 1.3131e-04\n",
      "Epoch 395/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.4327e-04 - val_loss: 1.3191e-04\n",
      "Epoch 396/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4752e-04 - val_loss: 2.7838e-04\n",
      "Epoch 397/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.0128e-04 - val_loss: 3.7925e-04\n",
      "Epoch 398/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.8394e-04 - val_loss: 1.5039e-04\n",
      "Epoch 399/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 2.0956e-04 - val_loss: 1.3171e-04\n",
      "Epoch 400/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5544e-04 - val_loss: 1.3649e-04\n",
      "Epoch 401/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6304e-04 - val_loss: 1.5690e-04\n",
      "Epoch 402/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5825e-04 - val_loss: 1.8849e-04\n",
      "Epoch 403/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4818e-04 - val_loss: 1.3766e-04\n",
      "Epoch 404/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5142e-04 - val_loss: 1.3255e-04\n",
      "Epoch 405/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5140e-04 - val_loss: 1.3298e-04\n",
      "Epoch 406/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5253e-04 - val_loss: 2.3408e-04\n",
      "Epoch 407/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.9325e-04 - val_loss: 1.3379e-04\n",
      "Epoch 408/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.6719e-04 - val_loss: 1.8377e-04\n",
      "Epoch 409/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5238e-04 - val_loss: 2.2929e-04\n",
      "Epoch 410/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6527e-04 - val_loss: 2.0820e-04\n",
      "Epoch 411/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.1055e-04 - val_loss: 1.4629e-04\n",
      "Epoch 412/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6081e-04 - val_loss: 1.7869e-04\n",
      "Epoch 413/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6976e-04 - val_loss: 1.4457e-04\n",
      "Epoch 414/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5268e-04 - val_loss: 2.8654e-04\n",
      "Epoch 415/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.8986e-04 - val_loss: 1.3314e-04\n",
      "Epoch 416/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4889e-04 - val_loss: 2.3272e-04\n",
      "Epoch 417/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.7728e-04 - val_loss: 1.3069e-04\n",
      "Epoch 418/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5289e-04 - val_loss: 3.2713e-04\n",
      "Epoch 419/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.4871e-04 - val_loss: 2.5867e-04\n",
      "Epoch 420/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.7175e-04 - val_loss: 1.5157e-04\n",
      "Epoch 421/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4381e-04 - val_loss: 1.8251e-04\n",
      "Epoch 422/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5651e-04 - val_loss: 1.5705e-04\n",
      "Epoch 423/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4553e-04 - val_loss: 1.9968e-04\n",
      "Epoch 424/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5399e-04 - val_loss: 2.8315e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.1428e-04 - val_loss: 1.4277e-04\n",
      "Epoch 426/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5929e-04 - val_loss: 1.4407e-04\n",
      "Epoch 427/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4656e-04 - val_loss: 1.4968e-04\n",
      "Epoch 428/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5557e-04 - val_loss: 1.3097e-04\n",
      "Epoch 429/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.4412e-04 - val_loss: 1.4886e-04\n",
      "Epoch 430/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5259e-04 - val_loss: 1.4282e-04\n",
      "Epoch 431/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4638e-04 - val_loss: 1.4834e-04\n",
      "Epoch 432/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4745e-04 - val_loss: 1.6033e-04\n",
      "Epoch 433/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4679e-04 - val_loss: 1.3269e-04\n",
      "Epoch 434/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5416e-04 - val_loss: 1.3730e-04\n",
      "Epoch 435/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4617e-04 - val_loss: 1.7113e-04\n",
      "Epoch 436/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7096e-04 - val_loss: 1.9791e-04\n",
      "Epoch 437/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4701e-04 - val_loss: 1.3232e-04\n",
      "Epoch 438/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4920e-04 - val_loss: 1.3286e-04\n",
      "Epoch 439/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4961e-04 - val_loss: 2.0897e-04\n",
      "Epoch 440/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6721e-04 - val_loss: 1.4701e-04\n",
      "Epoch 441/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5537e-04 - val_loss: 1.3149e-04\n",
      "Epoch 442/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.6096e-04 - val_loss: 1.4451e-04\n",
      "Epoch 443/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6609e-04 - val_loss: 1.7616e-04\n",
      "Epoch 444/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6636e-04 - val_loss: 1.5768e-04\n",
      "Epoch 445/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 2.1214e-04 - val_loss: 3.6729e-04\n",
      "Epoch 446/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.9797e-04 - val_loss: 2.6323e-04\n",
      "Epoch 447/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.4066e-04 - val_loss: 1.4728e-04\n",
      "Epoch 448/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 2.0112e-04 - val_loss: 2.0521e-04\n",
      "Epoch 449/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.6052e-04 - val_loss: 1.4944e-04\n",
      "Epoch 450/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4842e-04 - val_loss: 1.7287e-04\n",
      "Epoch 451/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6632e-04 - val_loss: 1.6570e-04\n",
      "Epoch 452/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6499e-04 - val_loss: 1.9206e-04\n",
      "Epoch 453/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.9352e-04 - val_loss: 2.3450e-04\n",
      "Epoch 454/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5859e-04 - val_loss: 1.9392e-04\n",
      "Epoch 455/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5161e-04 - val_loss: 1.7026e-04\n",
      "Epoch 456/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5827e-04 - val_loss: 1.3293e-04\n",
      "Epoch 457/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5525e-04 - val_loss: 1.5833e-04\n",
      "Epoch 458/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.8378e-04 - val_loss: 1.3660e-04\n",
      "Epoch 459/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.9887e-04 - val_loss: 6.1330e-04\n",
      "Epoch 460/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.9286e-04 - val_loss: 1.3338e-04\n",
      "Epoch 461/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 2.0011e-04 - val_loss: 7.0345e-04\n",
      "Epoch 462/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 2.7097e-04 - val_loss: 1.3814e-04\n",
      "Epoch 463/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.6370e-04 - val_loss: 3.4806e-04\n",
      "Epoch 464/2000\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 2.4989e-04 - val_loss: 2.3392e-04\n",
      "Epoch 465/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.8480e-04 - val_loss: 1.6736e-04\n",
      "Epoch 466/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4760e-04 - val_loss: 1.5630e-04\n",
      "Epoch 467/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.7007e-04 - val_loss: 1.4510e-04\n",
      "Epoch 468/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4919e-04 - val_loss: 2.1759e-04\n",
      "Epoch 469/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6572e-04 - val_loss: 1.3169e-04\n",
      "Epoch 470/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.5026e-04 - val_loss: 1.3322e-04\n",
      "Epoch 471/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5338e-04 - val_loss: 1.9241e-04\n",
      "Epoch 472/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5005e-04 - val_loss: 1.4843e-04\n",
      "Epoch 473/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6304e-04 - val_loss: 1.5655e-04\n",
      "Epoch 474/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6756e-04 - val_loss: 2.3603e-04\n",
      "Epoch 475/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.8230e-04 - val_loss: 1.5676e-04\n",
      "Epoch 476/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7332e-04 - val_loss: 2.0110e-04\n",
      "Epoch 477/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7436e-04 - val_loss: 3.9182e-04\n",
      "Epoch 478/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.1203e-04 - val_loss: 4.1693e-04\n",
      "Epoch 479/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.9649e-04 - val_loss: 1.7473e-04\n",
      "Epoch 480/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7768e-04 - val_loss: 3.1260e-04\n",
      "Epoch 481/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.7895e-04 - val_loss: 1.3286e-04\n",
      "Epoch 482/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4986e-04 - val_loss: 2.3973e-04\n",
      "Epoch 483/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 2.0014e-04 - val_loss: 2.7988e-04\n",
      "Epoch 484/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.8521e-04 - val_loss: 3.2426e-04\n",
      "Epoch 485/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 2.1432e-04 - val_loss: 1.3166e-04\n",
      "Epoch 486/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6302e-04 - val_loss: 3.2429e-04\n",
      "Epoch 487/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.8507e-04 - val_loss: 1.6705e-04\n",
      "Epoch 488/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6764e-04 - val_loss: 1.5122e-04\n",
      "Epoch 489/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.8776e-04 - val_loss: 3.7097e-04\n",
      "Epoch 490/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7662e-04 - val_loss: 3.1488e-04\n",
      "Epoch 491/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.8021e-04 - val_loss: 1.3129e-04\n",
      "Epoch 492/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4971e-04 - val_loss: 1.7066e-04\n",
      "Epoch 493/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4626e-04 - val_loss: 1.3753e-04\n",
      "Epoch 494/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4492e-04 - val_loss: 1.3692e-04\n",
      "Epoch 495/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4435e-04 - val_loss: 1.3602e-04\n",
      "Epoch 496/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5045e-04 - val_loss: 1.7606e-04\n",
      "Epoch 497/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6226e-04 - val_loss: 2.0100e-04\n",
      "Epoch 498/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4928e-04 - val_loss: 1.3475e-04\n",
      "Epoch 499/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4712e-04 - val_loss: 1.6795e-04\n",
      "Epoch 500/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.5029e-04 - val_loss: 1.3359e-04\n",
      "Epoch 501/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4894e-04 - val_loss: 1.3719e-04\n",
      "Epoch 502/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.5099e-04 - val_loss: 2.0151e-04\n",
      "Epoch 503/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6996e-04 - val_loss: 1.3331e-04\n",
      "Epoch 504/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.4961e-04 - val_loss: 1.7606e-04\n",
      "Epoch 505/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5983e-04 - val_loss: 2.6837e-04\n",
      "Epoch 506/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6401e-04 - val_loss: 1.4423e-04\n",
      "Epoch 507/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.5966e-04 - val_loss: 1.7430e-04\n",
      "Epoch 508/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6789e-04 - val_loss: 1.3740e-04\n",
      "Epoch 509/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4566e-04 - val_loss: 1.7709e-04\n",
      "Epoch 510/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7510e-04 - val_loss: 1.6503e-04\n",
      "Epoch 511/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5649e-04 - val_loss: 1.5807e-04\n",
      "Epoch 512/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.7339e-04 - val_loss: 1.5927e-04\n",
      "Epoch 513/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.7697e-04 - val_loss: 3.2147e-04\n",
      "Epoch 514/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 2.0224e-04 - val_loss: 1.3503e-04\n",
      "Epoch 515/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5361e-04 - val_loss: 3.0518e-04\n",
      "Epoch 516/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 2.4143e-04 - val_loss: 2.1481e-04\n",
      "Epoch 517/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.8970e-04 - val_loss: 1.4970e-04\n",
      "Epoch 518/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5477e-04 - val_loss: 1.3755e-04\n",
      "Epoch 519/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4712e-04 - val_loss: 1.7242e-04\n",
      "Epoch 520/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5265e-04 - val_loss: 2.9269e-04\n",
      "Epoch 521/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 2.0767e-04 - val_loss: 1.5760e-04\n",
      "Epoch 522/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6590e-04 - val_loss: 2.4924e-04\n",
      "Epoch 523/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6037e-04 - val_loss: 1.4087e-04\n",
      "Epoch 524/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.7009e-04 - val_loss: 1.3399e-04\n",
      "Epoch 525/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.6051e-04 - val_loss: 2.5806e-04\n",
      "Epoch 526/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5669e-04 - val_loss: 1.4649e-04\n",
      "Epoch 527/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4201e-04 - val_loss: 1.4523e-04\n",
      "Epoch 528/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4710e-04 - val_loss: 2.7177e-04\n",
      "Epoch 529/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.6752e-04 - val_loss: 1.4519e-04\n",
      "Epoch 530/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5300e-04 - val_loss: 1.3527e-04\n",
      "Epoch 531/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4993e-04 - val_loss: 1.7347e-04\n",
      "Epoch 532/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.7672e-04 - val_loss: 1.7780e-04\n",
      "Epoch 533/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.6831e-04 - val_loss: 1.4792e-04\n",
      "Epoch 534/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5736e-04 - val_loss: 1.5697e-04\n",
      "Epoch 535/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4622e-04 - val_loss: 1.5510e-04\n",
      "Epoch 536/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4845e-04 - val_loss: 3.2475e-04\n",
      "Epoch 537/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.5927e-04 - val_loss: 1.4566e-04\n",
      "Epoch 538/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.7926e-04 - val_loss: 3.9733e-04\n",
      "Epoch 539/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.9922e-04 - val_loss: 1.5639e-04\n",
      "Epoch 540/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5373e-04 - val_loss: 1.3140e-04\n",
      "Epoch 541/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4643e-04 - val_loss: 2.2803e-04\n",
      "Epoch 542/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.7347e-04 - val_loss: 1.5471e-04\n",
      "Epoch 543/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4981e-04 - val_loss: 1.4342e-04\n",
      "Epoch 544/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4645e-04 - val_loss: 2.7681e-04\n",
      "Epoch 545/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.9740e-04 - val_loss: 1.8627e-04\n",
      "Epoch 546/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6377e-04 - val_loss: 2.0829e-04\n",
      "Epoch 547/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7907e-04 - val_loss: 1.5583e-04\n",
      "Epoch 548/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.5534e-04 - val_loss: 1.9045e-04\n",
      "Epoch 549/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6067e-04 - val_loss: 1.5065e-04\n",
      "Epoch 550/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5257e-04 - val_loss: 1.3958e-04\n",
      "Epoch 551/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4527e-04 - val_loss: 3.4093e-04\n",
      "Epoch 552/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.8174e-04 - val_loss: 1.3186e-04\n",
      "Epoch 553/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4587e-04 - val_loss: 1.8747e-04\n",
      "Epoch 554/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6014e-04 - val_loss: 2.6553e-04\n",
      "Epoch 555/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.2403e-04 - val_loss: 2.2382e-04\n",
      "Epoch 556/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.8604e-04 - val_loss: 1.2980e-04\n",
      "Epoch 557/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5005e-04 - val_loss: 1.4081e-04\n",
      "Epoch 558/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.5316e-04 - val_loss: 1.5958e-04\n",
      "Epoch 559/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.5038e-04 - val_loss: 2.4669e-04\n",
      "Epoch 560/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.1728e-04 - val_loss: 1.3209e-04\n",
      "Epoch 561/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.7168e-04 - val_loss: 1.3666e-04\n",
      "Epoch 562/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6370e-04 - val_loss: 1.6707e-04\n",
      "Epoch 563/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.6438e-04 - val_loss: 2.1188e-04\n",
      "Epoch 564/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5718e-04 - val_loss: 1.3135e-04\n",
      "Epoch 565/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4241e-04 - val_loss: 2.0989e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 566/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.7854e-04 - val_loss: 2.1500e-04\n",
      "Epoch 567/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6851e-04 - val_loss: 1.3102e-04\n",
      "Epoch 568/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4073e-04 - val_loss: 1.3292e-04\n",
      "Epoch 569/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4168e-04 - val_loss: 1.3015e-04\n",
      "Epoch 570/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4440e-04 - val_loss: 1.3548e-04\n",
      "Epoch 571/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4587e-04 - val_loss: 3.0170e-04\n",
      "Epoch 572/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.7486e-04 - val_loss: 2.9900e-04\n",
      "Epoch 573/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.9314e-04 - val_loss: 4.3678e-04\n",
      "Epoch 574/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 2.3786e-04 - val_loss: 1.9868e-04\n",
      "Epoch 575/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.7750e-04 - val_loss: 1.3686e-04\n",
      "Epoch 576/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6456e-04 - val_loss: 1.3265e-04\n",
      "Epoch 577/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4068e-04 - val_loss: 1.5542e-04\n",
      "Epoch 578/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4804e-04 - val_loss: 1.6318e-04\n",
      "Epoch 579/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5390e-04 - val_loss: 1.3633e-04\n",
      "Epoch 580/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4103e-04 - val_loss: 1.6215e-04\n",
      "Epoch 581/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5472e-04 - val_loss: 1.3050e-04\n",
      "Epoch 582/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5043e-04 - val_loss: 1.4062e-04\n",
      "Epoch 583/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4738e-04 - val_loss: 1.4128e-04\n",
      "Epoch 584/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4662e-04 - val_loss: 1.6812e-04\n",
      "Epoch 585/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4980e-04 - val_loss: 1.3925e-04\n",
      "Epoch 586/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4477e-04 - val_loss: 1.3442e-04\n",
      "Epoch 587/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4314e-04 - val_loss: 1.3676e-04\n",
      "Epoch 588/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4645e-04 - val_loss: 1.7261e-04\n",
      "Epoch 589/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6212e-04 - val_loss: 1.9222e-04\n",
      "Epoch 590/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.7004e-04 - val_loss: 1.5077e-04\n",
      "Epoch 591/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5788e-04 - val_loss: 1.6004e-04\n",
      "Epoch 592/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5543e-04 - val_loss: 1.5446e-04\n",
      "Epoch 593/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.7120e-04 - val_loss: 1.3154e-04\n",
      "Epoch 594/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5812e-04 - val_loss: 1.4978e-04\n",
      "Epoch 595/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4348e-04 - val_loss: 1.3097e-04\n",
      "Epoch 596/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4575e-04 - val_loss: 1.6024e-04\n",
      "Epoch 597/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6069e-04 - val_loss: 2.2976e-04\n",
      "Epoch 598/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7775e-04 - val_loss: 4.1205e-04\n",
      "Epoch 599/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.5345e-04 - val_loss: 1.3852e-04\n",
      "Epoch 600/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6961e-04 - val_loss: 2.4715e-04\n",
      "Epoch 601/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 2.0029e-04 - val_loss: 1.5156e-04\n",
      "Epoch 602/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5108e-04 - val_loss: 2.0625e-04\n",
      "Epoch 603/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6475e-04 - val_loss: 2.5167e-04\n",
      "Epoch 604/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6735e-04 - val_loss: 2.0064e-04\n",
      "Epoch 605/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6958e-04 - val_loss: 1.3186e-04\n",
      "Epoch 606/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4557e-04 - val_loss: 2.1151e-04\n",
      "Epoch 607/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5660e-04 - val_loss: 2.0787e-04\n",
      "Epoch 608/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.9627e-04 - val_loss: 4.6414e-04\n",
      "Epoch 609/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.0896e-04 - val_loss: 2.0914e-04\n",
      "Epoch 610/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7967e-04 - val_loss: 2.5797e-04\n",
      "Epoch 611/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6152e-04 - val_loss: 1.3152e-04\n",
      "Epoch 612/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4110e-04 - val_loss: 1.8262e-04\n",
      "Epoch 613/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5312e-04 - val_loss: 1.4755e-04\n",
      "Epoch 614/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4771e-04 - val_loss: 1.8960e-04\n",
      "Epoch 615/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4616e-04 - val_loss: 1.3641e-04\n",
      "Epoch 616/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4289e-04 - val_loss: 1.4984e-04\n",
      "Epoch 617/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5444e-04 - val_loss: 3.5621e-04\n",
      "Epoch 618/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.8978e-04 - val_loss: 3.6557e-04\n",
      "Epoch 619/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.7784e-04 - val_loss: 1.3234e-04\n",
      "Epoch 620/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.6376e-04 - val_loss: 1.3146e-04\n",
      "Epoch 621/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4989e-04 - val_loss: 1.9824e-04\n",
      "Epoch 622/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6410e-04 - val_loss: 1.6943e-04\n",
      "Epoch 623/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5986e-04 - val_loss: 2.0552e-04\n",
      "Epoch 624/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4392e-04 - val_loss: 1.3121e-04\n",
      "Epoch 625/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4725e-04 - val_loss: 1.5515e-04\n",
      "Epoch 626/2000\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 1.4975e-04 - val_loss: 1.3114e-04\n",
      "Epoch 627/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4113e-04 - val_loss: 1.6774e-04\n",
      "Epoch 628/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6093e-04 - val_loss: 1.7489e-04\n",
      "Epoch 629/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4397e-04 - val_loss: 1.3090e-04\n",
      "Epoch 630/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4466e-04 - val_loss: 1.9296e-04\n",
      "Epoch 631/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5399e-04 - val_loss: 1.6473e-04\n",
      "Epoch 632/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7805e-04 - val_loss: 1.3105e-04\n",
      "Epoch 633/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5697e-04 - val_loss: 1.3729e-04\n",
      "Epoch 634/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4610e-04 - val_loss: 1.3109e-04\n",
      "Epoch 635/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5089e-04 - val_loss: 1.3279e-04\n",
      "Epoch 636/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4678e-04 - val_loss: 1.9818e-04\n",
      "Epoch 637/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.7442e-04 - val_loss: 1.3790e-04\n",
      "Epoch 638/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6953e-04 - val_loss: 1.5962e-04\n",
      "Epoch 639/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5303e-04 - val_loss: 1.3204e-04\n",
      "Epoch 640/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4151e-04 - val_loss: 1.3137e-04\n",
      "Epoch 641/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4173e-04 - val_loss: 1.6643e-04\n",
      "Epoch 642/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4910e-04 - val_loss: 1.2999e-04\n",
      "Epoch 643/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5828e-04 - val_loss: 1.3227e-04\n",
      "Epoch 644/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4542e-04 - val_loss: 1.7344e-04\n",
      "Epoch 645/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5484e-04 - val_loss: 1.9444e-04\n",
      "Epoch 646/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6149e-04 - val_loss: 1.3634e-04\n",
      "Epoch 647/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6642e-04 - val_loss: 1.4567e-04\n",
      "Epoch 648/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.5624e-04 - val_loss: 2.1433e-04\n",
      "Epoch 649/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6065e-04 - val_loss: 2.4364e-04\n",
      "Epoch 650/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.7204e-04 - val_loss: 1.6468e-04\n",
      "Epoch 651/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4579e-04 - val_loss: 1.5122e-04\n",
      "Epoch 652/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4685e-04 - val_loss: 1.4033e-04\n",
      "Epoch 653/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4604e-04 - val_loss: 1.8683e-04\n",
      "Epoch 654/2000\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 1.6107e-04 - val_loss: 1.4450e-04\n",
      "Epoch 655/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5678e-04 - val_loss: 1.8208e-04\n",
      "Epoch 656/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.7359e-04 - val_loss: 3.0426e-04\n",
      "Epoch 657/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.9397e-04 - val_loss: 2.1969e-04\n",
      "Epoch 658/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.8958e-04 - val_loss: 1.4005e-04\n",
      "Epoch 659/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6278e-04 - val_loss: 2.2513e-04\n",
      "Epoch 660/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.7542e-04 - val_loss: 2.3781e-04\n",
      "Epoch 661/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6098e-04 - val_loss: 3.0144e-04\n",
      "Epoch 662/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 2.0878e-04 - val_loss: 2.8113e-04\n",
      "Epoch 663/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.0694e-04 - val_loss: 1.6441e-04\n",
      "Epoch 664/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5576e-04 - val_loss: 1.4190e-04\n",
      "Epoch 665/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5938e-04 - val_loss: 2.0713e-04\n",
      "Epoch 666/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6774e-04 - val_loss: 2.7465e-04\n",
      "Epoch 667/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.8058e-04 - val_loss: 1.8646e-04\n",
      "Epoch 668/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6657e-04 - val_loss: 1.9527e-04\n",
      "Epoch 669/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4951e-04 - val_loss: 1.4294e-04\n",
      "Epoch 670/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4054e-04 - val_loss: 1.3810e-04\n",
      "Epoch 671/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4460e-04 - val_loss: 1.3334e-04\n",
      "Epoch 672/2000\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 1.3957e-04 - val_loss: 1.9216e-04\n",
      "Epoch 673/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5953e-04 - val_loss: 2.1806e-04\n",
      "Epoch 674/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.6701e-04 - val_loss: 1.9369e-04\n",
      "Epoch 675/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7855e-04 - val_loss: 2.3277e-04\n",
      "Epoch 676/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6615e-04 - val_loss: 2.3458e-04\n",
      "Epoch 677/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.7050e-04 - val_loss: 1.3812e-04\n",
      "Epoch 678/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4270e-04 - val_loss: 1.4625e-04\n",
      "Epoch 679/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4026e-04 - val_loss: 1.3683e-04\n",
      "Epoch 680/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5040e-04 - val_loss: 1.5022e-04\n",
      "Epoch 681/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.5110e-04 - val_loss: 1.3707e-04\n",
      "Epoch 682/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4255e-04 - val_loss: 1.8003e-04\n",
      "Epoch 683/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4949e-04 - val_loss: 1.4486e-04\n",
      "Epoch 684/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4075e-04 - val_loss: 1.3894e-04\n",
      "Epoch 685/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4213e-04 - val_loss: 2.6342e-04\n",
      "Epoch 686/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.8207e-04 - val_loss: 1.8412e-04\n",
      "Epoch 687/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5814e-04 - val_loss: 1.8874e-04\n",
      "Epoch 688/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6917e-04 - val_loss: 1.4284e-04\n",
      "Epoch 689/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4691e-04 - val_loss: 1.4983e-04\n",
      "Epoch 690/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5180e-04 - val_loss: 1.5987e-04\n",
      "Epoch 691/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4872e-04 - val_loss: 1.3206e-04\n",
      "Epoch 692/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4251e-04 - val_loss: 2.0129e-04\n",
      "Epoch 693/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6242e-04 - val_loss: 1.3363e-04\n",
      "Epoch 694/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.4885e-04 - val_loss: 1.3526e-04\n",
      "Epoch 695/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5207e-04 - val_loss: 1.3442e-04\n",
      "Epoch 696/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5269e-04 - val_loss: 1.3580e-04\n",
      "Epoch 697/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.6241e-04 - val_loss: 1.3986e-04\n",
      "Epoch 698/2000\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 1.4671e-04 - val_loss: 2.0836e-04\n",
      "Epoch 699/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.5478e-04 - val_loss: 1.3344e-04\n",
      "Epoch 700/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4440e-04 - val_loss: 1.8072e-04\n",
      "Epoch 701/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.8130e-04 - val_loss: 2.7980e-04\n",
      "Epoch 702/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.7259e-04 - val_loss: 2.1854e-04\n",
      "Epoch 703/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7210e-04 - val_loss: 1.3995e-04\n",
      "Epoch 704/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4298e-04 - val_loss: 1.5583e-04\n",
      "Epoch 705/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5155e-04 - val_loss: 1.6994e-04\n",
      "Epoch 706/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5482e-04 - val_loss: 1.3318e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 707/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6367e-04 - val_loss: 1.9793e-04\n",
      "Epoch 708/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 2.0393e-04 - val_loss: 1.9262e-04\n",
      "Epoch 709/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6629e-04 - val_loss: 1.3565e-04\n",
      "Epoch 710/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5342e-04 - val_loss: 1.7168e-04\n",
      "Epoch 711/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5857e-04 - val_loss: 1.4292e-04\n",
      "Epoch 712/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6082e-04 - val_loss: 1.4174e-04\n",
      "Epoch 713/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5606e-04 - val_loss: 2.9074e-04\n",
      "Epoch 714/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6802e-04 - val_loss: 1.9883e-04\n",
      "Epoch 715/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.6165e-04 - val_loss: 1.8805e-04\n",
      "Epoch 716/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6480e-04 - val_loss: 1.6037e-04\n",
      "Epoch 717/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5291e-04 - val_loss: 2.0329e-04\n",
      "Epoch 718/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6952e-04 - val_loss: 2.2797e-04\n",
      "Epoch 719/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.8520e-04 - val_loss: 3.1716e-04\n",
      "Epoch 720/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.8889e-04 - val_loss: 1.4570e-04\n",
      "Epoch 721/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4943e-04 - val_loss: 1.3236e-04\n",
      "Epoch 722/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4637e-04 - val_loss: 1.3244e-04\n",
      "Epoch 723/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4736e-04 - val_loss: 1.4655e-04\n",
      "Epoch 724/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5713e-04 - val_loss: 1.3946e-04\n",
      "Epoch 725/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4264e-04 - val_loss: 1.3263e-04\n",
      "Epoch 726/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4601e-04 - val_loss: 1.4810e-04\n",
      "Epoch 727/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4998e-04 - val_loss: 1.6654e-04\n",
      "Epoch 728/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.5363e-04 - val_loss: 2.7647e-04\n",
      "Epoch 729/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.9094e-04 - val_loss: 1.8365e-04\n",
      "Epoch 730/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.0498e-04 - val_loss: 2.0553e-04\n",
      "Epoch 731/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7537e-04 - val_loss: 1.8360e-04\n",
      "Epoch 732/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5170e-04 - val_loss: 1.5619e-04\n",
      "Epoch 733/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5850e-04 - val_loss: 1.8011e-04\n",
      "Epoch 734/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5174e-04 - val_loss: 2.4013e-04\n",
      "Epoch 735/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.9245e-04 - val_loss: 6.1545e-04\n",
      "Epoch 736/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 2.2312e-04 - val_loss: 1.8400e-04\n",
      "Epoch 737/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.7007e-04 - val_loss: 2.0450e-04\n",
      "Epoch 738/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5253e-04 - val_loss: 1.4749e-04\n",
      "Epoch 739/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5101e-04 - val_loss: 1.3105e-04\n",
      "Epoch 740/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4703e-04 - val_loss: 2.4184e-04\n",
      "Epoch 741/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.8867e-04 - val_loss: 3.1608e-04\n",
      "Epoch 742/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.1864e-04 - val_loss: 1.3535e-04\n",
      "Epoch 743/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4761e-04 - val_loss: 1.4678e-04\n",
      "Epoch 744/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4537e-04 - val_loss: 1.4036e-04\n",
      "Epoch 745/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4528e-04 - val_loss: 1.3814e-04\n",
      "Epoch 746/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4191e-04 - val_loss: 1.3681e-04\n",
      "Epoch 747/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4069e-04 - val_loss: 1.3131e-04\n",
      "Epoch 748/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3985e-04 - val_loss: 2.2353e-04\n",
      "Epoch 749/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5660e-04 - val_loss: 1.6183e-04\n",
      "Epoch 750/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5110e-04 - val_loss: 1.6418e-04\n",
      "Epoch 751/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5236e-04 - val_loss: 1.4335e-04\n",
      "Epoch 752/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4312e-04 - val_loss: 2.6752e-04\n",
      "Epoch 753/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.8920e-04 - val_loss: 2.4897e-04\n",
      "Epoch 754/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6179e-04 - val_loss: 1.3298e-04\n",
      "Epoch 755/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4681e-04 - val_loss: 1.7691e-04\n",
      "Epoch 756/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4756e-04 - val_loss: 1.5290e-04\n",
      "Epoch 757/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4957e-04 - val_loss: 1.5127e-04\n",
      "Epoch 758/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5264e-04 - val_loss: 1.4171e-04\n",
      "Epoch 759/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4795e-04 - val_loss: 1.3758e-04\n",
      "Epoch 760/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4141e-04 - val_loss: 1.4386e-04\n",
      "Epoch 761/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4150e-04 - val_loss: 1.3396e-04\n",
      "Epoch 762/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4014e-04 - val_loss: 2.1976e-04\n",
      "Epoch 763/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7030e-04 - val_loss: 1.6710e-04\n",
      "Epoch 764/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5736e-04 - val_loss: 1.8392e-04\n",
      "Epoch 765/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5691e-04 - val_loss: 3.7701e-04\n",
      "Epoch 766/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.9499e-04 - val_loss: 1.3450e-04\n",
      "Epoch 767/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6053e-04 - val_loss: 1.3138e-04\n",
      "Epoch 768/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5185e-04 - val_loss: 1.4400e-04\n",
      "Epoch 769/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4704e-04 - val_loss: 1.7571e-04\n",
      "Epoch 770/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6618e-04 - val_loss: 3.3124e-04\n",
      "Epoch 771/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7704e-04 - val_loss: 1.3204e-04\n",
      "Epoch 772/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4349e-04 - val_loss: 1.4701e-04\n",
      "Epoch 773/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4267e-04 - val_loss: 1.7633e-04\n",
      "Epoch 774/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5530e-04 - val_loss: 1.4640e-04\n",
      "Epoch 775/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6751e-04 - val_loss: 1.4235e-04\n",
      "Epoch 776/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5103e-04 - val_loss: 1.3065e-04\n",
      "Epoch 777/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4026e-04 - val_loss: 1.3349e-04\n",
      "Epoch 778/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4096e-04 - val_loss: 1.8488e-04\n",
      "Epoch 779/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6719e-04 - val_loss: 1.5919e-04\n",
      "Epoch 780/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4835e-04 - val_loss: 1.3324e-04\n",
      "Epoch 781/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5812e-04 - val_loss: 1.9710e-04\n",
      "Epoch 782/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7475e-04 - val_loss: 1.3445e-04\n",
      "Epoch 783/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5103e-04 - val_loss: 1.3894e-04\n",
      "Epoch 784/2000\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 1.3931e-04 - val_loss: 1.5593e-04\n",
      "Epoch 785/2000\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 1.4043e-04 - val_loss: 1.4923e-04\n",
      "Epoch 786/2000\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 1.4626e-04 - val_loss: 2.4715e-04\n",
      "Epoch 787/2000\n",
      "4143/4143 [==============================] - 2s 603us/step - loss: 1.7390e-04 - val_loss: 1.8210e-04\n",
      "Epoch 788/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.5206e-04 - val_loss: 1.3455e-04\n",
      "Epoch 789/2000\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 1.5196e-04 - val_loss: 1.3964e-04\n",
      "Epoch 790/2000\n",
      "4143/4143 [==============================] - 2s 590us/step - loss: 1.5881e-04 - val_loss: 1.3080e-04\n",
      "Epoch 791/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5439e-04 - val_loss: 2.5303e-04\n",
      "Epoch 792/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.6900e-04 - val_loss: 1.3295e-04\n",
      "Epoch 793/2000\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 1.4037e-04 - val_loss: 1.5511e-04\n",
      "Epoch 794/2000\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 1.4851e-04 - val_loss: 4.6506e-04\n",
      "Epoch 795/2000\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 2.3751e-04 - val_loss: 1.6864e-04\n",
      "Epoch 796/2000\n",
      "4143/4143 [==============================] - 2s 588us/step - loss: 1.8098e-04 - val_loss: 2.6402e-04\n",
      "Epoch 797/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7071e-04 - val_loss: 2.7603e-04\n",
      "Epoch 798/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.7821e-04 - val_loss: 1.6827e-04\n",
      "Epoch 799/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5744e-04 - val_loss: 1.3705e-04\n",
      "Epoch 800/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4219e-04 - val_loss: 2.2514e-04\n",
      "Epoch 801/2000\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 1.5337e-04 - val_loss: 2.7291e-04\n",
      "Epoch 802/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6860e-04 - val_loss: 3.4461e-04\n",
      "Epoch 803/2000\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 1.8199e-04 - val_loss: 1.3277e-04\n",
      "Epoch 804/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4167e-04 - val_loss: 1.6674e-04\n",
      "Epoch 805/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4360e-04 - val_loss: 1.3350e-04\n",
      "Epoch 806/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3936e-04 - val_loss: 1.3470e-04\n",
      "Epoch 807/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4536e-04 - val_loss: 2.5333e-04\n",
      "Epoch 808/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6545e-04 - val_loss: 5.0323e-04\n",
      "Epoch 809/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.8169e-04 - val_loss: 5.2590e-04\n",
      "Epoch 810/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.0970e-04 - val_loss: 1.4114e-04\n",
      "Epoch 811/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5049e-04 - val_loss: 1.4807e-04\n",
      "Epoch 812/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4816e-04 - val_loss: 1.4285e-04\n",
      "Epoch 813/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4326e-04 - val_loss: 1.3665e-04\n",
      "Epoch 814/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4974e-04 - val_loss: 1.3943e-04\n",
      "Epoch 815/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4405e-04 - val_loss: 1.3508e-04\n",
      "Epoch 816/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4398e-04 - val_loss: 1.4729e-04\n",
      "Epoch 817/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5937e-04 - val_loss: 1.3819e-04\n",
      "Epoch 818/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.5302e-04 - val_loss: 2.6594e-04\n",
      "Epoch 819/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6860e-04 - val_loss: 1.3356e-04\n",
      "Epoch 820/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4308e-04 - val_loss: 1.3261e-04\n",
      "Epoch 821/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4127e-04 - val_loss: 1.5438e-04\n",
      "Epoch 822/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4145e-04 - val_loss: 1.4364e-04\n",
      "Epoch 823/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4944e-04 - val_loss: 1.3528e-04\n",
      "Epoch 824/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4070e-04 - val_loss: 2.1749e-04\n",
      "Epoch 825/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.7826e-04 - val_loss: 1.6271e-04\n",
      "Epoch 826/2000\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 1.4399e-04 - val_loss: 1.3707e-04\n",
      "Epoch 827/2000\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 1.4197e-04 - val_loss: 1.9466e-04\n",
      "Epoch 828/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.5355e-04 - val_loss: 1.3233e-04\n",
      "Epoch 829/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4176e-04 - val_loss: 1.5498e-04\n",
      "Epoch 830/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4537e-04 - val_loss: 1.3571e-04\n",
      "Epoch 831/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4166e-04 - val_loss: 2.4776e-04\n",
      "Epoch 832/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6984e-04 - val_loss: 1.3219e-04\n",
      "Epoch 833/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4172e-04 - val_loss: 1.3660e-04\n",
      "Epoch 834/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4193e-04 - val_loss: 1.8621e-04\n",
      "Epoch 835/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5823e-04 - val_loss: 1.4062e-04\n",
      "Epoch 836/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.6753e-04 - val_loss: 4.4785e-04\n",
      "Epoch 837/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.5634e-04 - val_loss: 3.8493e-04\n",
      "Epoch 838/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 2.0488e-04 - val_loss: 1.8057e-04\n",
      "Epoch 839/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4781e-04 - val_loss: 1.5437e-04\n",
      "Epoch 840/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.5839e-04 - val_loss: 1.4690e-04\n",
      "Epoch 841/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4226e-04 - val_loss: 1.3037e-04\n",
      "Epoch 842/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3996e-04 - val_loss: 1.4564e-04\n",
      "Epoch 843/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4262e-04 - val_loss: 1.3346e-04\n",
      "Epoch 844/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4160e-04 - val_loss: 1.4374e-04\n",
      "Epoch 845/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4213e-04 - val_loss: 1.3881e-04\n",
      "Epoch 846/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4157e-04 - val_loss: 1.4671e-04\n",
      "Epoch 847/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4867e-04 - val_loss: 1.7694e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 848/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5543e-04 - val_loss: 3.2627e-04\n",
      "Epoch 849/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 2.0855e-04 - val_loss: 3.4716e-04\n",
      "Epoch 850/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.8213e-04 - val_loss: 1.3341e-04\n",
      "Epoch 851/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5340e-04 - val_loss: 2.5371e-04\n",
      "Epoch 852/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6998e-04 - val_loss: 1.3110e-04\n",
      "Epoch 853/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5917e-04 - val_loss: 1.5094e-04\n",
      "Epoch 854/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4814e-04 - val_loss: 1.6663e-04\n",
      "Epoch 855/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6247e-04 - val_loss: 1.3208e-04\n",
      "Epoch 856/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4878e-04 - val_loss: 1.3432e-04\n",
      "Epoch 857/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4288e-04 - val_loss: 2.7037e-04\n",
      "Epoch 858/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6660e-04 - val_loss: 1.4111e-04\n",
      "Epoch 859/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5734e-04 - val_loss: 1.3151e-04\n",
      "Epoch 860/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5396e-04 - val_loss: 2.1590e-04\n",
      "Epoch 861/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5892e-04 - val_loss: 1.8527e-04\n",
      "Epoch 862/2000\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 1.5855e-04 - val_loss: 1.3148e-04\n",
      "Epoch 863/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.5271e-04 - val_loss: 2.0609e-04\n",
      "Epoch 864/2000\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 1.6785e-04 - val_loss: 1.3112e-04\n",
      "Epoch 865/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4254e-04 - val_loss: 1.4216e-04\n",
      "Epoch 866/2000\n",
      "4143/4143 [==============================] - 2s 584us/step - loss: 1.4389e-04 - val_loss: 3.1609e-04\n",
      "Epoch 867/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.8126e-04 - val_loss: 1.3750e-04\n",
      "Epoch 868/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4032e-04 - val_loss: 1.8770e-04\n",
      "Epoch 869/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5647e-04 - val_loss: 3.3195e-04\n",
      "Epoch 870/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 2.0873e-04 - val_loss: 4.3180e-04\n",
      "Epoch 871/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.2886e-04 - val_loss: 3.4490e-04\n",
      "Epoch 872/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.0317e-04 - val_loss: 4.2939e-04\n",
      "Epoch 873/2000\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 2.4165e-04 - val_loss: 2.8937e-04\n",
      "Epoch 874/2000\n",
      "4143/4143 [==============================] - 3s 607us/step - loss: 1.9889e-04 - val_loss: 1.8015e-04\n",
      "Epoch 875/2000\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 1.5171e-04 - val_loss: 1.9080e-04\n",
      "Epoch 876/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5280e-04 - val_loss: 1.6995e-04\n",
      "Epoch 877/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4595e-04 - val_loss: 1.3447e-04\n",
      "Epoch 878/2000\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 1.4916e-04 - val_loss: 1.3536e-04\n",
      "Epoch 879/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6212e-04 - val_loss: 1.5743e-04\n",
      "Epoch 880/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.4366e-04 - val_loss: 1.5670e-04\n",
      "Epoch 881/2000\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 1.4703e-04 - val_loss: 1.8564e-04\n",
      "Epoch 882/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5518e-04 - val_loss: 1.3209e-04\n",
      "Epoch 883/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5141e-04 - val_loss: 2.0297e-04\n",
      "Epoch 884/2000\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 1.6097e-04 - val_loss: 1.3402e-04\n",
      "Epoch 885/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4939e-04 - val_loss: 1.9092e-04\n",
      "Epoch 886/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5243e-04 - val_loss: 1.4050e-04\n",
      "Epoch 887/2000\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 1.4452e-04 - val_loss: 1.6439e-04\n",
      "Epoch 888/2000\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 1.4181e-04 - val_loss: 1.6849e-04\n",
      "Epoch 889/2000\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 1.5146e-04 - val_loss: 1.5831e-04\n",
      "Epoch 890/2000\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 1.4654e-04 - val_loss: 1.5997e-04\n",
      "Epoch 891/2000\n",
      "4143/4143 [==============================] - 3s 631us/step - loss: 1.5711e-04 - val_loss: 1.5878e-04\n",
      "Epoch 892/2000\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 1.4320e-04 - val_loss: 1.4216e-04\n",
      "Epoch 893/2000\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 1.3972e-04 - val_loss: 1.7498e-04\n",
      "Epoch 894/2000\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 1.5155e-04 - val_loss: 1.3778e-04\n",
      "Epoch 895/2000\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 1.6904e-04 - val_loss: 2.5185e-04\n",
      "Epoch 896/2000\n",
      "4143/4143 [==============================] - 2s 583us/step - loss: 1.7008e-04 - val_loss: 1.4432e-04\n",
      "Epoch 897/2000\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 1.4046e-04 - val_loss: 1.6855e-04\n",
      "Epoch 898/2000\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 1.4243e-04 - val_loss: 1.3890e-04\n",
      "Epoch 899/2000\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 1.4293e-04 - val_loss: 1.7375e-04\n",
      "Epoch 900/2000\n",
      "4143/4143 [==============================] - 3s 605us/step - loss: 1.5041e-04 - val_loss: 1.3753e-04\n",
      "Epoch 901/2000\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 1.4500e-04 - val_loss: 1.5921e-04\n",
      "Epoch 902/2000\n",
      "4143/4143 [==============================] - 3s 628us/step - loss: 1.6337e-04 - val_loss: 1.4736e-04\n",
      "Epoch 903/2000\n",
      "4143/4143 [==============================] - 3s 635us/step - loss: 1.4904e-04 - val_loss: 1.3561e-04\n",
      "Epoch 904/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 1.5582e-04 - val_loss: 2.6540e-04\n",
      "Epoch 905/2000\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 2.1256e-04 - val_loss: 2.6470e-04\n",
      "Epoch 906/2000\n",
      "4143/4143 [==============================] - 2s 600us/step - loss: 1.7619e-04 - val_loss: 1.3529e-04\n",
      "Epoch 907/2000\n",
      "4143/4143 [==============================] - 3s 606us/step - loss: 1.6153e-04 - val_loss: 1.3480e-04\n",
      "Epoch 908/2000\n",
      "4143/4143 [==============================] - 2s 594us/step - loss: 1.5638e-04 - val_loss: 1.5479e-04\n",
      "Epoch 909/2000\n",
      "4143/4143 [==============================] - 3s 636us/step - loss: 1.4454e-04 - val_loss: 1.9082e-04\n",
      "Epoch 910/2000\n",
      "4143/4143 [==============================] - 3s 617us/step - loss: 1.5342e-04 - val_loss: 1.5179e-04\n",
      "Epoch 911/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 1.6421e-04 - val_loss: 2.3333e-04\n",
      "Epoch 912/2000\n",
      "4143/4143 [==============================] - 3s 623us/step - loss: 1.8877e-04 - val_loss: 1.5550e-04\n",
      "Epoch 913/2000\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 1.6884e-04 - val_loss: 1.3221e-04\n",
      "Epoch 914/2000\n",
      "4143/4143 [==============================] - 3s 624us/step - loss: 1.4664e-04 - val_loss: 1.4874e-04\n",
      "Epoch 915/2000\n",
      "4143/4143 [==============================] - 3s 626us/step - loss: 1.4541e-04 - val_loss: 1.5208e-04\n",
      "Epoch 916/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 1.4822e-04 - val_loss: 1.3129e-04\n",
      "Epoch 917/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 1.4360e-04 - val_loss: 1.7399e-04\n",
      "Epoch 918/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 3s 619us/step - loss: 1.4451e-04 - val_loss: 1.3932e-04\n",
      "Epoch 919/2000\n",
      "4143/4143 [==============================] - 3s 625us/step - loss: 1.4276e-04 - val_loss: 1.3564e-04\n",
      "Epoch 920/2000\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 1.4326e-04 - val_loss: 1.5106e-04\n",
      "Epoch 921/2000\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 1.4463e-04 - val_loss: 1.6934e-04\n",
      "Epoch 922/2000\n",
      "4143/4143 [==============================] - 3s 633us/step - loss: 1.5426e-04 - val_loss: 1.3327e-04\n",
      "Epoch 923/2000\n",
      "4143/4143 [==============================] - 3s 614us/step - loss: 1.4902e-04 - val_loss: 1.8069e-04\n",
      "Epoch 924/2000\n",
      "4143/4143 [==============================] - 3s 613us/step - loss: 1.5504e-04 - val_loss: 1.4513e-04\n",
      "Epoch 925/2000\n",
      "4143/4143 [==============================] - 3s 620us/step - loss: 1.4575e-04 - val_loss: 1.5705e-04\n",
      "Epoch 926/2000\n",
      "4143/4143 [==============================] - 3s 618us/step - loss: 1.4794e-04 - val_loss: 1.3346e-04\n",
      "Epoch 927/2000\n",
      "4143/4143 [==============================] - 3s 615us/step - loss: 1.4297e-04 - val_loss: 2.0344e-04\n",
      "Epoch 928/2000\n",
      "4143/4143 [==============================] - 3s 621us/step - loss: 1.8947e-04 - val_loss: 2.8502e-04\n",
      "Epoch 929/2000\n",
      "4143/4143 [==============================] - 3s 622us/step - loss: 1.6659e-04 - val_loss: 2.5704e-04\n",
      "Epoch 930/2000\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 2.0306e-04 - val_loss: 2.4920e-04\n",
      "Epoch 931/2000\n",
      "4143/4143 [==============================] - 3s 616us/step - loss: 2.0517e-04 - val_loss: 1.9068e-04\n",
      "Epoch 932/2000\n",
      "4143/4143 [==============================] - 3s 612us/step - loss: 1.7343e-04 - val_loss: 1.3757e-04\n",
      "Epoch 933/2000\n",
      "4143/4143 [==============================] - 3s 627us/step - loss: 1.4698e-04 - val_loss: 1.3250e-04\n",
      "Epoch 934/2000\n",
      "4143/4143 [==============================] - 3s 611us/step - loss: 1.4202e-04 - val_loss: 1.3299e-04\n",
      "Epoch 935/2000\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 1.4170e-04 - val_loss: 1.4332e-04\n",
      "Epoch 936/2000\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 1.4210e-04 - val_loss: 1.5388e-04\n",
      "Epoch 937/2000\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 1.5019e-04 - val_loss: 2.6934e-04\n",
      "Epoch 938/2000\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 1.6465e-04 - val_loss: 2.5498e-04\n",
      "Epoch 939/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.9920e-04 - val_loss: 1.4648e-04\n",
      "Epoch 940/2000\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 1.4441e-04 - val_loss: 2.0145e-04\n",
      "Epoch 941/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7672e-04 - val_loss: 1.7077e-04\n",
      "Epoch 942/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5591e-04 - val_loss: 1.4147e-04\n",
      "Epoch 943/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4863e-04 - val_loss: 1.6018e-04\n",
      "Epoch 944/2000\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 1.4446e-04 - val_loss: 3.1478e-04\n",
      "Epoch 945/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.9314e-04 - val_loss: 2.2956e-04\n",
      "Epoch 946/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.6883e-04 - val_loss: 1.5197e-04\n",
      "Epoch 947/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.4676e-04 - val_loss: 1.3730e-04\n",
      "Epoch 948/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4485e-04 - val_loss: 2.0165e-04\n",
      "Epoch 949/2000\n",
      "4143/4143 [==============================] - 2s 589us/step - loss: 1.5178e-04 - val_loss: 1.3234e-04\n",
      "Epoch 950/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.5273e-04 - val_loss: 1.6131e-04\n",
      "Epoch 951/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6131e-04 - val_loss: 2.1998e-04\n",
      "Epoch 952/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5531e-04 - val_loss: 1.3348e-04\n",
      "Epoch 953/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.4460e-04 - val_loss: 1.3120e-04\n",
      "Epoch 954/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4015e-04 - val_loss: 1.3277e-04\n",
      "Epoch 955/2000\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 1.4203e-04 - val_loss: 1.3741e-04\n",
      "Epoch 956/2000\n",
      "4143/4143 [==============================] - 2s 578us/step - loss: 1.4590e-04 - val_loss: 1.9915e-04\n",
      "Epoch 957/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7423e-04 - val_loss: 2.0905e-04\n",
      "Epoch 958/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6433e-04 - val_loss: 1.9984e-04\n",
      "Epoch 959/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.7558e-04 - val_loss: 1.4546e-04\n",
      "Epoch 960/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.5606e-04 - val_loss: 1.7754e-04\n",
      "Epoch 961/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.6254e-04 - val_loss: 4.2751e-04\n",
      "Epoch 962/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 2.0427e-04 - val_loss: 1.8321e-04\n",
      "Epoch 963/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7523e-04 - val_loss: 1.3225e-04\n",
      "Epoch 964/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6168e-04 - val_loss: 1.6506e-04\n",
      "Epoch 965/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6217e-04 - val_loss: 1.3419e-04\n",
      "Epoch 966/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4024e-04 - val_loss: 1.3180e-04\n",
      "Epoch 967/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4353e-04 - val_loss: 1.4337e-04\n",
      "Epoch 968/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4324e-04 - val_loss: 1.3994e-04\n",
      "Epoch 969/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5209e-04 - val_loss: 1.6534e-04\n",
      "Epoch 970/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4818e-04 - val_loss: 1.5743e-04\n",
      "Epoch 971/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4281e-04 - val_loss: 1.7176e-04\n",
      "Epoch 972/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.7510e-04 - val_loss: 1.3538e-04\n",
      "Epoch 973/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5265e-04 - val_loss: 5.6206e-04\n",
      "Epoch 974/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 2.2769e-04 - val_loss: 1.5706e-04\n",
      "Epoch 975/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5812e-04 - val_loss: 1.8396e-04\n",
      "Epoch 976/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5232e-04 - val_loss: 1.3497e-04\n",
      "Epoch 977/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.5893e-04 - val_loss: 3.9414e-04\n",
      "Epoch 978/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.9942e-04 - val_loss: 1.3337e-04\n",
      "Epoch 979/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7459e-04 - val_loss: 1.3256e-04\n",
      "Epoch 980/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.5012e-04 - val_loss: 1.6580e-04\n",
      "Epoch 981/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4856e-04 - val_loss: 2.1454e-04\n",
      "Epoch 982/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6416e-04 - val_loss: 1.3239e-04\n",
      "Epoch 983/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5609e-04 - val_loss: 1.3417e-04\n",
      "Epoch 984/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4033e-04 - val_loss: 1.3516e-04\n",
      "Epoch 985/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3882e-04 - val_loss: 1.3354e-04\n",
      "Epoch 986/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4437e-04 - val_loss: 1.3123e-04\n",
      "Epoch 987/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3973e-04 - val_loss: 1.3134e-04\n",
      "Epoch 988/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4293e-04 - val_loss: 1.5322e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 989/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7175e-04 - val_loss: 1.4554e-04\n",
      "Epoch 990/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5140e-04 - val_loss: 1.8058e-04\n",
      "Epoch 991/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4685e-04 - val_loss: 1.3557e-04\n",
      "Epoch 992/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3914e-04 - val_loss: 1.3472e-04\n",
      "Epoch 993/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4924e-04 - val_loss: 1.3502e-04\n",
      "Epoch 994/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3955e-04 - val_loss: 1.4370e-04\n",
      "Epoch 995/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4178e-04 - val_loss: 1.4303e-04\n",
      "Epoch 996/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5418e-04 - val_loss: 1.5288e-04\n",
      "Epoch 997/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4841e-04 - val_loss: 1.7112e-04\n",
      "Epoch 998/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7844e-04 - val_loss: 1.6370e-04\n",
      "Epoch 999/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5625e-04 - val_loss: 1.3312e-04\n",
      "Epoch 1000/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6888e-04 - val_loss: 1.3814e-04\n",
      "Epoch 1001/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4281e-04 - val_loss: 1.3194e-04\n",
      "Epoch 1002/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4487e-04 - val_loss: 1.7623e-04\n",
      "Epoch 1003/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5786e-04 - val_loss: 1.8029e-04\n",
      "Epoch 1004/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.6999e-04 - val_loss: 2.6596e-04\n",
      "Epoch 1005/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.7309e-04 - val_loss: 1.4698e-04\n",
      "Epoch 1006/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5304e-04 - val_loss: 1.3330e-04\n",
      "Epoch 1007/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4600e-04 - val_loss: 1.3724e-04\n",
      "Epoch 1008/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4851e-04 - val_loss: 1.4458e-04\n",
      "Epoch 1009/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4628e-04 - val_loss: 2.4121e-04\n",
      "Epoch 1010/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6107e-04 - val_loss: 1.4656e-04\n",
      "Epoch 1011/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6608e-04 - val_loss: 1.3850e-04\n",
      "Epoch 1012/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5507e-04 - val_loss: 1.3373e-04\n",
      "Epoch 1013/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.3984e-04 - val_loss: 1.7706e-04\n",
      "Epoch 1014/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.5427e-04 - val_loss: 1.3840e-04\n",
      "Epoch 1015/2000\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 1.4363e-04 - val_loss: 1.6385e-04\n",
      "Epoch 1016/2000\n",
      "4143/4143 [==============================] - 2s 591us/step - loss: 1.5369e-04 - val_loss: 1.6373e-04\n",
      "Epoch 1017/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5222e-04 - val_loss: 3.2850e-04\n",
      "Epoch 1018/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7775e-04 - val_loss: 1.9189e-04\n",
      "Epoch 1019/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6952e-04 - val_loss: 1.3755e-04\n",
      "Epoch 1020/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6105e-04 - val_loss: 1.4414e-04\n",
      "Epoch 1021/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4248e-04 - val_loss: 1.5899e-04\n",
      "Epoch 1022/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4983e-04 - val_loss: 1.4792e-04\n",
      "Epoch 1023/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4765e-04 - val_loss: 1.9852e-04\n",
      "Epoch 1024/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5135e-04 - val_loss: 1.4296e-04\n",
      "Epoch 1025/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5245e-04 - val_loss: 1.3257e-04\n",
      "Epoch 1026/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4027e-04 - val_loss: 1.3430e-04\n",
      "Epoch 1027/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3975e-04 - val_loss: 1.4538e-04\n",
      "Epoch 1028/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4696e-04 - val_loss: 2.4973e-04\n",
      "Epoch 1029/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6393e-04 - val_loss: 1.5219e-04\n",
      "Epoch 1030/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.6095e-04 - val_loss: 2.8520e-04\n",
      "Epoch 1031/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 2.0014e-04 - val_loss: 1.4399e-04\n",
      "Epoch 1032/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.6984e-04 - val_loss: 2.4438e-04\n",
      "Epoch 1033/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.5884e-04 - val_loss: 1.3133e-04\n",
      "Epoch 1034/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4580e-04 - val_loss: 1.3232e-04\n",
      "Epoch 1035/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4000e-04 - val_loss: 1.3528e-04\n",
      "Epoch 1036/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4205e-04 - val_loss: 1.6970e-04\n",
      "Epoch 1037/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4906e-04 - val_loss: 1.4135e-04\n",
      "Epoch 1038/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4394e-04 - val_loss: 1.3237e-04\n",
      "Epoch 1039/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4444e-04 - val_loss: 1.5380e-04\n",
      "Epoch 1040/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6135e-04 - val_loss: 1.4581e-04\n",
      "Epoch 1041/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4744e-04 - val_loss: 1.4010e-04\n",
      "Epoch 1042/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6128e-04 - val_loss: 1.7917e-04\n",
      "Epoch 1043/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5224e-04 - val_loss: 1.3448e-04\n",
      "Epoch 1044/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4967e-04 - val_loss: 1.7385e-04\n",
      "Epoch 1045/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4715e-04 - val_loss: 1.4336e-04\n",
      "Epoch 1046/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4339e-04 - val_loss: 1.4561e-04\n",
      "Epoch 1047/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5411e-04 - val_loss: 1.3912e-04\n",
      "Epoch 1048/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4032e-04 - val_loss: 1.6537e-04\n",
      "Epoch 1049/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5843e-04 - val_loss: 1.8003e-04\n",
      "Epoch 1050/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5511e-04 - val_loss: 1.3225e-04\n",
      "Epoch 1051/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4628e-04 - val_loss: 2.3380e-04\n",
      "Epoch 1052/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.7517e-04 - val_loss: 2.2542e-04\n",
      "Epoch 1053/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5250e-04 - val_loss: 1.3243e-04\n",
      "Epoch 1054/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4094e-04 - val_loss: 1.8313e-04\n",
      "Epoch 1055/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.5612e-04 - val_loss: 1.3804e-04\n",
      "Epoch 1056/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4771e-04 - val_loss: 1.3575e-04\n",
      "Epoch 1057/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4740e-04 - val_loss: 1.3465e-04\n",
      "Epoch 1058/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4393e-04 - val_loss: 1.3128e-04\n",
      "Epoch 1059/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4247e-04 - val_loss: 1.4349e-04\n",
      "Epoch 1060/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4435e-04 - val_loss: 1.3545e-04\n",
      "Epoch 1061/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5708e-04 - val_loss: 1.4837e-04\n",
      "Epoch 1062/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4576e-04 - val_loss: 1.4764e-04\n",
      "Epoch 1063/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5053e-04 - val_loss: 1.3416e-04\n",
      "Epoch 1064/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4245e-04 - val_loss: 1.3298e-04\n",
      "Epoch 1065/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4278e-04 - val_loss: 1.6243e-04\n",
      "Epoch 1066/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5712e-04 - val_loss: 2.1521e-04\n",
      "Epoch 1067/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.9660e-04 - val_loss: 1.8209e-04\n",
      "Epoch 1068/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6059e-04 - val_loss: 1.9544e-04\n",
      "Epoch 1069/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6731e-04 - val_loss: 2.3958e-04\n",
      "Epoch 1070/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 2.0143e-04 - val_loss: 3.3831e-04\n",
      "Epoch 1071/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.6991e-04 - val_loss: 1.8289e-04\n",
      "Epoch 1072/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6013e-04 - val_loss: 1.9492e-04\n",
      "Epoch 1073/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5916e-04 - val_loss: 3.0173e-04\n",
      "Epoch 1074/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 2.1113e-04 - val_loss: 3.4595e-04\n",
      "Epoch 1075/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.9934e-04 - val_loss: 2.2305e-04\n",
      "Epoch 1076/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7614e-04 - val_loss: 1.3184e-04\n",
      "Epoch 1077/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.7356e-04 - val_loss: 3.3245e-04\n",
      "Epoch 1078/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.7258e-04 - val_loss: 1.6348e-04\n",
      "Epoch 1079/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.5382e-04 - val_loss: 1.6190e-04\n",
      "Epoch 1080/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5257e-04 - val_loss: 1.5904e-04\n",
      "Epoch 1081/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6778e-04 - val_loss: 2.1562e-04\n",
      "Epoch 1082/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5635e-04 - val_loss: 1.8369e-04\n",
      "Epoch 1083/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5877e-04 - val_loss: 1.3227e-04\n",
      "Epoch 1084/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5469e-04 - val_loss: 2.2596e-04\n",
      "Epoch 1085/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7011e-04 - val_loss: 1.3116e-04\n",
      "Epoch 1086/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4984e-04 - val_loss: 1.3741e-04\n",
      "Epoch 1087/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5290e-04 - val_loss: 1.9820e-04\n",
      "Epoch 1088/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6563e-04 - val_loss: 1.6918e-04\n",
      "Epoch 1089/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.5574e-04 - val_loss: 1.3254e-04\n",
      "Epoch 1090/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4606e-04 - val_loss: 1.4473e-04\n",
      "Epoch 1091/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4279e-04 - val_loss: 1.6532e-04\n",
      "Epoch 1092/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5049e-04 - val_loss: 1.4340e-04\n",
      "Epoch 1093/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4649e-04 - val_loss: 1.3307e-04\n",
      "Epoch 1094/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4153e-04 - val_loss: 1.5713e-04\n",
      "Epoch 1095/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5838e-04 - val_loss: 2.2553e-04\n",
      "Epoch 1096/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6919e-04 - val_loss: 1.3620e-04\n",
      "Epoch 1097/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4479e-04 - val_loss: 1.7098e-04\n",
      "Epoch 1098/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6459e-04 - val_loss: 1.4308e-04\n",
      "Epoch 1099/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5923e-04 - val_loss: 3.5085e-04\n",
      "Epoch 1100/2000\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 2.0525e-04 - val_loss: 1.9706e-04\n",
      "Epoch 1101/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7895e-04 - val_loss: 1.5224e-04\n",
      "Epoch 1102/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4727e-04 - val_loss: 1.6185e-04\n",
      "Epoch 1103/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4411e-04 - val_loss: 1.7204e-04\n",
      "Epoch 1104/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.5354e-04 - val_loss: 1.3177e-04\n",
      "Epoch 1105/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4136e-04 - val_loss: 1.3643e-04\n",
      "Epoch 1106/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4001e-04 - val_loss: 1.3233e-04\n",
      "Epoch 1107/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4418e-04 - val_loss: 1.3352e-04\n",
      "Epoch 1108/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5127e-04 - val_loss: 1.8598e-04\n",
      "Epoch 1109/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6356e-04 - val_loss: 1.4539e-04\n",
      "Epoch 1110/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4711e-04 - val_loss: 1.3060e-04\n",
      "Epoch 1111/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4908e-04 - val_loss: 1.9683e-04\n",
      "Epoch 1112/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6419e-04 - val_loss: 1.4544e-04\n",
      "Epoch 1113/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4689e-04 - val_loss: 1.8793e-04\n",
      "Epoch 1114/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5295e-04 - val_loss: 1.4042e-04\n",
      "Epoch 1115/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4322e-04 - val_loss: 2.0168e-04\n",
      "Epoch 1116/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.6062e-04 - val_loss: 1.3493e-04\n",
      "Epoch 1117/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4901e-04 - val_loss: 1.3238e-04\n",
      "Epoch 1118/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4355e-04 - val_loss: 1.3324e-04\n",
      "Epoch 1119/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4451e-04 - val_loss: 1.7446e-04\n",
      "Epoch 1120/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5894e-04 - val_loss: 1.6796e-04\n",
      "Epoch 1121/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5194e-04 - val_loss: 2.8377e-04\n",
      "Epoch 1122/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7766e-04 - val_loss: 1.3305e-04\n",
      "Epoch 1123/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.6017e-04 - val_loss: 1.6899e-04\n",
      "Epoch 1124/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6369e-04 - val_loss: 3.0084e-04\n",
      "Epoch 1125/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7672e-04 - val_loss: 1.4798e-04\n",
      "Epoch 1126/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4732e-04 - val_loss: 1.6415e-04\n",
      "Epoch 1127/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4726e-04 - val_loss: 1.3573e-04\n",
      "Epoch 1128/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4338e-04 - val_loss: 1.7418e-04\n",
      "Epoch 1129/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.5081e-04 - val_loss: 1.3207e-04\n",
      "Epoch 1130/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3989e-04 - val_loss: 1.6657e-04\n",
      "Epoch 1131/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4451e-04 - val_loss: 1.3226e-04\n",
      "Epoch 1132/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4073e-04 - val_loss: 1.6710e-04\n",
      "Epoch 1133/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5020e-04 - val_loss: 1.7256e-04\n",
      "Epoch 1134/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4488e-04 - val_loss: 1.7544e-04\n",
      "Epoch 1135/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6116e-04 - val_loss: 1.3699e-04\n",
      "Epoch 1136/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4250e-04 - val_loss: 1.4145e-04\n",
      "Epoch 1137/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4417e-04 - val_loss: 1.3322e-04\n",
      "Epoch 1138/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4752e-04 - val_loss: 1.3222e-04\n",
      "Epoch 1139/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4007e-04 - val_loss: 1.3643e-04\n",
      "Epoch 1140/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4416e-04 - val_loss: 1.4365e-04\n",
      "Epoch 1141/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3997e-04 - val_loss: 2.0401e-04\n",
      "Epoch 1142/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5106e-04 - val_loss: 1.3242e-04\n",
      "Epoch 1143/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4960e-04 - val_loss: 1.8119e-04\n",
      "Epoch 1144/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5726e-04 - val_loss: 1.3701e-04\n",
      "Epoch 1145/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5237e-04 - val_loss: 1.4172e-04\n",
      "Epoch 1146/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4317e-04 - val_loss: 1.4575e-04\n",
      "Epoch 1147/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3822e-04 - val_loss: 1.3321e-04\n",
      "Epoch 1148/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.3975e-04 - val_loss: 1.4240e-04\n",
      "Epoch 1149/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4174e-04 - val_loss: 1.5510e-04\n",
      "Epoch 1150/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4358e-04 - val_loss: 1.7173e-04\n",
      "Epoch 1151/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5782e-04 - val_loss: 1.3488e-04\n",
      "Epoch 1152/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4111e-04 - val_loss: 1.3329e-04\n",
      "Epoch 1153/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4014e-04 - val_loss: 1.3800e-04\n",
      "Epoch 1154/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4041e-04 - val_loss: 1.5443e-04\n",
      "Epoch 1155/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4476e-04 - val_loss: 1.4956e-04\n",
      "Epoch 1156/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4291e-04 - val_loss: 1.3303e-04\n",
      "Epoch 1157/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4153e-04 - val_loss: 1.3215e-04\n",
      "Epoch 1158/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4862e-04 - val_loss: 1.4941e-04\n",
      "Epoch 1159/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4580e-04 - val_loss: 1.6151e-04\n",
      "Epoch 1160/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5599e-04 - val_loss: 1.3372e-04\n",
      "Epoch 1161/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4122e-04 - val_loss: 1.4653e-04\n",
      "Epoch 1162/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3992e-04 - val_loss: 1.5292e-04\n",
      "Epoch 1163/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4990e-04 - val_loss: 1.3819e-04\n",
      "Epoch 1164/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4020e-04 - val_loss: 1.5721e-04\n",
      "Epoch 1165/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4503e-04 - val_loss: 2.7289e-04\n",
      "Epoch 1166/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7827e-04 - val_loss: 1.9208e-04\n",
      "Epoch 1167/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6701e-04 - val_loss: 1.5432e-04\n",
      "Epoch 1168/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4684e-04 - val_loss: 1.3563e-04\n",
      "Epoch 1169/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4633e-04 - val_loss: 1.3333e-04\n",
      "Epoch 1170/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4149e-04 - val_loss: 1.5869e-04\n",
      "Epoch 1171/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5008e-04 - val_loss: 2.0717e-04\n",
      "Epoch 1172/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.8661e-04 - val_loss: 1.3413e-04\n",
      "Epoch 1173/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.5695e-04 - val_loss: 2.0882e-04\n",
      "Epoch 1174/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.7342e-04 - val_loss: 1.3992e-04\n",
      "Epoch 1175/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5005e-04 - val_loss: 1.3544e-04\n",
      "Epoch 1176/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5040e-04 - val_loss: 1.3590e-04\n",
      "Epoch 1177/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4799e-04 - val_loss: 1.3538e-04\n",
      "Epoch 1178/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3923e-04 - val_loss: 1.3126e-04\n",
      "Epoch 1179/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.4157e-04 - val_loss: 1.4432e-04\n",
      "Epoch 1180/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4389e-04 - val_loss: 1.3348e-04\n",
      "Epoch 1181/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4996e-04 - val_loss: 1.6291e-04\n",
      "Epoch 1182/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5271e-04 - val_loss: 1.3238e-04\n",
      "Epoch 1183/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3950e-04 - val_loss: 1.3609e-04\n",
      "Epoch 1184/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4063e-04 - val_loss: 2.2892e-04\n",
      "Epoch 1185/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6992e-04 - val_loss: 1.4444e-04\n",
      "Epoch 1186/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5091e-04 - val_loss: 1.3359e-04\n",
      "Epoch 1187/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4726e-04 - val_loss: 1.7480e-04\n",
      "Epoch 1188/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.5430e-04 - val_loss: 1.3449e-04\n",
      "Epoch 1189/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5919e-04 - val_loss: 2.2929e-04\n",
      "Epoch 1190/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7980e-04 - val_loss: 1.4313e-04\n",
      "Epoch 1191/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4569e-04 - val_loss: 1.8586e-04\n",
      "Epoch 1192/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5515e-04 - val_loss: 1.3372e-04\n",
      "Epoch 1193/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4146e-04 - val_loss: 1.6117e-04\n",
      "Epoch 1194/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5738e-04 - val_loss: 1.4256e-04\n",
      "Epoch 1195/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6034e-04 - val_loss: 1.6375e-04\n",
      "Epoch 1196/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4179e-04 - val_loss: 1.5259e-04\n",
      "Epoch 1197/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4105e-04 - val_loss: 1.5686e-04\n",
      "Epoch 1198/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4400e-04 - val_loss: 1.3260e-04\n",
      "Epoch 1199/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4151e-04 - val_loss: 3.6100e-04\n",
      "Epoch 1200/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 2.1008e-04 - val_loss: 2.1838e-04\n",
      "Epoch 1201/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5845e-04 - val_loss: 1.3231e-04\n",
      "Epoch 1202/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4731e-04 - val_loss: 1.7758e-04\n",
      "Epoch 1203/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4873e-04 - val_loss: 1.4242e-04\n",
      "Epoch 1204/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4079e-04 - val_loss: 1.7309e-04\n",
      "Epoch 1205/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5244e-04 - val_loss: 1.8831e-04\n",
      "Epoch 1206/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5321e-04 - val_loss: 1.8391e-04\n",
      "Epoch 1207/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5318e-04 - val_loss: 1.7053e-04\n",
      "Epoch 1208/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5778e-04 - val_loss: 1.5787e-04\n",
      "Epoch 1209/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5032e-04 - val_loss: 1.3315e-04\n",
      "Epoch 1210/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4315e-04 - val_loss: 1.3462e-04\n",
      "Epoch 1211/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4154e-04 - val_loss: 1.3714e-04\n",
      "Epoch 1212/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4365e-04 - val_loss: 1.3256e-04\n",
      "Epoch 1213/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.3968e-04 - val_loss: 1.3871e-04\n",
      "Epoch 1214/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4894e-04 - val_loss: 1.5504e-04\n",
      "Epoch 1215/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4768e-04 - val_loss: 1.4473e-04\n",
      "Epoch 1216/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4187e-04 - val_loss: 1.4001e-04\n",
      "Epoch 1217/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4189e-04 - val_loss: 1.3728e-04\n",
      "Epoch 1218/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3906e-04 - val_loss: 1.3386e-04\n",
      "Epoch 1219/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4319e-04 - val_loss: 1.4903e-04\n",
      "Epoch 1220/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4720e-04 - val_loss: 1.3603e-04\n",
      "Epoch 1221/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5281e-04 - val_loss: 2.1979e-04\n",
      "Epoch 1222/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5037e-04 - val_loss: 1.3132e-04\n",
      "Epoch 1223/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4124e-04 - val_loss: 2.0317e-04\n",
      "Epoch 1224/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6650e-04 - val_loss: 1.9249e-04\n",
      "Epoch 1225/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5038e-04 - val_loss: 1.4975e-04\n",
      "Epoch 1226/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5200e-04 - val_loss: 1.4390e-04\n",
      "Epoch 1227/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4461e-04 - val_loss: 1.4885e-04\n",
      "Epoch 1228/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4530e-04 - val_loss: 1.6662e-04\n",
      "Epoch 1229/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6343e-04 - val_loss: 1.4077e-04\n",
      "Epoch 1230/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.5582e-04 - val_loss: 1.3892e-04\n",
      "Epoch 1231/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5088e-04 - val_loss: 1.3165e-04\n",
      "Epoch 1232/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4469e-04 - val_loss: 1.7283e-04\n",
      "Epoch 1233/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5538e-04 - val_loss: 1.5481e-04\n",
      "Epoch 1234/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4553e-04 - val_loss: 1.3142e-04\n",
      "Epoch 1235/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.3860e-04 - val_loss: 1.4591e-04\n",
      "Epoch 1236/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5271e-04 - val_loss: 2.3302e-04\n",
      "Epoch 1237/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 2.0002e-04 - val_loss: 4.4108e-04\n",
      "Epoch 1238/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 2.1296e-04 - val_loss: 2.3244e-04\n",
      "Epoch 1239/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.8735e-04 - val_loss: 1.9590e-04\n",
      "Epoch 1240/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6598e-04 - val_loss: 1.9527e-04\n",
      "Epoch 1241/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.5887e-04 - val_loss: 1.4807e-04\n",
      "Epoch 1242/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4061e-04 - val_loss: 1.3629e-04\n",
      "Epoch 1243/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4278e-04 - val_loss: 1.7512e-04\n",
      "Epoch 1244/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5212e-04 - val_loss: 1.3357e-04\n",
      "Epoch 1245/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.3945e-04 - val_loss: 1.3134e-04\n",
      "Epoch 1246/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3916e-04 - val_loss: 1.6507e-04\n",
      "Epoch 1247/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5440e-04 - val_loss: 1.8661e-04\n",
      "Epoch 1248/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5805e-04 - val_loss: 1.4702e-04\n",
      "Epoch 1249/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4145e-04 - val_loss: 1.3185e-04\n",
      "Epoch 1250/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4673e-04 - val_loss: 1.3144e-04\n",
      "Epoch 1251/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4229e-04 - val_loss: 1.7031e-04\n",
      "Epoch 1252/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4834e-04 - val_loss: 1.4603e-04\n",
      "Epoch 1253/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4060e-04 - val_loss: 1.4016e-04\n",
      "Epoch 1254/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4235e-04 - val_loss: 1.9690e-04\n",
      "Epoch 1255/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5505e-04 - val_loss: 1.3329e-04\n",
      "Epoch 1256/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4203e-04 - val_loss: 1.4741e-04\n",
      "Epoch 1257/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4754e-04 - val_loss: 2.6989e-04\n",
      "Epoch 1258/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.5556e-04 - val_loss: 1.3831e-04\n",
      "Epoch 1259/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4684e-04 - val_loss: 1.3627e-04\n",
      "Epoch 1260/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4169e-04 - val_loss: 1.6429e-04\n",
      "Epoch 1261/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5511e-04 - val_loss: 1.7448e-04\n",
      "Epoch 1262/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6468e-04 - val_loss: 1.8815e-04\n",
      "Epoch 1263/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6028e-04 - val_loss: 1.3932e-04\n",
      "Epoch 1264/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4000e-04 - val_loss: 1.4839e-04\n",
      "Epoch 1265/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4584e-04 - val_loss: 1.6270e-04\n",
      "Epoch 1266/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4731e-04 - val_loss: 1.3758e-04\n",
      "Epoch 1267/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5837e-04 - val_loss: 1.4092e-04\n",
      "Epoch 1268/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4277e-04 - val_loss: 1.7304e-04\n",
      "Epoch 1269/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.5337e-04 - val_loss: 1.3336e-04\n",
      "Epoch 1270/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5205e-04 - val_loss: 1.4324e-04\n",
      "Epoch 1271/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4222e-04 - val_loss: 1.3385e-04\n",
      "Epoch 1272/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4460e-04 - val_loss: 1.7748e-04\n",
      "Epoch 1273/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4642e-04 - val_loss: 1.3107e-04\n",
      "Epoch 1274/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4276e-04 - val_loss: 1.7588e-04\n",
      "Epoch 1275/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5237e-04 - val_loss: 1.3087e-04\n",
      "Epoch 1276/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3971e-04 - val_loss: 1.3806e-04\n",
      "Epoch 1277/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4155e-04 - val_loss: 2.6331e-04\n",
      "Epoch 1278/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.5890e-04 - val_loss: 2.3910e-04\n",
      "Epoch 1279/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.8093e-04 - val_loss: 1.8446e-04\n",
      "Epoch 1280/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.8861e-04 - val_loss: 1.4170e-04\n",
      "Epoch 1281/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5983e-04 - val_loss: 1.4564e-04\n",
      "Epoch 1282/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5925e-04 - val_loss: 2.0988e-04\n",
      "Epoch 1283/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5656e-04 - val_loss: 1.9251e-04\n",
      "Epoch 1284/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6017e-04 - val_loss: 1.6549e-04\n",
      "Epoch 1285/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6081e-04 - val_loss: 1.4087e-04\n",
      "Epoch 1286/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4175e-04 - val_loss: 1.6663e-04\n",
      "Epoch 1287/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5251e-04 - val_loss: 1.3578e-04\n",
      "Epoch 1288/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5781e-04 - val_loss: 1.3298e-04\n",
      "Epoch 1289/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5325e-04 - val_loss: 1.9285e-04\n",
      "Epoch 1290/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4701e-04 - val_loss: 1.3466e-04\n",
      "Epoch 1291/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3970e-04 - val_loss: 1.4710e-04\n",
      "Epoch 1292/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4182e-04 - val_loss: 1.3751e-04\n",
      "Epoch 1293/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3858e-04 - val_loss: 2.1935e-04\n",
      "Epoch 1294/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5595e-04 - val_loss: 1.4767e-04\n",
      "Epoch 1295/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4264e-04 - val_loss: 1.3569e-04\n",
      "Epoch 1296/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4334e-04 - val_loss: 1.3608e-04\n",
      "Epoch 1297/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3997e-04 - val_loss: 1.3749e-04\n",
      "Epoch 1298/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4940e-04 - val_loss: 1.3882e-04\n",
      "Epoch 1299/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5485e-04 - val_loss: 1.5223e-04\n",
      "Epoch 1300/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7327e-04 - val_loss: 2.2533e-04\n",
      "Epoch 1301/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5148e-04 - val_loss: 1.4691e-04\n",
      "Epoch 1302/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.5583e-04 - val_loss: 1.3986e-04\n",
      "Epoch 1303/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.5627e-04 - val_loss: 2.5894e-04\n",
      "Epoch 1304/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.7405e-04 - val_loss: 1.3518e-04\n",
      "Epoch 1305/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6304e-04 - val_loss: 1.6666e-04\n",
      "Epoch 1306/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5016e-04 - val_loss: 1.4860e-04\n",
      "Epoch 1307/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4982e-04 - val_loss: 1.6005e-04\n",
      "Epoch 1308/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4776e-04 - val_loss: 1.4436e-04\n",
      "Epoch 1309/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4156e-04 - val_loss: 2.1509e-04\n",
      "Epoch 1310/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6067e-04 - val_loss: 1.6815e-04\n",
      "Epoch 1311/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6809e-04 - val_loss: 1.3581e-04\n",
      "Epoch 1312/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5395e-04 - val_loss: 1.5203e-04\n",
      "Epoch 1313/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4521e-04 - val_loss: 1.3409e-04\n",
      "Epoch 1314/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4112e-04 - val_loss: 1.3268e-04\n",
      "Epoch 1315/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3942e-04 - val_loss: 1.5373e-04\n",
      "Epoch 1316/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4275e-04 - val_loss: 1.5062e-04\n",
      "Epoch 1317/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4449e-04 - val_loss: 1.3311e-04\n",
      "Epoch 1318/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4348e-04 - val_loss: 1.3452e-04\n",
      "Epoch 1319/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4296e-04 - val_loss: 2.0828e-04\n",
      "Epoch 1320/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6167e-04 - val_loss: 1.3143e-04\n",
      "Epoch 1321/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5311e-04 - val_loss: 1.3212e-04\n",
      "Epoch 1322/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4193e-04 - val_loss: 1.3225e-04\n",
      "Epoch 1323/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3890e-04 - val_loss: 1.5227e-04\n",
      "Epoch 1324/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4966e-04 - val_loss: 1.5060e-04\n",
      "Epoch 1325/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4714e-04 - val_loss: 1.3247e-04\n",
      "Epoch 1326/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4073e-04 - val_loss: 1.7526e-04\n",
      "Epoch 1327/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5236e-04 - val_loss: 2.4071e-04\n",
      "Epoch 1328/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.6511e-04 - val_loss: 1.8514e-04\n",
      "Epoch 1329/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.9463e-04 - val_loss: 1.3226e-04\n",
      "Epoch 1330/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6750e-04 - val_loss: 2.9227e-04\n",
      "Epoch 1331/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.9155e-04 - val_loss: 3.2938e-04\n",
      "Epoch 1332/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 2.0141e-04 - val_loss: 1.8438e-04\n",
      "Epoch 1333/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5453e-04 - val_loss: 1.5120e-04\n",
      "Epoch 1334/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4541e-04 - val_loss: 1.4988e-04\n",
      "Epoch 1335/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4762e-04 - val_loss: 1.3322e-04\n",
      "Epoch 1336/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4019e-04 - val_loss: 1.8582e-04\n",
      "Epoch 1337/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5099e-04 - val_loss: 1.3949e-04\n",
      "Epoch 1338/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4832e-04 - val_loss: 1.4426e-04\n",
      "Epoch 1339/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4117e-04 - val_loss: 1.8568e-04\n",
      "Epoch 1340/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4802e-04 - val_loss: 1.4690e-04\n",
      "Epoch 1341/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5238e-04 - val_loss: 1.3361e-04\n",
      "Epoch 1342/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4395e-04 - val_loss: 2.1727e-04\n",
      "Epoch 1343/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6782e-04 - val_loss: 1.4799e-04\n",
      "Epoch 1344/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4538e-04 - val_loss: 1.3551e-04\n",
      "Epoch 1345/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4283e-04 - val_loss: 1.3338e-04\n",
      "Epoch 1346/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4343e-04 - val_loss: 1.3235e-04\n",
      "Epoch 1347/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4448e-04 - val_loss: 1.6580e-04\n",
      "Epoch 1348/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4564e-04 - val_loss: 1.4502e-04\n",
      "Epoch 1349/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4150e-04 - val_loss: 1.3419e-04\n",
      "Epoch 1350/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4685e-04 - val_loss: 1.3695e-04\n",
      "Epoch 1351/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4689e-04 - val_loss: 2.0638e-04\n",
      "Epoch 1352/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6357e-04 - val_loss: 4.9468e-04\n",
      "Epoch 1353/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 2.3287e-04 - val_loss: 2.0315e-04\n",
      "Epoch 1354/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4632e-04 - val_loss: 1.3528e-04\n",
      "Epoch 1355/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5429e-04 - val_loss: 1.3595e-04\n",
      "Epoch 1356/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4255e-04 - val_loss: 1.4580e-04\n",
      "Epoch 1357/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4824e-04 - val_loss: 1.8258e-04\n",
      "Epoch 1358/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5240e-04 - val_loss: 1.3841e-04\n",
      "Epoch 1359/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4133e-04 - val_loss: 1.5803e-04\n",
      "Epoch 1360/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4173e-04 - val_loss: 1.3332e-04\n",
      "Epoch 1361/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.3805e-04 - val_loss: 1.3309e-04\n",
      "Epoch 1362/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3955e-04 - val_loss: 1.3476e-04\n",
      "Epoch 1363/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4489e-04 - val_loss: 1.3330e-04\n",
      "Epoch 1364/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4396e-04 - val_loss: 1.4539e-04\n",
      "Epoch 1365/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4337e-04 - val_loss: 1.5674e-04\n",
      "Epoch 1366/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4920e-04 - val_loss: 1.3332e-04\n",
      "Epoch 1367/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4469e-04 - val_loss: 2.2837e-04\n",
      "Epoch 1368/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7336e-04 - val_loss: 2.9509e-04\n",
      "Epoch 1369/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 2.1932e-04 - val_loss: 2.1637e-04\n",
      "Epoch 1370/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 2.0359e-04 - val_loss: 1.3925e-04\n",
      "Epoch 1371/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.7820e-04 - val_loss: 2.9695e-04\n",
      "Epoch 1372/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.7847e-04 - val_loss: 1.3172e-04\n",
      "Epoch 1373/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4538e-04 - val_loss: 1.5731e-04\n",
      "Epoch 1374/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4453e-04 - val_loss: 1.5858e-04\n",
      "Epoch 1375/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4374e-04 - val_loss: 1.4763e-04\n",
      "Epoch 1376/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4416e-04 - val_loss: 1.4002e-04\n",
      "Epoch 1377/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4329e-04 - val_loss: 1.4516e-04\n",
      "Epoch 1378/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5517e-04 - val_loss: 1.6233e-04\n",
      "Epoch 1379/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4844e-04 - val_loss: 1.4968e-04\n",
      "Epoch 1380/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5444e-04 - val_loss: 1.3646e-04\n",
      "Epoch 1381/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4466e-04 - val_loss: 1.5317e-04\n",
      "Epoch 1382/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4473e-04 - val_loss: 1.3316e-04\n",
      "Epoch 1383/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3744e-04 - val_loss: 1.4545e-04\n",
      "Epoch 1384/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3788e-04 - val_loss: 2.0499e-04\n",
      "Epoch 1385/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6527e-04 - val_loss: 1.8573e-04\n",
      "Epoch 1386/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5178e-04 - val_loss: 1.6453e-04\n",
      "Epoch 1387/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5055e-04 - val_loss: 2.2109e-04\n",
      "Epoch 1388/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7415e-04 - val_loss: 2.7103e-04\n",
      "Epoch 1389/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.9207e-04 - val_loss: 1.6179e-04\n",
      "Epoch 1390/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5209e-04 - val_loss: 1.5813e-04\n",
      "Epoch 1391/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.5329e-04 - val_loss: 1.3467e-04\n",
      "Epoch 1392/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4345e-04 - val_loss: 1.4815e-04\n",
      "Epoch 1393/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4572e-04 - val_loss: 1.3632e-04\n",
      "Epoch 1394/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4043e-04 - val_loss: 1.4236e-04\n",
      "Epoch 1395/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.3767e-04 - val_loss: 1.5461e-04\n",
      "Epoch 1396/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4541e-04 - val_loss: 1.3346e-04\n",
      "Epoch 1397/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4212e-04 - val_loss: 1.3529e-04\n",
      "Epoch 1398/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3854e-04 - val_loss: 1.3835e-04\n",
      "Epoch 1399/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4235e-04 - val_loss: 1.6642e-04\n",
      "Epoch 1400/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5149e-04 - val_loss: 1.3833e-04\n",
      "Epoch 1401/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4822e-04 - val_loss: 1.5281e-04\n",
      "Epoch 1402/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3825e-04 - val_loss: 1.3577e-04\n",
      "Epoch 1403/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3839e-04 - val_loss: 1.6406e-04\n",
      "Epoch 1404/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5648e-04 - val_loss: 1.5877e-04\n",
      "Epoch 1405/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4767e-04 - val_loss: 1.6111e-04\n",
      "Epoch 1406/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4285e-04 - val_loss: 2.0968e-04\n",
      "Epoch 1407/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5535e-04 - val_loss: 1.3296e-04\n",
      "Epoch 1408/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4909e-04 - val_loss: 1.4342e-04\n",
      "Epoch 1409/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4378e-04 - val_loss: 1.4017e-04\n",
      "Epoch 1410/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.3914e-04 - val_loss: 1.4467e-04\n",
      "Epoch 1411/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4058e-04 - val_loss: 1.4394e-04\n",
      "Epoch 1412/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4753e-04 - val_loss: 1.4863e-04\n",
      "Epoch 1413/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5363e-04 - val_loss: 1.3595e-04\n",
      "Epoch 1414/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4043e-04 - val_loss: 1.3283e-04\n",
      "Epoch 1415/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4239e-04 - val_loss: 1.3841e-04\n",
      "Epoch 1416/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4256e-04 - val_loss: 1.4707e-04\n",
      "Epoch 1417/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.3891e-04 - val_loss: 1.4364e-04\n",
      "Epoch 1418/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3703e-04 - val_loss: 1.5500e-04\n",
      "Epoch 1419/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4587e-04 - val_loss: 1.3236e-04\n",
      "Epoch 1420/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5618e-04 - val_loss: 1.4009e-04\n",
      "Epoch 1421/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4108e-04 - val_loss: 1.4193e-04\n",
      "Epoch 1422/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4200e-04 - val_loss: 1.3242e-04\n",
      "Epoch 1423/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4106e-04 - val_loss: 1.3781e-04\n",
      "Epoch 1424/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4583e-04 - val_loss: 1.4805e-04\n",
      "Epoch 1425/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4096e-04 - val_loss: 1.3693e-04\n",
      "Epoch 1426/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4188e-04 - val_loss: 1.3643e-04\n",
      "Epoch 1427/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3991e-04 - val_loss: 2.9398e-04\n",
      "Epoch 1428/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.7056e-04 - val_loss: 1.5852e-04\n",
      "Epoch 1429/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6287e-04 - val_loss: 1.3692e-04\n",
      "Epoch 1430/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4537e-04 - val_loss: 1.5429e-04\n",
      "Epoch 1431/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4786e-04 - val_loss: 2.3445e-04\n",
      "Epoch 1432/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5559e-04 - val_loss: 1.4179e-04\n",
      "Epoch 1433/2000\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 1.4603e-04 - val_loss: 1.3494e-04\n",
      "Epoch 1434/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4085e-04 - val_loss: 1.3992e-04\n",
      "Epoch 1435/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4110e-04 - val_loss: 1.3543e-04\n",
      "Epoch 1436/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4851e-04 - val_loss: 1.4162e-04\n",
      "Epoch 1437/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.3763e-04 - val_loss: 1.6123e-04\n",
      "Epoch 1438/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4187e-04 - val_loss: 1.5350e-04\n",
      "Epoch 1439/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4258e-04 - val_loss: 1.3405e-04\n",
      "Epoch 1440/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.4910e-04 - val_loss: 1.4591e-04\n",
      "Epoch 1441/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4916e-04 - val_loss: 2.0212e-04\n",
      "Epoch 1442/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5267e-04 - val_loss: 1.6037e-04\n",
      "Epoch 1443/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4626e-04 - val_loss: 1.3517e-04\n",
      "Epoch 1444/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4108e-04 - val_loss: 1.6577e-04\n",
      "Epoch 1445/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4811e-04 - val_loss: 1.3716e-04\n",
      "Epoch 1446/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4327e-04 - val_loss: 1.5020e-04\n",
      "Epoch 1447/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4555e-04 - val_loss: 1.6281e-04\n",
      "Epoch 1448/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5456e-04 - val_loss: 1.3846e-04\n",
      "Epoch 1449/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5119e-04 - val_loss: 1.3666e-04\n",
      "Epoch 1450/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3886e-04 - val_loss: 1.4916e-04\n",
      "Epoch 1451/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4335e-04 - val_loss: 1.3382e-04\n",
      "Epoch 1452/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4649e-04 - val_loss: 1.8044e-04\n",
      "Epoch 1453/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6299e-04 - val_loss: 1.3668e-04\n",
      "Epoch 1454/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4872e-04 - val_loss: 1.7371e-04\n",
      "Epoch 1455/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4652e-04 - val_loss: 1.3822e-04\n",
      "Epoch 1456/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4653e-04 - val_loss: 1.3247e-04\n",
      "Epoch 1457/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4085e-04 - val_loss: 1.3551e-04\n",
      "Epoch 1458/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4327e-04 - val_loss: 1.7199e-04\n",
      "Epoch 1459/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4818e-04 - val_loss: 1.6451e-04\n",
      "Epoch 1460/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.6874e-04 - val_loss: 1.3497e-04\n",
      "Epoch 1461/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4875e-04 - val_loss: 1.3903e-04\n",
      "Epoch 1462/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5913e-04 - val_loss: 1.5387e-04\n",
      "Epoch 1463/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3949e-04 - val_loss: 1.6770e-04\n",
      "Epoch 1464/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4493e-04 - val_loss: 1.3296e-04\n",
      "Epoch 1465/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4398e-04 - val_loss: 1.3106e-04\n",
      "Epoch 1466/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3717e-04 - val_loss: 1.8284e-04\n",
      "Epoch 1467/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4841e-04 - val_loss: 1.3382e-04\n",
      "Epoch 1468/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4695e-04 - val_loss: 1.6804e-04\n",
      "Epoch 1469/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4620e-04 - val_loss: 2.7900e-04\n",
      "Epoch 1470/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.7248e-04 - val_loss: 1.3753e-04\n",
      "Epoch 1471/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4646e-04 - val_loss: 1.5374e-04\n",
      "Epoch 1472/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5553e-04 - val_loss: 1.5753e-04\n",
      "Epoch 1473/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4252e-04 - val_loss: 1.3302e-04\n",
      "Epoch 1474/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4410e-04 - val_loss: 1.8352e-04\n",
      "Epoch 1475/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4457e-04 - val_loss: 1.3640e-04\n",
      "Epoch 1476/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4198e-04 - val_loss: 1.3940e-04\n",
      "Epoch 1477/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5260e-04 - val_loss: 2.3591e-04\n",
      "Epoch 1478/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7256e-04 - val_loss: 1.3636e-04\n",
      "Epoch 1479/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4232e-04 - val_loss: 1.4194e-04\n",
      "Epoch 1480/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4510e-04 - val_loss: 1.4056e-04\n",
      "Epoch 1481/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4278e-04 - val_loss: 1.5992e-04\n",
      "Epoch 1482/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3846e-04 - val_loss: 1.3102e-04\n",
      "Epoch 1483/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4088e-04 - val_loss: 1.6719e-04\n",
      "Epoch 1484/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4802e-04 - val_loss: 1.4065e-04\n",
      "Epoch 1485/2000\n",
      "4143/4143 [==============================] - 2s 590us/step - loss: 1.4102e-04 - val_loss: 1.3845e-04\n",
      "Epoch 1486/2000\n",
      "4143/4143 [==============================] - 2s 598us/step - loss: 1.4535e-04 - val_loss: 1.7672e-04\n",
      "Epoch 1487/2000\n",
      "4143/4143 [==============================] - 2s 601us/step - loss: 1.4655e-04 - val_loss: 1.7469e-04\n",
      "Epoch 1488/2000\n",
      "4143/4143 [==============================] - 2s 602us/step - loss: 1.4599e-04 - val_loss: 1.3836e-04\n",
      "Epoch 1489/2000\n",
      "4143/4143 [==============================] - 2s 576us/step - loss: 1.4237e-04 - val_loss: 1.3154e-04\n",
      "Epoch 1490/2000\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 1.3881e-04 - val_loss: 1.3271e-04\n",
      "Epoch 1491/2000\n",
      "4143/4143 [==============================] - 2s 593us/step - loss: 1.4336e-04 - val_loss: 2.1221e-04\n",
      "Epoch 1492/2000\n",
      "4143/4143 [==============================] - 2s 592us/step - loss: 1.5608e-04 - val_loss: 1.8652e-04\n",
      "Epoch 1493/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4947e-04 - val_loss: 1.6056e-04\n",
      "Epoch 1494/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.5539e-04 - val_loss: 1.6015e-04\n",
      "Epoch 1495/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4489e-04 - val_loss: 1.8718e-04\n",
      "Epoch 1496/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5824e-04 - val_loss: 1.3893e-04\n",
      "Epoch 1497/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5404e-04 - val_loss: 1.8961e-04\n",
      "Epoch 1498/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6461e-04 - val_loss: 1.5623e-04\n",
      "Epoch 1499/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4617e-04 - val_loss: 1.5021e-04\n",
      "Epoch 1500/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4423e-04 - val_loss: 1.5178e-04\n",
      "Epoch 1501/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4575e-04 - val_loss: 1.5448e-04\n",
      "Epoch 1502/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5080e-04 - val_loss: 1.4001e-04\n",
      "Epoch 1503/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3984e-04 - val_loss: 1.9488e-04\n",
      "Epoch 1504/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4870e-04 - val_loss: 1.3824e-04\n",
      "Epoch 1505/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4115e-04 - val_loss: 1.3479e-04\n",
      "Epoch 1506/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.4965e-04 - val_loss: 1.3685e-04\n",
      "Epoch 1507/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4768e-04 - val_loss: 1.3514e-04\n",
      "Epoch 1508/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4613e-04 - val_loss: 1.4436e-04\n",
      "Epoch 1509/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4883e-04 - val_loss: 1.4619e-04\n",
      "Epoch 1510/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5217e-04 - val_loss: 2.0191e-04\n",
      "Epoch 1511/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.6624e-04 - val_loss: 1.3120e-04\n",
      "Epoch 1512/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5767e-04 - val_loss: 1.3198e-04\n",
      "Epoch 1513/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4373e-04 - val_loss: 1.3377e-04\n",
      "Epoch 1514/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3828e-04 - val_loss: 1.8377e-04\n",
      "Epoch 1515/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4860e-04 - val_loss: 1.3319e-04\n",
      "Epoch 1516/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4773e-04 - val_loss: 1.3944e-04\n",
      "Epoch 1517/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4201e-04 - val_loss: 1.4181e-04\n",
      "Epoch 1518/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3988e-04 - val_loss: 1.8123e-04\n",
      "Epoch 1519/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5166e-04 - val_loss: 1.9570e-04\n",
      "Epoch 1520/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5885e-04 - val_loss: 1.4564e-04\n",
      "Epoch 1521/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6133e-04 - val_loss: 3.4992e-04\n",
      "Epoch 1522/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.0922e-04 - val_loss: 1.7886e-04\n",
      "Epoch 1523/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5982e-04 - val_loss: 1.9507e-04\n",
      "Epoch 1524/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6952e-04 - val_loss: 1.5975e-04\n",
      "Epoch 1525/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5124e-04 - val_loss: 1.3462e-04\n",
      "Epoch 1526/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4672e-04 - val_loss: 2.1833e-04\n",
      "Epoch 1527/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5856e-04 - val_loss: 1.6036e-04\n",
      "Epoch 1528/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4633e-04 - val_loss: 2.6351e-04\n",
      "Epoch 1529/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6580e-04 - val_loss: 1.3442e-04\n",
      "Epoch 1530/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4503e-04 - val_loss: 1.3344e-04\n",
      "Epoch 1531/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4637e-04 - val_loss: 1.3700e-04\n",
      "Epoch 1532/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4755e-04 - val_loss: 1.3406e-04\n",
      "Epoch 1533/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4556e-04 - val_loss: 1.7376e-04\n",
      "Epoch 1534/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4768e-04 - val_loss: 1.3489e-04\n",
      "Epoch 1535/2000\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 1.4073e-04 - val_loss: 1.4229e-04\n",
      "Epoch 1536/2000\n",
      "4143/4143 [==============================] - 2s 595us/step - loss: 1.4301e-04 - val_loss: 1.3709e-04\n",
      "Epoch 1537/2000\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 1.3916e-04 - val_loss: 1.4831e-04\n",
      "Epoch 1538/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4141e-04 - val_loss: 1.9218e-04\n",
      "Epoch 1539/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5476e-04 - val_loss: 1.3880e-04\n",
      "Epoch 1540/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4022e-04 - val_loss: 1.3098e-04\n",
      "Epoch 1541/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3915e-04 - val_loss: 1.3892e-04\n",
      "Epoch 1542/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3734e-04 - val_loss: 1.3343e-04\n",
      "Epoch 1543/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4092e-04 - val_loss: 1.3248e-04\n",
      "Epoch 1544/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3865e-04 - val_loss: 1.3781e-04\n",
      "Epoch 1545/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3912e-04 - val_loss: 1.4549e-04\n",
      "Epoch 1546/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4188e-04 - val_loss: 1.4065e-04\n",
      "Epoch 1547/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3972e-04 - val_loss: 1.4749e-04\n",
      "Epoch 1548/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4405e-04 - val_loss: 1.3444e-04\n",
      "Epoch 1549/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.4585e-04 - val_loss: 1.4467e-04\n",
      "Epoch 1550/2000\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 1.5070e-04 - val_loss: 1.4526e-04\n",
      "Epoch 1551/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 1.5052e-04 - val_loss: 1.3382e-04\n",
      "Epoch 1552/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4090e-04 - val_loss: 1.9384e-04\n",
      "Epoch 1553/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.6265e-04 - val_loss: 1.4267e-04\n",
      "Epoch 1554/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.5103e-04 - val_loss: 1.3712e-04\n",
      "Epoch 1555/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3871e-04 - val_loss: 3.0725e-04\n",
      "Epoch 1556/2000\n",
      "4143/4143 [==============================] - 2s 577us/step - loss: 2.0141e-04 - val_loss: 2.5479e-04\n",
      "Epoch 1557/2000\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 1.7501e-04 - val_loss: 1.3334e-04\n",
      "Epoch 1558/2000\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 1.5693e-04 - val_loss: 1.3300e-04\n",
      "Epoch 1559/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3918e-04 - val_loss: 1.3681e-04\n",
      "Epoch 1560/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4440e-04 - val_loss: 1.5644e-04\n",
      "Epoch 1561/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4940e-04 - val_loss: 1.3541e-04\n",
      "Epoch 1562/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4327e-04 - val_loss: 1.3336e-04\n",
      "Epoch 1563/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4317e-04 - val_loss: 1.3466e-04\n",
      "Epoch 1564/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4583e-04 - val_loss: 1.3294e-04\n",
      "Epoch 1565/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3961e-04 - val_loss: 1.3394e-04\n",
      "Epoch 1566/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3931e-04 - val_loss: 1.3213e-04\n",
      "Epoch 1567/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4031e-04 - val_loss: 1.3414e-04\n",
      "Epoch 1568/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4388e-04 - val_loss: 1.7245e-04\n",
      "Epoch 1569/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4522e-04 - val_loss: 1.3438e-04\n",
      "Epoch 1570/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4222e-04 - val_loss: 1.3249e-04\n",
      "Epoch 1571/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4087e-04 - val_loss: 1.4301e-04\n",
      "Epoch 1572/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4115e-04 - val_loss: 1.7925e-04\n",
      "Epoch 1573/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4612e-04 - val_loss: 1.3295e-04\n",
      "Epoch 1574/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4016e-04 - val_loss: 1.3576e-04\n",
      "Epoch 1575/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4498e-04 - val_loss: 1.3546e-04\n",
      "Epoch 1576/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4118e-04 - val_loss: 1.5411e-04\n",
      "Epoch 1577/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4378e-04 - val_loss: 1.3259e-04\n",
      "Epoch 1578/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3897e-04 - val_loss: 1.3259e-04\n",
      "Epoch 1579/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3863e-04 - val_loss: 1.4558e-04\n",
      "Epoch 1580/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4333e-04 - val_loss: 1.5414e-04\n",
      "Epoch 1581/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3967e-04 - val_loss: 1.4048e-04\n",
      "Epoch 1582/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4208e-04 - val_loss: 1.6423e-04\n",
      "Epoch 1583/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5366e-04 - val_loss: 1.4023e-04\n",
      "Epoch 1584/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4899e-04 - val_loss: 1.8159e-04\n",
      "Epoch 1585/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6755e-04 - val_loss: 2.1405e-04\n",
      "Epoch 1586/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.6488e-04 - val_loss: 1.3312e-04\n",
      "Epoch 1587/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4064e-04 - val_loss: 1.3558e-04\n",
      "Epoch 1588/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.3853e-04 - val_loss: 1.7609e-04\n",
      "Epoch 1589/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5093e-04 - val_loss: 1.5234e-04\n",
      "Epoch 1590/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5225e-04 - val_loss: 1.4072e-04\n",
      "Epoch 1591/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4831e-04 - val_loss: 1.3561e-04\n",
      "Epoch 1592/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4305e-04 - val_loss: 1.3583e-04\n",
      "Epoch 1593/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3872e-04 - val_loss: 1.3325e-04\n",
      "Epoch 1594/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3915e-04 - val_loss: 2.1907e-04\n",
      "Epoch 1595/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5798e-04 - val_loss: 1.7525e-04\n",
      "Epoch 1596/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.7227e-04 - val_loss: 2.5965e-04\n",
      "Epoch 1597/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.7034e-04 - val_loss: 1.9411e-04\n",
      "Epoch 1598/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5874e-04 - val_loss: 1.4923e-04\n",
      "Epoch 1599/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4498e-04 - val_loss: 1.3406e-04\n",
      "Epoch 1600/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3884e-04 - val_loss: 1.4727e-04\n",
      "Epoch 1601/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4228e-04 - val_loss: 1.7073e-04\n",
      "Epoch 1602/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5189e-04 - val_loss: 1.3468e-04\n",
      "Epoch 1603/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5062e-04 - val_loss: 1.3966e-04\n",
      "Epoch 1604/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4553e-04 - val_loss: 1.6208e-04\n",
      "Epoch 1605/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5186e-04 - val_loss: 1.3387e-04\n",
      "Epoch 1606/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5475e-04 - val_loss: 1.6229e-04\n",
      "Epoch 1607/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4717e-04 - val_loss: 1.3168e-04\n",
      "Epoch 1608/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4175e-04 - val_loss: 1.6480e-04\n",
      "Epoch 1609/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4095e-04 - val_loss: 1.3393e-04\n",
      "Epoch 1610/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.3859e-04 - val_loss: 1.3670e-04\n",
      "Epoch 1611/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3753e-04 - val_loss: 1.4801e-04\n",
      "Epoch 1612/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3764e-04 - val_loss: 1.4813e-04\n",
      "Epoch 1613/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4644e-04 - val_loss: 1.4528e-04\n",
      "Epoch 1614/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4042e-04 - val_loss: 1.5031e-04\n",
      "Epoch 1615/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4876e-04 - val_loss: 1.9075e-04\n",
      "Epoch 1616/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6670e-04 - val_loss: 2.0505e-04\n",
      "Epoch 1617/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6616e-04 - val_loss: 2.6209e-04\n",
      "Epoch 1618/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7501e-04 - val_loss: 1.3224e-04\n",
      "Epoch 1619/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4793e-04 - val_loss: 2.6173e-04\n",
      "Epoch 1620/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.8093e-04 - val_loss: 1.3356e-04\n",
      "Epoch 1621/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5161e-04 - val_loss: 1.3294e-04\n",
      "Epoch 1622/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3756e-04 - val_loss: 1.4978e-04\n",
      "Epoch 1623/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5177e-04 - val_loss: 1.3836e-04\n",
      "Epoch 1624/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4609e-04 - val_loss: 1.3346e-04\n",
      "Epoch 1625/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4160e-04 - val_loss: 1.3246e-04\n",
      "Epoch 1626/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4381e-04 - val_loss: 1.6303e-04\n",
      "Epoch 1627/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4540e-04 - val_loss: 1.3880e-04\n",
      "Epoch 1628/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4257e-04 - val_loss: 2.5463e-04\n",
      "Epoch 1629/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.7676e-04 - val_loss: 1.8002e-04\n",
      "Epoch 1630/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.6012e-04 - val_loss: 2.2348e-04\n",
      "Epoch 1631/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.7442e-04 - val_loss: 1.3209e-04\n",
      "Epoch 1632/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6370e-04 - val_loss: 1.3739e-04\n",
      "Epoch 1633/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5180e-04 - val_loss: 2.7279e-04\n",
      "Epoch 1634/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7102e-04 - val_loss: 2.1323e-04\n",
      "Epoch 1635/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.6447e-04 - val_loss: 1.7898e-04\n",
      "Epoch 1636/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5806e-04 - val_loss: 1.4020e-04\n",
      "Epoch 1637/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4483e-04 - val_loss: 1.6324e-04\n",
      "Epoch 1638/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.5340e-04 - val_loss: 1.9941e-04\n",
      "Epoch 1639/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6919e-04 - val_loss: 4.7163e-04\n",
      "Epoch 1640/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 2.1878e-04 - val_loss: 1.3918e-04\n",
      "Epoch 1641/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6496e-04 - val_loss: 1.3271e-04\n",
      "Epoch 1642/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4809e-04 - val_loss: 1.7091e-04\n",
      "Epoch 1643/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4427e-04 - val_loss: 1.3450e-04\n",
      "Epoch 1644/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3848e-04 - val_loss: 1.5108e-04\n",
      "Epoch 1645/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4579e-04 - val_loss: 1.3877e-04\n",
      "Epoch 1646/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4059e-04 - val_loss: 1.6892e-04\n",
      "Epoch 1647/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4604e-04 - val_loss: 1.5837e-04\n",
      "Epoch 1648/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4837e-04 - val_loss: 1.5026e-04\n",
      "Epoch 1649/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4309e-04 - val_loss: 1.4240e-04\n",
      "Epoch 1650/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4075e-04 - val_loss: 1.5845e-04\n",
      "Epoch 1651/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5113e-04 - val_loss: 1.4203e-04\n",
      "Epoch 1652/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4918e-04 - val_loss: 1.4730e-04\n",
      "Epoch 1653/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4609e-04 - val_loss: 1.6091e-04\n",
      "Epoch 1654/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5008e-04 - val_loss: 1.3709e-04\n",
      "Epoch 1655/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4244e-04 - val_loss: 2.2206e-04\n",
      "Epoch 1656/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.5473e-04 - val_loss: 2.3284e-04\n",
      "Epoch 1657/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5529e-04 - val_loss: 1.3679e-04\n",
      "Epoch 1658/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.3707e-04 - val_loss: 1.4596e-04\n",
      "Epoch 1659/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4418e-04 - val_loss: 1.7845e-04\n",
      "Epoch 1660/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4021e-04 - val_loss: 1.4460e-04\n",
      "Epoch 1661/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.3886e-04 - val_loss: 1.3761e-04\n",
      "Epoch 1662/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.3955e-04 - val_loss: 1.3960e-04\n",
      "Epoch 1663/2000\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 1.4575e-04 - val_loss: 1.3357e-04\n",
      "Epoch 1664/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4110e-04 - val_loss: 1.3536e-04\n",
      "Epoch 1665/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4790e-04 - val_loss: 1.6768e-04\n",
      "Epoch 1666/2000\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 1.5081e-04 - val_loss: 1.6998e-04\n",
      "Epoch 1667/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4438e-04 - val_loss: 1.5989e-04\n",
      "Epoch 1668/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4813e-04 - val_loss: 1.3348e-04\n",
      "Epoch 1669/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4271e-04 - val_loss: 1.6626e-04\n",
      "Epoch 1670/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5325e-04 - val_loss: 2.2887e-04\n",
      "Epoch 1671/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5593e-04 - val_loss: 1.3241e-04\n",
      "Epoch 1672/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4396e-04 - val_loss: 1.3113e-04\n",
      "Epoch 1673/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3699e-04 - val_loss: 1.3664e-04\n",
      "Epoch 1674/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4036e-04 - val_loss: 1.6380e-04\n",
      "Epoch 1675/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4573e-04 - val_loss: 2.6183e-04\n",
      "Epoch 1676/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6768e-04 - val_loss: 2.4578e-04\n",
      "Epoch 1677/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6053e-04 - val_loss: 1.5495e-04\n",
      "Epoch 1678/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4738e-04 - val_loss: 1.3160e-04\n",
      "Epoch 1679/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4056e-04 - val_loss: 1.3327e-04\n",
      "Epoch 1680/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3713e-04 - val_loss: 1.8524e-04\n",
      "Epoch 1681/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4682e-04 - val_loss: 1.3931e-04\n",
      "Epoch 1682/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4116e-04 - val_loss: 2.3991e-04\n",
      "Epoch 1683/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.6211e-04 - val_loss: 1.8357e-04\n",
      "Epoch 1684/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4493e-04 - val_loss: 1.3299e-04\n",
      "Epoch 1685/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4705e-04 - val_loss: 1.3446e-04\n",
      "Epoch 1686/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4496e-04 - val_loss: 1.4227e-04\n",
      "Epoch 1687/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4957e-04 - val_loss: 2.1530e-04\n",
      "Epoch 1688/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4699e-04 - val_loss: 1.5349e-04\n",
      "Epoch 1689/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4572e-04 - val_loss: 1.3298e-04\n",
      "Epoch 1690/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3868e-04 - val_loss: 1.7029e-04\n",
      "Epoch 1691/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4737e-04 - val_loss: 1.4861e-04\n",
      "Epoch 1692/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5127e-04 - val_loss: 1.3458e-04\n",
      "Epoch 1693/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3989e-04 - val_loss: 1.3238e-04\n",
      "Epoch 1694/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.3607e-04 - val_loss: 1.3170e-04\n",
      "Epoch 1695/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3673e-04 - val_loss: 1.3254e-04\n",
      "Epoch 1696/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3820e-04 - val_loss: 1.3270e-04\n",
      "Epoch 1697/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3873e-04 - val_loss: 1.3259e-04\n",
      "Epoch 1698/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3794e-04 - val_loss: 1.3734e-04\n",
      "Epoch 1699/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4230e-04 - val_loss: 1.4676e-04\n",
      "Epoch 1700/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4403e-04 - val_loss: 1.3076e-04\n",
      "Epoch 1701/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4010e-04 - val_loss: 1.6126e-04\n",
      "Epoch 1702/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4205e-04 - val_loss: 1.3229e-04\n",
      "Epoch 1703/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3725e-04 - val_loss: 1.4108e-04\n",
      "Epoch 1704/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3821e-04 - val_loss: 1.4008e-04\n",
      "Epoch 1705/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.3828e-04 - val_loss: 1.3285e-04\n",
      "Epoch 1706/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4100e-04 - val_loss: 2.7267e-04\n",
      "Epoch 1707/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.7126e-04 - val_loss: 1.3407e-04\n",
      "Epoch 1708/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4141e-04 - val_loss: 1.8953e-04\n",
      "Epoch 1709/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5257e-04 - val_loss: 2.9680e-04\n",
      "Epoch 1710/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.6974e-04 - val_loss: 1.3633e-04\n",
      "Epoch 1711/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4372e-04 - val_loss: 1.4120e-04\n",
      "Epoch 1712/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3782e-04 - val_loss: 2.3856e-04\n",
      "Epoch 1713/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6116e-04 - val_loss: 1.7893e-04\n",
      "Epoch 1714/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.8292e-04 - val_loss: 1.7305e-04\n",
      "Epoch 1715/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5840e-04 - val_loss: 1.3526e-04\n",
      "Epoch 1716/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4636e-04 - val_loss: 1.4075e-04\n",
      "Epoch 1717/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4143e-04 - val_loss: 2.8502e-04\n",
      "Epoch 1718/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.6757e-04 - val_loss: 1.4119e-04\n",
      "Epoch 1719/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5309e-04 - val_loss: 1.4104e-04\n",
      "Epoch 1720/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3969e-04 - val_loss: 1.6280e-04\n",
      "Epoch 1721/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.3741e-04 - val_loss: 1.3236e-04\n",
      "Epoch 1722/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3852e-04 - val_loss: 1.3370e-04\n",
      "Epoch 1723/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4531e-04 - val_loss: 1.3133e-04\n",
      "Epoch 1724/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3975e-04 - val_loss: 1.3521e-04\n",
      "Epoch 1725/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4025e-04 - val_loss: 1.3361e-04\n",
      "Epoch 1726/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4394e-04 - val_loss: 1.5941e-04\n",
      "Epoch 1727/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4093e-04 - val_loss: 1.5838e-04\n",
      "Epoch 1728/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3871e-04 - val_loss: 1.3313e-04\n",
      "Epoch 1729/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4188e-04 - val_loss: 3.1704e-04\n",
      "Epoch 1730/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.8316e-04 - val_loss: 2.4096e-04\n",
      "Epoch 1731/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7121e-04 - val_loss: 1.8153e-04\n",
      "Epoch 1732/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.4929e-04 - val_loss: 1.4401e-04\n",
      "Epoch 1733/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4862e-04 - val_loss: 1.7512e-04\n",
      "Epoch 1734/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5807e-04 - val_loss: 2.2045e-04\n",
      "Epoch 1735/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.7438e-04 - val_loss: 1.7711e-04\n",
      "Epoch 1736/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5536e-04 - val_loss: 1.6532e-04\n",
      "Epoch 1737/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5110e-04 - val_loss: 1.5736e-04\n",
      "Epoch 1738/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4177e-04 - val_loss: 1.4084e-04\n",
      "Epoch 1739/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4415e-04 - val_loss: 1.9003e-04\n",
      "Epoch 1740/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6482e-04 - val_loss: 1.5575e-04\n",
      "Epoch 1741/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5387e-04 - val_loss: 1.3815e-04\n",
      "Epoch 1742/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4821e-04 - val_loss: 1.3656e-04\n",
      "Epoch 1743/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4218e-04 - val_loss: 1.3318e-04\n",
      "Epoch 1744/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3823e-04 - val_loss: 1.4424e-04\n",
      "Epoch 1745/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4633e-04 - val_loss: 1.6916e-04\n",
      "Epoch 1746/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.6024e-04 - val_loss: 1.5606e-04\n",
      "Epoch 1747/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.6194e-04 - val_loss: 1.3115e-04\n",
      "Epoch 1748/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4416e-04 - val_loss: 1.8222e-04\n",
      "Epoch 1749/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4537e-04 - val_loss: 1.5563e-04\n",
      "Epoch 1750/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4240e-04 - val_loss: 1.8453e-04\n",
      "Epoch 1751/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5009e-04 - val_loss: 1.6890e-04\n",
      "Epoch 1752/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4080e-04 - val_loss: 1.9035e-04\n",
      "Epoch 1753/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5517e-04 - val_loss: 1.4892e-04\n",
      "Epoch 1754/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4419e-04 - val_loss: 1.5877e-04\n",
      "Epoch 1755/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4304e-04 - val_loss: 1.5505e-04\n",
      "Epoch 1756/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4312e-04 - val_loss: 1.3431e-04\n",
      "Epoch 1757/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4835e-04 - val_loss: 1.3943e-04\n",
      "Epoch 1758/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4122e-04 - val_loss: 1.3475e-04\n",
      "Epoch 1759/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3583e-04 - val_loss: 1.3088e-04\n",
      "Epoch 1760/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3836e-04 - val_loss: 1.4118e-04\n",
      "Epoch 1761/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4681e-04 - val_loss: 1.7980e-04\n",
      "Epoch 1762/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4836e-04 - val_loss: 2.0066e-04\n",
      "Epoch 1763/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5368e-04 - val_loss: 1.3619e-04\n",
      "Epoch 1764/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4634e-04 - val_loss: 1.5040e-04\n",
      "Epoch 1765/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4326e-04 - val_loss: 1.3150e-04\n",
      "Epoch 1766/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.3845e-04 - val_loss: 1.3840e-04\n",
      "Epoch 1767/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.3787e-04 - val_loss: 2.1205e-04\n",
      "Epoch 1768/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6380e-04 - val_loss: 3.0224e-04\n",
      "Epoch 1769/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.6864e-04 - val_loss: 1.8031e-04\n",
      "Epoch 1770/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4199e-04 - val_loss: 1.3266e-04\n",
      "Epoch 1771/2000\n",
      "4143/4143 [==============================] - 2s 579us/step - loss: 1.3791e-04 - val_loss: 1.3841e-04\n",
      "Epoch 1772/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.3944e-04 - val_loss: 1.4812e-04\n",
      "Epoch 1773/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3999e-04 - val_loss: 1.3389e-04\n",
      "Epoch 1774/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3937e-04 - val_loss: 1.3250e-04\n",
      "Epoch 1775/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3821e-04 - val_loss: 1.3540e-04\n",
      "Epoch 1776/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3818e-04 - val_loss: 1.4174e-04\n",
      "Epoch 1777/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3778e-04 - val_loss: 1.6255e-04\n",
      "Epoch 1778/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4520e-04 - val_loss: 1.6605e-04\n",
      "Epoch 1779/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4553e-04 - val_loss: 1.3708e-04\n",
      "Epoch 1780/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4180e-04 - val_loss: 1.3150e-04\n",
      "Epoch 1781/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3834e-04 - val_loss: 1.4004e-04\n",
      "Epoch 1782/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4013e-04 - val_loss: 1.3649e-04\n",
      "Epoch 1783/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4390e-04 - val_loss: 1.3351e-04\n",
      "Epoch 1784/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4061e-04 - val_loss: 1.8332e-04\n",
      "Epoch 1785/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6274e-04 - val_loss: 1.7731e-04\n",
      "Epoch 1786/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.5139e-04 - val_loss: 1.3496e-04\n",
      "Epoch 1787/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4948e-04 - val_loss: 1.3451e-04\n",
      "Epoch 1788/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3721e-04 - val_loss: 2.3178e-04\n",
      "Epoch 1789/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6552e-04 - val_loss: 1.3730e-04\n",
      "Epoch 1790/2000\n",
      "4143/4143 [==============================] - 2s 557us/step - loss: 1.4221e-04 - val_loss: 2.0917e-04\n",
      "Epoch 1791/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4922e-04 - val_loss: 1.3426e-04\n",
      "Epoch 1792/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3715e-04 - val_loss: 1.3966e-04\n",
      "Epoch 1793/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.3735e-04 - val_loss: 1.3338e-04\n",
      "Epoch 1794/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3893e-04 - val_loss: 1.6479e-04\n",
      "Epoch 1795/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4213e-04 - val_loss: 1.7847e-04\n",
      "Epoch 1796/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4428e-04 - val_loss: 1.3818e-04\n",
      "Epoch 1797/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.3588e-04 - val_loss: 3.3926e-04\n",
      "Epoch 1798/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.9053e-04 - val_loss: 1.5101e-04\n",
      "Epoch 1799/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.6262e-04 - val_loss: 1.3117e-04\n",
      "Epoch 1800/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4762e-04 - val_loss: 1.7654e-04\n",
      "Epoch 1801/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4854e-04 - val_loss: 1.3291e-04\n",
      "Epoch 1802/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3987e-04 - val_loss: 1.3199e-04\n",
      "Epoch 1803/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3918e-04 - val_loss: 1.4058e-04\n",
      "Epoch 1804/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4769e-04 - val_loss: 1.7137e-04\n",
      "Epoch 1805/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5935e-04 - val_loss: 1.7015e-04\n",
      "Epoch 1806/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4844e-04 - val_loss: 2.2804e-04\n",
      "Epoch 1807/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5740e-04 - val_loss: 1.3407e-04\n",
      "Epoch 1808/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4007e-04 - val_loss: 2.0318e-04\n",
      "Epoch 1809/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5652e-04 - val_loss: 1.3409e-04\n",
      "Epoch 1810/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.3699e-04 - val_loss: 1.3161e-04\n",
      "Epoch 1811/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3876e-04 - val_loss: 1.3316e-04\n",
      "Epoch 1812/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4069e-04 - val_loss: 3.0139e-04\n",
      "Epoch 1813/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.8804e-04 - val_loss: 1.5022e-04\n",
      "Epoch 1814/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5577e-04 - val_loss: 2.1241e-04\n",
      "Epoch 1815/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5777e-04 - val_loss: 1.9851e-04\n",
      "Epoch 1816/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.7067e-04 - val_loss: 1.3280e-04\n",
      "Epoch 1817/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4591e-04 - val_loss: 1.3370e-04\n",
      "Epoch 1818/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4012e-04 - val_loss: 1.7421e-04\n",
      "Epoch 1819/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.5464e-04 - val_loss: 1.3704e-04\n",
      "Epoch 1820/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3591e-04 - val_loss: 1.5253e-04\n",
      "Epoch 1821/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3873e-04 - val_loss: 1.3473e-04\n",
      "Epoch 1822/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3858e-04 - val_loss: 1.6760e-04\n",
      "Epoch 1823/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4489e-04 - val_loss: 1.6895e-04\n",
      "Epoch 1824/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4438e-04 - val_loss: 1.3236e-04\n",
      "Epoch 1825/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3738e-04 - val_loss: 2.1044e-04\n",
      "Epoch 1826/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.5558e-04 - val_loss: 1.5460e-04\n",
      "Epoch 1827/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3913e-04 - val_loss: 1.3227e-04\n",
      "Epoch 1828/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3998e-04 - val_loss: 1.5228e-04\n",
      "Epoch 1829/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4183e-04 - val_loss: 1.5349e-04\n",
      "Epoch 1830/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3941e-04 - val_loss: 1.3173e-04\n",
      "Epoch 1831/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3554e-04 - val_loss: 1.3535e-04\n",
      "Epoch 1832/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3942e-04 - val_loss: 1.3299e-04\n",
      "Epoch 1833/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3889e-04 - val_loss: 1.6109e-04\n",
      "Epoch 1834/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5169e-04 - val_loss: 1.6185e-04\n",
      "Epoch 1835/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4922e-04 - val_loss: 1.3373e-04\n",
      "Epoch 1836/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4214e-04 - val_loss: 1.4883e-04\n",
      "Epoch 1837/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4030e-04 - val_loss: 1.3645e-04\n",
      "Epoch 1838/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4318e-04 - val_loss: 1.5553e-04\n",
      "Epoch 1839/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.6432e-04 - val_loss: 1.5395e-04\n",
      "Epoch 1840/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5194e-04 - val_loss: 1.8790e-04\n",
      "Epoch 1841/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5511e-04 - val_loss: 1.7387e-04\n",
      "Epoch 1842/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5616e-04 - val_loss: 4.0972e-04\n",
      "Epoch 1843/2000\n",
      "4143/4143 [==============================] - 2s 574us/step - loss: 2.1298e-04 - val_loss: 2.6959e-04\n",
      "Epoch 1844/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7047e-04 - val_loss: 1.8732e-04\n",
      "Epoch 1845/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5310e-04 - val_loss: 1.6139e-04\n",
      "Epoch 1846/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5837e-04 - val_loss: 1.7742e-04\n",
      "Epoch 1847/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4878e-04 - val_loss: 1.5675e-04\n",
      "Epoch 1848/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4477e-04 - val_loss: 1.3578e-04\n",
      "Epoch 1849/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4153e-04 - val_loss: 1.3803e-04\n",
      "Epoch 1850/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3952e-04 - val_loss: 1.3812e-04\n",
      "Epoch 1851/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.3667e-04 - val_loss: 1.3496e-04\n",
      "Epoch 1852/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3689e-04 - val_loss: 1.4483e-04\n",
      "Epoch 1853/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3778e-04 - val_loss: 1.4115e-04\n",
      "Epoch 1854/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3824e-04 - val_loss: 1.6943e-04\n",
      "Epoch 1855/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4421e-04 - val_loss: 1.4884e-04\n",
      "Epoch 1856/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4123e-04 - val_loss: 1.4390e-04\n",
      "Epoch 1857/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4595e-04 - val_loss: 1.3413e-04\n",
      "Epoch 1858/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3715e-04 - val_loss: 1.4490e-04\n",
      "Epoch 1859/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4168e-04 - val_loss: 1.9686e-04\n",
      "Epoch 1860/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5054e-04 - val_loss: 1.4151e-04\n",
      "Epoch 1861/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4092e-04 - val_loss: 1.5882e-04\n",
      "Epoch 1862/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4860e-04 - val_loss: 1.5000e-04\n",
      "Epoch 1863/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5221e-04 - val_loss: 1.3864e-04\n",
      "Epoch 1864/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4480e-04 - val_loss: 1.3807e-04\n",
      "Epoch 1865/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4840e-04 - val_loss: 1.3622e-04\n",
      "Epoch 1866/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3652e-04 - val_loss: 1.5841e-04\n",
      "Epoch 1867/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4225e-04 - val_loss: 1.4130e-04\n",
      "Epoch 1868/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3773e-04 - val_loss: 1.4356e-04\n",
      "Epoch 1869/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4080e-04 - val_loss: 1.3375e-04\n",
      "Epoch 1870/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.3498e-04 - val_loss: 1.3629e-04\n",
      "Epoch 1871/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3885e-04 - val_loss: 1.4545e-04\n",
      "Epoch 1872/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3914e-04 - val_loss: 1.4105e-04\n",
      "Epoch 1873/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3833e-04 - val_loss: 1.5384e-04\n",
      "Epoch 1874/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.3889e-04 - val_loss: 2.6263e-04\n",
      "Epoch 1875/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.6853e-04 - val_loss: 1.6031e-04\n",
      "Epoch 1876/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4888e-04 - val_loss: 1.7468e-04\n",
      "Epoch 1877/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6339e-04 - val_loss: 1.3521e-04\n",
      "Epoch 1878/2000\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 1.6694e-04 - val_loss: 2.2991e-04\n",
      "Epoch 1879/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.7380e-04 - val_loss: 1.3126e-04\n",
      "Epoch 1880/2000\n",
      "4143/4143 [==============================] - 2s 575us/step - loss: 1.3927e-04 - val_loss: 1.3243e-04\n",
      "Epoch 1881/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.3904e-04 - val_loss: 1.3254e-04\n",
      "Epoch 1882/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3700e-04 - val_loss: 1.3536e-04\n",
      "Epoch 1883/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3842e-04 - val_loss: 1.3472e-04\n",
      "Epoch 1884/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3672e-04 - val_loss: 1.6037e-04\n",
      "Epoch 1885/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5078e-04 - val_loss: 1.3414e-04\n",
      "Epoch 1886/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4076e-04 - val_loss: 1.7876e-04\n",
      "Epoch 1887/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5698e-04 - val_loss: 1.6845e-04\n",
      "Epoch 1888/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5438e-04 - val_loss: 1.3550e-04\n",
      "Epoch 1889/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4134e-04 - val_loss: 1.4788e-04\n",
      "Epoch 1890/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4259e-04 - val_loss: 1.3614e-04\n",
      "Epoch 1891/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.3994e-04 - val_loss: 1.3202e-04\n",
      "Epoch 1892/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5461e-04 - val_loss: 2.0354e-04\n",
      "Epoch 1893/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6251e-04 - val_loss: 2.2138e-04\n",
      "Epoch 1894/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.5720e-04 - val_loss: 1.8919e-04\n",
      "Epoch 1895/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.6225e-04 - val_loss: 1.7888e-04\n",
      "Epoch 1896/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5877e-04 - val_loss: 1.3338e-04\n",
      "Epoch 1897/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4103e-04 - val_loss: 1.3421e-04\n",
      "Epoch 1898/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3641e-04 - val_loss: 1.5180e-04\n",
      "Epoch 1899/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4153e-04 - val_loss: 2.4475e-04\n",
      "Epoch 1900/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.7952e-04 - val_loss: 1.5026e-04\n",
      "Epoch 1901/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4228e-04 - val_loss: 1.4992e-04\n",
      "Epoch 1902/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.4154e-04 - val_loss: 1.3645e-04\n",
      "Epoch 1903/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.5148e-04 - val_loss: 1.8385e-04\n",
      "Epoch 1904/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5519e-04 - val_loss: 1.9448e-04\n",
      "Epoch 1905/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.5425e-04 - val_loss: 1.7575e-04\n",
      "Epoch 1906/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4142e-04 - val_loss: 1.4120e-04\n",
      "Epoch 1907/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4260e-04 - val_loss: 1.4167e-04\n",
      "Epoch 1908/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4365e-04 - val_loss: 1.5467e-04\n",
      "Epoch 1909/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4390e-04 - val_loss: 1.3359e-04\n",
      "Epoch 1910/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4025e-04 - val_loss: 1.3477e-04\n",
      "Epoch 1911/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4238e-04 - val_loss: 1.3594e-04\n",
      "Epoch 1912/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4412e-04 - val_loss: 1.5526e-04\n",
      "Epoch 1913/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.5136e-04 - val_loss: 1.3261e-04\n",
      "Epoch 1914/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.5099e-04 - val_loss: 1.3195e-04\n",
      "Epoch 1915/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4254e-04 - val_loss: 1.7973e-04\n",
      "Epoch 1916/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5587e-04 - val_loss: 1.6286e-04\n",
      "Epoch 1917/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4355e-04 - val_loss: 1.3855e-04\n",
      "Epoch 1918/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4137e-04 - val_loss: 1.7726e-04\n",
      "Epoch 1919/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4532e-04 - val_loss: 1.3602e-04\n",
      "Epoch 1920/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4515e-04 - val_loss: 1.4460e-04\n",
      "Epoch 1921/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4873e-04 - val_loss: 1.5408e-04\n",
      "Epoch 1922/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.5071e-04 - val_loss: 1.3959e-04\n",
      "Epoch 1923/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.3902e-04 - val_loss: 1.9537e-04\n",
      "Epoch 1924/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.5841e-04 - val_loss: 1.4753e-04\n",
      "Epoch 1925/2000\n",
      "4143/4143 [==============================] - 2s 558us/step - loss: 1.3819e-04 - val_loss: 1.8187e-04\n",
      "Epoch 1926/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4911e-04 - val_loss: 1.7359e-04\n",
      "Epoch 1927/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.4123e-04 - val_loss: 1.5652e-04\n",
      "Epoch 1928/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.3647e-04 - val_loss: 1.3538e-04\n",
      "Epoch 1929/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4987e-04 - val_loss: 1.3833e-04\n",
      "Epoch 1930/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.4355e-04 - val_loss: 1.3550e-04\n",
      "Epoch 1931/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.3891e-04 - val_loss: 1.3164e-04\n",
      "Epoch 1932/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4369e-04 - val_loss: 1.3735e-04\n",
      "Epoch 1933/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3696e-04 - val_loss: 1.3335e-04\n",
      "Epoch 1934/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.4134e-04 - val_loss: 1.3209e-04\n",
      "Epoch 1935/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.3633e-04 - val_loss: 1.3857e-04\n",
      "Epoch 1936/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4031e-04 - val_loss: 1.6167e-04\n",
      "Epoch 1937/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4976e-04 - val_loss: 1.6456e-04\n",
      "Epoch 1938/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.4779e-04 - val_loss: 1.4662e-04\n",
      "Epoch 1939/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4479e-04 - val_loss: 1.3428e-04\n",
      "Epoch 1940/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.3974e-04 - val_loss: 1.3422e-04\n",
      "Epoch 1941/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3826e-04 - val_loss: 1.3250e-04\n",
      "Epoch 1942/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3783e-04 - val_loss: 1.3671e-04\n",
      "Epoch 1943/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3996e-04 - val_loss: 1.3724e-04\n",
      "Epoch 1944/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3508e-04 - val_loss: 1.3540e-04\n",
      "Epoch 1945/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3611e-04 - val_loss: 1.3344e-04\n",
      "Epoch 1946/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3929e-04 - val_loss: 1.4395e-04\n",
      "Epoch 1947/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.3884e-04 - val_loss: 1.3293e-04\n",
      "Epoch 1948/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3633e-04 - val_loss: 2.1865e-04\n",
      "Epoch 1949/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.6890e-04 - val_loss: 1.3441e-04\n",
      "Epoch 1950/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.6177e-04 - val_loss: 1.3341e-04\n",
      "Epoch 1951/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4329e-04 - val_loss: 1.3308e-04\n",
      "Epoch 1952/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.3560e-04 - val_loss: 1.3488e-04\n",
      "Epoch 1953/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.3489e-04 - val_loss: 1.3366e-04\n",
      "Epoch 1954/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.3559e-04 - val_loss: 1.3675e-04\n",
      "Epoch 1955/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.5385e-04 - val_loss: 1.9098e-04\n",
      "Epoch 1956/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.5296e-04 - val_loss: 1.5397e-04\n",
      "Epoch 1957/2000\n",
      "4143/4143 [==============================] - 2s 563us/step - loss: 1.4919e-04 - val_loss: 1.3590e-04\n",
      "Epoch 1958/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.4339e-04 - val_loss: 1.3944e-04\n",
      "Epoch 1959/2000\n",
      "4143/4143 [==============================] - 2s 570us/step - loss: 1.3642e-04 - val_loss: 1.3773e-04\n",
      "Epoch 1960/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3791e-04 - val_loss: 1.4586e-04\n",
      "Epoch 1961/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3921e-04 - val_loss: 1.3500e-04\n",
      "Epoch 1962/2000\n",
      "4143/4143 [==============================] - 2s 566us/step - loss: 1.3892e-04 - val_loss: 1.5424e-04\n",
      "Epoch 1963/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.4699e-04 - val_loss: 1.3242e-04\n",
      "Epoch 1964/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.4144e-04 - val_loss: 1.3277e-04\n",
      "Epoch 1965/2000\n",
      "4143/4143 [==============================] - 2s 559us/step - loss: 1.3429e-04 - val_loss: 1.3543e-04\n",
      "Epoch 1966/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.3657e-04 - val_loss: 1.4158e-04\n",
      "Epoch 1967/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4295e-04 - val_loss: 1.6695e-04\n",
      "Epoch 1968/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.4862e-04 - val_loss: 2.6987e-04\n",
      "Epoch 1969/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.9451e-04 - val_loss: 2.0795e-04\n",
      "Epoch 1970/2000\n",
      "4143/4143 [==============================] - 2s 562us/step - loss: 1.5628e-04 - val_loss: 3.6087e-04\n",
      "Epoch 1971/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 2.1457e-04 - val_loss: 1.4321e-04\n",
      "Epoch 1972/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.6179e-04 - val_loss: 1.5073e-04\n",
      "Epoch 1973/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.3903e-04 - val_loss: 1.3428e-04\n",
      "Epoch 1974/2000\n",
      "4143/4143 [==============================] - 2s 567us/step - loss: 1.3607e-04 - val_loss: 1.3327e-04\n",
      "Epoch 1975/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3675e-04 - val_loss: 1.3536e-04\n",
      "Epoch 1976/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.3653e-04 - val_loss: 1.5998e-04\n",
      "Epoch 1977/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3958e-04 - val_loss: 1.3234e-04\n",
      "Epoch 1978/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3742e-04 - val_loss: 1.4749e-04\n",
      "Epoch 1979/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3796e-04 - val_loss: 1.4865e-04\n",
      "Epoch 1980/2000\n",
      "4143/4143 [==============================] - 2s 565us/step - loss: 1.3571e-04 - val_loss: 1.3429e-04\n",
      "Epoch 1981/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.3580e-04 - val_loss: 1.5058e-04\n",
      "Epoch 1982/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4214e-04 - val_loss: 1.5016e-04\n",
      "Epoch 1983/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3680e-04 - val_loss: 1.6096e-04\n",
      "Epoch 1984/2000\n",
      "4143/4143 [==============================] - 2s 571us/step - loss: 1.4343e-04 - val_loss: 1.7018e-04\n",
      "Epoch 1985/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4439e-04 - val_loss: 1.3272e-04\n",
      "Epoch 1986/2000\n",
      "4143/4143 [==============================] - 2s 564us/step - loss: 1.3672e-04 - val_loss: 1.4952e-04\n",
      "Epoch 1987/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4580e-04 - val_loss: 1.3308e-04\n",
      "Epoch 1988/2000\n",
      "4143/4143 [==============================] - 2s 560us/step - loss: 1.3415e-04 - val_loss: 1.4302e-04\n",
      "Epoch 1989/2000\n",
      "4143/4143 [==============================] - 2s 572us/step - loss: 1.3851e-04 - val_loss: 1.3759e-04\n",
      "Epoch 1990/2000\n",
      "4143/4143 [==============================] - 2s 561us/step - loss: 1.4129e-04 - val_loss: 1.3504e-04\n",
      "Epoch 1991/2000\n",
      "4143/4143 [==============================] - 2s 586us/step - loss: 1.3834e-04 - val_loss: 1.9947e-04\n",
      "Epoch 1992/2000\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 1.5141e-04 - val_loss: 1.4928e-04\n",
      "Epoch 1993/2000\n",
      "4143/4143 [==============================] - 2s 596us/step - loss: 1.4626e-04 - val_loss: 1.3287e-04\n",
      "Epoch 1994/2000\n",
      "4143/4143 [==============================] - 3s 604us/step - loss: 1.3956e-04 - val_loss: 1.7419e-04\n",
      "Epoch 1995/2000\n",
      "4143/4143 [==============================] - 2s 568us/step - loss: 1.4070e-04 - val_loss: 1.3305e-04\n",
      "Epoch 1996/2000\n",
      "4143/4143 [==============================] - 2s 585us/step - loss: 1.3391e-04 - val_loss: 1.4242e-04\n",
      "Epoch 1997/2000\n",
      "4143/4143 [==============================] - 2s 569us/step - loss: 1.4084e-04 - val_loss: 2.6960e-04\n",
      "Epoch 1998/2000\n",
      "4143/4143 [==============================] - 2s 581us/step - loss: 1.8340e-04 - val_loss: 1.4611e-04\n",
      "Epoch 1999/2000\n",
      "4143/4143 [==============================] - 2s 573us/step - loss: 1.4233e-04 - val_loss: 1.5560e-04\n",
      "Epoch 2000/2000\n",
      "4143/4143 [==============================] - 2s 580us/step - loss: 1.3810e-04 - val_loss: 1.4821e-04\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lstmsize': 162,\n",
       " 'twice': True,\n",
       " 'shuffle': True,\n",
       " 'optimizer': 'adam',\n",
       " 'activation': 'elu',\n",
       " 'density': 188,\n",
       " 'full_density': True,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x1fb4ee0bb88>]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_363 (LSTM)              (None, 92, 162)           108864    \n",
      "_________________________________________________________________\n",
      "lstm_364 (LSTM)              (None, 162)               210600    \n",
      "_________________________________________________________________\n",
      "dense_780 (Dense)            (None, 188)               30644     \n",
      "_________________________________________________________________\n",
      "dense_781 (Dense)            (None, 94)                17766     \n",
      "_________________________________________________________________\n",
      "dense_782 (Dense)            (None, 47)                4465      \n",
      "_________________________________________________________________\n",
      "dense_783 (Dense)            (None, 23)                1104      \n",
      "_________________________________________________________________\n",
      "dense_784 (Dense)            (None, 1)                 24        \n",
      "=================================================================\n",
      "Total params: 373,467\n",
      "Trainable params: 373,467\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_MSE/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 6.56\n",
      "Medium error is 1.74\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 70.93%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 60.62%\n",
      "Accuracy for downward trend is: 79.32%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), true_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
