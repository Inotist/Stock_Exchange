{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from joblib import load\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 2\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(len(data) * train_size)\n",
    "\n",
    "train = data.to_numpy()[:split]\n",
    "test = data.to_numpy()[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalisers\n",
    "normaliser = load('./normalisers/x_normaliser.joblib')\n",
    "y_normaliser = load('./normalisers/y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "train_norm = normaliser.transform(train)\n",
    "test_norm = normaliser.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now I get indexes for chunks from 2 in 2 days (history doubles the backlook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(train),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_train = np.array([train_norm[ix].copy() for ix in ordered_index])\n",
    "Y_train = np.array([train_norm[ordered_index[i+days][-1],3].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_train = np.expand_dims(Y_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_train = X_train[:Y_train.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(test),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised test chunks\n",
    "X_test = np.array([test_norm[ix].copy() for ix in ordered_index])\n",
    "Y_test = np.array([test_norm[ordered_index[i+days][-1],3].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_test = np.expand_dims(Y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_test = X_test[:Y_test.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.2160 - val_loss: 0.1692\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0960 - val_loss: 0.0663\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 312us/step - loss: 0.0546 - val_loss: 0.0267\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 320us/step - loss: 0.0395 - val_loss: 0.0121\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 312us/step - loss: 0.0352 - val_loss: 0.0066\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0323 - val_loss: 0.0044\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0296 - val_loss: 0.0034\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 320us/step - loss: 0.0274 - val_loss: 0.0029\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 0.0252 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0231 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0218 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 0.0197 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 0.0176 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 311us/step - loss: 0.0156 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0144 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0128 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0117 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0106 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0096 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 320us/step - loss: 0.0088 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0074 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0072 - val_loss: 0.0029\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 313us/step - loss: 0.0065 - val_loss: 0.0031\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0276 - val_loss: 0.0246\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0352 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0040 - val_loss: 0.0079\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0044 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 318us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0042 - val_loss: 0.0049\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 0.0034 - val_loss: 0.0060\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0030 - val_loss: 0.0057\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0023 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 312us/step - loss: 0.0027 - val_loss: 0.0058\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0030 - val_loss: 0.0044\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 313us/step - loss: 0.0038 - val_loss: 0.0074\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0080 - val_loss: 0.0161\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 0.0097 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 1.7217 - val_loss: 0.0196\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0385 - val_loss: 0.0100\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0242 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 318us/step - loss: 0.0148 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 0.0095 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0068 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0047 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 0.0039 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 0.0034 - val_loss: 0.0027\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 321us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 313us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 320us/step - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 312us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0031 - val_loss: 0.0024\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 317us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 736us/step - loss: 0.8218 - val_loss: 0.0090\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0165 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0082 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0059 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0051 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0046 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0043 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0034 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 702us/step - loss: 2.5473 - val_loss: 0.0181\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0370 - val_loss: 0.0072\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 483us/step - loss: 0.0265 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 477us/step - loss: 0.0183 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 476us/step - loss: 0.0129 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0102 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0082 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0073 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0070 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 481us/step - loss: 0.0065 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 477us/step - loss: 0.0060 - val_loss: 0.0033\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0059 - val_loss: 0.0052\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 483us/step - loss: 0.0059 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0056 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 481us/step - loss: 0.0054 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 482us/step - loss: 0.0054 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 479us/step - loss: 0.0054 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 482us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 481us/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 483us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 483us/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 639us/step - loss: 0.1257 - val_loss: 0.0232\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0578 - val_loss: 0.1529\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0268 - val_loss: 0.0943\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0299 - val_loss: 0.0109\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0049 - val_loss: 0.0376\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.0134 - val_loss: 0.0189\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0070 - val_loss: 0.0313\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.0130 - val_loss: 0.0314\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0069 - val_loss: 0.0114\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0054 - val_loss: 0.0219\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0117 - val_loss: 0.0154\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0040 - val_loss: 0.0090\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0072 - val_loss: 0.0292\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0083 - val_loss: 0.0117\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0040 - val_loss: 0.0126\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0062 - val_loss: 0.0149\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0071 - val_loss: 0.0144\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 362us/step - loss: 0.0053 - val_loss: 0.0105\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0040 - val_loss: 0.0073\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0036 - val_loss: 0.0103\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0048 - val_loss: 0.0159\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0059 - val_loss: 0.0097\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0039 - val_loss: 0.0130\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 630us/step - loss: 4.4237 - val_loss: 0.0171\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0263 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0120 - val_loss: 0.0206\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 359us/step - loss: 0.0558 - val_loss: 0.0397\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0213 - val_loss: 0.0208\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0255 - val_loss: 0.0422\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0362 - val_loss: 0.0519\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0332 - val_loss: 0.0492\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0381 - val_loss: 0.0573\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0473 - val_loss: 0.0648\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0444 - val_loss: 0.0554\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0454 - val_loss: 0.0663\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0448 - val_loss: 0.0795\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0521 - val_loss: 0.0477\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0381 - val_loss: 0.0509\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0384 - val_loss: 0.0423\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0276 - val_loss: 0.0307\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0368 - val_loss: 0.0497\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0328 - val_loss: 0.0251\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0216 - val_loss: 0.0236\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0314 - val_loss: 0.0319\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0227 - val_loss: 0.0202\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0220 - val_loss: 0.0134\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0214 - val_loss: 0.0189\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 667us/step - loss: 0.0585 - val_loss: 0.0342\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0169 - val_loss: 0.0135\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0100 - val_loss: 0.0080\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0048 - val_loss: 0.0106\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 359us/step - loss: 0.0093 - val_loss: 0.0172\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0087 - val_loss: 0.0078\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0060 - val_loss: 0.0111\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0090 - val_loss: 0.0138\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0069 - val_loss: 0.0111\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0063 - val_loss: 0.0168\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 359us/step - loss: 0.0087 - val_loss: 0.0121\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0077 - val_loss: 0.0068\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0040 - val_loss: 0.0094\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 359us/step - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0046 - val_loss: 0.0110\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0090 - val_loss: 0.0154\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0086 - val_loss: 0.0131\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0077 - val_loss: 0.0090\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0068 - val_loss: 0.0098\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0044 - val_loss: 0.0061\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0053 - val_loss: 0.0127\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 359us/step - loss: 0.0055 - val_loss: 0.0061\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 359us/step - loss: 0.0053 - val_loss: 0.0075\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0040 - val_loss: 0.0095\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 664us/step - loss: 0.0629 - val_loss: 0.0469\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0148 - val_loss: 0.0119\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0111 - val_loss: 0.0118\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0109 - val_loss: 0.0123\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0084 - val_loss: 0.0060\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 363us/step - loss: 0.0069 - val_loss: 0.0081\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0101 - val_loss: 0.0096\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0069 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0074 - val_loss: 0.0091\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0078 - val_loss: 0.0087\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0075 - val_loss: 0.0076\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0083 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0086 - val_loss: 0.0071\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0068 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0048 - val_loss: 0.0077\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0081 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0057 - val_loss: 0.0082\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0071 - val_loss: 0.0060\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0060 - val_loss: 0.0055\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 665us/step - loss: 0.5204 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0133 - val_loss: 0.0702\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0120 - val_loss: 0.0110\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0078 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 362us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 710us/step - loss: 2.1057 - val_loss: 0.0028\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0089 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0055 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0044 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0040 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 407us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0036 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0034 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0034 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0031 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 700us/step - loss: 1.9170 - val_loss: 0.0168\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0193 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0071 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 886us/step - loss: 0.0718 - val_loss: 0.0135\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0256 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0174 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0118 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0083 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0057 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0045 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0027 - val_loss: 0.0016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 922us/step - loss: 0.0450 - val_loss: 0.0062\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0167 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0112 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0079 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0053 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0048 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0041 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0042 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0041 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0039 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0038 - val_loss: 0.0022\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 938us/step - loss: 1.7152 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0122 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0054 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0045 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0037 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 977us/step - loss: 0.0727 - val_loss: 0.0130\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0100 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0017 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0015 - val_loss: 8.7132e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 990us/step - loss: 0.1570 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0149 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0072 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0031 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 996us/step - loss: 5.1199 - val_loss: 0.0034\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0085 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0043 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0026 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0024 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1ms/step - loss: 0.0872 - val_loss: 0.0111\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0117 - val_loss: 0.0102\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0029 - val_loss: 9.5120e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0021 - val_loss: 9.6563e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 0.0015 - val_loss: 9.9517e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0014 - val_loss: 9.9670e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0014 - val_loss: 8.8009e-04\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1ms/step - loss: 0.0972 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0145 - val_loss: 0.0072\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0081 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1ms/step - loss: 0.1054 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0126 - val_loss: 0.0063\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0075 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1ms/step - loss: 0.0746 - val_loss: 0.0122\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0243 - val_loss: 0.0067\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0168 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0115 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0083 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0062 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1ms/step - loss: 0.0850 - val_loss: 0.0233\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0388 - val_loss: 0.0152\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0314 - val_loss: 0.0117\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0254 - val_loss: 0.0091\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0203 - val_loss: 0.0068\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0162 - val_loss: 0.0050\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0129 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0104 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0084 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0070 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0060 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0040 - val_loss: 0.0025\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0036 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 895us/step - loss: 0.7027 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0081 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0057 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0042 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0040 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 346us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0030 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 948us/step - loss: 0.3570 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0087 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0075 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0069 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0057 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0056 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0161 - val_loss: 0.0103\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0089 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0074 - val_loss: 0.0079\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0140 - val_loss: 0.0166\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0123 - val_loss: 0.0072\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0082 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0121 - val_loss: 0.0143\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0110 - val_loss: 0.0082\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0097 - val_loss: 0.0115\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0113 - val_loss: 0.0136\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0117 - val_loss: 0.0110\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0065 - val_loss: 0.0096\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0115 - val_loss: 0.0204\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0197 - val_loss: 0.0073\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0054 - val_loss: 9.2550e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 985us/step - loss: 0.2088 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0135 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0101 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0082 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0068 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0096 - val_loss: 0.0240\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0190 - val_loss: 0.0052\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0071 - val_loss: 0.0069\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0142 - val_loss: 0.0164\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0117 - val_loss: 0.0029\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0051 - val_loss: 0.0051\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0134 - val_loss: 0.0146\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0104 - val_loss: 0.0104\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0086 - val_loss: 0.0085\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0085 - val_loss: 0.0065\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0072 - val_loss: 0.0082\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0118 - val_loss: 0.0089\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0067 - val_loss: 0.0091\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0097 - val_loss: 0.0114\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0085 - val_loss: 0.0089\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0096 - val_loss: 0.0167\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0136 - val_loss: 0.0155\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1000us/step - loss: 0.3614 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0108 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0085 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0073 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0059 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0055 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0066 - val_loss: 0.0379\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0295 - val_loss: 0.0050\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0066 - val_loss: 0.0055\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0155 - val_loss: 0.0181\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0136 - val_loss: 0.0171\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0125 - val_loss: 0.0162\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0134 - val_loss: 0.0117\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0076 - val_loss: 0.0100\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0100 - val_loss: 0.0193\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0131 - val_loss: 0.0124\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0111 - val_loss: 0.0145\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0097 - val_loss: 0.0155\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0105 - val_loss: 0.0133\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0094 - val_loss: 0.0152\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0095 - val_loss: 0.0129\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1ms/step - loss: 0.1198 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0071 - val_loss: 0.0282\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0163 - val_loss: 0.0087\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0155 - val_loss: 0.0125\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0139 - val_loss: 0.0283\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0136 - val_loss: 0.0201\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0142 - val_loss: 0.0112\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0118 - val_loss: 0.0182\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0112 - val_loss: 0.0156\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0111 - val_loss: 0.0159\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0109 - val_loss: 0.0125\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0079 - val_loss: 0.0139\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0115 - val_loss: 0.0093\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0052 - val_loss: 0.0198\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0108 - val_loss: 0.0129\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0054 - val_loss: 0.0177\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0092 - val_loss: 0.0144\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0046 - val_loss: 0.0131\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0086 - val_loss: 0.0149\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0048 - val_loss: 0.0158\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0081 - val_loss: 0.0133\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0049 - val_loss: 0.0095\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0067 - val_loss: 0.0207\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0048 - val_loss: 0.0096\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.0971 - val_loss: 0.0205\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0118 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0057 - val_loss: 0.0096\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0036 - val_loss: 9.8833e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0021 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.1094 - val_loss: 0.0017\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0138 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0078 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0038 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.1060 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0033 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0027 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0033 - val_loss: 0.0069\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0069 - val_loss: 0.0133\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0056 - val_loss: 0.0087\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0066 - val_loss: 0.0088\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0069 - val_loss: 0.0138\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0105 - val_loss: 0.0129\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0078 - val_loss: 0.0065\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0064 - val_loss: 0.0107\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0072 - val_loss: 0.0105\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0083 - val_loss: 0.0147\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0090 - val_loss: 0.0080\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0053 - val_loss: 0.0070\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0055 - val_loss: 0.0134\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0082 - val_loss: 0.0071\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0074 - val_loss: 0.0083\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0055 - val_loss: 0.0073\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0044 - val_loss: 0.0081\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0083 - val_loss: 0.0118\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.0390 - val_loss: 0.0206\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0086 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0069 - val_loss: 0.0072\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0058 - val_loss: 0.0093\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0073 - val_loss: 0.0063\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0051 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0062 - val_loss: 0.0072\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0058 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0049 - val_loss: 0.0036\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0051 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0045 - val_loss: 0.0060\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0061 - val_loss: 0.0041\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0044 - val_loss: 0.0051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0039 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0043 - val_loss: 0.0062\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0036 - val_loss: 0.0041\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0051 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.0487 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0037 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0042 - val_loss: 0.0103\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0097 - val_loss: 0.0047\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0063 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0060 - val_loss: 0.0052\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0058 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0039 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0065 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0053 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0063 - val_loss: 0.0038\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0047 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0061 - val_loss: 0.0049\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0038 - val_loss: 0.0029\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0055 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0035 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0049 - val_loss: 0.0046\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.0765 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0035 - val_loss: 0.0103\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0092 - val_loss: 0.0144\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0088 - val_loss: 0.0160\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0080 - val_loss: 0.0104\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0058 - val_loss: 0.0089\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0072 - val_loss: 0.0140\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0075 - val_loss: 0.0113\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0074 - val_loss: 0.0113\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0076 - val_loss: 0.0102\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0062 - val_loss: 0.0083\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0050 - val_loss: 0.0096\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0059 - val_loss: 0.0092\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0073 - val_loss: 0.0124\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0061 - val_loss: 0.0086\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0052 - val_loss: 0.0143\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0079 - val_loss: 0.0087\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0040 - val_loss: 0.0098\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0065 - val_loss: 0.0110\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.2657 - val_loss: 0.1215\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0544 - val_loss: 0.0211\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0916 - val_loss: 0.3482\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0912 - val_loss: 0.0309\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0583 - val_loss: 0.1511\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0600 - val_loss: 0.0495\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0395 - val_loss: 0.0614\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0428 - val_loss: 0.0329\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0354 - val_loss: 0.0364\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0318 - val_loss: 0.0352\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0314 - val_loss: 0.0199\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0241 - val_loss: 0.0199\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0265 - val_loss: 0.0214\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0282 - val_loss: 0.0206\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0289 - val_loss: 0.0216\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0249 - val_loss: 0.0126\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0212 - val_loss: 0.0154\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0235 - val_loss: 0.0205\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0315 - val_loss: 0.0300\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0281 - val_loss: 0.0122\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0186 - val_loss: 0.0097\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0174 - val_loss: 0.0134\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0181 - val_loss: 0.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0239 - val_loss: 0.0150\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.1205 - val_loss: 0.0074\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0583 - val_loss: 0.0271\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0518 - val_loss: 0.2326\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.1017 - val_loss: 0.0316\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0382 - val_loss: 0.1124\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0526 - val_loss: 0.0210\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0208 - val_loss: 0.0156\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0220 - val_loss: 0.0110\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0181 - val_loss: 0.0065\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0138 - val_loss: 0.0062\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0123 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0175 - val_loss: 0.0117\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0176 - val_loss: 0.0092\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0154 - val_loss: 0.0067\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0139 - val_loss: 0.0058\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0176 - val_loss: 0.0129\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0152 - val_loss: 0.0044\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0108 - val_loss: 0.0085\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0166 - val_loss: 0.0075\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0135 - val_loss: 0.0075\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0156 - val_loss: 0.0069\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0107 - val_loss: 0.0037\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0130 - val_loss: 0.0061\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0137 - val_loss: 0.0051\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.5192 - val_loss: 0.0040\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0719 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0717 - val_loss: 0.0301\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0294 - val_loss: 0.0922\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0708 - val_loss: 0.0188\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0565 - val_loss: 0.0344\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0303 - val_loss: 0.0954\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0382 - val_loss: 0.0505\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0416 - val_loss: 0.0406\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0235 - val_loss: 0.0711\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0312 - val_loss: 0.0547\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0263 - val_loss: 0.0598\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0252 - val_loss: 0.0506\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0220 - val_loss: 0.0488\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0204 - val_loss: 0.0395\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0218 - val_loss: 0.0537\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0149 - val_loss: 0.0564\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0205 - val_loss: 0.0354\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0179 - val_loss: 0.0472\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0143 - val_loss: 0.0388\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0161 - val_loss: 0.0299\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0141 - val_loss: 0.0343\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0129 - val_loss: 0.0375\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0128 - val_loss: 0.0284\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: nan - val_loss: nan\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.3189 - val_loss: 0.0540\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0218 - val_loss: 0.0090\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0106 - val_loss: 0.0118\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0067 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0042 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 2.0082 - val_loss: 1.1268\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.4850 - val_loss: 0.3175\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.1333 - val_loss: 0.0934\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 362us/step - loss: 0.0697 - val_loss: 0.0337\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0678 - val_loss: 0.0193\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0705 - val_loss: 0.0179\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.0700 - val_loss: 0.0213\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0681 - val_loss: 0.0265\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 365us/step - loss: 0.0668 - val_loss: 0.0320\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.0661 - val_loss: 0.0360\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 362us/step - loss: 0.0659 - val_loss: 0.0385\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0659 - val_loss: 0.0395\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 362us/step - loss: 0.0659 - val_loss: 0.0400\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 363us/step - loss: 0.0659 - val_loss: 0.0397\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 364us/step - loss: 0.0659 - val_loss: 0.0396\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0659 - val_loss: 0.0391\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 363us/step - loss: 0.0659 - val_loss: 0.0390\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 359us/step - loss: 0.0659 - val_loss: 0.0386\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 363us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.0887 - val_loss: 0.0892\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 367us/step - loss: 0.0688 - val_loss: 0.0254\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0624 - val_loss: 0.0174\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 363us/step - loss: 0.0494 - val_loss: 0.0183\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 363us/step - loss: 0.0348 - val_loss: 0.0081\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 367us/step - loss: 0.0217 - val_loss: 0.0050\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0135 - val_loss: 0.0092\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 367us/step - loss: 0.0088 - val_loss: 0.0130\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 367us/step - loss: 0.0059 - val_loss: 0.0031\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 365us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 366us/step - loss: 0.0038 - val_loss: 0.0037\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 363us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 364us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 367us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 364us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 367us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 369us/step - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 366us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 364us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 366us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 365us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 365us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 364us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 2ms/step - loss: 0.6235 - val_loss: 0.0204\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 499us/step - loss: 0.0967 - val_loss: 0.0464\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0727 - val_loss: 0.0972\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0804 - val_loss: 0.0915\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 494us/step - loss: 0.0742 - val_loss: 0.0651\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0677 - val_loss: 0.0452\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0659 - val_loss: 0.0355\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0661 - val_loss: 0.0329\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0661 - val_loss: 0.0340\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0660 - val_loss: 0.0363\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 494us/step - loss: 0.0659 - val_loss: 0.0385\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 495us/step - loss: 0.0659 - val_loss: 0.0394\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0659 - val_loss: 0.0394\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0659 - val_loss: 0.0396\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0659 - val_loss: 0.0390\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0659 - val_loss: 0.0386\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0659 - val_loss: 0.0386\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 491us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0659 - val_loss: 0.0390\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 491us/step - loss: 0.0659 - val_loss: 0.0391\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0659 - val_loss: 0.0390\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.4091 - val_loss: 0.0093\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0270 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0104 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0057 - val_loss: 0.0119\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0026 - val_loss: 9.6437e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0015 - val_loss: 8.9283e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0016 - val_loss: 9.2866e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0015 - val_loss: 9.6118e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0015 - val_loss: 9.0491e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0015 - val_loss: 8.6145e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0014 - val_loss: 7.4719e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0014 - val_loss: 8.0545e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0014 - val_loss: 7.3361e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0014 - val_loss: 8.9158e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0013 - val_loss: 7.6578e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0013 - val_loss: 8.1382e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.3211 - val_loss: 0.0164\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0261 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0120 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0055 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0035 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0016 - val_loss: 9.7812e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0015 - val_loss: 9.9976e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0015 - val_loss: 8.9953e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0014 - val_loss: 9.3371e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0014 - val_loss: 8.7200e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0014 - val_loss: 8.8447e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0013 - val_loss: 8.3064e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0013 - val_loss: 8.8577e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0013 - val_loss: 8.6462e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0013 - val_loss: 8.0250e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0465 - val_loss: 0.0067\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0070 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0035 - val_loss: 9.5677e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0018 - val_loss: 8.5187e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0016 - val_loss: 9.6338e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0013 - val_loss: 9.3563e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0012 - val_loss: 7.5718e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0011 - val_loss: 7.1725e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0011 - val_loss: 7.2568e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0012 - val_loss: 8.2823e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0011 - val_loss: 6.9985e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0011 - val_loss: 7.4585e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0011 - val_loss: 7.4052e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0011 - val_loss: 7.1520e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0011 - val_loss: 6.6933e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0010 - val_loss: 6.7537e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0945 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0105 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0060 - val_loss: 9.6242e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0024 - val_loss: 9.3726e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 407us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0438 - val_loss: 0.0282\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 371us/step - loss: 0.0112 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 373us/step - loss: 0.0044 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 373us/step - loss: 0.0034 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 369us/step - loss: 0.0029 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 373us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 369us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 374us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 373us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 370us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 375us/step - loss: 0.0016 - val_loss: 9.5695e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 369us/step - loss: 0.0015 - val_loss: 9.5998e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 371us/step - loss: 0.0015 - val_loss: 8.9643e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 370us/step - loss: 0.0015 - val_loss: 8.6176e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 374us/step - loss: 0.0014 - val_loss: 8.4950e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 371us/step - loss: 0.0014 - val_loss: 8.3842e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 370us/step - loss: 0.0014 - val_loss: 8.7357e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 371us/step - loss: 0.0013 - val_loss: 8.9148e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 373us/step - loss: 0.0013 - val_loss: 8.0534e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 371us/step - loss: 0.0013 - val_loss: 8.1238e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 377us/step - loss: 0.0013 - val_loss: 8.0483e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 371us/step - loss: 0.0012 - val_loss: 8.4297e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 372us/step - loss: 0.0013 - val_loss: 8.4940e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0579 - val_loss: 0.0263\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0082 - val_loss: 0.0135\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0012 - val_loss: 9.0135e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0012 - val_loss: 9.3700e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0012 - val_loss: 7.9131e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0011 - val_loss: 7.6101e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0011 - val_loss: 6.9417e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0011 - val_loss: 7.3409e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0011 - val_loss: 8.1945e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0011 - val_loss: 6.7283e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0010 - val_loss: 7.3394e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0010 - val_loss: 7.3980e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0010 - val_loss: 6.5214e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0010 - val_loss: 7.0419e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 9.9123e-04 - val_loss: 6.4760e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0442 - val_loss: 0.0066\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0095 - val_loss: 0.0144\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0108 - val_loss: 0.0101\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0059 - val_loss: 0.0076\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0062 - val_loss: 0.0063\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0041 - val_loss: 0.0046\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0054 - val_loss: 0.0108\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0065 - val_loss: 0.0083\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0059 - val_loss: 0.0069\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0057 - val_loss: 0.0070\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0038 - val_loss: 0.0087\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0063 - val_loss: 0.0110\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0049 - val_loss: 0.0074\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0044 - val_loss: 0.0068\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0037 - val_loss: 0.0063\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0055 - val_loss: 0.0097\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0037 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0050 - val_loss: 0.0082\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0047 - val_loss: 0.0054\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0339 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0069 - val_loss: 0.0158\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0088 - val_loss: 0.0118\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0061 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0048 - val_loss: 0.0085\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0070 - val_loss: 0.0081\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0063 - val_loss: 0.0110\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0058 - val_loss: 0.0071\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0045 - val_loss: 0.0085\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0049 - val_loss: 0.0095\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0057 - val_loss: 0.0064\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0042 - val_loss: 0.0059\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 321us/step - loss: 0.0053 - val_loss: 0.0108\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0049 - val_loss: 0.0076\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0045 - val_loss: 0.0091\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0051 - val_loss: 0.0055\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0036 - val_loss: 0.0075\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0042 - val_loss: 0.0086\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0068 - val_loss: 0.0088\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0039 - val_loss: 0.0069\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0037 - val_loss: 0.0050\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 321us/step - loss: 0.0032 - val_loss: 0.0052\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0363 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0054 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0066 - val_loss: 0.0101\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0100 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0052 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0066 - val_loss: 0.0062\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0041 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0053 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0066 - val_loss: 0.0067\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0063 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0037 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 320us/step - loss: 0.0056 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0061 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0040 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0051 - val_loss: 0.0047\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0048 - val_loss: 0.0028\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0057 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0598 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0077 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0095 - val_loss: 0.0222\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0113 - val_loss: 0.0059\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0053 - val_loss: 0.0067\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0050 - val_loss: 0.0065\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0078 - val_loss: 0.0122\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0083 - val_loss: 0.0101\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0055 - val_loss: 0.0087\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0046 - val_loss: 0.0040\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0048 - val_loss: 0.0081\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0062 - val_loss: 0.0111\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0071 - val_loss: 0.0074\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0040 - val_loss: 0.0053\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0053 - val_loss: 0.0125\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0051 - val_loss: 0.0064\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0054 - val_loss: 0.0074\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0037 - val_loss: 0.0058\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0048 - val_loss: 0.0118\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0062 - val_loss: 0.0071\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0035 - val_loss: 0.0053\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0406 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0054 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0093 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0071 - val_loss: 0.0066\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0069 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0066 - val_loss: 0.0134\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0106 - val_loss: 0.0039\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0046 - val_loss: 8.9586e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0039 - val_loss: 0.0059\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0069 - val_loss: 0.0061\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0065 - val_loss: 0.0065\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0052 - val_loss: 0.0040\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0062 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0047 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0036 - val_loss: 0.0029\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0492 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0066 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0082 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0058 - val_loss: 0.0050\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0091 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0065 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0061 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0066 - val_loss: 0.0038\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0072 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0065 - val_loss: 0.0051\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0042 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0049 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0062 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0046 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0070 - val_loss: 0.0045\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0044 - val_loss: 0.0025\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0038 - val_loss: 0.0027\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0052 - val_loss: 0.0031\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0957 - val_loss: 0.0023\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0084 - val_loss: 0.0083\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0124 - val_loss: 0.0207\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0115 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0055 - val_loss: 0.0057\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0056 - val_loss: 0.0085\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0072 - val_loss: 0.0114\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0071 - val_loss: 0.0123\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0043 - val_loss: 0.0071\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0053 - val_loss: 0.0121\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0078 - val_loss: 0.0109\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0054 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0033 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 322us/step - loss: 0.0058 - val_loss: 0.0116\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0073 - val_loss: 0.0097\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0059 - val_loss: 0.0063\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0038 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0037 - val_loss: 0.0070\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0044 - val_loss: 0.0070\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0060 - val_loss: 0.0073\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0041 - val_loss: 0.0058\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0032 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0033 - val_loss: 0.0082\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 1.5980 - val_loss: 0.0061\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0096 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 0.0456 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0057 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0022 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0013 - val_loss: 8.7132e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0012 - val_loss: 9.5053e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0012 - val_loss: 7.3466e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0011 - val_loss: 7.2603e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0012 - val_loss: 8.5713e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0011 - val_loss: 7.2457e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0012 - val_loss: 6.9827e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0011 - val_loss: 8.5017e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0011 - val_loss: 6.8149e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0011 - val_loss: 6.7336e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0010 - val_loss: 6.9635e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0010 - val_loss: 6.9237e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0010 - val_loss: 6.5046e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 9.7563e-04 - val_loss: 6.7037e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 9.5318e-04 - val_loss: 7.1215e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 0.1202 - val_loss: 0.0167\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0162 - val_loss: 0.0123\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0076 - val_loss: 0.0096\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: nan - val_loss: nan\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 10s 2ms/step - loss: 154.2012 - val_loss: 0.3638\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.1158 - val_loss: 0.0342\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0686 - val_loss: 0.0320\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0648 - val_loss: 0.0262\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0597 - val_loss: 0.0230\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0543 - val_loss: 0.0207\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0515 - val_loss: 0.0190\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0499 - val_loss: 0.0162\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0422 - val_loss: 0.0149\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0409 - val_loss: 0.0130\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0423 - val_loss: 0.0137\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0377 - val_loss: 0.0111\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0358 - val_loss: 0.0085\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0353 - val_loss: 0.0095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0338 - val_loss: 0.0082\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0337 - val_loss: 0.0069\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0328 - val_loss: 0.0075\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0299 - val_loss: 0.0070\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0298 - val_loss: 0.0059\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0307 - val_loss: 0.0057\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0286 - val_loss: 0.0059\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0293 - val_loss: 0.0050\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0275 - val_loss: 0.0054\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0274 - val_loss: 0.0042\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 1.3831 - val_loss: 0.0047\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0115 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 505us/step - loss: 0.0035 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 505us/step - loss: 0.0031 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 504us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0026 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 10s 2ms/step - loss: 0.5474 - val_loss: 0.0240\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0135 - val_loss: 0.0156\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0080 - val_loss: 0.0058\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0039 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0029 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0017 - val_loss: 9.9579e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0015 - val_loss: 9.9068e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 10s 2ms/step - loss: 0.4697 - val_loss: 0.0900\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0312 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0049 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 491us/step - loss: 0.0026 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0051 - val_loss: 0.0053\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0033 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0025 - val_loss: 0.0031\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 494us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 495us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 499us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 491us/step - loss: 0.0022 - val_loss: 0.0011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 489us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 10s 2ms/step - loss: 0.0683 - val_loss: 0.0264\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0648 - val_loss: 0.0433\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0574 - val_loss: 0.0202\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0406 - val_loss: 0.0066\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0225 - val_loss: 0.0105\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0226 - val_loss: 0.1011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0465 - val_loss: 0.0402\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0650 - val_loss: 0.0405\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0660 - val_loss: 0.0374\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0659 - val_loss: 0.0426\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0661 - val_loss: 0.0362\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0659 - val_loss: 0.0433\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0659 - val_loss: 0.0360\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0659 - val_loss: 0.0413\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0659 - val_loss: 0.0378\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0659 - val_loss: 0.0355\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0657 - val_loss: 0.0424\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0647 - val_loss: 0.0265\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0567 - val_loss: 0.0046\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0246 - val_loss: 0.0111\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0119 - val_loss: 0.0152\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0102 - val_loss: 0.0127\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0067 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 10s 3ms/step - loss: 0.0622 - val_loss: 0.0206\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0099 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0036 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0026 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0018 - val_loss: 8.7005e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0013 - val_loss: 9.2944e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0013 - val_loss: 8.4460e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0012 - val_loss: 8.6810e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0012 - val_loss: 7.8526e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0012 - val_loss: 7.7019e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0011 - val_loss: 8.6936e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0012 - val_loss: 7.1286e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0011 - val_loss: 7.8059e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0010 - val_loss: 7.3037e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0010 - val_loss: 7.9057e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0010 - val_loss: 7.2116e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: 0.0011 - val_loss: 6.8181e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 11s 3ms/step - loss: 0.0533 - val_loss: 0.0167\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0065 - val_loss: 0.0123\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0035 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 8.9664e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0015 - val_loss: 8.5417e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0015 - val_loss: 8.3019e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 8.3591e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0014 - val_loss: 8.3408e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0013 - val_loss: 8.2955e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0013 - val_loss: 9.2385e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0012 - val_loss: 7.6371e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0012 - val_loss: 8.5524e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0011 - val_loss: 7.8639e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0011 - val_loss: 7.2657e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0011 - val_loss: 7.3200e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0011 - val_loss: 6.9760e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0011 - val_loss: 7.4521e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0010 - val_loss: 6.6562e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0010 - val_loss: 7.3628e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0010 - val_loss: 6.5010e-04\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0011 - val_loss: 7.0316e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0011 - val_loss: 8.9537e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 11s 3ms/step - loss: 0.1018 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0081 - val_loss: 0.0413\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0099 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0028 - val_loss: 0.0074\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0102 - val_loss: 0.0087\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0036 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0049 - val_loss: 0.0343\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0087 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0043 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0031 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0040 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0047 - val_loss: 0.0064\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0023 - val_loss: 8.6476e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0034 - val_loss: 0.0014\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 12s 3ms/step - loss: 0.2125 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0078 - val_loss: 0.0134\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0090 - val_loss: 0.0104\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0053 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0041 - val_loss: 0.0066\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0050 - val_loss: 0.0115\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0059 - val_loss: 0.0104\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0042 - val_loss: 0.0052\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0028 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0056 - val_loss: 0.0132\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0049 - val_loss: 0.0063\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0034 - val_loss: 0.0039\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0031 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0035 - val_loss: 0.0100\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0056 - val_loss: 0.0057\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0028 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0019 - val_loss: 8.1318e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0042 - val_loss: 0.0064\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0056 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0025 - val_loss: 7.8774e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 9.1933e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0016 - val_loss: 7.5063e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 11s 3ms/step - loss: 0.0491 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0130 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0078 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0047 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0028 - val_loss: 0.0026\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0048 - val_loss: 0.0098\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0051 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0034 - val_loss: 0.0067\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0047 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0024 - val_loss: 8.4036e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0016 - val_loss: 7.1519e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0021 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0051 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0020 - val_loss: 8.0786e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0017 - val_loss: 9.8728e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0022 - val_loss: 9.6731e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 12s 3ms/step - loss: 0.1031 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0063 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0035 - val_loss: 0.0088\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0021 - val_loss: 9.0048e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0044 - val_loss: 0.0067\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0028 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0018 - val_loss: 8.3117e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0017 - val_loss: 8.4849e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0037 - val_loss: 0.0112\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0040 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0019 - val_loss: 9.7702e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 8.5178e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0029 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0019 - val_loss: 7.2230e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0015 - val_loss: 7.0399e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0016 - val_loss: 6.9707e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 12s 3ms/step - loss: 0.1061 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0079 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0066 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0036 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0031 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0034 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0027 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0028 - val_loss: 0.0028\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0037 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0030 - val_loss: 0.0053\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 12s 3ms/step - loss: 0.0971 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0039 - val_loss: 0.0110\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0087 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 540us/step - loss: 0.0110 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 542us/step - loss: 0.0063 - val_loss: 0.0414\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0098 - val_loss: 0.0129\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0089 - val_loss: 0.0145\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0074 - val_loss: 0.0155\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0113 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 0.0040 - val_loss: 0.0146\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 540us/step - loss: 0.0087 - val_loss: 0.0060\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0051 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0073 - val_loss: 0.0069\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0054 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0054 - val_loss: 0.0125\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0065 - val_loss: 8.7325e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0041 - val_loss: 0.0088\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0070 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0030 - val_loss: 0.0047\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0059 - val_loss: 0.0116\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0045 - val_loss: 7.2450e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0038 - val_loss: 0.0040\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 542us/step - loss: 0.0054 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 543us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 12s 3ms/step - loss: 0.0849 - val_loss: 0.0118\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0268 - val_loss: 0.0080\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: 0.0184 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0129 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0088 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0031 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0031 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0027 - val_loss: 0.0018\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 13s 3ms/step - loss: 0.1390 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0191 - val_loss: 0.0241\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0102 - val_loss: 0.0081\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0048 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0034 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0023 - val_loss: 9.8158e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 9.8558e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0013 - val_loss: 8.7827e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 7.9054e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0013 - val_loss: 8.1198e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0013 - val_loss: 7.9219e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0012 - val_loss: 8.8897e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0012 - val_loss: 7.8691e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0012 - val_loss: 7.9663e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0012 - val_loss: 8.1425e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0011 - val_loss: 7.9962e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 13s 3ms/step - loss: 0.2919 - val_loss: 0.0055\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0248 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0069 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0034 - val_loss: 9.7694e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0019 - val_loss: 9.5508e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 9.0009e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 8.3029e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 8.4121e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 8.7544e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 8.3011e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0015 - val_loss: 8.2378e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 0.0015 - val_loss: 8.5068e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 608us/step - loss: 0.0015 - val_loss: 9.8068e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 0.0015 - val_loss: 7.9865e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 0.0014 - val_loss: 7.6801e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0014 - val_loss: 7.4506e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0014 - val_loss: 8.3507e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 13s 3ms/step - loss: 0.4379 - val_loss: 0.0035\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0219 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 0.0135 - val_loss: 0.0160\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0084 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0046 - val_loss: 0.0095\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0030 - val_loss: 8.9014e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0019 - val_loss: 9.6662e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0017 - val_loss: 9.5181e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0016 - val_loss: 8.7995e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0016 - val_loss: 9.9725e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 8.8523e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0015 - val_loss: 9.3100e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 8.4094e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0014 - val_loss: 7.9258e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0014 - val_loss: 9.1222e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 8.8627e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0014 - val_loss: 7.6799e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0014 - val_loss: 7.6197e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 13s 3ms/step - loss: 0.1826 - val_loss: 0.0502\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0850 - val_loss: 0.0638\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0623 - val_loss: 0.0038\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0272 - val_loss: 0.0261\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0117 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0043 - val_loss: 0.0088\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0016 - val_loss: 9.5461e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 8.5835e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 9.9058e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 8.2376e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0013 - val_loss: 8.0603e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 13s 3ms/step - loss: 0.1173 - val_loss: 0.0334\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0647 - val_loss: 0.0372\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0593 - val_loss: 0.0327\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0488 - val_loss: 0.0268\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0538 - val_loss: 0.1167\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0435 - val_loss: 0.0429\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0266 - val_loss: 0.0079\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0137 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0118 - val_loss: 0.0082\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0157 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0099 - val_loss: 0.0026\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0134 - val_loss: 0.0083\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0162 - val_loss: 0.0035\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0096 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0082 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0146 - val_loss: 0.0067\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0135 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0115 - val_loss: 0.0064\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0119 - val_loss: 0.0063\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0102 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0111 - val_loss: 0.0052\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0095 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0123 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0105 - val_loss: 0.0047\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 14s 3ms/step - loss: 0.0961 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0027 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0106 - val_loss: 0.0159\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0070 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0029 - val_loss: 0.0037\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0124 - val_loss: 0.0241\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0119 - val_loss: 0.0072\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0060 - val_loss: 0.0050\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0063 - val_loss: 0.0087\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0102 - val_loss: 0.0124\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0078 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0067 - val_loss: 0.0082\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0069 - val_loss: 0.0058\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0065 - val_loss: 0.0104\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0077 - val_loss: 0.0110\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0081 - val_loss: 0.0087\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0077 - val_loss: 0.0057\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0055 - val_loss: 0.0054\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0069 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0053 - val_loss: 0.0069\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 14s 3ms/step - loss: 0.1652 - val_loss: 0.0606\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0317 - val_loss: 0.0138\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0191 - val_loss: 0.0338\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0161 - val_loss: 0.0227\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0147 - val_loss: 0.0122\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0117 - val_loss: 0.0064\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0076 - val_loss: 0.0169\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0112 - val_loss: 0.0094\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0086 - val_loss: 0.0138\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0072 - val_loss: 0.0076\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0065 - val_loss: 0.0066\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0057 - val_loss: 0.0074\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0054 - val_loss: 0.0110\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0071 - val_loss: 0.0115\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0066 - val_loss: 0.0059\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0036 - val_loss: 0.0048\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0045 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0054 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0054 - val_loss: 0.0078\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0049 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0040 - val_loss: 0.0055\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 14s 3ms/step - loss: 0.2072 - val_loss: 0.2219\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.1183 - val_loss: 0.1258\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0788 - val_loss: 0.0775\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0623 - val_loss: 0.0537\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0552 - val_loss: 0.0411\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0516 - val_loss: 0.0337\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0489 - val_loss: 0.0293\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0470 - val_loss: 0.0269\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0455 - val_loss: 0.0248\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0441 - val_loss: 0.0230\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0429 - val_loss: 0.0215\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0414 - val_loss: 0.0204\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0399 - val_loss: 0.0193\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0386 - val_loss: 0.0185\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0372 - val_loss: 0.0173\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0356 - val_loss: 0.0164\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0342 - val_loss: 0.0154\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0327 - val_loss: 0.0145\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0313 - val_loss: 0.0136\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0294 - val_loss: 0.0125\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0280 - val_loss: 0.0117\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0265 - val_loss: 0.0110\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0249 - val_loss: 0.0099\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0232 - val_loss: 0.0090\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 15s 4ms/step - loss: 0.0681 - val_loss: 0.0095\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0084 - val_loss: 0.0036\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0054 - val_loss: 0.0097\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0037 - val_loss: 8.7733e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0021 - val_loss: 8.7132e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0019 - val_loss: 9.7363e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0017 - val_loss: 9.0694e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0017 - val_loss: 9.0863e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0014 - val_loss: 9.9487e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0015 - val_loss: 7.7446e-04\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 7.2679e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0014 - val_loss: 8.0908e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0014 - val_loss: 7.4463e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0013 - val_loss: 7.7939e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0014 - val_loss: 7.0913e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 7.4849e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 14s 4ms/step - loss: 0.0585 - val_loss: 0.0173\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0080 - val_loss: 0.0060\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0028 - val_loss: 9.8894e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0013 - val_loss: 9.6245e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0013 - val_loss: 8.5795e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0013 - val_loss: 7.7973e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0012 - val_loss: 7.4454e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0012 - val_loss: 7.6499e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0012 - val_loss: 7.8511e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0011 - val_loss: 7.1953e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0011 - val_loss: 7.5259e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0011 - val_loss: 7.7112e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0011 - val_loss: 7.4419e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0010 - val_loss: 6.9037e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0011 - val_loss: 6.7897e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0010 - val_loss: 6.6743e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0010 - val_loss: 6.7634e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 15s 4ms/step - loss: 0.0902 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0051 - val_loss: 0.0189\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0055 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0059 - val_loss: 0.0054\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0037 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0021 - val_loss: 8.4454e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0058 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0018 - val_loss: 8.4793e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0043 - val_loss: 0.0077\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0054 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0030 - val_loss: 0.0029\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0038 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0017 - val_loss: 7.5120e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0015 - val_loss: 9.4238e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0024 - val_loss: 0.0045\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 15s 4ms/step - loss: 0.1027 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0040 - val_loss: 0.0145\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0188 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0072 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0057 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0027 - val_loss: 0.0067\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0073 - val_loss: 0.0073\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0054 - val_loss: 0.0080\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0034 - val_loss: 0.0048\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0030 - val_loss: 0.0046\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0047 - val_loss: 0.0106\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0068 - val_loss: 0.0072\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0038 - val_loss: 0.0050\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0035 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0020 - val_loss: 9.4849e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0047 - val_loss: 0.0062\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0039 - val_loss: 9.5276e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0020 - val_loss: 7.3586e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 15s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: nan - val_loss: nan\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 15s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 16s 4ms/step - loss: 0.2362 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0082 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0062 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0057 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0058 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0052 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0052 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0051 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0045 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0045 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0038 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 16s 4ms/step - loss: 0.7943 - val_loss: 0.0113\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0243 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0146 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0104 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0082 - val_loss: 0.0013\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0076 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0071 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0069 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0065 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 505us/step - loss: 0.0060 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0058 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0056 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0058 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0055 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0052 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0051 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0049 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 505us/step - loss: 0.0049 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: 0.0047 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0041 - val_loss: 0.0013\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 16s 4ms/step - loss: 0.0807 - val_loss: 0.0105\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0247 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0176 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0125 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0095 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0076 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0071 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0060 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0054 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0054 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0051 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0051 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0049 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0046 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0044 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0044 - val_loss: 0.0019\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 17s 4ms/step - loss: 0.8606 - val_loss: 0.7932\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.4103 - val_loss: 0.3918\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.1893 - val_loss: 0.1857\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0987 - val_loss: 0.0865\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0699 - val_loss: 0.0442\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0661 - val_loss: 0.0287\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0673 - val_loss: 0.0251\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0675 - val_loss: 0.0270\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0667 - val_loss: 0.0315\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0662 - val_loss: 0.0362\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0659 - val_loss: 0.0393\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0659 - val_loss: 0.0404\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0659 - val_loss: 0.0403\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0659 - val_loss: 0.0398\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0659 - val_loss: 0.0390\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0659 - val_loss: 0.0385\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0659 - val_loss: 0.0381\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 17s 4ms/step - loss: 0.0804 - val_loss: 0.0172\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0103 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0048 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0032 - val_loss: 9.7376e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0025 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0016 - val_loss: 8.2731e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0014 - val_loss: 7.8687e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0014 - val_loss: 8.5632e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0012 - val_loss: 8.2473e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 8.2749e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 7.4908e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0011 - val_loss: 7.0620e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0011 - val_loss: 7.8366e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0011 - val_loss: 7.7576e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0011 - val_loss: 6.9880e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0011 - val_loss: 8.5026e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 7.3687e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0010 - val_loss: 6.7787e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0010 - val_loss: 7.8452e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 18s 4ms/step - loss: 0.3397 - val_loss: 0.0376\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0558 - val_loss: 0.0123\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0752 - val_loss: 0.0498\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0620 - val_loss: 0.0170\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0701 - val_loss: 0.0389\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0644 - val_loss: 0.0387\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0616 - val_loss: 0.0071\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0681 - val_loss: 0.0565\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0595 - val_loss: 0.0410\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0855 - val_loss: 0.0401\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0657 - val_loss: 0.0310\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0649 - val_loss: 0.0247\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0646 - val_loss: 0.0109\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0659 - val_loss: 0.0434\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0623 - val_loss: 0.1072\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0636 - val_loss: 0.0062\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0388 - val_loss: 0.0316\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0203 - val_loss: 0.0066\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0144 - val_loss: 0.0498\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0077 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0123 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0039 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0138 - val_loss: 0.0025\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 18s 4ms/step - loss: 0.2704 - val_loss: 0.0789\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0853 - val_loss: 0.0681\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0653 - val_loss: 0.0109\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0591 - val_loss: 0.0240\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0356 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0102 - val_loss: 0.0090\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0066 - val_loss: 0.0049\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 18s 4ms/step - loss: 5.6652 - val_loss: 0.0051\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0116 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0065 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0039 - val_loss: 0.0030\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0037 - val_loss: 0.0027\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0036 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 18s 4ms/step - loss: 4.4299 - val_loss: 0.0061\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0128 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0063 - val_loss: 0.0036\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0050 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0044 - val_loss: 0.0036\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0043 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0041 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0040 - val_loss: 0.0030\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0038 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0033 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0032 - val_loss: 0.0023\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 19s 5ms/step - loss: 0.2770 - val_loss: 0.0185\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0207 - val_loss: 0.0143\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0349 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0058 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0050 - val_loss: 0.0139\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0034 - val_loss: 0.0091\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0025 - val_loss: 0.0072\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0022 - val_loss: 0.0074\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0028 - val_loss: 0.0073\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0023 - val_loss: 0.0045\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0019 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0021 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 19s 5ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 572us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: nan - val_loss: nan\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 18s 4ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 387us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 385us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 390us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 387us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 385us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 387us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 389us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 19s 5ms/step - loss: 0.0656 - val_loss: 0.0144\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0108 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0035 - val_loss: 0.0042\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0020 - val_loss: 9.5753e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0014 - val_loss: 9.0622e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0013 - val_loss: 8.8179e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0013 - val_loss: 8.0839e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0013 - val_loss: 8.4178e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0012 - val_loss: 7.6767e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0012 - val_loss: 7.3761e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0012 - val_loss: 7.9003e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 7.3286e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0011 - val_loss: 7.2209e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 8.3583e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 7.1413e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0011 - val_loss: 6.9906e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 20s 5ms/step - loss: 0.0468 - val_loss: 0.0188\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0066 - val_loss: 0.0095\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0041 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0022 - val_loss: 9.8325e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0020 - val_loss: 9.1728e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0014 - val_loss: 8.8628e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0014 - val_loss: 7.9667e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 8.3567e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 7.5838e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0011 - val_loss: 8.0312e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 7.8176e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0011 - val_loss: 9.4810e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0011 - val_loss: 7.3919e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 8.3882e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0012 - val_loss: 6.8517e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0011 - val_loss: 6.8856e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0010 - val_loss: 9.1260e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0011 - val_loss: 6.8963e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0011 - val_loss: 7.1573e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 19s 5ms/step - loss: 0.0807 - val_loss: 0.0258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0125 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0066 - val_loss: 0.0109\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0034 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.0022 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 335us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0017 - val_loss: 9.3361e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0016 - val_loss: 8.6573e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.0016 - val_loss: 8.6907e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0015 - val_loss: 9.4158e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0015 - val_loss: 9.1439e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.0014 - val_loss: 8.0875e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0013 - val_loss: 7.6563e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0013 - val_loss: 7.7727e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 335us/step - loss: 0.0013 - val_loss: 7.7778e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.0013 - val_loss: 8.1732e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 20s 5ms/step - loss: 0.0468 - val_loss: 0.0085\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0100 - val_loss: 0.0111\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0083 - val_loss: 0.0121\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0084 - val_loss: 0.0078\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0065 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0072 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0042 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0071 - val_loss: 0.0080\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0056 - val_loss: 0.0055\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0065 - val_loss: 0.0076\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0072 - val_loss: 0.0079\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0062 - val_loss: 0.0050\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0056 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0063 - val_loss: 0.0053\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0058 - val_loss: 0.0054\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0054 - val_loss: 0.0090\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0060 - val_loss: 0.0072\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0062 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0051 - val_loss: 0.0042\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0049 - val_loss: 0.0068\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 20s 5ms/step - loss: 0.0558 - val_loss: 0.0084\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 389us/step - loss: 0.0166 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0095 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0050 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0045 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0044 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0042 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0039 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 389us/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0035 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 20s 5ms/step - loss: 0.0682 - val_loss: 0.0106\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0241 - val_loss: 0.0075\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0174 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0131 - val_loss: 0.0033\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0099 - val_loss: 0.0023\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0080 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 335us/step - loss: 0.0063 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0051 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0043 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0041 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 335us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 335us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0035 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.0032 - val_loss: 0.0018\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 20s 5ms/step - loss: 0.0739 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.0098 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 335us/step - loss: 0.0053 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 335us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 335us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 337us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 341us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 337us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 20s 5ms/step - loss: 0.0566 - val_loss: 0.0141\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0078 - val_loss: 0.0076\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 337us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0032 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0027 - val_loss: 9.6328e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0026 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 343us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 335us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 337us/step - loss: 0.0018 - val_loss: 9.4660e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 20s 5ms/step - loss: 0.0480 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 334us/step - loss: 0.0083 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0049 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0032 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 342us/step - loss: 0.0026 - val_loss: 9.6504e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 345us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 346us/step - loss: 0.0020 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 367us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.0019 - val_loss: 9.9965e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 356us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 354us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 359us/step - loss: 0.0017 - val_loss: 9.5716e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 343us/step - loss: 0.0016 - val_loss: 9.7208e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.0636 - val_loss: 0.0079\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 489us/step - loss: 0.0104 - val_loss: 0.0070\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0033 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0020 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0016 - val_loss: 9.9692e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 491us/step - loss: 0.0015 - val_loss: 9.1106e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 491us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0014 - val_loss: 9.6335e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0013 - val_loss: 9.3782e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0013 - val_loss: 9.8875e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0012 - val_loss: 7.4817e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0013 - val_loss: 7.4053e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0012 - val_loss: 7.9954e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0011 - val_loss: 8.5250e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0012 - val_loss: 7.1707e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0011 - val_loss: 8.0019e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0011 - val_loss: 8.5301e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.0868 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0109 - val_loss: 0.0025\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0044 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0023 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 9.7295e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0014 - val_loss: 8.1812e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0014 - val_loss: 7.7309e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0013 - val_loss: 7.5725e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0013 - val_loss: 8.5092e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 8.3643e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 7.8914e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 7.2794e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 7.6212e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 7.4967e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 9.1349e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 8.3654e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 6.8336e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 7.7324e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0010 - val_loss: 7.4169e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0010 - val_loss: 6.6925e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0010 - val_loss: 6.8517e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 9.8661e-04 - val_loss: 7.8341e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 23s 6ms/step - loss: 0.2014 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0199 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0019 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0049 - val_loss: 0.0109\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0063 - val_loss: 0.0085\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0036 - val_loss: 0.0047\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0037 - val_loss: 0.0064\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0045 - val_loss: 0.0066\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0033 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0019 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0023 - val_loss: 0.0061\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0052 - val_loss: 0.0063\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0039 - val_loss: 0.0055\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0031 - val_loss: 0.0045\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0033 - val_loss: 0.0046\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0021 - val_loss: 0.0031\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0025 - val_loss: 0.0063\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0034 - val_loss: 0.0062\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0033 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0034 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0024 - val_loss: 0.0036\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 23s 6ms/step - loss: 0.1124 - val_loss: 0.0054\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0099 - val_loss: 0.0077\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0087 - val_loss: 0.0072\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0050 - val_loss: 0.0081\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0064 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0034 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0045 - val_loss: 0.0070\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0052 - val_loss: 0.0065\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0047 - val_loss: 0.0049\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0036 - val_loss: 0.0046\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0046 - val_loss: 0.0089\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0046 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0033 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0028 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0037 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0035 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 23s 6ms/step - loss: 0.2042 - val_loss: 0.2342\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.1300 - val_loss: 0.1506\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0915 - val_loss: 0.0964\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0703 - val_loss: 0.0636\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0591 - val_loss: 0.0451\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0535 - val_loss: 0.0349\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0501 - val_loss: 0.0288\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0478 - val_loss: 0.0246\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0460 - val_loss: 0.0221\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0441 - val_loss: 0.0202\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0424 - val_loss: 0.0186\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0407 - val_loss: 0.0173\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0393 - val_loss: 0.0161\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0374 - val_loss: 0.0152\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0356 - val_loss: 0.0143\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0342 - val_loss: 0.0133\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0321 - val_loss: 0.0122\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0309 - val_loss: 0.0113\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0291 - val_loss: 0.0105\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0274 - val_loss: 0.0097\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0253 - val_loss: 0.0087\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0235 - val_loss: 0.0081\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0214 - val_loss: 0.0074\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0197 - val_loss: 0.0066\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 23s 6ms/step - loss: 0.1305 - val_loss: 0.0256\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0149 - val_loss: 0.0516\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0178 - val_loss: 0.0215\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0154 - val_loss: 0.0171\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0129 - val_loss: 0.0205\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0118 - val_loss: 0.0128\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0105 - val_loss: 0.0130\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0114 - val_loss: 0.0125\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0083 - val_loss: 0.0217\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0083 - val_loss: 0.0123\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0103 - val_loss: 0.0257\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0067 - val_loss: 0.0035\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0090 - val_loss: 0.0144\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0067 - val_loss: 0.0173\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0064 - val_loss: 0.0249\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0084 - val_loss: 0.0033\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0071 - val_loss: 0.0046\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0063 - val_loss: 0.0090\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0068 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0052 - val_loss: 0.0064\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0062 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0047 - val_loss: 0.0101\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0059 - val_loss: 0.0026\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 24s 6ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: nan - val_loss: nan\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 24s 6ms/step - loss: 0.2266 - val_loss: 0.2853\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.1574 - val_loss: 0.1891\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.1101 - val_loss: 0.1260\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0829 - val_loss: 0.0867\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0677 - val_loss: 0.0625\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0593 - val_loss: 0.0473\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0545 - val_loss: 0.0377\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0515 - val_loss: 0.0316\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0497 - val_loss: 0.0275\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0480 - val_loss: 0.0249\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0467 - val_loss: 0.0228\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0451 - val_loss: 0.0211\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0441 - val_loss: 0.0200\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0425 - val_loss: 0.0188\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0412 - val_loss: 0.0179\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0399 - val_loss: 0.0169\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0385 - val_loss: 0.0161\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0369 - val_loss: 0.0152\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0354 - val_loss: 0.0144\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0340 - val_loss: 0.0136\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0326 - val_loss: 0.0128\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0308 - val_loss: 0.0118\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0293 - val_loss: 0.0108\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0273 - val_loss: 0.0098\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 24s 6ms/step - loss: 0.2217 - val_loss: 0.2692\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.1533 - val_loss: 0.1785\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.1089 - val_loss: 0.1212\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0840 - val_loss: 0.0871\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0707 - val_loss: 0.0660\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0639 - val_loss: 0.0528\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0599 - val_loss: 0.0443\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0576 - val_loss: 0.0387\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0561 - val_loss: 0.0349\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0551 - val_loss: 0.0324\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0543 - val_loss: 0.0306\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0534 - val_loss: 0.0293\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0527 - val_loss: 0.0281\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0519 - val_loss: 0.0273\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0511 - val_loss: 0.0265\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0504 - val_loss: 0.0260\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0498 - val_loss: 0.0255\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0486 - val_loss: 0.0249\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0481 - val_loss: 0.0243\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0470 - val_loss: 0.0238\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0457 - val_loss: 0.0230\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0450 - val_loss: 0.0223\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0439 - val_loss: 0.0217\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0426 - val_loss: 0.0208\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 25s 6ms/step - loss: 0.0517 - val_loss: 0.0165\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 499us/step - loss: 0.0046 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 495us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 494us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 494us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 494us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 501us/step - loss: 0.0013 - val_loss: 9.6160e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0014 - val_loss: 9.8540e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 502us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 498us/step - loss: 0.0013 - val_loss: 8.4478e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0013 - val_loss: 7.4488e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0012 - val_loss: 8.2873e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 495us/step - loss: 0.0012 - val_loss: 9.8356e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0012 - val_loss: 7.1896e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 504us/step - loss: 0.0012 - val_loss: 7.0790e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 501us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 504us/step - loss: 0.0011 - val_loss: 6.9450e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 501us/step - loss: 0.0011 - val_loss: 7.0224e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0011 - val_loss: 7.2788e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0011 - val_loss: 7.8751e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0011 - val_loss: 6.7167e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 25s 6ms/step - loss: 0.0783 - val_loss: 0.0222\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0120 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0022 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0020 - val_loss: 9.7481e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0017 - val_loss: 9.6102e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 8.9635e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0014 - val_loss: 8.8247e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0013 - val_loss: 8.1435e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0013 - val_loss: 8.1157e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0013 - val_loss: 8.0456e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0012 - val_loss: 7.9172e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 0.0012 - val_loss: 7.9140e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 8.8045e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 8.6028e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0012 - val_loss: 7.2079e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 7.1650e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0012 - val_loss: 9.3403e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0011 - val_loss: 7.2141e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 26s 6ms/step - loss: 0.1251 - val_loss: 0.0240\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0172 - val_loss: 0.0071\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0056 - val_loss: 0.0080\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0029 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0014 - val_loss: 9.5279e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0012 - val_loss: 8.9609e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 8.8500e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 8.3782e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 26s 7ms/step - loss: 0.3729 - val_loss: 0.0604\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0280 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0076 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0046 - val_loss: 0.0031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0028 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0024 - val_loss: 9.7183e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0019 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0016 - val_loss: 9.8285e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 9.0122e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0015 - val_loss: 8.9343e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0015 - val_loss: 9.8816e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0015 - val_loss: 9.2351e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0014 - val_loss: 8.9177e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 9.1060e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0014 - val_loss: 8.3282e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0014 - val_loss: 7.9999e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 27s 7ms/step - loss: 0.5260 - val_loss: 0.0384\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0577 - val_loss: 0.0427\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0250 - val_loss: 0.0483\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0123 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0072 - val_loss: 0.0089\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0047 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0018 - val_loss: 9.2961e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0018 - val_loss: 9.1554e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0018 - val_loss: 9.9662e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0018 - val_loss: 8.8894e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0017 - val_loss: 8.1857e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 28s 7ms/step - loss: 0.7150 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0058 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0054 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0048 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0045 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0041 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0047 - val_loss: 0.0052\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0127 - val_loss: 0.0086\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0081 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0151 - val_loss: 0.0367\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0183 - val_loss: 0.0030\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0056 - val_loss: 0.0052\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0115 - val_loss: 0.0246\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0297 - val_loss: 0.1423\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.2338 - val_loss: 0.2196\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0232 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0022 - val_loss: 9.6948e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0031 - val_loss: 0.0051\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0054 - val_loss: 0.0021\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 28s 7ms/step - loss: 0.4042 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0056 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0048 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0044 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0040 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0039 - val_loss: 9.8295e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0099 - val_loss: 0.0095\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0098 - val_loss: 0.0103\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0106 - val_loss: 0.0138\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0120 - val_loss: 0.0118\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0104 - val_loss: 0.0168\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0156 - val_loss: 0.0155\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0086 - val_loss: 0.0120\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0110 - val_loss: 0.0112\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0089 - val_loss: 0.0118\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0151 - val_loss: 0.1166\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0879 - val_loss: 0.0075\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0020 - val_loss: 7.9375e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0021 - val_loss: 7.9495e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 27s 7ms/step - loss: 0.0741 - val_loss: 0.0125\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 441us/step - loss: 0.0168 - val_loss: 0.0185\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 439us/step - loss: 0.0156 - val_loss: 0.0125\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 441us/step - loss: 0.0116 - val_loss: 0.0159\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 439us/step - loss: 0.0092 - val_loss: 0.0056\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 437us/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 437us/step - loss: 0.0075 - val_loss: 0.0095\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0087 - val_loss: 0.0076\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 436us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 440us/step - loss: 0.0055 - val_loss: 0.0108\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 440us/step - loss: 0.0072 - val_loss: 0.0068\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 436us/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 441us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 436us/step - loss: 0.0043 - val_loss: 0.0044\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0061 - val_loss: 0.0031\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 439us/step - loss: 0.0058 - val_loss: 0.0064\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0070 - val_loss: 0.0033\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 439us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 437us/step - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 440us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 433us/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 28s 7ms/step - loss: 0.7649 - val_loss: 0.5750\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.1726 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 438us/step - loss: 0.0855 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 436us/step - loss: 0.0515 - val_loss: 0.0527\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0273 - val_loss: 0.0121\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0103 - val_loss: 0.0111\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0069 - val_loss: 0.0042\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 441us/step - loss: 0.0050 - val_loss: 0.0068\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 441us/step - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0032 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0030 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0029 - val_loss: 0.0027\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 437us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 437us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 433us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 438us/step - loss: 0.0025 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 436us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 436us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 433us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 29s 7ms/step - loss: 0.0547 - val_loss: 0.0064\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0061 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 0.0035 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0014 - val_loss: 8.6580e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0013 - val_loss: 8.5667e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0013 - val_loss: 9.8424e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 7.7716e-04\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0012 - val_loss: 8.2871e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0012 - val_loss: 8.1006e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0012 - val_loss: 9.2699e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0012 - val_loss: 7.3046e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 8.0987e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 7.2456e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0011 - val_loss: 8.0192e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0011 - val_loss: 7.0145e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0010 - val_loss: 7.6586e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 7.7152e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 7.5892e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 6.7303e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 28s 7ms/step - loss: 0.0640 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0097 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 500us/step - loss: 0.0047 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 495us/step - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 494us/step - loss: 0.0025 - val_loss: 0.0035\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0017 - val_loss: 9.0592e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 498us/step - loss: 0.0015 - val_loss: 9.7618e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 495us/step - loss: 0.0014 - val_loss: 9.0632e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0014 - val_loss: 8.4365e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 493us/step - loss: 0.0014 - val_loss: 9.1659e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 494us/step - loss: 0.0014 - val_loss: 9.0153e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0012 - val_loss: 7.9871e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0013 - val_loss: 8.0296e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0012 - val_loss: 9.0537e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 498us/step - loss: 0.0013 - val_loss: 8.0402e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: 0.0012 - val_loss: 8.1382e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 500us/step - loss: 0.0012 - val_loss: 7.6845e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0012 - val_loss: 7.7490e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 495us/step - loss: 0.0012 - val_loss: 7.5996e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 495us/step - loss: 0.0011 - val_loss: 8.5645e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 498us/step - loss: 0.0011 - val_loss: 7.4698e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 29s 7ms/step - loss: 0.0694 - val_loss: 0.0058\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0101 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0031 - val_loss: 0.0056\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0026 - val_loss: 8.9381e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0014 - val_loss: 9.2935e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0013 - val_loss: 9.5205e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0013 - val_loss: 7.5901e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0013 - val_loss: 8.3477e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0012 - val_loss: 8.6242e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0012 - val_loss: 9.5408e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0012 - val_loss: 7.6041e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0012 - val_loss: 7.3232e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0012 - val_loss: 7.4118e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0011 - val_loss: 8.0366e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0011 - val_loss: 7.0452e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0011 - val_loss: 7.3467e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0011 - val_loss: 7.9703e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 29s 7ms/step - loss: 0.0570 - val_loss: 0.0145\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0072 - val_loss: 0.0168\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0029 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0021 - val_loss: 8.8582e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0017 - val_loss: 7.9048e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0015 - val_loss: 8.0912e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0014 - val_loss: 7.6736e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0014 - val_loss: 7.5992e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: 0.0012 - val_loss: 8.9618e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0012 - val_loss: 7.2211e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0012 - val_loss: 7.0800e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: 0.0011 - val_loss: 7.1425e-04\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0011 - val_loss: 6.9079e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0011 - val_loss: 7.5708e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0011 - val_loss: 7.1263e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0011 - val_loss: 6.7203e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0010 - val_loss: 8.1595e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0010 - val_loss: 6.5910e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0010 - val_loss: 6.8107e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 9.9977e-04 - val_loss: 9.4598e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0010 - val_loss: 6.6773e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 34s 8ms/step - loss: 0.0590 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0093 - val_loss: 0.0101\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0064 - val_loss: 0.0077\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0027 - val_loss: 9.3013e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 433us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0019 - val_loss: 9.4859e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 433us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 433us/step - loss: 0.0014 - val_loss: 9.5575e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0014 - val_loss: 8.7899e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0013 - val_loss: 7.8375e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0013 - val_loss: 8.2842e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0012 - val_loss: 7.5006e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0013 - val_loss: 9.8906e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0013 - val_loss: 9.9224e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0012 - val_loss: 7.2215e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 433us/step - loss: 0.0012 - val_loss: 7.0236e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 34s 8ms/step - loss: 0.0698 - val_loss: 0.0057\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 440us/step - loss: 0.0103 - val_loss: 0.0081\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0066 - val_loss: 0.0094\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0028 - val_loss: 0.0027\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 436us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 436us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0018 - val_loss: 9.7767e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0018 - val_loss: 9.4012e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0017 - val_loss: 8.7574e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 436us/step - loss: 0.0017 - val_loss: 9.2546e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 437us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 437us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 437us/step - loss: 0.0015 - val_loss: 9.4005e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0014 - val_loss: 7.9688e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 433us/step - loss: 0.0015 - val_loss: 7.6485e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 31s 8ms/step - loss: 0.0516 - val_loss: 0.0175\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 481us/step - loss: 0.0100 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0052 - val_loss: 0.0106\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 481us/step - loss: 0.0043 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0025 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 482us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 482us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 476us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 479us/step - loss: 0.0017 - val_loss: 9.8915e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0016 - val_loss: 9.6124e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0016 - val_loss: 9.1278e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 481us/step - loss: 0.0015 - val_loss: 8.9168e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 479us/step - loss: 0.0015 - val_loss: 8.7418e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0014 - val_loss: 8.9870e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 481us/step - loss: 0.0014 - val_loss: 8.7271e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0014 - val_loss: 8.5892e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0013 - val_loss: 7.8530e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 477us/step - loss: 0.0014 - val_loss: 7.5151e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 31s 8ms/step - loss: 0.0754 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0106 - val_loss: 0.0084\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0069 - val_loss: 0.0096\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0032 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0027 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0024 - val_loss: 9.8473e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0017 - val_loss: 9.3012e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0016 - val_loss: 8.9424e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0016 - val_loss: 9.3768e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0016 - val_loss: 8.2886e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 33s 8ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 503us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 505us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: nan - val_loss: nan\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 33s 8ms/step - loss: 1.3785 - val_loss: 0.4147\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0552 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0057 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0062 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0045 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0036 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0035 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0032 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0031 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0030 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0028 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0028 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 34s 8ms/step - loss: 0.0569 - val_loss: 0.0148\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0096 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0048 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 8.3524e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0015 - val_loss: 9.0336e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0013 - val_loss: 9.7273e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0012 - val_loss: 8.6043e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0012 - val_loss: 8.5662e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0012 - val_loss: 7.9518e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0011 - val_loss: 8.4935e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0011 - val_loss: 7.3564e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 7.5950e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 0.0011 - val_loss: 9.3921e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0011 - val_loss: 6.8896e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0010 - val_loss: 6.8782e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 0.0010 - val_loss: 7.3067e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 9.8197e-04 - val_loss: 6.8925e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 9.9560e-04 - val_loss: 6.8066e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 33s 8ms/step - loss: 0.0611 - val_loss: 0.0313\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0120 - val_loss: 0.0054\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0051 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0022 - val_loss: 9.4568e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0014 - val_loss: 9.1527e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0014 - val_loss: 9.1522e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0013 - val_loss: 8.4176e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0012 - val_loss: 9.0532e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0013 - val_loss: 8.6870e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0013 - val_loss: 7.9494e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0012 - val_loss: 7.7987e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0012 - val_loss: 7.6002e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0012 - val_loss: 7.6130e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0012 - val_loss: 8.3016e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0012 - val_loss: 7.8939e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 34s 8ms/step - loss: 0.1476 - val_loss: 0.0596\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0182 - val_loss: 0.0188\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0080 - val_loss: 0.0061\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0058 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0032 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0022 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 35s 9ms/step - loss: 0.0968 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 345us/step - loss: 0.0048 - val_loss: 0.0246\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 341us/step - loss: 0.0110 - val_loss: 0.0103\n",
      "Epoch 5/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0122 - val_loss: 0.0093\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0077 - val_loss: 0.0159\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0089 - val_loss: 0.0151\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0083 - val_loss: 0.0134\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 365us/step - loss: 0.0081 - val_loss: 0.0073\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0063 - val_loss: 0.0109\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0080 - val_loss: 0.0068\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 341us/step - loss: 0.0053 - val_loss: 0.0127\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 362us/step - loss: 0.0080 - val_loss: 0.0066\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 371us/step - loss: 0.0053 - val_loss: 0.0072\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0053 - val_loss: 0.0104\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 346us/step - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 343us/step - loss: 0.0058 - val_loss: 0.0085\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 345us/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 345us/step - loss: 0.0040 - val_loss: 0.0086\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 346us/step - loss: 0.0046 - val_loss: 0.0084\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 342us/step - loss: 0.0032 - val_loss: 0.0092\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 34s 8ms/step - loss: 0.0847 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 362us/step - loss: 0.0038 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0103 - val_loss: 0.0085\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0065 - val_loss: 0.0162\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 346us/step - loss: 0.0104 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0092 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 382us/step - loss: 0.0085 - val_loss: 0.0072\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 355us/step - loss: 0.0076 - val_loss: 0.0064\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0090 - val_loss: 0.0067\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0053 - val_loss: 0.0058\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0095 - val_loss: 0.0152\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.0061 - val_loss: 0.0054\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 345us/step - loss: 0.0058 - val_loss: 0.0103\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 345us/step - loss: 0.0073 - val_loss: 9.7328e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 341us/step - loss: 0.0037 - val_loss: 0.0173\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0066 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 346us/step - loss: 0.0049 - val_loss: 0.0081\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 341us/step - loss: 0.0053 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 346us/step - loss: 0.0041 - val_loss: 0.0100\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0056 - val_loss: 7.8711e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 370us/step - loss: 0.0037 - val_loss: 0.0099\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 35s 9ms/step - loss: 0.1929 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0065 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0071 - val_loss: 0.0090\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0130 - val_loss: 0.0131\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0105 - val_loss: 0.0327\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0138 - val_loss: 0.0064\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0158 - val_loss: 0.0281\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 346us/step - loss: 0.0114 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0063 - val_loss: 0.0199\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 343us/step - loss: 0.0181 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 345us/step - loss: 0.0048 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0112 - val_loss: 0.0146\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 341us/step - loss: 0.0076 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0089 - val_loss: 0.0113\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0075 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 342us/step - loss: 0.0083 - val_loss: 0.0182\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 342us/step - loss: 0.0081 - val_loss: 8.3916e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 341us/step - loss: 0.0049 - val_loss: 0.0164\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0074 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 342us/step - loss: 0.0072 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 345us/step - loss: 0.0065 - val_loss: 0.0073\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 342us/step - loss: 0.0056 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 345us/step - loss: 0.0059 - val_loss: 0.0027\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 35s 9ms/step - loss: 0.6269 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0084 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0064 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 341us/step - loss: 0.0196 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 343us/step - loss: 0.0069 - val_loss: 0.0122\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0233 - val_loss: 0.0036\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0111 - val_loss: 0.0404\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0278 - val_loss: 0.0162\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0132 - val_loss: 0.0019\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 342us/step - loss: 0.0120 - val_loss: 0.0202\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0277 - val_loss: 0.0192\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0063 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 343us/step - loss: 0.0113 - val_loss: 0.0135\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0114 - val_loss: 0.0038\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0132 - val_loss: 0.0279\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0116 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0089 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0086 - val_loss: 0.0068\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 343us/step - loss: 0.0088 - val_loss: 0.0148\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0127 - val_loss: 9.5395e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0059 - val_loss: 0.0036\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0073 - val_loss: 0.0070\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0088 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0058 - val_loss: 0.0156\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 36s 9ms/step - loss: 0.5887 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 345us/step - loss: 0.0095 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0063 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0188 - val_loss: 0.0120\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0068 - val_loss: 0.0125\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0207 - val_loss: 0.0144\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0146 - val_loss: 0.0234\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0424 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 353us/step - loss: 0.0121 - val_loss: 0.0516\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0084 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0134 - val_loss: 0.0132\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 350us/step - loss: 0.0162 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 348us/step - loss: 0.0092 - val_loss: 0.0092\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0185 - val_loss: 0.0136\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0086 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 347us/step - loss: 0.0110 - val_loss: 0.0051\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 343us/step - loss: 0.0096 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0101 - val_loss: 0.0076\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 344us/step - loss: 0.0109 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0068 - val_loss: 0.0074\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0087 - val_loss: 0.0054\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0064 - val_loss: 0.0088\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 343us/step - loss: 0.0113 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0040 - val_loss: 0.0100\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 38s 9ms/step - loss: 0.2806 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 0.0139 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0061 - val_loss: 0.0236\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0142 - val_loss: 0.0049\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0165 - val_loss: 0.0087\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0127 - val_loss: 0.0148\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0129 - val_loss: 0.0390\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0278 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0043 - val_loss: 0.0091\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0106 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0103 - val_loss: 0.0353\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0213 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0026 - val_loss: 0.0124\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0101 - val_loss: 0.0042\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0067 - val_loss: 0.0092\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0133 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0021 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0103 - val_loss: 0.0146\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0065 - val_loss: 8.5009e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0057 - val_loss: 0.0050\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0088 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0094 - val_loss: 0.0165\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 38s 9ms/step - loss: 0.0524 - val_loss: 0.0132\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0065 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0037 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0028 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0021 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0013 - val_loss: 8.4317e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 7.6726e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0013 - val_loss: 9.4596e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0012 - val_loss: 8.0212e-04\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 7.4103e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0012 - val_loss: 7.2339e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 7.5339e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 7.2344e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0011 - val_loss: 8.3925e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0011 - val_loss: 7.4018e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0010 - val_loss: 6.9482e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0010 - val_loss: 6.9398e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 9.9461e-04 - val_loss: 7.6016e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 9.6304e-04 - val_loss: 6.7350e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 38s 9ms/step - loss: 0.9497 - val_loss: 0.7749\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.3716 - val_loss: 0.3212\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.1484 - val_loss: 0.1298\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0786 - val_loss: 0.0538\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0665 - val_loss: 0.0276\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0681 - val_loss: 0.0213\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0688 - val_loss: 0.0233\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0675 - val_loss: 0.0291\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0663 - val_loss: 0.0351\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0659 - val_loss: 0.0396\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0659 - val_loss: 0.0412\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0659 - val_loss: 0.0411\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0659 - val_loss: 0.0403\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0659 - val_loss: 0.0391\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0659 - val_loss: 0.0382\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0659 - val_loss: 0.0381\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0659 - val_loss: 0.0386\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0659 - val_loss: 0.0386\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0659 - val_loss: 0.0390\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 38s 9ms/step - loss: 0.4244 - val_loss: 0.3182\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.1305 - val_loss: 0.0790\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0687 - val_loss: 0.0187\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0739 - val_loss: 0.0117\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0736 - val_loss: 0.0192\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0675 - val_loss: 0.0342\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0661 - val_loss: 0.0464\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0664 - val_loss: 0.0474\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0662 - val_loss: 0.0421\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0659 - val_loss: 0.0376\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0659 - val_loss: 0.0363\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0659 - val_loss: 0.0379\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0659 - val_loss: 0.0391\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0659 - val_loss: 0.0396\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0659 - val_loss: 0.0383\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0659 - val_loss: 0.0384\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0659 - val_loss: 0.0382\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0659 - val_loss: 0.0384\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0659 - val_loss: 0.0393\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 39s 10ms/step - loss: 0.9504 - val_loss: 0.3751\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.1450 - val_loss: 0.1025\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 441us/step - loss: 0.0731 - val_loss: 0.0544\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0665 - val_loss: 0.0427\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0659 - val_loss: 0.0408\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0659 - val_loss: 0.0390\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0659 - val_loss: 0.0393\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0659 - val_loss: 0.0386\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0659 - val_loss: 0.0392\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0659 - val_loss: 0.0394\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0659 - val_loss: 0.0391\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0659 - val_loss: 0.0395\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0659 - val_loss: 0.0392\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0659 - val_loss: 0.0392\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0658 - val_loss: 0.0390\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0659 - val_loss: 0.0383\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0658 - val_loss: 0.0383\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0659 - val_loss: 0.0380\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0658 - val_loss: 0.0386\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 39s 10ms/step - loss: 0.1599 - val_loss: 0.0975\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0719 - val_loss: 0.0511\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0666 - val_loss: 0.0417\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0662 - val_loss: 0.0399\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0662 - val_loss: 0.0394\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0662 - val_loss: 0.0384\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0662 - val_loss: 0.0383\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0662 - val_loss: 0.0386\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0662 - val_loss: 0.0387\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0662 - val_loss: 0.0392\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0662 - val_loss: 0.0389\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0662 - val_loss: 0.0391\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0662 - val_loss: 0.0383\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0662 - val_loss: 0.0389\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0661 - val_loss: 0.0383\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0661 - val_loss: 0.0386\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0661 - val_loss: 0.0390\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0661 - val_loss: 0.0388\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0661 - val_loss: 0.0387\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0661 - val_loss: 0.0391\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0661 - val_loss: 0.0391\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0661 - val_loss: 0.0393\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0661 - val_loss: 0.0396\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0661 - val_loss: 0.0384\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 40s 10ms/step - loss: 0.0668 - val_loss: 0.0208\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 433us/step - loss: 0.0158 - val_loss: 0.0142\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0066 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0046 - val_loss: 0.0065\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0025 - val_loss: 0.0038\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 440us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 433us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 427us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 40s 10ms/step - loss: 0.0492 - val_loss: 0.0206\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0105 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0047 - val_loss: 0.0084\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0040 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0030 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0015 - val_loss: 9.2358e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0015 - val_loss: 9.9037e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0013 - val_loss: 8.8109e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0013 - val_loss: 9.9254e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0013 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0013 - val_loss: 8.4201e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 42s 10ms/step - loss: 0.1187 - val_loss: 0.0306\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0507 - val_loss: 0.0204\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0419 - val_loss: 0.0162\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0354 - val_loss: 0.0139\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0296 - val_loss: 0.0118\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 542us/step - loss: 0.0247 - val_loss: 0.0089\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 0.0201 - val_loss: 0.0068\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0166 - val_loss: 0.0052\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0138 - val_loss: 0.0039\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0115 - val_loss: 0.0030\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0094 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0082 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0071 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0063 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0054 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0050 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0050 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0049 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0044 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0044 - val_loss: 0.0031\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 42s 10ms/step - loss: 0.0718 - val_loss: 0.0115\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0112 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0050 - val_loss: 9.5312e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0034 - val_loss: 0.0060\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0027 - val_loss: 8.8998e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0019 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0014 - val_loss: 8.8202e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0013 - val_loss: 8.3503e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0013 - val_loss: 8.0616e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 8.1969e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 9.6072e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 9.4090e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0012 - val_loss: 8.0134e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 0.0012 - val_loss: 7.0422e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0011 - val_loss: 7.0599e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 7.7925e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0011 - val_loss: 8.0231e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0010 - val_loss: 6.7693e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0010 - val_loss: 7.9452e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0011 - val_loss: 7.4050e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 0.0011 - val_loss: 6.6560e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 42s 10ms/step - loss: 0.0809 - val_loss: 0.0046\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0099 - val_loss: 0.0068\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0032 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0026 - val_loss: 9.2676e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0014 - val_loss: 8.2913e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0013 - val_loss: 8.1996e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0013 - val_loss: 8.6166e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0012 - val_loss: 7.6820e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0012 - val_loss: 7.4219e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0012 - val_loss: 7.8597e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 0.0012 - val_loss: 8.9911e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0011 - val_loss: 8.0312e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0011 - val_loss: 8.0396e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0011 - val_loss: 7.2293e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0011 - val_loss: 7.5349e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0011 - val_loss: 9.6684e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0011 - val_loss: 8.4102e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0011 - val_loss: 7.6180e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0011 - val_loss: 7.6774e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 42s 10ms/step - loss: 0.6671 - val_loss: 0.5662\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.2611 - val_loss: 0.2212\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.1043 - val_loss: 0.0774\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0678 - val_loss: 0.0291\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0686 - val_loss: 0.0178\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 607us/step - loss: 0.0707 - val_loss: 0.0193\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0686 - val_loss: 0.0272\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0665 - val_loss: 0.0361\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0660 - val_loss: 0.0420\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 0.0660 - val_loss: 0.0431\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 0.0660 - val_loss: 0.0413\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0659 - val_loss: 0.0392\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0659 - val_loss: 0.0381\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0659 - val_loss: 0.0382\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 0.0659 - val_loss: 0.0382\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0659 - val_loss: 0.0384\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0659 - val_loss: 0.0386\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 0.0659 - val_loss: 0.0398\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0659 - val_loss: 0.0384\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 43s 11ms/step - loss: 1.0984 - val_loss: 1.0039\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.5465 - val_loss: 0.5298\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.2673 - val_loss: 0.2706\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.1338 - val_loss: 0.1316\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0811 - val_loss: 0.0640\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0672 - val_loss: 0.0359\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0666 - val_loss: 0.0267\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0674 - val_loss: 0.0261\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0671 - val_loss: 0.0295\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0664 - val_loss: 0.0338\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0660 - val_loss: 0.0377\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0659 - val_loss: 0.0398\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0659 - val_loss: 0.0403\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0659 - val_loss: 0.0398\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0659 - val_loss: 0.0393\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0659 - val_loss: 0.0391\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0659 - val_loss: 0.0384\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0659 - val_loss: 0.0391\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0659 - val_loss: 0.0385\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0659 - val_loss: 0.0385\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0659 - val_loss: 0.0385\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 45s 11ms/step - loss: 0.0692 - val_loss: 0.0580\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0660 - val_loss: 0.0264\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0595 - val_loss: 0.0329\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0465 - val_loss: 0.0118\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0382 - val_loss: 0.0830\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0686 - val_loss: 0.0208\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0675 - val_loss: 0.0440\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 565us/step - loss: 0.0671 - val_loss: 0.0439\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0663 - val_loss: 0.0304\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0652 - val_loss: 0.0435\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0600 - val_loss: 0.0113\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0313 - val_loss: 0.0108\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0751 - val_loss: 0.0457\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0705 - val_loss: 0.0376\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0689 - val_loss: 0.0111\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0768 - val_loss: 0.0998\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0516 - val_loss: 0.0141\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0266 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0155 - val_loss: 0.0092\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0109 - val_loss: 0.0069\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0071 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0055 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0040 - val_loss: 0.0021\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 43s 11ms/step - loss: 0.4961 - val_loss: 0.0894\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.2058 - val_loss: 0.0070\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0932 - val_loss: 0.0165\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0674 - val_loss: 0.0472\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0678 - val_loss: 0.0639\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0694 - val_loss: 0.0616\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0679 - val_loss: 0.0511\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0664 - val_loss: 0.0411\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0659 - val_loss: 0.0362\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0660 - val_loss: 0.0351\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0660 - val_loss: 0.0368\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0659 - val_loss: 0.0381\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0659 - val_loss: 0.0396\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0659 - val_loss: 0.0400\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0659 - val_loss: 0.0386\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0659 - val_loss: 0.0382\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0659 - val_loss: 0.0383\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0659 - val_loss: 0.0392\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0659 - val_loss: 0.0390\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0659 - val_loss: 0.0386\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0659 - val_loss: 0.0386\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 44s 11ms/step - loss: 0.6375 - val_loss: 0.4753\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.2139 - val_loss: 0.1817\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0938 - val_loss: 0.0753\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0681 - val_loss: 0.0383\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0664 - val_loss: 0.0270\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0674 - val_loss: 0.0253\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0673 - val_loss: 0.0278\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0667 - val_loss: 0.0314\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0662 - val_loss: 0.0350\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0659 - val_loss: 0.0376\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0659 - val_loss: 0.0395\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0659 - val_loss: 0.0396\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0659 - val_loss: 0.0395\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0659 - val_loss: 0.0393\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0659 - val_loss: 0.0390\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 44s 11ms/step - loss: 0.1352 - val_loss: 0.0055\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 407us/step - loss: 0.0238 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0112 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 413us/step - loss: 0.0072 - val_loss: 0.0035\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 413us/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0037 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0035 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0035 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0032 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0030 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0029 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 407us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 407us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 46s 11ms/step - loss: 0.1079 - val_loss: 0.0068\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0138 - val_loss: 0.0089\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0170 - val_loss: 0.0060\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0147 - val_loss: 0.0073\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0140 - val_loss: 0.0074\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0124 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 540us/step - loss: 0.0121 - val_loss: 0.0067\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0098 - val_loss: 0.0114\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0112 - val_loss: 0.0086\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0126 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0080 - val_loss: 0.0053\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0092 - val_loss: 0.0066\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0083 - val_loss: 0.0080\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0085 - val_loss: 0.0061\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0074 - val_loss: 0.0058\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0085 - val_loss: 0.0072\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0066 - val_loss: 0.0061\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0078 - val_loss: 0.0055\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0062 - val_loss: 0.0034\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0063 - val_loss: 0.0095\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0067 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0060 - val_loss: 0.0049\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0055 - val_loss: 0.0059\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 45s 11ms/step - loss: 0.0784 - val_loss: 0.0396\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0131 - val_loss: 0.0118\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0020 - val_loss: 8.8737e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0015 - val_loss: 9.7763e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0013 - val_loss: 7.8818e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0013 - val_loss: 7.5373e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0013 - val_loss: 7.4489e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0012 - val_loss: 7.4982e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0013 - val_loss: 7.5518e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0013 - val_loss: 8.0801e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0012 - val_loss: 7.4801e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0012 - val_loss: 8.4415e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0012 - val_loss: 7.8155e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0012 - val_loss: 7.0587e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0012 - val_loss: 6.9862e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 49s 12ms/step - loss: 0.0615 - val_loss: 0.0215\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0096 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0033 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0017 - val_loss: 9.0319e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0013 - val_loss: 9.2651e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0013 - val_loss: 8.2389e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0012 - val_loss: 7.4776e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 7.3454e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 7.8468e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0012 - val_loss: 7.6599e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0011 - val_loss: 7.0907e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0011 - val_loss: 7.4689e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 6.9504e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0010 - val_loss: 7.2351e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0010 - val_loss: 6.9193e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0010 - val_loss: 6.9786e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 47s 12ms/step - loss: 0.1122 - val_loss: 0.0093\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0155 - val_loss: 0.0092\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0081 - val_loss: 0.0044\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0039 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0014 - val_loss: 9.4689e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 9.7038e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 48s 12ms/step - loss: 0.1096 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0156 - val_loss: 0.0117\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0084 - val_loss: 0.0102\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0042 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0032 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 49s 12ms/step - loss: 0.0396 - val_loss: 0.0118\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0020 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0016 - val_loss: 8.9639e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0015 - val_loss: 9.3513e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0016 - val_loss: 9.2781e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0015 - val_loss: 8.9565e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0015 - val_loss: 9.4002e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0015 - val_loss: 9.8603e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0015 - val_loss: 9.1746e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0015 - val_loss: 8.4732e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 49s 12ms/step - loss: 0.1249 - val_loss: 0.0202\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0128 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0074 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0042 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0028 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 413us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 413us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 50s 12ms/step - loss: 0.0727 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0192 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0027 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0021 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0127 - val_loss: 0.0064\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 413us/step - loss: 0.0045 - val_loss: 0.0054\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0046 - val_loss: 0.0110\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0044 - val_loss: 0.0075\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0059 - val_loss: 0.0120\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0036 - val_loss: 0.0110\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 413us/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 413us/step - loss: 0.0030 - val_loss: 0.0042\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0026 - val_loss: 0.0059\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 413us/step - loss: 0.0049 - val_loss: 0.0094\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0050 - val_loss: 0.0066\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0041 - val_loss: 0.0057\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0033 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0027 - val_loss: 0.0067\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0034 - val_loss: 0.0043\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0029 - val_loss: 0.0044\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0037 - val_loss: 0.0056\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0019 - val_loss: 0.0041\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 51s 13ms/step - loss: 0.1381 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 0.0063 - val_loss: 0.0964\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 0.0115 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 0.0018 - val_loss: 9.7595e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 0.0031 - val_loss: 0.0081\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 0.0069 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 0.0022 - val_loss: 8.9099e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 0.0088 - val_loss: 0.0054\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 0.0036 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 0.0043 - val_loss: 0.0046\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 0.0043 - val_loss: 0.0052\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 0.0033 - val_loss: 9.5738e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 606us/step - loss: 0.0015 - val_loss: 7.5969e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 0.0012 - val_loss: 7.8643e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 606us/step - loss: 0.0012 - val_loss: 7.2060e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 0.0026 - val_loss: 0.0091\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 0.0068 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0030 - val_loss: 0.0010\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 50s 12ms/step - loss: 3.7874 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0057 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0037 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0036 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0035 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0032 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0032 - val_loss: 0.0025\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0030 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0030 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0028 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0027 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 52s 13ms/step - loss: 0.0788 - val_loss: 0.0047\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0114 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0057 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0040 - val_loss: 0.0057\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0023 - val_loss: 9.5067e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0014 - val_loss: 7.7550e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0014 - val_loss: 9.8866e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0013 - val_loss: 8.3488e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0013 - val_loss: 8.0985e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0013 - val_loss: 9.8745e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0012 - val_loss: 7.5563e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0012 - val_loss: 8.2981e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0012 - val_loss: 8.7467e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0012 - val_loss: 7.4351e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 52s 13ms/step - loss: 0.0720 - val_loss: 0.0308\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0114 - val_loss: 0.0023\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0047 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0027 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0024 - val_loss: 0.0040\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0017 - val_loss: 9.2765e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0014 - val_loss: 9.6356e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 9.9706e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 9.2763e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0012 - val_loss: 9.2088e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 8.1796e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0012 - val_loss: 8.7065e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 7.5199e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0012 - val_loss: 7.5241e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 7.6219e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 7.2741e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 7.0772e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 7.8037e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 53s 13ms/step - loss: 0.0595 - val_loss: 0.0092\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0080 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0016 - val_loss: 8.8404e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0014 - val_loss: 9.4233e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0013 - val_loss: 9.0039e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0013 - val_loss: 8.2156e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0013 - val_loss: 7.8802e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0013 - val_loss: 7.8146e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0013 - val_loss: 8.8894e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 7.9504e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0012 - val_loss: 8.3181e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0012 - val_loss: 8.9867e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0012 - val_loss: 7.2517e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 7.1825e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 7.7022e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 7.7316e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0011 - val_loss: 6.9329e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 52s 13ms/step - loss: 0.0524 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0072 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0043 - val_loss: 0.0014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0028 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0018 - val_loss: 8.7011e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0013 - val_loss: 8.7304e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0013 - val_loss: 8.1520e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0012 - val_loss: 8.1362e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 8.1218e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 7.6768e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 8.6525e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 7.1638e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 7.0837e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0011 - val_loss: 7.7303e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 8.9860e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0010 - val_loss: 6.8866e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0010 - val_loss: 6.8078e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0010 - val_loss: 7.4682e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0010 - val_loss: 7.3890e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0011 - val_loss: 6.6359e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 53s 13ms/step - loss: 0.0719 - val_loss: 0.0174\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0100 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0057 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0032 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0020 - val_loss: 8.7721e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0017 - val_loss: 9.7434e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0016 - val_loss: 9.1119e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0014 - val_loss: 9.5946e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0014 - val_loss: 8.3829e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0014 - val_loss: 8.6712e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0013 - val_loss: 8.7959e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0013 - val_loss: 8.1537e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0013 - val_loss: 7.8936e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 9.2594e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 7.2127e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0013 - val_loss: 7.2488e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0012 - val_loss: 7.1155e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0012 - val_loss: 7.1931e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0011 - val_loss: 7.8726e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 8.5144e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0011 - val_loss: 8.2636e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 54s 13ms/step - loss: 0.0492 - val_loss: 0.0137\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0078 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0040 - val_loss: 0.0078\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0029 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0022 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0017 - val_loss: 9.0530e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0013 - val_loss: 9.6445e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0013 - val_loss: 8.3703e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0013 - val_loss: 8.2475e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0012 - val_loss: 7.7992e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 0.0012 - val_loss: 8.5282e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0012 - val_loss: 9.7881e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0012 - val_loss: 8.3080e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0011 - val_loss: 7.4694e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0011 - val_loss: 7.4810e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0011 - val_loss: 7.5131e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 7.2155e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 610us/step - loss: 0.0011 - val_loss: 7.1957e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 0.0011 - val_loss: 7.2278e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0011 - val_loss: 8.0380e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 55s 14ms/step - loss: 0.0632 - val_loss: 0.0233\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0112 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0061 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0038 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0027 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0012 - val_loss: 9.5796e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0011 - val_loss: 8.8506e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 8.3205e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0010 - val_loss: 8.3342e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 9.6479e-04 - val_loss: 8.7976e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 9.9738e-04 - val_loss: 8.2270e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 9.8180e-04 - val_loss: 9.1200e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 9.3573e-04 - val_loss: 7.4584e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 9.7287e-04 - val_loss: 7.8854e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 55s 14ms/step - loss: 0.0658 - val_loss: 0.0015\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0094 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0048 - val_loss: 9.7725e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0037 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 0.0027 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 9.6018e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0012 - val_loss: 9.9507e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0011 - val_loss: 8.4882e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0011 - val_loss: 8.8642e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 0.0011 - val_loss: 8.4325e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0011 - val_loss: 8.4635e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0011 - val_loss: 9.9917e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0011 - val_loss: 9.3210e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0010 - val_loss: 8.9756e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0011 - val_loss: 7.8218e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0010 - val_loss: 8.8236e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0010 - val_loss: 7.2995e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0010 - val_loss: 8.3060e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 56s 14ms/step - loss: 0.0654 - val_loss: 0.0204\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0111 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 542us/step - loss: 0.0062 - val_loss: 0.0137\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 543us/step - loss: 0.0023 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 0.0018 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 540us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0012 - val_loss: 8.0291e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0012 - val_loss: 8.2172e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0012 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0012 - val_loss: 7.6240e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0011 - val_loss: 8.7137e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 543us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 542us/step - loss: 0.0010 - val_loss: 7.6083e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 9.9650e-04 - val_loss: 0.0010\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.013227377086877823,\n",
       " 0.007363521493971348,\n",
       " 0.006701738107949495,\n",
       " 0.003694563638418913,\n",
       " 0.002590484917163849,\n",
       " 0.0015512638492509723,\n",
       " 0.0012072541285306215,\n",
       " 0.0012590375263243914,\n",
       " 0.0011046809377148747,\n",
       " 0.0008431740570813417,\n",
       " 0.0007672550855204463,\n",
       " 0.0009459569118916988,\n",
       " 0.0008021177491173148,\n",
       " 0.0007410324178636074,\n",
       " 0.0011878845980390906,\n",
       " 0.0007233860669657588,\n",
       " 0.0007533943862654269,\n",
       " 0.0007234434597194195,\n",
       " 0.0008392457384616137,\n",
       " 0.0007401793263852596,\n",
       " 0.0006948179798200727,\n",
       " 0.0006939750164747238,\n",
       " 0.00076015864033252,\n",
       " 0.0006735030910931528]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "density: 238\n",
      "twice: True\n",
      "optimizer: adam\n",
      "dropout: 0.1\n",
      "activation: elu\n",
      "full_density: True\n",
      "shuffle: True\n",
      "lstmsize: 176\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_147\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_293 (LSTM)              (None, 92, 176)           128128    \n",
      "_________________________________________________________________\n",
      "dropout_293 (Dropout)        (None, 92, 176)           0         \n",
      "_________________________________________________________________\n",
      "lstm_294 (LSTM)              (None, 176)               248512    \n",
      "_________________________________________________________________\n",
      "dropout_294 (Dropout)        (None, 176)               0         \n",
      "_________________________________________________________________\n",
      "dense_755 (Dense)            (None, 238)               42126     \n",
      "_________________________________________________________________\n",
      "dense_756 (Dense)            (None, 119)               28441     \n",
      "_________________________________________________________________\n",
      "dense_757 (Dense)            (None, 59)                7080      \n",
      "_________________________________________________________________\n",
      "dense_758 (Dense)            (None, 29)                1740      \n",
      "_________________________________________________________________\n",
      "dense_759 (Dense)            (None, 14)                420       \n",
      "_________________________________________________________________\n",
      "dense_760 (Dense)            (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 456,462\n",
      "Trainable params: 456,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/2000\n",
      "4059/4059 [==============================] - 58s 14ms/step - loss: 0.0518 - val_loss: 0.0168\n",
      "Epoch 2/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 0.0074 - val_loss: 0.0145\n",
      "Epoch 3/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0040 - val_loss: 0.0064\n",
      "Epoch 4/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 5/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 0.0021 - val_loss: 8.4252e-04\n",
      "Epoch 6/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0017 - val_loss: 8.5756e-04\n",
      "Epoch 7/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0016 - val_loss: 9.0598e-04\n",
      "Epoch 8/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 0.0015 - val_loss: 9.3380e-04\n",
      "Epoch 9/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 10/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0013 - val_loss: 8.1422e-04\n",
      "Epoch 11/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0013 - val_loss: 7.3817e-04\n",
      "Epoch 12/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0012 - val_loss: 8.3908e-04\n",
      "Epoch 13/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0012 - val_loss: 7.7968e-04\n",
      "Epoch 14/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0011 - val_loss: 7.4083e-04\n",
      "Epoch 15/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0011 - val_loss: 7.9477e-04\n",
      "Epoch 16/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 0.0011 - val_loss: 7.2068e-04\n",
      "Epoch 17/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 0.0011 - val_loss: 6.9992e-04\n",
      "Epoch 18/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0011 - val_loss: 6.9212e-04\n",
      "Epoch 19/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 0.0010 - val_loss: 7.4745e-04\n",
      "Epoch 20/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 0.0010 - val_loss: 6.6624e-04\n",
      "Epoch 21/2000\n",
      "4059/4059 [==============================] - 2s 607us/step - loss: 0.0010 - val_loss: 6.6437e-04\n",
      "Epoch 22/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 0.0010 - val_loss: 7.7541e-04\n",
      "Epoch 23/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 9.9827e-04 - val_loss: 6.4830e-04\n",
      "Epoch 24/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 9.7946e-04 - val_loss: 6.7198e-04\n",
      "Epoch 25/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 9.9347e-04 - val_loss: 7.5322e-04\n",
      "Epoch 26/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 9.5871e-04 - val_loss: 6.8489e-04\n",
      "Epoch 27/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 9.4108e-04 - val_loss: 6.3576e-04\n",
      "Epoch 28/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 9.0043e-04 - val_loss: 6.4775e-04\n",
      "Epoch 29/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 8.9909e-04 - val_loss: 6.4558e-04\n",
      "Epoch 30/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 9.1973e-04 - val_loss: 6.3128e-04\n",
      "Epoch 31/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 8.7203e-04 - val_loss: 6.0560e-04\n",
      "Epoch 32/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 8.8397e-04 - val_loss: 6.0660e-04\n",
      "Epoch 33/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 8.6961e-04 - val_loss: 7.8332e-04\n",
      "Epoch 34/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 9.0754e-04 - val_loss: 7.4851e-04\n",
      "Epoch 35/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 9.0509e-04 - val_loss: 7.6314e-04\n",
      "Epoch 36/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 8.7869e-04 - val_loss: 6.1868e-04\n",
      "Epoch 37/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 8.6253e-04 - val_loss: 5.7999e-04\n",
      "Epoch 38/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 8.0976e-04 - val_loss: 7.3983e-04\n",
      "Epoch 39/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 9.0078e-04 - val_loss: 5.9581e-04\n",
      "Epoch 40/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 8.3103e-04 - val_loss: 6.2860e-04\n",
      "Epoch 41/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 7.8318e-04 - val_loss: 6.1650e-04\n",
      "Epoch 42/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 7.9664e-04 - val_loss: 6.5121e-04\n",
      "Epoch 43/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 7.9875e-04 - val_loss: 8.2538e-04\n",
      "Epoch 44/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 7.8356e-04 - val_loss: 5.5095e-04\n",
      "Epoch 45/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 7.7946e-04 - val_loss: 6.3803e-04\n",
      "Epoch 46/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 7.7441e-04 - val_loss: 8.3706e-04\n",
      "Epoch 47/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 7.7771e-04 - val_loss: 6.2063e-04\n",
      "Epoch 48/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 7.4412e-04 - val_loss: 6.1914e-04\n",
      "Epoch 49/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 7.6211e-04 - val_loss: 5.6250e-04\n",
      "Epoch 50/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 8.4380e-04 - val_loss: 5.7069e-04\n",
      "Epoch 51/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 8.7005e-04 - val_loss: 5.3338e-04\n",
      "Epoch 52/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 7.7776e-04 - val_loss: 5.3134e-04\n",
      "Epoch 53/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 7.2793e-04 - val_loss: 5.2270e-04\n",
      "Epoch 54/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 7.3880e-04 - val_loss: 5.3146e-04\n",
      "Epoch 55/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 7.6452e-04 - val_loss: 5.1953e-04\n",
      "Epoch 56/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 8.2247e-04 - val_loss: 5.3337e-04\n",
      "Epoch 57/2000\n",
      "4059/4059 [==============================] - 2s 607us/step - loss: 7.6424e-04 - val_loss: 5.2045e-04\n",
      "Epoch 58/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 7.0071e-04 - val_loss: 5.7874e-04\n",
      "Epoch 59/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 6.9139e-04 - val_loss: 5.2300e-04\n",
      "Epoch 60/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 7.0114e-04 - val_loss: 6.4331e-04\n",
      "Epoch 61/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 6.9156e-04 - val_loss: 5.7721e-04\n",
      "Epoch 62/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 7.4140e-04 - val_loss: 5.6054e-04\n",
      "Epoch 63/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 7.6389e-04 - val_loss: 4.9735e-04\n",
      "Epoch 64/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 7.2965e-04 - val_loss: 5.0100e-04\n",
      "Epoch 65/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 7.0150e-04 - val_loss: 5.1415e-04\n",
      "Epoch 66/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 6.6591e-04 - val_loss: 4.9704e-04\n",
      "Epoch 67/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 6.5388e-04 - val_loss: 4.9288e-04\n",
      "Epoch 68/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 6.7889e-04 - val_loss: 5.0343e-04\n",
      "Epoch 69/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 6.9309e-04 - val_loss: 8.3895e-04\n",
      "Epoch 70/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 7.5563e-04 - val_loss: 5.4716e-04\n",
      "Epoch 71/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 6.6476e-04 - val_loss: 4.8258e-04\n",
      "Epoch 72/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 6.5515e-04 - val_loss: 4.7694e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 6.5430e-04 - val_loss: 4.8902e-04\n",
      "Epoch 74/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 6.4437e-04 - val_loss: 4.9532e-04\n",
      "Epoch 75/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 6.3573e-04 - val_loss: 5.1657e-04\n",
      "Epoch 76/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 6.3423e-04 - val_loss: 6.8315e-04\n",
      "Epoch 77/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 6.4113e-04 - val_loss: 4.6870e-04\n",
      "Epoch 78/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 6.4582e-04 - val_loss: 7.0944e-04\n",
      "Epoch 79/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 6.7559e-04 - val_loss: 4.7165e-04\n",
      "Epoch 80/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 6.4249e-04 - val_loss: 4.8498e-04\n",
      "Epoch 81/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 6.6100e-04 - val_loss: 6.6357e-04\n",
      "Epoch 82/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 6.2361e-04 - val_loss: 7.1850e-04\n",
      "Epoch 83/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 6.7057e-04 - val_loss: 4.7750e-04\n",
      "Epoch 84/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 6.5357e-04 - val_loss: 4.5569e-04\n",
      "Epoch 85/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.8981e-04 - val_loss: 4.8009e-04\n",
      "Epoch 86/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 6.2981e-04 - val_loss: 5.9405e-04\n",
      "Epoch 87/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.9972e-04 - val_loss: 4.5162e-04\n",
      "Epoch 88/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 6.1239e-04 - val_loss: 4.5377e-04\n",
      "Epoch 89/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 6.8043e-04 - val_loss: 9.6660e-04\n",
      "Epoch 90/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 6.6309e-04 - val_loss: 4.8355e-04\n",
      "Epoch 91/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 6.0622e-04 - val_loss: 4.5852e-04\n",
      "Epoch 92/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 6.1434e-04 - val_loss: 4.5709e-04\n",
      "Epoch 93/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.8380e-04 - val_loss: 5.0665e-04\n",
      "Epoch 94/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 5.8132e-04 - val_loss: 6.5892e-04\n",
      "Epoch 95/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 6.0912e-04 - val_loss: 4.4084e-04\n",
      "Epoch 96/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.7884e-04 - val_loss: 4.4693e-04\n",
      "Epoch 97/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 6.3683e-04 - val_loss: 5.2712e-04\n",
      "Epoch 98/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.8545e-04 - val_loss: 4.8579e-04\n",
      "Epoch 99/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 5.6585e-04 - val_loss: 4.8952e-04\n",
      "Epoch 100/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.6927e-04 - val_loss: 5.1954e-04\n",
      "Epoch 101/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 5.9117e-04 - val_loss: 5.0026e-04\n",
      "Epoch 102/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 5.7089e-04 - val_loss: 4.4420e-04\n",
      "Epoch 103/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 5.7742e-04 - val_loss: 8.0902e-04\n",
      "Epoch 104/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 6.1498e-04 - val_loss: 4.8099e-04\n",
      "Epoch 105/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 6.0641e-04 - val_loss: 4.3076e-04\n",
      "Epoch 106/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 5.7389e-04 - val_loss: 4.2621e-04\n",
      "Epoch 107/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 5.5684e-04 - val_loss: 4.5060e-04\n",
      "Epoch 108/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 5.3787e-04 - val_loss: 5.9610e-04\n",
      "Epoch 109/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.8654e-04 - val_loss: 4.1378e-04\n",
      "Epoch 110/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 5.7727e-04 - val_loss: 5.6468e-04\n",
      "Epoch 111/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 7.0363e-04 - val_loss: 4.1266e-04\n",
      "Epoch 112/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 6.2905e-04 - val_loss: 6.0175e-04\n",
      "Epoch 113/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 5.9463e-04 - val_loss: 6.2759e-04\n",
      "Epoch 114/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 6.0891e-04 - val_loss: 0.0011\n",
      "Epoch 115/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 6.1220e-04 - val_loss: 4.7400e-04\n",
      "Epoch 116/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 5.4857e-04 - val_loss: 4.4599e-04\n",
      "Epoch 117/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.8823e-04 - val_loss: 6.1362e-04\n",
      "Epoch 118/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 5.6602e-04 - val_loss: 4.0586e-04\n",
      "Epoch 119/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 5.5536e-04 - val_loss: 4.1699e-04\n",
      "Epoch 120/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 5.4483e-04 - val_loss: 4.0407e-04\n",
      "Epoch 121/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.2978e-04 - val_loss: 4.1248e-04\n",
      "Epoch 122/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.3175e-04 - val_loss: 4.0012e-04\n",
      "Epoch 123/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 5.8095e-04 - val_loss: 5.2002e-04\n",
      "Epoch 124/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.5752e-04 - val_loss: 3.9400e-04\n",
      "Epoch 125/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 5.1828e-04 - val_loss: 4.8513e-04\n",
      "Epoch 126/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 5.2630e-04 - val_loss: 5.5323e-04\n",
      "Epoch 127/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 5.1644e-04 - val_loss: 4.0247e-04\n",
      "Epoch 128/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.1301e-04 - val_loss: 3.8739e-04\n",
      "Epoch 129/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 5.2162e-04 - val_loss: 3.8906e-04\n",
      "Epoch 130/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 5.1580e-04 - val_loss: 3.9080e-04\n",
      "Epoch 131/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 5.0167e-04 - val_loss: 3.9535e-04\n",
      "Epoch 132/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 5.4198e-04 - val_loss: 4.4426e-04\n",
      "Epoch 133/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 5.2344e-04 - val_loss: 4.0831e-04\n",
      "Epoch 134/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 5.2078e-04 - val_loss: 4.0513e-04\n",
      "Epoch 135/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 5.4461e-04 - val_loss: 6.1961e-04\n",
      "Epoch 136/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 5.4406e-04 - val_loss: 4.1713e-04\n",
      "Epoch 137/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 5.0055e-04 - val_loss: 4.7045e-04\n",
      "Epoch 138/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 4.9807e-04 - val_loss: 3.9049e-04\n",
      "Epoch 139/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 5.0806e-04 - val_loss: 3.7213e-04\n",
      "Epoch 140/2000\n",
      "4059/4059 [==============================] - 2s 606us/step - loss: 5.3702e-04 - val_loss: 0.0010\n",
      "Epoch 141/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 5.8760e-04 - val_loss: 3.7173e-04\n",
      "Epoch 142/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 5.7893e-04 - val_loss: 5.4610e-04\n",
      "Epoch 143/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 5.6716e-04 - val_loss: 3.6868e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 4.9116e-04 - val_loss: 3.8909e-04\n",
      "Epoch 145/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 5.2973e-04 - val_loss: 5.0895e-04\n",
      "Epoch 146/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 5.7741e-04 - val_loss: 5.1470e-04\n",
      "Epoch 147/2000\n",
      "4059/4059 [==============================] - 2s 606us/step - loss: 5.5633e-04 - val_loss: 3.8677e-04\n",
      "Epoch 148/2000\n",
      "4059/4059 [==============================] - 2s 605us/step - loss: 5.4546e-04 - val_loss: 4.7200e-04\n",
      "Epoch 149/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 5.3953e-04 - val_loss: 5.2811e-04\n",
      "Epoch 150/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 5.0011e-04 - val_loss: 4.7058e-04\n",
      "Epoch 151/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.8625e-04 - val_loss: 3.5230e-04\n",
      "Epoch 152/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.9947e-04 - val_loss: 3.8671e-04\n",
      "Epoch 153/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 5.3687e-04 - val_loss: 5.9797e-04\n",
      "Epoch 154/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 5.5161e-04 - val_loss: 7.9769e-04\n",
      "Epoch 155/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 5.3004e-04 - val_loss: 3.5708e-04\n",
      "Epoch 156/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.9750e-04 - val_loss: 3.4485e-04\n",
      "Epoch 157/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.8334e-04 - val_loss: 3.7725e-04\n",
      "Epoch 158/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 4.9604e-04 - val_loss: 3.9900e-04\n",
      "Epoch 159/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 5.3536e-04 - val_loss: 3.6589e-04\n",
      "Epoch 160/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 4.9504e-04 - val_loss: 5.9579e-04\n",
      "Epoch 161/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 5.2708e-04 - val_loss: 4.9238e-04\n",
      "Epoch 162/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.9674e-04 - val_loss: 3.4052e-04\n",
      "Epoch 163/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.5889e-04 - val_loss: 3.6788e-04\n",
      "Epoch 164/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.7637e-04 - val_loss: 3.6641e-04\n",
      "Epoch 165/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 5.2369e-04 - val_loss: 4.2391e-04\n",
      "Epoch 166/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 5.1576e-04 - val_loss: 3.5652e-04\n",
      "Epoch 167/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 4.7972e-04 - val_loss: 4.2463e-04\n",
      "Epoch 168/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 5.0696e-04 - val_loss: 3.2759e-04\n",
      "Epoch 169/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 4.7466e-04 - val_loss: 4.4390e-04\n",
      "Epoch 170/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 4.7013e-04 - val_loss: 4.1830e-04\n",
      "Epoch 171/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.9017e-04 - val_loss: 3.7167e-04\n",
      "Epoch 172/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 5.1172e-04 - val_loss: 3.4155e-04\n",
      "Epoch 173/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 5.1722e-04 - val_loss: 4.9511e-04\n",
      "Epoch 174/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 4.5999e-04 - val_loss: 4.1556e-04\n",
      "Epoch 175/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.6248e-04 - val_loss: 3.2805e-04\n",
      "Epoch 176/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 4.4287e-04 - val_loss: 3.2924e-04\n",
      "Epoch 177/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 4.5150e-04 - val_loss: 3.1926e-04\n",
      "Epoch 178/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.3608e-04 - val_loss: 3.6275e-04\n",
      "Epoch 179/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 4.3353e-04 - val_loss: 3.1946e-04\n",
      "Epoch 180/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 4.3407e-04 - val_loss: 3.7746e-04\n",
      "Epoch 181/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.3633e-04 - val_loss: 3.3767e-04\n",
      "Epoch 182/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.3757e-04 - val_loss: 3.1377e-04\n",
      "Epoch 183/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.4493e-04 - val_loss: 3.0620e-04\n",
      "Epoch 184/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.2905e-04 - val_loss: 3.1476e-04\n",
      "Epoch 185/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.7677e-04 - val_loss: 3.9426e-04\n",
      "Epoch 186/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.7977e-04 - val_loss: 3.1727e-04\n",
      "Epoch 187/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 4.3633e-04 - val_loss: 4.3123e-04\n",
      "Epoch 188/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.5192e-04 - val_loss: 3.4864e-04\n",
      "Epoch 189/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.4514e-04 - val_loss: 4.4133e-04\n",
      "Epoch 190/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.6555e-04 - val_loss: 3.4506e-04\n",
      "Epoch 191/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.2256e-04 - val_loss: 3.1666e-04\n",
      "Epoch 192/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 4.2757e-04 - val_loss: 2.9666e-04\n",
      "Epoch 193/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.1278e-04 - val_loss: 3.1135e-04\n",
      "Epoch 194/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 4.3398e-04 - val_loss: 3.9847e-04\n",
      "Epoch 195/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.2881e-04 - val_loss: 2.9653e-04\n",
      "Epoch 196/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.1843e-04 - val_loss: 3.4391e-04\n",
      "Epoch 197/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.2881e-04 - val_loss: 2.8961e-04\n",
      "Epoch 198/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.2083e-04 - val_loss: 2.9121e-04\n",
      "Epoch 199/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.1695e-04 - val_loss: 3.3479e-04\n",
      "Epoch 200/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.3878e-04 - val_loss: 2.9088e-04\n",
      "Epoch 201/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.3768e-04 - val_loss: 2.9370e-04\n",
      "Epoch 202/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.2508e-04 - val_loss: 2.9759e-04\n",
      "Epoch 203/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.5115e-04 - val_loss: 2.8249e-04\n",
      "Epoch 204/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.1730e-04 - val_loss: 2.9464e-04\n",
      "Epoch 205/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 4.0099e-04 - val_loss: 3.5166e-04\n",
      "Epoch 206/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 4.0757e-04 - val_loss: 3.4469e-04\n",
      "Epoch 207/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.1316e-04 - val_loss: 3.0555e-04\n",
      "Epoch 208/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.9988e-04 - val_loss: 2.7945e-04\n",
      "Epoch 209/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.0609e-04 - val_loss: 3.5561e-04\n",
      "Epoch 210/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.2283e-04 - val_loss: 2.8945e-04\n",
      "Epoch 211/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.3153e-04 - val_loss: 2.7535e-04\n",
      "Epoch 212/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.9303e-04 - val_loss: 2.8320e-04\n",
      "Epoch 213/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.9291e-04 - val_loss: 2.9624e-04\n",
      "Epoch 214/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.0387e-04 - val_loss: 2.8229e-04\n",
      "Epoch 215/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.9265e-04 - val_loss: 4.7618e-04\n",
      "Epoch 216/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 4.3344e-04 - val_loss: 3.4270e-04\n",
      "Epoch 217/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.6121e-04 - val_loss: 3.4668e-04\n",
      "Epoch 218/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.2145e-04 - val_loss: 3.2769e-04\n",
      "Epoch 219/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.3641e-04 - val_loss: 2.7184e-04\n",
      "Epoch 220/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.2092e-04 - val_loss: 2.8493e-04\n",
      "Epoch 221/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.8161e-04 - val_loss: 3.7004e-04\n",
      "Epoch 222/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.4384e-04 - val_loss: 2.6763e-04\n",
      "Epoch 223/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.8059e-04 - val_loss: 3.1042e-04\n",
      "Epoch 224/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.1389e-04 - val_loss: 3.6844e-04\n",
      "Epoch 225/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.3793e-04 - val_loss: 3.0942e-04\n",
      "Epoch 226/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.9529e-04 - val_loss: 2.9434e-04\n",
      "Epoch 227/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 4.1691e-04 - val_loss: 3.2007e-04\n",
      "Epoch 228/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.0976e-04 - val_loss: 3.4404e-04\n",
      "Epoch 229/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.7230e-04 - val_loss: 3.1950e-04\n",
      "Epoch 230/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 5.0913e-04 - val_loss: 5.5894e-04\n",
      "Epoch 231/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 4.9952e-04 - val_loss: 3.7301e-04\n",
      "Epoch 232/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.4950e-04 - val_loss: 4.0738e-04\n",
      "Epoch 233/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.0853e-04 - val_loss: 2.6311e-04\n",
      "Epoch 234/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.8894e-04 - val_loss: 2.8479e-04\n",
      "Epoch 235/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.8178e-04 - val_loss: 2.6322e-04\n",
      "Epoch 236/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.8599e-04 - val_loss: 2.8636e-04\n",
      "Epoch 237/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.3179e-04 - val_loss: 4.2234e-04\n",
      "Epoch 238/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.9706e-04 - val_loss: 2.6726e-04\n",
      "Epoch 239/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.6540e-04 - val_loss: 2.6262e-04\n",
      "Epoch 240/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.8172e-04 - val_loss: 3.2911e-04\n",
      "Epoch 241/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.8759e-04 - val_loss: 2.9059e-04\n",
      "Epoch 242/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.9505e-04 - val_loss: 2.7864e-04\n",
      "Epoch 243/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.1152e-04 - val_loss: 2.6284e-04\n",
      "Epoch 244/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.8447e-04 - val_loss: 3.4962e-04\n",
      "Epoch 245/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.7515e-04 - val_loss: 3.3934e-04\n",
      "Epoch 246/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.7620e-04 - val_loss: 3.4249e-04\n",
      "Epoch 247/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.9780e-04 - val_loss: 2.6599e-04\n",
      "Epoch 248/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.8605e-04 - val_loss: 2.9724e-04\n",
      "Epoch 249/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.3646e-04 - val_loss: 2.9690e-04\n",
      "Epoch 250/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 4.2960e-04 - val_loss: 4.4671e-04\n",
      "Epoch 251/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.0580e-04 - val_loss: 2.6818e-04\n",
      "Epoch 252/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 4.0286e-04 - val_loss: 4.2244e-04\n",
      "Epoch 253/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 4.5983e-04 - val_loss: 2.7594e-04\n",
      "Epoch 254/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.4487e-04 - val_loss: 5.5373e-04\n",
      "Epoch 255/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.0457e-04 - val_loss: 2.8779e-04\n",
      "Epoch 256/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.8945e-04 - val_loss: 2.7726e-04\n",
      "Epoch 257/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.9853e-04 - val_loss: 2.5690e-04\n",
      "Epoch 258/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.7787e-04 - val_loss: 2.6532e-04\n",
      "Epoch 259/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.6597e-04 - val_loss: 2.7769e-04\n",
      "Epoch 260/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.6943e-04 - val_loss: 2.6221e-04\n",
      "Epoch 261/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.8025e-04 - val_loss: 3.0565e-04\n",
      "Epoch 262/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.7363e-04 - val_loss: 2.5858e-04\n",
      "Epoch 263/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.9081e-04 - val_loss: 2.5522e-04\n",
      "Epoch 264/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.5865e-04 - val_loss: 2.5632e-04\n",
      "Epoch 265/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.5976e-04 - val_loss: 2.8904e-04\n",
      "Epoch 266/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.6676e-04 - val_loss: 2.7107e-04\n",
      "Epoch 267/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.7185e-04 - val_loss: 2.9730e-04\n",
      "Epoch 268/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.6578e-04 - val_loss: 2.5848e-04\n",
      "Epoch 269/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.5264e-04 - val_loss: 2.7000e-04\n",
      "Epoch 270/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.9260e-04 - val_loss: 2.5620e-04\n",
      "Epoch 271/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.1581e-04 - val_loss: 8.1020e-04\n",
      "Epoch 272/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 4.8507e-04 - val_loss: 4.1738e-04\n",
      "Epoch 273/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 5.1068e-04 - val_loss: 2.6204e-04\n",
      "Epoch 274/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 4.3278e-04 - val_loss: 3.8919e-04\n",
      "Epoch 275/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.0763e-04 - val_loss: 3.7331e-04\n",
      "Epoch 276/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.9459e-04 - val_loss: 2.5868e-04\n",
      "Epoch 277/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.6149e-04 - val_loss: 2.6195e-04\n",
      "Epoch 278/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.4848e-04 - val_loss: 2.7832e-04\n",
      "Epoch 279/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.6886e-04 - val_loss: 2.6012e-04\n",
      "Epoch 280/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.6074e-04 - val_loss: 2.7702e-04\n",
      "Epoch 281/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.6296e-04 - val_loss: 2.7539e-04\n",
      "Epoch 282/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.7359e-04 - val_loss: 2.6417e-04\n",
      "Epoch 283/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.1159e-04 - val_loss: 3.8139e-04\n",
      "Epoch 284/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 4.2074e-04 - val_loss: 3.1052e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 285/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.9732e-04 - val_loss: 2.7877e-04\n",
      "Epoch 286/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.8774e-04 - val_loss: 2.8316e-04\n",
      "Epoch 287/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.8481e-04 - val_loss: 3.0711e-04\n",
      "Epoch 288/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.6389e-04 - val_loss: 2.5927e-04\n",
      "Epoch 289/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.5773e-04 - val_loss: 2.5904e-04\n",
      "Epoch 290/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.6566e-04 - val_loss: 3.0336e-04\n",
      "Epoch 291/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.6942e-04 - val_loss: 3.3045e-04\n",
      "Epoch 292/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.9916e-04 - val_loss: 2.6113e-04\n",
      "Epoch 293/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.7557e-04 - val_loss: 4.1228e-04\n",
      "Epoch 294/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.9091e-04 - val_loss: 2.5912e-04\n",
      "Epoch 295/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.7356e-04 - val_loss: 2.5432e-04\n",
      "Epoch 296/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.6421e-04 - val_loss: 2.8210e-04\n",
      "Epoch 297/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.7626e-04 - val_loss: 3.2639e-04\n",
      "Epoch 298/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.9542e-04 - val_loss: 3.6752e-04\n",
      "Epoch 299/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.6804e-04 - val_loss: 2.8896e-04\n",
      "Epoch 300/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.8695e-04 - val_loss: 4.5206e-04\n",
      "Epoch 301/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.0836e-04 - val_loss: 2.5325e-04\n",
      "Epoch 302/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.6323e-04 - val_loss: 3.2490e-04\n",
      "Epoch 303/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.7098e-04 - val_loss: 2.5384e-04\n",
      "Epoch 304/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.5570e-04 - val_loss: 2.5553e-04\n",
      "Epoch 305/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.6845e-04 - val_loss: 4.3913e-04\n",
      "Epoch 306/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.7602e-04 - val_loss: 2.6243e-04\n",
      "Epoch 307/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.6683e-04 - val_loss: 2.5641e-04\n",
      "Epoch 308/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.7987e-04 - val_loss: 3.4845e-04\n",
      "Epoch 309/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.7739e-04 - val_loss: 2.5458e-04\n",
      "Epoch 310/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.5764e-04 - val_loss: 2.5342e-04\n",
      "Epoch 311/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.5574e-04 - val_loss: 3.9422e-04\n",
      "Epoch 312/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.8554e-04 - val_loss: 3.0392e-04\n",
      "Epoch 313/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.8366e-04 - val_loss: 4.0028e-04\n",
      "Epoch 314/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.7027e-04 - val_loss: 2.6147e-04\n",
      "Epoch 315/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.4969e-04 - val_loss: 2.5382e-04\n",
      "Epoch 316/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.9294e-04 - val_loss: 2.6971e-04\n",
      "Epoch 317/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.7141e-04 - val_loss: 4.0883e-04\n",
      "Epoch 318/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.8948e-04 - val_loss: 2.9005e-04\n",
      "Epoch 319/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.6445e-04 - val_loss: 2.5364e-04\n",
      "Epoch 320/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.4379e-04 - val_loss: 2.6590e-04\n",
      "Epoch 321/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.3838e-04 - val_loss: 2.5537e-04\n",
      "Epoch 322/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.6635e-04 - val_loss: 2.6247e-04\n",
      "Epoch 323/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.7881e-04 - val_loss: 3.7373e-04\n",
      "Epoch 324/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.0073e-04 - val_loss: 3.0796e-04\n",
      "Epoch 325/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 4.5171e-04 - val_loss: 6.4928e-04\n",
      "Epoch 326/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.8938e-04 - val_loss: 2.8664e-04\n",
      "Epoch 327/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.6925e-04 - val_loss: 2.7328e-04\n",
      "Epoch 328/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 4.1334e-04 - val_loss: 3.9143e-04\n",
      "Epoch 329/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 4.3356e-04 - val_loss: 4.3266e-04\n",
      "Epoch 330/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.9702e-04 - val_loss: 2.5490e-04\n",
      "Epoch 331/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 4.0232e-04 - val_loss: 2.7321e-04\n",
      "Epoch 332/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.3447e-04 - val_loss: 4.5103e-04\n",
      "Epoch 333/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 4.2320e-04 - val_loss: 3.9284e-04\n",
      "Epoch 334/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 4.4103e-04 - val_loss: 2.8961e-04\n",
      "Epoch 335/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 4.0552e-04 - val_loss: 3.8798e-04\n",
      "Epoch 336/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.0573e-04 - val_loss: 4.0335e-04\n",
      "Epoch 337/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.6742e-04 - val_loss: 3.6708e-04\n",
      "Epoch 338/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.6251e-04 - val_loss: 2.5578e-04\n",
      "Epoch 339/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.8703e-04 - val_loss: 3.1417e-04\n",
      "Epoch 340/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.8955e-04 - val_loss: 2.5616e-04\n",
      "Epoch 341/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.5731e-04 - val_loss: 2.7384e-04\n",
      "Epoch 342/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.6062e-04 - val_loss: 2.5619e-04\n",
      "Epoch 343/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.5249e-04 - val_loss: 3.2209e-04\n",
      "Epoch 344/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.4860e-04 - val_loss: 2.5382e-04\n",
      "Epoch 345/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.7853e-04 - val_loss: 3.7107e-04\n",
      "Epoch 346/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.9169e-04 - val_loss: 2.6219e-04\n",
      "Epoch 347/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.8322e-04 - val_loss: 4.3537e-04\n",
      "Epoch 348/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 4.4340e-04 - val_loss: 3.5692e-04\n",
      "Epoch 349/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 4.1379e-04 - val_loss: 2.9948e-04\n",
      "Epoch 350/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 4.1720e-04 - val_loss: 3.5842e-04\n",
      "Epoch 351/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.9030e-04 - val_loss: 5.0925e-04\n",
      "Epoch 352/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 4.0160e-04 - val_loss: 3.0582e-04\n",
      "Epoch 353/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.9134e-04 - val_loss: 2.6316e-04\n",
      "Epoch 354/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.4517e-04 - val_loss: 2.8530e-04\n",
      "Epoch 355/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 607us/step - loss: 3.5526e-04 - val_loss: 2.6485e-04\n",
      "Epoch 356/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.6194e-04 - val_loss: 2.6531e-04\n",
      "Epoch 357/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.7924e-04 - val_loss: 2.5900e-04\n",
      "Epoch 358/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.5576e-04 - val_loss: 3.2432e-04\n",
      "Epoch 359/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.5357e-04 - val_loss: 2.5595e-04\n",
      "Epoch 360/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 4.0572e-04 - val_loss: 3.2543e-04\n",
      "Epoch 361/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 4.1082e-04 - val_loss: 2.5763e-04\n",
      "Epoch 362/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.5516e-04 - val_loss: 3.0794e-04\n",
      "Epoch 363/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.7061e-04 - val_loss: 4.4041e-04\n",
      "Epoch 364/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.6895e-04 - val_loss: 2.8193e-04\n",
      "Epoch 365/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.6897e-04 - val_loss: 2.5520e-04\n",
      "Epoch 366/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.3803e-04 - val_loss: 2.5578e-04\n",
      "Epoch 367/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.4150e-04 - val_loss: 2.5703e-04\n",
      "Epoch 368/2000\n",
      "4059/4059 [==============================] - 3s 631us/step - loss: 3.5065e-04 - val_loss: 2.5539e-04\n",
      "Epoch 369/2000\n",
      "4059/4059 [==============================] - 3s 672us/step - loss: 3.4504e-04 - val_loss: 3.1280e-04\n",
      "Epoch 370/2000\n",
      "4059/4059 [==============================] - 3s 663us/step - loss: 3.3887e-04 - val_loss: 2.6321e-04\n",
      "Epoch 371/2000\n",
      "4059/4059 [==============================] - 3s 679us/step - loss: 3.4231e-04 - val_loss: 2.7616e-04\n",
      "Epoch 372/2000\n",
      "4059/4059 [==============================] - 3s 676us/step - loss: 3.3674e-04 - val_loss: 3.4250e-04\n",
      "Epoch 373/2000\n",
      "4059/4059 [==============================] - 3s 659us/step - loss: 3.9037e-04 - val_loss: 3.6199e-04\n",
      "Epoch 374/2000\n",
      "4059/4059 [==============================] - 3s 664us/step - loss: 4.1899e-04 - val_loss: 5.1478e-04\n",
      "Epoch 375/2000\n",
      "4059/4059 [==============================] - 3s 660us/step - loss: 3.9104e-04 - val_loss: 2.6446e-04\n",
      "Epoch 376/2000\n",
      "4059/4059 [==============================] - 3s 657us/step - loss: 3.6371e-04 - val_loss: 2.5972e-04\n",
      "Epoch 377/2000\n",
      "4059/4059 [==============================] - 3s 663us/step - loss: 3.3652e-04 - val_loss: 2.7099e-04\n",
      "Epoch 378/2000\n",
      "4059/4059 [==============================] - 3s 657us/step - loss: 3.5871e-04 - val_loss: 3.3533e-04\n",
      "Epoch 379/2000\n",
      "4059/4059 [==============================] - 3s 660us/step - loss: 3.7404e-04 - val_loss: 3.4801e-04\n",
      "Epoch 380/2000\n",
      "4059/4059 [==============================] - 3s 665us/step - loss: 3.8137e-04 - val_loss: 2.6002e-04\n",
      "Epoch 381/2000\n",
      "4059/4059 [==============================] - 3s 662us/step - loss: 3.9510e-04 - val_loss: 2.5430e-04\n",
      "Epoch 382/2000\n",
      "4059/4059 [==============================] - 3s 661us/step - loss: 3.4570e-04 - val_loss: 2.9647e-04\n",
      "Epoch 383/2000\n",
      "4059/4059 [==============================] - 3s 662us/step - loss: 4.0372e-04 - val_loss: 4.8097e-04\n",
      "Epoch 384/2000\n",
      "4059/4059 [==============================] - 3s 658us/step - loss: 3.9800e-04 - val_loss: 3.9933e-04\n",
      "Epoch 385/2000\n",
      "4059/4059 [==============================] - 3s 659us/step - loss: 4.0117e-04 - val_loss: 3.8293e-04\n",
      "Epoch 386/2000\n",
      "4059/4059 [==============================] - 3s 664us/step - loss: 3.5154e-04 - val_loss: 2.5469e-04\n",
      "Epoch 387/2000\n",
      "4059/4059 [==============================] - 3s 662us/step - loss: 3.4496e-04 - val_loss: 2.6077e-04\n",
      "Epoch 388/2000\n",
      "4059/4059 [==============================] - 3s 672us/step - loss: 3.5988e-04 - val_loss: 3.6156e-04\n",
      "Epoch 389/2000\n",
      "4059/4059 [==============================] - 3s 671us/step - loss: 3.5310e-04 - val_loss: 2.7760e-04\n",
      "Epoch 390/2000\n",
      "4059/4059 [==============================] - 3s 669us/step - loss: 3.5877e-04 - val_loss: 2.7106e-04\n",
      "Epoch 391/2000\n",
      "4059/4059 [==============================] - 3s 660us/step - loss: 3.4836e-04 - val_loss: 2.5619e-04\n",
      "Epoch 392/2000\n",
      "4059/4059 [==============================] - 3s 670us/step - loss: 3.4593e-04 - val_loss: 2.5770e-04\n",
      "Epoch 393/2000\n",
      "4059/4059 [==============================] - 3s 669us/step - loss: 3.3983e-04 - val_loss: 2.6233e-04\n",
      "Epoch 394/2000\n",
      "4059/4059 [==============================] - 3s 672us/step - loss: 3.4722e-04 - val_loss: 3.0279e-04\n",
      "Epoch 395/2000\n",
      "4059/4059 [==============================] - 3s 661us/step - loss: 3.7594e-04 - val_loss: 2.5709e-04\n",
      "Epoch 396/2000\n",
      "4059/4059 [==============================] - 3s 666us/step - loss: 3.8251e-04 - val_loss: 4.7196e-04\n",
      "Epoch 397/2000\n",
      "4059/4059 [==============================] - 3s 667us/step - loss: 3.5222e-04 - val_loss: 2.9434e-04\n",
      "Epoch 398/2000\n",
      "4059/4059 [==============================] - 3s 661us/step - loss: 3.4740e-04 - val_loss: 2.5590e-04\n",
      "Epoch 399/2000\n",
      "4059/4059 [==============================] - 3s 668us/step - loss: 3.4109e-04 - val_loss: 2.6211e-04\n",
      "Epoch 400/2000\n",
      "4059/4059 [==============================] - 3s 670us/step - loss: 3.3970e-04 - val_loss: 2.6106e-04\n",
      "Epoch 401/2000\n",
      "4059/4059 [==============================] - 3s 662us/step - loss: 3.5437e-04 - val_loss: 3.0697e-04\n",
      "Epoch 402/2000\n",
      "4059/4059 [==============================] - 3s 659us/step - loss: 3.6509e-04 - val_loss: 2.6682e-04\n",
      "Epoch 403/2000\n",
      "4059/4059 [==============================] - 3s 660us/step - loss: 3.5021e-04 - val_loss: 2.7521e-04\n",
      "Epoch 404/2000\n",
      "4059/4059 [==============================] - 3s 663us/step - loss: 3.6709e-04 - val_loss: 2.6439e-04\n",
      "Epoch 405/2000\n",
      "4059/4059 [==============================] - 3s 659us/step - loss: 3.5272e-04 - val_loss: 4.4032e-04\n",
      "Epoch 406/2000\n",
      "4059/4059 [==============================] - 3s 674us/step - loss: 4.2262e-04 - val_loss: 3.8901e-04\n",
      "Epoch 407/2000\n",
      "4059/4059 [==============================] - 3s 662us/step - loss: 4.2919e-04 - val_loss: 3.2253e-04\n",
      "Epoch 408/2000\n",
      "4059/4059 [==============================] - 3s 662us/step - loss: 3.6104e-04 - val_loss: 2.6556e-04\n",
      "Epoch 409/2000\n",
      "4059/4059 [==============================] - 3s 663us/step - loss: 4.2019e-04 - val_loss: 3.8048e-04\n",
      "Epoch 410/2000\n",
      "4059/4059 [==============================] - 3s 661us/step - loss: 4.2449e-04 - val_loss: 3.1797e-04\n",
      "Epoch 411/2000\n",
      "4059/4059 [==============================] - 3s 658us/step - loss: 3.6712e-04 - val_loss: 4.3315e-04\n",
      "Epoch 412/2000\n",
      "4059/4059 [==============================] - 3s 663us/step - loss: 3.5983e-04 - val_loss: 3.3835e-04\n",
      "Epoch 413/2000\n",
      "4059/4059 [==============================] - 3s 663us/step - loss: 3.4408e-04 - val_loss: 2.9389e-04\n",
      "Epoch 414/2000\n",
      "4059/4059 [==============================] - 3s 662us/step - loss: 3.8447e-04 - val_loss: 2.5585e-04\n",
      "Epoch 415/2000\n",
      "4059/4059 [==============================] - 3s 662us/step - loss: 3.4984e-04 - val_loss: 2.7309e-04\n",
      "Epoch 416/2000\n",
      "4059/4059 [==============================] - 3s 665us/step - loss: 3.7914e-04 - val_loss: 4.0177e-04\n",
      "Epoch 417/2000\n",
      "4059/4059 [==============================] - 3s 665us/step - loss: 3.6751e-04 - val_loss: 2.9419e-04\n",
      "Epoch 418/2000\n",
      "4059/4059 [==============================] - 3s 672us/step - loss: 3.8208e-04 - val_loss: 3.9150e-04\n",
      "Epoch 419/2000\n",
      "4059/4059 [==============================] - 3s 661us/step - loss: 4.0099e-04 - val_loss: 2.6267e-04\n",
      "Epoch 420/2000\n",
      "4059/4059 [==============================] - 3s 659us/step - loss: 3.4352e-04 - val_loss: 2.7228e-04\n",
      "Epoch 421/2000\n",
      "4059/4059 [==============================] - 3s 672us/step - loss: 3.4664e-04 - val_loss: 2.8094e-04\n",
      "Epoch 422/2000\n",
      "4059/4059 [==============================] - 3s 677us/step - loss: 3.7973e-04 - val_loss: 2.8646e-04\n",
      "Epoch 423/2000\n",
      "4059/4059 [==============================] - 3s 659us/step - loss: 3.5207e-04 - val_loss: 2.6560e-04\n",
      "Epoch 424/2000\n",
      "4059/4059 [==============================] - 3s 673us/step - loss: 3.3363e-04 - val_loss: 2.5756e-04\n",
      "Epoch 425/2000\n",
      "4059/4059 [==============================] - 3s 664us/step - loss: 3.4288e-04 - val_loss: 2.8867e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 426/2000\n",
      "4059/4059 [==============================] - 3s 665us/step - loss: 3.4524e-04 - val_loss: 2.5763e-04\n",
      "Epoch 427/2000\n",
      "4059/4059 [==============================] - 3s 661us/step - loss: 3.5602e-04 - val_loss: 2.6822e-04\n",
      "Epoch 428/2000\n",
      "4059/4059 [==============================] - 3s 666us/step - loss: 3.5085e-04 - val_loss: 2.9721e-04\n",
      "Epoch 429/2000\n",
      "4059/4059 [==============================] - 3s 659us/step - loss: 3.8136e-04 - val_loss: 3.3446e-04\n",
      "Epoch 430/2000\n",
      "4059/4059 [==============================] - 3s 677us/step - loss: 3.7745e-04 - val_loss: 2.7288e-04\n",
      "Epoch 431/2000\n",
      "4059/4059 [==============================] - 3s 666us/step - loss: 3.4062e-04 - val_loss: 2.8900e-04\n",
      "Epoch 432/2000\n",
      "4059/4059 [==============================] - 3s 659us/step - loss: 3.5095e-04 - val_loss: 3.3010e-04\n",
      "Epoch 433/2000\n",
      "4059/4059 [==============================] - 3s 659us/step - loss: 3.5363e-04 - val_loss: 2.6018e-04\n",
      "Epoch 434/2000\n",
      "4059/4059 [==============================] - 3s 667us/step - loss: 3.3620e-04 - val_loss: 2.6209e-04\n",
      "Epoch 435/2000\n",
      "4059/4059 [==============================] - 3s 663us/step - loss: 3.4371e-04 - val_loss: 3.0700e-04\n",
      "Epoch 436/2000\n",
      "4059/4059 [==============================] - 3s 673us/step - loss: 3.6851e-04 - val_loss: 2.9946e-04\n",
      "Epoch 437/2000\n",
      "4059/4059 [==============================] - 3s 662us/step - loss: 3.7475e-04 - val_loss: 3.3931e-04\n",
      "Epoch 438/2000\n",
      "4059/4059 [==============================] - 3s 665us/step - loss: 3.6914e-04 - val_loss: 4.4496e-04\n",
      "Epoch 439/2000\n",
      "4059/4059 [==============================] - 3s 669us/step - loss: 5.3368e-04 - val_loss: 3.0284e-04\n",
      "Epoch 440/2000\n",
      "4059/4059 [==============================] - 3s 670us/step - loss: 4.7995e-04 - val_loss: 8.5719e-04\n",
      "Epoch 441/2000\n",
      "4059/4059 [==============================] - 3s 687us/step - loss: 5.2195e-04 - val_loss: 2.9291e-04\n",
      "Epoch 442/2000\n",
      "4059/4059 [==============================] - 3s 679us/step - loss: 4.2981e-04 - val_loss: 4.2443e-04\n",
      "Epoch 443/2000\n",
      "4059/4059 [==============================] - 3s 675us/step - loss: 4.1588e-04 - val_loss: 2.8906e-04\n",
      "Epoch 444/2000\n",
      "4059/4059 [==============================] - 3s 674us/step - loss: 3.4629e-04 - val_loss: 2.5880e-04\n",
      "Epoch 445/2000\n",
      "4059/4059 [==============================] - 3s 672us/step - loss: 3.4116e-04 - val_loss: 2.6814e-04\n",
      "Epoch 446/2000\n",
      "4059/4059 [==============================] - 3s 670us/step - loss: 3.3643e-04 - val_loss: 2.5814e-04\n",
      "Epoch 447/2000\n",
      "4059/4059 [==============================] - 3s 672us/step - loss: 3.6859e-04 - val_loss: 3.1022e-04\n",
      "Epoch 448/2000\n",
      "4059/4059 [==============================] - 3s 662us/step - loss: 3.4890e-04 - val_loss: 2.5368e-04\n",
      "Epoch 449/2000\n",
      "4059/4059 [==============================] - 3s 666us/step - loss: 3.5313e-04 - val_loss: 2.8851e-04\n",
      "Epoch 450/2000\n",
      "4059/4059 [==============================] - 3s 673us/step - loss: 3.3957e-04 - val_loss: 2.5655e-04\n",
      "Epoch 451/2000\n",
      "4059/4059 [==============================] - 3s 664us/step - loss: 3.3486e-04 - val_loss: 2.6018e-04\n",
      "Epoch 452/2000\n",
      "4059/4059 [==============================] - 3s 676us/step - loss: 3.6206e-04 - val_loss: 3.1735e-04\n",
      "Epoch 453/2000\n",
      "4059/4059 [==============================] - 3s 671us/step - loss: 3.4504e-04 - val_loss: 3.2101e-04\n",
      "Epoch 454/2000\n",
      "4059/4059 [==============================] - 3s 666us/step - loss: 3.5180e-04 - val_loss: 2.9285e-04\n",
      "Epoch 455/2000\n",
      "4059/4059 [==============================] - 3s 663us/step - loss: 3.8865e-04 - val_loss: 3.2613e-04\n",
      "Epoch 456/2000\n",
      "4059/4059 [==============================] - 3s 666us/step - loss: 3.6096e-04 - val_loss: 3.5837e-04\n",
      "Epoch 457/2000\n",
      "4059/4059 [==============================] - 3s 669us/step - loss: 3.6349e-04 - val_loss: 2.6641e-04\n",
      "Epoch 458/2000\n",
      "4059/4059 [==============================] - 3s 668us/step - loss: 3.5203e-04 - val_loss: 2.6009e-04\n",
      "Epoch 459/2000\n",
      "4059/4059 [==============================] - 3s 673us/step - loss: 3.5961e-04 - val_loss: 4.3297e-04\n",
      "Epoch 460/2000\n",
      "4059/4059 [==============================] - 3s 675us/step - loss: 4.3159e-04 - val_loss: 2.5637e-04\n",
      "Epoch 461/2000\n",
      "4059/4059 [==============================] - 3s 668us/step - loss: 4.0292e-04 - val_loss: 3.5961e-04\n",
      "Epoch 462/2000\n",
      "4059/4059 [==============================] - 3s 667us/step - loss: 3.7526e-04 - val_loss: 2.5563e-04\n",
      "Epoch 463/2000\n",
      "4059/4059 [==============================] - 3s 677us/step - loss: 4.0223e-04 - val_loss: 3.9885e-04\n",
      "Epoch 464/2000\n",
      "4059/4059 [==============================] - 3s 677us/step - loss: 3.6966e-04 - val_loss: 2.6879e-04\n",
      "Epoch 465/2000\n",
      "4059/4059 [==============================] - 3s 676us/step - loss: 3.3393e-04 - val_loss: 3.0249e-04\n",
      "Epoch 466/2000\n",
      "4059/4059 [==============================] - 3s 668us/step - loss: 3.4276e-04 - val_loss: 2.6214e-04\n",
      "Epoch 467/2000\n",
      "4059/4059 [==============================] - 3s 672us/step - loss: 3.4954e-04 - val_loss: 2.6689e-04\n",
      "Epoch 468/2000\n",
      "4059/4059 [==============================] - 3s 668us/step - loss: 3.3974e-04 - val_loss: 2.7467e-04\n",
      "Epoch 469/2000\n",
      "4059/4059 [==============================] - 3s 669us/step - loss: 3.3471e-04 - val_loss: 2.5978e-04\n",
      "Epoch 470/2000\n",
      "4059/4059 [==============================] - 3s 673us/step - loss: 3.4209e-04 - val_loss: 2.8890e-04\n",
      "Epoch 471/2000\n",
      "4059/4059 [==============================] - 3s 665us/step - loss: 3.8126e-04 - val_loss: 3.1177e-04\n",
      "Epoch 472/2000\n",
      "4059/4059 [==============================] - 3s 634us/step - loss: 3.5004e-04 - val_loss: 3.3612e-04\n",
      "Epoch 473/2000\n",
      "4059/4059 [==============================] - 3s 648us/step - loss: 3.7426e-04 - val_loss: 3.1652e-04\n",
      "Epoch 474/2000\n",
      "4059/4059 [==============================] - 3s 666us/step - loss: 3.8554e-04 - val_loss: 2.5675e-04\n",
      "Epoch 475/2000\n",
      "4059/4059 [==============================] - 3s 686us/step - loss: 3.3762e-04 - val_loss: 2.6951e-04\n",
      "Epoch 476/2000\n",
      "4059/4059 [==============================] - 3s 693us/step - loss: 3.4271e-04 - val_loss: 2.5960e-04\n",
      "Epoch 477/2000\n",
      "4059/4059 [==============================] - 3s 674us/step - loss: 3.3808e-04 - val_loss: 2.5743e-04\n",
      "Epoch 478/2000\n",
      "4059/4059 [==============================] - 3s 659us/step - loss: 3.4207e-04 - val_loss: 2.5742e-04\n",
      "Epoch 479/2000\n",
      "4059/4059 [==============================] - 3s 665us/step - loss: 3.2792e-04 - val_loss: 2.7033e-04\n",
      "Epoch 480/2000\n",
      "4059/4059 [==============================] - 3s 658us/step - loss: 3.6124e-04 - val_loss: 2.5598e-04\n",
      "Epoch 481/2000\n",
      "4059/4059 [==============================] - 3s 666us/step - loss: 3.5559e-04 - val_loss: 4.1104e-04\n",
      "Epoch 482/2000\n",
      "4059/4059 [==============================] - 3s 623us/step - loss: 3.7684e-04 - val_loss: 2.9737e-04\n",
      "Epoch 483/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.7804e-04 - val_loss: 3.0241e-04\n",
      "Epoch 484/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.4266e-04 - val_loss: 2.5689e-04\n",
      "Epoch 485/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.4029e-04 - val_loss: 2.5569e-04\n",
      "Epoch 486/2000\n",
      "4059/4059 [==============================] - 3s 653us/step - loss: 3.3958e-04 - val_loss: 2.5902e-04\n",
      "Epoch 487/2000\n",
      "4059/4059 [==============================] - 3s 641us/step - loss: 3.3367e-04 - val_loss: 2.5644e-04\n",
      "Epoch 488/2000\n",
      "4059/4059 [==============================] - 3s 631us/step - loss: 3.3197e-04 - val_loss: 3.1341e-04\n",
      "Epoch 489/2000\n",
      "4059/4059 [==============================] - 3s 628us/step - loss: 3.7018e-04 - val_loss: 3.8111e-04\n",
      "Epoch 490/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.4105e-04 - val_loss: 2.5722e-04\n",
      "Epoch 491/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5088e-04 - val_loss: 2.7884e-04\n",
      "Epoch 492/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5528e-04 - val_loss: 3.0889e-04\n",
      "Epoch 493/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.3888e-04 - val_loss: 2.7577e-04\n",
      "Epoch 494/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.5777e-04 - val_loss: 3.1115e-04\n",
      "Epoch 495/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 3.5551e-04 - val_loss: 3.0719e-04\n",
      "Epoch 496/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.6524e-04 - val_loss: 2.6203e-04\n",
      "Epoch 497/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.7779e-04 - val_loss: 5.6546e-04\n",
      "Epoch 498/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.7243e-04 - val_loss: 2.5666e-04\n",
      "Epoch 499/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.4168e-04 - val_loss: 2.5923e-04\n",
      "Epoch 500/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.6837e-04 - val_loss: 2.8074e-04\n",
      "Epoch 501/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.4307e-04 - val_loss: 2.5849e-04\n",
      "Epoch 502/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.5138e-04 - val_loss: 2.8779e-04\n",
      "Epoch 503/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.7596e-04 - val_loss: 2.8636e-04\n",
      "Epoch 504/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 4.2954e-04 - val_loss: 2.5594e-04\n",
      "Epoch 505/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.7205e-04 - val_loss: 3.3023e-04\n",
      "Epoch 506/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.8733e-04 - val_loss: 2.7966e-04\n",
      "Epoch 507/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.8431e-04 - val_loss: 2.9762e-04\n",
      "Epoch 508/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.4563e-04 - val_loss: 3.1642e-04\n",
      "Epoch 509/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.7132e-04 - val_loss: 3.0456e-04\n",
      "Epoch 510/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.8128e-04 - val_loss: 2.8494e-04\n",
      "Epoch 511/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.6820e-04 - val_loss: 3.5552e-04\n",
      "Epoch 512/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5489e-04 - val_loss: 2.5570e-04\n",
      "Epoch 513/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.4511e-04 - val_loss: 2.5643e-04\n",
      "Epoch 514/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.3723e-04 - val_loss: 3.3260e-04\n",
      "Epoch 515/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.3639e-04 - val_loss: 2.6226e-04\n",
      "Epoch 516/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.5420e-04 - val_loss: 2.7355e-04\n",
      "Epoch 517/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.4474e-04 - val_loss: 3.4790e-04\n",
      "Epoch 518/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.6066e-04 - val_loss: 2.6745e-04\n",
      "Epoch 519/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.5877e-04 - val_loss: 2.6265e-04\n",
      "Epoch 520/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.5858e-04 - val_loss: 3.2838e-04\n",
      "Epoch 521/2000\n",
      "4059/4059 [==============================] - 3s 626us/step - loss: 3.6129e-04 - val_loss: 2.6293e-04\n",
      "Epoch 522/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.5228e-04 - val_loss: 2.7307e-04\n",
      "Epoch 523/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.6681e-04 - val_loss: 2.6083e-04\n",
      "Epoch 524/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.7349e-04 - val_loss: 2.5673e-04\n",
      "Epoch 525/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.4015e-04 - val_loss: 3.4415e-04\n",
      "Epoch 526/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.3431e-04 - val_loss: 2.6823e-04\n",
      "Epoch 527/2000\n",
      "4059/4059 [==============================] - 3s 626us/step - loss: 3.3250e-04 - val_loss: 2.6554e-04\n",
      "Epoch 528/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.3980e-04 - val_loss: 3.1914e-04\n",
      "Epoch 529/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5717e-04 - val_loss: 2.9351e-04\n",
      "Epoch 530/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.4480e-04 - val_loss: 2.6585e-04\n",
      "Epoch 531/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.3900e-04 - val_loss: 2.9407e-04\n",
      "Epoch 532/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.3570e-04 - val_loss: 3.0971e-04\n",
      "Epoch 533/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.8260e-04 - val_loss: 6.5370e-04\n",
      "Epoch 534/2000\n",
      "4059/4059 [==============================] - 3s 632us/step - loss: 4.0490e-04 - val_loss: 2.5465e-04\n",
      "Epoch 535/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.3032e-04 - val_loss: 3.0333e-04\n",
      "Epoch 536/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.7823e-04 - val_loss: 2.6904e-04\n",
      "Epoch 537/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 4.1356e-04 - val_loss: 2.8146e-04\n",
      "Epoch 538/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.8569e-04 - val_loss: 5.3213e-04\n",
      "Epoch 539/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.7597e-04 - val_loss: 2.6680e-04\n",
      "Epoch 540/2000\n",
      "4059/4059 [==============================] - 3s 623us/step - loss: 3.4417e-04 - val_loss: 2.7828e-04\n",
      "Epoch 541/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.3456e-04 - val_loss: 2.5812e-04\n",
      "Epoch 542/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.3815e-04 - val_loss: 2.9078e-04\n",
      "Epoch 543/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.3555e-04 - val_loss: 2.5996e-04\n",
      "Epoch 544/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.7046e-04 - val_loss: 3.1356e-04\n",
      "Epoch 545/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 4.0818e-04 - val_loss: 2.7317e-04\n",
      "Epoch 546/2000\n",
      "4059/4059 [==============================] - 3s 626us/step - loss: 4.0041e-04 - val_loss: 3.0108e-04\n",
      "Epoch 547/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5916e-04 - val_loss: 3.7990e-04\n",
      "Epoch 548/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.5265e-04 - val_loss: 2.9062e-04\n",
      "Epoch 549/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 4.1796e-04 - val_loss: 3.7305e-04\n",
      "Epoch 550/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.5630e-04 - val_loss: 3.1111e-04\n",
      "Epoch 551/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.5166e-04 - val_loss: 2.6286e-04\n",
      "Epoch 552/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.4632e-04 - val_loss: 4.3243e-04\n",
      "Epoch 553/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.5498e-04 - val_loss: 2.7124e-04\n",
      "Epoch 554/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.3570e-04 - val_loss: 2.9970e-04\n",
      "Epoch 555/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4772e-04 - val_loss: 2.6798e-04\n",
      "Epoch 556/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.5837e-04 - val_loss: 3.0384e-04\n",
      "Epoch 557/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.6794e-04 - val_loss: 3.1205e-04\n",
      "Epoch 558/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.6471e-04 - val_loss: 2.8494e-04\n",
      "Epoch 559/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 3.3891e-04 - val_loss: 2.6067e-04\n",
      "Epoch 560/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.2782e-04 - val_loss: 2.7021e-04\n",
      "Epoch 561/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.6360e-04 - val_loss: 3.2406e-04\n",
      "Epoch 562/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5891e-04 - val_loss: 3.4429e-04\n",
      "Epoch 563/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.6101e-04 - val_loss: 2.9292e-04\n",
      "Epoch 564/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.5140e-04 - val_loss: 2.6398e-04\n",
      "Epoch 565/2000\n",
      "4059/4059 [==============================] - 3s 623us/step - loss: 3.6543e-04 - val_loss: 3.1892e-04\n",
      "Epoch 566/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.5542e-04 - val_loss: 3.4780e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 567/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 4.0397e-04 - val_loss: 4.3926e-04\n",
      "Epoch 568/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 4.0908e-04 - val_loss: 2.7992e-04\n",
      "Epoch 569/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.5213e-04 - val_loss: 2.7986e-04\n",
      "Epoch 570/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.3308e-04 - val_loss: 2.6041e-04\n",
      "Epoch 571/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.2874e-04 - val_loss: 2.7455e-04\n",
      "Epoch 572/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.3445e-04 - val_loss: 3.1217e-04\n",
      "Epoch 573/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.3962e-04 - val_loss: 2.5876e-04\n",
      "Epoch 574/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.8811e-04 - val_loss: 3.0249e-04\n",
      "Epoch 575/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 4.0431e-04 - val_loss: 5.0966e-04\n",
      "Epoch 576/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 4.0276e-04 - val_loss: 2.9547e-04\n",
      "Epoch 577/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.7087e-04 - val_loss: 2.8549e-04\n",
      "Epoch 578/2000\n",
      "4059/4059 [==============================] - 3s 625us/step - loss: 3.6010e-04 - val_loss: 2.9989e-04\n",
      "Epoch 579/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.3830e-04 - val_loss: 2.5995e-04\n",
      "Epoch 580/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5673e-04 - val_loss: 5.1560e-04\n",
      "Epoch 581/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.9974e-04 - val_loss: 2.6021e-04\n",
      "Epoch 582/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.4277e-04 - val_loss: 2.9222e-04\n",
      "Epoch 583/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.6084e-04 - val_loss: 2.6372e-04\n",
      "Epoch 584/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.5213e-04 - val_loss: 2.6961e-04\n",
      "Epoch 585/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4539e-04 - val_loss: 3.6339e-04\n",
      "Epoch 586/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.5132e-04 - val_loss: 2.7635e-04\n",
      "Epoch 587/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.5523e-04 - val_loss: 3.0361e-04\n",
      "Epoch 588/2000\n",
      "4059/4059 [==============================] - 3s 623us/step - loss: 3.3398e-04 - val_loss: 2.9894e-04\n",
      "Epoch 589/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4526e-04 - val_loss: 3.2608e-04\n",
      "Epoch 590/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.5002e-04 - val_loss: 2.6001e-04\n",
      "Epoch 591/2000\n",
      "4059/4059 [==============================] - 3s 626us/step - loss: 3.4761e-04 - val_loss: 2.5873e-04\n",
      "Epoch 592/2000\n",
      "4059/4059 [==============================] - 3s 626us/step - loss: 3.2933e-04 - val_loss: 2.7541e-04\n",
      "Epoch 593/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.3481e-04 - val_loss: 2.5970e-04\n",
      "Epoch 594/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.2834e-04 - val_loss: 2.7165e-04\n",
      "Epoch 595/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.6011e-04 - val_loss: 2.8535e-04\n",
      "Epoch 596/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.4157e-04 - val_loss: 2.5875e-04\n",
      "Epoch 597/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 3.5056e-04 - val_loss: 3.6092e-04\n",
      "Epoch 598/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.8482e-04 - val_loss: 2.7472e-04\n",
      "Epoch 599/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.6731e-04 - val_loss: 2.7033e-04\n",
      "Epoch 600/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.3382e-04 - val_loss: 2.6192e-04\n",
      "Epoch 601/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.3459e-04 - val_loss: 2.7043e-04\n",
      "Epoch 602/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.3437e-04 - val_loss: 2.8461e-04\n",
      "Epoch 603/2000\n",
      "4059/4059 [==============================] - 3s 626us/step - loss: 3.3152e-04 - val_loss: 3.8281e-04\n",
      "Epoch 604/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.6948e-04 - val_loss: 2.7732e-04\n",
      "Epoch 605/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 3.8522e-04 - val_loss: 2.5645e-04\n",
      "Epoch 606/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.5573e-04 - val_loss: 2.7490e-04\n",
      "Epoch 607/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.3233e-04 - val_loss: 2.7835e-04\n",
      "Epoch 608/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.3264e-04 - val_loss: 3.4929e-04\n",
      "Epoch 609/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.2863e-04 - val_loss: 2.7147e-04\n",
      "Epoch 610/2000\n",
      "4059/4059 [==============================] - 3s 625us/step - loss: 3.2455e-04 - val_loss: 2.8512e-04\n",
      "Epoch 611/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.4916e-04 - val_loss: 2.6553e-04\n",
      "Epoch 612/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.5592e-04 - val_loss: 4.2616e-04\n",
      "Epoch 613/2000\n",
      "4059/4059 [==============================] - 3s 623us/step - loss: 3.5691e-04 - val_loss: 2.6001e-04\n",
      "Epoch 614/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.6570e-04 - val_loss: 2.6093e-04\n",
      "Epoch 615/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 4.1766e-04 - val_loss: 8.1092e-04\n",
      "Epoch 616/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 4.0513e-04 - val_loss: 2.7008e-04\n",
      "Epoch 617/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.4033e-04 - val_loss: 2.7571e-04\n",
      "Epoch 618/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.4854e-04 - val_loss: 2.9711e-04\n",
      "Epoch 619/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.4155e-04 - val_loss: 2.6565e-04\n",
      "Epoch 620/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.3731e-04 - val_loss: 2.7211e-04\n",
      "Epoch 621/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.3640e-04 - val_loss: 2.6328e-04\n",
      "Epoch 622/2000\n",
      "4059/4059 [==============================] - 3s 623us/step - loss: 3.3889e-04 - val_loss: 3.4425e-04\n",
      "Epoch 623/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.4698e-04 - val_loss: 2.9457e-04\n",
      "Epoch 624/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.6364e-04 - val_loss: 3.2651e-04\n",
      "Epoch 625/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.3879e-04 - val_loss: 2.8628e-04\n",
      "Epoch 626/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.6246e-04 - val_loss: 4.4310e-04\n",
      "Epoch 627/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4163e-04 - val_loss: 2.6148e-04\n",
      "Epoch 628/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.3142e-04 - val_loss: 2.7116e-04\n",
      "Epoch 629/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.4893e-04 - val_loss: 2.5930e-04\n",
      "Epoch 630/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.2987e-04 - val_loss: 2.6121e-04\n",
      "Epoch 631/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.2886e-04 - val_loss: 2.6253e-04\n",
      "Epoch 632/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4813e-04 - val_loss: 4.1940e-04\n",
      "Epoch 633/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.5620e-04 - val_loss: 2.7246e-04\n",
      "Epoch 634/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.4637e-04 - val_loss: 3.7230e-04\n",
      "Epoch 635/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 3.7183e-04 - val_loss: 2.6065e-04\n",
      "Epoch 636/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.6193e-04 - val_loss: 3.3183e-04\n",
      "Epoch 637/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 3s 624us/step - loss: 3.5974e-04 - val_loss: 2.8101e-04\n",
      "Epoch 638/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.2617e-04 - val_loss: 2.6489e-04\n",
      "Epoch 639/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.2303e-04 - val_loss: 2.7504e-04\n",
      "Epoch 640/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.4073e-04 - val_loss: 2.7923e-04\n",
      "Epoch 641/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.3154e-04 - val_loss: 2.6285e-04\n",
      "Epoch 642/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.5057e-04 - val_loss: 2.9793e-04\n",
      "Epoch 643/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.5382e-04 - val_loss: 2.7215e-04\n",
      "Epoch 644/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.5643e-04 - val_loss: 2.7217e-04\n",
      "Epoch 645/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.7916e-04 - val_loss: 4.9136e-04\n",
      "Epoch 646/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5531e-04 - val_loss: 2.6669e-04\n",
      "Epoch 647/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.8643e-04 - val_loss: 3.1747e-04\n",
      "Epoch 648/2000\n",
      "4059/4059 [==============================] - 3s 626us/step - loss: 3.8169e-04 - val_loss: 2.6713e-04\n",
      "Epoch 649/2000\n",
      "4059/4059 [==============================] - 3s 626us/step - loss: 3.5237e-04 - val_loss: 2.6692e-04\n",
      "Epoch 650/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.3478e-04 - val_loss: 2.6306e-04\n",
      "Epoch 651/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.3047e-04 - val_loss: 2.7163e-04\n",
      "Epoch 652/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.3875e-04 - val_loss: 2.8332e-04\n",
      "Epoch 653/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.6476e-04 - val_loss: 4.7125e-04\n",
      "Epoch 654/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.9255e-04 - val_loss: 2.6162e-04\n",
      "Epoch 655/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.7692e-04 - val_loss: 5.4628e-04\n",
      "Epoch 656/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 4.6321e-04 - val_loss: 3.6707e-04\n",
      "Epoch 657/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.9165e-04 - val_loss: 2.8009e-04\n",
      "Epoch 658/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4633e-04 - val_loss: 2.6258e-04\n",
      "Epoch 659/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.2089e-04 - val_loss: 2.6209e-04\n",
      "Epoch 660/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.3466e-04 - val_loss: 2.6070e-04\n",
      "Epoch 661/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.5566e-04 - val_loss: 3.6064e-04\n",
      "Epoch 662/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.6320e-04 - val_loss: 5.9707e-04\n",
      "Epoch 663/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 4.2197e-04 - val_loss: 2.6211e-04\n",
      "Epoch 664/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.8809e-04 - val_loss: 3.1593e-04\n",
      "Epoch 665/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 4.0442e-04 - val_loss: 3.7957e-04\n",
      "Epoch 666/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 4.0385e-04 - val_loss: 2.7100e-04\n",
      "Epoch 667/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.5501e-04 - val_loss: 3.6056e-04\n",
      "Epoch 668/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.4427e-04 - val_loss: 2.6552e-04\n",
      "Epoch 669/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.3385e-04 - val_loss: 2.6882e-04\n",
      "Epoch 670/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.4059e-04 - val_loss: 2.9357e-04\n",
      "Epoch 671/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.4024e-04 - val_loss: 3.0051e-04\n",
      "Epoch 672/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.3600e-04 - val_loss: 2.8976e-04\n",
      "Epoch 673/2000\n",
      "4059/4059 [==============================] - 3s 623us/step - loss: 3.3495e-04 - val_loss: 2.9123e-04\n",
      "Epoch 674/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4660e-04 - val_loss: 2.6269e-04\n",
      "Epoch 675/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.2005e-04 - val_loss: 2.7482e-04\n",
      "Epoch 676/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.3189e-04 - val_loss: 2.8611e-04\n",
      "Epoch 677/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.4970e-04 - val_loss: 3.2620e-04\n",
      "Epoch 678/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4795e-04 - val_loss: 2.7429e-04\n",
      "Epoch 679/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.4027e-04 - val_loss: 3.0085e-04\n",
      "Epoch 680/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.4168e-04 - val_loss: 2.6546e-04\n",
      "Epoch 681/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.4806e-04 - val_loss: 2.6248e-04\n",
      "Epoch 682/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.4675e-04 - val_loss: 4.1284e-04\n",
      "Epoch 683/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5597e-04 - val_loss: 2.6643e-04\n",
      "Epoch 684/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.4167e-04 - val_loss: 3.0168e-04\n",
      "Epoch 685/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.6394e-04 - val_loss: 3.1715e-04\n",
      "Epoch 686/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.5548e-04 - val_loss: 2.6502e-04\n",
      "Epoch 687/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.5452e-04 - val_loss: 3.2263e-04\n",
      "Epoch 688/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.2097e-04 - val_loss: 2.7415e-04\n",
      "Epoch 689/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.2326e-04 - val_loss: 2.7185e-04\n",
      "Epoch 690/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.2821e-04 - val_loss: 2.6288e-04\n",
      "Epoch 691/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.1990e-04 - val_loss: 3.2662e-04\n",
      "Epoch 692/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.3239e-04 - val_loss: 2.8731e-04\n",
      "Epoch 693/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5380e-04 - val_loss: 3.2928e-04\n",
      "Epoch 694/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.5939e-04 - val_loss: 2.8035e-04\n",
      "Epoch 695/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.5324e-04 - val_loss: 3.7586e-04\n",
      "Epoch 696/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.6286e-04 - val_loss: 2.6892e-04\n",
      "Epoch 697/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.3482e-04 - val_loss: 2.7350e-04\n",
      "Epoch 698/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.2725e-04 - val_loss: 2.6268e-04\n",
      "Epoch 699/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 3.5757e-04 - val_loss: 3.9268e-04\n",
      "Epoch 700/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.8442e-04 - val_loss: 4.1703e-04\n",
      "Epoch 701/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.9867e-04 - val_loss: 4.4420e-04\n",
      "Epoch 702/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 4.0210e-04 - val_loss: 3.6016e-04\n",
      "Epoch 703/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.5792e-04 - val_loss: 2.6985e-04\n",
      "Epoch 704/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.5495e-04 - val_loss: 3.2566e-04\n",
      "Epoch 705/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.2552e-04 - val_loss: 2.7393e-04\n",
      "Epoch 706/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5504e-04 - val_loss: 3.1424e-04\n",
      "Epoch 707/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.4938e-04 - val_loss: 2.7519e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 708/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.4552e-04 - val_loss: 3.0949e-04\n",
      "Epoch 709/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.6148e-04 - val_loss: 2.6185e-04\n",
      "Epoch 710/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.6564e-04 - val_loss: 4.3718e-04\n",
      "Epoch 711/2000\n",
      "4059/4059 [==============================] - 3s 627us/step - loss: 3.6442e-04 - val_loss: 2.6272e-04\n",
      "Epoch 712/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.3245e-04 - val_loss: 2.9337e-04\n",
      "Epoch 713/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.2459e-04 - val_loss: 3.2739e-04\n",
      "Epoch 714/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.1862e-04 - val_loss: 3.3713e-04\n",
      "Epoch 715/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4461e-04 - val_loss: 2.6233e-04\n",
      "Epoch 716/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.1743e-04 - val_loss: 2.6831e-04\n",
      "Epoch 717/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.1433e-04 - val_loss: 2.8165e-04\n",
      "Epoch 718/2000\n",
      "4059/4059 [==============================] - 3s 626us/step - loss: 3.2702e-04 - val_loss: 2.6825e-04\n",
      "Epoch 719/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.2344e-04 - val_loss: 2.8528e-04\n",
      "Epoch 720/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.3688e-04 - val_loss: 3.3905e-04\n",
      "Epoch 721/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4265e-04 - val_loss: 2.7570e-04\n",
      "Epoch 722/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.2415e-04 - val_loss: 4.5307e-04\n",
      "Epoch 723/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.4827e-04 - val_loss: 2.6730e-04\n",
      "Epoch 724/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.2475e-04 - val_loss: 2.6339e-04\n",
      "Epoch 725/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.2792e-04 - val_loss: 2.6386e-04\n",
      "Epoch 726/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.1688e-04 - val_loss: 2.7552e-04\n",
      "Epoch 727/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5793e-04 - val_loss: 3.1373e-04\n",
      "Epoch 728/2000\n",
      "4059/4059 [==============================] - 3s 631us/step - loss: 4.4945e-04 - val_loss: 7.2269e-04\n",
      "Epoch 729/2000\n",
      "4059/4059 [==============================] - 3s 631us/step - loss: 3.9797e-04 - val_loss: 2.7612e-04\n",
      "Epoch 730/2000\n",
      "4059/4059 [==============================] - 3s 634us/step - loss: 3.6402e-04 - val_loss: 3.3990e-04\n",
      "Epoch 731/2000\n",
      "4059/4059 [==============================] - 3s 637us/step - loss: 3.6853e-04 - val_loss: 3.2159e-04\n",
      "Epoch 732/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.4085e-04 - val_loss: 2.6421e-04\n",
      "Epoch 733/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.3500e-04 - val_loss: 3.3126e-04\n",
      "Epoch 734/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.5762e-04 - val_loss: 2.7106e-04\n",
      "Epoch 735/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.6761e-04 - val_loss: 2.6412e-04\n",
      "Epoch 736/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.6939e-04 - val_loss: 5.1081e-04\n",
      "Epoch 737/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 4.0007e-04 - val_loss: 2.6632e-04\n",
      "Epoch 738/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.7416e-04 - val_loss: 3.3439e-04\n",
      "Epoch 739/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.4225e-04 - val_loss: 2.7691e-04\n",
      "Epoch 740/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.3448e-04 - val_loss: 3.1226e-04\n",
      "Epoch 741/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.3931e-04 - val_loss: 2.8434e-04\n",
      "Epoch 742/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.1978e-04 - val_loss: 2.6476e-04\n",
      "Epoch 743/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.2022e-04 - val_loss: 3.1436e-04\n",
      "Epoch 744/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.2725e-04 - val_loss: 2.6922e-04\n",
      "Epoch 745/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.2631e-04 - val_loss: 2.7036e-04\n",
      "Epoch 746/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.2488e-04 - val_loss: 2.9680e-04\n",
      "Epoch 747/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.3868e-04 - val_loss: 2.9851e-04\n",
      "Epoch 748/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.4709e-04 - val_loss: 3.1357e-04\n",
      "Epoch 749/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.4397e-04 - val_loss: 3.4980e-04\n",
      "Epoch 750/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.5570e-04 - val_loss: 2.6815e-04\n",
      "Epoch 751/2000\n",
      "4059/4059 [==============================] - 2s 611us/step - loss: 3.2233e-04 - val_loss: 2.7560e-04\n",
      "Epoch 752/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.3907e-04 - val_loss: 2.7269e-04\n",
      "Epoch 753/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.2780e-04 - val_loss: 2.8893e-04\n",
      "Epoch 754/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.1964e-04 - val_loss: 3.3075e-04\n",
      "Epoch 755/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.5271e-04 - val_loss: 2.7722e-04\n",
      "Epoch 756/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.2559e-04 - val_loss: 2.6647e-04\n",
      "Epoch 757/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.3698e-04 - val_loss: 4.2819e-04\n",
      "Epoch 758/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.5745e-04 - val_loss: 2.6629e-04\n",
      "Epoch 759/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.2327e-04 - val_loss: 2.8148e-04\n",
      "Epoch 760/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.3798e-04 - val_loss: 2.6767e-04\n",
      "Epoch 761/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.3756e-04 - val_loss: 2.7523e-04\n",
      "Epoch 762/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.8931e-04 - val_loss: 5.2286e-04\n",
      "Epoch 763/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.6931e-04 - val_loss: 3.5677e-04\n",
      "Epoch 764/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.5584e-04 - val_loss: 2.7753e-04\n",
      "Epoch 765/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.3784e-04 - val_loss: 2.7470e-04\n",
      "Epoch 766/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.2777e-04 - val_loss: 2.8792e-04\n",
      "Epoch 767/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.6510e-04 - val_loss: 2.6684e-04\n",
      "Epoch 768/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.5656e-04 - val_loss: 3.6484e-04\n",
      "Epoch 769/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.2765e-04 - val_loss: 3.1472e-04\n",
      "Epoch 770/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.4158e-04 - val_loss: 2.6564e-04\n",
      "Epoch 771/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.5374e-04 - val_loss: 3.2788e-04\n",
      "Epoch 772/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.3297e-04 - val_loss: 3.1830e-04\n",
      "Epoch 773/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.2712e-04 - val_loss: 2.7589e-04\n",
      "Epoch 774/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.3030e-04 - val_loss: 2.7470e-04\n",
      "Epoch 775/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.4707e-04 - val_loss: 3.4486e-04\n",
      "Epoch 776/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.3271e-04 - val_loss: 2.6800e-04\n",
      "Epoch 777/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.2927e-04 - val_loss: 2.8278e-04\n",
      "Epoch 778/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.2638e-04 - val_loss: 2.6937e-04\n",
      "Epoch 779/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.4711e-04 - val_loss: 2.6695e-04\n",
      "Epoch 780/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.3110e-04 - val_loss: 2.8126e-04\n",
      "Epoch 781/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.3461e-04 - val_loss: 3.8002e-04\n",
      "Epoch 782/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.5819e-04 - val_loss: 2.8068e-04\n",
      "Epoch 783/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.2383e-04 - val_loss: 2.7065e-04\n",
      "Epoch 784/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.1857e-04 - val_loss: 3.0810e-04\n",
      "Epoch 785/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.1738e-04 - val_loss: 2.7221e-04\n",
      "Epoch 786/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.1748e-04 - val_loss: 2.9352e-04\n",
      "Epoch 787/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.2782e-04 - val_loss: 2.7217e-04\n",
      "Epoch 788/2000\n",
      "4059/4059 [==============================] - 3s 625us/step - loss: 3.2709e-04 - val_loss: 3.8516e-04\n",
      "Epoch 789/2000\n",
      "4059/4059 [==============================] - 2s 611us/step - loss: 3.9149e-04 - val_loss: 3.8850e-04\n",
      "Epoch 790/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4486e-04 - val_loss: 3.5046e-04\n",
      "Epoch 791/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.7304e-04 - val_loss: 2.7239e-04\n",
      "Epoch 792/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.4434e-04 - val_loss: 3.1146e-04\n",
      "Epoch 793/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.1967e-04 - val_loss: 2.8026e-04\n",
      "Epoch 794/2000\n",
      "4059/4059 [==============================] - 3s 623us/step - loss: 3.3206e-04 - val_loss: 2.7992e-04\n",
      "Epoch 795/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.5072e-04 - val_loss: 2.9238e-04\n",
      "Epoch 796/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.5025e-04 - val_loss: 3.0093e-04\n",
      "Epoch 797/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.3576e-04 - val_loss: 2.7791e-04\n",
      "Epoch 798/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.3773e-04 - val_loss: 2.7724e-04\n",
      "Epoch 799/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.2597e-04 - val_loss: 3.0262e-04\n",
      "Epoch 800/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.1240e-04 - val_loss: 2.6614e-04\n",
      "Epoch 801/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.2277e-04 - val_loss: 2.7478e-04\n",
      "Epoch 802/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.1957e-04 - val_loss: 2.6809e-04\n",
      "Epoch 803/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.1660e-04 - val_loss: 3.2572e-04\n",
      "Epoch 804/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.2480e-04 - val_loss: 2.8044e-04\n",
      "Epoch 805/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.1970e-04 - val_loss: 2.6558e-04\n",
      "Epoch 806/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.0648e-04 - val_loss: 2.8088e-04\n",
      "Epoch 807/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 3.2727e-04 - val_loss: 3.8063e-04\n",
      "Epoch 808/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.5393e-04 - val_loss: 2.8891e-04\n",
      "Epoch 809/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.6240e-04 - val_loss: 3.1035e-04\n",
      "Epoch 810/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.2552e-04 - val_loss: 2.6606e-04\n",
      "Epoch 811/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.1497e-04 - val_loss: 2.9385e-04\n",
      "Epoch 812/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.1147e-04 - val_loss: 2.8954e-04\n",
      "Epoch 813/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.0655e-04 - val_loss: 2.8322e-04\n",
      "Epoch 814/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.6044e-04 - val_loss: 2.6590e-04\n",
      "Epoch 815/2000\n",
      "4059/4059 [==============================] - 2s 611us/step - loss: 3.3906e-04 - val_loss: 3.5696e-04\n",
      "Epoch 816/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.6038e-04 - val_loss: 2.6341e-04\n",
      "Epoch 817/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.5988e-04 - val_loss: 3.1601e-04\n",
      "Epoch 818/2000\n",
      "4059/4059 [==============================] - 2s 611us/step - loss: 3.4413e-04 - val_loss: 3.1415e-04\n",
      "Epoch 819/2000\n",
      "4059/4059 [==============================] - 2s 611us/step - loss: 3.4429e-04 - val_loss: 2.7914e-04\n",
      "Epoch 820/2000\n",
      "4059/4059 [==============================] - 3s 623us/step - loss: 3.3808e-04 - val_loss: 3.4198e-04\n",
      "Epoch 821/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.4980e-04 - val_loss: 2.8086e-04\n",
      "Epoch 822/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4750e-04 - val_loss: 3.1152e-04\n",
      "Epoch 823/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.7772e-04 - val_loss: 5.3256e-04\n",
      "Epoch 824/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.8766e-04 - val_loss: 3.2275e-04\n",
      "Epoch 825/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.6106e-04 - val_loss: 2.8534e-04\n",
      "Epoch 826/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.3440e-04 - val_loss: 3.5945e-04\n",
      "Epoch 827/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.3596e-04 - val_loss: 2.6475e-04\n",
      "Epoch 828/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.4271e-04 - val_loss: 2.7032e-04\n",
      "Epoch 829/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.6014e-04 - val_loss: 3.8241e-04\n",
      "Epoch 830/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.6162e-04 - val_loss: 3.8713e-04\n",
      "Epoch 831/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.3231e-04 - val_loss: 2.7374e-04\n",
      "Epoch 832/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.2225e-04 - val_loss: 2.7681e-04\n",
      "Epoch 833/2000\n",
      "4059/4059 [==============================] - 3s 630us/step - loss: 3.3466e-04 - val_loss: 2.7231e-04\n",
      "Epoch 834/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.2631e-04 - val_loss: 2.8824e-04\n",
      "Epoch 835/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 3.4500e-04 - val_loss: 2.6386e-04\n",
      "Epoch 836/2000\n",
      "4059/4059 [==============================] - 3s 631us/step - loss: 3.5141e-04 - val_loss: 3.1600e-04\n",
      "Epoch 837/2000\n",
      "4059/4059 [==============================] - 3s 637us/step - loss: 3.6620e-04 - val_loss: 3.8255e-04\n",
      "Epoch 838/2000\n",
      "4059/4059 [==============================] - 3s 633us/step - loss: 4.0934e-04 - val_loss: 6.1377e-04\n",
      "Epoch 839/2000\n",
      "4059/4059 [==============================] - 3s 641us/step - loss: 4.3555e-04 - val_loss: 3.2592e-04\n",
      "Epoch 840/2000\n",
      "4059/4059 [==============================] - 3s 631us/step - loss: 3.4560e-04 - val_loss: 2.7210e-04\n",
      "Epoch 841/2000\n",
      "4059/4059 [==============================] - 3s 625us/step - loss: 3.3617e-04 - val_loss: 2.6204e-04\n",
      "Epoch 842/2000\n",
      "4059/4059 [==============================] - 3s 627us/step - loss: 3.2697e-04 - val_loss: 2.7300e-04\n",
      "Epoch 843/2000\n",
      "4059/4059 [==============================] - 3s 633us/step - loss: 3.0539e-04 - val_loss: 3.7855e-04\n",
      "Epoch 844/2000\n",
      "4059/4059 [==============================] - 3s 636us/step - loss: 3.5272e-04 - val_loss: 3.0554e-04\n",
      "Epoch 845/2000\n",
      "4059/4059 [==============================] - 3s 636us/step - loss: 3.4335e-04 - val_loss: 3.5641e-04\n",
      "Epoch 846/2000\n",
      "4059/4059 [==============================] - 3s 632us/step - loss: 4.0432e-04 - val_loss: 2.8705e-04\n",
      "Epoch 847/2000\n",
      "4059/4059 [==============================] - 3s 644us/step - loss: 3.6803e-04 - val_loss: 2.8812e-04\n",
      "Epoch 848/2000\n",
      "4059/4059 [==============================] - 3s 652us/step - loss: 3.5695e-04 - val_loss: 2.7215e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 849/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.4851e-04 - val_loss: 2.8159e-04\n",
      "Epoch 850/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.3172e-04 - val_loss: 3.0681e-04\n",
      "Epoch 851/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 3.3338e-04 - val_loss: 3.0400e-04\n",
      "Epoch 852/2000\n",
      "4059/4059 [==============================] - 2s 606us/step - loss: 3.2230e-04 - val_loss: 3.0644e-04\n",
      "Epoch 853/2000\n",
      "4059/4059 [==============================] - 2s 606us/step - loss: 3.1601e-04 - val_loss: 2.6532e-04\n",
      "Epoch 854/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.1798e-04 - val_loss: 3.6552e-04\n",
      "Epoch 855/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2717e-04 - val_loss: 2.8847e-04\n",
      "Epoch 856/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.2791e-04 - val_loss: 2.6996e-04\n",
      "Epoch 857/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.2918e-04 - val_loss: 3.2430e-04\n",
      "Epoch 858/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.4562e-04 - val_loss: 2.8233e-04\n",
      "Epoch 859/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.4974e-04 - val_loss: 2.7300e-04\n",
      "Epoch 860/2000\n",
      "4059/4059 [==============================] - 2s 608us/step - loss: 3.3710e-04 - val_loss: 4.1085e-04\n",
      "Epoch 861/2000\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 3.3564e-04 - val_loss: 2.6716e-04\n",
      "Epoch 862/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.5884e-04 - val_loss: 2.6821e-04\n",
      "Epoch 863/2000\n",
      "4059/4059 [==============================] - 2s 608us/step - loss: 3.2398e-04 - val_loss: 2.8775e-04\n",
      "Epoch 864/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.2181e-04 - val_loss: 2.7346e-04\n",
      "Epoch 865/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.1970e-04 - val_loss: 2.6880e-04\n",
      "Epoch 866/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1264e-04 - val_loss: 3.0651e-04\n",
      "Epoch 867/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.1778e-04 - val_loss: 2.6684e-04\n",
      "Epoch 868/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.0903e-04 - val_loss: 3.0044e-04\n",
      "Epoch 869/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1776e-04 - val_loss: 2.6629e-04\n",
      "Epoch 870/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.2760e-04 - val_loss: 2.9092e-04\n",
      "Epoch 871/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.3585e-04 - val_loss: 3.0555e-04\n",
      "Epoch 872/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 3.3155e-04 - val_loss: 3.0816e-04\n",
      "Epoch 873/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.3801e-04 - val_loss: 2.8477e-04\n",
      "Epoch 874/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.3325e-04 - val_loss: 3.5825e-04\n",
      "Epoch 875/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2469e-04 - val_loss: 2.6376e-04\n",
      "Epoch 876/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.2834e-04 - val_loss: 2.6093e-04\n",
      "Epoch 877/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.4247e-04 - val_loss: 2.6630e-04\n",
      "Epoch 878/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.6740e-04 - val_loss: 3.3013e-04\n",
      "Epoch 879/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.1680e-04 - val_loss: 2.8020e-04\n",
      "Epoch 880/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.2022e-04 - val_loss: 2.8594e-04\n",
      "Epoch 881/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.3931e-04 - val_loss: 3.1764e-04\n",
      "Epoch 882/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.3050e-04 - val_loss: 2.6811e-04\n",
      "Epoch 883/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.1583e-04 - val_loss: 2.7985e-04\n",
      "Epoch 884/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.2499e-04 - val_loss: 2.6632e-04\n",
      "Epoch 885/2000\n",
      "4059/4059 [==============================] - 2s 609us/step - loss: 3.4937e-04 - val_loss: 2.6812e-04\n",
      "Epoch 886/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.2335e-04 - val_loss: 3.0501e-04\n",
      "Epoch 887/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.2076e-04 - val_loss: 2.7014e-04\n",
      "Epoch 888/2000\n",
      "4059/4059 [==============================] - 3s 624us/step - loss: 3.1923e-04 - val_loss: 2.8984e-04\n",
      "Epoch 889/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.4409e-04 - val_loss: 2.8310e-04\n",
      "Epoch 890/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.5839e-04 - val_loss: 3.3238e-04\n",
      "Epoch 891/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.1948e-04 - val_loss: 3.1085e-04\n",
      "Epoch 892/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.0902e-04 - val_loss: 3.3343e-04\n",
      "Epoch 893/2000\n",
      "4059/4059 [==============================] - 3s 616us/step - loss: 3.4507e-04 - val_loss: 2.8705e-04\n",
      "Epoch 894/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.2583e-04 - val_loss: 2.8722e-04\n",
      "Epoch 895/2000\n",
      "4059/4059 [==============================] - 2s 609us/step - loss: 3.1732e-04 - val_loss: 2.6587e-04\n",
      "Epoch 896/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 3.1945e-04 - val_loss: 3.8904e-04\n",
      "Epoch 897/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.3670e-04 - val_loss: 2.8595e-04\n",
      "Epoch 898/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.5206e-04 - val_loss: 3.8099e-04\n",
      "Epoch 899/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.5482e-04 - val_loss: 3.5991e-04\n",
      "Epoch 900/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.2701e-04 - val_loss: 2.8851e-04\n",
      "Epoch 901/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 3.1307e-04 - val_loss: 2.6586e-04\n",
      "Epoch 902/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 3.1144e-04 - val_loss: 5.0252e-04\n",
      "Epoch 903/2000\n",
      "4059/4059 [==============================] - 3s 620us/step - loss: 3.7251e-04 - val_loss: 3.5088e-04\n",
      "Epoch 904/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.2477e-04 - val_loss: 3.2705e-04\n",
      "Epoch 905/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.4780e-04 - val_loss: 4.0918e-04\n",
      "Epoch 906/2000\n",
      "4059/4059 [==============================] - 2s 609us/step - loss: 3.3446e-04 - val_loss: 2.6457e-04\n",
      "Epoch 907/2000\n",
      "4059/4059 [==============================] - 2s 611us/step - loss: 3.5291e-04 - val_loss: 2.6436e-04\n",
      "Epoch 908/2000\n",
      "4059/4059 [==============================] - 2s 608us/step - loss: 3.1984e-04 - val_loss: 2.6865e-04\n",
      "Epoch 909/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.5372e-04 - val_loss: 3.2534e-04\n",
      "Epoch 910/2000\n",
      "4059/4059 [==============================] - 3s 623us/step - loss: 3.3235e-04 - val_loss: 2.8429e-04\n",
      "Epoch 911/2000\n",
      "4059/4059 [==============================] - 2s 607us/step - loss: 3.1727e-04 - val_loss: 2.7034e-04\n",
      "Epoch 912/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.1639e-04 - val_loss: 2.6467e-04\n",
      "Epoch 913/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.1283e-04 - val_loss: 3.4735e-04\n",
      "Epoch 914/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.2421e-04 - val_loss: 2.6551e-04\n",
      "Epoch 915/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.3726e-04 - val_loss: 2.6851e-04\n",
      "Epoch 916/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.3596e-04 - val_loss: 2.6211e-04\n",
      "Epoch 917/2000\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 3.4126e-04 - val_loss: 4.1146e-04\n",
      "Epoch 918/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 4.5214e-04 - val_loss: 3.5762e-04\n",
      "Epoch 919/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 615us/step - loss: 4.4187e-04 - val_loss: 6.6665e-04\n",
      "Epoch 920/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.7062e-04 - val_loss: 3.1889e-04\n",
      "Epoch 921/2000\n",
      "4059/4059 [==============================] - 2s 605us/step - loss: 3.2718e-04 - val_loss: 2.7032e-04\n",
      "Epoch 922/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.3817e-04 - val_loss: 2.7368e-04\n",
      "Epoch 923/2000\n",
      "4059/4059 [==============================] - 2s 610us/step - loss: 3.4862e-04 - val_loss: 3.6192e-04\n",
      "Epoch 924/2000\n",
      "4059/4059 [==============================] - 2s 615us/step - loss: 3.4396e-04 - val_loss: 2.8473e-04\n",
      "Epoch 925/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.1984e-04 - val_loss: 2.9286e-04\n",
      "Epoch 926/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 3.5902e-04 - val_loss: 2.6609e-04\n",
      "Epoch 927/2000\n",
      "4059/4059 [==============================] - 2s 611us/step - loss: 3.2199e-04 - val_loss: 2.7081e-04\n",
      "Epoch 928/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 3.3591e-04 - val_loss: 4.6507e-04\n",
      "Epoch 929/2000\n",
      "4059/4059 [==============================] - 2s 606us/step - loss: 3.4247e-04 - val_loss: 3.0907e-04\n",
      "Epoch 930/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.1525e-04 - val_loss: 2.7749e-04\n",
      "Epoch 931/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.1221e-04 - val_loss: 2.6504e-04\n",
      "Epoch 932/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.1567e-04 - val_loss: 3.1783e-04\n",
      "Epoch 933/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.1503e-04 - val_loss: 2.7121e-04\n",
      "Epoch 934/2000\n",
      "4059/4059 [==============================] - 2s 606us/step - loss: 3.1439e-04 - val_loss: 3.2873e-04\n",
      "Epoch 935/2000\n",
      "4059/4059 [==============================] - 2s 606us/step - loss: 3.2487e-04 - val_loss: 2.9482e-04\n",
      "Epoch 936/2000\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 3.4723e-04 - val_loss: 2.7133e-04\n",
      "Epoch 937/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.3987e-04 - val_loss: 4.1540e-04\n",
      "Epoch 938/2000\n",
      "4059/4059 [==============================] - 2s 605us/step - loss: 3.3309e-04 - val_loss: 2.6282e-04\n",
      "Epoch 939/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.1340e-04 - val_loss: 2.8828e-04\n",
      "Epoch 940/2000\n",
      "4059/4059 [==============================] - 2s 612us/step - loss: 3.5417e-04 - val_loss: 2.8431e-04\n",
      "Epoch 941/2000\n",
      "4059/4059 [==============================] - 2s 608us/step - loss: 3.1618e-04 - val_loss: 2.9158e-04\n",
      "Epoch 942/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.5723e-04 - val_loss: 2.6250e-04\n",
      "Epoch 943/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 4.1215e-04 - val_loss: 3.4174e-04\n",
      "Epoch 944/2000\n",
      "4059/4059 [==============================] - 2s 611us/step - loss: 3.3295e-04 - val_loss: 2.7380e-04\n",
      "Epoch 945/2000\n",
      "4059/4059 [==============================] - 2s 611us/step - loss: 3.1270e-04 - val_loss: 2.6289e-04\n",
      "Epoch 946/2000\n",
      "4059/4059 [==============================] - 2s 609us/step - loss: 3.1292e-04 - val_loss: 2.6912e-04\n",
      "Epoch 947/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 3.1447e-04 - val_loss: 2.6705e-04\n",
      "Epoch 948/2000\n",
      "4059/4059 [==============================] - 2s 609us/step - loss: 3.1672e-04 - val_loss: 3.4608e-04\n",
      "Epoch 949/2000\n",
      "4059/4059 [==============================] - 3s 636us/step - loss: 3.0846e-04 - val_loss: 2.6302e-04\n",
      "Epoch 950/2000\n",
      "4059/4059 [==============================] - 3s 625us/step - loss: 3.0792e-04 - val_loss: 2.6167e-04\n",
      "Epoch 951/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.0347e-04 - val_loss: 2.6462e-04\n",
      "Epoch 952/2000\n",
      "4059/4059 [==============================] - 2s 605us/step - loss: 3.0752e-04 - val_loss: 2.8308e-04\n",
      "Epoch 953/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.2577e-04 - val_loss: 2.7014e-04\n",
      "Epoch 954/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.2254e-04 - val_loss: 2.8505e-04\n",
      "Epoch 955/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.2268e-04 - val_loss: 2.7875e-04\n",
      "Epoch 956/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.0835e-04 - val_loss: 2.8071e-04\n",
      "Epoch 957/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.1546e-04 - val_loss: 2.9507e-04\n",
      "Epoch 958/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0985e-04 - val_loss: 2.9135e-04\n",
      "Epoch 959/2000\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 3.1007e-04 - val_loss: 2.6448e-04\n",
      "Epoch 960/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.0659e-04 - val_loss: 2.7339e-04\n",
      "Epoch 961/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.1602e-04 - val_loss: 2.6629e-04\n",
      "Epoch 962/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.1169e-04 - val_loss: 2.8713e-04\n",
      "Epoch 963/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.1502e-04 - val_loss: 3.5210e-04\n",
      "Epoch 964/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.1791e-04 - val_loss: 2.7275e-04\n",
      "Epoch 965/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.1849e-04 - val_loss: 3.0759e-04\n",
      "Epoch 966/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.2301e-04 - val_loss: 2.6225e-04\n",
      "Epoch 967/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.0583e-04 - val_loss: 2.5869e-04\n",
      "Epoch 968/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.0743e-04 - val_loss: 2.8510e-04\n",
      "Epoch 969/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.0622e-04 - val_loss: 3.9341e-04\n",
      "Epoch 970/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.4214e-04 - val_loss: 3.7180e-04\n",
      "Epoch 971/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.8006e-04 - val_loss: 2.9576e-04\n",
      "Epoch 972/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.4612e-04 - val_loss: 3.1472e-04\n",
      "Epoch 973/2000\n",
      "4059/4059 [==============================] - 2s 611us/step - loss: 3.1229e-04 - val_loss: 2.9573e-04\n",
      "Epoch 974/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.3949e-04 - val_loss: 3.6005e-04\n",
      "Epoch 975/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.2062e-04 - val_loss: 2.7605e-04\n",
      "Epoch 976/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.2480e-04 - val_loss: 4.4601e-04\n",
      "Epoch 977/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.3339e-04 - val_loss: 3.5065e-04\n",
      "Epoch 978/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.1589e-04 - val_loss: 3.2776e-04\n",
      "Epoch 979/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.2200e-04 - val_loss: 2.6382e-04\n",
      "Epoch 980/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.2522e-04 - val_loss: 2.7101e-04\n",
      "Epoch 981/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.1349e-04 - val_loss: 2.7210e-04\n",
      "Epoch 982/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.0182e-04 - val_loss: 2.6621e-04\n",
      "Epoch 983/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.2762e-04 - val_loss: 2.6013e-04\n",
      "Epoch 984/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.2383e-04 - val_loss: 2.9855e-04\n",
      "Epoch 985/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.6020e-04 - val_loss: 3.5577e-04\n",
      "Epoch 986/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 3.2576e-04 - val_loss: 3.0565e-04\n",
      "Epoch 987/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.3981e-04 - val_loss: 2.6912e-04\n",
      "Epoch 988/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.1817e-04 - val_loss: 3.5299e-04\n",
      "Epoch 989/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.2183e-04 - val_loss: 2.6047e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 990/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.1290e-04 - val_loss: 3.0520e-04\n",
      "Epoch 991/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0953e-04 - val_loss: 2.6609e-04\n",
      "Epoch 992/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.1323e-04 - val_loss: 2.6321e-04\n",
      "Epoch 993/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.9741e-04 - val_loss: 2.6622e-04\n",
      "Epoch 994/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.1480e-04 - val_loss: 2.6211e-04\n",
      "Epoch 995/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.2369e-04 - val_loss: 2.7052e-04\n",
      "Epoch 996/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.1309e-04 - val_loss: 2.8541e-04\n",
      "Epoch 997/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0255e-04 - val_loss: 2.6233e-04\n",
      "Epoch 998/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.1425e-04 - val_loss: 2.6628e-04\n",
      "Epoch 999/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.2001e-04 - val_loss: 3.0495e-04\n",
      "Epoch 1000/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.6975e-04 - val_loss: 4.7648e-04\n",
      "Epoch 1001/2000\n",
      "4059/4059 [==============================] - 2s 607us/step - loss: 3.6307e-04 - val_loss: 2.5871e-04\n",
      "Epoch 1002/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.4142e-04 - val_loss: 3.0060e-04\n",
      "Epoch 1003/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.2346e-04 - val_loss: 3.2587e-04\n",
      "Epoch 1004/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.5869e-04 - val_loss: 3.7907e-04\n",
      "Epoch 1005/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.2601e-04 - val_loss: 3.0816e-04\n",
      "Epoch 1006/2000\n",
      "4059/4059 [==============================] - 2s 614us/step - loss: 3.3577e-04 - val_loss: 2.6920e-04\n",
      "Epoch 1007/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 3.0708e-04 - val_loss: 2.6600e-04\n",
      "Epoch 1008/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.3056e-04 - val_loss: 3.5382e-04\n",
      "Epoch 1009/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.2884e-04 - val_loss: 3.4053e-04\n",
      "Epoch 1010/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.4080e-04 - val_loss: 2.8687e-04\n",
      "Epoch 1011/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.0915e-04 - val_loss: 2.8157e-04\n",
      "Epoch 1012/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.2856e-04 - val_loss: 2.6229e-04\n",
      "Epoch 1013/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.4394e-04 - val_loss: 4.1715e-04\n",
      "Epoch 1014/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.2593e-04 - val_loss: 3.4283e-04\n",
      "Epoch 1015/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.2628e-04 - val_loss: 2.6703e-04\n",
      "Epoch 1016/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.3520e-04 - val_loss: 2.7937e-04\n",
      "Epoch 1017/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.1611e-04 - val_loss: 2.6001e-04\n",
      "Epoch 1018/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.3381e-04 - val_loss: 2.6633e-04\n",
      "Epoch 1019/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.4216e-04 - val_loss: 3.4143e-04\n",
      "Epoch 1020/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.4078e-04 - val_loss: 2.6659e-04\n",
      "Epoch 1021/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.1200e-04 - val_loss: 3.8728e-04\n",
      "Epoch 1022/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 4.0820e-04 - val_loss: 3.5750e-04\n",
      "Epoch 1023/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.9203e-04 - val_loss: 5.1790e-04\n",
      "Epoch 1024/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.8236e-04 - val_loss: 2.5488e-04\n",
      "Epoch 1025/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.2503e-04 - val_loss: 2.7151e-04\n",
      "Epoch 1026/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0563e-04 - val_loss: 2.7878e-04\n",
      "Epoch 1027/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.1433e-04 - val_loss: 4.1446e-04\n",
      "Epoch 1028/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.3019e-04 - val_loss: 2.6586e-04\n",
      "Epoch 1029/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.0943e-04 - val_loss: 2.6924e-04\n",
      "Epoch 1030/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.0980e-04 - val_loss: 3.0447e-04\n",
      "Epoch 1031/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.3087e-04 - val_loss: 2.8211e-04\n",
      "Epoch 1032/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.2387e-04 - val_loss: 3.4024e-04\n",
      "Epoch 1033/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.2958e-04 - val_loss: 2.8690e-04\n",
      "Epoch 1034/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.1769e-04 - val_loss: 2.6919e-04\n",
      "Epoch 1035/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.0907e-04 - val_loss: 2.7132e-04\n",
      "Epoch 1036/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.2291e-04 - val_loss: 3.2867e-04\n",
      "Epoch 1037/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.1693e-04 - val_loss: 2.6846e-04\n",
      "Epoch 1038/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.3768e-04 - val_loss: 3.1211e-04\n",
      "Epoch 1039/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.2841e-04 - val_loss: 3.9804e-04\n",
      "Epoch 1040/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.3309e-04 - val_loss: 2.6474e-04\n",
      "Epoch 1041/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.1572e-04 - val_loss: 2.7429e-04\n",
      "Epoch 1042/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.1199e-04 - val_loss: 2.6233e-04\n",
      "Epoch 1043/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1907e-04 - val_loss: 2.8853e-04\n",
      "Epoch 1044/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1614e-04 - val_loss: 3.0434e-04\n",
      "Epoch 1045/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1881e-04 - val_loss: 3.3755e-04\n",
      "Epoch 1046/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.1422e-04 - val_loss: 3.2901e-04\n",
      "Epoch 1047/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.3549e-04 - val_loss: 2.6401e-04\n",
      "Epoch 1048/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.3079e-04 - val_loss: 3.8032e-04\n",
      "Epoch 1049/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.4730e-04 - val_loss: 2.7235e-04\n",
      "Epoch 1050/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.2340e-04 - val_loss: 3.0077e-04\n",
      "Epoch 1051/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.1894e-04 - val_loss: 3.5342e-04\n",
      "Epoch 1052/2000\n",
      "4059/4059 [==============================] - 2s 607us/step - loss: 3.3292e-04 - val_loss: 2.6532e-04\n",
      "Epoch 1053/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.4065e-04 - val_loss: 2.7711e-04\n",
      "Epoch 1054/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.2485e-04 - val_loss: 2.6655e-04\n",
      "Epoch 1055/2000\n",
      "4059/4059 [==============================] - 2s 605us/step - loss: 3.3317e-04 - val_loss: 2.9082e-04\n",
      "Epoch 1056/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.2026e-04 - val_loss: 2.9798e-04\n",
      "Epoch 1057/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.0447e-04 - val_loss: 3.9847e-04\n",
      "Epoch 1058/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.2688e-04 - val_loss: 4.1570e-04\n",
      "Epoch 1059/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.3648e-04 - val_loss: 2.6131e-04\n",
      "Epoch 1060/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.2825e-04 - val_loss: 3.4069e-04\n",
      "Epoch 1061/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.1191e-04 - val_loss: 2.7765e-04\n",
      "Epoch 1062/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.2010e-04 - val_loss: 2.7296e-04\n",
      "Epoch 1063/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.9791e-04 - val_loss: 2.6341e-04\n",
      "Epoch 1064/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.0140e-04 - val_loss: 2.6378e-04\n",
      "Epoch 1065/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.9615e-04 - val_loss: 2.6524e-04\n",
      "Epoch 1066/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.0621e-04 - val_loss: 2.6787e-04\n",
      "Epoch 1067/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.0497e-04 - val_loss: 3.3198e-04\n",
      "Epoch 1068/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.0542e-04 - val_loss: 3.0110e-04\n",
      "Epoch 1069/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.0423e-04 - val_loss: 3.2532e-04\n",
      "Epoch 1070/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.0645e-04 - val_loss: 2.7122e-04\n",
      "Epoch 1071/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.2042e-04 - val_loss: 3.0051e-04\n",
      "Epoch 1072/2000\n",
      "4059/4059 [==============================] - 2s 610us/step - loss: 3.0658e-04 - val_loss: 3.0518e-04\n",
      "Epoch 1073/2000\n",
      "4059/4059 [==============================] - 3s 619us/step - loss: 3.3456e-04 - val_loss: 3.8878e-04\n",
      "Epoch 1074/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.0481e-04 - val_loss: 2.6816e-04\n",
      "Epoch 1075/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.0621e-04 - val_loss: 2.7338e-04\n",
      "Epoch 1076/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.4273e-04 - val_loss: 3.3500e-04\n",
      "Epoch 1077/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.3155e-04 - val_loss: 2.8996e-04\n",
      "Epoch 1078/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.3343e-04 - val_loss: 2.5813e-04\n",
      "Epoch 1079/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.0318e-04 - val_loss: 2.6003e-04\n",
      "Epoch 1080/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.0747e-04 - val_loss: 3.1091e-04\n",
      "Epoch 1081/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.1573e-04 - val_loss: 2.8390e-04\n",
      "Epoch 1082/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1413e-04 - val_loss: 2.8456e-04\n",
      "Epoch 1083/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.1623e-04 - val_loss: 2.6489e-04\n",
      "Epoch 1084/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.9706e-04 - val_loss: 2.7760e-04\n",
      "Epoch 1085/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0793e-04 - val_loss: 2.6217e-04\n",
      "Epoch 1086/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0387e-04 - val_loss: 3.0181e-04\n",
      "Epoch 1087/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.1778e-04 - val_loss: 3.1402e-04\n",
      "Epoch 1088/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.3673e-04 - val_loss: 2.7902e-04\n",
      "Epoch 1089/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 3.0335e-04 - val_loss: 2.5991e-04\n",
      "Epoch 1090/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2551e-04 - val_loss: 4.0787e-04\n",
      "Epoch 1091/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2406e-04 - val_loss: 4.6096e-04\n",
      "Epoch 1092/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.3500e-04 - val_loss: 2.6487e-04\n",
      "Epoch 1093/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.0718e-04 - val_loss: 3.0954e-04\n",
      "Epoch 1094/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1800e-04 - val_loss: 2.6108e-04\n",
      "Epoch 1095/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.9922e-04 - val_loss: 2.6450e-04\n",
      "Epoch 1096/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.9968e-04 - val_loss: 2.7516e-04\n",
      "Epoch 1097/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9158e-04 - val_loss: 2.7243e-04\n",
      "Epoch 1098/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1535e-04 - val_loss: 2.7072e-04\n",
      "Epoch 1099/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.1620e-04 - val_loss: 3.3009e-04\n",
      "Epoch 1100/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.3381e-04 - val_loss: 2.7296e-04\n",
      "Epoch 1101/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.1712e-04 - val_loss: 2.6055e-04\n",
      "Epoch 1102/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.0838e-04 - val_loss: 2.6630e-04\n",
      "Epoch 1103/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.9931e-04 - val_loss: 2.6058e-04\n",
      "Epoch 1104/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.2657e-04 - val_loss: 3.0162e-04\n",
      "Epoch 1105/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.0820e-04 - val_loss: 3.9701e-04\n",
      "Epoch 1106/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.3285e-04 - val_loss: 2.9263e-04\n",
      "Epoch 1107/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.4447e-04 - val_loss: 2.9443e-04\n",
      "Epoch 1108/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.1142e-04 - val_loss: 2.6429e-04\n",
      "Epoch 1109/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 3.1797e-04 - val_loss: 3.7147e-04\n",
      "Epoch 1110/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.4640e-04 - val_loss: 4.0036e-04\n",
      "Epoch 1111/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.3847e-04 - val_loss: 2.7712e-04\n",
      "Epoch 1112/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0802e-04 - val_loss: 2.6468e-04\n",
      "Epoch 1113/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0896e-04 - val_loss: 2.7569e-04\n",
      "Epoch 1114/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 3.0962e-04 - val_loss: 2.6161e-04\n",
      "Epoch 1115/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.9634e-04 - val_loss: 2.6079e-04\n",
      "Epoch 1116/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0978e-04 - val_loss: 2.6481e-04\n",
      "Epoch 1117/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.0047e-04 - val_loss: 2.7026e-04\n",
      "Epoch 1118/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 3.1150e-04 - val_loss: 2.6098e-04\n",
      "Epoch 1119/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 3.1765e-04 - val_loss: 3.6363e-04\n",
      "Epoch 1120/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.3580e-04 - val_loss: 4.6879e-04\n",
      "Epoch 1121/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 3.4559e-04 - val_loss: 2.6938e-04\n",
      "Epoch 1122/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.1615e-04 - val_loss: 2.5986e-04\n",
      "Epoch 1123/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.0977e-04 - val_loss: 2.6640e-04\n",
      "Epoch 1124/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2488e-04 - val_loss: 3.3771e-04\n",
      "Epoch 1125/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.3172e-04 - val_loss: 2.5945e-04\n",
      "Epoch 1126/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2099e-04 - val_loss: 4.0201e-04\n",
      "Epoch 1127/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1453e-04 - val_loss: 3.4044e-04\n",
      "Epoch 1128/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.2322e-04 - val_loss: 2.6175e-04\n",
      "Epoch 1129/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0936e-04 - val_loss: 2.9474e-04\n",
      "Epoch 1130/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.5111e-04 - val_loss: 3.7526e-04\n",
      "Epoch 1131/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.5217e-04 - val_loss: 2.7509e-04\n",
      "Epoch 1132/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.3528e-04 - val_loss: 2.7160e-04\n",
      "Epoch 1133/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.2068e-04 - val_loss: 2.7100e-04\n",
      "Epoch 1134/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.1750e-04 - val_loss: 2.6733e-04\n",
      "Epoch 1135/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.0996e-04 - val_loss: 2.6850e-04\n",
      "Epoch 1136/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.2798e-04 - val_loss: 2.6961e-04\n",
      "Epoch 1137/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.2401e-04 - val_loss: 2.8587e-04\n",
      "Epoch 1138/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1432e-04 - val_loss: 2.6087e-04\n",
      "Epoch 1139/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.0303e-04 - val_loss: 2.7898e-04\n",
      "Epoch 1140/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.1217e-04 - val_loss: 2.6262e-04\n",
      "Epoch 1141/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.0238e-04 - val_loss: 4.1737e-04\n",
      "Epoch 1142/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 3.2283e-04 - val_loss: 2.7126e-04\n",
      "Epoch 1143/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0792e-04 - val_loss: 2.9463e-04\n",
      "Epoch 1144/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.2838e-04 - val_loss: 2.8176e-04\n",
      "Epoch 1145/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1363e-04 - val_loss: 2.6318e-04\n",
      "Epoch 1146/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.3924e-04 - val_loss: 2.7844e-04\n",
      "Epoch 1147/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.1731e-04 - val_loss: 3.3394e-04\n",
      "Epoch 1148/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1614e-04 - val_loss: 2.6611e-04\n",
      "Epoch 1149/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0939e-04 - val_loss: 2.6617e-04\n",
      "Epoch 1150/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2953e-04 - val_loss: 3.2736e-04\n",
      "Epoch 1151/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.3362e-04 - val_loss: 2.6652e-04\n",
      "Epoch 1152/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.2054e-04 - val_loss: 3.5027e-04\n",
      "Epoch 1153/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.3098e-04 - val_loss: 2.6513e-04\n",
      "Epoch 1154/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.1090e-04 - val_loss: 3.4828e-04\n",
      "Epoch 1155/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.2804e-04 - val_loss: 2.6157e-04\n",
      "Epoch 1156/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.6980e-04 - val_loss: 3.3664e-04\n",
      "Epoch 1157/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.2033e-04 - val_loss: 2.5836e-04\n",
      "Epoch 1158/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.0157e-04 - val_loss: 3.1443e-04\n",
      "Epoch 1159/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0745e-04 - val_loss: 2.6345e-04\n",
      "Epoch 1160/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9782e-04 - val_loss: 2.7771e-04\n",
      "Epoch 1161/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0099e-04 - val_loss: 2.8877e-04\n",
      "Epoch 1162/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.1535e-04 - val_loss: 2.7036e-04\n",
      "Epoch 1163/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.0250e-04 - val_loss: 2.6692e-04\n",
      "Epoch 1164/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.4188e-04 - val_loss: 3.2351e-04\n",
      "Epoch 1165/2000\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 3.3913e-04 - val_loss: 2.6264e-04\n",
      "Epoch 1166/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.2159e-04 - val_loss: 2.8823e-04\n",
      "Epoch 1167/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0149e-04 - val_loss: 2.9326e-04\n",
      "Epoch 1168/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.1337e-04 - val_loss: 2.5835e-04\n",
      "Epoch 1169/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.2342e-04 - val_loss: 2.9737e-04\n",
      "Epoch 1170/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.4780e-04 - val_loss: 2.6114e-04\n",
      "Epoch 1171/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.1399e-04 - val_loss: 2.6026e-04\n",
      "Epoch 1172/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0385e-04 - val_loss: 3.0232e-04\n",
      "Epoch 1173/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.4900e-04 - val_loss: 7.7584e-04\n",
      "Epoch 1174/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.8218e-04 - val_loss: 3.2765e-04\n",
      "Epoch 1175/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1433e-04 - val_loss: 2.7017e-04\n",
      "Epoch 1176/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0079e-04 - val_loss: 2.6037e-04\n",
      "Epoch 1177/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.9661e-04 - val_loss: 2.6304e-04\n",
      "Epoch 1178/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.9930e-04 - val_loss: 2.7335e-04\n",
      "Epoch 1179/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.2633e-04 - val_loss: 3.0216e-04\n",
      "Epoch 1180/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1621e-04 - val_loss: 3.0190e-04\n",
      "Epoch 1181/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.1277e-04 - val_loss: 2.6771e-04\n",
      "Epoch 1182/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.9633e-04 - val_loss: 2.6477e-04\n",
      "Epoch 1183/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0837e-04 - val_loss: 2.5828e-04\n",
      "Epoch 1184/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.9664e-04 - val_loss: 2.6627e-04\n",
      "Epoch 1185/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.0193e-04 - val_loss: 2.7631e-04\n",
      "Epoch 1186/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 3.0592e-04 - val_loss: 2.6515e-04\n",
      "Epoch 1187/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0912e-04 - val_loss: 2.9058e-04\n",
      "Epoch 1188/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2958e-04 - val_loss: 2.7094e-04\n",
      "Epoch 1189/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.5290e-04 - val_loss: 3.4319e-04\n",
      "Epoch 1190/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.2507e-04 - val_loss: 2.6975e-04\n",
      "Epoch 1191/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0601e-04 - val_loss: 2.6897e-04\n",
      "Epoch 1192/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.9947e-04 - val_loss: 2.8441e-04\n",
      "Epoch 1193/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0212e-04 - val_loss: 2.7226e-04\n",
      "Epoch 1194/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 3.0866e-04 - val_loss: 2.6866e-04\n",
      "Epoch 1195/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0476e-04 - val_loss: 2.9352e-04\n",
      "Epoch 1196/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0405e-04 - val_loss: 2.6252e-04\n",
      "Epoch 1197/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.9856e-04 - val_loss: 2.6302e-04\n",
      "Epoch 1198/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.0454e-04 - val_loss: 2.6019e-04\n",
      "Epoch 1199/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.9356e-04 - val_loss: 2.6124e-04\n",
      "Epoch 1200/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.0127e-04 - val_loss: 2.7197e-04\n",
      "Epoch 1201/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0342e-04 - val_loss: 3.2657e-04\n",
      "Epoch 1202/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.1618e-04 - val_loss: 3.5935e-04\n",
      "Epoch 1203/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.4434e-04 - val_loss: 3.1067e-04\n",
      "Epoch 1204/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.2181e-04 - val_loss: 2.7458e-04\n",
      "Epoch 1205/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.9426e-04 - val_loss: 2.6527e-04\n",
      "Epoch 1206/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.9293e-04 - val_loss: 2.6631e-04\n",
      "Epoch 1207/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0752e-04 - val_loss: 2.7146e-04\n",
      "Epoch 1208/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.6241e-04 - val_loss: 4.8380e-04\n",
      "Epoch 1209/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2764e-04 - val_loss: 2.9824e-04\n",
      "Epoch 1210/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0006e-04 - val_loss: 3.3457e-04\n",
      "Epoch 1211/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.3333e-04 - val_loss: 3.6637e-04\n",
      "Epoch 1212/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.2753e-04 - val_loss: 2.7128e-04\n",
      "Epoch 1213/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1297e-04 - val_loss: 2.6526e-04\n",
      "Epoch 1214/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.9904e-04 - val_loss: 2.6020e-04\n",
      "Epoch 1215/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.0221e-04 - val_loss: 2.8176e-04\n",
      "Epoch 1216/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.9745e-04 - val_loss: 3.2565e-04\n",
      "Epoch 1217/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1234e-04 - val_loss: 2.6049e-04\n",
      "Epoch 1218/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.9436e-04 - val_loss: 2.6231e-04\n",
      "Epoch 1219/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.0035e-04 - val_loss: 3.0230e-04\n",
      "Epoch 1220/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.9631e-04 - val_loss: 2.6546e-04\n",
      "Epoch 1221/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1604e-04 - val_loss: 2.6294e-04\n",
      "Epoch 1222/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0942e-04 - val_loss: 2.9022e-04\n",
      "Epoch 1223/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.0650e-04 - val_loss: 3.1243e-04\n",
      "Epoch 1224/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.2315e-04 - val_loss: 2.6915e-04\n",
      "Epoch 1225/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.0412e-04 - val_loss: 2.6223e-04\n",
      "Epoch 1226/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.9290e-04 - val_loss: 2.6025e-04\n",
      "Epoch 1227/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.9262e-04 - val_loss: 2.6046e-04\n",
      "Epoch 1228/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.9817e-04 - val_loss: 2.7003e-04\n",
      "Epoch 1229/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.0146e-04 - val_loss: 2.9357e-04\n",
      "Epoch 1230/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.2247e-04 - val_loss: 2.7997e-04\n",
      "Epoch 1231/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0213e-04 - val_loss: 2.7189e-04\n",
      "Epoch 1232/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.9999e-04 - val_loss: 2.7329e-04\n",
      "Epoch 1233/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.9833e-04 - val_loss: 2.6656e-04\n",
      "Epoch 1234/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0390e-04 - val_loss: 2.9994e-04\n",
      "Epoch 1235/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0763e-04 - val_loss: 3.9193e-04\n",
      "Epoch 1236/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.5523e-04 - val_loss: 2.6615e-04\n",
      "Epoch 1237/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.3557e-04 - val_loss: 2.7396e-04\n",
      "Epoch 1238/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.1142e-04 - val_loss: 2.7583e-04\n",
      "Epoch 1239/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.0403e-04 - val_loss: 2.6972e-04\n",
      "Epoch 1240/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9783e-04 - val_loss: 2.6813e-04\n",
      "Epoch 1241/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.9936e-04 - val_loss: 3.4368e-04\n",
      "Epoch 1242/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0509e-04 - val_loss: 2.9232e-04\n",
      "Epoch 1243/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.0679e-04 - val_loss: 4.0362e-04\n",
      "Epoch 1244/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0734e-04 - val_loss: 2.9661e-04\n",
      "Epoch 1245/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.0424e-04 - val_loss: 2.7061e-04\n",
      "Epoch 1246/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0042e-04 - val_loss: 2.6164e-04\n",
      "Epoch 1247/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.9362e-04 - val_loss: 2.9025e-04\n",
      "Epoch 1248/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.0017e-04 - val_loss: 2.7332e-04\n",
      "Epoch 1249/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.1980e-04 - val_loss: 2.9206e-04\n",
      "Epoch 1250/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.1928e-04 - val_loss: 2.6477e-04\n",
      "Epoch 1251/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.9247e-04 - val_loss: 4.7581e-04\n",
      "Epoch 1252/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.5055e-04 - val_loss: 2.6486e-04\n",
      "Epoch 1253/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.3685e-04 - val_loss: 2.7520e-04\n",
      "Epoch 1254/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.2090e-04 - val_loss: 3.2201e-04\n",
      "Epoch 1255/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1574e-04 - val_loss: 2.7129e-04\n",
      "Epoch 1256/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.9376e-04 - val_loss: 2.6363e-04\n",
      "Epoch 1257/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.8645e-04 - val_loss: 2.7275e-04\n",
      "Epoch 1258/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0548e-04 - val_loss: 2.6981e-04\n",
      "Epoch 1259/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.1435e-04 - val_loss: 3.2666e-04\n",
      "Epoch 1260/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0874e-04 - val_loss: 2.6012e-04\n",
      "Epoch 1261/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.0162e-04 - val_loss: 2.6127e-04\n",
      "Epoch 1262/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0438e-04 - val_loss: 2.6222e-04\n",
      "Epoch 1263/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9553e-04 - val_loss: 2.6377e-04\n",
      "Epoch 1264/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0689e-04 - val_loss: 2.6758e-04\n",
      "Epoch 1265/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.0563e-04 - val_loss: 3.9134e-04\n",
      "Epoch 1266/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1726e-04 - val_loss: 2.8781e-04\n",
      "Epoch 1267/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.9754e-04 - val_loss: 2.7735e-04\n",
      "Epoch 1268/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.9808e-04 - val_loss: 2.9753e-04\n",
      "Epoch 1269/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0538e-04 - val_loss: 2.6227e-04\n",
      "Epoch 1270/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0317e-04 - val_loss: 2.9547e-04\n",
      "Epoch 1271/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.2440e-04 - val_loss: 2.6461e-04\n",
      "Epoch 1272/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0068e-04 - val_loss: 2.7684e-04\n",
      "Epoch 1273/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.9664e-04 - val_loss: 4.0242e-04\n",
      "Epoch 1274/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.3581e-04 - val_loss: 3.9888e-04\n",
      "Epoch 1275/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.1269e-04 - val_loss: 3.0898e-04\n",
      "Epoch 1276/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.2273e-04 - val_loss: 2.6029e-04\n",
      "Epoch 1277/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.2541e-04 - val_loss: 3.6472e-04\n",
      "Epoch 1278/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.1680e-04 - val_loss: 3.6189e-04\n",
      "Epoch 1279/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.0323e-04 - val_loss: 2.6008e-04\n",
      "Epoch 1280/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.2652e-04 - val_loss: 2.7646e-04\n",
      "Epoch 1281/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.2174e-04 - val_loss: 3.0449e-04\n",
      "Epoch 1282/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0689e-04 - val_loss: 3.7141e-04\n",
      "Epoch 1283/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9756e-04 - val_loss: 3.3270e-04\n",
      "Epoch 1284/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.0142e-04 - val_loss: 2.7451e-04\n",
      "Epoch 1285/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.0084e-04 - val_loss: 2.6611e-04\n",
      "Epoch 1286/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.0669e-04 - val_loss: 2.7323e-04\n",
      "Epoch 1287/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.9634e-04 - val_loss: 2.8213e-04\n",
      "Epoch 1288/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.0072e-04 - val_loss: 2.7226e-04\n",
      "Epoch 1289/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.0266e-04 - val_loss: 2.6824e-04\n",
      "Epoch 1290/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9341e-04 - val_loss: 2.6729e-04\n",
      "Epoch 1291/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0047e-04 - val_loss: 2.6897e-04\n",
      "Epoch 1292/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0833e-04 - val_loss: 3.7003e-04\n",
      "Epoch 1293/2000\n",
      "4059/4059 [==============================] - 2s 606us/step - loss: 3.2763e-04 - val_loss: 4.1101e-04\n",
      "Epoch 1294/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1105e-04 - val_loss: 2.6441e-04\n",
      "Epoch 1295/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.9537e-04 - val_loss: 2.6310e-04\n",
      "Epoch 1296/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.8943e-04 - val_loss: 2.8220e-04\n",
      "Epoch 1297/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.1950e-04 - val_loss: 2.8337e-04\n",
      "Epoch 1298/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.1889e-04 - val_loss: 3.1592e-04\n",
      "Epoch 1299/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.1413e-04 - val_loss: 2.6155e-04\n",
      "Epoch 1300/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0155e-04 - val_loss: 2.6648e-04\n",
      "Epoch 1301/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.0291e-04 - val_loss: 2.9770e-04\n",
      "Epoch 1302/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.9305e-04 - val_loss: 2.6129e-04\n",
      "Epoch 1303/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.9648e-04 - val_loss: 3.0168e-04\n",
      "Epoch 1304/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.9859e-04 - val_loss: 2.7798e-04\n",
      "Epoch 1305/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.1482e-04 - val_loss: 2.6981e-04\n",
      "Epoch 1306/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.0218e-04 - val_loss: 2.8626e-04\n",
      "Epoch 1307/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.0606e-04 - val_loss: 2.8630e-04\n",
      "Epoch 1308/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.9007e-04 - val_loss: 2.6633e-04\n",
      "Epoch 1309/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0762e-04 - val_loss: 3.0424e-04\n",
      "Epoch 1310/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2132e-04 - val_loss: 3.3251e-04\n",
      "Epoch 1311/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.8837e-04 - val_loss: 2.8639e-04\n",
      "Epoch 1312/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.0047e-04 - val_loss: 3.3508e-04\n",
      "Epoch 1313/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 3.2127e-04 - val_loss: 3.2825e-04\n",
      "Epoch 1314/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2270e-04 - val_loss: 2.6510e-04\n",
      "Epoch 1315/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.0181e-04 - val_loss: 2.8983e-04\n",
      "Epoch 1316/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.2583e-04 - val_loss: 4.1407e-04\n",
      "Epoch 1317/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.3139e-04 - val_loss: 3.4224e-04\n",
      "Epoch 1318/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.1771e-04 - val_loss: 2.6329e-04\n",
      "Epoch 1319/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.2826e-04 - val_loss: 2.7281e-04\n",
      "Epoch 1320/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.1597e-04 - val_loss: 3.4866e-04\n",
      "Epoch 1321/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.1483e-04 - val_loss: 3.8465e-04\n",
      "Epoch 1322/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0845e-04 - val_loss: 2.7859e-04\n",
      "Epoch 1323/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 3.0286e-04 - val_loss: 3.2130e-04\n",
      "Epoch 1324/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.9706e-04 - val_loss: 2.6611e-04\n",
      "Epoch 1325/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8767e-04 - val_loss: 3.0862e-04\n",
      "Epoch 1326/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.9401e-04 - val_loss: 2.9860e-04\n",
      "Epoch 1327/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.9899e-04 - val_loss: 2.7623e-04\n",
      "Epoch 1328/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.9396e-04 - val_loss: 2.9583e-04\n",
      "Epoch 1329/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.9447e-04 - val_loss: 2.6708e-04\n",
      "Epoch 1330/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.9282e-04 - val_loss: 2.6655e-04\n",
      "Epoch 1331/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.0146e-04 - val_loss: 2.7113e-04\n",
      "Epoch 1332/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.0616e-04 - val_loss: 2.9236e-04\n",
      "Epoch 1333/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.0020e-04 - val_loss: 2.7190e-04\n",
      "Epoch 1334/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.0737e-04 - val_loss: 2.8366e-04\n",
      "Epoch 1335/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2179e-04 - val_loss: 3.1602e-04\n",
      "Epoch 1336/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2517e-04 - val_loss: 3.5546e-04\n",
      "Epoch 1337/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.0460e-04 - val_loss: 3.2483e-04\n",
      "Epoch 1338/2000\n",
      "4059/4059 [==============================] - 2s 605us/step - loss: 2.9152e-04 - val_loss: 3.2317e-04\n",
      "Epoch 1339/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.1231e-04 - val_loss: 3.2821e-04\n",
      "Epoch 1340/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.9976e-04 - val_loss: 3.3379e-04\n",
      "Epoch 1341/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.1212e-04 - val_loss: 3.5383e-04\n",
      "Epoch 1342/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1483e-04 - val_loss: 3.3544e-04\n",
      "Epoch 1343/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.9648e-04 - val_loss: 2.9528e-04\n",
      "Epoch 1344/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.9508e-04 - val_loss: 2.9524e-04\n",
      "Epoch 1345/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.2808e-04 - val_loss: 2.6713e-04\n",
      "Epoch 1346/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.0317e-04 - val_loss: 3.1283e-04\n",
      "Epoch 1347/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.1198e-04 - val_loss: 2.9765e-04\n",
      "Epoch 1348/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1731e-04 - val_loss: 2.8236e-04\n",
      "Epoch 1349/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9646e-04 - val_loss: 2.7616e-04\n",
      "Epoch 1350/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1209e-04 - val_loss: 2.7125e-04\n",
      "Epoch 1351/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0441e-04 - val_loss: 3.3185e-04\n",
      "Epoch 1352/2000\n",
      "4059/4059 [==============================] - 3s 618us/step - loss: 2.9876e-04 - val_loss: 3.1166e-04\n",
      "Epoch 1353/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.2098e-04 - val_loss: 3.2563e-04\n",
      "Epoch 1354/2000\n",
      "4059/4059 [==============================] - 2s 605us/step - loss: 3.0188e-04 - val_loss: 3.1009e-04\n",
      "Epoch 1355/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 2.8620e-04 - val_loss: 2.7390e-04\n",
      "Epoch 1356/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.8640e-04 - val_loss: 2.8252e-04\n",
      "Epoch 1357/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.9918e-04 - val_loss: 3.4342e-04\n",
      "Epoch 1358/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0390e-04 - val_loss: 2.6775e-04\n",
      "Epoch 1359/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.9267e-04 - val_loss: 2.9048e-04\n",
      "Epoch 1360/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.9083e-04 - val_loss: 2.7683e-04\n",
      "Epoch 1361/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0915e-04 - val_loss: 3.3204e-04\n",
      "Epoch 1362/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0316e-04 - val_loss: 3.4106e-04\n",
      "Epoch 1363/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.2956e-04 - val_loss: 2.7965e-04\n",
      "Epoch 1364/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.1762e-04 - val_loss: 3.1387e-04\n",
      "Epoch 1365/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1127e-04 - val_loss: 3.2415e-04\n",
      "Epoch 1366/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.3801e-04 - val_loss: 3.4942e-04\n",
      "Epoch 1367/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0441e-04 - val_loss: 3.2860e-04\n",
      "Epoch 1368/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.9482e-04 - val_loss: 2.8673e-04\n",
      "Epoch 1369/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.9421e-04 - val_loss: 3.2558e-04\n",
      "Epoch 1370/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.8923e-04 - val_loss: 2.8162e-04\n",
      "Epoch 1371/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.8831e-04 - val_loss: 2.7471e-04\n",
      "Epoch 1372/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.8991e-04 - val_loss: 2.7161e-04\n",
      "Epoch 1373/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.8022e-04 - val_loss: 3.6386e-04\n",
      "Epoch 1374/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.8912e-04 - val_loss: 2.7819e-04\n",
      "Epoch 1375/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.9528e-04 - val_loss: 3.0200e-04\n",
      "Epoch 1376/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.0693e-04 - val_loss: 3.7276e-04\n",
      "Epoch 1377/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.4907e-04 - val_loss: 3.0270e-04\n",
      "Epoch 1378/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.3223e-04 - val_loss: 3.5771e-04\n",
      "Epoch 1379/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.3224e-04 - val_loss: 3.8504e-04\n",
      "Epoch 1380/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.2842e-04 - val_loss: 2.9895e-04\n",
      "Epoch 1381/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.3378e-04 - val_loss: 3.0243e-04\n",
      "Epoch 1382/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9384e-04 - val_loss: 2.7613e-04\n",
      "Epoch 1383/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.8824e-04 - val_loss: 3.6058e-04\n",
      "Epoch 1384/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.9166e-04 - val_loss: 2.7487e-04\n",
      "Epoch 1385/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8881e-04 - val_loss: 2.9892e-04\n",
      "Epoch 1386/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.8789e-04 - val_loss: 3.7146e-04\n",
      "Epoch 1387/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0961e-04 - val_loss: 2.7465e-04\n",
      "Epoch 1388/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.9042e-04 - val_loss: 2.9641e-04\n",
      "Epoch 1389/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9008e-04 - val_loss: 2.8473e-04\n",
      "Epoch 1390/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9149e-04 - val_loss: 2.7614e-04\n",
      "Epoch 1391/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8524e-04 - val_loss: 2.8574e-04\n",
      "Epoch 1392/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.7407e-04 - val_loss: 3.0840e-04\n",
      "Epoch 1393/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.7885e-04 - val_loss: 2.7894e-04\n",
      "Epoch 1394/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.8168e-04 - val_loss: 2.8700e-04\n",
      "Epoch 1395/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.9236e-04 - val_loss: 3.0242e-04\n",
      "Epoch 1396/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0920e-04 - val_loss: 2.8535e-04\n",
      "Epoch 1397/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.8597e-04 - val_loss: 2.9070e-04\n",
      "Epoch 1398/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8786e-04 - val_loss: 3.1902e-04\n",
      "Epoch 1399/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.9303e-04 - val_loss: 3.0738e-04\n",
      "Epoch 1400/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.8545e-04 - val_loss: 3.0276e-04\n",
      "Epoch 1401/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.9571e-04 - val_loss: 2.7560e-04\n",
      "Epoch 1402/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.9258e-04 - val_loss: 3.1015e-04\n",
      "Epoch 1403/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.8206e-04 - val_loss: 2.7650e-04\n",
      "Epoch 1404/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.8306e-04 - val_loss: 2.8816e-04\n",
      "Epoch 1405/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8909e-04 - val_loss: 3.2161e-04\n",
      "Epoch 1406/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.9640e-04 - val_loss: 3.1575e-04\n",
      "Epoch 1407/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.8546e-04 - val_loss: 3.0824e-04\n",
      "Epoch 1408/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0320e-04 - val_loss: 2.7880e-04\n",
      "Epoch 1409/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 3.1266e-04 - val_loss: 2.9758e-04\n",
      "Epoch 1410/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1543e-04 - val_loss: 3.0571e-04\n",
      "Epoch 1411/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.9991e-04 - val_loss: 2.8380e-04\n",
      "Epoch 1412/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.3672e-04 - val_loss: 4.4870e-04\n",
      "Epoch 1413/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.4496e-04 - val_loss: 2.8873e-04\n",
      "Epoch 1414/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.0093e-04 - val_loss: 2.9075e-04\n",
      "Epoch 1415/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.8282e-04 - val_loss: 3.2961e-04\n",
      "Epoch 1416/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.8841e-04 - val_loss: 2.7456e-04\n",
      "Epoch 1417/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.8037e-04 - val_loss: 2.9113e-04\n",
      "Epoch 1418/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.7314e-04 - val_loss: 2.9484e-04\n",
      "Epoch 1419/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.8328e-04 - val_loss: 3.3984e-04\n",
      "Epoch 1420/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.8792e-04 - val_loss: 2.9579e-04\n",
      "Epoch 1421/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.8418e-04 - val_loss: 2.9835e-04\n",
      "Epoch 1422/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9982e-04 - val_loss: 2.9484e-04\n",
      "Epoch 1423/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 3.0573e-04 - val_loss: 3.0683e-04\n",
      "Epoch 1424/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.0985e-04 - val_loss: 3.0926e-04\n",
      "Epoch 1425/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 3.0944e-04 - val_loss: 2.8728e-04\n",
      "Epoch 1426/2000\n",
      "4059/4059 [==============================] - 2s 607us/step - loss: 2.9949e-04 - val_loss: 2.8079e-04\n",
      "Epoch 1427/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9427e-04 - val_loss: 3.0378e-04\n",
      "Epoch 1428/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.9094e-04 - val_loss: 3.2322e-04\n",
      "Epoch 1429/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0597e-04 - val_loss: 2.8537e-04\n",
      "Epoch 1430/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.9861e-04 - val_loss: 2.8728e-04\n",
      "Epoch 1431/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.8941e-04 - val_loss: 2.9579e-04\n",
      "Epoch 1432/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.8610e-04 - val_loss: 3.1694e-04\n",
      "Epoch 1433/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 2.9780e-04 - val_loss: 2.9969e-04\n",
      "Epoch 1434/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.0106e-04 - val_loss: 3.6563e-04\n",
      "Epoch 1435/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 3.0190e-04 - val_loss: 3.5406e-04\n",
      "Epoch 1436/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.4432e-04 - val_loss: 2.9830e-04\n",
      "Epoch 1437/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 3.2619e-04 - val_loss: 4.3609e-04\n",
      "Epoch 1438/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.2842e-04 - val_loss: 3.5407e-04\n",
      "Epoch 1439/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.9670e-04 - val_loss: 2.9578e-04\n",
      "Epoch 1440/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.1232e-04 - val_loss: 3.8529e-04\n",
      "Epoch 1441/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 3.4870e-04 - val_loss: 4.6202e-04\n",
      "Epoch 1442/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.3907e-04 - val_loss: 4.2706e-04\n",
      "Epoch 1443/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 3.1272e-04 - val_loss: 3.1587e-04\n",
      "Epoch 1444/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.8797e-04 - val_loss: 3.3178e-04\n",
      "Epoch 1445/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.9112e-04 - val_loss: 3.2331e-04\n",
      "Epoch 1446/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.8345e-04 - val_loss: 3.1761e-04\n",
      "Epoch 1447/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8712e-04 - val_loss: 2.8805e-04\n",
      "Epoch 1448/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.7346e-04 - val_loss: 3.0716e-04\n",
      "Epoch 1449/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.7833e-04 - val_loss: 2.9297e-04\n",
      "Epoch 1450/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.8174e-04 - val_loss: 3.1939e-04\n",
      "Epoch 1451/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.9310e-04 - val_loss: 3.4286e-04\n",
      "Epoch 1452/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.9479e-04 - val_loss: 2.8879e-04\n",
      "Epoch 1453/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.8611e-04 - val_loss: 3.0341e-04\n",
      "Epoch 1454/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.9410e-04 - val_loss: 3.2133e-04\n",
      "Epoch 1455/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8102e-04 - val_loss: 3.1698e-04\n",
      "Epoch 1456/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.7950e-04 - val_loss: 2.9429e-04\n",
      "Epoch 1457/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8075e-04 - val_loss: 3.1450e-04\n",
      "Epoch 1458/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8363e-04 - val_loss: 2.9629e-04\n",
      "Epoch 1459/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7266e-04 - val_loss: 2.9910e-04\n",
      "Epoch 1460/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.7853e-04 - val_loss: 2.9488e-04\n",
      "Epoch 1461/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7963e-04 - val_loss: 2.9903e-04\n",
      "Epoch 1462/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.7292e-04 - val_loss: 3.0866e-04\n",
      "Epoch 1463/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.7444e-04 - val_loss: 2.9181e-04\n",
      "Epoch 1464/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.6318e-04 - val_loss: 3.0316e-04\n",
      "Epoch 1465/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.7039e-04 - val_loss: 3.3420e-04\n",
      "Epoch 1466/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8010e-04 - val_loss: 3.1407e-04\n",
      "Epoch 1467/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.8025e-04 - val_loss: 3.0733e-04\n",
      "Epoch 1468/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.8738e-04 - val_loss: 3.3132e-04\n",
      "Epoch 1469/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.8468e-04 - val_loss: 3.0660e-04\n",
      "Epoch 1470/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.8361e-04 - val_loss: 2.9845e-04\n",
      "Epoch 1471/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.8055e-04 - val_loss: 3.0007e-04\n",
      "Epoch 1472/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.9240e-04 - val_loss: 3.1870e-04\n",
      "Epoch 1473/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.9720e-04 - val_loss: 3.1238e-04\n",
      "Epoch 1474/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0102e-04 - val_loss: 2.9721e-04\n",
      "Epoch 1475/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 2.7640e-04 - val_loss: 3.3133e-04\n",
      "Epoch 1476/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.9283e-04 - val_loss: 4.0994e-04\n",
      "Epoch 1477/2000\n",
      "4059/4059 [==============================] - 2s 616us/step - loss: 2.9381e-04 - val_loss: 3.7503e-04\n",
      "Epoch 1478/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.9518e-04 - val_loss: 3.7373e-04\n",
      "Epoch 1479/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 3.0621e-04 - val_loss: 2.8403e-04\n",
      "Epoch 1480/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.8482e-04 - val_loss: 3.4071e-04\n",
      "Epoch 1481/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.9247e-04 - val_loss: 3.5529e-04\n",
      "Epoch 1482/2000\n",
      "4059/4059 [==============================] - 2s 608us/step - loss: 2.8352e-04 - val_loss: 3.4009e-04\n",
      "Epoch 1483/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8694e-04 - val_loss: 3.5503e-04\n",
      "Epoch 1484/2000\n",
      "4059/4059 [==============================] - 2s 610us/step - loss: 2.9092e-04 - val_loss: 3.0480e-04\n",
      "Epoch 1485/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8419e-04 - val_loss: 3.3345e-04\n",
      "Epoch 1486/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.8020e-04 - val_loss: 3.0795e-04\n",
      "Epoch 1487/2000\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 2.8000e-04 - val_loss: 3.0766e-04\n",
      "Epoch 1488/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.0176e-04 - val_loss: 3.3028e-04\n",
      "Epoch 1489/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.2917e-04 - val_loss: 3.9923e-04\n",
      "Epoch 1490/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.1435e-04 - val_loss: 3.2602e-04\n",
      "Epoch 1491/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 3.0415e-04 - val_loss: 3.0598e-04\n",
      "Epoch 1492/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.9457e-04 - val_loss: 3.3531e-04\n",
      "Epoch 1493/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.9298e-04 - val_loss: 3.9051e-04\n",
      "Epoch 1494/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.8257e-04 - val_loss: 3.0118e-04\n",
      "Epoch 1495/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.7248e-04 - val_loss: 3.2223e-04\n",
      "Epoch 1496/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.7347e-04 - val_loss: 3.1242e-04\n",
      "Epoch 1497/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.6983e-04 - val_loss: 3.1860e-04\n",
      "Epoch 1498/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7023e-04 - val_loss: 3.1786e-04\n",
      "Epoch 1499/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.7521e-04 - val_loss: 3.1210e-04\n",
      "Epoch 1500/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7552e-04 - val_loss: 3.1124e-04\n",
      "Epoch 1501/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.6867e-04 - val_loss: 3.4167e-04\n",
      "Epoch 1502/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.7200e-04 - val_loss: 3.2503e-04\n",
      "Epoch 1503/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7029e-04 - val_loss: 3.3166e-04\n",
      "Epoch 1504/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8898e-04 - val_loss: 3.9788e-04\n",
      "Epoch 1505/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.8128e-04 - val_loss: 3.1980e-04\n",
      "Epoch 1506/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.8391e-04 - val_loss: 3.1489e-04\n",
      "Epoch 1507/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.7549e-04 - val_loss: 3.0994e-04\n",
      "Epoch 1508/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.6264e-04 - val_loss: 3.3106e-04\n",
      "Epoch 1509/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7255e-04 - val_loss: 3.1146e-04\n",
      "Epoch 1510/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7565e-04 - val_loss: 3.1436e-04\n",
      "Epoch 1511/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8381e-04 - val_loss: 3.9792e-04\n",
      "Epoch 1512/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9132e-04 - val_loss: 3.2354e-04\n",
      "Epoch 1513/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8272e-04 - val_loss: 3.1283e-04\n",
      "Epoch 1514/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7546e-04 - val_loss: 3.1706e-04\n",
      "Epoch 1515/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.7235e-04 - val_loss: 3.0257e-04\n",
      "Epoch 1516/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.6991e-04 - val_loss: 3.1650e-04\n",
      "Epoch 1517/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.7535e-04 - val_loss: 3.4206e-04\n",
      "Epoch 1518/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.9836e-04 - val_loss: 3.2836e-04\n",
      "Epoch 1519/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.7944e-04 - val_loss: 3.1533e-04\n",
      "Epoch 1520/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7371e-04 - val_loss: 3.1383e-04\n",
      "Epoch 1521/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8283e-04 - val_loss: 3.2954e-04\n",
      "Epoch 1522/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7899e-04 - val_loss: 3.1812e-04\n",
      "Epoch 1523/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.7501e-04 - val_loss: 3.1928e-04\n",
      "Epoch 1524/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.6988e-04 - val_loss: 3.1829e-04\n",
      "Epoch 1525/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7110e-04 - val_loss: 3.2423e-04\n",
      "Epoch 1526/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.7173e-04 - val_loss: 3.1616e-04\n",
      "Epoch 1527/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.7365e-04 - val_loss: 3.3369e-04\n",
      "Epoch 1528/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.7849e-04 - val_loss: 3.5752e-04\n",
      "Epoch 1529/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.7660e-04 - val_loss: 3.0761e-04\n",
      "Epoch 1530/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.6778e-04 - val_loss: 3.1770e-04\n",
      "Epoch 1531/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.8825e-04 - val_loss: 3.2525e-04\n",
      "Epoch 1532/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.3055e-04 - val_loss: 3.2820e-04\n",
      "Epoch 1533/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 3.1758e-04 - val_loss: 3.0886e-04\n",
      "Epoch 1534/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 3.0639e-04 - val_loss: 3.0242e-04\n",
      "Epoch 1535/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.9888e-04 - val_loss: 3.2775e-04\n",
      "Epoch 1536/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8835e-04 - val_loss: 2.9903e-04\n",
      "Epoch 1537/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.8743e-04 - val_loss: 3.1910e-04\n",
      "Epoch 1538/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.8083e-04 - val_loss: 3.2228e-04\n",
      "Epoch 1539/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7839e-04 - val_loss: 3.3545e-04\n",
      "Epoch 1540/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.8042e-04 - val_loss: 3.1529e-04\n",
      "Epoch 1541/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.6901e-04 - val_loss: 3.1701e-04\n",
      "Epoch 1542/2000\n",
      "4059/4059 [==============================] - 2s 591us/step - loss: 2.6423e-04 - val_loss: 3.1968e-04\n",
      "Epoch 1543/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.7154e-04 - val_loss: 3.3156e-04\n",
      "Epoch 1544/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.7788e-04 - val_loss: 3.3321e-04\n",
      "Epoch 1545/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7035e-04 - val_loss: 3.2126e-04\n",
      "Epoch 1546/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7223e-04 - val_loss: 3.2070e-04\n",
      "Epoch 1547/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.7305e-04 - val_loss: 3.2930e-04\n",
      "Epoch 1548/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6761e-04 - val_loss: 3.1423e-04\n",
      "Epoch 1549/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.7308e-04 - val_loss: 4.1354e-04\n",
      "Epoch 1550/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.8160e-04 - val_loss: 3.9069e-04\n",
      "Epoch 1551/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.7274e-04 - val_loss: 3.0521e-04\n",
      "Epoch 1552/2000\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 2.7417e-04 - val_loss: 3.9042e-04\n",
      "Epoch 1553/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 3.1570e-04 - val_loss: 4.4843e-04\n",
      "Epoch 1554/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.9898e-04 - val_loss: 3.5441e-04\n",
      "Epoch 1555/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.8577e-04 - val_loss: 3.5426e-04\n",
      "Epoch 1556/2000\n",
      "4059/4059 [==============================] - 2s 605us/step - loss: 2.9074e-04 - val_loss: 3.1813e-04\n",
      "Epoch 1557/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7151e-04 - val_loss: 3.5895e-04\n",
      "Epoch 1558/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.7430e-04 - val_loss: 3.3526e-04\n",
      "Epoch 1559/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7519e-04 - val_loss: 3.4471e-04\n",
      "Epoch 1560/2000\n",
      "4059/4059 [==============================] - 3s 637us/step - loss: 3.0786e-04 - val_loss: 3.8534e-04\n",
      "Epoch 1561/2000\n",
      "4059/4059 [==============================] - 3s 623us/step - loss: 3.0690e-04 - val_loss: 3.9165e-04\n",
      "Epoch 1562/2000\n",
      "4059/4059 [==============================] - 3s 622us/step - loss: 3.2302e-04 - val_loss: 3.6192e-04\n",
      "Epoch 1563/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.0240e-04 - val_loss: 3.0803e-04\n",
      "Epoch 1564/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.7883e-04 - val_loss: 3.4815e-04\n",
      "Epoch 1565/2000\n",
      "4059/4059 [==============================] - 2s 613us/step - loss: 2.7175e-04 - val_loss: 3.0869e-04\n",
      "Epoch 1566/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.6424e-04 - val_loss: 3.4035e-04\n",
      "Epoch 1567/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7217e-04 - val_loss: 4.0230e-04\n",
      "Epoch 1568/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.7976e-04 - val_loss: 4.5766e-04\n",
      "Epoch 1569/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.7836e-04 - val_loss: 3.8673e-04\n",
      "Epoch 1570/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.9852e-04 - val_loss: 3.5975e-04\n",
      "Epoch 1571/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.9037e-04 - val_loss: 3.1447e-04\n",
      "Epoch 1572/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.8714e-04 - val_loss: 3.2813e-04\n",
      "Epoch 1573/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8270e-04 - val_loss: 3.8402e-04\n",
      "Epoch 1574/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6955e-04 - val_loss: 3.9885e-04\n",
      "Epoch 1575/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8193e-04 - val_loss: 3.3934e-04\n",
      "Epoch 1576/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.7056e-04 - val_loss: 4.0874e-04\n",
      "Epoch 1577/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.9361e-04 - val_loss: 3.9510e-04\n",
      "Epoch 1578/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8269e-04 - val_loss: 3.9297e-04\n",
      "Epoch 1579/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.9302e-04 - val_loss: 3.6001e-04\n",
      "Epoch 1580/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8591e-04 - val_loss: 3.1778e-04\n",
      "Epoch 1581/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7993e-04 - val_loss: 3.2165e-04\n",
      "Epoch 1582/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.8680e-04 - val_loss: 3.5152e-04\n",
      "Epoch 1583/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.6895e-04 - val_loss: 3.1146e-04\n",
      "Epoch 1584/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.7249e-04 - val_loss: 3.4463e-04\n",
      "Epoch 1585/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.6765e-04 - val_loss: 3.3726e-04\n",
      "Epoch 1586/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.6303e-04 - val_loss: 3.4001e-04\n",
      "Epoch 1587/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7558e-04 - val_loss: 3.4423e-04\n",
      "Epoch 1588/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.7568e-04 - val_loss: 3.3687e-04\n",
      "Epoch 1589/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.7392e-04 - val_loss: 3.3017e-04\n",
      "Epoch 1590/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.7564e-04 - val_loss: 3.9875e-04\n",
      "Epoch 1591/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8194e-04 - val_loss: 3.4215e-04\n",
      "Epoch 1592/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.7875e-04 - val_loss: 3.4744e-04\n",
      "Epoch 1593/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.7299e-04 - val_loss: 3.1348e-04\n",
      "Epoch 1594/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.7585e-04 - val_loss: 3.5215e-04\n",
      "Epoch 1595/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.7375e-04 - val_loss: 3.3545e-04\n",
      "Epoch 1596/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.7450e-04 - val_loss: 3.4409e-04\n",
      "Epoch 1597/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8385e-04 - val_loss: 3.2209e-04\n",
      "Epoch 1598/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.6727e-04 - val_loss: 3.1775e-04\n",
      "Epoch 1599/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.7220e-04 - val_loss: 3.8392e-04\n",
      "Epoch 1600/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6493e-04 - val_loss: 3.7084e-04\n",
      "Epoch 1601/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.7613e-04 - val_loss: 3.4106e-04\n",
      "Epoch 1602/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.7945e-04 - val_loss: 3.4228e-04\n",
      "Epoch 1603/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.7178e-04 - val_loss: 4.2801e-04\n",
      "Epoch 1604/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.6647e-04 - val_loss: 4.0160e-04\n",
      "Epoch 1605/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 3.0310e-04 - val_loss: 3.4550e-04\n",
      "Epoch 1606/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.8050e-04 - val_loss: 3.4226e-04\n",
      "Epoch 1607/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.7235e-04 - val_loss: 3.3315e-04\n",
      "Epoch 1608/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.6202e-04 - val_loss: 3.6675e-04\n",
      "Epoch 1609/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.7783e-04 - val_loss: 3.5017e-04\n",
      "Epoch 1610/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6414e-04 - val_loss: 3.4956e-04\n",
      "Epoch 1611/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.8542e-04 - val_loss: 3.4494e-04\n",
      "Epoch 1612/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.8655e-04 - val_loss: 5.5702e-04\n",
      "Epoch 1613/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.9398e-04 - val_loss: 3.8903e-04\n",
      "Epoch 1614/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.9240e-04 - val_loss: 3.2710e-04\n",
      "Epoch 1615/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.7979e-04 - val_loss: 3.1321e-04\n",
      "Epoch 1616/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.6999e-04 - val_loss: 3.3580e-04\n",
      "Epoch 1617/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7284e-04 - val_loss: 3.4849e-04\n",
      "Epoch 1618/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7259e-04 - val_loss: 4.1238e-04\n",
      "Epoch 1619/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.7756e-04 - val_loss: 4.2963e-04\n",
      "Epoch 1620/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.7702e-04 - val_loss: 3.3075e-04\n",
      "Epoch 1621/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7305e-04 - val_loss: 3.3410e-04\n",
      "Epoch 1622/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8289e-04 - val_loss: 3.1454e-04\n",
      "Epoch 1623/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.6151e-04 - val_loss: 3.3594e-04\n",
      "Epoch 1624/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7431e-04 - val_loss: 3.2594e-04\n",
      "Epoch 1625/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7577e-04 - val_loss: 3.3255e-04\n",
      "Epoch 1626/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6939e-04 - val_loss: 3.4128e-04\n",
      "Epoch 1627/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6039e-04 - val_loss: 3.4416e-04\n",
      "Epoch 1628/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5994e-04 - val_loss: 3.4386e-04\n",
      "Epoch 1629/2000\n",
      "4059/4059 [==============================] - 3s 617us/step - loss: 2.6615e-04 - val_loss: 3.3068e-04\n",
      "Epoch 1630/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.5997e-04 - val_loss: 3.2808e-04\n",
      "Epoch 1631/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.7128e-04 - val_loss: 3.6003e-04\n",
      "Epoch 1632/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.5653e-04 - val_loss: 3.4874e-04\n",
      "Epoch 1633/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.6714e-04 - val_loss: 3.6353e-04\n",
      "Epoch 1634/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6223e-04 - val_loss: 3.5389e-04\n",
      "Epoch 1635/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.6468e-04 - val_loss: 3.4605e-04\n",
      "Epoch 1636/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.9269e-04 - val_loss: 4.4853e-04\n",
      "Epoch 1637/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.8100e-04 - val_loss: 3.2774e-04\n",
      "Epoch 1638/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.8390e-04 - val_loss: 3.4751e-04\n",
      "Epoch 1639/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.1440e-04 - val_loss: 3.3683e-04\n",
      "Epoch 1640/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.0075e-04 - val_loss: 4.1041e-04\n",
      "Epoch 1641/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.8511e-04 - val_loss: 3.4345e-04\n",
      "Epoch 1642/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7861e-04 - val_loss: 4.1911e-04\n",
      "Epoch 1643/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.9239e-04 - val_loss: 4.1593e-04\n",
      "Epoch 1644/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8161e-04 - val_loss: 3.3437e-04\n",
      "Epoch 1645/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6089e-04 - val_loss: 3.4858e-04\n",
      "Epoch 1646/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6110e-04 - val_loss: 3.3793e-04\n",
      "Epoch 1647/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 2.5945e-04 - val_loss: 3.3492e-04\n",
      "Epoch 1648/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.6588e-04 - val_loss: 4.0156e-04\n",
      "Epoch 1649/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.6062e-04 - val_loss: 3.5683e-04\n",
      "Epoch 1650/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.5520e-04 - val_loss: 3.5545e-04\n",
      "Epoch 1651/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.8044e-04 - val_loss: 3.9024e-04\n",
      "Epoch 1652/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.9545e-04 - val_loss: 4.4518e-04\n",
      "Epoch 1653/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.9684e-04 - val_loss: 3.5023e-04\n",
      "Epoch 1654/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.7817e-04 - val_loss: 3.5098e-04\n",
      "Epoch 1655/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.7071e-04 - val_loss: 3.9883e-04\n",
      "Epoch 1656/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7185e-04 - val_loss: 3.5901e-04\n",
      "Epoch 1657/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.6920e-04 - val_loss: 3.3269e-04\n",
      "Epoch 1658/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6041e-04 - val_loss: 3.2882e-04\n",
      "Epoch 1659/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.7105e-04 - val_loss: 4.0091e-04\n",
      "Epoch 1660/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.6100e-04 - val_loss: 3.3919e-04\n",
      "Epoch 1661/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.6344e-04 - val_loss: 3.5231e-04\n",
      "Epoch 1662/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.6297e-04 - val_loss: 3.6224e-04\n",
      "Epoch 1663/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.6296e-04 - val_loss: 3.6164e-04\n",
      "Epoch 1664/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.6855e-04 - val_loss: 3.4753e-04\n",
      "Epoch 1665/2000\n",
      "4059/4059 [==============================] - 2s 605us/step - loss: 2.6247e-04 - val_loss: 3.3536e-04\n",
      "Epoch 1666/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7016e-04 - val_loss: 3.3197e-04\n",
      "Epoch 1667/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.6455e-04 - val_loss: 3.5910e-04\n",
      "Epoch 1668/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5531e-04 - val_loss: 3.8223e-04\n",
      "Epoch 1669/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.6755e-04 - val_loss: 3.6346e-04\n",
      "Epoch 1670/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6089e-04 - val_loss: 4.0444e-04\n",
      "Epoch 1671/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.7031e-04 - val_loss: 3.8125e-04\n",
      "Epoch 1672/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6748e-04 - val_loss: 3.7897e-04\n",
      "Epoch 1673/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.6400e-04 - val_loss: 3.5013e-04\n",
      "Epoch 1674/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6161e-04 - val_loss: 3.3671e-04\n",
      "Epoch 1675/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.7783e-04 - val_loss: 3.3500e-04\n",
      "Epoch 1676/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.7553e-04 - val_loss: 3.5699e-04\n",
      "Epoch 1677/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.7974e-04 - val_loss: 3.4968e-04\n",
      "Epoch 1678/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6750e-04 - val_loss: 3.5251e-04\n",
      "Epoch 1679/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5537e-04 - val_loss: 3.2040e-04\n",
      "Epoch 1680/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5955e-04 - val_loss: 3.7759e-04\n",
      "Epoch 1681/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.6578e-04 - val_loss: 3.6691e-04\n",
      "Epoch 1682/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.5535e-04 - val_loss: 3.5855e-04\n",
      "Epoch 1683/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5171e-04 - val_loss: 3.4736e-04\n",
      "Epoch 1684/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5947e-04 - val_loss: 3.7333e-04\n",
      "Epoch 1685/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.5532e-04 - val_loss: 3.6548e-04\n",
      "Epoch 1686/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.4879e-04 - val_loss: 3.6930e-04\n",
      "Epoch 1687/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6380e-04 - val_loss: 3.6758e-04\n",
      "Epoch 1688/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.5233e-04 - val_loss: 3.5574e-04\n",
      "Epoch 1689/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.5210e-04 - val_loss: 3.7651e-04\n",
      "Epoch 1690/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5533e-04 - val_loss: 3.5084e-04\n",
      "Epoch 1691/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5074e-04 - val_loss: 3.8349e-04\n",
      "Epoch 1692/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5629e-04 - val_loss: 4.0141e-04\n",
      "Epoch 1693/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.6590e-04 - val_loss: 3.9707e-04\n",
      "Epoch 1694/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7130e-04 - val_loss: 3.8141e-04\n",
      "Epoch 1695/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.5735e-04 - val_loss: 3.5278e-04\n",
      "Epoch 1696/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.7714e-04 - val_loss: 3.6829e-04\n",
      "Epoch 1697/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.0224e-04 - val_loss: 4.6988e-04\n",
      "Epoch 1698/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.6817e-04 - val_loss: 3.9804e-04\n",
      "Epoch 1699/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 3.9022e-04 - val_loss: 3.5669e-04\n",
      "Epoch 1700/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 3.2899e-04 - val_loss: 3.0861e-04\n",
      "Epoch 1701/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 3.1120e-04 - val_loss: 2.9338e-04\n",
      "Epoch 1702/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.8047e-04 - val_loss: 3.1331e-04\n",
      "Epoch 1703/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.9033e-04 - val_loss: 3.3009e-04\n",
      "Epoch 1704/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.7778e-04 - val_loss: 4.0296e-04\n",
      "Epoch 1705/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.9406e-04 - val_loss: 3.2288e-04\n",
      "Epoch 1706/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5277e-04 - val_loss: 3.5809e-04\n",
      "Epoch 1707/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7084e-04 - val_loss: 3.3604e-04\n",
      "Epoch 1708/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.7491e-04 - val_loss: 3.9835e-04\n",
      "Epoch 1709/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6454e-04 - val_loss: 3.2814e-04\n",
      "Epoch 1710/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.5955e-04 - val_loss: 3.2090e-04\n",
      "Epoch 1711/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.5213e-04 - val_loss: 3.2455e-04\n",
      "Epoch 1712/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5537e-04 - val_loss: 3.3126e-04\n",
      "Epoch 1713/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6362e-04 - val_loss: 3.6507e-04\n",
      "Epoch 1714/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6858e-04 - val_loss: 3.5153e-04\n",
      "Epoch 1715/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.6331e-04 - val_loss: 3.7410e-04\n",
      "Epoch 1716/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.6729e-04 - val_loss: 3.3807e-04\n",
      "Epoch 1717/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.7401e-04 - val_loss: 3.3564e-04\n",
      "Epoch 1718/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6296e-04 - val_loss: 3.5968e-04\n",
      "Epoch 1719/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.7549e-04 - val_loss: 4.0028e-04\n",
      "Epoch 1720/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.8049e-04 - val_loss: 4.3847e-04\n",
      "Epoch 1721/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.7048e-04 - val_loss: 3.3619e-04\n",
      "Epoch 1722/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.5790e-04 - val_loss: 3.2806e-04\n",
      "Epoch 1723/2000\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 2.5448e-04 - val_loss: 3.5356e-04\n",
      "Epoch 1724/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.5876e-04 - val_loss: 3.7317e-04\n",
      "Epoch 1725/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.5076e-04 - val_loss: 3.5536e-04\n",
      "Epoch 1726/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.5498e-04 - val_loss: 3.4977e-04\n",
      "Epoch 1727/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.5152e-04 - val_loss: 3.9919e-04\n",
      "Epoch 1728/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.5233e-04 - val_loss: 3.7730e-04\n",
      "Epoch 1729/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.6102e-04 - val_loss: 3.6166e-04\n",
      "Epoch 1730/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.5008e-04 - val_loss: 3.6849e-04\n",
      "Epoch 1731/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6398e-04 - val_loss: 4.0730e-04\n",
      "Epoch 1732/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.7903e-04 - val_loss: 3.9541e-04\n",
      "Epoch 1733/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.6937e-04 - val_loss: 3.9606e-04\n",
      "Epoch 1734/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.4848e-04 - val_loss: 3.6037e-04\n",
      "Epoch 1735/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.4395e-04 - val_loss: 3.7012e-04\n",
      "Epoch 1736/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.4312e-04 - val_loss: 3.6796e-04\n",
      "Epoch 1737/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.4771e-04 - val_loss: 3.9393e-04\n",
      "Epoch 1738/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.6371e-04 - val_loss: 3.9842e-04\n",
      "Epoch 1739/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.6297e-04 - val_loss: 3.4415e-04\n",
      "Epoch 1740/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6101e-04 - val_loss: 3.5107e-04\n",
      "Epoch 1741/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.5737e-04 - val_loss: 3.8075e-04\n",
      "Epoch 1742/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.5806e-04 - val_loss: 3.8424e-04\n",
      "Epoch 1743/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5550e-04 - val_loss: 3.7644e-04\n",
      "Epoch 1744/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.5172e-04 - val_loss: 3.9801e-04\n",
      "Epoch 1745/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.5175e-04 - val_loss: 3.9146e-04\n",
      "Epoch 1746/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5313e-04 - val_loss: 3.7563e-04\n",
      "Epoch 1747/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.7281e-04 - val_loss: 3.9098e-04\n",
      "Epoch 1748/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.8126e-04 - val_loss: 3.8383e-04\n",
      "Epoch 1749/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.8480e-04 - val_loss: 4.8249e-04\n",
      "Epoch 1750/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.9664e-04 - val_loss: 3.6627e-04\n",
      "Epoch 1751/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.7632e-04 - val_loss: 3.7780e-04\n",
      "Epoch 1752/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5401e-04 - val_loss: 3.4872e-04\n",
      "Epoch 1753/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6362e-04 - val_loss: 3.6138e-04\n",
      "Epoch 1754/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.4756e-04 - val_loss: 3.6527e-04\n",
      "Epoch 1755/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.5459e-04 - val_loss: 3.9844e-04\n",
      "Epoch 1756/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5589e-04 - val_loss: 4.1951e-04\n",
      "Epoch 1757/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.4779e-04 - val_loss: 4.6982e-04\n",
      "Epoch 1758/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4928e-04 - val_loss: 3.7260e-04\n",
      "Epoch 1759/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.4916e-04 - val_loss: 3.6975e-04\n",
      "Epoch 1760/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.5005e-04 - val_loss: 3.7903e-04\n",
      "Epoch 1761/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.6410e-04 - val_loss: 3.8991e-04\n",
      "Epoch 1762/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6858e-04 - val_loss: 4.0929e-04\n",
      "Epoch 1763/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5810e-04 - val_loss: 3.6755e-04\n",
      "Epoch 1764/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.4552e-04 - val_loss: 3.5863e-04\n",
      "Epoch 1765/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5723e-04 - val_loss: 4.2149e-04\n",
      "Epoch 1766/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4652e-04 - val_loss: 4.0031e-04\n",
      "Epoch 1767/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4502e-04 - val_loss: 3.9946e-04\n",
      "Epoch 1768/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.4258e-04 - val_loss: 4.4485e-04\n",
      "Epoch 1769/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.4439e-04 - val_loss: 3.8947e-04\n",
      "Epoch 1770/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.4771e-04 - val_loss: 3.9089e-04\n",
      "Epoch 1771/2000\n",
      "4059/4059 [==============================] - 2s 604us/step - loss: 2.3714e-04 - val_loss: 4.0340e-04\n",
      "Epoch 1772/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.4616e-04 - val_loss: 3.9879e-04\n",
      "Epoch 1773/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.4127e-04 - val_loss: 3.8740e-04\n",
      "Epoch 1774/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.4399e-04 - val_loss: 4.6214e-04\n",
      "Epoch 1775/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.5514e-04 - val_loss: 4.6163e-04\n",
      "Epoch 1776/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.5731e-04 - val_loss: 4.0731e-04\n",
      "Epoch 1777/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.5849e-04 - val_loss: 4.2670e-04\n",
      "Epoch 1778/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.5136e-04 - val_loss: 4.2681e-04\n",
      "Epoch 1779/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.4352e-04 - val_loss: 4.1528e-04\n",
      "Epoch 1780/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.4782e-04 - val_loss: 4.2144e-04\n",
      "Epoch 1781/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.3870e-04 - val_loss: 4.5733e-04\n",
      "Epoch 1782/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4285e-04 - val_loss: 5.0309e-04\n",
      "Epoch 1783/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5541e-04 - val_loss: 3.9547e-04\n",
      "Epoch 1784/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5796e-04 - val_loss: 4.5310e-04\n",
      "Epoch 1785/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5972e-04 - val_loss: 3.9425e-04\n",
      "Epoch 1786/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6236e-04 - val_loss: 4.4924e-04\n",
      "Epoch 1787/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5501e-04 - val_loss: 4.9789e-04\n",
      "Epoch 1788/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5658e-04 - val_loss: 4.4864e-04\n",
      "Epoch 1789/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.4537e-04 - val_loss: 4.2692e-04\n",
      "Epoch 1790/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.4197e-04 - val_loss: 4.0120e-04\n",
      "Epoch 1791/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.4697e-04 - val_loss: 4.0266e-04\n",
      "Epoch 1792/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4727e-04 - val_loss: 3.8759e-04\n",
      "Epoch 1793/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.5389e-04 - val_loss: 3.8938e-04\n",
      "Epoch 1794/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.4876e-04 - val_loss: 3.8838e-04\n",
      "Epoch 1795/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.4211e-04 - val_loss: 4.2291e-04\n",
      "Epoch 1796/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3550e-04 - val_loss: 4.2128e-04\n",
      "Epoch 1797/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4198e-04 - val_loss: 4.2149e-04\n",
      "Epoch 1798/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.4324e-04 - val_loss: 4.0602e-04\n",
      "Epoch 1799/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5405e-04 - val_loss: 3.8977e-04\n",
      "Epoch 1800/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.4793e-04 - val_loss: 4.7171e-04\n",
      "Epoch 1801/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.3857e-04 - val_loss: 4.0393e-04\n",
      "Epoch 1802/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.4833e-04 - val_loss: 4.0639e-04\n",
      "Epoch 1803/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.4756e-04 - val_loss: 4.0680e-04\n",
      "Epoch 1804/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.3312e-04 - val_loss: 4.5183e-04\n",
      "Epoch 1805/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4742e-04 - val_loss: 4.4911e-04\n",
      "Epoch 1806/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.5263e-04 - val_loss: 4.9929e-04\n",
      "Epoch 1807/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.5780e-04 - val_loss: 5.2318e-04\n",
      "Epoch 1808/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.6466e-04 - val_loss: 5.9496e-04\n",
      "Epoch 1809/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6693e-04 - val_loss: 3.8150e-04\n",
      "Epoch 1810/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.4536e-04 - val_loss: 4.5536e-04\n",
      "Epoch 1811/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.3663e-04 - val_loss: 4.4595e-04\n",
      "Epoch 1812/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.4934e-04 - val_loss: 4.6347e-04\n",
      "Epoch 1813/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.4247e-04 - val_loss: 4.6957e-04\n",
      "Epoch 1814/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.5993e-04 - val_loss: 4.4594e-04\n",
      "Epoch 1815/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.5034e-04 - val_loss: 4.7777e-04\n",
      "Epoch 1816/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4981e-04 - val_loss: 4.3497e-04\n",
      "Epoch 1817/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.5551e-04 - val_loss: 4.0886e-04\n",
      "Epoch 1818/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4661e-04 - val_loss: 4.7367e-04\n",
      "Epoch 1819/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4857e-04 - val_loss: 4.1551e-04\n",
      "Epoch 1820/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.5950e-04 - val_loss: 4.7977e-04\n",
      "Epoch 1821/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.4096e-04 - val_loss: 4.2396e-04\n",
      "Epoch 1822/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.4133e-04 - val_loss: 4.1487e-04\n",
      "Epoch 1823/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.3496e-04 - val_loss: 4.1983e-04\n",
      "Epoch 1824/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.3439e-04 - val_loss: 5.0220e-04\n",
      "Epoch 1825/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.3861e-04 - val_loss: 4.5943e-04\n",
      "Epoch 1826/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3758e-04 - val_loss: 4.5062e-04\n",
      "Epoch 1827/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2626e-04 - val_loss: 4.9428e-04\n",
      "Epoch 1828/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3480e-04 - val_loss: 4.4847e-04\n",
      "Epoch 1829/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3040e-04 - val_loss: 4.7849e-04\n",
      "Epoch 1830/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3061e-04 - val_loss: 4.7992e-04\n",
      "Epoch 1831/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.3723e-04 - val_loss: 5.4631e-04\n",
      "Epoch 1832/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.3459e-04 - val_loss: 5.2032e-04\n",
      "Epoch 1833/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.2751e-04 - val_loss: 4.4884e-04\n",
      "Epoch 1834/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3538e-04 - val_loss: 4.6851e-04\n",
      "Epoch 1835/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.3432e-04 - val_loss: 4.2869e-04\n",
      "Epoch 1836/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.4805e-04 - val_loss: 5.4613e-04\n",
      "Epoch 1837/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.6485e-04 - val_loss: 4.3967e-04\n",
      "Epoch 1838/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5354e-04 - val_loss: 4.8608e-04\n",
      "Epoch 1839/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3839e-04 - val_loss: 4.3159e-04\n",
      "Epoch 1840/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.3992e-04 - val_loss: 6.0982e-04\n",
      "Epoch 1841/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4701e-04 - val_loss: 4.9614e-04\n",
      "Epoch 1842/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.3948e-04 - val_loss: 5.2473e-04\n",
      "Epoch 1843/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.2990e-04 - val_loss: 5.0474e-04\n",
      "Epoch 1844/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3528e-04 - val_loss: 5.6305e-04\n",
      "Epoch 1845/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3646e-04 - val_loss: 5.0248e-04\n",
      "Epoch 1846/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3462e-04 - val_loss: 4.9929e-04\n",
      "Epoch 1847/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.3664e-04 - val_loss: 5.6235e-04\n",
      "Epoch 1848/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4268e-04 - val_loss: 5.3999e-04\n",
      "Epoch 1849/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.4220e-04 - val_loss: 5.0356e-04\n",
      "Epoch 1850/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.3636e-04 - val_loss: 5.5411e-04\n",
      "Epoch 1851/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.4372e-04 - val_loss: 4.3010e-04\n",
      "Epoch 1852/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.4488e-04 - val_loss: 4.4423e-04\n",
      "Epoch 1853/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.3071e-04 - val_loss: 4.3939e-04\n",
      "Epoch 1854/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3518e-04 - val_loss: 5.0430e-04\n",
      "Epoch 1855/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3290e-04 - val_loss: 5.6054e-04\n",
      "Epoch 1856/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.4138e-04 - val_loss: 5.7103e-04\n",
      "Epoch 1857/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.4256e-04 - val_loss: 5.1355e-04\n",
      "Epoch 1858/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3951e-04 - val_loss: 4.8204e-04\n",
      "Epoch 1859/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.4432e-04 - val_loss: 4.8286e-04\n",
      "Epoch 1860/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.3760e-04 - val_loss: 5.1851e-04\n",
      "Epoch 1861/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3461e-04 - val_loss: 6.4892e-04\n",
      "Epoch 1862/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3753e-04 - val_loss: 4.8432e-04\n",
      "Epoch 1863/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2999e-04 - val_loss: 5.5110e-04\n",
      "Epoch 1864/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.2223e-04 - val_loss: 5.5964e-04\n",
      "Epoch 1865/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2963e-04 - val_loss: 4.9889e-04\n",
      "Epoch 1866/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.2502e-04 - val_loss: 6.7517e-04\n",
      "Epoch 1867/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.1847e-04 - val_loss: 5.1882e-04\n",
      "Epoch 1868/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3800e-04 - val_loss: 5.4056e-04\n",
      "Epoch 1869/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.3044e-04 - val_loss: 4.8801e-04\n",
      "Epoch 1870/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.3601e-04 - val_loss: 5.6683e-04\n",
      "Epoch 1871/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.4221e-04 - val_loss: 5.5219e-04\n",
      "Epoch 1872/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.5771e-04 - val_loss: 4.9788e-04\n",
      "Epoch 1873/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.4778e-04 - val_loss: 6.2016e-04\n",
      "Epoch 1874/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3972e-04 - val_loss: 5.6981e-04\n",
      "Epoch 1875/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3299e-04 - val_loss: 6.8824e-04\n",
      "Epoch 1876/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2529e-04 - val_loss: 6.4995e-04\n",
      "Epoch 1877/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.3100e-04 - val_loss: 6.8635e-04\n",
      "Epoch 1878/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.2289e-04 - val_loss: 6.0090e-04\n",
      "Epoch 1879/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.3037e-04 - val_loss: 5.6445e-04\n",
      "Epoch 1880/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.3425e-04 - val_loss: 5.0583e-04\n",
      "Epoch 1881/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2540e-04 - val_loss: 8.3984e-04\n",
      "Epoch 1882/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3798e-04 - val_loss: 7.5385e-04\n",
      "Epoch 1883/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3639e-04 - val_loss: 6.7597e-04\n",
      "Epoch 1884/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.3735e-04 - val_loss: 5.9161e-04\n",
      "Epoch 1885/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3378e-04 - val_loss: 5.6422e-04\n",
      "Epoch 1886/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3049e-04 - val_loss: 5.9066e-04\n",
      "Epoch 1887/2000\n",
      "4059/4059 [==============================] - 2s 595us/step - loss: 2.2090e-04 - val_loss: 6.6186e-04\n",
      "Epoch 1888/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3749e-04 - val_loss: 5.0531e-04\n",
      "Epoch 1889/2000\n",
      "4059/4059 [==============================] - 2s 594us/step - loss: 2.4746e-04 - val_loss: 6.2171e-04\n",
      "Epoch 1890/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2773e-04 - val_loss: 6.2873e-04\n",
      "Epoch 1891/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.1653e-04 - val_loss: 5.5609e-04\n",
      "Epoch 1892/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2444e-04 - val_loss: 5.6334e-04\n",
      "Epoch 1893/2000\n",
      "4059/4059 [==============================] - 2s 602us/step - loss: 2.2124e-04 - val_loss: 5.7567e-04\n",
      "Epoch 1894/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.2250e-04 - val_loss: 5.8494e-04\n",
      "Epoch 1895/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.2621e-04 - val_loss: 6.6319e-04\n",
      "Epoch 1896/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.3122e-04 - val_loss: 5.9955e-04\n",
      "Epoch 1897/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.3692e-04 - val_loss: 6.4588e-04\n",
      "Epoch 1898/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.3483e-04 - val_loss: 6.5145e-04\n",
      "Epoch 1899/2000\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 2.3265e-04 - val_loss: 7.1003e-04\n",
      "Epoch 1900/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.3208e-04 - val_loss: 5.5309e-04\n",
      "Epoch 1901/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.3609e-04 - val_loss: 5.9039e-04\n",
      "Epoch 1902/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.2350e-04 - val_loss: 5.9440e-04\n",
      "Epoch 1903/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.2740e-04 - val_loss: 6.2297e-04\n",
      "Epoch 1904/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2246e-04 - val_loss: 6.4040e-04\n",
      "Epoch 1905/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.2960e-04 - val_loss: 8.7996e-04\n",
      "Epoch 1906/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2143e-04 - val_loss: 5.9250e-04\n",
      "Epoch 1907/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.2250e-04 - val_loss: 6.2749e-04\n",
      "Epoch 1908/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2087e-04 - val_loss: 5.7222e-04\n",
      "Epoch 1909/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2630e-04 - val_loss: 7.6949e-04\n",
      "Epoch 1910/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.2215e-04 - val_loss: 5.5425e-04\n",
      "Epoch 1911/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.1414e-04 - val_loss: 6.7204e-04\n",
      "Epoch 1912/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2181e-04 - val_loss: 6.5188e-04\n",
      "Epoch 1913/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.0977e-04 - val_loss: 8.5370e-04\n",
      "Epoch 1914/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.1316e-04 - val_loss: 6.5894e-04\n",
      "Epoch 1915/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.2955e-04 - val_loss: 6.6552e-04\n",
      "Epoch 1916/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.3653e-04 - val_loss: 6.7656e-04\n",
      "Epoch 1917/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.2929e-04 - val_loss: 5.9574e-04\n",
      "Epoch 1918/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.1738e-04 - val_loss: 6.4395e-04\n",
      "Epoch 1919/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.2029e-04 - val_loss: 5.0780e-04\n",
      "Epoch 1920/2000\n",
      "4059/4059 [==============================] - 2s 596us/step - loss: 2.3526e-04 - val_loss: 6.1515e-04\n",
      "Epoch 1921/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.2439e-04 - val_loss: 6.9750e-04\n",
      "Epoch 1922/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.2400e-04 - val_loss: 7.7671e-04\n",
      "Epoch 1923/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.2427e-04 - val_loss: 7.7414e-04\n",
      "Epoch 1924/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.3218e-04 - val_loss: 6.9974e-04\n",
      "Epoch 1925/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.4715e-04 - val_loss: 7.6044e-04\n",
      "Epoch 1926/2000\n",
      "4059/4059 [==============================] - 2s 600us/step - loss: 2.2954e-04 - val_loss: 5.6951e-04\n",
      "Epoch 1927/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.1976e-04 - val_loss: 7.7253e-04\n",
      "Epoch 1928/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2164e-04 - val_loss: 6.6109e-04\n",
      "Epoch 1929/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.1875e-04 - val_loss: 8.1689e-04\n",
      "Epoch 1930/2000\n",
      "4059/4059 [==============================] - 2s 599us/step - loss: 2.3658e-04 - val_loss: 6.8831e-04\n",
      "Epoch 1931/2000\n",
      "4059/4059 [==============================] - 2s 598us/step - loss: 2.2749e-04 - val_loss: 6.5742e-04\n",
      "Epoch 1932/2000\n",
      "4059/4059 [==============================] - 2s 601us/step - loss: 2.1558e-04 - val_loss: 7.0759e-04\n",
      "Epoch 1933/2000\n",
      "4059/4059 [==============================] - 2s 597us/step - loss: 2.2568e-04 - val_loss: 6.6329e-04\n",
      "Epoch 1934/2000\n",
      "4059/4059 [==============================] - 2s 606us/step - loss: 2.3060e-04 - val_loss: 6.6493e-04\n",
      "Epoch 1935/2000\n",
      "4059/4059 [==============================] - 2s 592us/step - loss: 2.3114e-04 - val_loss: 6.9227e-04\n",
      "Epoch 1936/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.2657e-04 - val_loss: 6.1330e-04\n",
      "Epoch 1937/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.2353e-04 - val_loss: 7.3867e-04\n",
      "Epoch 1938/2000\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 2.2549e-04 - val_loss: 7.6874e-04\n",
      "Epoch 1939/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.2132e-04 - val_loss: 7.5761e-04\n",
      "Epoch 1940/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.2260e-04 - val_loss: 9.6079e-04\n",
      "Epoch 1941/2000\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 2.3074e-04 - val_loss: 9.5466e-04\n",
      "Epoch 1942/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.2731e-04 - val_loss: 8.3473e-04\n",
      "Epoch 1943/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.2050e-04 - val_loss: 6.9401e-04\n",
      "Epoch 1944/2000\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 2.3158e-04 - val_loss: 6.4098e-04\n",
      "Epoch 1945/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.1477e-04 - val_loss: 7.8594e-04\n",
      "Epoch 1946/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.2256e-04 - val_loss: 6.0472e-04\n",
      "Epoch 1947/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.3360e-04 - val_loss: 8.3161e-04\n",
      "Epoch 1948/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.6543e-04 - val_loss: 6.2266e-04\n",
      "Epoch 1949/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.7647e-04 - val_loss: 7.0095e-04\n",
      "Epoch 1950/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.5768e-04 - val_loss: 5.1335e-04\n",
      "Epoch 1951/2000\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 2.4852e-04 - val_loss: 5.6027e-04\n",
      "Epoch 1952/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 2.3794e-04 - val_loss: 6.1026e-04\n",
      "Epoch 1953/2000\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 2.2894e-04 - val_loss: 6.5754e-04\n",
      "Epoch 1954/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 2.3189e-04 - val_loss: 6.2353e-04\n",
      "Epoch 1955/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.2488e-04 - val_loss: 7.0145e-04\n",
      "Epoch 1956/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.1867e-04 - val_loss: 6.2783e-04\n",
      "Epoch 1957/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 2.1819e-04 - val_loss: 7.0322e-04\n",
      "Epoch 1958/2000\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 2.0566e-04 - val_loss: 8.1980e-04\n",
      "Epoch 1959/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.3240e-04 - val_loss: 6.6548e-04\n",
      "Epoch 1960/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.3728e-04 - val_loss: 7.9198e-04\n",
      "Epoch 1961/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.2376e-04 - val_loss: 7.3295e-04\n",
      "Epoch 1962/2000\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 2.2581e-04 - val_loss: 7.2644e-04\n",
      "Epoch 1963/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.1693e-04 - val_loss: 8.5451e-04\n",
      "Epoch 1964/2000\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 2.2407e-04 - val_loss: 5.7805e-04\n",
      "Epoch 1965/2000\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 2.2787e-04 - val_loss: 7.9697e-04\n",
      "Epoch 1966/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.2078e-04 - val_loss: 6.3385e-04\n",
      "Epoch 1967/2000\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 2.1613e-04 - val_loss: 7.1491e-04\n",
      "Epoch 1968/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 2.0829e-04 - val_loss: 7.3852e-04\n",
      "Epoch 1969/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.0854e-04 - val_loss: 8.7949e-04\n",
      "Epoch 1970/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.0618e-04 - val_loss: 6.2703e-04\n",
      "Epoch 1971/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.1070e-04 - val_loss: 8.5752e-04\n",
      "Epoch 1972/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.0800e-04 - val_loss: 8.2589e-04\n",
      "Epoch 1973/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.1609e-04 - val_loss: 8.2726e-04\n",
      "Epoch 1974/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.0966e-04 - val_loss: 6.4158e-04\n",
      "Epoch 1975/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.0903e-04 - val_loss: 9.3899e-04\n",
      "Epoch 1976/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.2494e-04 - val_loss: 7.8111e-04\n",
      "Epoch 1977/2000\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 2.2230e-04 - val_loss: 7.4182e-04\n",
      "Epoch 1978/2000\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 2.1653e-04 - val_loss: 9.5555e-04\n",
      "Epoch 1979/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 2.1138e-04 - val_loss: 6.9277e-04\n",
      "Epoch 1980/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.1285e-04 - val_loss: 7.3576e-04\n",
      "Epoch 1981/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.1285e-04 - val_loss: 8.9927e-04\n",
      "Epoch 1982/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.4015e-04 - val_loss: 8.9714e-04\n",
      "Epoch 1983/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 2.3634e-04 - val_loss: 8.1617e-04\n",
      "Epoch 1984/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.4209e-04 - val_loss: 8.4191e-04\n",
      "Epoch 1985/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.1999e-04 - val_loss: 7.3535e-04\n",
      "Epoch 1986/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.0773e-04 - val_loss: 9.2694e-04\n",
      "Epoch 1987/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.1410e-04 - val_loss: 8.8924e-04\n",
      "Epoch 1988/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.1127e-04 - val_loss: 8.2711e-04\n",
      "Epoch 1989/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.1900e-04 - val_loss: 7.0374e-04\n",
      "Epoch 1990/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.4472e-04 - val_loss: 6.6581e-04\n",
      "Epoch 1991/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 2.4971e-04 - val_loss: 9.0783e-04\n",
      "Epoch 1992/2000\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 2.4132e-04 - val_loss: 6.9835e-04\n",
      "Epoch 1993/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.1881e-04 - val_loss: 6.8222e-04\n",
      "Epoch 1994/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 2.2973e-04 - val_loss: 8.1055e-04\n",
      "Epoch 1995/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.1519e-04 - val_loss: 8.2050e-04\n",
      "Epoch 1996/2000\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 2.1337e-04 - val_loss: 8.5285e-04\n",
      "Epoch 1997/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 2.0279e-04 - val_loss: 7.7767e-04\n",
      "Epoch 1998/2000\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 1.9804e-04 - val_loss: 7.9366e-04\n",
      "Epoch 1999/2000\n",
      "4059/4059 [==============================] - 2s 590us/step - loss: 2.0018e-04 - val_loss: 8.3760e-04\n",
      "Epoch 2000/2000\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 2.0280e-04 - val_loss: 7.3427e-04\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'density': 238,\n",
       " 'twice': True,\n",
       " 'optimizer': 'adam',\n",
       " 'dropout': 0.1,\n",
       " 'activation': 'elu',\n",
       " 'full_density': True,\n",
       " 'shuffle': True,\n",
       " 'lstmsize': 176,\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x246434b7188>]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_184\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_367 (LSTM)              (None, 92, 176)           128128    \n",
      "_________________________________________________________________\n",
      "dropout_367 (Dropout)        (None, 92, 176)           0         \n",
      "_________________________________________________________________\n",
      "lstm_368 (LSTM)              (None, 176)               248512    \n",
      "_________________________________________________________________\n",
      "dropout_368 (Dropout)        (None, 176)               0         \n",
      "_________________________________________________________________\n",
      "dense_945 (Dense)            (None, 238)               42126     \n",
      "_________________________________________________________________\n",
      "dense_946 (Dense)            (None, 119)               28441     \n",
      "_________________________________________________________________\n",
      "dense_947 (Dense)            (None, 59)                7080      \n",
      "_________________________________________________________________\n",
      "dense_948 (Dense)            (None, 29)                1740      \n",
      "_________________________________________________________________\n",
      "dense_949 (Dense)            (None, 14)                420       \n",
      "_________________________________________________________________\n",
      "dense_950 (Dense)            (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 456,462\n",
      "Trainable params: 456,462\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_2days/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 13.18\n",
      "Medium error is 2.52\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 67.26%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 41.78%\n",
      "Accuracy for downward trend is: 86.84%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAACdwAAAc1CAYAAACU+4XAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAMTQAADE0B0s6tTgAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nOzdbXPUd57f+0/rAgFqwAYkYfAFoG4xsZlks5nMno03Mx6D7ToXdR7LuZXK5hGck83d8xBOJamkUqmtpCq+3Jk5O7vZ7G4yu8aeoVuyjceyaQkw0BKgy86NlmY8ay4a1N3/lni97vyM1P3/f32T4l2/b6nVarUCAAAAAAAAAAAAPNRQ0QMAAAAAAAAAAADAbiC4AwAAAAAAAAAAgA4I7gAAAAAAAAAAAKADgjsAAAAAAAAAAADogOAOAAAAAAAAAAAAOiC4AwAAAAAAAAAAgA6MFD3A/YyNjWViYqLoMQAAAAAAAAAAAHjKLC4uZmVl5b6/G8jgbmJiIl988UXRYwAAAAAAAAAAAPCUef755x/4OytlAQAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAAAACADgjuAAAAAAAAAAAAoAOCOwAAAAAAAAAAAOiA4A4AAAAAAAAAAAA6ILgDAAAAAAAG1ufX72Rzs1X0GAAAAJBEcAcAAAAAAAyoS/O38oM/+pP8x5/PFz0KAAAAJBHcAQAAAAAAA+p//Opm+/z8ZsGTAAAAQJvgDgAAAAAAGEi1q80kyezCUsGTAAAAQJvgDgAAAAAAGEi1xlZwtyi4AwAAYDAI7gAAAAAAgIFU37rZbrG5klt31wqeBgAAAAR3AAAAAADAALq2tJIby6sZKrX/bK0sAAAAg0BwBwAAAAAADJztdbK/d+ZYkmROcAcAAMAAENwBAAAAAAADp3a1Hdz9b989kSSZXRTcAQAAUDzBHQAAAAAAMHBqWzfavf73prJveCj1rRvvAAAAoEiCOwAAAAAAYODUG80c2j+Sk0f258zxcTfcAQAAMBAEdwAAAAAAwEBptVqpNZZybupQSqVSKpPlfPH13dxb2yh6NAAAAJ5ygjsAAAAAAGCgLDZXcuvuWqpTh5IklclyWq1kzi13AAAAFExwBwAAAAAADJTLjWaSZGaqnKQd3CXJ7ILgDgAAgGIJ7gAAAAAAgIFSa7TDuplv3HCXJHOCOwAAAAomuAMAAAAAAAZKfeuGu+rWDXdnjo9nqJTMWikLAABAwQR3AAAAAADAQKk1mnn24GgmymNJkv2jw3nh6EErZQEAACic4A4AAAAAABgYrVYr9cZSqlOHUiqVfv3zykQ5n15bzvrGZoHTAQAA8LQT3AEAAAAAAAPjq1v30lxZz8zWOtltlcly1jZa+fzGnYImAwAAAMEdAAAAAAAwQGqNZpJkZurQb/18erId4FkrCwAAQJEEdwAAAAAAwMCoN9pBXXXyt4O7ylZwVxfcAQAAUCDBHQAAAAAAMDB+c8Pdt1fKJsmc4A4AAIACCe4AAAAAAICBUVtYyvHyvhwrj/3Wzw/vH83kobHMLgruAAAAKI7gDgAAAAAAGAibm63UG81vrZPdVpksZ25hKa1Wq8+TAQAAQJvgDgAAAAAAGAjzN+/mzurGt9bJbqtMlrO8upGvbt3r82QAAADQJrgDAAAAAAAGQn2hmSSpTt3/hrvqZDvEm12wVhYAAIBiCO4AAAAAAICBUGu0Q7pzJ+4f3E0L7gAAACiY4A4AAAAAABgItUb7hruZyfsHd5Xt4G5RcAcAAEAxBHcAAAAAAMBAqDWamTw0liMHR+/7+4nyWA7vH3HDHQAAAIUR3AEAAAAAAIXb3GxldmEpM1P3v90uSUqlUiqT5cwJ7gAAACiI4A4AAAAAACjcr76+k3trm6lOlR/6ucpkOdeXV/P18mqfJgMAAIDfENwBAAAAAACFqzXat9ade8gNd0k7uEuS2UW33AEAANB/gjsAAAAAAKBwtUYzSVLtMLirNwR3AAAA9J/gDgAAAAAAKFz918HdI1bKTrSDvNkFwR0AAAD9J7gDAAAAAAAKd7mxlOeO7M/h/aMP/dypZw9kbGTISlkAAAAKIbgDAAAAAAAKtbHZytzi0iPXySbJ8FApZyfKmXPDHQAAAAUQ3AEAAAAAAIW6cn05q+ubOfeIdbLbKpPlzN+8m+WV9R5PBgAAAL9NcAcAAAAAABSq1mjfVtfJDXdJUp1sh3mfLC73bCYAAAC4H8EdAAAAAABQqHqjmSSZ6TC4q2wFd7OLzZ7NBAAAAPcjuAMAAAAAAAp1eSu427657lF+HdwtLPVsJgAAALgfwR0AAAAAAFCoemMpp545kPGxkY4+f/rYeIaHSoI7AAAA+k5wBwAAAAAAFGZtYzOfXFvKuROdrZNNkn0jQ3np6EHBHQAAAH0nuAMAAAAAAApz5fpy1jZaqU51tk522/RkOVeu38naxmaPJgMAAIBvE9wBAAAAAACFqTXat9TNTHZ+w12SVCbLWd9s5cr15V6MBQAAAPcluAMAAAAAAApz+WozSTIz9ZjB3UT7Rrx6w1pZAAAA+kdwBwAAAAAAFKa+0Eyp1L6x7nFsf352QXAHAABA/wjuAAAAAACAwtQaS3nx6MEc2Df8WN+b3g7uFgV3AAAA9I/gDgAAAAAAKMTq+mY+u7ac6uTjrZNNkvLYSJ47st8NdwAAAPSV4A4AAAAAACjEp9eWs77ZyszU462T3VaZLGducSmbm60uTwYAAAD3J7gDAAAAAAAKcbnRTJLMTD3+DXdJO7i7t7aZ+Zt3uzkWAAAAPJDgDgAAAAAAKER9K7ir7uCGuySZXbRWFgAAgP4Q3AEAAAAAAIWoNZoZKiXTE08Y3G19b25BcAcAAEB/CO4AAAAAAIBC1BtLOX1sPPtHh5/o+7++4U5wBwAAQJ8I7gAAAAAAgL67t7aRz64vP/E62SQ5Vh7LswdHBXcAAAD0jeAOAAAAAADou7nFpWy2kpmpQzt6TmWynPrCUlqtVpcmAwAAgAcT3AEAAAAAAH1Xb7Rvpat2Ibi7dXct15ZWuzEWAAAAPJTgDgAAAAAA6Ltao5kkObfD4G56or2S1lpZAAAA+kFwBwAAAAAA9F2tsZSRoVLOHB/f0XMqk1vB3aLgDgAAgN4T3AEAAAAAAH1XX2jm9PHx7BvZ2T9VbAd3c264AwAAoA8EdwAAAAAAQF/dXd3I5zfuZGaqvONnnTxyIAdGh62UBQAAoC8EdwAAAAAAQF/NLiyl1Uqqk4d2/KyhoVKmJ8cFdwAAAPSF4A4AAAAAAOirWqOZJDl3YufBXZJUJsq5evtemvfWuvI8AAAAeBDBHQAAAAAA0Fe1hXZw142VsklSnWqHe3OLy115HgAAADyI4A4AAAAAAOiremMpo8OlvHRsvCvPm55oh3vWygIAANBrgjsAAAAAAKCvLl9t5uzxckaHu/PPFJVJwR0AAAD9IbgDAAAAAAD6ZnllPfM376bapXWySfLSsYMZGSoJ7gAAAOg5wR0AAAAAANA39a0o7tzUoa49c3R4KKePj2duUXAHAABAbwnuAAAAAACAvqk1mkmSaheDuySpTJRz5fpy7q1tdPW5AAAA8E2COwAAAAAAoG/qW8HdTBdXyiZJZbKczVby2fXlrj4XAAAAvklwBwAAAAAA9E2tsZR9I0N56dh4V59bmWwHfLML1soCAADQO4I7AAAAAACgb2qNZqYnyhkeKnX1uYI7AAAA+kFwBwAAAAAA9MXte2v56ta9nOvyOtkkOTvRvjFPcAcAAEAvCe4AAAAAAIC+qDfaMVx16lDXn31w30hOPXNAcAcAAEBPCe4AAAAAAIC+qDeaSZKZHgR3SXut7CfXlrOx2erJ85/Y+mqyIgQEAADYCwR3AAAAAABAX9S2brib6cFK2SSpTpazur6ZL76+05PnP7H/9H8l/+/3k421oicBAABghwR3AAAAAABAX9QazewfHcoLzx7syfMrk+2Qb6DWyq6vJh//cXJ7PvniL4ueBgAAgB0S3AEAAAAAAH1RazRTnTyUoaFST54/kMHd53+WrLZX6Wb2vWJnAQAAYMcEdwAAAAAAQM/durOWheZKqj1aJ5sMaHBXf7d9Do0K7gAAAPYAwR0AAAAAANBztYX2LW8zU4d69o5nDu7L8fK+zC4OUHBXezs59Fzy8v+ZfPU3ydJi0RMBAACwA4I7AAAAAACg52qN7eCudzfcJcn0RDmzjaW0Wq2evqcjNz5JrteT6htJ5WL7Z3MfFDsTAAAAOyK4AwAAAAAAeq52tR3cVSd7d8Nd0l4r21xZz0Jzpafv6cj2OtnqW8n06+3/tlYWAABgVxPcAQAAAAAAPVdrLGV833BOPXOgp++pTLZv0JtdGIC1srW3k6HR5OxryaETyYnvJnPvJ5ubRU8GAADAExLcAQAAAAAAPVdfaKYydShDQ6WevmdggrvV5eSzP01Ov5qMba3RrVxM7lxPvvp5sbMBAADwxAR3AAAAAABAT91YXs21pdXMbMVwvTQwwd0nP0k2VtrrZLdVLrbPufeLmQkAAIAdE9wBAAAAAAA9VWs0kyQzU4d6/q4Th/enPDZSfHBXf6d9znwjuHv++8m+cjIruAMAANitBHcAAAAAAEBPbQd31ane33BXKpUyPTGe2cUCg7tWqx3cHZ1Ojk3/5ucj+5IzP0x+9d+SuzeLmw8AAIAnJrgDAAAAAAB6aju4O3ei9zfcJcn0ZDmLzZXcurvWl/d9S+Oj5PZ8Un3z27+rXEhaG8mnP+n/XAAAAOyY4A4AAAAAAOipWmMph8ZGcuLw/r68rzrZDvsKWyv763WyDwjukmT2vf7NAwAAQNcI7gAAAAAAgJ5ptVqpN5qpTpVTKpX68s7KZHt17VyRwd3oePLSq9/+3bOnk2PVZPaD9upZAAAAdhXBHQAAAAAA0DPXllbz9Z21zEz1Z51s8pvgbnaxgODuzo3kV3+RnH0tGRm7/2cqF5LbXySLl/s5GQAAAF0guAMAAAAAAHqm1mgmSap9DO5eePZA9g0Ppb717r6a+yBpbd5/ney2ysX2aa0sAADAriO4AwAAAAAAemY7uDvXx+BuZHgoZ46PF3PDXf2d9ll9SHD30qvJ8JjgDgAAYBcS3AEAAAAAAD1Ta7Sjt5mpcl/fW5ks54uv7+be2kb/Xrq5kdTfTaa+mxw++eDP7TuYnH41ufJnyeqd/s0HAADAjgnuAAAAAACAnqk3mjlyYDQTh8b6+t7pyXJarWSun7fczf91cvfGw9fJbqtcTDZWkis/6/1cAAAAdI3gDgAAAAAA6IlWq5Vao5mZqXJKpVJf312ZbN+oN7vQx+Du1+tk33r0Z6cvtE9rZQEAAHYVwR0AAAAAANATjdsruX1vPdWpQ31/d2WiHdzN9TO4q72dHHg2ef57j/7sxLnk8POCOwAAgF1GcAcAAAAAAPRErdFMkpwrILg7OzGeUimZ7ddK2dtfJVf/tr0qdmj40Z8vlZLKheT6bHLj097PBwAAQFcI7gAAAAAAgJ7YDu6qU+W+v3v/6HBeePZg/1bKzr7bPjtZJ7utcrF9zr3f/XkAAADoCcEdAAAAAADQE/VGO3abKeCGuySpTJbz6bXlrG9s9v5ltbeT0lD71rpOnf1hUhpOZj/o3VwAAAB0leAOAAAAAADoidpCM0fH9+V4eayQ91cny1nbaOXzG3d6+6L1leSTHyfP/+Pk4NHOv7f/SPLC95NPf5Ksr/ZsPAAAALpHcAcAAAAAAHRdq9VKvbGU6mT/18lum956d8/Xyn7+58nqUlJ98/G/W7nQ/u6v/qL7cwEAANB1gjsAAAAAAKDrvrx1L0sr6zl3oph1skl7pWySzC72OLirvdM+Z956/O9WLrbP2fe6Nw8AAAA9I7gDAAAAAAC6rtZoJkmqUwMQ3DV6HNzV304OnUymzj/+d0/8g+Tg8WT2/e7PBQAAQNcJ7gAAAAAAgK6rbwV3MwWulD28fzSTh8Z6e8Pd9bnk+mxSfSMplR7/+0ND7bWyjQ+T5tXuzwcAAEBXCe4AAAAAAICuq23dKjdT4A13SfuWu7mFpbRard68oP5u+3ySdbLbpi+0z7kPdj4PAAAAPSW4AwAAAAAAuq7eaOZ4eSzPju8rdI7KZDnLqxv56ta93ryg/nYyvC8588Mnf8b06+1z9r3uzAQAAEDPCO4AAAAAAICu2txspdZYyrkTxa2T3VbZWmk7u9CDtbIrS8lnf5q89GoytoP/1/JE8tzvtG+429zo3nwAAAB0neAOAAAAAADoqvmbd3N3bSPVyWLXySZJZaKHwd2nP002Vne2TnZb5WJy9+vky/+x82cBAADQM4I7AAAAAACgq2qNZpJkZmoAgrvtG+4WexDc1d9un9U3d/6sysX2Ofv+zp8FAABAzwjuAAAAAACArqo12nHbzFTxK2UnDo3l0P6R7t9w12ol9XeTo9PJsemdP+/57yVjh5PZ93b+LAAAAHpGcAcAAAAAAHRVfeuGu+oA3HBXKpVSmSxnrtvBXeOj5PZ8d9bJJsnwaHL2h8n8XyV3bnTnmQAAAHSd4A4AAAAAAOiqy41mThzenyMHRoseJUlSmSjn+vJqvl5e7d5Du7lOdlvlYtLaTD75cfeeCQAAQFcJ7gAAAAAAgK7Z2GxldmEp1QFYJ7tte5bZxS7ecld7JxkdT176J9175vSF9jn7fveeCQAAQFcJ7gAAAAAAgK751Y07WVnfzMwArJPdVpncCu66tVb2zo3ki/+WTP8oGRnrzjOT5JkXkonvJHPvJ61W954LAABA1wjuAAAAAACArqk1mkmSmQG64a4y0Y7/6o0uBXdzH7RXv3Zzney26QtJ86tk4ePuPxsAAIAdE9wBAAAAAABdU9+6Ra46QDfcnXr2QMZGhrq3Urb2dvusvtGd531TZXut7HvdfzYAAAA7JrgDAAAAAAC65vLV9g131cnBueFueKiUsxPlzHVjpezmRjuGO/Hd5PDJnT/v73rp1WTkgOAOAABgQAnuAAAAAACArqk1mjn1zIEc2j9a9Ci/pTJZzvzNu1leWd/Zg+b/Orl7I6m+1Z3B/q7R/cnpP0iu/Hmy0qUb+QAAAOgawR0AAAAAANAV6xub+WRxOdWpwbndbltloj3TJ4vLO3vQr9fJvrnDiR6icjHZXEs++9PevQMAAIAnIrgDAAAAAAC64sqNO1nd2MzM1KGiR/mWytaK29nF5s4eVH87OXA0ef57XZjqASoX2qe1sgAAAANHcAcAAAAAAHRFvdGO2aqTA3jD3XZwt7CDNa23v0yufti+gW5ouEuT3cexSvLMi4I7AACAASS4AwAAAAAAuuLy1XbMdu7E4N1wd/r4wQyVdhjc1d9tnzNvdWeoBymV2lHf158m1+d6+y4AAAAei+AOAAAAAADoitpC+4a7ygDecDc2MpyXjo3vMLh7JykNJdOvd2+wB6lcbJ+z7/f+XQAAAHRMcAcAAAAAAHRFvdHMC0cP5OC+kaJHua/piXKuXL+TtY3Nx//y+kryyY+T57+fHDza9dm+5cwPkqGRZE5wBwAAMEgEdwAAAAAAwI6tbWzm02vLmZkcvHWy26pT5axvtnLl+vLjf/nKnyWrS8nMm90f7H7GDiUv/C/Jpz9tx34AAAAMBMEdAAAAAACwY59dW87aRivVqcEN7ioT7VW39cYTrJWtv9M+q30K7pKkciFZu5N8/uf9eycAAAAPJbgDAAAAAAB27HKjmSQ5d6Jc8CQPVplszza78ATBXe3t5PCpZOp8l6d6iMrF9jn7Xv/eCQAAwEMJ7gAAAAAAgB2rbd0aVx3glbLT28Hd4mMGd9fnkhtzSfWNpFTqwWQPcOK7SXkqmX2/f+8EAADgoQR3AAAAAADAjtUbzQyVfnOL3CAqj43kuSP7H/+GuyLWySbtuG/6QrLwcXJrvr/vBgAA4L4EdwAAAAAAwI7VGs28ePRg9o8OFz3KQ1Umy5lbXMrmZqvzL9XeTob3JWd+2LvBHqRyoX3OfdD/dwMAAPAtgjsAAAAAAGBHVtY38tn1O6lODe462W3TE+XcW9vM/M27nX1hZSm58rPk9B8kYwXc3nf2R0lKyex7/X83AAAA3yK4AwAAAAAAduSTxeVsbLZybhcEd9srb2cXO1wr++lPko3VpPpWD6d6iPFjyanfTT75k2RjvZgZAAAA+DXBHQAAAAAAsCO1RjNJUp0q4Aa4x7Qd3M0tdBjc1d5un9U3ejRRByoXk3u3kvm/Lm4GAAAAkgjuAAAAAACAHao32vHazG664a6T4K7VSurvJscqybHpHk/2EJWL7dNaWQAAgMIJ7gAAAAAAgB2pNZoZHirl7MR40aM80rHxfXnm4GhnwV3jUtL8srh1sttO/m6y/0gy936xcwAAACC4AwAAAAAAdqa+sJSXjh3M2Mhw0aM8UqlUSmWinNnFpbRarYd/eBDWySbJ8Ehy9kfJ/H9Plq8XOwsAAMBTTnAHAAAAAAA8sXtrG/ns+nLO7YJ1stsqk+XcvLOW68urD/9g/Z1kXzl56dX+DPYwlYtJWsknf1L0JAAAAE81wR0AAAAAAPDEZheW0mol1V0W3CVJvfGQtbJ3biRf/GVy9rVkZF9f5nqoyoX2OftesXMAAAA85QR3AAAAAADAE6svNJMkM1Plgifp3HZwN7v4kOBu9v2ktZlU3+zTVI9w+GQy+Up7rs3NoqcBAAB4agnuAAAAAACAJ1bbuiVuZhfecDe38JDgrv52+xyU4C5JKq8nywtJ41LRkwAAADy1BHcAAAAAAMATqzeaGRkq5fSx8aJH6djJIwdyYHQ4sw8K7jY32qtbT/z95PBz/R3uYSoX26e1sgAAAIUR3AEAAAAAAE+s1ljK2Ynx7BvZPf/kMDRUyvTk+IODuy/+Krn79WDdbpckL/5+MnqwvVYWAACAQuyev/0CAAAAAAAD5c7qej6/cSfVXbROdltlopyrt++leW/t27/cXic781Z/h3qUkbHkzA+SX/3X5N7toqcBAAB4KgnuAAAAAACAJ7J9Q9zM5C4M7ibLSZK5xeVv/7L+TnLwWHLqH/V5qg5ULiab68mnPy16EgAAgKeS4A4AAAAAAHgitcZWcDdVLniSx7cd3H1rreztL5OrH7bDtqHhAiZ7hOnX2+ectbIAAABFENwBAAAAAABPpN5oJsnuXCn7oOCu/k77rL7Z54k6dGw6efZMMvte0moVPQ0AAMBTR3AHAAAAAAA8kVqjmX3DQzl97GDRozy2l46NZ2So9O3grvZOUhr6zU1yg6hyMbn5eXJ9tuhJAAAAnjqCOwAAAAAA4InUGks5OzGekeHd988No8NDeenYwcwtfiO4W19JPvlx8sLvJQePFjbbI1Uuts/Z94qdAwAA4Cm0+/4GDAAAAAAAFO72vbXM37ybmV24TnZbZbKcK9eXs7K+0f7BlZ8la8tJ9Y1iB3uU03+QDI0K7gAAAAoguAMAAAAAAB7bR/O3kyTnTx0ueJInV508lM1W8um15fYPau9s/eKt4obqxFg5een3k89+lqzdLXoaAACAp4rgDgAAAAAAeGwffXkrSXL+5JGCJ3lylclykmR2YWutbP2d5PCpZOqVAqfqUOVisn43ufJnRU8CAADwVBHcAQAAAAAAj+3SfDu4e+XUHgnurs8lN+ba62RLpYIn60DlYvucfb/YOQAAAJ4ygjsAAAAAAOCxXfrydl48ejBHDowWPcoTOzsxnmQruKu93f7hoK+T3Tb5cnLouWT2vaInAQAAeKoI7gAAAAAAgMeyvLKeucWlnD91uOhRduTgvpGceuZAO7irv5MMjyVnf1j0WJ0plZLpC8m1y8nNXxU9DQAAwFNDcAcAAAAAADyWX3x1O42ndPwAACAASURBVK1Wcn4Xr5PdVpks5+q162ld+Vly+g+SfeNFj9S5yoX2OWetLAAAQL8I7gAAAAAAgMdyaf5WkuT8yb0R3H1/829S2lhNqm8WPc7jOftaUhqyVhYAAKCPRooeAAAAAAAA2F0ufXk7SfLKyd29UjZJfueFZ1IZ+nn7DzO7LLg7eDQ59b3kk58kG2vJ8GjREwEAAOx5brgDAAAAAAAey6X5Wzl5ZH+OlceKHmXHfjhzPD8a/nm+HHkhOXq26HEeX+VisnI7+eIvi54EAADgqSC4AwAAAAAAOnZvbSP1haWcP7X718kmyeGbv8yJ0tf5LyvfTfPeWtHjPL7KhfZprSwAAEBfCO4AAAAAAICO/fJqMxubrT0T3OWTHydJ3t/4B/lJbbHYWZ7EyX+YHHg2mX2/6EkAAACeCoI7AAAAAACgYx/O30qSnD91uOBJumThF0mSDzfP5J2PGgUP8wSGhpPp15Ovfp4s7cJgEAAAYJcR3AEAAAAAAB37aDu4O7lHbri7VkvGJ3PmhefzJ79cyOr6ZtETPb7KxfY590GxcwAAADwFBHcAAAAAAEDHLn15K5OHxjJ5eH/Ro+xcq9UO7ibO5c2Xp9JcWc9ffHq96Kke3/Tr7bP+drFzAAAAPAUEdwAAAAAAQEdW1zdz+Woz50/tkdvtmleTldvJ8WrefHkqSXbnWtlDJ5IX/0ny8R8nNz8vehoAAIA9TXAHAAAAAAB0pNZoZm2jlfMnDxc9Sndcu9w+j59LZbKcM8fH8+7HjbRarWLnehI//GfJ5lry039V9CQAAAB7muAOAAAAAADoyKX5W0myd264W6y1z4mZlEqlvPHyVK7evpcPt/4/d5WzryUv/n7y8/8v+fqzgocBAADYuwR3AAAAAABARy59uceCu2/ccJdkd6+VLZWS1/4w2VxPfvpHRU8DAACwZwnuAAAAAACAjnw4fztHx/fluSP7ix6lOxYvJ/sOJYdPJkn+4YvP5nh5X975+GrBgz2hMz9IXno1+fm/Tm58UvQ0AAAAe5LgDgAAAAAAeKS1jc384qvbeeXk4ZRKpaLH6Y5r9eR4tX07XJLhoVIufGcqtcZSPru2XPBwT2D7lrvWRvLTf1X0NAAAAHuS4A4AAAAAAHikucWlrK5v5rt7ZZ3svVvJ0tVk4txv/fjNV9prZd/9eBeulU2SM/80Of1Pk7/5N8n1uaKnAQAA2HMEdwAAAAAAwCNdmr+dJDm/V4K7xVr7PD7zWz9+tXI8B/cN7961ssk3brn7o6InAQAA2HMEdwAAAAAAwCNdmr+VJDl/co8Ed9cut8+/E9ztHx3OD6oT+asrX+fa0koBg3XB6VeTMz9I/vbfJtdmi54GAABgTxHcAQAAAAAAj3Rp/lYO7x/JC0cPFD1KdyxuBXd/Z6Vs0l4r22olH/xioc9DddFr/yJpbSY//ZdFTwIAALCnCO4AAAAAAICH2ths5eOvbuf8qSMplUpFj9Md12rJ0Gjy7Jlv/er170xmeKi0u9fKvvT7ydnXkg//XXKtXvQ0AAAAe4bgDgAAAAAAeKhPry3nzupGzp/aI+tkk/YNd8emk+GRb/3qmYP78ntnjub/r1/LndX1Aobrku1b7n7y/xQ9CQAAwJ4huAMAAAAAAB7q0vytJMkrJw8XPEmXrN1Lbl5Jjs888CNvvDyVlfXN/LR2rY+DddmLv5dMX0g+/Pe/WaELAADAjgjuAAAAAACAh9oO7r67V264uzHXvvlt4twDP/LGy1NJsrvXyibJj/5FkpZb7gAAALpEcAcAAAAAADzUpS9vZXzfcE4fGy96lO7Yvu3t+IODu+efPZhXTh7OB79cyPrGZp8G64Hnv5dU3kgu/Ydk4RdFTwMAALDrCe4AAAAAAIAH2txs5aP523nl5JEMDZWKHqc7rtXa5/HqQz/2xstTuXlnLX/52dd9GKqHXvvDuOUOAACgOwR3AAAAAADAA31+406aK+s5v1fWySbfuOHu4cHdmy+fSLIH1so+/4+S6lvJR/8xaXxU9DQAAAC7muAOAAAAAAB4oEtf3kqSnD91uOBJuuhaLTnyYrLv4Sty/95zh/L8swfyzkeNtFqtPg3XI6/98ySt5Mf/d9GTAAAA7GqCOwAAAAAA4IEuzd9Okr1zw93mRnKtnkzMPPKjpVIpb7w8lfmbd/OLr5p9GK6HTv1uMvO/Jr/44+Tqh0VPAwAAsGsJ7gAAAAAAgAe6NH8r+0eHcvb4w2+D2zVufp5srCTHz3X08T2zVjbZuuUubrkDAADYAcEdAAAAAABwX61WK5e+vJWXnzuckeE98k8K12rts4Mb7pLkH59+Ns8cHM07HzV6OFSfnPyd5Nz/nvzyPyVf/W3R0wAAAOxKe+RvxwAAAAAAQLfN37ybm3fW9s462SRZvNw+O7zhbmR4KK9/ZzIff3U7X3x9p4eD9Ylb7gAAAHZEcAcAAAAAANzXpflbSZLzJ/dQcHdtO7jr7Ia75DdrZd/9eA/ccvfc30++838kl/9z8uXPi54GAABg1xHcAQAAAAAA93Vp/naS7LEb7mrJwWPJ+LGOv/KDmeMZGxnaG2tlk+S1P2yfbrkDAAB4bII7AAAAAADgvi59+T/Zu/PgNu87z/MfHCRAAgQpnhJB8RAlyhZJ2Y4s2aIta+LYTm33TM9ukt70NTk620lqO9W7m55kZquy00f1Jls1Ndnercpukq3sTLo7mdme6clktrPdVtod2ZIpW0p8kJRtkqJIigB1EKQIXgJIAs/+8QB0FF08HuABHrxfVaqfDJLP81GFqSKID77fuMo9bh1oCtodxRqGYU642+Q62azKcq9OHKjX+Yk5za+s5ihcHu3ukR7+FWnkb6ToG3anAQAAAICiQuEOAAAAAAAAAADcwTAMDUXjemhPlco8Dnk5YemGlIhLDZtfJ5v1wqHdSqUN/f17N3IQzAb/4J+bJ1PuAAAAAGBLHPIMGQAAAAAAAAAAWOn6QlKxpVV1NztonWxsxDy3OOFOkj70cKPcLjlnrWxTt9T9X0mjL0qRn9mdBgAAAACKBoU7AAAAAAAAAABwh6FoXJLUG3ZS4W7YPLcx4a4u6NPjbbV6eWRGibWUxcFscvKfS3JJp79mdxIAAAAAKBoU7gAAAAAAAAAAwB2Gps3CXU84ZHMSC81sf8KdJD1/qEm31lJ69VLMwlA2anxI6vmIdOnH0tQFu9MAAAAAQFGgcAcAAAAAAAAAAO4wFF2Q1+1SV1OV3VGsExuWyiqlUHhbX/78oSZJDlorK0kn/5mYcgcAAAAAm0fhDgAAAAAAAAAA3GEoGldXU5X8ZR67o1hnZkSqPyC5t/fySHt9QAebqvR3715XKm1YHM4mDQel3o9JYy9JU+ftTgMAAAAABY/CHQAAAAAAAAAAuM3MYlLXFhLOWiebWJAWp7e9Tjbr+UNNml1e1ZtXbloUrACc/GeSyy395Kt2JwEAAACAgkfhDgAAAAAAAAAA3ObidFyS1BOutjmJhWZHzbOha0eXeaE7s1b2HQetla0/IPX+qnT5J9LkObvTAAAAAEBBo3AHAAAAAAAAAABuMxQ1C3fdzQ4q3M2MmOcOJ9z1hqu1O+TXqYvXZBgOWSsrSc982Zxyd5opdwAAAABwPxTuAAAAAAAAAADAbYaiC3K7pEN7HLRSNjZsng07K9y5XC49f6hJE7MrunRjyYJgBaJ+v3T449L4K9LEq3anAQAAAICCReEOAAAAAAAAAADcZmg6rv2NQVWUe+yOYp2ZEcntlWr37fhSjlwrK0nPfElyeaTTX7M7CQAAAAAULAp3AAAAAAAAAABgw/zKqiI3b6nHSetkJXPC3a4OyVO240s90VGnKr9Xpy5esyBYAanrlB75NWnijDR+xu40AAAAAFCQKNwBAAAAAAAAAIANQ9EFSVJ32EGFu/VVaW58x+tks8q9bn3wYKPejsR1LZ6w5JoF45l/+v6UO8OwOw0AAAAAFBwKdwAAAAAAAAAAYMPQdFyS1Oukwt3cmGSkpPouyy6ZXSv743cdtla2dp/06K9Lk69K46/YnQYAAAAACg6FOwAAAAAAAAAAsGEoahbuDjWHbE5iodiIeVo04U6STnY1qNzjdt5aWUl65kuS28uUOwAAAAC4Cwp3AAAAAAAAAABgw1A0rn31AQV9XrujWGcmU7izcMJdlb9Mxzvr9NrlWS0k1iy7bkHY1S49+pvSlXPS5dN2pwEAAACAgkLhDgAAAAAAAAAASJIWEmuamF1Rj5PWyUpSbNg8LSzcSeZa2bWUodPDM5ZetyA8808ldxlT7gAAAADgF1C4AwAAAAAAAAAAkqR3phckST1hB62TlaSZYSnUIvmCll72+YebJMmZa2VrWqXHfkuael0a+3u70wAAAABAwaBwBwAAAAAAAAAAJJnrZCWpp9lBE+7SaSk2KtUfsPzSjSG/Hmut0enhGSXXU5Zf33Ynfp8pdwAAAADwCyjcAQAAAAAAAAAASe8X7rqdVLiLT0nrt6SGgzm5/POHmrSUXNdrl+dycn1b1eyVPvAJKXJBuvSS3WkAAAAAoCBQuAMAAAAAAAAAAJKkoekFtdZWqrqyzO4o1omNmGd9V04u/8Kh3ZIculZWMqfcecql019lyh0AAAAAiMIdAAAAAAAAAACQtLK6rrGZJfWEQ3ZHsVa2cJejCXf7G4Pa1xDQj9+5rnTagYW06rD0gU9K0Z9Jo6fsTgMAAAAAtqNwBwAAAAAAAAAA9M70ggzDYetkJWlm2Dzrc1O4k8y1sjcWkxrIrOR1nBNflDw+6fTXmHIHAAAAoORRuAMAAAAAAAAAABrKlMV6ww4r3MVGpIpdUqA+Z7dw/FrZULN05FPS9JvSyIt2pwEAAAAAW1G4AwAAAAAAAAAAGppekCR1NztspezMsDndzuXK2S0e21uj+qBPp965nrN72O7Y75jnxBl7cwAAAACAzSjcAQAAAAAAAAAADUXjaq72qy7oszuKdZZj0q05qaErp7dxu116/lCjLt1Y0uWZpZzeyzbZCYEJh67NBQAAAIBNonAHAAAAAAAAAECJS6ylNHpjSd1OWyc7M2ye9bkt3Envr5X9sVOn3Pkykw+TC/bmAAAAAACbUbgDAAAAAAAAAKDEvXdtUam0oV6nFe5i2cLdwZzf6nhnnQLlHueulXV7pPIqJtwBAAAAKHkU7gAAAAAAAAAAKHFDUbNE1RMO2ZzEYrFR88zxSllJ8pd5dPJgg964clMzi8mc388W/pCUYMIdAAAAgNJG4Q4AAAAAAAAAgBJ3cTpTuGt22IS7mWHJWyFVt+bldi8c2i3DkF5616FT7nwhVsoCAAAAKHkU7gAAAAAAAAAAKHGD0bgaq3xqDPntjmKt2IhUv19y5+flkA8ebJTX7XLuWlkm3AEAAAAAhTsAAAAAAAAAAErZ6npaw9cW1RN22HS75JIUn5LqD+btltWVZXpyX53OXoppObmet/vmjb9aSsTtTgEAAAAAtqJwBwAAAAAAAABACRu5vqi1lKGe5pDdUaw1O2qeDfkr3EnS84eatLqe1isjM3m9b174QlIqKa0n7U4CAAAAALahcAcAAAAAAAAAQAkbipoTy7qdNuFuZsQ86w/k9bbPH2qSJGeulfVnSpmslQUAAABQwijcAQAAAAAAAABQwoamzcJdr9MKd7Fh88zjSllJaq6pUG+4Wn//3g2tpdJ5vXfO+TKFuySFOwAAAACli8IdAAAAAAAAAAAlbCi6oNpAufZU++2OYq3YiORyS3Wdeb/184eaFL+1pgvjc3m/d075M6XMRNzeHAAAAABgIwp3AAAAAAAAAACUqPVUWu9eXVB3c0gul8vuONaaGZF2dUheX95v/UK3Q9fKbqyUpXAHAAAAoHRRuAMAAAAAAAAAoERdmllScj3tvHWyqTVpbkxqyO862ayDTVVqra3Uj9+5LsMwbMmQE77M9wkrZQEAAACUMAp3AAAAAAAAAACUqKGoWZzqcVrhbm5cSq9L9V223N7lcun5Q02Kzt/SxWkHldM2Jtw56N8EAAAAAFu0qcLd7/3e76m9vV0ul0tDQ0Mbj7/wwgs6fPiwHn30UZ04cUJvvfXWxsdGR0fV19enrq4uHTt2TO+884716QEAAAAAAAAAwLYNRc3VoD3NDivcxYbN06YJd5L0wiEHrpX1ZQp3TLgDAAAAUMI2Vbj72Mc+prNnz6qtre22x//yL/9SAwMDeuutt/T7v//7+u3f/u2Nj33uc5/TZz/7WY2MjOjLX/6yPvOZz1ibHAAAAAAAAAAA7MhQNK6Q36u9tRV2R7HWTKZwZ9OEO0k60rZLtYFynbp4zbYMlvNniplMuAMAAABQwjZVuHvmmWfU0tJyx+M1NTUbf4/H43K7zcvduHFDb7zxhn7rt35LkvTRj35U4+PjmpiYsCAyAAAAAAAAAADYqVTa0DtXF9QTrpbL5bI7jrViI+ZZf8C2CF6PW88+1Kj3ri1qam7FthyW2lgpG7c3BwAAAADYaFOFu/v5xCc+ob179+orX/mKvvvd70qSpqam1NzcLK/XK0lyuVxqbW3VlStX7nqNr3/962ppadn4s7S0tNNYAAAAAAAAAADgPsZjy1pZTakn7LB1spJZuKva8/5ENps4bq0sK2UBAAAAYOeFuz/7sz/T1NSU/uRP/kRf+tKXNh7/xXfDGYZxz2t88YtfVCQS2fgTDAZ3GgsAAAAAAAAAANzHxWlzSll3c8jmJBYzDCk2aus62awTBxrkL3M7Z61seVCSiwl3AAAAAErajgt3WZ/85Cf1k5/8RLOzs9q7d68ikYjW19clmWW7qakptba2WnU7AAAAAAAAAACwA4MRszTV67QJdwtRaXVJajhodxJVlHt04kCDLkzM6ebyqt1xds7tNqfcMeEOAAAAQAnbduFuYWFB09PTG//9gx/8QHV1daqtrVVjY6Mee+wx/cVf/IUk6a/+6q/U3t6u9vb2HQcGAAAAAAAAAAA7NzQdV6Dco/a6gN1RrDUzbJ4FMOFOMtfKpg3ppfdu2B3FGv5qJtwBAAAAKGnezXzS7/7u7+qHP/yhrl27pueee07BYFA/+clP9NGPflS3bt2S2+1WQ0OD/vqv/3pjley3vvUtfepTn9JXv/pVhUIhffe7383pPwQAAAAAAAAAAGxOOm3oYnRB3c3VcrtddsexVmzEPAtgwp0kfejhJrld0qmL1/SxIy12x9k5f0hKMOEOAAAAQOnaVOHuG9/4hr7xjW/c8fj58+fv+TUHDx7UuXPntp8MAAAAAAAAAADkxNTNFS0m19UdDtkdxXoFNuGuNlCuI227dPZSzO4o1vCFpMWrdqcAAAAAANtse6UsAAAAAAAAAAAoToNRcyVob7ja5iQ5EBuRfNVSsMnuJBuaayq0sppScj1ld5Sdy064Mwy7kwAAAACALSjcAQAAAAAAAABQYoai5krQHqcW7hq6JFfhrMoN+MyFQ8tJJxTuqqX0mrSesDsJAAAAANiCwh0AAAAAAAAAACXm4nRc/jK39tUH7I5irZU5aXlGqj9od5LbVGUKd0uJdZuTWMCXWUOciNubAwAAAABsQuEOAAAAAAAAAIASYhiGBqNxPbwnJK/HYS8TxEbMs6HL3hy/IDvhbinpgMKdP1u4W7A3BwAAAADYxGHPpAEAAAAAAAAAwP1E529pfmVNvU5cJzszbJ4FNuEu6KTCXXbCXZLCHQAAAIDSROEOAAAAAAAAAIASMhQ1i1I9zQ4s3BXohLts4W7ZCYU7PytlAQAAAJQ2CncAAAAAAAAAAJSQi9NmUao7HLI5SQ7MDEsen1TTZneS22RXyi46onCXKWpSuAMAAABQoijcAQAAAAAAAABQQgajcZV73OpqqrI7ivViw1LdfsntsTvJbYJ+B02482UKd6yUBQAAAFCiKNwBAAAAAAAAAFAiDMPQUDSuh/ZUqczjsJcIVlek+amCWycrSUGfWQB0ROFuY6UshTsAAAAApclhz6YBAAAAAAAAAMC93FhMKra0qu7marujWG/2kiRDqj9od5I7BH1lkqTFhAMKd75M4Y4JdwAAAABKFIU7AAAAAAAAAABKxGAkLknqCYdsTpIDsRHzLMAJdwFHTbjLlDWZcAcAAACgRFG4AwAAAAAAAACgRAxNm4W73rADJ9zNDJtnAU64q8pMuFtyROEuu1I2bm8OAAAAALAJhTsAAAAAAAAAAErEUHRBXrdLXU1VdkexXmxYkkuq2293kjtkJ9w5onBXVim5PKyUBQAAAFCyKNwBAAAAAAAAAFAiLk7HdaCpSv4yj91RrDczIu1qk8r8die5g9fjlr/M7YzCnctlTrljpSwAAACAEkXhDgAAAAAAAACAEhBbSupqPKHecMjuKNZLrUuzlwpynWxW0OfVshMKd5LkC0lJVsoCAAAAKE0U7gAAAAAAAAAAKAFDUbMg1ROutjlJDsxPSuk1qaHL7iT3FPB5tZhwSOHOX82EOwAAAAAli8IdAAAAAAAAAAAl4OK0WZDqbnZg4W5m2DwLfcLdqpMKd0y4AwAAAFCaKNwBAAAAAAAAAFAChqJxuV3SoT0OXCkbyxTuGgq3cBfwebWcTNkdwxq+kJRclAzD7iQAAAAAkHcU7gAAAAAAAAAAKAGD0bj2NwZVUe6xO4r1ZkbMs75wV8pW+bxacsxK2ZBkpKTVZbuTAAAAAEDeUbgDAAAAAAAAAMDh5ldWFbl5Sz1OXCcrmRPugk1SRY3dSe4p4PNqNZVWct0BU+58mSmJyQV7cwAAAACADSjcAQAAAAAAAADgcBenzWJUd9iBhTvDMCfcFfB0O0kK+r2S5Iy1sv7M91Eibm8OAAAAALABhTsAAAAAAAAAABxuMGoWo3qdWLhbvCqtLhZ+4c6XLdw5YK2sPzPhLsGEOwAAAAClh8IdAAAAAAAAAAAON5Qp3B1qDtmcJAdiI+bZcNDeHA8QKDcLd4sJBxTuWCkLAAAAoIRRuAMAAAAAAAAAwOEuTi9oX31gY8qao8xkCneFPuEuu1J21QGFu40Jd6yUBQAAAFB6KNwBAAAAAAAAAOBgi4k1jceW1e3EdbKSFBs2zwKfcBf0eSRJS06YcOfPfC8x4Q4AAABACaJwBwAAAAAAAACAg12cNktRvWEHrpOVpJlhqbxKqtpjd5L7CvrKJElLSQcU7nyZwh0T7gAAAACUIAp3AAAAAAAAAAA42FDULEX1NDt1wt2I1NAluVx2J7mvQGbC3bITCncbK2WZcAcAAACg9FC4AwAAAAAAAADAwbIT7rqdWLi7NS8tXZfqC3udrCRV+b2SnDLhLlO4Y6UsAAAAgBJE4Q4AAAAAAAAAAAcbjMbVWlup6soyu6NYLzZinvUH7M2xCQGfgwp3TLgDAAAAUMIo3AEAAAAAAAAA4FArq+sam1lSTzhkd5TcyBbuGgp/wl0wW7hLOKBw5/VLnnIm3AEAAAAoSRTuAAAAAAAAAABwqHevLsgwHLpOVpJmhs2zCFbKZgt3y6sOKNy5XOZa2UTc7iQAAAAAkHdeuwMAAAAAAAAAAFBqLk7H9R9+FtGje2t0fF+dGkP+nNxnKGpOIOsJO7RwFxsxJ63tarc7yQNlV8ouOmHCnWSulWWlLAAAAIASROEOAAAAAAAAAIA8+9bLl/Wf357e+O/OhoD6OuvV11mnJ/fVaVeg3JL7DEbNCWQ9zQ5dKTszLNV2Sp7Cf7mjzOOWz+vWctIhhTtfSFqZtTsFAAAAAORd4T8DBQAAAAAAAADAYQYi82rZVaH/4bku9Y/Nqn8spj9/bVJ//tqkJOnhPSH1ddapr7NOxzpqVeUv29Z9hqJxNVf7VRf0WRm/MKwlpPlJ6eF/ZHeSTQv6vFpOpuyOYQ1/tTQ3bncKAAAAAMg7CncAAAAAAAAAAORRfGVNE7Mr+pVHmvXRIy366JEWGYahydkV9Y/N6tzlWZ0bi+k7Z8f1nbPj8rhd6glXbxTwHm+rVUW554H3SaylNHpjSc8+1JiHf5UNZi9JRlqqP2h3kk0L+r1adMqEO39ISi5I6bTkdtudBgAAAADyhsIdAAAAAAAAAAB5NDRtrnk93FK98ZjL5VJ7fUDt9QH9xhOtMgxDozeW1H8ppv6xWb12eVZvT83r/zw9pjKPS4+17tLxfWYB79HWGvm8dxbw3ru2qFTaUG+4+o6POUJs2Dzru+zNsQWBcq+WnFK481VLMqTVRXPaHQAAAACUCAp3AAAAAAAAAADk0UAkW7iruefnuFwudTVVqaupSp96qkOptKF3ry6of8ws4J0fn9P58Tn9by+Nyl/m1tH2Wj2ZKeD1hqvl9bg1FDXv0xMO5eXflXexUfNsKJ7CXdDv1bWFhN0xrOHPfF8lFijcAQAAACgpFO4AAAAAAAAAAMijgci8XC6pu3nzRbjsWtmecLU++0yn1lJpDUTiOpcp4L0+PqczozFJUtDn1RMdtYotr0qSepodWoaaGZbkkuoO2J1k04I+J024y3z/JhfszQEAAAAAeUbhDgAAAAAAAACAPBqIxLW/IaiAb/u/oi/zuHWkbZeOtO3SF549oMRaSm9emd8o4L08MqP1tKE91X41hvwWpi8gsRGpZq9UXml3kk0L+rxaXU9rdT2tcq/b7jg7k51ql6BwBwAAAKC0ULgDAAAAAAAAACBPZpeSis7f0kc/0GLpdf1lHh3vrNPxzjp9UdJycl0/nbyp3U4t26VT5krZjmfsTrIl2ZLlcnJd5d5ym9Ps0MZK2bi9OQAAAAAgzyjcAQAAAAAAAACQJ4NRs5x0uCW3a14DPq9OdjXk9B62mp+UUkmp4aDdSbYk6PNIkpaS69oVKPLCHStlAQAAAJSoIp9XDgAAAAAAAABA8RiImIW73hwX7hxvZsQ867vszbFFQV+ZJLNwV/SYcAcAAACgRFG4AwAAAAAAAAAgTwYicXndLh3aE7I7SnGLDZtnkRXuApkJybF50wAAIABJREFUd8uOKNxlSqNMuAMAAABQYijcAQAAAAAAAACQJ4PReXU1Vclf5rE7SnGLZSbcFdlK2Sq/V5K06ITCnY8JdwAAAABKE4U7AAAAAAAAAADy4PpCQtcXkjrMOtmdmxmRKuulylq7k2xJwGcW7hw14S7BhDsAAAAApYXCHQAAAABg2y5Ox5VYS9kdAwAAoCgMRMxJYL0U7nbGMMyVskU23U6SgpnC3VLCAYW77IQ7VsoCAAAAKDEU7gAAAAAA2/LetQX98v9+Vt85O253FAAAgKIwGJmXJB0O19icpMgt3TDXmNZ32Z1kyzYKd06YcOctl7x+JtwBAADAMum0oT9/bVKzS0m7owD3ReEOAAAAALAtr4zMSJJ+OjFncxIAAIDiMBCNq9zj1sHdVXZHKW6xYfMswgl3AScV7iRzrSwT7gAAAGCRs5di+p/+05D+5//vXbujAPdF4Q4AAAAAsC39Y7OSpMHoggzDsDkNAABAYTMMQ4ORuB7eU6VyL7+a35GZTOGuiCfcLTulcOcLmdMGAQAAAAucHzff3P2f35pWdP6WzWmAe+NZPQAAAABgy9ZS6Y1ffsSWkrq+wIh/AACA+4nO39Ls8qp6W6rtjlL8YiPmWcSFO+dMuAuxUhYAAACWOT8xJ5dLWk8b+s6ZcbvjAPdE4Q4AAAAAsGUDkXmtrKYUrqmQJA1GmWoBAABwP4MR8+elwy01NidxgNiIVBaQqlvsTrJl76+UTdmcxCK+ECtlAQAAYInkekpvTc3r6f31enhPSP/uwhXNr6zaHQu4Kwp3AAAAAIAt679krpP97ac7JFG4AwAAeJCBaLZwx4S7HZsZkeoPSC6X3Um2rNzrVrnX7ZyVsv6QtLokpR1SIAQAAIBtBiNxra6nday9Vp8/uU8rqyn92blJu2MBd0XhDgAAAACwZecuz8pf5tbHj+5VmcelIQp3AAAA9zUYictf5tb+hqDdUYpbYkFanJYaDtqdZNuqfF4tJZxSuMsUSJlyBwAAgB06PzEnSTraUatf7t2jcE2F/k3/hG6t8uYOFB4KdwAAAACALUmspfTTyZs62l6roM+rg7urmHAHAABwH4ZhaCAyr+7mank9/Fp+R2Kj5lnfZW+OHQj4vFpyyoQ7X8g8EzwfAAAAwM6cH59TucetR/fWyOtx63dOdGhueVX//mdTdkcD7sAzewAAAADAlrxx5aZW19M63lknSeoNV2tmManrCwmbkwEAABSmydkVLSTWWSdrhdiweRbxhLugkwp32Ql3CSbcAQAAYPtSaUM/m7ipwy3V8pd5JEn/9dG92lVZpm+/clnrqbTNCYHbUbgDAAAAAGzJubFZSVJfZ70kqSdsvsg2GGGqBQAAwN0MZKYBU7izwEymcFdf3IW7ZacU7rIT7lgpCwAAgB1479qCFpPrOtpRu/FYZblXn+xrV+TmLf1o8KqN6YA7UbgDAAAAAGxJ/9isqnxe9TSbL671NGcKd6yVBQAAuKvByLwkqTdcY3MSB4iNSG6vVNthd5JtC/g8WnRK4Y4JdwAAALDAhfE5SdKx9trbHv/k8XZVlHn0zZcvyzAMO6IBd0XhDgAAAACwaUvJdb09Na8n9tXK6zGfUh7cXSWv26WL0xTuAAAA7ubtSFxBn1f76gN2Ryl+sRGpdp/kKbM7ybYF/WVaXU9rzQlrsfyZCXcJngsAAABg+y5M3JTLJX2gbddtj+8KlOvjR/fq3asLemU0ZlM64E4U7gAAAAAAm3ZhYk7raUPHM+tkJclf5lFXUxUT7gAAAO4ilTZ0MRpXTzgkt9tld5zitr4qzY1L9V12J9mRoM8jSc5YK8tKWQAAAOyQYRg6PzGnh3aHVF1x5xtr/psTHfK4XfrWy2M2pAPujsIdAAAAAGDTXhublST1ddbd9nhvuFrXF5K6sZiwIxYAAEDBGo8taXk1pcMtrJPdsbkxyUhJDQftTrIjQZ9XkrSYcEDhbmPCHYU7AAAAbM/k7IpmFpM61r7rrh9v2VWpX3mkWf1jsxqIzOc5HXB3FO4AAAAAAJvWPzarXZVlOthUddvjPS3VkqQhptwBAADcZiBi/nzUG662OYkDzAybZ31xF+4CmcLd8qoDCncbE+54HgAAAIDtOT8xJ0k62lF7z8/53Ml9kqRvMuUOBYLCHQAAAABgU+Iraxqajut4Z90d69CyLyAPRphsAQAA8POyhbvDLRTudiw2Yp4Nxb5S1izcLTliwl3m+5oJdwAAANimC+Nm4e5Y+70Ldw/tDumDBxv0N0PXNB5bzlc04J4o3AEAAAAANuW18VkZhnS8s/6Ojz20u0pet0uDTLgDAAC4zUBkXtUVZWqtrbQ7SvHLTrirO2Bvjh3aKNwlHVC4y064S/A8AAAAANtzYWJObXWVagz57/t5nz/ZKcOQvv3K5TwlA+6Nwh0AAAAAYFPOjc1Kkvo66+74mL/MowNNVayUBQAA+DnrqbQuTi/ocEu1XC7Xg78A9xcblkItki9od5IdCTipcOfxSmUBKcmEOwAAAGzdjcWEJmZXdPQ+0+2yjnXU6rHWGv3VGxHdWEzkIR1wbxTuAAAAAACb0j8WU1PIp331gbt+vDcc0rWFhGYWk3lOBgAAUJhGbywpuZ5Wb5h1sjuWTkuxS0W/TlaSgn6zcLfshMKdJPlDrJQFAADAtlwYvynp/utks1wulz5/slOr62n961cncpwMuD8KdwAAAACAB5pZTGrk+pL6OuvvOZ0l+0Jy0U25u/Gu9Ob37E4BAAAcaCAyL0k63ELhbsfiU9L6Lan+oN1Jdiy7UnYx4ZTCXTUT7gAAALAt58fNrSpHOx5cuJOk5x9uUmdDQH/x2qQWE2u5jAbcF4U7AAAAAMADvXbZ/MXH8busk83qyRTuBoutcPe3/6P0w/9WujlhdxIAAOAwAxHz56LDLTU2J3GA2Ih5OmHCnS874S5lcxKL+JhwBwAAgO05P3FT9UGf2usqN/X5brdLn3umU4uJdX3/9Ss5TgfcG4U7AAAAAMAD9Y9lCnf77l24e3hPSB63q7gKd8klafJV8++T/fZmAQAAjjMYjas+WK491X67oxS/mWHzdNCEu+VVp0y4C0mJInoOAAAAgIIQv7Wm964t6ImO2ntuVbmbf/xYs5pCPn3n7LiS6w55EwuKDoU7AAAAAMADnRuLaW9thfbW3vudhv4yjw40Botrpezl01Jq1fz7xKu2RgEAAM6SXE/p3asL6g1Xb+nFI9xDLFO4a3BO4c4xK2V9IXPdb4qVXgAAANi8NyZvyjCko+27tvR1Pq9Hn3m6QzcWk/pPb0ZzlA64Pwp3AAAAAID7is7f0sTsivr21T/wc3vC1boaTyi2lMxDMguMvmie/pr3J90BAABYYPjaotZSButkrTIzIlXUSoEH/0xa6AIbK2UdUrjzh8yTtbIAAADYgvMTc5Kkox21W/7aXz/Wqiq/V9965bLSacPqaMADUbgDAAAAANzXucw62b79914nm9Ubrpak4phyZxjS6I+lugPSw/9QujkuLUzbnQoAADjEQMT8eehwS7XNSRzAMMwJdw6YbidJ5V63yr1uLTmmcJf5Hk8WwXMAAAAAFIwL43Oq8nn10O7Qlr+2yl+mf/Jkmy7PLOvUO9dzkA64Pwp3AAAAAID76h+LSZKO73tw4a6nmAp31wakxatS14eltqfNx1grCwAALDKYKdxl35CAHViZlW7dlOoP2J3EMkGf1zmFO192wl0RPAcAAABAQUispTQQietI+y553K5tXePTT3Wo3OvWN18ek2Ew5Q75ReEOAAAAAHBPhmHo3Nis9jcG1RjyP/DzD+0Jye2SBouhcDdyyjwPvCC19Zl/Z60sAACwyEA0rt0h/6Z+hsIDzAybZ70zJtxJUsDn0VLCIYW77IQ7VsoCAABgk96emtdqKq2j7VtfJ5vVUOXTx4606K2peb0+PmdhOuDBKNwBAAAAAO5pYnZFV+MJ9XU+eLqdJFWUe3SgsUpD0SJ4sW30Ram8Smo9Lu1qk6r3UrgDAACWuLWa0sj1RdbJWiWWKdw5ZKWsJAV9ZVpedUjhLjvhLlkEzwEAAABQEC5MmAW5Yx3bL9xJ0u+c2CeXS/rmy2NWxAI2jcIdAAAAAOCezo3NStrcOtmsnnC1ovO3NLe8mqtYO7cckyI/lTo/KHnLzcfa+qTYiLQ0Y282AABQ9N65uqBU2qBwZ5WZEfOs77I3h4WCjppwl10pS+EOAAAAm3N+4qbKve4dP2fqqA/ov+jZrdPDM3r3Kj+PIn8o3AEAAAAA7ql/LCZJenILhbvesPmCW0Gvlb30d5IMqevD7z/W9pR5MuUOAADs0GBkXpLU21JjcxKHiA1LZZXmRGKHCPq8Wko6pXCXeZGUCXcAAADYhFTa0BuTN/VoS418Xs+Or/f5k52SpG8x5Q55ROEOAAAAAHBXhmHo3NisDu0JaVegfNNf15t5V+JQIRfuRl40z/3Pv//YRuGuP/95AACAowxkfg7qDTPhzhIzI1LdfsntnJc0Aj6vkutpraXSdkfZuexK2UQB//wPAACAgvHu1QUtJdd1tGOXJdc73FKjvs46/b8DVzU1t2LJNXcs7YCf83Ffznl2CgAAAACw1Mj1Jc0ur6qvc/PT7STp0J5quV3SYKRAX3BLrUtjL0nNj0lVTe8/XtcpBZuYcAcAAHZsIBLX3toK1W7hTQu4h+SStBCRGg7ancRSVX6vJGnZCVPuWCkLAACALTg/PidJOtpea9k1P3+yU6m0oe+cHbfsmjvy6p9K3/tVaemG3UmQI167AwAAAAAAClN2nWzf/q0V7irKPdrfGCzclbJTr5vTNw58+PbHXS5zyt3FH0grc1Kldb/wAQAApWMpua6xmSX9Us8eu6PknmFIP/xd6fpFyUjf+Sed+rn/NiQjdY+PG5nzLh+XYd6rvsvWf6rVAuXmyzNLyXXVVBZ5MTM74S5ZoD//AwAAoKCcH5+T2yUdabNmwp0knThQr+7mkP6fC1P67z50YEsbWyy3Mied/VOpokby19iXAzlF4Q4AAAAAcFf9Y7PyuF3beqdhT7ha//GNqG4ur9r7y427Gc2sk+164c6PtfVJF/+jdOU16aFfym8uAADgCBejcRmG1NtSAutkYyPSW98zX0Sq2CW53O//cXslT7n5pgaXW3J5fuHj2f92/dzjv/g5mdNbIR3+uN3/WksF/e8X7oqeLyTJxYQ7AAAAPJBhGLowMaeH94RU5S+z7Loul0ufO9mp3/u3b+q75yb03z9n4xt2zvwr880o//DrkrfAfjcOy1C4AwAAAADcIZU29NrlWR1uqd7WLz56M4W7wWhcz3Q15CDhDoyckgKN0p7H7vxY+9PmOfkqhTsAALAt2Sm/h8MlULgbf8U8/8v/Q3rol+3NUmSCPgetlHW7JV+VOUUaAAAAuI/LsWXNLq/qHz3SbPm1f6lnt/5lbYW+2z+hzz6zT5XlNlSi5qek89+Wdh+Wuj+S//sjb9x2BwAAAAAAFJ53phe0mFhXX+fW1slm9WZeYC64tbLzV6SZd6UDz5svDP6i+oNSRa1ZuAMAANiGtyPmzz89pTDhbuKMJJc5JRhbEsgU7hYTDijcSeaUuyQT7gAAAHB/F8bnJElPdGx9q8qDeD1uffbEPt1cWdNfXpiy/PqbcvprUmpVev6P7v77ZzgG/+sCAAAAAO7QPxaTJB3fV7+tr394T0gulzRUaIW7kcw62QN3WScrmb8EaeuTrr7NSiwAALAtg5F57asPKGTheqSClE5LE2elPYfNdbLYkvcn3KVsTmIRf4ifnwEAAPBA5yfMwt3j7dYX7iTpVx/fq7pAuf6vM+NaS6Vzco97un5Reuv7UsdJqfPZ/N4beUfhDgAAAABwh/6xWZV73DrStr0XTwM+rzobghqaLrDC3egpye2VOj94789pf1oy0tLU+fzlAgAAjhBfWdPE7Ip6S2G63cy70sqs1H7C7iRFyVErZSUm3AEAAGBTLkzMaV99QA1Vvpxc31/m0af62hWdv6UfDVzNyT3u6aU/lmRIz/1hfu8LW1C4AwAAAADcZnU9rQsTc3qstUYV5Z5tX6c3XK2puVuaX1m1MN0OrK5I469Irccl/31eBM+uRJs8m59cAADAMbJvNugNl0DhbvwV8+w4aW+OIhX0Z1bKOqVw569mwh0AAADu61o8oam5Wzqao+l2Wf/keJsqyz365stjMgwjp/faMPGqNPK3UvdHpPAH8nNP2IrCHQAAAADgNgORea2sptTXub11slk9mReah6IF8sLbxBlpPSF1ffj+n9fUI/mqpcn+/OQCAACO8XZkXpL0yN4am5PkwfgZyeWR2o7bnaQoBcodNuHOH5JSSWktYXcSAAAAFKjsOtmjHbkt3NVUluvXj7XqvWuLOj0yk9N7SZIMQ/q7PzA3qzz7ldzfDwWBwh0AAAAA4Db9Y7OSpL79dTu6Tnayy2C0QNbKjrxongceULhze6TWJ6XoG+ZUPAAAgE0ajMTldkmH9oTsjpJb6ZQ5Dbj5MclXZXeaolSVmXC35JTCnS/zPc9aWQAAANzDhXGzcHcsxxPuJOkzT3fI63bpm6fHcn4vvfcjKXJBOvJpqa4z9/dDQaBwBwAAAAC4Tf9YTBVlHj3SsrPJLN3NIblc0lAhFO4MQxo9Je1ql+oPPPjz25+S0mtS5HzOowEAAOcYiMS1vzGogM9rd5TcujYoJeJSxwm7kxSt7PeIYwp3/kzhjrWyAAAAuIcLE3NqCvm0t7Yi5/dqrqnQP340rNfH5/TmlZu5u1FqXXrpj6SygHTyy7m7DwoOhTsAAAAAwIbEWkpvTM7raEetyr07e8oY8Hm1rz5QGBPubrwrxafM6XYu14M/v+0p82StLAAA2KTZpaSi87fUGy6BdbITZ8yzncLddgV8HknSUsIphTtzurWSBfCzPwAAAApOfGVNw9cXdbS9Vq7N/H7WAp8/uU+S9M2Xczjl7q3vSbERqe8LUrAxd/dBwaFwBwAAAADY8MbkTa2m0jq+b2frZLN6w9W6Mrei+MqaJdfbttHMOtmuFzb3+XseMd+VOPFq7jIBAABHGci8yeCRvdU2J8mD8TOSu0xqfdLuJEXL5/Wo3OPWslMm3PmYcAcAAIB7++nknAxDOtaR+3WyWQeaqvTcw4069c51jc0sWX+D1RXp9Nekynrp+Besvz4KGoU7AAAAAMCG/rFZSVJfpzWFu56w+YLz0LTNky5GTklllVLb05v7fE+Z1PqEFLkgrSdzmw0AADjCYMT8eac37PDCXWrdnAIcPiKVB+xOU9QCPo8WnVK4y064SzDhDgAAAHc6PzEnSTranr/CnSR9/mSnDEP69suXrb/469+UFq+aq2T9Ieuvj4JG4Q4AAAAAsKF/LKYqv1fdzdb8giD7grOta2Vv3ZSmXpf2/QOpzL/5r2vrk1JJKfqzXCUDAAAOMhCJy+t26eE9Dn+h5epb0uqi1PGM3UmKXtDvdd6EuyQT7gAAAHCn8+NzCvm9OthUldf7Pt5eq8fbdukHb0Z1fSFh3YVX5qSzfyrVtElHPm3ddVE0KNwBAAAAACRJS8l1vR2J64mOOnk91jxd7A5Xy+WyuXB36SXJSEkHNrlONis7DW+StbIAAODBBqPzOri7Sv4yj91Rcmv8FfPsOGFvDgcIlDuocOdnpSwAAADu7tZqSoORuB5vr5Xb7cr7/T9/slOrqbT+77Pj1l307NelZFz60L+QvOXWXRdFg8IdAAAAAECSdGF8Tqm0Ydk6WUkK+rzqqA9oyM7C3egp89xq4S78AcnrlyYo3AEAgPu7vpDQ9YWkDrc4fJ2sJE2ckTw+qeWY3UmKXpXfqyXHFO4y3/tMuAMAAMAveHPqptbTRt7XyWY9+1CjDjQG9b3Xryh+a23nF5yfkl7/trT7sNT9kZ1fD0WJwh0AAAAAQJK5TlaS+vZbV7iTpJ7mak3Orljzy4ytSqek0R9LTb1SdXhrX+v1SS1HpanzUsqG7AAAoGgMRMw3F/SGa2xOkmPrq9KV16S9x6Qyv91pil7A56DCXXalbMLGN9oAAACgIF0YvylJOtaxy5b7u90ufe5kp5aS6/re65M7v+Dpr0mppPTcH0pualeliv/lAQAAAACSpP6xWdUFytXVWGXpdXvD5rSLi3ZMuYv+TLo1J3VtcbpdVluftLYsXX3b2lwAAMBRBiPzkuT8CXfTb0hrK1I762StEPR5lVhLaz2VtjvKzrFSFgAAAPdwYWJOPq/b1jco/cojzdpT7de/fnVCibXU9i90/aL01veljpNS57PWBUTRoXAHAAAAAND8yqreubqgJ/fVye12WXrtnkzhbmjahsLdyIvmeeDD2/v6tqfMc+KsNXkAAIAjDUTjKve61dVk7RsXCs74GfPsoHBnhaDPK0laTu7gBb9CUR6UXG5WygIAAOA266m03rhyU4+11qjca19Fqdzr1mee7tDMYlI/eDO6/Qu99MeSDHO6ncva36OjuFC4AwAAAADotctzMgzpeKe162QlqTtsTrsYjNrw4tvoi1JFrdTy+Pa+vuWo5C6TJvutzQUAABzDMAwNROJ6eE/I1heQ8mLiFclbIYWP2J3EEQKZwt1ics3mJBZwuSRfFStlAQAAcJuL0wtaWU3pWHut3VH0a8daFfJ79e1XLiuVNrZ+gcl+aeRvpe6PSOEPWB8QRcXhz/4BAAAAAJtxbiwmSerLQeEu5C9TR31AQ/leKbswLV0blPY/J7k927tGeaX5y5Mr56S0AyaPAAAAy0Xnb2lueVWHww5fJ7uWkK68LrU+IXl9dqdxBEdNuJMkfzUT7gAAAHCbCxNzkqSjHfYX7oI+rz5xvF3jsWWdunhta19sGNKP/0Bye6Vnv5KbgCgqFO4AAAAAAOofm9XukF8d9YGcXL8nXK3x2LIWEnmc3jF6yjy7trlONqvtKfOFw+tDO88EAAAcZzBivqmgt8XhhbvIBSmVlDqesTuJY2QLd0tOmHAnSb5qJtwBAADgNufH5+Rxu/SB1l12R5Ekfeqpdvm8bn3z5TEZxham3L33IylyXjryaamuM3cBUTQo3AEAAABAibuxmNDojSX1ddbJ5XLl5B69mbWyF/O5VnbklORyS53P7uw6bU+Z58SrO88EAAAcZyAzxfeRlhqbk+TYxBnzbKdwZ5WgP1u4c8qEu5CUYMIdAAAATIZh6KeTN9XdHFIg82YTu9UHffrVx1v0diSu8+Nzm/ui1Lr00h9JZQHp5JdzGxBFg8IdAAAAAJS4c2OzkqTjOVgnm9WTWbGWt7Wy60np8mlp7xNS5Q7XFbQ+YRb3JincAQCAOw1E5lVR5lFnQ24mBReM8TNSeVBqftTuJI4R2Fgpu25zEov4QuZk6K1MCgEAAIBjjc0saW55VUfb7V8n+/M+1dchSfr++Sub+4K3vifFRqS+L0jBxhwmQzGhcAcAAAAAJS6fhbvBfBXuJs5Ka8vSgRd2fi1flbTnEWmyX0qnd349AADgGIZhaCASV3dzSF6Pg3/dvrpirpRtPS55yuxO4xhV2ZWyCYcU7vzVUnpdWrtldxIAAAAUgPPjNyWp4Ap3+xuDenJfrf5m8Jrmllfv/8mrK9Lp/0WqrJeOfyE/AVEUHPwbAAAAAADAZvSPzaq1tlItuypzdo+Qv0ztdZX5m3A3eso8uz5szfXanpJuzUkz71lzPQAA4AiTsytaTKyrt6Xa7ii5NfW6lF6TOk7YncRRshPulpwy4c4fMs9Enn7mBwAAQEG7MGGubD3avsvmJHf6jSfatJpK6z/8bOr+n3j+W9LitLlKNvvzLiAKdwAAAABQ0iI3V3RlbkV9OZxul9UTrtbl2LIWE2u5vZFhSCMvSqEWqfGQNddsf9o8WSsLAAB+ztuReUnSIy01NifJsYkz5tlO4c5KAZ9HkoMKd77MC5DJBXtzAAAAoCCcH59TZ0NAdUGf3VHu8OHuJtUFyvX9168onTbu/kkrc9KZ/1WqaZOOfDq/AVHwKNwBAAAAQAnLxzrZrN7MWtmL0zl+AW72knRzXOp6QXK5rLlm65OSXBTuAADAbQYj5iQvx0+4Gz8j+aqlPY/YncRRqnzmet5lpxTuNibcUbgDAAAoddH5W4rO39KxjsJaJ5vl83r0scdbNDG7ov7M78jvcPbrUjIufehfSN7y/AZEwaNwBwAAAAAlzI7CXc7Xyo68aJ4HLFonK0kVu6SmHmmy35ygBwAAIGkgGlfQ51VHXcDuKLmTXJSiP5Pan5LcHrvTOEp2wt2iUwp3GxPuWCkLAABQ6i6MZ9fJFmbhTpJ+41irJOn75yfv/OD8lPT6t6Xdh6Xuj+Q5GYoBhTsAAAAAKFGGYah/bFYHGoNqrPLn/H7dzWbhbjDXhbvRFyWvX+p4xtrrtvVJS9el2TFrrwsAAIpSKm3oYjSunnBIbrdFU3UL0ZXXJCPFOtkcCPq9kpw04S4z6ZEJdwAAACXv/EThF+7a6gI6caBepy5e143FxO0fPP01KZWUnvtDyU21CnfiuwIAAAAAStR4bFnXFhLqy8N0O0mqrixTa21lbifcJRbMKXTtJ6TySmuv3f6UebJWFgAASLo8s6Tl1ZQeaamxO0pujb9inh0U7qzm83pU5nE5qHCXXSnLhDsAAIBSd2F8Tnuq/WrZVWF3lPv6zSdatZ429O9/Gnn/wevvSG//W6njpNT5rH3hUNAo3AEAAABAierfWCdbn7d79oardTm2rKVcvah4+SdSel3qsnCdbFZrn3lSuAMAAJIGImapqLel2uYkOTZxRqqolRq77U7iSEGfV4sJhxTufJn/LySZcAcAAFDKbi6vavTGko6218rlKuxp4B96uEkNVT59//UrSqUN88GX/lgy0uZ0uwLPD/tQuAMAAACAEnVubFYul/TkvvyN9e8JV8swpHemc/Qi3Mgp8zzwgvXXDjZI9QeliVd+OWl5AAAgAElEQVQlw7D++gAAoKgMZqb2Hg47eMJdIi5dfduc9MsapZwI+LxaXnVI4W5jwh2FOwAAgFJ2IbNO9lhH4a6TzSrzuPVrR/cqOn9Lr4zOmNtTRv5G6v6IFP6A3fFQwHiGDAAAAAAlKJ029NrlWR3aE1JNZXne7tsbNqdeDOZirWw6LY2ekhoekna1WX99yXyxeSEizV/JzfUBAEDRGIjMq6ayTHtrC3tF0o5M9puTHdqfsTuJYwV9Xi05ZcKdnwl3AAAAKK7CnSR9/OheuVzS985NSj/+A8ntlZ79it2xUOAo3AEAAABACRq5sajZ5VX1ddbl9b49YXPqxVAuCndX35KWb+Rmul1W21PmyVpZAABK2loqrYvTC+oNVxf8iqQdGT9jnh0n7M3hYEGfV0vJlN0xrOFjwh0AAACk8xM3VVNZpv0NQbujbErLrkp98GCjPKM/kiLnpSOfkuo67Y6FAkfhDgAAAABKUP+lWUlSX2d9Xu9bU1muvbUVuZlwN5pZJ9v1YeuvndXWZ54U7gAAKGmj15eUXE/rcEu13VFya/wVKdBgThBGTgR8Xi0l1+yOYY2yCnMaSCIHP+sDAACgKKysrutiNK7H22rldhfPm5N+8/Fm/f/s3WlglPW99vHvLMlM9gAhCwkkISSsAURZBEEU0bpRu50uPj093bSttbba1tPWLra2PT32VLuqbe1iq7W21rrWfWMTUJQdEiALCSEhhOyZSWZ5XtwJYkVNYGb+k3uuz5t/hTD3pTVmluv+/b7suo9+Zwos+6rpODIKqHAnIiIiIiKSgNbtO4LL6WC+gbH+lYVZ7DvcTY8/wquzqp4ATxZMXBjZxz1e5gQYUwq1KtyJiIgksm2N7QBUFmYbThJFvW3QvA1KloKdp/gZlu514xsIEQiGTEc5dQ6HNeVOK2VFREREEtar9e0EQmEWlI4xHWVEzvE/Tbmzkbu4lEDqeNNxZBRQ4U5ERERERCTBBIIhNuw/wpyiLNI97phff1ZhFuEw7GyK4Adx3S1wcDNMORdcSZF73BMpWQJHa6DzYHSvIyIiInFra4M1wWvORBtPuKtdY51aJxtV6cnW8/Eeu6yV9WZqpayIiIhIAttY0wbA/JLY3+h90vp7cT7/P/QmjeHW3vN5dneL6UQyCqhwJyIiIiIikmB2HOykyx+I+TrZIZWF1gfT2xoiuGqq+inrLI/iOtkhxWdZZ9266F9LRERE4tLWhg5y0j3kZ3pNR4me2tXWWbLMbA6bS/dahbvu/ghPfzbFmwV+rZQVERERSVSbattISXIxq3AU3Zy08Q7oOkhgyZfpc6Zxz8Z604lkFFDhTkREREREJMGs23cEgDPLxhm5/qwJ1pst2xsjWbh7AnBA+crIPeZbKV5snUNTX0RERCSh+ANBdh/qZHZRFg47r1qtWQ0ZBTCuzHQSW0vzDE24s0nhzpMJPhXuRERERBJRfyDE5vqjnDYpmyTXKKkj9bbB6lsgu5jMs65gxbRcXqg6zIG2XtPJJM6Nkn/DRUREREREJFLW7z9CssvJ6cVjjFx/TFoyRWNS2Bapwl1wAPY9B4WnQ1oMpvaNKYasiZpwJyIikqD2HOpiIBg+NrXXlroPw+FdULIU7FwqjAMZg4W7Lp9NCnfeLPB3QThsOomIiIiIxNj2gx34BkKja53smlusCc3nfhPcyVy+qJhwGO7dpCl38vZUuBMREREREUkg/YEQm2ramFecjTfJZSzHrAlZ7DvcTW8kVmfVrwd/J1TEYJ3skOLF0LrH+jBaREREEsrWBuumgTkTbVy4G1onW7rUbI4EYMsJd+EQ9HebTiIiIiIiMbappg2ABaWjpHDX0QAb7oD8Spj1PgCWTslh4tgU/rqpgYFgyHBAiWcq3ImIiIiIiCSQLQ3t9A0EWVwWg0lwb6OyKItQGHYe7Dz1B6t6wjrLzz/1xxqu4iXWWa8pdyIiIolma0M7ALPsPOGu5kXrLFHhLtrSvVbhrtsuhTtvpnX6IvA8X0RERERGlU21bbidDk6blG06yvA890MI+uG8G8Fp1aecTgcfXjCJ1m4/T+1sNhxQ4pkKdyIiIiIiIglk3d4jACwuG2c0x9AH1NsjsVa2+klIz4eCOaf+WMM1VLirXRu7a4qIiEhc2NrQQUGWl9wMr+ko0VO7GrImwZgS00lsL91jTZ22T+FusIjqV+FOREREJJGEQmE21R5lZmEWqclu03HeWfNO2HIPlJ4NZee+4bc+cPpE3E4Hd2+oMxRORgMV7kRERERERBLIun2tpCa7mF1k9i7DysHC3bbGU/wgrq0GWqugfCU4HBFINkzjyiA9D+o04U5ERCSR9PUHqW7pPvZcxpY6m+DIXmudbCyfXyWotMEPI7t9NinceYYm3EXgxhoRERERGTWqW7rp6BtgQckY01GG55nvQjgE533nTa97xmd4uGBWPmv3HqGmtcdIPIl/KtyJiIiIiIgkiL7+IK/WtzO/ZCzJbrMvB8emJVOYnXLqE+6qn7TOigtOPdRIOBzWlLvm7dB3NLbXFhEREWN2NnUSDIWZM3GUrEg6GbWrrVPrZGNiaKVsj20m3GmlrIiIiEgi2ljbBsD8krGGkwxD7Vqo+hfMfC8Uzjvhl1y+YBIAf9lYH8tkMoqocCciIiIiIpIgXqk7Sn8wxJmG18kOmVWYSXVLF339wZN/kOonwZkEk5dHKtbwFS8GwlC3PvbXFhERESO2NrQD2HvCXc2L1lmqwl0spHsGJ9zZpXA3NOFOK2VFREREEsqmmlFSuBvwwSNfBJcHzr3hLb/szLJxTM5J428vH8AfOIX3r8W2VLgTERERERFJEOv2tQKwOE4Kd5WFWYTC1qSYk9LfAzWroWQJeDIiG244Ss6yzrq1sb+2iIiIGLGtwZrOa+vCXe1qGFMKWUWmkyQE2xXuvIPfG1opKyIiIpIwwuEwm2rbqMhLZ0xasuk4b2/1j6G1CpZfD+PK3vLLHA4HH14wiaO9Azy+/VAMA8poocKdiIiIiIhIgli//wgZXjczJ8THB8SzBj+oPum1sjUvQtAP5edHMNUI5EyFlLEq3ImIiCSQrY0dTBybEv8fIp2s9gNwtFbT7WIozWPTlbKacCciIiKSMBqO9tHU4Yv/6XaHtsGaWyC/EhZ/4R2//H2nF5HsdnL3Bq2VlTdT4U5ERERERCQBdPkG2NrQwaLJ43A5HabjAK9Phtl2soW7qiess/yCCCUaIafTWivbtAX8XWYyiIiISMx0+wPsO9zN7KJs01Gip3a1dZYsM5sjgXjcTpJcDvtMuPNowp2IiIhIotlUa62TXVAax4W7YAAe/DyEw7DqF+BKesc/MjYtmYtm5bOxpo3qZr3/K2+kwp2IiIiIiEgC2FTbRjAUjpt1sgDj0j1MyPKe3IS7cBiqn4SxkyFnSuTDDVfxEgiHoH6DuQwiIiISE9sbOwiHYbad18nWvGidmnAXMw6HgzSP2z6Fu6EJdz5NuBMRERFJFEOFu7iecPfSL6HpNVjyBZgwd9h/7PJFxQDcs1FT7uSNVLgTERERERFJAOv2HgFgcVmO4SRvNKswi+qWbnwDwZH9weYd0NlobrrdkJIl1qm1siIiIra3rcG6SaCyyKaFu3AYalZDTgVk5JtOk1DSkm1UuPNopayIiIhIotlY00ZhdgoTslNMRzmxI/vguR/AuClw9vUj+qNnFI+hPDed+19pGPl72GJrKtyJiIiIiIgkgHX7jjAuLZmKvHTTUd6gsjCLYCjMzqYRfiBXPbhOtuL8yIcaibxZ1tosFe5ERERsb+vgVN5Zdp1wd7QGOhugRNPtYi3D66bHb5MP75K84PJowp2IiIhIgmjt9rPvcE/8rpMNheChL0DAB6t+DkkjKwU6HA4uXziJTl+AR7Y2RSmkjEYq3ImIiIiIiNjc0Z5+djZ1sqhsHA6Hw3ScN5g1OCFmxGtlq56EpDRrpatJThdMWgSNm6G/12wWERERiaptDe1MHp9GpjfJdJToqFltnVonG3NpHjddPptMuANrraxvhM/vRURERGRUejne18lu/gPUrYH5n4LixSf1EO+ZV4Q3ycndG+oim01GNRXuREREREREbO6l/UPrZMcZTvJmsyZYhbuhFW3D0tsGDRuh7Bxwe6KUbARKlkBoABo2mU4iIiIiUdLRO0DtkV5m23W6HUDtYOFOE+5iLt3jpscuK2XBWiurlbIiIiIiCWFjzVEAFpSOMZzkBDoa4clvQWYRrPj2ST9MVkoSl86ewKv17ew8qOe5YlHhTkRERERExObWHyvc5RhO8mbjMzzkZ3rZNpIJd3ufgXAIyg2vkx0yNGVPa2VFRERsa+i5SmVRtuEkURIOWxPucmdAWvw9Z7S7dI+bvoEgwVDYdJTI8GZqpayIiIhIgthU28bYtGTKxqebjvJG4TA88iXo74JLbrGeo56CjyycBMA9GzXlTiwq3ImIiIiIiNjcun1HKMjyUjIu1XSUE5pVmEV1Sze+geDw/kD1E9YZL4W7gjnWetu6daaTiIiISJRsbWwHYE6RTSfcHdkL3Yc03c6QdI8bgG67TLnzZmnCnYiIiEgC6PYH2HGwgzOKx+BwOEzHeaPt91vvI8/+IFSc+vvIcydmM6Mgk3++etBe06nlpKlwJyIiIiIiYmMtnT72tnRzZtm4+HvTY1BlYRbBUJjdh7re+YtDQdj7NOTPhsyC6IcbDlcSTFxgrZQN+E2nERERkSjY1tCB0wEzJpzaVIS4VfOCdZaqcGdC2mDhzjYf3Hkywd8FoZDpJCIiIiISRZvrjhIKw4LSsaajvFFPK/zrq5CaAxf8MCIP6XA4+MjCSXT7Azy05WBEHlNGNxXuREREREREbCye18kOqSyyPrge1lrZhk3QdxQqLohyqhEqWQIBHzRuNp1EREREomBrQwfluRmkJrtNR4mOmtWAA4qXmE6SkNK9dptwlwmENeVORERExOY21bYBML8kzgp3j/839B6Bi/4X0sZF7GEvO62QtGQX92yoj9hjyuilwp2IiIiIiIiNrdtrFe7OLIvcGwuRNqvQWs22vWEYhbuqoXWycVa4Kz7LOuvWmM0hIiIiEdfa7aexvY9Ku66TDYehdg3kV0JqnH1QliDSPS7ARoU7z+D3igp3IiIiIra2saaN1GQXM+NpEviex2Hb32DqRTDzvRF96HSPm1VzC9nW2MHWhvaIPraMPirciYiIiIiI2Ni6/a2UjEulMDvFdJS3lJvhJS/TM7wJd9VPQuo4KJwX/WAjUTgP3F6oXWs6iYiIiETY0HOUOXYt3LXsgt5WKF1mOknCGlop2+2zSeHOO/iBq0+FOxEREZFY+urft3Du/z3PXzfVMxAMRfVa/kCQ1w60M2/SGNyuOKke+TrhkS+BJxMu/j9wOCJ+icsXTgLQlDtR4U5ERERERMSuDrT1cqCtL66n2w2pLMyiqrkL30Dwrb+oowGat8OUleB0xS7ccLg9UDQfDmyE4IDpNCIiIhJB2wan8FYWZRtOEiW1q62zZKnZHAksfbBw12OXCXdeTbgTERERibXtjR3c93ID+w/3cP392zjnx89z78Z6+gPRKd5tb+zAHwixoDSOpmQ//W3oOgjnfw8yJ0TlErMKs5hTlMWDrx2k06f3gROZCnciIiIiIiI2tX7f0DrZHMNJ3tmswiwCoTB7DnW99RdVP2mdFefHJtRIFS+GgR5o2mI6iYiIiETQ1oZ23E4H0/IzTEeJjpoXweGE4jNNJ0lYQ4W7LrsU7jxDE+6GMcFaRERERCLi589WA3DflWfylQum0u0P8N//sIp3f4lC8W5jzVEA5pfESeGudg28/DvrRqJ5H4vqpS5fWEzfQJAHX22M6nUkvqlwJyIiIiIiYlPr9w8W7iaPjgl3wNuvla16EhwuKFsRo1QjVLzEOuu0VlZERMROtjZ0MDU/A29SnE3YjYRQyPpgqmDu61PJJObsN+FOK2VFREREYmlXUydP7Ghm5Yw8FpSO5apzprDm+nP56rum0tsf4GuDxbt7NkSueLepto0kl4PTJsXBJPCBPnjoanCnwKU/jcoq2eNdMqeADI+buzfUEw6Ho3otiV8q3ImIiIiIiNhMKBTm/lcaeHpnMxV56YzP8JiO9I6GCnfb36pwN+CDmhdg0iJIiYM3cU6kaD44k6BWhTsRERG7aO700dLlZ7Zd18k2bwNfO5RqnaxJaXYr3A1NuNNKWREREZGYGJpu94Vzy4/9WrrHzeeWT2H19edy/bum0dsf4OsPWMW7uzfUnVLxLhgKs6m2jcrCrPi4Men5H0Lbfjj3GzCuLOqXS0128955hew+1MXm+vaoX0/ikwp3IiIiIiIiNvLS/iOs+uUarvvbFlwuB1+9YJrpSMOSm+klN8Pz1hPuatfAQC+Ux+k6WYDkVCicB/UvQShoOo2IiIhEwNYG67nJ7CKbTn+rWW2dJcvM5khwGV6brZQdmpaolbIiIiIiUbfnUBePbTvEimm5VJ7gdUu6x81nl5ex5vpz+e8Lp9E3EOQbD2xn+c3P8eeX6vAHRv4+5p5DXXT5AswvjYN1so2bYd3PYcI8WPjZmF32IwuLAbh7Q13MrinxRYU7ERERERERG6ht7eHKP73Mh379EnsOdfGps0p54cvncN6MPNPRhq2yMIuq5q4Tv8lT/YR1VlwQ21AjVbwE/B3QvN10EhEREYmArQ3WtIKhaby2U7sanG5rirAYY7sJd15NuBMRERGJlWPT7VaUv+3XpXncfObsMlZ/9Ry+duE0fIEQN/xzO8tvfp4/ra8dUfFuU20bAAtKDBfuggPWKlmHE979C3C5Y3bpqfkZnFE8hke3NtHe2x+z60r8UOFORERERERkFOvoHeB7j+xk5S0v8MSOZt41M5+nvnQ2N1wyg6zUJNPxRmRmYRYDwTB7DnW98TfCYah6ArImwfg4n9hXvMQ669aZzSEiIiIRsbWhg2S3k6n5GaajRF4wYD1nKTwdPOmm0yS09MHCXbfPJoU7jybciYiIiMRCdXMXj25rYvnU8cyZmD2sP5PmcXPl2WWsuf4cvn7RNPoDIb754A6W3/w8d62vxTfwzsW7jbVtOBxwRrHhwt3aW60bn5deB3kzY375jyychD8Q4v7NjTG/tpinwp2IiIiIiMgoNBAM8fu1NZz94+e4c00N0/Iz+esVi7j9o6dTkpNmOt5JGZoc86a1sq1V0F4HFeeDw2Eg2QhMWmjdUVm7xnQSEREROUXhcJhtjR3MKMgkyWXDt9IPbbEmkJUsNZ0k4XncTtxOB93+ka/ziktDE+58mnAnIiIiEk2/eG4v4fA7T7c7kdRkN1csK2P19efwjYumMxAM8a3B4t0f17118S4cDrOppo2peRlmb/g+vAde+F/rBu2l1xmJcFFlAdmpSdyzoY5wOGwkg5hjw3cJRERERERE7CscDvPUzmYuuOVFbnx4JylJLm754BwevGoJCyePMx3vlAwV7rY3/tsHc1WD62TL43ydLIAnAwrmWNNiQiHTaUREROQUNLb30dbTz+wim66TrVltnaUq3JnmcDhI87jp9g+YjhIZriRwp2ilrIiIiEgU7TvczcNbDrK0PId5k8ac9OOkJrv59LLJrP7qudxw8XQCoRDffmgHZ9/8HH9YW/Om4l19Wy8tXX7mm1wnGwrCg5+3Vsqu+gW4PUZieJNcvG9eEfsO97Chps1IBjFHhTsREREREZFRYntjBx/5zQY+fdfLHOr0cd3KCp69bjnvOa0IpzPOJ78NQ16mh5x0D9v/fcJd9ZPWB3aj5cPg4iXQ1wate0wnERERkVOwtcF6TjJ0U4Dt1K4GVzJMXGg6iWCtle2xy4Q7AG+WJtyJiIiIRNEvn91LKAxfPG/k0+1OJCXZxaeWvl68C4bgOw/v5Oybn+P3xxXvNg4Wy+aXGizcbfotNGyERZ+FifPN5cBaKwtw94Z6ozkk9tymA4iIiIiIiMjba+70cfMTe7h/cwMAHzxjItedX0FuptdwsshyOBxUFmaydu8R+gMhkt1O8HVA/XooWwFJKaYjDk/JWbD+F9Za2dzpptOIiIjISRoq3M0uyjacJAqCA1C3Hormj57nWDaX7nHT7Q+YjhE53kxNuBMRERGJkprWHv75WiNLpozj9OLIFt+GineXLyzmno313P7CPm58eCe3Pb+Pz5xdxpaGdgAWmJpwd7QOnr4Rsovh3BvMZDhO2fh0Fk0ey+Pbm2jtnkFOuplpexJ7mnAnIiIiIiISp3r7A9z6dBXLb36ev7/SwOKycTx69VJ+9P7ZtivbDakszKI/GKKquQsaXoEHPgOhAFScbzra8E1aBDistbIiIiIyam1rbCclycWU3HTTUSKvcTMM9EDJKJkgnADSvTYr3HkyrZtnRERERCTifvmcNd3umhUVUbtGSrKLT55VyuqvnsO3LplBGPjuIzt58LWDTBybQn6Wgfenw2F4+Brrtcyqn0FyWuwznMDlC4sZCIb5+ysNpqNIDGnCnYiIiIiISJwJhcL849VGbn5iN82dfiaPT+OGi6dzztRcHI7Rvzr27VQWpHGR8yXy/vYjaN9i/WLZCqj8D7PBRiJlDOTNgrq11ptANv//TERExI7C4TBbGzqYVZiJy2nDn+W1L1pn6TKzOeSYNI+bHjsV7ryZ0LLLdAoRERER26k70sMDrzayaPJYFsRgras3ycUnzirlIwsn8ZeN9fx+bS3vOa0w6tc9odfugf3PwWkfhcnLzWQ4gQtm5jMuLZm/bKzniqWTcdrxNaS8iQp3IiIiIiIicWT9viN8/7GdbG/sZExqEjeumslHFk4iyWXzAeV97fDqnzjnpdtZmdzAQEcynPb/YNHnIG+m6XQjV7wYNt4BbfthXJnpNCIiIjJCtUd66fIFqCy04TpZgJrV4PZC0Rmmk8igDI+b3v4gwVDYHiVPT6Y1eSQYAJc+ihIRERGJlF89t49gKBzV6XYn4k1y8fElpXx8SWlMr3tMVzM88TVIz4fzbzKT4S0ku5184IyJ3P7CPtbua2Vp+XjTkSQG9CpHREREREQkDtS09vDDx3bx5M5mklwOrlg2mavOmUJWSpLpaNHVth9euh1euxv6u3Gljed25wdZm72KP737EtPpTl7JEqtwV7tGhTsREZFR6JldzQDMmZhlOEkUBPxwYANMXAhuj+k0MijN4wKgpz9AptcGrwG8g987/k5Ijf7kFREREZFEcKCtl/s3N7CgZCyLJifYc6zHvgy+DvjgryAl/m6M+vACq3B3z4Z6Fe4ShAp3IiIiIiIiBrX39vOzZ/Zy1/paAqEwF1Xmc/27plE8Ls10tOgJh60i2ku3wZ7HgLC1gnXR53BUvp+X/rSFDXuP0B8IkewepZP9Ji22zrq1cPrHzGYRERGREWnv7efnz+5lQpaXC2bmm44TeQ0vQ8AHpUtNJ5HjpHmsj2u6fXYp3GVap69DhTsRERGRCPnV8/sIhMJcc145DocNpiIP184HYddDMOMymB6fN2kXj0tjaXkOT+5spqXTR26m13QkiTIV7kRERERERAzoD4T480t1/PSZajr6BphTlMUNl8xgfomNP4wK+GH7P+ClX8KhbYADKt4Fiz4Lpctg8E2iysIsnt9zmKrmLmYVjtKpMunjIWcq1K0znURERERG6OfP7qWjb4AbV83Em+QyHSfyaldbZ8kysznkDTIGC3c9/oDhJBHiOW7CnYiIiIicssb2Pv7+ygFOLx7D4rJxpuPETt9RePTL4M2Gi242neZtXb5wEqurW7nv5QN8/txy03EkylS4ExERERERMeALf3mVx3ccoiDLy42rZrJqzgScTpveldjTCi//Djb9FrqbISkV5n/aKtqdYN3qUMlue2PH6C3cgbVW9uXfwdE6GFNsOo2IiIgMQ21rD3etr2V2URar5kwwHSc6alZDUhoUzjOdRI4zNOGuyy6Fu2MT7lS4ExEREYmE257fy0AwzDUrEmy63RM3QE8LXHY7pOeaTvO2VkzPIzfDw182HuCzy6fgsuv7/QLAKN3NIyIiIiIiMnq9UtfG4zsOsWJaLs9et5zLTiu0Z9muZRc8dDXcMhOe+z44k2Dld+HanXDxj09YtoPXC3fbGjtimTbyipdYp6bciYiIjBr/86/dDATD3HDxDHs+Pxvog4aNMGkRuGywttRG0r02m3Dn1YQ7ERERkUhp6ujjvk0NzJ2YzdLyHNNxYmffs/Dan6FsBcz5kOk07yjJ5eSD8yfS2N7Hi1WHTceRKFPhTkREREREJMZ+/EQVTgd87aLppCTbbE1ZKATVT8Fdl8GvFsHmuyBvFrz/d3DNa7DkGkgZ87YPMSHLy9i0ZLaP+sLdYuusW2M2h4iIiAzLxhrrpoh3zcxnQelY03Gi48AGCPZDqdbJxpt0262U1YQ7ERERkUi5/fl99AdDXHNeAk2383fDw9dY07kvvRVGyd/3hxZMwumAuzfUmY4iUaaVsiIiIiIiIjG0dm8r6/cf4f2nFzElN910nMjp74Wt98JLt0FrFThcMPM9sOgqmDh/RA/lcDiYVZjFS/uPMBAMkeQapfeKZU6AMaWacCciIjIKhEJhbnp0J0kuB/994TTTcaKnZrV1li41m0PeZKhw1+WzSeHu2ErZUX4TjYiIiIhhzZ0+/rLpALOLslheMd50nNh59iZor4cLb4bsSabTDFthdgrLp+by7O4WDrb3MSE7xXQkiZJR+qmFiIiIiIjI6BMOh7n5iT0kuRxcs6LcdJzI6DwIT98It8yAR74EXc2w+Gq4Zgt84A8jLtsNqSzMpD8Qorq5O7J5Y61kCbTth84m00lERETkbTy4pZGtDR187MwSSnLSTMeJntrV1uSx/Dmmk8i/SbPrhDutlBURERE5Jbe/sI/+QIhrViTQdLsDG2HD7TBxEcz/lOk0I3b5wkmEwnDvpgOmo0gUqXAnIiIiIiISI81BuTkAACAASURBVM/sauG1A+18aP4kJo5NNR3n1HU2wS8XwZqfWGtiL7wZrt0J598E2RNP6aErC7MAbLBWdol11q01m0NERETeUl9/kP99fA/ZqUlcfa5Nboo4EX83NL5irb13aflNvBmacNdtl8KdJtyJiIiInLKWTh/3bKhnVmEm507LNR0nNgJ+ePDz4EqCVT8H5+irNS2fmsuELC9/3VRPIBgyHUeiZPT9mykiIiIiIjIKhUJh/u+pKjxuJ58/d4rpOJGx71nwd8B534HPvwILrwBPZNbkzhos3G1T4U5ERESi7M41+2nq8HHNinKyUpNMx4meAy9BKAAlWicbj14v3AUNJ4kQr/V8XhPuRERERE7er1/cjz8Q4gvnJtB0u21/h9Y9sPTLML7CdJqT4nI6uHxRMXOKsmnvGzAdR6JEt7GJiIiIiIjEwGPbm9jV1Mmnl5aSl+k1HScyhkpksz8U8TsNC7NTGJOaNPoLd2OKIWsi1KpwJyIiEo9aunzc9vw+SnPSuHxhsek40VWz2jpLVbiLR2nHCnc2+UBuaKWsT4U7ERERkZNxuMvPnzfUMb0gk5Uz8kzHiY1wGDbeAUmpsPBK02lOyVXn2OSme3lLmnAnIiIiIiISZYFgiJ88VUVasovPLrfRC+26tTB2MmQWRPyhHQ4Hswqz2NXUOfrH7hcvtu7K7D5sOomIiIj8m1ueqqKnP8jXLpxGstvmb5fXvAjebMirNJ1ETiDDaxXueuwy4c7pguR0rZQVEREROUm/Xb0f30CIa1ZMSZzpdgc2QtMWmPMhSMk2nUbkbdn8HQQRERERERHzHni1kf2He/jkWaWMTUs2HScyOhrhaK1VJouSysIs/IEQ1S3dUbtGTAytla1fZzaHiIiIvMHuQ538ddMBFpaOtf/ECF8HNL0GJWdFfDKxRIbH7cTldNDlC5iOEjmeTK2UFRERETkJR7r93LW+jql5GZw/I990nNjZeId1LrjCbA6RYdAraxERERERkSjqD4T46TPVZKUk8allk03HiZz69dY5VCaLgsrCLIDRv1Z26J9RnQp3IiIi8SIcDvP9R3cRBr55yQz7T4yoWw/hEJQuM51E3oLD4SDd46bHb6PCnTdLK2VFRERETsJv19TQNxDkCyvKcTpt/lplSGcT7HzQes2SO910GpF3pMKdiIiIiIhIFP11Uz0NR/u48uzJZHqTTMeJnLq11hnFwt2swcLd9tFeuBtXBul5r/8zExEREeOerzrM6upW3nta0bHnHLZWu9o6S5aazSFvK93jpqffToU7TbgTERERGamjPf3cta6W8tx0LpyVQNPtXvkDhAKw4ErTSUSGRYU7ERERERGRKPENBPn5s3vJSU/mvxaXmI4TWXXrILMIsidF7RJFY1LITk0a/RPuHA4oPB1adsGAz3QaERGRhBcIhvjBo7vwJjn5ygVTTceJjZoXITVHkyLiXLrHTbfdVsr6RvlzeREREZEYu3NNDT39Qa5OpOl2gX545feQNQmmXmg6jciwqHAnIiIiIiISJX9aX0dLl5/PLZ9CarLbdJzI6WmFw7uheLFVJosSh8NBZWEWu5o6CQRDUbtOTEw4zbpDs3mH6SQiIiIJ795NB6hu6eaKZWXkZ3lNx4m+3jY4tA1Kzorqczc5dWkeF922WimbCQGf9QGqiIiIiLyj9t5+/rCulrLxaVxcWWA6TuzsfBC6m2H+J8HpMp1GZFhUuBMREREREYmCbn+A217YR0GWl48sjN4UOCPq11tn8eKoX2rmhCx8AyH2Hu6O+rWiqmCudTa9ajaHiIhIguvyDXDLU1WMz/Bw5bLJpuPERt06IAylWicb79I8bnsV7jyZ1qm1siIiIiLD8ru1tXT7A1x9bjmuRJluB7DxDnB7Yd5/mk4iMmwq3ImIiIiIiETB79bU0NbTzxdWlONNstldeXXrrLN4SdQvNXOC9SHd7qauqF8rqiYMFu4OvmY2h4iIxLU11a0sv/k5qptH+c+9OPar5/dxpKefr5w/lTSPjSYQv53a1dZZssxsDnlHGV43vf1BgqGw6SiR4c2yTq2VFREREXlHHX0D/H5tDaU5aVwyO4Gm2zVuhoZNUPkBSB1rOo3IsKlwJyIiIiIiEmHtvf385sX9FI9L5f2nF5mOE3l1ayE1B3LKo36pirwMAKpGe/EgPRcyJkCTCnciIvLWnt3dQu2RXr7+wDZCdincxJEDbb3cuaaGafkZvM+Oz9HeSs2LkJ4Xk+ducmrSkq0SaE+/TabceTXhTkRERGS4/rC2li5fgM+fMwW3K4GqPBt/bZ0LrzSbQ2SEEui7VEREREREJDZ+/eJ+uvwBvnReBUl2e3PE1wGHtlnrZB3RX2tQmpOG2+mgqnmUr5QFa8pdyy4Y8JlOIiIicaq6xSqYb6o9yt83NxhOYz83P7GH/kCIGy6ekTjrmXpaoWUnlC6LyXM3OTXp3sHCnV3Wyg6tlNWEOxEREZG31ekb4M411g3c7547wXSc2Ok+DNvvh0mLIb/SdBqREbHZJz8iIiIiIiJmHe7y8/u1tVTkpXPpHBu+OXJgI4RDMVknC5DsdlKakzb6J9wBFMyFUACad5hOIiIicaq6uZvJOWnkpHv44WO7aOvpNx3JNjbXH+WhLQdZMS2Xs8pzTMeJnWPrZJeazSHDku6xWeHu2EpZTbgTEREReTt3raul0xfgqkSbbrf5DxDsh4VXmE4iMmIJ9J0qIiIiIiISfb96fi99A0GuXVlhz8kpdWuts3hxzC5ZkZfBgaO99PUHY3bNqJgw1zqbXjWbQ0RE4lKnb4BDnT7mTMzmm5dM52jvAP/zr12mY9lCOBzmpkd24nI6+NpF003Hia2awcJdqQp3o8FQ4a7LZ5PCnUcrZUVERETeSbc/wG/X1DBxbArvOa3QdJzYCQ7Apt9BxgSYdonpNCIjpsKdiIiIiIhIhBxs7+Pul+qpLMzigpn5puNER9068GRB3syYXbI8L51wGPa2jPK1sgWDhbuDr5nNISIicWno59yU3HRWzZnAkinjuO/lBjbVthlONvo9tu0Qm+vbuXzhJKbkppuOEzvdLbDjH5A9CcaUmk4jw5B2bMLdKL/RZIgm3ImIiIi8o7vW19LeO8BVy6eQlEjT7XY/Al0HYf4nwJVkOo3IiCXQd6uIiIiIiEh0/fzZavqDIa47vwKHw4bT7fp7oXEzTFoETlfMLluRlwEw+tfKZuRZd2w2qXAnIiJvtrfZKtxV5GXgcDj43rtnkexy8o0HtjEQDBlON3r5A0H+5/FdZHjcXLOi3HSc2HrsK9B3FFZ+D+z43NSGMrxW4a7bP2A4SYR4Byfc+TrM5hARERGJUz3+AL95cT+F2Sm8d16R6TixteHX4EqGef9lOonISVHhTkREREREJAJqW3u47+UG5peM4eyK8abjREfjyxAaiOk6WTiucNcyygt3YK2VbdkFAz7TSUREJM5UD/6cKx+cwDZ5fDqfXV5GVXM3d66pMRltVPvjuloOtPXx+XOnMC7dYzpO7Ox8EHb+E6avgpmXmU4jw5SWPFS4s8mEO62UFREREXlbf36pjqO9A3zunDKS3QlU3zm0DerXwaz3QbpN30sX20ug71gREREREZHo+ekz1QRDYb58/lR7TrcDqF1rncVLYnrZknGpJLucVB2yQeGuYC6EAtCyw3QSERGJM9Ut3SS7nUwcm3rs1z67vIyScanc+nQVB9p6DaYbnY50+/n5M3uZODaFjy0uMR0ndnrb4NEvQ8oYuOjHptPICAytlO322W3CnQp3IiIiIv+utz/Ar1/cT0GWl/efnmjT7e6wzgVXmM0hcgpUuBMRERERETlFVc1d/PO1RpaW57Bw8jjTcaKnbi0kpULBnJhe1u1yMnl8GlWDq/ZGtQlzrfOg1sqKiMgbVTd3UzY+HZfz9eK+N8nF9y6bhW8gxI0Pq6w9Uj99ppouf4Dr3zUNb5LLdJzYefxr0NMC7/qRtdJeRo2hlbI9/TaZcJecATjAr5WyIiIiIv/ung31HOnp53PLy/C4E+j1Sm8bbPsbFM2Hwnmm04icNBXuRERERERETtFPnqwiHIbrzp9qOkr0BPqhYZP1Rog7OeaXL8/LoLG9jx5/IObXjqiCocLdq2ZziIhIXOn2B2hs7zu2TvZ4S8vHs2rOBJ7e1cKTOw4ZSDc67W3p5u4N9cyblM3FlQWm48RO1ROw9V4ovwBm/4fpNDJCQxPuunyj/DnvEKfTWiurCXciIiIib9DXH+T2F/aTl+nhA2dMNB0ntjbfBQEfLLjSdBKRU6LCnYiIiIiIyCnY1tDB4zsOsXJGHnMnZpuOEz0HX7XeCCk5y8jlKwYLCNUto3zKXUYeZBRAkybciYjI6/YN/nw7UeEO4IZLppPhcfOdh3aM/vJ5jPzwsV0EQ2FuuGQGDofjnf+AHfS1w8PXWAWnS26BRPn7tpH0wcKdrb7PvZng04Q7ERERkeP9ZWM9rd1+Pnt2WWJN4w4FYdOdkJ4HM95tOo3IKVHhTkRERERE5BT8+Mk9OBxw3fkVpqNEV91a6yxebOTyFfkZgLW+d9SbcBq07IIBn+kkIiISJ4YK5eV5GSf8/dwML19511QOdvj46TPVsYw2Kq3d28ozu1u4dM4E5k0aYzpO7Dz1TehqgvNvgqxC02nkJNiycOfJBL8m3ImIiIgM8Q0Euf2FfYzP8PChBZNMx4mtPf+Cjno4/eNGtqiIRJIKdyIiIiIiIidpU20bL1Qd5tLZE5iWn2k6TnTVrQNXMhSebuTyFYMFhKpDNijcFcyFUABadphOIiIicaK6xfr5Vp534gl3AJcvLGZ2URZ3rqlhV5PKK28lGApz06O7SHY7+eoFU03HiZ19z1qrmSYvh3n/aTqNnCRvkhOX00GXnQp3Xq2UFRERETneXzcdoKXLz2cSbbodwMY7wOmGMz5uOonIKVPhTkRERERE5CSEw2F+/MQeXE4HX1pp8+l2oSDUv2SV7ZJSjESYNDYVj9tJ1WhfKQswYa51HtRaWRERsext7ibJ5aB4bOpbfo3L6eD7l1USDof5xgPbCIXCMUw4etz/SgO7mjr5xJJSJr7NP09b8XfDQ9dAUhpc+jOtkh3FHA4Hackue02482Zpwp2IiIjIIH8gyG3P7yMn3cNHEm26XcsuqHkRZlwGGfmm04icMhXuRERERERETsKava1sqGnj/fOKKM1JMx0nug5tg/4uY+tkwSoZlI1Pp9oOK2ULBgt3TSrciYiIpaqli8k56bhdb/92bWVRFv95Zgmb69u57+UDMUo3evT4A/z4yT2MS0vmc+eUmY4TO8/caK1lWnkjjCk2nUZOUbrHTbedCneeTAj2w4DPdJJjDnX4eGZXs+kYIiIikoDue7mBQ50+rlw2mZTkRJtu92vrXHil2RwiEaLCnYiIiIiIyAgNTbdLdjn5wnnlpuNEX9066zRYuAOoyEunqcNHp2/AaI5TlpEHGQVw8FXTSUREJA709gdoONrHlLdZJ3u8686vIDfDww//tZsj3f4opxtd7nhxPy1dfr64soJMb5LpOLFRt8764GrSYjjjk6bTSASke21WuPNmWqevw2yO49zyVBWf/OPLPL1TpTsRERGJHX8gyG3P7WVcWjKXL0qw6XZ97bDlXutG5KL5ptOIRIQKdyIiIiIiIiP01M5mtjR08OEFEynMNrNiNabq1oLDCRMXGo1RkZ8BQHWzDdbKFsy11ijE0aQPERExY//hHsJhKM8dXuEuw5vEty6dQUffAD94bHeU040ehzp8/PrFfUzJTefD8yeajhMb/b3w4FXg9sK7fwFOvd1vB2keN90+GxXuPIOFuzhaK7ujySr/ffuhHfZa3ysiIiJx7W8vN3Cww8enl00mNdltOk5svXY3DPTCgivA4TCdRiQi9ApcRERERERkBEKhMD95qgpvkpOrzp1iOk70hcPW5JSCOeDJMBqlIte6fpUd1spOmAuhALTsMJ1EREQMq26xfq5V5A3/5+zFlQUsqxjP/ZsbWL/vSLSijSo3P7EH30CIb1w0/R1X89rGc9+Htv1w7g0wLoFW6NpcusdtrxKYN8s6ffFRuAsEQ1Q1d5OS5KKxvY9bn64yHUlEREQSQJdvgFufriIn3cNHFxWbjhNboRBs/A2kjoNZ7zOdRiRiEuSdBxERERERkch4ZFsTuw918bHFJeRmeE3Hib7De6CvDYqXmE5yrIhgj8LdadZ58DWzOURExLihya3DnXAH4HA4+N67Z5LsdvLNB7fTHwhFK96osL2xg/s3N7C0PIflU8ebjhMbBzbBS7+CwtNh0edMp5EISve46ekPEgqFTUeJjKGVsv74WClbe6SX/kCIj55ZzOyiLH63tpadB+OjDCgiIiL29avn99Ha3c+Xz68gzZNg0+32Pg1Ha2DexyApAd5Pl4Shwp2IiIiIiMgwBYIhbn2qigyPm88sS5ApInVrrbN4sdkcQNGYFFKSXPZZKQvQpMKdiEiiq27pxu10UDwubUR/rnhcGlefM4W9Ld38ZvX+KKWLf+FwmJse3YnDAV+/aDqORFhPFPBbq2Sdbnj3L8HpMp1IIih98APYnn6bTLkbWinri4/C3e5DVrluRkEmP3hPJeFwmK8/sI2gXQqOIiIiEncOtPVy55oaphdk8oEzJpqOE3sb7wCHC+Z/0nQSkYhS4U5ERERERGSY/rG5kf2tPXxyaSlj0pJNx4mNunXWOelMszkAp9PBlNx0e0y4y8iDjAJNuBMREaqbuyjJSSPZPfK3aq84ezKTx6fxs2eqqT/SG4V08e+pnc28tL+ND54xkekFmabjxMYL/wute+Dsr0LudNNpJMKGJp70+IOGk0RInK2U3d1kvZaYmp/BrMIsPr6klNcOtHPPhjrDyURERMSu/ufx3fQHQtxw8XRczgS4Qeh4rXutCXfTLoasItNpRCJKhTsREREREZFh8AeC/PSZarJTk/jkWaWm48RGOGwV7nJnQOpY02kAa61sS5ef9t5+01FOXcFcaNkFAz7TSURExBDfQJD6tt4RrZM9nsft4qZ3z8IfCPGth7YTDifWhKb+QIgf/ms3qckurj2/wnSc2GjaAmtugfzZsOSLptNIFGR4rcJdt3/AcJIIGZpw54+Twt2hLtxOB2Xjrf/uXruygglZXv738T20dOp5uYiIiETWy7VtPLq1ifOm57JkSo7pOLG36TfWufBKszlEokCFOxERERERkWG4d+MBGtv7+MzZZWR4k0zHiY2jtdB1MC7WyQ6pyLM+GKuyw1rZCXMhNAAtO0wnERERQ/Yf7iEU5qQLdwCLp+TwntMKeX7PYR7ffiiC6eLf3RvqqGnt4bNnl5Gb4TUdJ/qCA/DPq8DhsFbJuhLkOWmCGZpw160Jd1Gx+1AnZePTj00VTfO4+c6qmXT5A3z3kZ2G04mIiIidhEJhvvfITtxOB1+/KAEnU/u74NW7IXcmFC8xnUYk4lS4ExEREREReQd9/UF+8dxexmd4+NiZJabjxE7dWuuMq8JdBoA91soWzLVOrZUVEUlY1S3Wz7PywZ9vJ+vrF00n0+vmxod30u0PRCJa3OvoHeCnz1RTkOXlU0snm44TG2tuheZtcNa1UDDbdBqJkmOFO59Nvpe98TPhrss3QMPRPqYVvPG/uefPzGfljDwe2drE83taDKUTERERu3loy0G2NHTw0TOLmTz+5G+yGrW23Av9XbDwCuumIRGbcZsOICIiIiIiEu/uWl/L4S4/N66aSUqyy3Sc2KlbZ51xdAdi+eCEu2o7FO4mDBbumlS4ExFJVHtbrImtQz/fTtb4DA/XXziNbzywnVuequKbl8yIRLyTEgqFeXRbE/sOd+N2OnA5nYOnA7fLOpOczjf89Zu+zunA7XIe93vW1x7/db9dvZ/23gG+9R8zEuP5WfNOeOFHMH46LPuy6TQSRRnHJtzZpHA3tFLW12E2B6/ftDMtP/NNv3fjqpms3dvKNx/czpNfPDsx/rsiIiIiUdPXH+RHj+8mKyWJa1aUm44Te+EwbPw1eLOh8j9MpxGJChXuRERERERE3kaXb4DbXthHYXYKH1ow0XSc2KpbC2PLICPfdJJjCrNTSEt22WOlbEY+ZBRowp2ISAKrbu7G6YDSnLRTfqwPz5/E315u4Pdra3jPaYXMKsyKQMKR2drQzrce3MFrB9pjcr3Kwiwum1sYk2sZFQzAg1dBOGitknV7TCeSKEqzW+EuOQ0crrhYKbv70FDh7s1TRSdkp3DtygpuenQXP3u2muvfNS3W8URERMRGfrN6P00dPr596QyyU5NNx4m9/c9BaxUsvhqSU02nEYkKFe5ERERERETexp1ramjvHeDrF07H406gKQcdjXC0Fk77qOkkb+BwOCjPyzi2gm/UK5gLe5+GgF8fnouIJKCqli5KxqVF5DmG0+ng+++ZxaU/X8M3/rmdf3x2MS5nbNb2tPX0c/MTe7h3Uz1Oh4NPLCnl/acXESZMMBQmELLOgWDo9b8Ovv7rgdDrvx4IhgmGQsf93uB53K8HQmHC4TAfnD8RZ4z+Ho166ZdwcDMs/gIUnW46jURZ+mDhrscuhTuHAzwZcbFSdnfTYOGu4MRrvP9rcQkPvNrIb17cz2VzC5l6gmKeiIiIyDtp7vRx2/P7mDw+jf+3qNh0HDM2/BpwwPxPmU4iEjUq3ImIiIiIiLyFoz39/HZ1DaU5abx3XgJMTzle/XrrjKN1skMq8tJ57UA7R7r9jEsf5SW1CXOh6l/QvAMK55lOIyIiMeQPBKk70suKabkRe8yZE7L4+JJS7lxTw1821kf9w51gKMw9G+v58RN76OgbYGHpWL777lkqqURSazU8+31r6vA5XzedRmIg3W4T7gC8WXGxUnbPoS4yvW7yM70n/H23y8kP3lPJZb9ayzce2MZ9V54Z36XegT5wecDpNJ1EREREjnPzE3voGwjyjYumk+RKwJ/TbTVQ9ThMvRDGlJhOIxI1CfjdLSIiIiIiMjy3v7iPbn+AL55XjjvR3hypW2udxYvN5jiBijzrQ3xbrJUtmGudB181m0NERGKutrWXYChMeV56RB/3SysryM/08qPHd3O4yx/Rxz7eK3VtrPrFGr75z+14k5z87MOnce8Vi1S2i6RQCB78PAT7rVWySSmmE0kMpHvtWLjLND7hLhwOs+tQJ9MKMnE43rpEN2diNv+5qJiX647y15cPxDDhCAX8cMssa920iIiIxI3tjR3cv7mBs6bkcG4Eb64aVTb9FgjDgitMJxGJqgT7xEhERERERGR4Wrp8/HFdLdPyM7h09gTTcWKvbh1kFkH2JNNJ3qR8sHBni7WyEwYLd02vmc0hIiIxN/RzbKhIHinpHjffWTWDLl+AHzy2K6KPDdZzpOvu28L7bltPVXMXnzm7jGevW86qORPetsQiJ2HTb+DAS9YHVcVnmk4jMZLmsVZM22alLIDH/IS7pg4fXb4A04ZRCr7ugqnkZXr44WO7olpcPiVH9kFvK2y5B6qeNJ1GREREsAr+331kJw7ghkumJ+bro/4eePVPkDMVJi83nUYkqlS4ExEREREROYFfPbcP30CIa1dWxPcaoWjoaYXDu63pdnH4xlDF4CSgqmYbFO4y8iE9Hw6qcCcikmiqBye1TsmN7IQ7gAtm5nPutFweeLWRdXtbI/KYA8EQd66pYcWPX+D+zQ0sLc/h8S8u478vnEba4ApMiaCjtfD0dyC7GFZ8y3QaiaEMTxIA3T4bFe68meDrhHDYWITdh6wJe9PyM9/xazO9SXz70pl0+gJ8/9Gd0Y52clqrXv/fj14LfhtM/xYRERnlnthxiI01bXxw/sRhPeewpa33WTdaLPh0XL6vLBJJKtyJiIiIiIj8m8b2Pu7ZUM+cidmsnJFnOk7s1a+3zjhcJwuQn+klw+u2x0pZsKbcteyy1kKJiEjC2NvSjcMBZeMjX7hzOBzcuGom3iQnN/xzO/5A8JQeb/2+I1z8s9V875GdZKYkccdHT+euTyyISnbBKiU9dDUM9MKqn4FH/5wTiTfJidNht5WyWRAOWv9OG7L7kHWzznDXXl84yyou//O1g6ypjkxxOaJaq61z7uXQcQCevclsHhERkQTnDwT5wWO7Sfe4uXblVNNxzAiHYeOvwZMJcz5sOo1I1KlwJyIiIiIi8m/+urGe/mCIL51Xnpij/+vWWWfxErM53oLD4aAiL4Pq5i7CBqdkRMyE0yA0AM07TCcREZEYqmruYtLYVLxJrqg8/sSxqVx9bjn7W3u444X9J/UYTR19XP2XV/nwb16i9kgv16wo5+lrz+aCmfmJ+RwpVl75A9S8CKf/l9YwJSCHw0Gax22vwp1ncMKLr9NYhN1NIyvcvbG4vA3fwKkVlyPuyGDh7oIfQNEC2HA7NLxiNpOIiEgC++O6WurbevncOWWMz/CYjmNG7Rpo2WndEKCbhiQBqHAnIiIiIiLyb7Yf7CTJ5WBxWY7pKGbUrYXUHMgpN53kLVXkpXO0d4DD3TaYClcw1zqbtFZWRCRRDARD1LT2UB6FdbLH+/TSyUzJTecXz+2ltrVn2H/OHwhy2/P7WPF/L/DwloOcNz2Pp790Nl9aWUFKcnQKgjKoowGe/CZkFsLK75pOI4ZkeNz02Klw5x0q3HUYi7D7UCcTx6aQPoIV2BPHpvLF8yqoPdLLr57bG8V0J6G1CjIKICXbmoTpdFuTMYMDppOJiIgknCPdfn7+zF6KxqTwiSWlpuOYs/EO61zwabM5RGJEhTsREREREZF/s6upkym5GSS7E/Alk68DDm2z1snG8eSa8lxrMkW1HdbKThgs3B1U4U5EJFHUHekhEAozJXd4k5ZOVrLbyfcvm0V/IMQ3H9w+rMmwL1Qd5sJbV/Ojx3eTm+Hh9/81n99+7AwmjUuNalbBWsH08BehvwsuudVawykJKc3jpstOhbuhT1jHWwAAIABJREFUCXd+MxPu/IEg+w/3MC0/c8R/9pNnlTItP4PbXtjH3pY4ee0RDlsrZcdNsf46dzosvRZadsC6n5nNJiIikoBufbqaLn+A/75wWtQmmMe99gOw+1GYshLGlZlOIxITCfjpkYiIiIiIyFs72tNPU4eP6QXR/QA8bh3YCOFQ3K6THVKRZ/3/U9XcZThJBGTkQ3o+HHzVdBIREYmRocJ4RV701+wsnDyO959exOrqVh7d1vSWX3egrZcr7nqZj/1uI00dPr5ywVSe+NIyzpmWG/WMMmjLvbD3KZjzYag433QaMSjda9cJd2YKd/tarJLztGGukz1eksvJ999TSSAU5hsPbBtWcTnqug5BfzfkVLz+a0uvs/76+R/BkX3msomIiCSY6uYu7tlYzxnFY7i4ssB0HHNevtN6T3nhlaaTiMSMCnciIiIiIiLH2dVkfQg0o2Dk0w9soW6tdRYvNpvjHQwVFKrsMOEOrCl3LbsgYIMVuSIi8o6qB6cklUd5wt2Qr104jayUJL778E46fW9cN+gbCHLr01Wc95MXeHJnMxfPLuCZ687mqnOm4HEn6HQGE7oOwePXQ1ouXPAD02nEsHSPmx5/0HSMyBma1ug3s1J2T7P1Gu9kJtwBnF48ho8smMSGmjb+/kpDJKOdnNYq6zy+cOf2wKU/g6AfHr7GmoInIiIiUXfTo7sIhsJ885IZOOJ4W0hUDfTBK3+EsWVQtsJ0GpGYUeFORERERETkODsTvnC3DjxZkDfTdJK3NT7DQ3ZqEtV2mHAHUDAXQgPQvMN0EhERiYGhwl1ZblpMrjcu3cPXLpxGS5efnzxpFTXC4TBP7Wxm5S0vcOvT1Uwcm8rdn1rILz8yjwnZKTHJJYPCYXj0OvB1wCU/gdSxphOJYekeN93+AKGQTUpTHrMT7nY3Wa8Zpp3CFPOvvmsaOekefvDYLtp6+iMV7eQcK9xNeeOvF58Jp38calfDq3+OfS4REfn/7N13eFzlmf7x7xRpVEbF6sW23CTLBbBlQjcldAg9kAQ2HUKSTe8JJNkESH6pu8mmkb6EVDA4NAMJYEJMtwwukqyRu9Ulq3fNnN8fr2Q7cUFlRmfmzP25Lq43xtLMgyGSZs597kfizPrtLTxb28o1K4s5aU6m3ePYZ+saGDgAp9wCbkWQJH7ov3YREREREZHDVI9djFkSj4G74X6or4S5p4E7uhttXC4XZXlpbG/uiY61TtNVtMKcja/ZO4eIiMyIQHMPs2clk5LonbHnvOHkOawqmcU9L+zmkc0NvPe3r3DLPa/S0TfC7ZcvYd3HV3PmopwZm0cOs+1BqHkEll0DS66wexqJAqk+87Whf8QhLXfjDXeD9jTc1TT14PO6mZc99ZBzRnICX37LEjr6R/jGY9VhnG4K2uvMeXjD3bgLvwb+Anjyduhtmdm5RERE4shoMMRdj1aTlODmc5cstnsc+1gWvHQ3JKTCihvtnkZkRilwJyIiIiIicpjqxm4KM5KYlZpo9ygzb/8rpmUtytfJjivN99MzOEpztwPWsBaOBe4aFLgTEXG60WCIna19lOb5Z/R53W4Xd12zHJfLxUf+sIn121u5dmUxT3/6HG5evYAEj94qtkVfGzz2GUjJhku/Y/c0EiX8Y4G73sFRmycJk/GGuyGbGu6auinLT8Pjnt6atytPKmJ1aQ73b9zPizvbwzTdFLTVgjcZ0mcf+XtJGXDZd2CwE9Z9fuZnExERiRN/fHkvgZZePnD2Qgoz4rghfN9L0LQZVrzj0E0WInFC76KIiIiIiIiMGR4NEWjpic92OzDrZAHmnWXvHBNUlm9WQtU6Ya1seqFpolDDnYiI4+090M9wMERp/tRXG05VeUE6X7iknNMWZHHfB0/n+29bQV560ozPIYdZ9znob4dLvw3+XLunkShxMHA35JDA3cGGu5kP3HX0DdPcPcTigul/zXW5XNx59XJ8Xje3PbiFoVGbGgjbApC96Ngr25ZeCeVvgW0PQO0TMzubiIhIHOgaGOH7f6slL83HrWcvsHsce738c3Oe8gF75xCxgQJ3IiIiIiIiY3a09jIStFhSOPMXwKPCng2QkAKFJ9k9yYSU5ptmIEcE7sCslW2uglEHNPaJiMgxBVp6AWa84W7cLWcv4E8fOJ03zcuy5fnlMNvWwtY1sPhyWH6d3dNIFEl1XODOvoa7mibzWqE8DIE7gJLsVD52fik7Wvu4+9mdYXnMSRnuh659kFN6/I+77DumWfCRT8GQQ14viYiIRIkfPR2go3+Ez168+ODPbXGpuxGq/goLzoXcOF6rK3FLgTsREREREZEx1Y3mAtDSwjisvx8dNitl55wCngS7p5mQxWPNQIHmXpsnCZPCFWalb/M2uycREZEIqhsP3NnQcCdRZPcGePBWs0r28u+Ba3qrLsVZ/Enmwm2fUwJ33iRwJ8Bg14w/9fYm8xqvvCB8Lea3rF5AaZ6fHz1Tx662vrA97oS015kzp+z4H5deBBd8Fbr3w9N3Rn4uERGROLG7rY/fPr+b5cXpXFdxlPXu8WTjbyA0CqfcavckIrZQ4E5ERERERGRMVYO5GBOXDXcNm2B0EErOtHuSCcv2+8hOTWS7kxruQGtlRUQcLjD2fWuRTQ13EgUaXoM/vt0EkP5jjVktL3IYv88DQM+gQwJ3LpdpubNhpezBhrswvsZL9Lq565oTGB4N8eW1W7EsK2yP/YbaA+Z8o4Y7gFXvgzmnwUt3w/5XIzuXiIhInPjmumpGghZfvnwpbncc3zQzOgyv/gYy50LZxXZPI2ILBe5ERERERETGVDd1k5zgoSQ71e5RZt6eDeYsOcPeOSapNN9PXUvvzF7kipTCscBdgwJ3IiJOFmjppSgjCX88rx6KZ621cO+1ZoX8O/4IRSvtnkiikN9nGqcd03AHZr2pDStlq5t6yPEnkuP3hfVxT5mfxdtOnsM/69r462sNYX3s42qbRODO7YYrfgBuLzz0MQiORHY2ERERh3txZztPbGvmkmUFnLog2+5x7FW1Fvpa4E03g9tj9zQitlDgTkREREREBLAsi+rGHhYXpOGJx7sT9zwPnkQoXmX3JJNSlp9G79AoDV2Ddo8yfemF4M9Xw52IiIMFQxZ1Lb0s0jrZ+NS5D353DQx0wg3/B/NX2z2RRKnUsYa7vmEHBe6SMma84S4Usqht6gnrOtnDfeHScrJSE7nz0So6+4cj8hxHaKs1Z/aiiX18Xjms/jS0bIMNP4jcXCIiIg4XClnc+WgViR43X7ys3O5x7PfS3eBNhpXvtHsSEdsocCciIiIiIgI0dw9xoG+YpUWRuRgT1UJB2PuiCdslJNs9zaSUjgUWah2zVnYlNFeZ1hsREXGc/R39DI2GKNU62fjT2wq/uxq698PVP4XFl9o9kUSxtLGGO8eslAWzUnaoa0afcu+BfgZGgiwuiEzIeVZqIrdfvoS23mG+9XhNRJ7jCG0BSJ8NiZNoZV/9KchZDM9+G9rqIjebiIiIg62p3M/W+m7ec+a8+NyOcrj6jVD/Kpx4PaRk2T2NiG0UuBMREREREQGqG03bwpLCOAzcNW2B4Z6YWycLsHgscBdwSuCucAWERqClyu5JREQkAgLNvQCU5StwNy2jw7B9nQmxxYLBLrNGtr0OLv0OnPQ2uyeSKHew4c5pK2UHuyEUmrGnrGkyrxHKIxS4A7hmZTFnLMzmjy/v49XdByL2PID5s2uvm9g62cN5fWa1bHAIHvkEWFZk5hMREXGovqFRvvPEdrJSE/nImyfYMutkL/3cnKfcau8cIjZT4E5ERERERASoGgvcLS2MwxVve543ZwwG7sYDC9ubem2eJEyKVpizYZO9c4iISEQEWsz3q0V5cfjzRjgMdsE//wd+cCL88e1w92rTrhDNhvvhD2+Hps1w3m1w6gfsnkhigN/nBaDXSYG7pAzAguGZ+7m9psm8xovUSlkAl8vFHVcvJ9Hj5rYHtzISjGCgsLseRvohp2zyn1tyOpz8Ptj9HGz6XfhnExERcbC7n91BS88Qn7ywjPSkBLvHsVfnXti6BkrOhILldk8jYisF7kRERERERDANdy4XLI7gxZiotWcDuNww51S7J5m0zJREctN8BFoc1HAH0PCavXOIiEhEjH+/WqSVspPTtR+euA2+vwz+/lXz9065FQY64DeXweb77J3vWEaH4b53w97n4bT/hLM/a/dEEiP8SQ4M3PnGXmcNdc/YU25v6sHtgtIIt4ouzPXz4fMWsr25h188tzNyT9QeMOdkG+7GXfBfkFYIT94OPc3hmkpERMTRGjoH+PlzOynN8/OON82xexz7rf+W2c5xzufsnkTEdgrciYiIiIiIYBruSrJSDrZJxA3LMg13hSeBLzbbdsry/QSaewmFHLAaKb0Q/PnQqMCdiIgT1bX0kp/uIyM5zlsRJqppCzzwAfjBSfDCjyBzDlz9U/j4Zrjs2/DexyB5FjxwM/ztqxAK2j3xIaEgrP0gBJ6EFTfBRXeCy2X3VBIjkhM8uF3QO+igwF1ShjkHZy5wV9PUw/ycVJISPBF/rg+du5AFOan88KkA+w70R+ZJ2qYZuEvKgMu+Y9pC1+kiuYiIyER8+/EaBkdC3Hb5EryeOI/XtG6H1/8A88+GBefaPY2I7eL8K4KIiIiIiAgMDAfZ3dbHksI4bLdr3Q4DB8wagBhVmpfGwEiQ+s4Bu0cJj8IV0FwFo0N2TyIiImEUClkEmnsp1TrZ47MsqHsK7rkafnYWbP6zWXt/0xr40POw4kbwJpqPLV4FH1gPxSfDhv+BP77DBEnsZlnw2GfMqqXyt8AVPwS33oqXiXO5XKT6vPQNOylwN7MNdwPDQXa390V0nezhfF4Pd16znMGRELev3YplReBmoLZac05lpey4JVeYr0tVa2H7uvDMJSIi4lCv7etk7WsNnFOWy7mL8+wex37P3AVWCM7/qt2TiEQFvcoXEREREZG4t725h5AFS+MxcLdngzlLzrB3jmlYXGCCC7XNDlkrW7TCrGZoqbJ7EhERCaP6zgEGRoJaJ3sswRF4/U8mZHfvtbDrH7D8rfCBZ+HdD0PpBUdviEsrgPc8CifdCIEn4JcXQPuOmZ//cE/fAa/+GuafA9f9Cjxx1qAsYeH3eekdiqLWxukaXyk7Q6HY2uYeLAvKC2Yu5HzGwhyurSjm2dpWHt3SGP4naAtAot+shZ2Oy75r/n08+ukZbRwUERGJJZZlcccjVXjcLm6/fInd49ivYRNU/RUWXw6zT7Z7GpGooMCdiIiIiIjEvaoGc5EhLhvu9jxvzrmn2zvHNJTlm+DCdscE7laas0FrZUVEnKSupReAsnw13P2LwW7Y8EOzNvbBW+HALjjtw/CxTfDWX5kg+htJSIKrfwIXfwPa6+AX58GOpyM/+9Fs+CE89z3Tuvf2P5jZRKbA7/PSOzhi9xjhM95wN0MBr+1N5rXB4hkM3AHcdtkSMlMS+NrDVXSH+99fWwArexHDQYuB4SB9Q1NsQEwvhAv+C7rrTUBYREREjvDI5kY27ungxlPmUqrXcPDUHYAL3ny73ZOIRA3dWiciIiIiInGvunEscFcUZ4E7yzKBu7xlkJJl9zRTtmhsNV+gudfmScKkcCxY0KjAnYiIkwRaTPijNF8NdwB01cNLP4ONvzUrJv35ZjXRye+F5FmTfzyXC07/T8hdDPe9D+69zgTwTv3g0ZvxImHj/8Hfvgy5S+Cm+8Cnf9cydak+L01dg3aPET5JGeYcmpmGu+ome26qyvb7+NKlS/jcms3c9IuXKMhIIhiyGA1ZBEMhRoPWwV+PHvbrQx9j/v7BjwmaXyeF+nktoYG1nfP55O2HVsF++NyFfO6S8skPuuq9sOU+ePkXcML1MOeUMP4piIiIxLbBkSD/b10NaUlePnnhNFa5O8Xuf8KOp+DEt0H+UrunEYkaCtyJiIiIiEjcq27sJj3JS1FGnDWQdOyCngYov9zuSaYlIzmBgvQk56yUTS80oYOGTXZPIiIiYTQeDF+UG+chrKat8MKPTNAjNAq55XDGN03gw+ub/uMvugBueRr++HZ4/Avm+d7y/fA89vFsWwuPfAIyS+CdD8b0zQwSHdKSvNS1TLHBLBr5Zr7hLjXRQ3Fm8ow83+GuP3n2wbWyVY3deN0uvG4XHrcLr8dtzvFfj50JHjdJCS4SPON/f+zjxn69cOQANIA3t4wrc4vwelxsqGvjDy/v5eMXlOLzeiY3pNsNV/wQfnYmPPQxuPUf4E2MzB+IiIhIjPn1hl3Udw5w22VLyEqN8++PlgVPfR3cXjj3C3ZPIxJVFLgTEREREZG4FgpZ1DT1sLw4HddMtZ9Ei/F1siVn2DtHGJTm+3l51wGCIQuP2wH/HgtXmFV4o0ORDwiIiMiMCLT0kuP3MSseL9hYFuxcD8//r2lGAJi3Gs74KCy60AQ/wilnEdzyFNz/fnjtXmirhbfdC2n54X2ecXVPwZqbITUX3rXWhOdFpik10Uvf8CihkIXbCT/fjjfcDUa+4c6yLKobu1lckGbLn53L5eLHN1XwI8sK32vMzbvhAbji/HO4YtlKAH727A7+37oanqlp5ZLlBZN/zNwyWP0ZWP8N2PADOOez4ZlVREQkhrX2DPGTZ3ZQkp3Cu84osXsc+wWehH0vwcnvh6wFdk8jElXC/E6GiIiIiIhIbNnX0U/v0OiMrxqKCg4K3C3OT2NoNMS+A/12jxIeRSsgNAItVXZPIiIiYWBZFnUtvZTmxVm7XXAENv8F7l4Nv7sadj4Dy66FW56B9zwCZReHP2w3LikDbvwznPlx2P8y/OK8yLTH7n0J/vwfkJgK71yri1ASNqk+L5YF/SNBu0cJj/GGu6HIN9y19gzR0T/C4gJ7X+OF9Yautlpz5hxaa3fNymLcLlhTuX/qj3vWJ03T6D++DW2BaQ4pIiIS+77/t+30Do3yxUuXTL5B1mlCIXjqDvAmwdkK5ov8OwXuREREREQkrlU3mgs+8Rm42wBZCyFtCm0IUaYsPw2A7U5ZK1u4wpwNr9k7h4iIhEVj1yC9Q6OU5sdJ4G6oB174MfxwJTxwC7TvgFM/CB/bBNf/BoorZmYOtwcu/Dpc83Poa4NfXwJb7g/f4zdthT9cD7jgpvshf2n4HlviXlqSWVDUN+SQtbJJM7dStqbJvCZYUpgW8eeaMW0BwPUvod789CTOXJTDMzUtHOgbntrjehPNatngCDz8cXNhXUREJE5VN3bz51f2cer8LC5eFqF27Fiy7QFo3gKnfEAt3iJHocCdiIiIiDjDrudmZDWNOE9Vo7kYszTeAndd9dCx2xHtdsDBAEPAKYG7orHAXaMCdyIiThBo6QWgNN9B4Y/j+d218MSXzGr0N38ZPrkNLv0WzJpnzzwnvQ3euw6SMmHN++Gpr08/VNK+A353DYwMwNt/D3PeFJ5ZRcak+kyjSs+gQwJ3Xp9pR5mBhruaJvMci530NbctAJlzISH5X/72dRWzGQ1ZPPx6w9Qfe+6p8Kb3mxuyNt0zzUFFRERik2VZ3PloFRbw5bcsDW9TbSwKjsAzd5mW4rM+afc0IlFJgTsRERERiX2t2+H/3mJaNEQmqaqhG6/bFT+NM+P2vmDOkjPtnSNMxgMMtc29Nk8SJmmF4M9Xw52IiEOMB8LjYqVsX7tZ4Vp6MXxiC5z9GUjJsnsqmL0KPrAeilfBc9+DP9049aat7gazIre/Da77FSw8L5yTigDg9yUADmq4A3PBdgYb7sptXikbNqEgtNf9yzrZcRctyyc10TO9tbIA538V0orgya9AT9P0HktERCQGPVnVzIa6dq6rmM3y4gy7x7Hfa7+HAzvhjI9Gx+s5kSikwJ2IiIiIxL6GTeZsq7V3DolJ1Y3dLMz14/N67B5lZu3ZYE6HNNz5fV6KM5OpdUrDnctl1so2bzPtQCIiEtPqxhvu4iFw11BpzkUXQEKSvbP8u/RCeM9jcOLboXYd/OpCcxFpMvoPmGa7zr1mDePSKyMzq8Q9/1jDnaMCd0npM9JMX9PYQ2FGEhkpCRF/rhnRtQ+CQ5BTesRvpSR6ueyEQjbv75pe23dSOlz+XRjqgnWfm8awIiIisadvaJSvPbSNNJ+Xz1282O5x7DcyCOu/BSk5cNqH7J5GJGopcCciIiIisa9pizk799o7h8ScroER6jsHWFrkkOaDydjzPKTPNmuJHKIs38/O1j5Gg9NcERctilZAaARaquyeREREpinQ0ktWaiLZfp/do0Re/VjgrrjC3jmOJSEJrvkZXHSnuWHn5+fBzvUT+9yhHrj3OmitgYvugop3RnRUiW/+JC8APU4K3PnSI75SdjQYoq6ll/ICh62ThaMG7gCurZgNwAOb6qf3POWXw5IroeqvUPPY9B5LREQkhvzgqQANXYN89pLF5KVH2U1Ddnjll9DTAKs/DT4H/UwlEmYK3ImIiIjEuWDIIhiy7B5jehS4kymqbjQXe5YUxtkbB31t5kJxyRmmSc0hyvLTGA6G2N3eb/co4VG4wpxaKysiEtMsy6K2uYdF8dBuB1C/EdwJkL/c7kmOzeUyq5Fu/AtYFvzuWnjpbvO/j2VkEP74DtPgd/Zn4YyPzNy8EpdSE03gzlkNdxkRXym7q62P4WCI8kIH3VQ13uZ/lJWyAKfOz6I4M5kHK+un//7OZd8BXwY8+ukZWf8rIiJit5qmbn71z12cODuDm04tsXsc+w12w3PfMzdqn/w+u6cRiWoK3ImIiIjEua8+tJWL/vtZrONdXIpmlnUocNfXCsN99s4jMeVQ4M5BF2MmYu8L5nTIOtlxpfkmODmtVUrRpGgscNeowJ2ISCxr6RmiZ3A0PtbJWpYJpOUvi751skdTeiHc8hRkzTcrFB/+GIwOH/lxwVG4/32w+zl40y1w3m0zP6vEHb/PBO56HRW4S4fhHggFI/YUNU3mtYAjG+6yj95w53a7uLaimKbuQV7Y0T6950orgAu/Zlptnvr69B5LREQkyoVCFrc9uBXLsrjr6hPwuJ1zY/KUvfhTGDgA534+Nl7TidhIgTsRERGROGZZFk9sa2ZHax/dgzH6Jn53g3kBOK5zn32zSMyJ28DdnufNWXKmvXOEWVm+CTLUNvfaPEmYpBVCap4a7kREYlxg7PtSWb6Dwh/H0rXP3ARTvMruSSYupxRufgoWng+V98A9V0Jv66HfD4XgoY/A9kfhhOvh0m87qiFYotf4SllHBe58Y6+7IrhWtqbJPHZ5gYNe47UFTOucP++YH3LNymIAHqjcP/3nq3g3zD3DrJPb9/L0H09ERCRK/eXVfWzc08G7Tp/HCbMz7B7Hfn3t8Pz/QtZCOOlGu6cRiXoK3ImIiIjEsf0dA7T2DAFQ3zFg8zRT1LzVnEUV5uzcY98sEnOqG3vIS/OR4/fZPcrM2rMBUnLMBWYHGV/VV9vikIY7l8u03LVUHb1tR0REYkJg7PtSXDTc1Veas7jC3jkmKzkTbroPTv+IaQL++bnQuNk09j3xRXj9j1B2CVz9U3DrLXWZGanjDXexenPc0SSNXciO4KrS7U09JHhcLMhNjdhzzLi2WvPa7Thh3wW5flbOzWTd1qbphzTdbrjiB+BJgIc+CiMx+n6RiIjIcbT3DvHNdTXkpfn41EVHX9sedzb8t2kjfvNt4PHaPY1I1NO7AyIiIiJxrHJvx8H/Xd8Zo2+gNm02Z/nl5uzca98sElNGgyG2N/fEX7vdYJdZw1xyhuPaWVISvczNSnHOSlmAopUQHDahOxERiUmBFtNwtyg/HgJ3G80ZSw1349weuPguuPpn0NcCv7rIrJF96WemFfj635rwicgMSRsL3PWp4W5Sqht7WJjrJ8HjkMtfA53ma9IEbpa6rmI2AyNBHt/aNP3nzS2Dsz8LrTXwnVK4772w9QEYctBrLRERiWvfeKyGroERvnLFUtKT9HM+3Q3w8i+g4ARYeo3d04jEBIe84hARERGRqajccyhw1xCzgbst4HLD4kvNr9VwJxO0s62P4dFQ/AXu9r0MVshx62THleX72dlq/t06QuEKczZssncOERGZsrrmXjKSE8iNh0bdhk2QkAo5MdwQseId8J7HICkdtj0AhSfBO/4ECcl2TyZxZrzhrsdJgbsIN9x1D45Q3zlAeYGDVni315lzAoG7t5xYSKLHHZ61sgBnfQou/ibklZuvh/e/F769EP7wdtj0e+g/EJ7nERERmWEv7mxnTeV+zi7L5fITCu0eJzo8+20YHYQ3f0Wt3iITpB5IERERkTi2cW8HXreL0ZAVww13WyB7EWSXAi7oUOBOJqa60VzkWVoUZ4G7PRvMOc+ZgbvS/DT+Xt3C7vY+yvIdcKGtaCxw1/iavXOIiMiUWJZFbUsPpXl+XA5rlj1CKGgCd0UrTVtcLJvzJvjAerNKtuI9JnwnMsNSEj24XA5ruEuKbMNdbZNpXyt30k1VbbXmnECQOTMlkfOX5PH4tibqOwcozpxmUNjjhdM/bP7qboCaR6H6YQg8CbXrwOWBeWfBkiug/C2QrsCCiIhEv+HRELev3Uqi183Xr1zm/NdpE9G+Azb9DuacBqUX2j2NSMxQNFVEREQkTvUPj1Ld2MOZi3JwuWJ0pexQDxzYBfnLwZsI6cVaKSsTVtUwFrgrdEAoazL2PG+aJfKW2j1JRJSNreurdcpa2bRCSM2DBgXuRERiUVvvMJ39I5TGwzrZtgAM90LxSrsnCY/0Ilj9aUjNtnsSiVMulwt/ope+oaDdo4TP+ErZwa6IPHz1WOBusZMa7toC5sx+44Y7MGtlLQvWbqoP7xzpRXDKLfDuh+CzdXDVT6D0Itj7Ijz2Gfh+OfzyAtjwAziwM7zPLSIiEka/eG4ndS29fOS8RczLSbV7nOiw/psQGoULvgoKIIpMmBruREREROLU6/u6CIYsTl+YTXVjN/UdMRi4a64CLCg4wfzbowoEAAAgAElEQVQ6cy60Vts6ksSOqsZufF4387Lj6I2V4X6or4RF58d+88wxlOaZi2u1zb02TxImLpdpudu5HkaHTbhYRERiRqDFhD/Gvz85Wv1GcxavsncOEQfxJ3kdtlJ2PHAXmYa77U3mcZcUOKzhzuWBrPkT+vBzFueSlZrImsr9fPjchZFp7UnJgpU3mb+GeiDwN6h5BGqfgP2vwN++Ym6MXHKF+StvqS7ei4hIVNjb3s8PnwqwICeVW89ZYPc40aFpK2y5HxZdACVn2D2NSExRw52IiIhInKrc2wHAqpJZFM9KpiEWG+6aNpuz4ERzziqBgY6IvXkvzlLd2EN5QRpeTxy9LNr/CoRGHP3myaI8P24XBJzScAdQuAKCw9BSZfckIiIySXUtJgAeFw13DZXmLKqwdw4RB0n1eR22UjbDnEORabiraewhIzmB/HRfRB7fFm0BmDUPvBP7Z0rwuLnypCJ2tvbx+v7I/Dn/C18aLL8W3vpr+OwOuPEvsPI/zAra9d+En54B/1thQnj7XoFQKPIziYiIHIVlWXz1oa0MjYa48+rl+LzOvBl50p65C7DgzV+2exKRmBNHV5ZERERE5HAb93SQ4HFxQnEGRZnJtPQMMTQaY6tqmrea8/CGO4CuffbMIzGjpWeQtt4hlhQ6qPlgIvY8b86SM+2dI4KSEjyUZKc6Z6UsmIY7gEatlRURiTWBscbVuGm4S8k59DO5iExbqs9L76CDAne+yDXcWZbF9iZzU1VEWt3sEBw161lzJrZOdtx1FbMBWLNxfySmOraEJCi7GK76MXwmAO9+GE75AIwMmlWzv7oA/nspPPoZ2Pms+ecTERGZIU9sa+KZ7a1cs7KYMxbl2D1OdNj3Mmx/DJZefej9RxGZMAXuREREROKQZVlU7u1gaVEGSQkeZmcmA9DUNWjzZJPUtAVScyEt3/x6/OJexx77ZpKYUN1owljxF7jbAAkpUHiS3ZNEVGmen93t/bEXIj6WopXmbFDgTkQk1gRaekjzeZ3VtnQ0o0NmFVFxhdYGioRRmmMb7sIfuKvvHKBnaJTyAgcFnDv3mIbySQbulhenU5bv5+HNDfa9JvJ4Yf7ZcNl34JPb4Oan4cxPQEIyvPILuOdK+O4iWPufsONpe2YUEZG40Ts0yn89VEV6kpcvXbbE7nGig2XBU18HlxvOu83uaURikgJ3IiIiInFoZ1sfnf0jrJo7C4CiscBdfUcMrZUNjkLztkPtdgCZJebs3GvPTBIzqhvNBZ64CtyNDpuVsnNOAU+C3dNEVFl+GsGQxc7WPrtHCY+0QkjNg4ZNdk8iIiKTFGjuZVG+3zltS8fStNWEQopX2T2JiKOk+jz0Do9iWZbdo4SHbywMNxj+Vafbm8xNVeVOeo3XVmvOnLJJfZrL5eLaitl09o/wTE1rBAabJLcbZq+CC78GH62ED70A534J0mfDa/fC766BTb+3e0oREXGw//5bLU3dg3zuknJy0xx+M9RE7XwGdj8HK26E3Mn9rCEihgJ3IiIiInFo454OAFaVmMBd8XjgrjOGAncHdsDo4L8F7sYa7jrVcCfHNx64Ky90UPvBG2nYZP4/4+B1suNK8/0Azlkr63KZtQ4tVSY4KSIiMaG9d4j2vmFK8/x2jxJ5DZXmLKqwdw4Rh/H7ErAs6B92SHOzJ8E0bkdgpWzNeODOSQ13bQFzZk+u4Q7g6hXFuF2wpnKG18q+EZcL8pfCuZ+HD/0TPrIR0ovh0U+b8LaIiEiYba3v4jcbdrFiTiY3njLX7nGiw3i7nScRzvm83dOIxCwF7kRERETiUOVY4K6iJBM4rOEulgJ3TVvMWXDiob+XXgwujxru5A1VNXQzJyuZ9CRnN739iz0bzFlyhr1zzIDFYxfZAs29Nk8SRoUrIDhsQnciIhIT6lrM96GyfAeFP46lfqM5ixW4Ewknv88D4Ly1shFYKTseuHPU19wpNtwBFGQkceaiHJ6paeFAXxTftJOzCK7/rWlJ/cu7IhLGFBGR+BUKWdy+1gS677pmOW63w5vHJ6rmEXNz9snvO1RiICKTpsCdiIiISBzauKeDoowkCjNM0K54ljkbYjFwl7/80N/zeCGjWA13clyDI0F2tvWxpMBBq4YmYs/z5q7FOFj1Nj8nFY/b5ZyGOzANdwCNr9k7h4iITFhgLHC3KB4a7uorzYWa1By7JxFxFH+SF4AeJwXufOmRabhr7KYkO4VUnzfsj22btgAkZ0Fq9pQ+/bqK2YyGLB5+vSHMg4XZnFPgojvNJoOHPmpad0RERMLgj6/s5bV9nbz3zPksK8qwe5zoEArC03dCQiqs/rTd04jENAXuREREROJM18AIgZZeKsbWyQKkJ3nx+7yx13DnTYLsRf/69zNLoEMNd3JsgeZegiGLpUVxFLgLBWHviyZsl5Bs9zQR5/N6mJed4qzAXeFY4K5BgTsRkVgx3nBX6qS2paMZ7DYtTHEQ6heZaePhMWc13KXDYFdYH3Jo1NxUtdhpX2/bA5Az+XWy4y5alk9qoif61soezakfhKVXQdVaeOluu6cREREHaO0Z4lvraihIT+KTF06+LdaxNv8FWmvgtA+BP8/uaURimgJ3IiIiInFm016zTnbVYYE7l8tFcWYy9R0xFrjLW2pa7Q6XWQJDXTDQac9cEvWqGs3FnSWFcRS4a9oCwz1xsU52XFl+GnsO9DM4ErR7lPBIL4LUXDXciYjEkEBLD6mJHooykuweJbIaXwMsBe5EIsA/FrjrHXRQ4M6XHvaVsnUt5qaqcie9xutrh/72aQXuUhK9XHZCIZv3dxGI9puRXC648keQtRCevA32vWL3RCIiEuO+8Vg13YOjfPWKpQd/pop7o8Ow/huQlAlnfNTuaURingJ3IiIiInGmcs+RgTuAoswkGroGCYViYHVHTzP0tUDB8iN/L3OuObVWVo6hutFcaFjqpIsxb2TP8+aMo8BdaX4alnWoXSjmuVym5a55m3lzTEREol5tcy+L8vy4XC67R4ms+o3mLKqwdw4RBzoYuHNaw91IPwRHwvaQNWOv8coLHNRw1x4wZ870GnmurZgNwAOb6qc7UeQlpcMN94DbC/e9x4QORUREpuD5ujYe3FTPeYtzuWR5gd3jRI/K/4POvXDWJyA50+5pRGKeAnciIiIicWbj3g6SEtxHtHsVz0pmeDREW9+QTZNNQvMWcxaceOTvzSoxZ6fWysrRVTV2k+bzMnuW81erHrRnA7jcMOdUuyeZMWX5fsC0CzlG0UoIDkNLld2TiIjIG+jsH6a1Z4hFeQ4KfxxLfaX5OaPwJLsnEXGcVEcG7jLMORS+n9O3NzswcNc2FrjLnnrDHcCp87Mozkzmwcp6grFwg2XBcrj8e9C9Hx64BUIhuycSEZEYMzQa5Pa1W/F53Xz9quXOvwFqoob74Nlvgz8fTrnV7mlEHEGBOxEREZE4EgxZvLa3kxNnZ5Lg+dcfBYszUwBo6By0Y7TJaRoP3J1w5O8dbLhT4E6OZFkW1Y3dLClMj583WyzLNNwVngQ+B12AegOL880/a22zQxruAIpWmFNrZUVEot54w+p4ANzR6ishtxx8cfDPKjLD0sYCd31OCtz5xm7+G+wK20NWN3aTlOCmJDs1bI9pu7Zac06z4c7tdnFtRTFN3YO8sCNGGuNW/of5a8dT8Nz37J5GRERizN3P7mRnWx8fO7+UOVkpdo8TPV6622wNOvuzkKg/F5FwUOBOREREJI5sb+qhbzh4xDpZMCtlAeo7BmZ6rMlr2mrO/GVH/t544K5DK2XlSPs7BugZHGVJYfwEz2jdDgMHoORMuyeZUfNyUknwuKhtclDDXeFY4K5BgTsRkWgXGAvclTo9cNfTbFqIirVOViQSxhvuepwUuEsKf+Bue1MPZflpeNwOuqmqLQDuhEMt/tNwzcpiAB6o3D/tx5oxl30X8pfDM3fBjmfsnkZERGLE7rY+fvRMHYvy/NyyeoHd40SPgU7Y8D/m2knFu+2eRsQxFLgTERERiSMb93YAsGrukYG78fWaDZ2xELjbArPmH72tK63QvCmthjs5iurGboAjVio72p4N5oyzwF2Cx838nFRqnbRSNr0IUnPVcCciEgMCYw2rpU5fKdtQac4iBe5EIsGf5MSGu/GVst1hebgDfcO09AwdbLh2jPYAZM0HT8K0H2pBrp+VczNZt7Updv5bSkiGG+6BRD+suRm6G+yeSEREopxlWXz5r1sZHg1x59XLSfQqCnPQ8z80Nzuc+yXwJto9jYhj6KuMiIiISByp3GMCdyvnZh7xe0WZJnBXH+2Bu+F+88bz0dbJArg9kDEbOtVwJ0eqbjThq6VF8RS4e96cc0+zdw4blOanse/AAP3DMXJR6Y24XKblrnkbjA7bPY2IiBxHoKWHpAQ3xWM/YztW/VjgrniVvXOIOJT/4ErZoM2ThFHSWOBuMDyBu5om8zjlTrqpanQYDuya9jrZw11bMZuBkSDrtjaF7TEjLnshXP1j6G+D+98HwRG7JxIRkSj26JZGngu0cV3FbE5bkG33ONGjtwVe/CnklsOJN9g9jYijKHAnIiIiEkcq93YwPyeVbL/viN/LS0vC63ZFf+CupRqsEBSceOyPyZxrGu4sa+bmkphQ1diF2wVlTms/OBbLMoG7vGWQkmX3NDOubKxVqG5srZ8jFK2A4DC0Vts9iYiIHEeguZdFeX7cTlpveDT1G8Hjg/xldk8i4kjjgbueQYfcQAKHVsqGqeGuZuymqvICB73G69gFVhBySsP2kFecWEiixx1ba2UBll4Fp/0n7H0Bnvqa3dOIiEiU6h4c4esPV5GRnMCXLiu3e5zo8tz3YKQf3ny7KSsQkbBR4E5EREQkTrT2DLGnvZ+Ko6yTBfC4XRRkJFHfEeWBu+Yt5ixYfuyPmVUCw70w0DEzM0nMqG7sYUGun6SEOHlzoWMX9DRAyRl2T2KLxQV+AGqbHRS4K1xhzoZN9s4hIiLH1D04QlP3oPPXyVqWWSlbeGJYVh6KyJFSEj24XE5bKTsWuAtTw932JgcG7toC5swOX+AuMyWR85fk8cLO9ui/0fLfXfg1mH0KPP+/UP2I3dOIiEgU+v6TtbT0DPHFS8uPWjYQtzr3wqu/hqIKKH+L3dOIOI4CdyIiIiJxonKvCZ+tKjl64A6gODOZhq4of+O1aTxwd4yVsmAa7gA6dkd8HIkdPYMj7D3Qz1InrRp6I+PrZOM0cFc61mRY29xj8yRhVLTSnA2v2TuHiIgc03izamm+3+ZJIqxjl7nBpajC7klEHMvlcpGa6KXXSYG78Ya7wa6wPFxNUze5aT5nXVxvqzVnGFfKglkra1mwdlN9WB834jwJcP1vICUb1n7YrNsVEREZs2V/F/e8sJtVJbO44eQ5do8TXdZ/y2zKOP8r4HJ4+7qIDRS4ExEREYkTlXtM4K6iJPOYH1OcmUxn/0h03z3ftAWSZ0F68bE/JnOeOTv3zshIEhvGmw+WKHAXN0qyUkj0uJ0VuEsvgtRcaFTgTkQkWtWNNas6vuGuvtKcxavsnUPE4fw+hwXufOFbKRsMWdQ29zqr3Q4ONdzlLArrw567OJes1ETWVO7HsqywPnbEZcyGa39h/rv5y7tgZNDuiUREJAoEQxa3rd2Cy+XizquX43YrVHZQ63Z4/Q8wbzUsONfuaUQcSYE7ERERkThRubeDNJ/3uBf+imclA9AQretFQiFo3mba7Y53R9Z4w13nnpmZS2JCVaO5oLOk0GEXY45n9z8hayGkFdg9iS28HjcLclMJOGmlrMtl1so2b4PRYbunERGRowi0mKB3aZ7DG+4OBu7UcCcSSak+j7MCd0kZ5gxDw93eA/0MjASdF7hrD5ibbJKPvaFgKhI8bq48qYidrX28vj88DYMzatH5cM7noWkzPP55u6cREZEo8PuX9rB5fxfvP2t+fN1kPRHP3AVWCM7/qtrtRCJEgTsRERGRODA8GuL1/V2smJuJ5zh3eRVlmsDd/mgN3HXsguFeyD/OOlk4LHCnhjs5pHoscLe0KE7efGnfYUKn88+2exJbleWnUd854KyLlEUrzDqI1mq7JxERkaMItPSS6HUzJyvF7lEiq6ESfBkm3C8iEeNPSojuFvrJ8o2F48LQcLe9yTzG4gIHvcazLLNSNszrZMddVzEbgDUb90fk8SPunM/BgvNg42/h9T/ZPY2IiNiopXuQ7zy+naKMJD5+fqnd40SXhk1Q9VdYfBnMeZPd04g4lgJ3IiIiInFgW0MXw6MhVpUc/+7o4rHAXX1HlAbumraYs+ANAnf+fPD4FLiTf1HV2EOOP5G8tCS7R5kZtU+Ys+xie+ew2eKxtouAk9bKFq4wZ8PMrpWt7xzgm+uqae8dmtHnFRGJNYHmXhbm+o97o0vMC46a70NFK8Ctt5hFIsnv89A76KDAndsDiWlhabirbjQ/4zuq4a6v1fzZ5EQmOLC8OJ2yfD8Pb25gaDQYkeeIKLcHrvslpBXBI5+E5iq7JxIREZvc8Wg1PUOj/NeVy0j1ee0eJ7o8dQfggjffbvckIo6md0NERERE4sDGPR0AVMw9fuBuvOEualfKTjRw53ZD5hzo0EpZMYIhi+1N3fG1WiDwhAmexnnD3fg6v1onBe6KxgN3m2bsKXe19XH9T5/n7md38usNu2bseUVEYk3v0Cj1nQPOXyfbWgOjA1C8yu5JRBzP7/PSNzyKZVl2jxI+SekwOP2Gu5qmbjxuF4uc9DW3LWDO7MgE7lwuF9dWzKazf4Rnaloj8hwRl5oD1//GtH7/5V0w5KDXeiIiMiHPBVp5+PUGLliSz0XLCuweJ7rs/ifseApOuB7yl9k9jYijKXAnIiIiEgc27e3E5YIVczOP+3EHG+6iNXDXvBXcCRNbrZJZYhrunHRRQqZsV1sfgyOh+AncDfXA7g0wfzUkpto9ja3K8k3bRW1zr82ThFF6MaTkQOPMNNzVNHVz/c9eoLlniNRED49vbZqR5xURiUU7Wsz3m7J8B4U/jqZ+ozmLK+ydQyQOpPq8hCwYGInBNrJjScoI00rZHubnpJKU4AnDUFGirdacEVopC3D1imJcLlhTGaNrZQHmngYXfh3aA/Dwx/Xej4hIHBkcCfLltVtJTvDwX1cutXuc6DLYDY99FtxeOPcLdk8j4ngK3ImIiIg4nGVZvLrnAIvz00hPSjjuxyYneshKTYzuhru8cvAmvvHHZs41rRt9MXrHtoRVdaO5mLM0XgJ3O9dDaARK43udLMCcrBR8XrezGu5cLihaCc3bYHQ4ok/12r5O3nb3i3QNDPPjGyu4amUxO1r7qGtx0J+niEgYBcYCd4vyHLTe8GgaKs2phjuRiEsbW5HmqLWyvuk33PUPj7LnQD+LnbROFg413EVopSxAQUYSZy3K4ZmaFg70Rfb1RESd9mFYcgVsXQOv/NLuaUREZIb8dP0Odrf38/ELSpk9K8XucaLH6DD85Z3QUgXn3QbZC+2eSMTxFLgTERERcbiGrkGau4eoKDn+OtlxxZnJ1HdEYeCurx2666HgxIl9fOZcc3bujdxMEjOqxgJ3cdNwV/uEOUsvtHeOKDC+YirgpIY7MGtlg8PQWh2xp3hxZzs3/eJFhkaD/PLdb+KS5QVcMramQy13IiJHFxgLJJfGQ8OdvwDSi+yeRMTxUscDd0MOCtwlpU+74a62uRfLgiVOC9y1B8DjO/SeRoRcVzGb0ZDFw683RPR5Isrlgqt+DLPmw+NfhP0b7Z5IREQibGdrLz9dv4OyfD/vP2u+3eNED8uChz5qbsI++X1w1iftnkgkLihwJyIiIuJwG/d0AFAxd2KBu6LMJJq6BxkNhiI51uQ1bzFnwQkT+/hZJebs3BOZeSSmVDd2k+hxsyA3DtarWhYE/mZWEGXpjSeAxflpNHUP0jUwYvco4VO4wpwNkVkru357C+/+9cu4XC7ued+pnFOWC8DpC7NJT/Ly+DYF7kREjqauuZcEj4uSLAc3LYwMQHOV2u1EZogjA3e+dBgdhNGhKT9EzdhNVYsLHHZTVVutaaRxR3ZN7kXL8klN9MT2Wlkw64lvuAdcbrjv3dB/wO6JREQkQizL4st/3cpwMMRd15xAgkdRl4OevhM2/wnKLoVLv2NC6SIScfoqJCIiIuJwlWOBu1UTbrhLIWRBU/dgJMeavKat5sxfPrGPzxwL3HUocCcmcFdW4I+PN2KaNkNvE5ReZPckUaM037ReBJy0VrZoLHDXGP7A3botjdxyz6ukJHr4wy2ncsr8rIO/l+Bxc8HSfLbWd7PvQH/Yn1tEJNbVtvSwIMeP18k/czRuBisIxSvtnkQkLqQlOTBwlzQWkpvGWtmaJvOzfbmTGu5GBs17GBFcJzsuJdHLpScUsnl/V+y/Tio8ES7/LnTtgwdvhVCU3UAqIiJh8dDrDWyoa+dtJ8/hTfOy3vgT4sWrv4bnvmtuiHrrr8DjtXsikbjh4Hd+RERERASgcm8HWamJzMueWMtG8axkABo6oy1wN95wN8nAnVbKxr323iGau4dY4rTmg2OpfdKcZRfbO0cUKRtb61frpLWy6cWQkhP2hrv7N+7nP/9QSWZKIn++9XROnJ15xMeMr5V9IkZb7rY1dPH41kZCIcvuUUTEYfqHR9nfMcAip6+Tbag0pxruRGZEauJY4G7QSYG7DHNOY61sTVM3fp+X2WPvYTjCgZ2ABdmRD9yBWSsL8MCm+hl5voha+U5YcRMEnoQN/233NCIiEmaDI0HueKSaWSkJfOHScrvHiR7bH4dHP23Wq7/jz5AYB9tdRKKIAnciIiIiDtY/PMq2hm4q5s7CNcEa8eLMJADqO6OsuahpC2TMheSJNfWRmgPeZK2UFaobzd36SwrjJHAXeMKsaJp7ut2TRI2ysYa72lhvbjicy2Va7pq3wuhwWB7ynhd285n7XqcwI5n7bj394J/bvzu7LJfkBA+Pb429wJ1lWXzkD5v44L2V3PjLF9nV1mf3SCLiIDtb+7AsKMtzUNvS0dRvNGeRGu5EZoJ/rOGub9hBgTvfeMNd15Q+3bIstjf1sLggbcLvdcSEtlpz5pTNyNOdOj+L4sxk1m6qJxjrN6O4XHDZdyFvmVmrt+sfdk8kIiJhtHFPB229Q9y8egGzUhPtHic67N8I97/XXC/5jzXgz7V7IpG4o8CdiIiIiINt3t9FMGRRUXJkQ9GxFGeaJryoargbHYK27RNvtwPzZmvmXDXcCdWNpjVhaVEcBO762mD/q7DwPPAk2D1N1CjOTCY5wUOgxUGBO4DCFRAchtbqaT/UT9bX8ZW/bmNBTir3ffB05uUc+47YpAQP55XnsnFvBy3Rtn78Dby+v4tdbX3My07hxZ0HuOR//sFP1+9gJKi1UyIyfePfZ0qd3nBXXwlZCyd+I4yITIvfN75SNmjzJGGUNL3AXUvPEB39I85aJwvQFjDnDKyUBXC7XVyzspjGrkFe2NE+I88ZUYkpcMM9kJAK978femLvBiERETm653e0AbC6NMfmSaLEgZ3whxvAsuDGv0D2QrsnEolLCtyJiIiIOFjl3g4AVs2d+MWworGGu/0dAxGZaUpaayA0CgUnTO7zZpVA5z4IKUgRz8YDd3GxUrbu74AFpVonezi320VZvt9ZK2XhULPQNNbKWpbFtx+v4duPb6e8II0/33o6RZlvvJbr4mUFWBY8WdU85ee2w19fM+uyfviOlfzl1tMpnpXMtx6v4aofbWBr/dQu+IqIjAuMfZ8pzXNw4G6gAw7sgOIKuycRiRsHA3dOWinrm95K2ZomE3B2XOCufSxwl71oxp7y2opiAB6o3D9jzxlROYvgqv+Fvha4/30QdND/b0RE4tiGunbSk7wsK8qwexT79bXBvdfBwAF4669h9sl2TyQStxS4ExEREXGwyj0deN0uTpw98Ya7rNREkhLcNHRGUeCuaYs5Jxu4y5wLwSHoja1AiIRXVWM3xZnJZKTEQeNb7RPmLL3Q3jmiUGl+Gq09Q3T0hWf9alQoWmHOxqkF7kIhi689XMVP1u9gxZxM/vyB08lN803oc99cnkeix80T22KnNWI0GOLh1xuZn5PKCcUZnDI/i8c+tpqPnLeI2uYervrxBr75WDUDww5qjxGRGRVo6cXrdlGSfeyW0JjXsMmcxavsnUMkjqSOBe76hhwUHDrYcDfFwN3YTVXlhQ67qaqtFtIKD/35zIAFuX5Wzs1k3dYm5/w3tuwaOPWDsGcDPH2H3dOIiMg0dQ+OsHl/J6ctyMbjdtAq+akY7oc/vt003F32HSi/zO6JROKaAnciIiIiDmVZFpV7O1lWlE5yomfCn+dyuSjKTKbeEYG7EnNqrWzcGhoNUtfSy5JChzUfHE1wFHY8BUUV4M+ze5qoUza23q+22UFrZdOLISVnSg13wZDF59Zs5rfP7+b0Bdnce/OpkwqlpiUlcFZpDi/saKezP4whxq56+Of/wKu/gZpHYd/LcGAXDE2/nfCFne209Q5x1YoiXC7zBm1SgofPXLyYhz96FsuL0rn7Hzu55Af/4Pm6tmk/n4jEn0BzD/NyUkn0Ovgt1/qN5ixSw53ITDm0UtYhYSiApOk13G0fa7gry3fQ6zzLMitlZ7Ddbty1FbMZGAmybmvs3Ezzhi68A4pPhg3/A9vX2T2NiIhMw8s7DxCy4IyF2XaPYq9QENbcDPtfgbM+CW+62e6JROKe1+4BRERERCQydrf3c6BvmCtPKpr05xZnJvPq7g4syzoYSrBV01bwpR8K0E1U5lxzdu6BuaeGfy6JenUtvYyGLJY6rfngaPa9BINdUKZ1skdTOnYxrrall1MXOOQNOpfLtNzteg6CI+CZWGBueDTEJ//8Go9uaeTN5Xn85KYKkhImHswed8myAp6uaeHv1S28ddXsSX/+UT15O2x74Oi/l5ACqTmQmgupeeZ/+/PGftVHryUAACAASURBVH3YX/48SJ4F7n/9Z1q7qQGAq1YUH/HQSwrTeeDDZ/KbDbv43pO13PjLl3jbyXP40mVL4qMdU0SmbXAkyN4D/Vy8rMDuUSKrfhO4PFB4ot2TiMQNf5IDA3e+6TXcVTf1mBbzZAf9nNbTBMO9kFM24099xYmF3PFwFQ9U7g/fz/V28ybC9b+Fu1fDg7fCrf+AWfPsnkpERKbg+R3tAJy5KMfmSWxkWbDuc7D9UTjhBnjzV+yeSERQ4E5ERETEsTbu6QBgVcmsSX9ucWYyz4200dk/wqzUxHCPNjmWZRru8pebcMlkHB64k7hU3WiaD5bEQ+AuoHWyxzPefhFwUsMdQOEKqPs7tFRPKPwwOBLkg/duZP32Vi4/sZD/vmHFlJuYLliaj/sBeHxrU3guzPW2QPXDMPd0OPsz0NsKfa3Q1wJ9beZ/97ZAdyM0bobQyLEfy+U27X+pueDPJZicw4nbBjgpK4f5ew9A6GTIW/Ivn+Jxu7h59QIuXlbAlx7cwp9f3cfT21v4+pXLuGR5QXQE0EUkau1s7SNkHQp4O1b9RshfCgnJdk8iEjdSxm6M6B10UODu4ErZrkl/6kgwRF1LD6tLc8M8lM3aas1pQ+AuMyWR85fk8fi2Juo7ByjOdMjX+Mw5cO0v4fdvhfvfDzf/ffLvK4mIiO2e39FGbpqPRXl+u0exz4YfwCu/hHmr4aofg9vBreoiMUSBOxERERGHmm7gDqC+c8D+wF3nXhjqmvw6WTh097JWysatqgbTmBAXgbvaJ03rV+FKuyeJSkUZSfh9XmetlAXTcAfQsOkNA3e9Q6O8/7ev8NKuA9xw8my+ee2JeNxTv+CUlZrIqfOz+Ueglb6hUVJ903yLYdPvTIju1A/CoguO/7GWBYOdJojX2zIWzGs9FMrrax0L6bVAfSWeoW7e7QL6gYf+z7SqfGILJGce8dBzslK4532nsKaynjseqeJDv6/koqX53HH1cvLTk6b3zygijhVoMd9fSp18Eai7AXqbYPEldk8iElfcbhd+n5e+YQcF7sYb7qawUnZXWx8jQYvyAocFnA8G7mZ+pSyYtbLrtjaxdlM9/3mePTNEROkFsOo9sPE30FAJxavsnkhERCahrXeImqYerlpRFL83Qm6+D/7+VchbCm+717S4ikhUUOBORERExKEq93RQmJFE0RTuTC46LHC3vDgj3KNNTvNWc04lcJc8CxL90KGGu3hV3dhNaqKHuVkpdo8SWZ17obUaVtykOxyPweVyUZrvp7a51+5RwqtwLHDX+Brw7mN+WGf/MO/+zSu8vq+T95wxj6+8ZSnuaYTtxl2yvIAXdrYfbMybslAQNv4W/PlQfvkbf7zLZb7GJ8+CnNI3/PAP/3YDm7fX8dD7FpNV/yys/wa8+itY/eljPLyLt66azTlluXzt4W08srmRF3a088XLlvD2N80Jy5+diDhLXYv5/lKa7+DAXf1GcxZV2DuHSBxK9XnocVLDXaLfNBJPoeGuutGE9BY7LXDXXmdOGxruAM4pyyUrNZE1lfv58LkLnRVqqHiXCdy9/mcF7kREYsyLO8062TMWZts8iU12/QPWfgjSiuCm+45646iI2EdXYkREREQcqHtwhNqWHirmTr7dDqB41ljgrmMgnGNNTdMWcxYsn/znulyQWaKGuzhlWRbVTd2UF6Y7PxwTeNKcpRfZO0eUK8tL40DfMG29Q3aPEj4Zs83q1IbXjvkhrT1DvP3nL/L6vk4++uZFfPWK8ITtAC5eVgDA49uapvdAdU+Zr9UV7wJPQhgmO6Srf4S/BbqYv6icrNLTYPWnIH02vPhTGDn+97ncNB8/urGCX77rZFJ9Xr704Bbe8YsX2dnqsOCmiExboLkXtwvm56TaPUrk1FeaU2EFkRnn93npG3JQ4M7tBl/alBrutjeZRlHHtZi31YI32fycaoNEr5srTypiZ2sfr++ffBAyqhWtNEHGrWsgOGL3NCIiMgkb6sYDdzk2T2KD5m3wp5sgIRn+437zHqCIRBUF7kREREQc6LW9nVgWVExhnSwcWinb0BklgTuXB3KXTO3zM+dC137TniRxpbFrkM7+EZYUOqz54GhqnwS3FxaeZ/ckUW28dchRa2VdLrNWtnnbUS8e1XcOcMPdL1DT1MMXLi3n0xctDmtbRUFGEivnZvJ0dTODI9P4Ovvqr0zLScWxW/qm6rGtjYwELa48qcj8DU8CnPFRs3b2td9P6DEuWJrP3z51Nu88rYSXdh3gkh88x0/W1zESDIV9XhGJTbUtPczLTsXn9dg9SuTUbzRhkNxyuycRiTuOC9wB+DJgcPKBu5qmHhI8LucFnNsCkL3I1sby6yrMhfw1G/fbNkNEuFxw4tugv83c6CMiIjHjhR1tzMlKZo7Tt5f8u656+P315kbRt90L+cvsnkhEjkKBOxEREREH2rinA4BVUwzcFWQk4XKZoIbtmjZD7mJISJra52fOhdAI/5+9O4+Pqr73P/6aJZnJvpKdBMgCBAi7CkRRUUFrxWqLVtvaqrd7e2v7s/d2vb3XLre3rXZf1a62xVotWq3gLhBESdiTkAVIyL4nkz2ZOb8/vjOIypLlzJyZk8/z8biPr49k5ns+6Q2TmXPe5/PB1axvXSLo+UYNFaYbPBbZ38aG1HiB7DXgNPnPOk0FqSp8WW3GsbLuEWireMuXT3YMsOWXezjRMcB9Ny7m4+tz/XL4TYvSGBh1U1LbMbUNeuqhajvkb4T42foWB2w70Ei43cqmxWlvfnHFByEiEUp+Au6JXbyOcYZx342L+dvH15CVEMH/PXuMzT/dzWGzdQARQkzayLibus5B8lJMPE7W41HdVDOWgc1udDVCzDjRTjsuswXunLFTGil7rMVFXkoMYTYTXd4aHYTeU5Ccb2gZizNjyU+J5qlDTYyMm+ymxaItaj30V2PrEEIIMWGNPUOc7Bxk7bwZ1t1uuFeF7foa4cafw7z1RlckhDgHE30iEUIIIYQQPmX13TjsVgqnOGIlzGYlNcZpfIe7oR4VxEidwjhZn4QctcpY2RnHF7gzfYe7EzthfAgKNhpdSdCbn6Z+F0zV4Q5U+AGg+c2xssdaXLzvV3to7h3i/i1L+eAlOX47vG+s7L8OT3GsbOnvAQ1W36VfUV7NvUPsPdHFVQtTiHGeMao2PAou/hh0n4Tyf0xqz9VzEnnms5fymSvzqGp1sflnu/j2MxUMjZrsoqQQYsJOdgzi9ming92m1FULI72QscLoSoSYkaLCVYc7TdOMLkU/jthJj5TtHRqjsWeIBWkme73trFFrcoGhZVgsFm5emUXP4BgvVbYbWovu4rMhpxgqn5lS0FMIIUTgldSoGzvX5iUZXEkAjY/C1g9A21HY8F9vBsaFEEFJAndCCCGEECbj9mgcqO+hKCuOcPvU3+5lJkQY3+Gu9aha05ZMfY/4bLV2102/HhFSypv7sFjeDFmZVvV2teZL4O5CUmIcxDrt5uxwB9C0H4CDp3q45dd76Bkc5ee3r+Am72gof5mTHMWCtBieq2hlfLIjVt1jUPYH9Vqde6XutT11sAlNg83LMt/5zYs+CmGRsOuHMMmL184wG1+4Zj7//GwxS7Li+fWrx9n4w1fZXTPFLn9CiJBW3aaC3L7R5abUWKbWTAncCWGEaIcdjwZDYyYK+Du9I2Un8T7Md+OM+QJ31Wo1uMMdwI3LMrFY4O9lJhsrC7D0FtUZvHyb0ZUIIYSYgD21nQCsyZ0hgTtNg22fUpNMVt0FxfcYXZEQ4gIkcCeEEEIIYTLVbS5cI+OsmOI4WZ/M+Ag6+kcZNvKEfsthtU4rcCcd7maqimYXc5OiiAw38dgzTYOqHZAwJyguzgQ7i8VCQWoMx1pd5uoOEpcFkUnQdIC9xzu5/cG9DI+5efCO1WxanB6QEjYtTqNncIzXT3RN7omV/4SBNlj5EbDadK/rH/ubiHXauXz+rHd+MzIRVn4YWg9DzQtT2n9BWiyPf2ItX7u+kHbXCLc/uJd7/3aQ3sGx6RUuhAgpviC3qUfKNpaqVQJ3Qhgi2qk+0/SbaaysMxY8YzA+POGnVHq7mC+YYjf/oNURPIG7tDgnxXnJvFTZRtfAqNHl6KtwM9idcHCr0ZUIIYS4AE3T2F3bQUFqNCkxTqPLCYwX/gcOPwrzr4PrvgcWi9EVCSEuQAJ3QgghhBAmU1rXDcDK7OkF7jLiIwCMHSurS+DO2+FOAnczyuDoOCc7B1iYYbILMW/XXgm99aq7nZyEmZD81Bh6h8Zod40YXYp+LBZIX4an5Qh3/bYEgD/ceTHrC84SMvOTTYvVWNlnj05yrOwbD4E1DJZ/UPeaqltdlDf3cd2SdBz2c4T51nwKrHbY9cCUj2OzWrireC477rmMS/OT+VtpAxvuf4XXjndOeU8hRGipaevHYoHcWSYO3DWVQUQCJMw1uhIhZqQohzdwN2yiwJ3D+1ltEuM9K1tM2uGuo0qtSXnG1uF184osxj0aTx1sMroUfTnjYP61ULdLzhEJIUSQO94xQGvfCGtzk40uJTDeeBB23Q+Zq+Dmh/xyU6oQQn8SuBNCCCGEMBlf4G7aHe4SfIG7id9trrvWwxCTDlHT+GAdEQ+OOOiRkbIzSWWLC02DQrN1Pni7Kt842WuMrSOEFHjH/VWZbKxsR2whVs8oi+xN/PnfLuaiuYkBPf781BjmJkex/WgLHs8Euwe2V8HJnVB4A0TrHw7cdkBdIDzrOFmfuCwoukVddDv1+rSONzsxkj/ceRH3b1nKwMg4336mYlr7CSFCR1Wri+zESJxhJr0oMj4KzYcgY4UE/IUwSLQ3cDcwYqaRsr7AXd+En1LZ4iIhMoyUGIefijJIRzXEZkF4lNGVAHDNolSiwm3mHCtbdKtaDz1qbB1CCCHOq6SmA5gh42Qrn4Fn7oXEeXDbVgiPNLoiIcQESeBOCCGEEMJk9tf3MCcpkuTo6Z2AzoxXrdobewb1KGvy3GPQVjG97nY+CdkSuJthypvURZuF6SbrfPB21TsgLBLmFBtdSciYn6p+J6paXQZXop+RcTc/P6Z+ru+t0yjKig94DRaLhY2L0mjtG+FAQ8/EnlT6W7Wuukv3ejRNY9vBRtJinVx8ofDhun9X664fTvu4FouFm1ZkccWCWRxu7KVn0GRjuIQQ7zDm9nCiY4B8M4+TbTsK7hHIXGl0JULMWL7AnWvERGPrnXFqHZlY4E7TNI61uJifFoPFTOFfjwc6a4JinKxPZLida5ekc6ihl2oTfW4CIG8DRCbDoa2gTfBGISGEEAFXUtuJ1QKXzDN54K5hHzx2p+omfvtj02s8IIQIOAncCSGEEEKYSGf/CCc6BlgxzXGyAJnx6k6qxm6DRsp2VIF7VJ/AXXwO9DaC20Tjd8R5VTSrizaF6XEGV+JHQ91Q/xrMXQ9hTqOrCRn53sBddZt5Lhzd/1wV/+pKByC7e69hdZweK3tkAmNlx4bgwCMwawHkrNW9lrL6Hk51DXHDsgys1gtckJ01HxZcD8eehrZKXY6/Li8ZTYM9tTJWVgizq+scYNyjnf77YkqNZWrNXGFsHULMYKbscDfJkbIN3UP0j4yzIM1kXcz7GmFsEJILjK7kLW5ekQXA4/sbDa5EZ7YwWHyzOufUtN/oaoQQQpyFx6Ox53gnizPjiIsIM7oc/+mshT9vUf9926OQlGtsPUKISZPAnRBCCCGEiZTVq65C0x0nC5BxusOdQSNlW46oNXXx9PeKzwbNrU5kixmhormPhMgwUmNNNmroTLUvqd/rAhknOxnJ0eEkRIZxrMUcgbvXT3Tx61ePkzI7F8+8K+DoE6o7qAGKMuNIj3Py7JEWtAt1izjyuLq4uupOv4wn3HZAvd7fsDRjYk9Y9zm17v6RLse/NE+NyN3pHYEihDCvau+IclN3uPMF7jIkcCeEUaJOB+5MdBOZb6TsBDvcVXrfvy9IM1nAubNarUHU4Q7g4rmJZMZH8I/9jbg9JusEt/QWtR7aamwdQgghzqq8uY+ewTHW5pq429tAB/zpZnVD9XsfhqxVRlckhJgCCdwJIYQQQphIaV03ACt1CNzFOMOIddqNGynbckitaUXT3ys+R6099dPfSwQ9j0ejssXFwvRYc40aervqHWrNl8DdZFgsFvJTY6hu7b9wKCzI9Y+M84W/HcBht/LAlqVYN3wN0ODFbxpSj9WqxsrWdw1S0XyBQOO+h9Q45KW36l7HmNvD04eayUuJZlHGBDugzF4Ncy6Fw49Cz6lp15CdFMnsxAh2S+BOCNOrbvMF7kwWADlTUxnEZkFMqtGVCDFjvTlS1kSBO4e3G/kEO9wda1HBvAXpJutw1xGcgTur1cJ7lmfS3DtMSa3J3tNmrICkfDj8GLhNNKZZCCFMwjctYG2uScfJjg6qznbdJ+C678OC64yuSAgxRRK4E0IIIYQwkbL6bqIddgp0GmmVER9Bk2Ed7g5DWBQkzp3+XvHZau2pm/5eIujVdQ0yOOqm0GwXYs7k8UD1c6oDZFyW0dWEnILUaFwj47T0GfT6ppP7nirnVNcQX75uIfNmRUPmSjUatfKf0FhqSE0bF3nHyh49z1jZpgOqvsU3g1P/sc+7ajroHBhl89KMyYVuiz8HnnHY8zNd6ijOS6auc5BTXQYF14UQAeEL3OWmRBlciZ+M9EN7pYyTFcJg0U4Td7gbnliHu4oWFxaLei9vKh1Vag2ykbIA712ZhcUCvy8x2bkUi0V1uRvsgNoXja5GCCHE2+yu7SDMZmHVnOk3FQg67nF47E51Xqz487D6LqMrEkJMgwTuhBBCCCFMYszt4eCpHpbNjsdm1aerV1ZCBM29Q3gCPT5E01TgLnURWG3T3y9BOtzNJBXN6oLNQjMH7prK1MUB6W43JfO9oeQq7xjAUPRceStb953i0vxkPnhJzpvfuPKrgAVeuM+Qui6am0hSVDjbj5wncLfvYbX66aTitv1qnOzmZZmTe2LuBkhbAmW/h8GuaddR7B0ru0u63AlhatWtLrISIogMtxtdin80HwTNI4E7IQwW7VCfi/uHzRS48954McGRssdaXOQkRprv9bajGsKjISbd6EreYU5yFFctTOWFylaOt4fuZ6ezWrJFrQf/amwdQggh3mLM7eH1E10sz04w3998gNd/BVX/gqJbYMPXja5GCDFNErgTQgghhDCJ8qY+RsY9rNBhnKxPRnwEY26N9v4R3facEFczDHVB2mJ99oubrdZuk92VLc5qRgTuqrartWCjsXWEqHxv4K669QJjT4NUZ/8IX3r8EHERYXzvvUvf2sUtZaE6aXf8JTjxasBrs1ktXF2YyrFW19kvyg33qtFNGcvV/+lscHScHeWtLM+OJzspcnJPtlig+B4YG4TXfz3tWtbmJmGxSOBOCDMbd3s43j5AforJui2dydcxNXOlsXUIMcNFO8IA6DdThzvHxDvcDY+5OdExwPw0E47v7qiGpDz1XjQI3VU8F02D3+4+aXQp+krIgZx1UPn0hMcaCyGE8L+Dp3oYHHWbd5xs7UtgC4d3/yho//YLISZOAndCCCGEECZRWtcNwEodA3eZ8REANHQP6bbnhLQcVmvaEn32c8ZCRIJ0uJshypv6CLNZyDPzxe/q7ep3Omu10ZWEJN/Y7WMtoRe40zSNLz1+mI7+Ue67cTFpcc53Pujy/wSrXXW50wLcoRTYuFiNld1+tPWd3zz0KIwNwCr/dLd7rryVwVE3N062u53Pws2QMAf2/hJGB6ZVS0JUOIsz4iip6Qh8p1ghREDUdw0y6vac/rtiSk1lgAXSlxldiRAzWpSvw52ZAne+kbIT6HBX09aP26OxIM1kN1WNuMDVFJTjZH0unpvI4sxY/lZ6ip7BUaPL0VfRLeAegfJtRlcihBDCq6S2E4B1eckGV+IHmqZuaEorgrAIo6sRQuhAAndCCCGEECZRVt+NxQLLZsfrtmeGN3DX1BPowN0htaYV6bdnfI4E7maIiuY+8lJiCLeb9OOOq0WNd8u7Sp+RyzNQYlQ4ydHhVLWF3likx0ob2FHeyg1LM7hhacbZH5Q4F1bcAQ2vv9kNMYDW5iYR47Dz7JHmt35D0+CNh8ARB4tv9suxnzzQhM1q4V1FUxzJZbPD2s/CUDeU/WHa9azLS6Z7cIzy5omNShNChJZq798RU4f8G0tVEMRpspCLECEmyjtSbcBMgbuwSLDYJtRdrNJ7o8wCs3W466xRa3K+sXWch8Vi4e7ieQyPeXhkr8nOqRRuBpsDDm41uhIhhBBeJbUdRITZWJql3zWOoNF9Qk31ke7hQpiGSa9ACSGEEELMPGV13eSnRBMXEabbnpkJKnDXGPDA3RHAokYj6iU+G/oaYdxkd2SLt+gZHKWpd5iF6Sa7EHOm6h1qzb/G2DpCXH5KDDWtLjQDOsBN1amuQf77qXLSYp3ct/kCI7cvuxfsTnjxPvB4AlOgl8Nu48qFKRxs6H3r34/616C9Apa9H8InOe51AroGRnmlqp3ivGSSox1T32jZ7RCVAiU/nfbfjGLvHdk7q2WsrBBmVOMN3OWbtcPdQIe6YUUuCAlhOKvVQlS4zVwd7iwWFeadwEjZYy3qMQvSTRb+7ahWaxAH7gCuW5JOWqyT35ecZHQ8sJ8t/CoiHuZfC3W75AZNIYQIAkOjbsrqelg9N9GcN1I3lqlVPl8JYRomfKUSQgghhJh5mnqGaOod1nWcLLw5UjbwHe4OQ1IehEfpt2dCDqBBX4N+e4qg4+siVWi2CzFnqtoOFqvqcCemrCA1moFRd+ADxVPk9mh84W8H6R8Z53vvKyIu8gLh6th0uOij0HoEjj4emCLPsGmRGiu742jLm1/c95BaV93pl2M+c7iZcY/GjcvP0flvosKccMkn1N+LI49Na6tVcxJw2K3srpHAnRBmVN2qOi6ZtsPd6QtCK4ytQwgBQLTTbq7AHYAzDkYm1uEuIsxGdqL+N20YqqNKrUE8UhYg3G7ljrVzaHON8PThJqPL0dfSW9V66FFj6xBCCEFpXTejbg/rcpOMLsU/GkvVmrXK2DqEELqRwJ0QQgghhAmU1XcDsCJb38DdrGgH4TYrjd0BDKSMuKDrOKQt0Xff+By1dtfpu68IKhXN6sK3aQN34yNw/GXIWg2RiUZXE9IKvOOoqltDY6zsQ7uO8/qJLu5Yk8Ol+bMm9qTieyA8Bl76FrjH/Fvg26yfPwtnmJVnj3gDdwMdUL4Ncoph1ny/HHPbgUacYVauLkyb/mar7wJHLOz64bQ6BDrDbKyek8jrJ7sYHnNPvy4hRFCpau0nI85JtMNudCn+0SSBOyGCSZTDbq6RsqDeb02gw11li4uC1GhsVksAigqgjmrAAonzjK7kgm67KJuIMBsP7jwRUl3CLyjvKohMgkNbwUw/lxBChKDdtepmxbW5yQZX4icN+9TNBiHwd18IMTESuBNCCCGEMIGyuh4A3TvcWa0W0uOdge0A1VoOaH4I3GWrVcaEmFqFt8PdQrMG7upKYLRfxsnqoMA7/u+YtztRMKts6eP726uYNyuK/7x2EqO2IxNh7WdUiPnAn/1X4NkOHW5nfcEs3jjZRUf/COz/E7hHYbV/uts1dA/yxsluri5M0yf44oxTnfg6jkHVv6a1VXF+MqPjHvad7J5+XUKIoOH2aNS295Nn1nGyoDowWMMg9QJjzIUQARHtsNM/bLLAnTMOhs/f4a6jf4R21wgL0kz4Ga+jWp2rCIswupILiosMY8uqLI429fHa8S6jy9GPLQwW36y6DTbtN7oaIYSY0UpqO4mLCKMww4R/891j0HxQjZO1mOwGAiFmMAncCSGEEEKYQGl9NwmRYcxN1nEEq1dGXESAA3eH1eqvDncSuDO18qY+0mKdJESFG12Kf1Q/p9aCjcbWYQIFKSogURXkgbuRcTf3bD2IW9N4YMsyIsJtk9tgzSdVx4ZXvgtjw/4p8hw2LU7Do8HzR5uh9LcQNQsWvNsvx3ryoBpttXnpNMfJnumST4DNATvvn1a3i+I8dWf2LhkrK4SpNHQPMjLuocCs42Q1TY2UTVsCdofR1Qgh8AbuzNjhbsR13vdax1rU+/X5aSYLOHvc0FkT9ONkz/SRdXOxWFT3bVMp8o2V3WpsHUIIMYP1DY9xuKGHS+Ylmq+jLUDrUXCPqMCdEMI0JHAnhBBCCBHihsfcHG3sZUV2AhY/3B2VmRCBa3icvuEAjSNs8VfgbrZae2SkrFmNuT3UtPWb8y5In+rtEJspnWZ0EBcZRkqMI+hHyv7w+Woqmvv49BV5LJ0dP/kNHDFQ/Hnoa1ShtwC6ckEqdquFU/uehu6TsPyDYPdPGHbb/ibiI8O4rGCC43YnIiYNlt0GjfugbveUtylMjyUhMoxdNe361TY6AC99G2pflNFXQhjE9/cjP9WkgbueehjskHGyQgSRKG/gzlTjPJ1xoLnVe5tzqPQG7hakmyxw13tKXXhPzje6kgmbkxzFVQtTeb6ijePtwf05alIyV0BSHhx+THUgEkIIEXB7j3fh0WBdnknHyTaWqjVzlbF1CCF0JYE7IYQQQogQd6ihl3GPxgqdx8n6ZMSr0SZNgepy13JYdUGKTtV33/Aota90uDOt2vZ+Rt0eFprtQoxPZ63qgJB/tYwe0ElBagw1bf14PMF50XLfyS5+9UotRVlxfPrKvKlvtPouiMmAV78PI4G7MBYXEcbavGSWtT6OhgVWftgvx6ls6eNYq4t3LUkn3K7zaY61nwGLFXY9MOUtrFYLa/OSOdrUR9fA6PRrco/DY3eqroV/fA88vAmOvyLBOyECrLpNvZ7mpZj0fUdTmVqlA4MQQSPGYcejwfCYx+hS9OP03iw10nfOh1Q2q++ZbqRsR7VaQyhwB3B38VwAHt59wuBKdGSxqC53gx3qhhYhhBABV1KrpgKszU0yuBI/OR24kxuahDATfRHkpwAAIABJREFUCdwJIYQQQoS4svpuAFb6KXCX5Q3cNXYHIHDncUNruere5Y9AUXw2dEuHO7Oq8F6IWZhusgsxPtU71Jov42T1UpAaw9CYm4ZAvL5NUv/IOJ9/9CBhNiv3b1lGmG0aH9/DImD9F9UFpL2/0K/ICXjPPLjSUkpr6qWQkOOXY/xjv3ec7LJM/TdPyoXCG6HmeWg+NOVtivOS0bQ3TyBPmabBv+6Fqmdh0U2w4g7Vge8PN8DvroeTu6a3vxBiwqrbVMelPLOOlPVdEMqQC0JCBIsohx0A14iJOnA5vJ/dhs8duDvW6iIlxkFilH86JRumo0qtITRSFuCiuYksyYzjsdIGuvW4mSRYFG1R68G/GluHEELMUCU1naTEOMidZeLPV3HZEJ1idCVCCB1J4E4IIYQQIsSV1nVjs1ooyorzy/4B7XDXWQvjQ/qPk/WJz4b+Fhgb9s/+wlDlTSYP3FVtB5sD5q03uhLTKPCOATzW6jK4knf65j/Lqe8a5EvXLtAnzLH8A5AwF3b/BAa7pr/fBG0ceRabRePvFv8ERT0ejacONpEZH8EqPwXPKf6cWnf/cOpbeEei7K6ZZuBu1wOw72GYux7e8yu44cfwmVL1/9/6PfC7d6ngXV3J9I4jhLig6tZ+UmMdxEWEGV2KfzTuh/CYkOu8JISZRTtV4G5gxG1wJTrydbgb7j3rt90ejWMtLuanmbCbqK/DXVJovc5aLBbuvnQuw2Me/vy6iSYIJORAzjo49sw5fx+FEEL4R7trhGOtLtbmJmEx41SP4T5oPybd7YQwIQncCSGEEEKEME3TKKvrpjA9lshwu1+OkZmgAncNgQjctXi7B6UV+Wf/eG93pd4G/+wvDFXR7CIizMacpCijS9HfSD/U7YY5xWo8stBFfqq6cFcVZIG758tb+esbp7g0P5kPrZmjz6a2MLjiKzDSCyU/1mfPC3GPEXn4EdptKfyscS5Do/pfHN5X101jzxDvXpqB1eqnk7LpSyF3Axx9ArqOT2mL2YmR5CRFsms6gbtDj8IL/w0pi+CWP4Ld2+UlYQ5s/hl8+g1Yept6rfjttfCHzVC/d+rHE0Kck8ejUdPWT75Zx8l63NC0HzKWgdVmdDVCCK9ohy9wN25wJTpynH+kbF3nACPjHnPeVNVRDY64kOx0c92SdNJinfy+5CSj4yYacVx0C4wPQ/mTRlcihBAzyp7jnQCszU02uBI/aT4AaJC1yuhKhBA6k8CdEEIIIUQIq+scpHNg1G/jZAHS45wANPUEoCtcy2G1+rPDHUDPSf/sLwyjaRoVzX3MT4vB5q/QjZGOvwzuUci/xuhKTCXf2+GuOogCd539I/zn44eIddr53nuX6hsiW3yzCmu99ktwteq377kc+xf0t1A/530MjsErVe26H+IfBxoBuHF5hu57v0Xx50DzQMlPp75FXjKnuoao6xyY/JOPvwL/+CTEZMDtfwPnWbraJuXCe34Bn94HRbfCiVfh4WvgjzdBw74p1y2EeKfGniGGxtyn/46YTkcVjA1IBwYhgowvcOcaNlHgzvee5hwdxSpb1Pv0+akmDDh3VKkuoiHYySfMZuWOtXNoc43wz0NNRpejn8LNqqv8oa1GVyKEEDPKnlp1c+LavCSDK/ET3zmZzJXG1iGE0J0E7oQQQgghQlhZfTcAK/wYuHOG2UiOdtDYPei3Y5zWekSd3EzK88/+Cd4Odz0mGnsiAGhzjdA5MGrOzgcA1dvVWiCBOz3FOsNIj3NS1dpvdCmACo5++YnDdPSPct+Ni0nzBp51Y7XClV9Vo7t3fl/fvc9m30NgtZNx5ccA2H60RdftR8c9PHO4mfmpMSxI8/O//TmXqhOj+/8E/W1T2sI3VnbSXe5ay2HrByAsAj7wGMRlnv/xSblw06/gU6/DkvdB7Yvw4AZ45H3QWDal2oUQb1XTpv5umLbDXWOpWjMkcCdEMIkyY4c75/k73PkCdwvSTfZ6O9QDA20hPbb7touyiQiz8eDOE2iaZnQ5+oiIh/nXwsmd0HPK6GqEEGLGKKntJDsxkqyESKNL8Y/GUrDY1AQFIYSpSOBOCCGEECKEldZ5A3fZ8X49Tma8M3Ad7lILweaf8binR8p21/lnf2GY8mZ1gaYww4SBO02D6ucgKR8S5xldjekUpMZQ096P22P8RaK/lzWy/Wgr1xels3nZBUJVUzX/WshcBft+69/Xws5a1ZlxwfWkZ+ZQlBXH8xWtuo6cerWqnZ7BMTb7u7sdqM4jxfeAewRe+8WUtliTm4TFAruqJxG462uCR94LY0NqjGzqook/Nzkfbn4QPvkaLLpJvY785gr48y3QdGDyP4AQ4rTqNhUAMW2HO184VzowCBFUoh1qxHO/mQJ3jgt0uGvuw2a1kJdistfbzhq1hnDgLi4yjC2rsihv7js9CtAUlt6q1sOPGluHEELMEA3dg9R1DrI216Td7UB9vkophPAooysRQuhMAndCCCGEECGstK6b1FgHmfERfj1OZkIEra5hXYMS7+Bqhf5W/42TBYibrVbpcGc6Fb7Andk6HwC0HAJXMxRsNLoSUypIjWZ03DO1MZ86auge5BtPHiU11sE3b1zsvwNZLLDh6+AZg1e+67/j7HtYravvAmDjojRcw+OU1E6yu9t5bDuoxlfdsDQAgTuA+e9Swdc3HjznReHziY8MpygzjpLazokFPIf7VFe6vkbY/FOYd/mkjwlAygJ432/hEyVqTFbVs/Dr9fCX26D50NT2FGKGq/Z2Rs2bZbIAiE9jKUTNgrgsoysRQpwh2hEGmCxw5+twN3z2DnfHWl3MS47CYbcFsKgA6KhSa3KBsXVM00fWzcVigYd2njC6FP3kXQWRSXBwq7r5TQghhF+V1KrQ9lrvVADT6WsCVxNkSvdwIcxIAndCCCGEECHKNTzGsVYXK3MSsFgsfj1WRlwEmgatfX7sctd6WK1pRf47RpgTotMkcGdCFc2q08x8f4+VNELVDrXmyzhZf8hPVSFNI8fKejwa/+9vB+kfGef/3ruU+Mhw/x5w3nqYux4O/gXaj+m//9gQHHhEhdPmXArAtYvTAP3GyvaPjPNceQur5yQEbuSI1QrFn1Mjz/b9dkpbrMtLpndojKNNFwjsjY/Cox9Uo9av/NqbnTamI7UQtvwBPr4bFlwPx56GX12qxtW2Hp3+/kLMIFVt/SRHO0iI8vPrtRHGhtVrQuZKFdIWQgSNKDN2uHN6O9ydZaTswMg4dZ2DLEg34We8jmq1JoVuhzuAOclRXL0wlRcq2zjebtznKV3ZwmDxzdBxDJqlK7QQQvhbSY26MXPNPJN2uGssVat0DxfClCRwJ4QQQggRog6e6kXTYEV2gt+PlZmgOug1dA/57yAtR9Sa6sfOTgDx2dAjI2XNpryplzlJkUQ7/DSO2EjVOyA8BrLXGF2JKRV4A3fVrS7Danh49wleO97FBy/JYX3BrMAcdMPXQfPAS9/Sf+/ybTDUDavuPB3WmDcrmoLUaHYcbdVlfO9z5S0Mj3n8N3r3XJZsgZgMeO3nKpQyScX56o7tnecbK6tp8NRn1UjelR+GS78wtVrPJW0x3PoIfGyn6tpX8RT8Yi08ege0Veh7LCFMSNM0alpd5JttvKFP6xHVBTVDOjAIEWxinOqzzoCZAneOc3e4q/K+P1+QZsIu5h1VYLFB4lyjK5m2uy+dB6jPNKZR5L3Z5eBWY+sQQgiT0zSNktpO5qfGMCvGYXQ5/iGBOyFMTQJ3QgghhBAhqrSuG4AVOf4P3GV4R9Y29fgzcOftcJe6yH/HAEjIgYF2GB3073FEwAyPuTnRMcBCM3Y+GOiEhjcg9wqwm7CLThDwBSaq2ozpyHCsxcX/PXuMuclRfOm6BYE7cNYqFbYq3wZN+/Xd+42HwO6EZe9/y5c3LUqjc2CUfSe7pn2If+xvwm61cN2S9GnvNSn2cFj7aTUC/eBfJv30FdkJOMOs7K45T+DupW+rvfM3wnU/8F+HqfQieP+f4aMvQ8EmKP8H/HwNPHanfzofCmESzb3DDIy6KUg1aeCusUytckFIiKAT5b25yDVsXOBO0zT+tu8Uu2s60PQYtxnmBFv4WTvcVbb4MXA3OgCdtfrvO1Ed1ZAwB+yhHy5YPSeBoqw4HittoHtg1Ohy9JG5ApLy4Mhj4DZRwFUIIYJMbfsAba4R1uSatLsdqMBdWBSkLDS6EiGEH0jgTgghhBAiRJXWdxNut7Iow/8ho0xv4K7R34G7hLng9PPPE5+tVhkraxrHWlx4NMwZuKt5HtCgYKPRlZhWlMNOVkKEIR3uRsc9fG7rAdyaxv1blhIZHuAOjVd+BbDAi9/Ub8+Ww9DwuhrDFPHWQPhG71jZZ6c5Vrajf4RdNR2sL5hFohHjHFfcAc542P0j8Lgn9VRnmI3VcxLZd7KbodGzPLf09/Dq/0H6Mnjvw2ALwO9ExnK4bSvc/SLkXQVH/g4/uxj+/m/QUeP/4wsRYqq9Ae28VBN2XII3OzBkLDe2DiHEO/i6eRvZ4e5Yq4t7HzvE7Q/u5ar7X+F3u0/QNzw2vU0dsTDc+44vVzarEN58fwTutn8Ffrr6zRv/Ask9Dl3HITm0x8n6WCwW7iqey/CYhz+/bpLzLBaL6nI30A61LxpdjRBCmFZJrboZca1ZA3ceNzTuh4xlYLUZXY0Qwg8kcCeEEEIIEYI8Ho399d0UZcbhsPv/w1qmvzvcjQ1BZ7Uac+dvErgznXLvhRhTBu6qt6s172pj6zC5gtQYqtv6+do/jvBqVTsj45MLUU3VD5+voqK5j09dnsvyAIwHf4fURbDkfSrYeXK3Pnvue1itq+56x7cK02OZnRjB9iMt0+qI8vShZtwejRuWZUx5j2lxRMPFH4PuE6pD4CRdmp/MqNvDG2/v9Ff9HPzzHvV36rZH1XECKWslfOAxuOt5yL0SDj8KP79YjbYVQpzmC2ibdqRsU5nquhRl0oteQoSwKO/NGQOjxgXuqlpV6HhdXhId/aN846lyLvn2C3zlicMca5niDSzO2LOOlK1scRHjsJ8+H6Eb95jq7Ku5VfBOj059k9FTp0Z3myRwB3DdknTSYp38ruRkwD5L+V3RFrUe+quxdQghhImV1HRitcDF80z62aOjGkZdqnOqEMKUJHAnhBBCCBGCatr7cQ2PszIA42QB4iPDiAy3+a/DXVs5aB5IK/LP/meKz1FrT53/jyUCosIbuCsMQLfHgHKPqyBUxnKISTW6GlP7wCXZZMZH8MfX6vjQw6+z8r7n+dQjZTyxv4GeQf+MRSqt6+KXr9SyJDOOz2ww8GLb5f8JVju8eN/0LzaOuODQo5C+9KwnEy0WC5sWpdHUO8yhhnd2MZmofxxoJDLcxtWFBv67uOhjYI+AXQ9M+n+3dXnJAOw6c6xs0wF49A51wfkDjxv7b372avjg4/CRf6nRwE98AganPwZYCLOo8Xa4M2XgbrgXOqogQy4ICRGMrFYLkeE2Q0fK+l4Dv3zdQl770gb+7+Yi5s2K4pG99Wz84ats+dUenjrYxJjbM/FNnXHvGCmraRqVLS7mp8VgsVj0/BHg5C4Y6gZHHJx4Bap36Lv/hXRUqTW5ILDH9aMwm5UPr5tDu2uEfx5sNrocfSTkQPZaqHz6rB0YhRBCTI/bo7HneCdLMuOIiwgzuhz/8HUPz1xpbB1CCL+RwJ0QQgghRAgqresGCFhHJIvFQmZ8BI3dfgrc+ca4pC3xz/5nOt3hTgJ3ZlHR3Ees005GnNPoUvTV8Lo6sZ8v42T97coFqbxy7+U8d89lfHHTfApSo3nmSDP3bD3Iym8+zy2/2sODO49zsmNAl+MNjIxzz9aDhNmsPHDLMsJsBn40T8qF5R+E+j3eEcbTcOhRGO2HVXeqMUxnsWlxOjD1sbL1nYPsr+9h46K0wI/gPVNUEqy8A1oOTXrM1MK0WJKiwtlV7Q3cddfBI+8Dzzi8/6/B0+0kZy1c+11wNanOe4Hu/iJEkKpqdZEYFU5StMPoUvTXdECtckFIiKAV7bAbOlK2tq0fiwXmJUcTEW5jy+rZPPXpYp745FpuWp7JgfoePvOX/az93xe5/7kqWnqHL7yp450d7lr7RugdGmNBuh/GyVY8qdYtv4ewSNjxVdX1LlA6qtWaFCTv+XTy/tXZRIbbeHDXiWl1sw4qS2+B8WEof9LoSoQQwnQqmvvoHRpjrfemRFM6HbhbZWwdQgi/kcCdEEIIIUQI8gXuVuTEB+yYGfERNPYM+efEaSADd3GzAYuMlDUJj0ejotnFwvRY/TsfGK3KO042/xpj65ghLBYL+akxfPLyPB7/5Dr2fnkD3715CVfMT+FgQw/ffLqCy7//Mlfd/wrffbaS0rpu3J6pvR5+8+kK6rsG+c9rF5AXDB2S1n8RbA544X/AM4luJGfSNDVO1hELi997zoctnx1PSoyDZ6c4VnbbgUYA48bJnmnNp1R3wF0PTOppVquFtXnJlDf30dXeAo+8Fwba4aZfQ/Ylfip2ipbdDgtvUGPXDso4LSE0TaO6rT84Xrv94fQFIelwJ0SwinbY6TcwcFfT1k9mfAQR4bbTX7NYLCzPTuD+W5ax50tX8sVN8wm3WfnxC9Ws++6LfPKRUvbUdp77vZ8zVnW4O+N9aEWLCuDNT9O5i7nHDRX/VN3lcq+Adf+uOs6V/k7f45yPCTvcAcRFhrFl1WwqmvvYc7zT6HL0UXij+px0aKvRlQghhOmU1KqbENfmmnScLEDjPohKgbgsoysRQviJBO6EEEIIIUJQWV032YmRpMQErqNXZkIEI+MeOgf8MF6x5Qg44yE2U/+9384eDrEZqqOQCHkN3UP0j4ybb5wsqNFGUbPUSFkRcCkxTm5Znc2Dd6xi/9eu4cEPreLW1bPpGRzjFy/XcvMvSrj428/zxccOsuNoC4OjE7vw+WJlK395vZ51eUncsWaOf3+IiYrNgIv+TXVrq9g2tT0a3oDWI1B0CzjOHUSxWi1sXJTGiY4Bqr0jySZK0zT+caCRpKhwioPhDuj4bBUuPLkTGkon9dRL85JxMIr219vURdeN34JFN/qp0GmwWODdP4KYdHjmXug+aXRFQhiqzTWCa3icglSTBu6aysBiVaPBhRBBKdppZ2DEbcixx90eTnQMnDd0nBTt4JOX5/HqF6/gNx9axdrcJJ453ML7f/MaG3/4Kn/cc/KdgUFHHKDBqOv0l461qP9emKZzh7tTe2GgTd1QALD2M+p9zkvfhqEefY91Lh3VEJGoOiabzEfWzcFigYd2njC6FH1ExMP8Ter9fs8po6sRQghT2V3TSbjNyqqcRKNL8Y+xIWg9qrqHm+0mcSHEaRK4E0IIIYQIMV0DoxzvGGBlTmDGyfpkxkcA0NSj81hZj0eFNNKWBO7DZ3y2dLgzifJm1flgYbrJAnc9p6CtHPKuBqt8bDNaRLiNqwpT+d+bi3j9yxt44pNr+dQVuSRFOXh0XwMf/WMpy//nOe763Rv85fV62vrOPjqra2CULz52mBinne+9dylWaxCdcCv+PIRHw4vfAvcUuqa88ZBaV991wYduWpwGwLNHJjdW9mhTH7XtA7yrKN3YMbxnWvfvat09uS536/IS+UHYL0nqLIVLPqm65QWryES48efqIvjjH5va74cQJuELgOSn+GHEYTBoLINZCyE8yuhKhBDnEBVuxzUcwPGnZ2joHmLU7SFv1oVDxzarhasLU/njXRfz4hfWc+e6uTT3DvO1bUe55Nsv8PVtR6hu9QbsnN7PcmeMla30fs4r0Dtw5xsNWugN3IVHwYavw1AX7Py+vsc6l85qSDbXOFmfnKQorilM5YXKNmrbJ3dzTdAqulWthx81tg4hhDCR0XEPb5zsYnl2/Fu65ppKy2HwjEPWSqMrEUL4UZCcoRZCCCGEEBO1v947TjY7cONk4c3AXWO3zoG77hMw2g9pRfruez7xOeqE+ojrwo8VQa3CeyGm0GyBu2rvONkCGScbbKxWNTLr3o0L2H7PZbx67xV87fpCVmQn8HJVO196/DAXffsFbvzZbn72Ug3HWlxomoamaXz58cN09I9w3+bFZHhfU4NGVBKs+bS6AHhokqNDB7vg6BOQvRZSFl7w4RfNTSQ+MmzSgbsnDzYBsHlZALqhTlRqIRRcq0aTtVdN+GmZb3yH622v8ZJ1Ddo13/RjgTrJvVIFA0+9NukRukKYiWmD/gCuFuhrlHGyQgS5aKedgVH3ucez+lGNtzvxZMdqz5sVzdffXcjeL2/gOzctYXZiJH/YU8fVD7zKrb/eQ1Wv9zLVyBmBuxYXmfERxDrDdKsfTYOKp9T5gDPPPxTdqjp77v0VdB3X73hnM9AJg52mDdwB3FU8D4CHd5mky13eVaoj4cGt6ndICCHEtB1s6GFw1M3a3CCYXuAvDfvUmimBOyHMTAJ3QgghhBAhprTOG7gLcIc7XzikUe8Ody2H1Zq2WN99zyc+W63S5S7klTf3YbdaJn3RJ+hV7QCrXYVcRFDLTorkruK5/OWjl1D21av50a3LuL4ondq2fr63/Rgbf/gql33vJT75SBnPHm3hXUvS2bwsw+iyz27NpyAiAV7+XxgfmfjzDjwC7hFYdeeEHh5ms3LVwlTKm/uo7xyc0HPcHo0nDzQxOzEi4IHzCyq+B9Cg5EcTe/zeX0HJT6iLWsLHBz/Gya6zd0QMOhv+C1IK4eXvTHqErhBm4Qv6L0g3YYe7xjK1SuBOiKAW7bDj9miMjHsCfuya9qkF7nwiw+28/6JsnvlsMX//xBo2L8ugtK6bvx7qBeBvu8pp6xtmzO2htr2fBXp3t2ssg74G1d3uzO76Vitc8y1wj8Lz39D3mG/XWa3W5AL/HsdAq+ckUJQVx9/LGugaGDW6nOmzh8Pim6HjGDQfMLoaIYQwhZKaTgDW5ZlvvPppjd7zJhnLja1DCOFXErgTQgghhAgxpXXdRIXbmJ8a2At9mQl+Cty1HlFr2hJ99z2fhBy1SuAu5FU095E7KxpnmInGD4wNwYlXIXsNOOOMrkZMQlxkGJuXZfLT21ZQ+rWr+dNdF/PhtXPweOBfR1pIiXHwzRsXYwnU+OzJcsaq8FjvKSj93cSe4/HAvochMunN0VwTcK1vrOzR5gk9fu+JTlr6htm8NDP4/vfLvlh19zu4FXobz//YiqfgX/8BSXnUXPkbRghnV01HYOqcrjAn3PQbsNrg8X+DEZOMCRNiEiqa+5idqHPHpWDR5AvcSQcGIYJZtMMOgGs48CPep9rh7u0sFgsrcxL50a3LKfnPDaxbNBeAf5VWsvZ/X+TO373BmFvTP9xcsU2tCze/83tzL4UF10P5Nqjbo+9xz9ThDdwlmbfDncVi4a7iuQyPefjz3jqjy9HHUu9Y2YNbja1DCCFMYndtB5HhNoqyguyGSj01lkJSnrqxVQhhWhK4E0IIIYQIIWNuD4caelmWHY/dFti3cqkxDmxWC03+6HBnDYPk+fruez6+DnfdJjn5O0P1Do3R0D3EQrN1mTm5C8aHIF/GyYaycLuV4vxkvnHDInb9xxVs/9xlPPnpYhKiwo0u7fxW/xtEp8Gr34PRgQs//sQravTW8g+A3THhw6zLSyYq3DbhsbJPHvCNkw3S7oDF94BnDF77+bkfc+p1+PvdEJUMtz/GqsI8rBbYVd0euDqnK20xXPUN6KqFHV8xuhohAmp4zE1t+wAL00w4ThbUBSG7U3WyFEIErShv4G5gxJjAXXJ0OPGR+r2fnRXjYMMyFT779+JULp6XyM5qdTNCYbqONx9pGpQ/CTEZ5w4WX/0/qsv49i+rm0r8oaNKrSbucAdw3ZJ00uOc/H5PHSPjbqPLmb7MlZCYC0ceA3fg/+0JIYSZDI262V/fzUVzEwm3mzSqMtgF3Scgc5XRlQgh/Mykr2JCCCGEEOZU2exiaMzNiuzA3xllt1lJi3X6Z6RsygI1piNQZKSsKVR6x7otTDfZhe+q7Wot2GhsHUI3FouF+WkxpMU5jS7lwsIjYf29MNAOe3954cfvewiwwMqPTOowzjAbVyxIoay+h9a+849UHRl388zhZgrTY8kPcHfXCcu/GlIWwb7fqhOrb9dZC3++BSxWuG0rJM4lLiKMoqx4Smo7cXu0wNc8VRd/AuZdrrogVj5tcDFCBE51az9uj2a+9x2ggiiNZZBWBDYTdu8TwkSiHaqzd3+AA3eaplHb1s+8WdPrbndW3q7eS5MtPHL3JTz/+fX8701L2LgoVb9jtB5RF74XvluNkD2bpFy46KOq4+eRx/Q79pk6qtUNh76u+yYVZrPy4bVzaHeN8M+DE+toHdQsFtXlbqAdal80uhohhAhp++q6GHNrrM2dAeNkpXu4EKYngTshhBBCiBBSWqcu4q/IMaYVeUa8k6ae8wcjJmWwC/oaITWA42QBYrPAYoMe6XAXyiq8gbvCDBNd+NY0qN4O8Tmm73oggtjyD6nfwd0/gqHucz+urwkqn4G8DZA4d9KH2eQdK7vj6Pm73L18rJ2+4XFuXB6k3e1AXYQrvgfGBuCNB9/6vf52+NPNMNwD7/3tW064Fucl4xoe51BDT4ALngarFW78hRqL8uRnwNVqdEVCBIQp33f4dB1Xr1GZK4yuRAhxAb6RsoEO3LW5RnCNjE97nOxZOb2vqyPqdTYvJZpbL8rWt6t/+ZNqLbzh/I+77F5wxsPz/w1jOt9sCNBZrd43z4Bw860XZRMZbuPBXSfQtBC6ueRcirao9dBfja1DCCFC3O6aTgDW5iYbXIkfSeBOiBlDAndCCCGEECGktF5dkF8x25jAXWZ8BF0DowyO6nRyv+WwWtMCHLiz2SE2UwJ3Ia6i2QWYrMNd+zHVebFgowrwCGEEezhc8WUY7oWSn5z7cWV/BM0Nq+6c0mEun59CuN3KsxcI3G070IjFAu9eGsSBO4BF71EdVF/7xZvaa9AwAAAgAElEQVTjeEcH4C+3qI4q7/oBzN/0lqcU56sTzLtrOgJd7fTEZsD1P4TBTtj2SRUWnqE0TeOhXSeoanUZXYrws3Jf4M5M7zt8mvarVS4ICRH0fCNl+4cDG7irbesHIM8fHe4c3tfV4T799/apeBKiZkH2mvM/LjIR1v8H9DXAnp/pW8P4KHSdmDE3VsVFhLFl1WwqmvvYU9tpdDnTlzBH/f5UPu3f31UhhDC5PbUdxEWEmfNzlU9jKdjCIW2x0ZUIIfxMAndCCCGEECGkrK6b/JRo4iKNuRs6Iz4CQL8ud0YF7kCFImSkbEiraOljVoyD5GiH0aXop9o7Tjb/GmPrEGLJ+2DWAhUe62975/fd42qkaGwm5E9t/HG0w85l+cm8dryL7oHRsz7GNTzG8xVtXDw3kfS4iCkdJ2Bsdlj7WRjqgv1/Ao8b/n63OtFa/PmzBhOXZ8cTEWZjV6gF7gAW3QjLboea59/Z1W8Gqe8a5L5/lvOFRw+ao3uLOKfy5j5iHHayEoL8tWgqfB0YMqTDnRDBLsapAncDet0EN0E17d7AnV863KmRsgz36r83QHsVtFfCgneB1Xbhx6++GxLnwa4H9O3k231C3aySnK/fnkHuI+vmYLHAg7tOGF2KPopugfFhFeAUQggxab1DYxxu7GXNvCSsVpPeaKxp6vNV2hKwm+ictRDirCRwJ4QQQggxDa19w7g9gbm42tI7TGPPECsNGicLkOm9wNjYo9NoldOBOwPu9krIUSf0h0JojJ84bdztobLFZb67Iat2gD0C5hQbXYmY6aw2uPKrMDYIO3/wzu9XbwdXE6y4QwXNpmjT4nTcHo3nKs5+MfPZIy2MjnvYvCxzyscIqOUfgMhk1Rnwmf8Hx56BJVtgw9fP+nCH3cbF8xIprevWr3tsIF37XdXtY8dXoa3S6GoMcbJzEIDDjb28fKzd4GqEv2iaRkVzHwvTY7GYsQNtY5kKvCTOM7oSIcQF+DrcuQLc4a6mzY+BO8dbR8rqrmKbWhdeYJysjz0crr4PRvvhpW/pV0dHtVqTZk7gLicpimsKU3mxsu3071BIW3Sj6lh0UMbKCiHEVOw93olHg3V5SUaX4j/dJ9U0AOkeLsSMIIE7IYQQQogpOnCqh0u+8wLv/skuSgLQmaasvhuAFdnGBe58He4au3UK3LUegbjZEGHAzxSfrVbpcheSTnQMMDruMdc42aEeqN8D89ZDmAm754jQs+B6yFgO+x5+52vlGw+BxQYrPjStQ1y1MAWb1cL2I2cfK7vtQBNhNgvXLU6f1nECJiwCLvkE9J5S/7vNvQw2/+y8I6KL85IZc2u8fqIrgIXqxBED7/k1uEfh8bthfMToigKuvnPg9H//6IVq6XJnUo09Q7iGx1mYHmN0Kfpzj0PzQfV6b5VTxUIEu2hv4G5gJPCBu6hwG+lxTv03t4erm478Naaz/Elwxqv3ZRO14F2QUwz7/wgtR/Spo6NKrTNkpKzP3ZeqMPfDu03Q5S4iAQo2wcld0NtgdDVCCBFySrwjxtfkJhtciR/5uodL4E6IGUHOogghhBBCTNGzR1rQNDjW6uK2B/dy9+/3Udvuvzt2S+u8gTsDO9xlnR4pq0PgbnxEjXUxYpwsQHyOWiVwF5LKm9XFGFNd+K59UY0YknGyIlhYLKozm3sUXvnum1/vOg61L6gLkbHTC8LFR4azZl4SO6s76H/bheO2vmFKaju4fH6KYaPUp2T13RCZBCmFcMuf1EXk81iXp04076oOwbGyANkXw2X3qq61enaBCRH1XarD3aX5yRw41ROa44HFBZU3+d53mCjo79NeAeNDckFIiBBhZOAuNyXaf10+nbH+6XDXdQJaDsH868A2ifeTFgts/JYaC7fjK2qdLl+Hu+S86e8VQlblJLA0K47HyxroGhg1upzpW/p+QINDjxpdiRBChJyS2g5SYhzkzooyuhT/aSxTa+YqY+sQQgSEBO6EEEIIIabolap2kqLCeekLl3N9UTrPV7Sy8YFX+caTR+n2w0nEsvpu4iPDmJds3AfS0x3u9AjctVeCZ9zAwJ2vw12dMccX0+IL3JlqpGz1DrVK4E4Ek3lXwJxL4cCf37xIWPo7ta66U5dDbFycxqjbw0uVbW/5+lOHmvFocGOojJP1iYiHT70BH31FjWi8gAVpMSRHh4d2UOuye1VYZ/eP4cROo6sJqLrOQWxWC/dtXozdauHH0uXOlCqaXYBJA3e+DgwZK4ytQwgxIadHygYwcNc3PEaba4S8WX4YJ+vjiIXhXv33rXhSrYUTHCd7poxlKlx1/GWofm76tXRWQ9QsYzr8G8hisXDXpfMYHvPw570mOP+SdxVEJMKhrfoEMYUQYoZod41Q1drPurxk/wX4g0FjqToXlDjP6EqEEAEggTshhBBCiClo7RumormPywpmkZ0UyU9vW8HfP7GWJVlx/K7kJOu/9xIP7jzO6LhHl+MNj7k50tjLiuwErFbjPpBGOezER4bpE7jzjWVJXTz9vaZCRsqGtIpmFw67lbkGBlB15fGoizgpiyB+ttHVCPEmiwWu/BpoHtW9bHwE9v8JEnNh7npdDrGxMBWLBZ49+taxsk8eaCTaYWfDwhRdjhNQUUkX7GznY7FYWJeXTGWLi3ZXiI5ktYXBTb+BsEh44mMw1G10RQFT3zVIZnwEc5KjuGlFJm+c7Oa14yE4HlicV0VzH1YLzE8zUWddn9MdGKTDnRChINoZ+A53NW2qk39uih8Dd85Y/4yULX8SwqPVTSRTseFratztjq+Ae2zqdWiaGik7w8bJ+ly7OI2MOCe/31PHyLjb6HKmxx4Oi29WN5E2HzS6GiGECBklteomwzW5SQZX4kfuMWg+oG5mskoMR4iZQP6lCyGEEEJMwatV7QCsL5h1+msrcxJ4/BNr+cn7lxPjDOObT1dw9QOv8OyR5ml3OjnS2MuYW2NFdvy09tFDZnwEjd16BO4Oq9WoDnexGWC1Q7cJ7rCegSqa+5ifFoPdZpKPNE37YbADCqS7nQhC2RdDwSY4+gS8eB8MdsKqj+h28jAl1smK7AReqmxjeExdgDvRMcDBhl42LkrDGWbT5TjBrNg7VtZ3AjokJeXCpu9AXyM8/YUZ0fFD0zTquwbJSYoE4FNX5GGzWvjJi9UGVzZ5nf0jPF/eanQZQauipY95s6LN+XrUWAYx6dMeES6ECIyocBW46w9g4K7WF7jzZ4c7Z5z+I2V7G6Fxn3ofG+ac2h6xGbDu31VYztfleSoG2lUHv+T8qe8RwsJsVj68bg7trhGeOthsdDnTt/RWtR7aamwdQggRQvbUdgKw1syBu7ZyGB+Wm5mEmEFMcnVKCCGEECKwXqlqx2KBS/OT3/J1i8XCu5dm8MIX1vMfmxbQ2T/Kx/9Uxi2/eo1DDT1TPl5pneoUsyLH+NEjGfERtPQN4/ZM80J6y2E1NiY+R5/CJstqg7gs6XAXgtpdI7S7RliYZqKxbtXb1Zq/0dg6hDiXK7+q1pKfgM0By27XdftNi9IYHHWzs1oFzrYdaATgxuUZuh4nWBV730/sqg7hwB3Aig/BguvhyN/h8N+Mrsbv2vtHGBx1k52oAnc5SVFsXppBSW0n+06GTpc7TdP47F/3c/cf9lHR7IfuQiHONTxGXeegOcfJjg6qi0JyQUiIkGGzWogMt9E/ErguYTXtKnCX588Od45YGO0Hj44/V8VTap3KONkzrfssRKfBy9+BoSme1+nwhvGTZmbgDuCW1dlEhtt4cOfxad+UarjMlarj9+HHwB248KsQQoSyktpOcpIiyUqINLoU/2ksVWvWKmPrEEIEjATuhBBCCCEmadztYWd1B0WZcSRFO876GGeYjU9cnsvL917O7Rdns6+uixt+upvPbz1A0xTGsZbVd2OzWliaFRwd7twejda+4alvomkqcJe62Nj26vE5KnAX6id7Z5jDjeoiR2GGiS58V20HZzxkrTa6EiHOLm2JGp0EsPgmiEzUdftNi9MAePZIC5qmse1AE8nRDtbMM/Gdz2dIj4sgd1YUu2o6QvsCpMUC7/4xRKeqLncm7yJ7qmsQ4HTgDuBTV+ZhscCPX6wxqqxJe6Gijd01qtuAr4uzeNOxFhcAhWYM3LUcAs0NGcuNrkQIMQlRDjv9w9MYbzpJtW392K2W0x1d/cLpfY3Vs8tdxZNqHGzeVdPbJzwKNnxddXne+YOp7dFRpdYZOlIWIC4ijC2rZlPZ4qLE2+UoZFksqsvdQBscf8noaoQQIuid6hqkvmvQ3N3tABq8gbuMFcbWIYQIGAncCSGEEEJM0sGGXnqHxt4yTvZckqMdfOs9S3j2c5exvmAWj+9v5MofvMz9O44xMMERMJqmUVrXw8L0GKIc9umWP22Z8REAUwoOntZ7CkZ6IW2xTlVNUXw2jLpgqNvYOsSkvFDRBsC6vOQLPDJEuFqg+YC6EGQz/t+4EOe04b/U72nx53XfenZiJIsyYnm+opWy+h5OdAzw7qXp5hkbPQHFeck09w5zvGPA6FKmJyoJbvy5umD+xMf17VQTZOo6VeDuzABC7qxori/K4NWqdg6cmnp340AZHffwrWcqiAy34bBbebVaAndv5+v6tzA9xuBK/KCxTK3S4U6IkBLjsDMQyA53bf3MSY4izJ/vyxzewN1wrz779bdBXQnkX6UCc9O19P2QVgR7fwldJyb/fF+Huxk6Utbnzv/P3n2Hx1Vf+R9/z4xGGvVRt4rVJVtyxcYNV8CmQwCTSpJNATYN9re7KYQkpADJlvSQTYM0FpKwGEINxcbYliu2KZYlq1q9jHrXSDNzf39cjUyRrTLlzlyd1/Pk+YI0c++xIzS3nPs5G3MwGODhkjn8HQaa5R9S17f+om0dQggRBM6Nk9XJtdzzaT4BsQshOkXrSoQQfjJ/rlwLIYQQQnjJvonkj62Lpm+4cytMieZPn1nLHz+9hsz4CH7+ajXbfvgaf3u9YdrRrI3dI3QO2lmVqf04WYD0OLXhrtmThru2U+q6YJkXKvKAe5xtr74TePREURR2l7eTkxhJXpIXbpwEgqpX1LXgCm3rEGI6cVnw8V2Q5JtkjquWLKBvZJxv/b0UgA+sTPfJfgKVu4k46MfKgtqYufafoeEQHPyp1tX4jLvhLjP+3Z9Hd16WD8Av9lT5vabZ+vPhOs52DvHFS/NZmxPP62d7GBnTb5PkXJRNNNzpMuHOPfJIEu6ECCqRYSEMzvABPk+Njjtp6B4mP8mH42QBLLETO/RSwt2Z5wAFij7gne0ZjXDlA+Acg93fmf37u6rAFKY+9DePZSZEcGXxAl49Y6PaNqh1OZ6Jy4bMDXDmee/93AohhE4drFGvc2zQc8KdfQA6zsjDTELMM9JwJ4QQQggxS/sqO4ixhMxpvOu2Rcm8cNdmHrhpKS6Xwtd2neLanx/gYPX5b66fbFDT11ZnBUbDXZpVRw13cRMNdzofeacnpc39tPfb2VGcgsFg0Loc76h6CTB4PupIiCDnHitb1tpPdkIEKzJiNa7Iv9bnJWAyGii5wDFBUNnxXUhaDHu/Dy1vaF2NTzS4R8q+Z8ReYUo0Vy9dwJ4zNkqbvZTU4wNdg3Z+tqeKdGs4n92Uw5aCJMacLo6cDfIxb15W1jpAYlQoSdFhWpfifS0nISEfwmd/XiOE0E6UHxvu6rqGcCmQn+ynhjtvjZQtewZMoVB4pXe2B5CzBRZdC2V/h4Yjs3tvZyUk5IHR5L16gtRtm3MA+P1BPaTcfRgco+r4YiGEEFNSFIVDNV0sXhBNYpQOz6ncWt4EFGm4E2KekYY7IYQQQohZ6B4a4+2mXjYXJM15zF2Iycit67J47Svb+Py2PGo7h7j1oaN89o+vT/mE74l6teHOpwl3LteMX+oeKdvc42HDncEESUVz34Y3uJ8u723Qtg4xY6+UtwOwvUgn0fyOMah5DTLWqGMYhZjH8pOjyJ1IrvzAynT9NNXOUIzFzIqMWI7UdOFwzvxzOWCZw+Hm3wEG2HU7jA1rXZHX1XcNkRgVSlTY+8eBf8mdcvdq4Kbc/WR3JQOjDr5+zWIsZhNbCtX05gOVOmn69AKnS6GirZ+i1Bj9/U4a7obuWrkhJEQQigwLYcjuQFEunJbvDe5rFHnJPk4Xnxwp64WGu+FuqDsAuZeCxcvppDu+B8YQeOmemV9HGR9VH/Kb5+Nk3VZnxbFioZVdJ5roHhrTuhzPLLlRbex8669aVyKEEAGr2jZIx4Bd3+l2AM3H1VXOr4SYV6ThTgghhBBiFg5UdaAosLVw5uNkzyfaYuZrVy1mz79t5foVaew5Y+PKn+7n20+Xvuui44n6HpKjw8iYGOXqdS/eAz9fCW2lM3p5QmQooSFGWjxNuEssBLNl7tvwhsmRstJwFyx2l7UTF2FmVaZOklgaDsHYABTKOFkhDAYDN61MJ9Rk5MaL5tc4WbdNBUkM2B281RS4qWizkrocLr9XHaP28je1rsbrGrpHWBgfMeX3lqTFsr0ohZdOt1PeGnhjxiraBnjsaANrsuO4dlkqAIUpUaTEhLG/qkPj6gJHXdcQo+MuivQ4TtadPJm2Sts6hBCzFhVmwuFSsDt836DvbrjLT4r27Y7cjXHeSLir+Ae4HFB8g+fbeq/EfFhzuzqSu3TXzN7TXQsokCANd6Ae89+2KQe7w8WjR4J82kB4HBReBXUl0NekdTVCCBGQDtWoCeqX5CVqXImPNZ8AgxFSV2hdiRDCj6ThTgghhBBiFvZVqjcgt3ih4c5tYXwEv/joRTz5hUtYkRHLnw7Xs/W/9/K7/bX0DI1xpq2fVZlxvkvVOPMc9NbD76+C6j3TvtxoNJBuDZ/7SNmRXnV/Wo+TBYhKUZ9G7g3yi7zzRFPPMGWt/Vy6OHnOCZMBp/JldS3w4qgjIYLYFy7Np+TuS8lJ9HGKSoDalK9egL7QqPmgs+FLkL0Zjj8MFS9qXY3XDNkddA7ayTpPwx3AXZerKXcP7q32V1kzoigK9z1XhgLce92SyWNMg8HA5oIkqm2Dnj1YoSNlLWrjR1GqjxtNtNB8Ul0lgUGIoBNlUZNV/TFWtqZjCPBnwp0XHjoof0ZN1F90jefbmsrWr4LFCru/A+Mz+LzsrFTXxELf1BOErl66gLRYC386XI/d4dS6HM+s+AigwNuPa12JEEIEpEM1nRgNsC43XutSfKv5JCQXQ1iU1pUIIfxIJ3ephBBCCCF8z+VS2F/ZyeIF0SyI9X4y26rMOHZ9/hIe/NhFxIabeeCFci790Wu4FHXkhk8MdarNZumrwWiExz4EJx+Z9m1pVgvNPSNzG2HTflpdA6HhzmiE2IWScBck9pTbANihl3GyAFUvQXRaYPz3IEQAMBkNJEdrnH6qoZULrUSEmiip0lHDndEIN/0aLLHw9Bdh0KZ1RV7R0K2OyM1MOH8DwvIMK9sWJfHCqVaqbQP+Km1ae8ptlFR3snNVBssyYt/1vcmxspJyBzCZTlicGjvNK4NQy0l1LKIcgwgRdCInRpkPjvq+4a7aNki6NZyI0PePT/cqy8TvWU9Hyo72Q82rkLMZInx0Yz8iXm2662+CI/8z/es7J8bLy0jZSSEmI5/amE3noJ1n3mzRuhzP5O+A8Hh4+2/ghzHPQggRTJwuhcM1XSzLsBJjMWtdju/0t0J/M6RLergQ84003AkhhBBCzFBZaz+dg3avjJM9H4PBwHXL09j9b1u5++rFOJzqxbq1OT66UNx8Ql1Xfgw++wrEpMEzX4I9913wQmG6NZyhMSf9I3O4wN8+Mbp2wdI5FOwDcVlqw51cGA14u8vbCTUZ2ezD/wb9qqsGuqqhYAf4KsFSCBFUQkOMrM9N4GRDD0N+SK3xm9gMuO4nMNwJT39JF5+59V1qw92FEu4A7rysAEWBB18NjJS7MYeLB14oJyLUxFeuXPS+72/KT8RggP16avr0QHlrP6EmI7lJOkvdVBT1PCBlCZjnb5OzEMEqOsw/CXdOl0JtxyB5yX5IapkcKethwl3Vy+AcgyIfjJN9pzW3Q3wuHPjx9A8TdE003CXk+7amIPPhNZlEhpp4uOTs3B7mDBQhobD0Zug4A61vaV2NEEIElLKWfvpHHWzMS9C6FN9y32OR9HAh5h1puBNCCCGEmCH3ONmti3zf7GMxm/jc1jxe+8o2/nrHelYstPpmR+88GUxaBLftgbRVcOCH8OQd4LBP+bY0azgATb3Ds99n29vqmhIgaRrWTBgfVtP+RMDqHx3nSG0XG/ISiArzcbqCv1S9oq6FMk5WCHHOxvxEHC6Fo2e7tC7Fu5buhOUfUZM9j/9e62o81tCtjtjLSrhww93qrDg25SfyzFstnO0c8kdpF/Tnw3Wc7RziC9vySIl5f6NVfGQoy9JjKanqxOkK4pvfXlLW2k9BShRmvYyyd+tvgcF29bhfCBF0Iv3UcNfcM4Ld4SI/yQ8Nd5MjZT1MuCt7GjDA4us8LumCQkJhx/dgbBD2PnDh13ZWQnTquaZCAUBsuJkPrVnImbYBDtUE+XHv8o+o61t/0bYOIYQIMAdr1Ovtl+QlalyJj0nDnRDzls6uFgkhhBBC+M6+ig4iQk1cnOWjtLkpJEaFsT7Xh0+ANR0HUxgkL1H/PSoZPvU8LLoWTj0Oj9wMIz3ve1v6RMNdS+/o7PfZdkq92BwVICll1ix1lbGyAW1/ZQfjToUdxToaJ1v5DzCFQs5WrSsRQgSQzQXqheiSqiC/8TiVa/4LYjPhpW9AR6XW1XhkcqTsNAl3AHddXoBLgV/u1TblrmvQzs/2VJFuDee2zbnnfd3mgkT6RsY51exhylCQ6x4ao73fTnGqDhsk5IaQEEHN/QCSr9NwqzvUcej5/ki4m2y48+CzZ2wYqndD5gaI9sN54+LrIGsjnPwztJ+e+jWKoo6UlXGyU/r0JTkYDfDQgVqtS/FMxsWQXAwn/gR9TVpXI4QQAeNQTRehJiMXZ8dpXYpvNZ8AcwQkFWldiRDCz6ThTgghhBBiBvpHxznR0MMleYmEhujkEMo9Sip1hfp0tltoBHz4EVj3OagvgYevgJ66d701PU5tuGvumWXCnXMcbOWQEiDjZEFNuAPordO0DHFhu8vaAbi8KFnjSrxksAPO7of87RDmhxtYQoigUZAcRVJ0GAerdZi8aomFm38DTjs8eRs4xrSuaM7qu4YJN5tIig6b9rVrc+JZlxPPU28009A1h3RgL/nJ7koGRh18/ZrFWMym875uS4H6UMT+iXTn+aq8VU1ZKtJjw13LSXVNl4Q7IYJRlJ8S7qptg4CfGu5MIWCOBLsHCXfVu9X0+mIfj5N1MxjgygdAcakPE0w1FnWgTU3BS5CGu6lkJkRw5ZIF7K3ooLZjUOty5s5ggCvuA8cI7P6u1tUIIURAGHO4eP1sN6uyrBc8/wx6Lhe0vAGpK9XjGSHEvKKTu8VCCCGEEL51qFodq+WPcbJ+010Lo71TJ1sYTXD1f8JV/6E+jf3Q9nNJGLwj4a5vlgl3nVXgHIMFATJOFiThLgiMO128esbGsvRYUmPDtS7HO8r+rt6YWbpT60qEEAHGYDCwKT+RivYBbP1zSJINdFmXwKZ/hda34LUfaF3NnDV0D5MZH4HBYJjR6//l8gKcLoVf7dMm5a6ibYDHjjZwcVYc1y5LveBrL8qMIzLUxIGq+d1wV9ai44a7puNqY0viIq0rEULMQZTFvw13eUmRPt3PJEusZyNly59R16LrvVPPTKRdBCs+CrV71Ya/9+qcSPRNLPRfTUHmE+vVazK7TgZ5Mlz+dii4Qp0W0fi61tUIIYTm3mzsZWTcqf9xsl1V6gMD8jCTEPOSNNwJIYQQQszAvomEj60FOmq4m8koqfWfhw//L9gH4Q/XwpnnAVgQa8FggOaekdnts+2UugZSw12cNNwFutfruukfdbC9SEfjZEufhJBwKLxK60qEEAFoU756QfpgjQ5T7gC2fV29QV3yE6g/pHU1s+ZwumjuGSEzYfpxsm4b8hJYnRXHEyeaaO6d5fGThxRF4b7nynApcO/1xdM2CYaGGNmQl8jJhl76R8f9VGXgcSfc6W6krNOhngekr5IEBiGCVKSfRsrWdAwRF2EmIWr6NFevsMTMPeHOYYfKl9TrG7EZ3q1rOpd9Sz23e+kb6u/Yd5psuJOEu/NZn5tAujWcJ08243RNkRIYTK64HwwmePHuqRMPhRBiHjk0cT1jY36CxpX4mPseS8bF2tYhhNCENNwJIYQQQkxDURT2VXSQmxg5qxurAW/yZPACDXcARdfBp56D0Ej4661w5NeEhZhIigqb/Q3jtrfVdcHy2dfrK5FJ6sXxnnqtKxHnsbvMBsD2Yp2Mk+1rhoZDUHiljJMVQkxp40TD3YEqnTbcmcxw8+/AHA5PfU4dwRJEWnpHcbgUsuJnflxoMBi46/ICxp0Kv36txofVvd+echsl1Z3csjqD5RnWGb1nS2EiTpfCoeouH1fnZf0t6oMiXlDW2k+6NZzYCLNXthcwbKfVkYsL12ldiRBijiZHyo76ruFOURSqbYP+GSfrFhYz94S72tfUZr0iP42TfafYdNh4F3RWwMk/vvt7XRPJttJwd15Go4Gdq9Jp7RudbM4IWkmLYM1t0HwcTj2hdTVCCKGpQ9VdRIaaZnwOGrRmEmoghNAtabgTQgghhJhGtW2Qlr5RthTqKN0O1FFS4XEQlzP9azMuhtt2Q0I+vPg1ePHrLLSGzr7hrr0UzBEQP4N9+ovBANZMSbgLUIqi8Ep5G2mxFv0kzJx+Sl1lnKwQ4jwWxFooSI7iYHUnil7TMRILYOXHoLceBlq0rmZWGrqHAWb9IMaWgkRWZMTyt9cbaevzz7jgMYeLB14oJyLUxFeunPn40C0Tqc5BNVa2vwUeXANPf8HjTY05XNR0DFKUGu2FwgJM4zF1XbhW2zqEEHM22XBnd/psH52DYz7Woz4AACAASURBVPSNjPu34c4SA6N9c3tv2cQ42WINGu4ALrkLohbA3u+/+8/QWak+4Bfj59S9ILNztfr388SJIB8rC7DtbrBYYfd3YGxY62qEEEITw2MO3mjsYW1OPGaTzttRmo6rD/THLtS6EiGEBnT+G04IIYQQwnOT42QX6ajhzjGmps2lr1YbzmYiPgc++zJkbYQj/8O3Rv6LgYF+7I4ZXuRXFHWkbMoSMJrmXrsvuBvugixhZz6osg3S2D3C9uKUaUfgBY3TT0JoNBTs0LoSIUQA25ifSHu/nZoO76R1BaT4PHXtPqttHbNU3z0EQOYsEu7gXMrdmNPFb/b7J+Xuz4frONs5xBe25ZESY5nx+7ISIlgYH87+qo7gafp89QEYG4QzL8Bwt0ebqrINMO5UKNJLs/87uRvuMtZoW4cQYs4iJxvufDf2u9qmHn/kJfk54c4xAs5Z/rmc41DxPKQsg/hc39Q2nbAouPxbMNwFB3507uudVZCYD0a5FXchWQmRrM2O58XSNvpGgnycfUQ8bPs69DfB4Qe1rkYIITRxvK6HcafCJXmJWpfiW+OjasDAbO6xCCF0RY7yhRBCCCGm8VpFB2EhRjbkJmhdive0l4JzDNIvnt37IuLhE0/Bsg+ycvAAfw29n/aWGT6BPNCqXnxesGz29fqaNROcdhiyaV2JeI9XytoB2FGconElXtJ9Vh01sPhadZSiEEKcx+YCnY+VhXOJtz3B1XDX0KWmlWQlRM76vZctTmZJWgyPHW3ANuDblLvuoTF+tqeKdGs4t22eXQOCwWBgS0ESjd0j1HcFQTpL2yl481GwxIJrHMqe9mhz5a0DAPpJ132nxqOQUKAe1wshgpI74W7Ihwl31RMN//5NuItV19mOla0rgZEe7dLt3FZ8VL3eceRX0FOnppv1Naq/c8W0blmdgd3h4vm3W7UuxXNrPqv+/17yEzWBVwgh5pmDEyPCN+Tp6H7KVNpOgcsx+3ssQgjdkIY7IYQQQogLGB5zcOxsN+tyE7CYAyyVzRPNJ9Q1ffXs3xsSBjf9lrdzbmelsYbkx69Vn9qeTtspdU1ZOvt9+lpclrrKWNmAs7u8naiwENbl6OQCzekn1VXGyQohprEuNwGT0cDBah033LnH2vfUaVrGbNV3DWM0QLp19o3TBoOBOy8rwO5w8dAB3zYa/uSVSgZGHXz9msVzOo7dPDFWdn8wjJV95V51/chjEGKBU094tLnyVrXZQ3cJd4M2dYyzjJMVIqiZjAbCzSYG7A6f7aPGpkXD3cTvXPssx8qWT4yTLdK44c5ogiseUB9u3P0d6KpWv55YqGlZweKa5amEm008caJR61I8ZzLDld+H8WHY8z2tqxFCCL87XNOFNcKszweY3mnyHssqbesQQmhGGu6EEEIIIS7gSG0XY04XWwt1NE4WPD8ZNBqxrfkKXxu/ndChFnhoO9QdvPB73A13C5bPbZ++ZM1U1556besQ72IbGOXNxl62LkoiNEQnpy6lT4LFCrnbtK5ECBHgosJCuGihlSO13Yw7dTry3N3wHnQjZYdJs4bP+bPpiuIUFqVE88jheroG7V6uTlXRNsCjR+u5OCuOa5elzmkbl+SrTZ/7KwO86bN6N9S8Css/DNmboPAqqD8IfTNMYZ5CWUs/kaGmWY8NDnjucbLScCdE0IuyhDDkw4a7atsg4WYTabF+TOUOm7gpP5uEO5cTyp9Tm9qSF/umrtnI3QqLroHTT6nJqwCJknA3E1FhIVy9dAEnG3qpmUhYDGoFOyDvcnjrL+euwQkhxDzQNzzOqeY+NuQmYDTqfMxq83F1TbtI2zqEEJrRyV0rIYQQQgjf2FehJnrosuEuLhsiE+e8iTRrOH9zXsrfi36iXuR+5MYLp4m0nQIMkFI85336jNWdcCcNd4Hk1XIbigI7inQyTrajQh3nXHwDhIRqXY0QIghsKkhk0O7grcZerUvxDXM4RKcG1UhZRVFo7B72qBHLaDRw5+X5jIw7ebjE+392RVG477kyXArce30xBsPcbnLEWMxctNDK4ZpOxhwB2vTpcsLL96qpdpd9U/3asg8CCpTumtMmFUWhvK2fxakx+rtB1HhUXTOk4U6IYBcV5vuGu9ykSP/+HpwcKTuLhLvGozBk0z7d7p12fA+MIXD01+q/S8PdjN2yOgOAXSfm3jQfMAwGuPIBMJjgxXtAUbSuSAgh/OLI2S4UBS7Jn/t9h6DRfALi8yAiXutKhBAakYY7IYQQQogL2FfZQbo1nLykSK1L8Z6RXuisnNs42XdIj1OfdD9sWAmf+QdEJMKuz8KBH019IbHtFCTkQ2gA/l1Kw11A2l3ejsloYNsinTS8lso4WSHE7GyauEBdovexskGUcNc9NMag3UFWgmfJZ1cvTSUvKZI/Haqjd3jMS9WpXj1jo6S6k52rMlieYfVoW1sKkxgac/JGQ4+XqvOyt/4CttOw/vNgXah+rWCH2rRx6v/mtMm2/lF6h8cpSo32YqEBoul1NUEqKQBSoIQQHokMMzEw6puGu0G7g7b+Uf+Ok4VzDXf2WSTclU2Mky0OoIa7xAJYc9u5f0/I166WILM+N4F0azhPnmzG6dJBg1pyEVz8aWg8oqYeCiHEPHBo4vrFJXkJGlfiY8Pd0F0LGRdrXYkQQkPScCeEEEIIcR51nUPUdQ2zdVHSnJNBAlLLG+rqYcNdjCWEqLAQmntHYMEyuG03pCyFPd+DZ+8C5/i5F9sH1RPQBUs92qfPRMSDORJ6G7SuREwYGXNyoKqTNdlxWCN0kAanTCTtRCZD9matqxFCBIkVC61EhYVQUqXjhrv4HBjthZEAbeh6j/ruYQAy4z17gMBkNHDnZQUMjTn5/cE6L1SmGnO4eOD5ciJCTXz1qkUeb29zgdr0ub+qw+Nted3YMLx6P0QkwKZ/Pff1kDAo/oD6sIftzKw3W9aiNnoUpcZ4q9LA4BiD5pPqDSGjXBIWIthFhYUwNOabhrsamzrOMz/Jzw13sx0p63JB+TPqA3QLlvuurrnY+jW1gdCaFZgPHQYoo9HAzlXptPWPclAvD5xsuwfCYuGVb8P4iNbVzAsjY05Gx51alyHEvHWopouUmDByE3X++dd8Ul09vMcihAhucnVFCCGEEOI83DcWdTlOFiDds6evDAYD6dZwWnonLhjGpsOn/wF5l8PJP8NjHz53odxWBihqY14gMhggLksa7gJISXUndoeL7XoZJ9t2CrqqYMmNYDRpXY0QIkiYTUbW58bzRmMvA6Pj078hGMXlqGtPnaZlzFRDl9pw52nCHcB1y1PJTojgDwfP0u+l/3//fLiO2s4hvrAtj5QYi8fbW55hJTbczIFAbPo8/EsYaIWtd59LRXJb9kF1nUPKXXmrThvu2k6B0y7jZIXQiaiwEAZHHSg+GFNZ7W6483vC3cTv3Zkm3LWchP5mNd0u0B6SjIiHTz4DH/yj1pUEnZ0TY2Wf0MNYWYDIBNj2NehrUI9dhE+Njju54cESPv7QUa1LEWJesg2MUmUbZGNeor4CDKYyeY9FGu6EmM+k4U4IIYQQ4jz2VXQQYjToL/68+QQYTJDq+RPgaVYLLb2juNyjPiwx8LG/wapPQs0e+MPV0NcMbW+r3w+0p87fyZoJvY3gkqdgA8HusnYAdhTrpOGudJe6LrlZ2zqEEEFnY34iTpfC0dpurUvxjbhsdQ2SsbL1Xe6EO88b7kJMRr54aT4Dow7+5IWUu+6hMX62p4p0azi3bc71eHugJvFtyk/kVHMf3UPeHX3rkUEbHPwpxOepo9reK2sjRKepDXezbEYpbx3AYIDFC3Q2UrZx4sbzQmm4E0IPosJCcLgU7A6X17dd3aFRw91kwl3fzF5f9rS6Fn3AN/V4Km0lpK/Suoqgk5UQydrseF463UbfiE4eOFlzu3rMcuDHMNCmdTW69tv9tVTZBjle34Otf1TrcoSYdw7XdAGwQW/3U6bSfAKM5sANGBBC+IU03AkhhBBCTMHucHKopouLs+OItpi1Lsd7FAWajkPKEjCHe7y59LhwxpwuOofs575oMsP1P4fL74X2Unho+7kL4SkBOlIW1IY717hc/AwALpfCnjPtFKZEkZWgg/EDigKnn4SYdFi4TutqhBBBxj3Ss0QvY7XeK96dcBccDXcN7pGyXki4A7jxonQy4sJ5+OBZBu2ejQb8ySuVDIw6uPvqxVjM3ktT3VKYiKIE2M/ga/8BY4Ow/Tvqsed7GU2w9GborYem12e16fLWfnISIokIDfFKqQGj6RhgUEfKCiGCXmSY+jvK08+OqVTbBjEZDf4/F7PMYqSsoqjjZKPTJFlGh25ZnYHd4eL5t1u1LsU7QkLhygdgfAj23Kd1NbpV3zXEg3urCTWpt773B2JCsxA6d6habbi7JD9R40p8TFHUhrsFyyAkTOtqhBAakoY7IYQQQogpvH62h5FxJ1sLk7Uuxbv6m2HI5rUbbWlWtWmvuWfk3d8wGGDzv8POh2G4E87uh4hEiF7glf36hDVLXXvrta1D8GZTL52DY/oZJ9t8Qh1XvOQmMMopmBBidvKSokiJCQusZidvco+UDZKEu4buIeIizMR46YEM80TKXe/wOI8cnvsxSEXbAI8erefirDiuW57qldrcNhckAbC/ssOr252zjko48UdYuB6Krj//65Z/SF1nMVZ2eMzB2a4h/Y2TBWh8HZKL3j9+VwgRlKIsasPdkA8a7mpsg2QlRBAa4udzF/fvJ/sMEu7aTqnj6Iuul3MsHbpmeSrhZhNPnGjUuhTvKbwKcrfBm49CyxtaV6M7iqLwnWdOM+Zw8eMPrwBgX6Acuwoxjxys6SQ7IYJ0q+cP+ge03nr1noc0/Qsx78mZiBBCCCHEFPZV2gDYWpikcSVe1nRcXb10Mug+eW7pPc+YhmW3wCf+DhYrZG1QG/EClTVTXXsbtK1D8MrEONntehsnu3SntnUIIYKSwWBgU34S1bZB2vp0OBYpIl4dIddTp3UlM1LfNUymlxN/dq7KIC3Wwu8O1DI8NvvGCUVRuP/5MlwK3Ht9MQYvH2+lWcPJT47iQFUHyizHs/rE7m+D4oQr7r/wseWC5ZBYCKVPgnNmI+nOtA2gKFCcprOGu75m6G+CjDVaVyKE8JKoiRTOgVHvNtyNOVzUdw+Tl+TncbIAodGAYWYJd+XPqGvxDT4tSWgjKiyEq5cu4GRDLzUTI46DnsEAV35fXV+8Z9Yj78WFvXS6jb0VHdx0UTrXLU9jaXoMJVUdOF3y9yyEvzR2D9PUM8KGPJ2n24H6cDVIw50QQhruhBBCCCGmsq+yg6ToMIpSo7UuxbsmTwa9k3CXETeRcNc7fP4XZW+E/3dKTbsLZHHuhDtpuNPa7rJ2EqNCWZlh1boUz7mc6o3+uBxIu0jraoQQQWpTQQIAB/WYcmcwQFx2UDTcjYw5sQ3YyYr3zjhZt9AQI5/flkf30BiPHZ39ccirZ2wcqOpk56oMlvvos3NLQRLt/XYq2zW+6V1XAhUvQPGNsHCa5jGDAZZ9UE0eqN03o82Xt6pNHro7B2g6pq4y2l4I3fBVwl191xBOl0J+sgYNd0YjhEWDfQYNd2XPQGQSZG7wfV1CE7eszgBg14kmjSvxopQlsOqfoOHQuaZR4bEhu4PvPltGtCWEe64pAtRj157hcU41zyAxUwjhFYdq1OsVG/MTNK7ED5pPqquXpggJIYKXNNwJIYQQQrxHS+8Ile2DbC1M8npCiOaaT6pPjScWeGVzadMl3LlZYiAkzCv79Bl3wl2PjJTVUl3nEFW2QS5fnILRqIP//hoOw2AbLL05sBMehRABbePEE+L6HSubDX1N4LBrXckFNXSrDxhkJXi34Q7ggxcvJDk6jF/vq2V03Dnj9405XDzwfDnhZhNfvWqR1+ty21yo/gweqNJwNJfLBS9/E4xm2P7tmb1n2S3qeurxGb28rMXdcKezhLtGd8PdWm3rEEJ4TWTYRMPdHJJRL6TapjZW52uRcAdq6u3oNA0yHRXQWQGLrwWjyT91Cb9bn5tAujWcJ0826yul7NJvqD/nL38LxnWYXq2Bn++porVvlK9euYikaPXao3tiyX4ZKyuE3xys7gJgQ+58aLg7AWGxEJ+ndSVCCI1Jw50QQgghxHu4L8bobpysywktb0DaSq9dlE6OthBiNNDUM+KV7WnKYlUvevZKw52WdpfLOFkhhHiv5BgLi1KiKanuDIyRnt4WnwMoAZ8yW981BMBCLyfcAVjMJj63NY/OQTt/PTbzv4dHjtRT2znEF7blkRJj8XpdbutzEgg1Gdmn5U3L00+qx7Jrb4f43Jm9Jz5XTXYufw7GLpDIPKG8tZ+4CDMLfPh3qYnGYxAeBwn5WlcihPCSqDDfjJSdbLjTIuEOwBI7/UjZMvc42Q/4vh6hGaPRwM5V6bT1j+or5TkqCbZ8Rb32dPRXWlcT9CraBni45CzL0mP52Lqsya+vyoojKixE22NXIeaR4TEHr1XYKEqNISEqwB+695RzHFrehPSL1HReIcS8Jr8FhBBCCCHeY19lB0YDbMpP1LoU7+o4A+NDXo06NxkNLIi10NKrg4Y7gwGsWdJwp7Hd5e1YzEZ9/PfndEDZ05C0GJKLta5GCBHkNuYn0jEQACM9fSEuR10DfKzsZMKdDxruAD66NpPEqFB+va8Wu2P6lLvuoTF+truSdGs4t2+ZYQPaHIWHmliTE8exs92zSuDzmvFR2P1dNUVgy1dm997lH1KPgSteuODLXC6FM20DFKXG6CvlenwUWt+CjLWStiuEjrgb7obs3v2dXN2hHmfkadZwFzP9SNnyp9UH5rI3+6cmoZmdE2Nln9DTWFmAdf+sHv/u/xEMtGtdTdBSFIVv/b0Up6Jw/41LMb1jSoLZZOSSvATeaOihb3hcwyqFmB92nWiif9TBx9Zlal2K79nKwTEC6au1rkQIEQCk4U4IIYQQ4h3GnS5KqjpZsdBKXGSo1uV4V/MJdfXyyWC6NZxmPTTcgTpWtq9ZbZQSftc7PMbrdT1syk8iPFQHo4HO7oPhLjXdTm5wCyE8tLlAx2Nl4yca7rrPalvHNM6NlI30yfbDQ03csSWXtv5R/u/49DeWf/JKJf2jDu6+ejEWs+8/N7cUJGF3uDh2ttvn+3qfY7+FvgbY8mWIiJ/de5fcBAYTnHrigi+r7x5meMypv3GyrW+CaxwWrtG6EiGEF7lHyg7avdtIUm0bJDXWMtnQ53dhMRdOuOs+C22n1HGyJrP/6hKayEqIZG12PC+dbqNvREdNUyFhcMX9MDYAe+/XupqgtetkM8fqurl1XSYrFlrf9/0thUm4FDhYo8PzJyECiMul8HDJWawRZnauSte6HN+bvMfivVADIUTwkoY7IYQQQoh3eLOxlwG7Q3/jZAGajqurDxru+kbGGbTroEktLgsUJwy0aF3JvPRaRQdOl8KO4mStS/GO0ifVdcnN2tYhhNCFtTnxmE0GfY3UcovLVteewG64q+8aJizESHK070bk3Loui7gIM796rYYxh+u8r6toG+DRo/WszorjuuWpPqvnnTYXqMfH+/09mmu4Gw78EGIzYe0ds39/VDLkboPqV9RtnUd5q9rgobuGu8Zj6rpwnbZ1CCG8KtribrjzXsKdy6VQ0zGo3ThZUBPunHY1nXMq5RPjZItu8F9NQlO3rM7A7nDx/NutWpfiXYuvVVMaTz4CrW9rXU3Q6R0e4wcvlJMYFcpXrlg85Wvc13b9fuwqxDyz54yNuq5hbl2XSUSoRg37/jTZcLdK2zqEEAFBGu6EEEIIId7htQobANsW6aTh552aT0J0GsSkeXWz6XHhAPoYK2udiL3vkbGyWnilvB2DAS5bnKJ1KZ5z2KH8WUhdAYn5WlcjhNCByLAQLsqM40ht1wUbsYJSTAYYQ4Ii4S4zPgKj0XeppZFhIdy2OZfm3hGeemPqlDtFUbj/+TJcCtx7XbHfxp8WpUaTGBXGgSo/N33u/yGM9sHl94LZMrdtLPsguBxQ9vfzvsTdcFesu4a7o2AwQprcEBJCTyYT7ka99+Bbc+8Io+Mu8pI0bLgLm/gdfL6xsmXPQGg05F3qv5qEpq5Znkq42cQTJxq1LsW7DAa46gfqP790DyiKtvUEmf9+qYKuoTHuuaaI2Iip0y4XxkeQmxjJvsoOFPn7FcJnHjpQi9lk4JMbsrUuxT+aT6jXMKIXaF2JECIASMOdEEIIIcQ77KvsIC7CzLL0WK1L8a6xIbCV+eTJqzSr2nDX3KOjhrveBm3rmIfsDif7KjpYudBKkg+Tg/ymeg/Y+yTdTgjhVZvyExkec/JmY6/WpXiXKUT9DO6p07qS83K6FJp61IY7X/vkhixiw838cm8NDuf7myv3Vtg4UNXJzlUZU47P8hWDwcCWgkQq2gdo6ztP8pC3ddeq42TTLlJHtM/V4mshxHLBsbLlrf2YTQZtk528TVGg6XVIWQJhOvpzCSEmR74OeTFpvrpjEIA8TRPuJq7FTDVWtq8Zmo9D4ZXqSE4xL0SFhXD10gWcbOilZuJnVDcWLINVn4C6A3Dmea2rCRpvNvby2LEG1uXEc9NFFx5fuaUwida+UaptOvvZESJAlDb3cfRsN9cvTyMlZo4PRwUT+wDYyiHDuxOEhBDBSxruhBBCCCEmdAzYKW3uZ3NBEiYfJpdoovUtdVSql8fJgjpSFtSn4YOeNUtdeyXhzt+O1nYzaHewvUgH6XYApbvUdclN2tYhhNCVjfmJAJRU6XAsUlyO2nAXoOkTrX0jjDsVMhN833AXbTHzmY05NHQP8/Sb7x5zP+Zwcf9z5YSbTXz1qkU+r+W9tkyM5jrgr5/BPd8D1zhccT8YPbiMaYmBRVdD/UHonTohp6yln7ykKEJDdHS5tLceBttlnKwQOhQZagJgcMx7DXc1Ew0p+Vom3FncCXd97/9e+bPqWizjZOebW1ZnALDrxNTpv0Htsm+pqY0vf1NNyhcX5HQpfOOpU5gMBu6/cem0Sc/usbL7ZKysED7xcImaUv+ZTTkaV+InrW8Bik/usQghgpOOriAJIYQQQnjGfePQfTFGV5pPqGvGxV7fdJquGu60S7hr6Brm3qdLufMvb0yZZqN3u8vbAdhRrIOGu7FhqPgHZKyFuCytqxFC6MiKjFiiw0IoqfbzSE9/iM8BxwgMtGldyZQauoYByPJDwh3ApzZmEx0Wwi/3VuN0nWtCfORIPbWdQ3xhW54mCQKbCtSmz/3+GCvb+DqcfgoKr4bsTZ5vb9kH1dXdFP8OvcNjtPSNUpymt3Gyr6trxlpt6xBCeF2IyYjFbPTqSFl3epimSZ/ukbJTJdyVPwMh4ZC/3b81Cc2tz00g3RrOkyeb33VcpAtRybDl36HnLBz9jdbVBLz/PVLP6ZZ+btucS0FK9LSvX5cbT2iIURruhPCBtr5Rnn2rhQ25CSzV27Sg82k6rq7ScCeEmCANd0IIIYQQE9wXXzYXJmpciQ80nwAMkLrS65t2J9y16KHhzhID4XF+bbg73dLHnX95g20/3MufD9fz7Fst1HYO+W3/gUBRFHaXtZMZH0GBHsa4Vb0E40Oejb4TQogphJiMrM9L4K2mPvpHx7Uux7vistW156ymZZxPffdEw11CpF/2Fxtu5lMbs6ntHOK5t9WUu+6hMX62u5J0azi3b8n1Sx3vlRgVxpK0GEqqOnD58oa3oqhJLwYT7Piud7aZvwMsVjj1f+/7VnnrAADFqTpruGs6pq4LpeFOCD2KCjN7d6SsbZDYcDOJUaFe2+asTY6UfU/C3aAN6g9BwXYI9c9nsQgcRqOBnavSaesf5aAeHzxZ93l14sL+/4ZBaQw7H9vAKD98qYK0WAt3XZ4/o/dEhIawNjueY2e7GR13+rhCIeaXPx2uw+FSuG3zPEm3A/Uei8Hok3ssQojgJA13QgghhBCoIwn2V3awJC2G5Gj/p4X4XNMJSFp0bjyLF4WHmoiPDKW5RwcNd6Cm3PX4dqSsoigcqunkEw8f5dqfl/DsWy1szE/k0xuzAahsH/Dp/gNNWWs/LX2j7ChOmXYcSFAo3QUYYMmNWlcihNChzQWJOF0KR2q6tC7Fu+ImLtJ3B2jD3UTCnT9Gyrp9ZmMOkaEmHny1GpdL4ae7K+kfdXD31YuxmE1+q+O9Nhck0TM8TmnLFOP+vOXMc9B4BFb/k3oM6w0hoVD8AWgvhfayd32rrFVNUirSW8Nd41GITDrX0CqE0JWoMBODXm64y0+O0vaczJ1wZ39Pwt2Z5wAFij7g95JEYNg5MVb2CT2OlTVb4Ir71J/7vQ9oXU3AeuD5cgbsDr59wxIiQkNm/L4thYnYHS6O1Ors/EkIDQ3ZHTx6pJ7cxEguXZSsdTn+03wSkoogTAcPjAshvEIa7oQQQgghgNLmPnqGx/U5TnbQBn0NkO79cbJu6dZwfSTcgdpwN9ACjjGvb9rpUvjHqVZu/OVBPva7oxys7uS65ak8d+cmHvnsOm6ZuIBc2Ta/Gu52l9kA2F6kg3Gyo/1Q+bI6+i56gdbVCCF0aGO+msSru3SP+ImGu546Tcs4n4buIQwGyIgL99s+4yJD+cSGbKpsg/z81SoePdrA6qw4rlue6rcaprJlIg36gK/GyjrH4ZVvQ2gUbPu6d7e9/EPqWvrEu75crseGu7EhaCuFhetADw80CCHeJ8oS4rWGu65BOz3D4+QnaXwDeTLh7j0Nd2XPgCkUCq/0f00iIGQlRLI2O56XTrfRN6KzpGeAohsgayOc/BO0n9a6moBzqLqTp99s4fLFyVxRPLtrR1sL1Wag/ZU6O38SQkO7TjbRP+rgM5tyMBrnybnGQBv0N0H6Kq0rEUIEEGm4E0IIIYTg3DhZXTbcNZ9UVx+eDKZZLbT1jzLudPlsH35jzQLFpZ5Ae4nd4eSvxxrY8eN9fP7Rk5S3DfDx9Zns/fI2OIqS8gAAIABJREFUHvzYKpamqzcV8pKiMBqgYp4l3O0ubyc23MzF2XFal+K5ihfAaYelN2tdiRBCp3ITI0mNtXBAbw13AT5StqF7mNQYC2Eh/k2Wu21zDhazkZ/ursLpUrj3umLfJA+1vg0vfAX6W6Z96eqsOMLNpsnjZ687/gforoGN/w+ivJyWkHkJRKepY2WVcyNxy1v7WRBjIT5SwzGK3tZ8EhQnZKzRuhIhhI9Ehnqv4a7aNghAfrLWDXdTJNwNd0PdAci91Cep/SJ43LI6A7vDxfNvt2pdivcZDHDl99Xjkxe//q7jlPluzOHim0+XEhZi5Ds3LJn1sXBhShQLYizsq7T5qEIh5heXS+H3JWexRpjZuSpD63L8p/mEuqav1rYOIURAkYY7IYQQQgjUhrvosBBWZemg4ee9mo+rqw9PBtOtEbgUaO8f9dk+/Maapa69DR5vamB0nF/vq2Hzf+7l7idP0Tlo54uX5nHwa5dx/43LyEqIfNfrLWYT2YmRVLUPerzvYNHaN8Kp5j4uXZSE2aSD05PSJ8FgklFHQgifMRgMbMpPpLZjSD/psgChkRCZHJAjZRVFob5r2K/jZN0So8L4+Dr12OTmVemsWGj1zY6O/QaO/RZ+vUlNar2AsBATG/ISOFnf49VRhgCM9sG+/4DoVNjwRe9uG8BohGU71eO8xmMAjDtdVLUPUpQa7f39aalJ/fOxcK22dQghfCbaEsKQ3YHihcac6o4Aabhzj5R9Z8JdxT/A5YDiG7SpSQSMa5anEm428cSJRq1L8Y20lbDyVji7Dypf1LqagPG7A7XUdgxx52X5LIyf/fG4wWBgS2EiNR1DNPUM+6BCIeaXPWds1HUNc+u6TMJD/ftAmqak4U4IMQUd3NESQgghhPBM7/AYbzT0sDE/UR8NP+/VfAJCLJCyxGe7SJ8Yr9bco4Mb/3GeN9zZBkb5zxfPcMkPXuU//nEGgwG+cU0Rh75+OV+5cjFJ0WHnfW9hcjR1XUOMjjvnvP9gsrt8YpzsLEeCBKThbqjZA3mXQmSC1tUIIXRsU4GOx8oGYMJd7/A4A6MOsuIjp3+xD9x5WQFfujSfb15b7LuddNWAOUJtaHjsg/DyN8Exdt6Xby5IxOFSOFzT5d06Sn4Cw11w6Tcg1EcNjssmxsqeehyAmo5BxpwufY2TBWh8HYwhkHaR1pUIIXwkMiyEcaeC3eF50nyNbQhQU9c15U6wG+0797XyZ9SHmhZdo01NImBEhYVw9dIFnGzopaZDpw8qXv4tMEfCS9+44LHYfNHYPcwvXq0iNymS27fkznk7WyYmmshYWSE899CBWswmA5/ckK11Kf7VfAJCwiHZh+flQoigo8M7ykIIIYQQs1NS3YlLga2LdDhO1uVSTwZTV4DJ7LPdpFstALT06aDhzpqprj31s35rXecQX3/yFJv+cy+/eq2GpJgw/mvncvZ/9VJu35JLVFjItNsoXBCNSzk30kfvdpe1YzYZJi9+BrXyZ9VGhaU7ta5ECKFzFy1UE3nPtOlsBHlcjtps9c5UmwBQ360mYWiRcAcQG2Hmy1cu8u24064a9eGMz5WoI0gP/QL+cBX01E35cvfn9oEqL46V7WuCI7+C5CWw8mPe2+57LVgGiYvg9FPgHKe8Vf15K07TUcOdoqgJdwuWgzlc62qEED7iPr8c8kLaaHXHIGEhxsmH6TQTGgUG47mRsqP9UPMq5GyGiHhtaxMB4ZbV6vjCXSeaNK7ER6IXwOZ/g+4aeP13Wlejue8+e5rRcRf3fWApYSFzT9LalJ+I0QD7K7147CrEPHSqqY+jZ7u5fkUaKTEWrcvxH5cLmt9Qk0hN01/fF0LMH9JwJ4QQQoh5b1+FerFFFw0/79Vdqz4Z7uOo83SregNaFwl3sQvVdRYJd6ea+vjioye59Eev8ZdjDRSnxvCbT6xm979u5UNrFs7qouCiFHWcWZUtSJsoBjvg1Qeg+eT0L7U7OFzTxfrcBGIsvmsI9ZvSXWAKhcXXal2JEELn0qwWQowG6rt0NhIpPkddz9PkpZX6LjX1J3MOI6yCwmgfDNkgIV998ODT/4CN/099aOPXW6Ds6fe9JTcxknRruHdvWr56PzhG4YrvgdGHo4kMBlj+QbW5s2Yv5a3qMZeuEu66a9U/38J1WlcihPChcw13nqej19gGyU2KwmQ0eLwtjxgM6lhZd8Jd1cvgHIMiGScrVOtzE0i3hvPkyWacLs/HKQekDV+E2Ex47T9hyMtpwkHklbJ2dpfbuGFFGhvzEz3aljUilBULrRys7mTc6XkqqF649PrfkPCZh0tqAfjsphyNK/Gzrmqw+/4eixAi+EjDnRBCCCHmNUVR2FfZQUFyFOlWHaY/NJ9QVx+fDKZNJNw19476dD9+ERYFEYnQe+GEO0VROFDVwa0PHeH6B0t4/lQrWwuT+Osd63nqC5dw5ZIFGOdws6IwRR3hU9EWZAl3Lie8/hA8uBr2/5c6Em4aByo7GHO62F6kg3GygzaoOwD5O8ASq3U1QgidCzEZyYgLp6F7SOtSvCvO3XAXWGNlGycS7rI0Srjzua4adU3IU1eTGXZ8F27dpf7z45+E5/8dxs8d5xkMBrYUJlLXNUyDNxo/W9+Ct/4KuZdC/nbPtzedpbeo66n/o6ylH4vZSHaCNiODfaLxqLouXKNtHUIIn4qcaLgbsI97tJ0hu4Pm3hHykzUeJ+tmiTmXcFf2NGCAxddpWpIIHEajgZ2r0mnrH+VgtU7Hg5rD1WMxex+89n2tq9HE8JiD7zxzmuiwEL55bZFXtrm1MIkBu4M3G3u9sr1gNmR3cOdf3mDNA7uxDejgWq7wi9a+EZ57u5VL8hJYkjbPrn366R6LECL4SMOdEEIIIea1M20D2AbsbNVjuh1A83F19fHJYHxkKBazkeZeHSTcgZrucp6EO6dL4bm3W7j+wRI+8fAxjtR2c+PKNP7xL5v546fXsj43AYNh7qkA2YmRmE0GKtuDKOGu+QQ8dLl6M94cCRbrjJolXilvB2B7sQ4a7sqeBsUFS2/WuhIhxDyRmRBJQ/cwiqKjVIK4bHXtDqyGO3eSYFa8jhqy3mmy4S7/3V8v2K6OmM3erDbVP7QdOqsnv72lQD1+3u/pWFlFgZe/pf7zFfd5tq2Zis+BjLUoZ57nbIuNxQtitE918qbGY+oqCXdC6Jq3Eu5qO9QG/vykAGm4C4tVE+7GhqB6N2RugGgdnDMKr9k5MVb2Cb2OlQVYchMsXA/H/wC2cq2r8btfvFpNc+8I/35FIcleGlvpnmzinnQyX9V2DHLjLw/y7FstdA2Ncah6/qYoitn506F6HC6F2zbPs3Q7kIY7IcR5ScOdEEIIIea1fRNjsLYu0mvD3QmISDh3A9tHDAYDadZwmnt0MtouLgsGWsFhn/ySoig8drSBy370Gl967A2qbYP804YsXvvyNn76kYu8NobMbDKSlxQVHA13Iz3w3L/C7y6HtlNwyV3wpdchbaXaLHGBJhCH08XeMzaKU2P0kS5ZugvMEbDoaq0rEULME1nxEYyOu7AN2Kd/cbCID8yEu/ruYWLDzcRG6GD8+VS6Jpro3ttwBxCTCp98GrbdA7bT8JstahIdcEleIkYDHPC04a56N5zdBys/BguWebat2Vj2QQzjQ6wePaKvcbKgNtxFp0FshtaVCCF8yN1wN+hhwl11h3ruGVAJd6P96ufD+DAUyzhZ8W5ZCZGszY7npdNt9I149vMfsAwGuOoHoDjhpXsueH1Fb6raB/jd/lqWpMXw8fVZXtvuigwrseFmzx8WCWIvn27jAw8epKZjkNsnmqaOnu3WuCoRDIbsDh47Wk9uUiTbCpO1Lsf/mo+rE3GsmVpXIoQIMNJwJ4QQQoh5bV9FBxazkTXZ8VqX4n0Ou9oElb5avVDnY+nWcFp6R/WRtOM+ee5tnPzSi6Vt3PPUKfpGxrnr8gIOfu0yvvuBpSyM9/54uYKUaJp6Rhi0O7y+ba9wueCNR+EXF8Px30PWJWoCzhX3qSN543JgbBCGzn8R80R9Dz3D4/pIt+trgobDUHgVhOo0/UgIEXDc403rOnU0VjYySU1K7anTupJ3aega1u84WTjXcBefO/X3jSbY9jX4p2fVJoin/hn+/gViQ8ZYudDKoeouxp2uue3b6VDT7ULC4dJvzG0bc7XkJlwGEzeYDlKcGu3fffvSaD/YymScrBDzQJTF3XDnWcJdtW0QCKSGu1h1pGzZM+q/F12vbT0iIN2yOgO7w8Xzb7dqXYrvpK+CFR+Fmleh6hWtq/ELRVH41tOlOBWF+29cSojJe7exTUYDmwoSOdXcR9egjh5amgGnS+GHL1VwxyMnMIcY+d/PruMb1xaTFmvh9TppuBPT23Wyif5RB5/ZmINRT8ngMzE+Cm2lfrvHIoQILtJwJ4QQQoh5a9Du4Hh9NxtyE7CYTVqX431tpeAc81vUebo1nJFxJz3DOni6eLLhrn7yS6UtfQD89Y71/NuOQhKiwny2+0Up6o2OqkBMuWs/DX+8Bp7+gnqR4abfwqeeh+Sic69x37Dvrj3vZnZPjJPdUaSDhrvTT6mrjJMVQvhR5kTDd323TtJlQf1cic8JqJGyo+NO2vpHfdJgHzC6qtU0tOmaxrM3qQ32+TvgzUfht9u4Ka2XAbuDtxp757bvNx+FjnLY8EWITZ/bNuYqKonGuHVsNb7NsvgAfchhLppPAIqMkxViHoh0J9yNevY7rNo2iNEA2YkB8lkXFgMuB1S8oF7PkLROMYVrlqcSbjbxxInG6V8czC6/V03Tf+kecOrgets0/v5mM0dqu/no2kwuyozz+va3FiahKFBS3en1bQeqnqExPv3H13lwbzUrMmJ59s5NXJKfCMCanHiqbYN0D41pXKUIZE6Xwu9LzmKNMLNz1Tz8TG4vBdc4ZFysdSVCiAA0o4a7u+66i+zsbAwGA6WlpQCMjo5y4403UlhYyMqVK7nqqquoq6ubfI/NZuOqq66ioKCApUuXUlJS4pM/gBBCCCHEXB2q7mTcqbBtkU5j0JtPqKsfG+4AWnpH/LI/n7Jmq+s7Gu7quoYxGCA7wfcJZoUpaspKVfugz/c1Y/YBePEe+PVmaDwKa++ALx2HFR9+/9N90zTcKYrCK2XtpMSEsTRdByPcSndBaLTagCCEEH6SNfF51NClo4Y7gLhsNTk0QG4oNvWof79Zem24UxToqoGEvJm9PjIRPvY47LgPumu59dSn+ZhpD/srbLPft30Q9n5fHc2z8V9m/34v2Be6DbPByeLuvZrs3ycaj6lrxlpt6xBC+Jx7pOyQh8noNR1DZMZHEBYSIA8iWibOEceHoUjGyYqpRYWFcPXSBZxs6KWmI4CunXhbTBps+lfoqoLXH9a6Gp/qGxnngefLiY8M5atXLvLJPrYUJAGwr3J+jJUtbe7j+gdL2F/ZwUfXLuRv/7xh8votMDnxRVLuxIXsKW+nrmuYj6/LIjw0QI4V/GnyHssqbesQQgSkGTXc3XLLLZSUlJCVlfWur99xxx1UVFTw5ptvct1113HHHXdMfu/uu+9m/fr1VFVV8Yc//IFbb70Vh0NHT4sKIYQQIui5L65sLUzSuBIf8XPDXdrEBZumHj003LkT7homv1TXOURqjMUvaYjuhruKQEi4UxS1oezBNXDkl5C2Em7fC9f8N4Rbp37PZMPd1AlFNR1D1HUNs70oBUOwR/F310LLG1B0HZgtWlcjhJhHdJlwB2rDneJ812ewluonGhp1O1J20AZjA5CQP/P3GI2w8S74zEsYopL5vvlh1p78Moz2zW7fhx+EwTbYdve55go/e3xwGaOEYinfpcn+faLpGJjCIHW51pUIIXzM3XA34EHD3bjTRV3nUOCMkwU14c6tWBruxPndslpNWtp1oknjSnxsw5cgJgNe+wEM67cx6kcvV9A5OMbXr16MNSLUJ/tYEGth8YJo9ld24nIpPtlHoHjiRBM7f3UIW7+d/7h5GT+4efn7rmmuzZlouDur358r4bmHSs5iNhn45Ias6V+sR03H1TVNGu6EEO83o4a7LVu2kJHx7ohQi8XCNddcM3mDbP369dTWnkuwePzxx/niF78IwJo1a0hJSZGUOyGEEEIEDEVR2FfZQVZCBNmJvk8s00TzcYjLgYh4v+wuPU5PCXcL1XXiZr+iKNR3DfvtZ2VhfAQWs5FKrRvuOqvgkRvhic/A+Ahc91P47G616e5C4rLV9TwJd+5xstuLdTBOtvRJdV26U9s6hBDzTnioiZSYMBq6hrQuxbvic9S1p07TMtzcDXeZ8To9XuyuUdfZNNy5ZVyM4XMHeCNyM5vsB3D+egs0n5zZewfa4eDPIaEAVn9q9vv2gtFxJ2VdCqeiNkLD4YBp8vSIywWNr6vHaiFhWlcjhPCxKIvnCXf1XcM4XAp5gdRwZ4lV15Rl5x7mEmIK63MTSLeG8+TJZpx6bp4KjYDt34HRXjj+e62r8YlTTX08cqSeNdlxPh9ZuaUwic5BO+Vt/T7dj1bGHC6+9fdSvvx/bxEfGcrjn9vAR9ZmTvna/KQorBFmSbgT5/V2Uy/HznZzw4p0kmPm6YPGzSfU4xE/3WMRQgSXGTXczcTPf/5zrr/+egC6urpwuVwkJZ1Li8nOzqahYeoLVz/+8Y/JyMiY/N/goI7jn4UQQggREGo7h2jqGdFvut1ID3RV+y3dDs6NlG3WQ8OdORyiUqBHHSnbNTTGoN0xOb7P10xGAwXJ0do13I0Nw5774H82QO1rcNHH4c4TcPGn1VSb6YRGQHTa+RvuytqJDDVxSV6Cd+vWQumTEB4Hudu0rkQIMQ9lxUdSp7uRsu6Gu6lTUv2toVvnCXdd1eo6l4Y7gPA4yjf/km+Ofxr6m+HhK+DwL9WE3At57fswPgQ7vgsm89z27aGKtgFcCrRlqtczKdVByl1nJdj7IGON1pUIIfwgKtTzhrtqm3ovJj8pkBruJhLuJN1OTMNoNLBzVTpt/aMcrO7UuhzfKroejCFqwr7OOP8/e/cdHtdZ5n38O13SqI4kq/fiXuKaxC09tIRUYGGpoSwlEGCBhV3YZTewGxYSWAh5gQ0klCQsCckC2RSn4LgklltcZUuy1bs06nXa+8czo7jIqjNzZo7uz3VxPYktnXOjyNbMee7nd3t9/OMzxzAaDNx7y0qMxtBOQgg8C9bjWNm2vlHe9/PX+c0b9VxZkspf7t7CmrxLTKdA/RlaX+DgeEv/vMeTa8Lrgbo90N+qdSW69fBu9b78ri1FGleikWGnOqSWs17rSoQQESooDXff/e53qa6u5jvf+c7Er104Gso3xYO2L33pSzQ1NU38Lz4+gt7cCSGEEEKXdp7W+TjZwAO43PC9GcxMisFg0EnCHaixsv6kk7oulR5UGMbN9rKMeNr7x+gdHg/bPQE4/Rw8uAl2fR/SF8PHXoR3Pwj2tNldx1E8acNd9+AYBxt62Faejs0c+vG8IdVRCR0nYNm7NWsWEEIsbPmpcfSNuOgbdmldSvAEEu4uMZY83Oq7h7CajGTo9TT/fBvugK3l6fzWcz0/LvoZpBTAC9+Ax//m0iPPOirh0K8h/0pY/I4533e+KltVqkns0htU8/zRP2hWS9A0Vag1b5O2dQghwsJuU++n5jNS9kynv+EukhLuSq+H5bfB2g9rXYmIArf7x8o+qfexspYYSCuHtqNaVxJ0j1U0cLSpj7u2FLE4MyHk91tfmEKsxcRrkdxw53HBkd+rA7EztO9sN+/68W4ONfTyqW3F/PpjG0mNnz7xeGNRCh6vj8MNvfOpOLz6muGv98GPVsMj74CnP6V1RbrU2jfCs0dbubIklWXZidN/gh4F9ljCGGoghIgu8264+/73v88f//hHnnvuOeLi1AZkaqpKqujsfOvFSn19Pfn5k0fWCiGEEEKE286qTqwmI5cX6yBhazJNB9UaxjeDFpORjIQYfSTcASQXwFAHjA9PpAeFc/zw4gz1kLGqPUzpzz118Nj74PH3qYTEt/0HfHIn5M9xw9ZRqMadXLDZ/sqpDnw+uG6pjsbJLr9N2zqEEAtWgUM9h6l36misbFIeGEwRM1K2wTlMriMWU4iTNjTTfUZ9vVMK5nyJPEccxWl2ft+UjO8Tr8Kq90LVc/D/tkD96xd/wo5/Bp8XbrgXDNp9XU/6G+6W5KbCsltUE337Cc3qCYrGfWrN26htHUKIsDCbjMRYjEFJuIuokbJJOXDnryBBB+8ZRcgVpNrZWOjghRNt9I3o6BDKZDJXqoOhI1HUGDWNzoExvvf8KbKSYvjCtWVhuafNbOLyYgcH6noYjNRUt30/g6c/Ca/827Qf6vP5eHh3Le//730Mj7t58P1r+fo7lmI2zawFYEOhGpNZEeljZT1udUj4sffCD1eoxGyvWyWk1+3W1Z+LSPHo3nrcXh8f37pA0+1AjZMFabgTQlzSvBru7r//fh5//HF27NhBcvL5kbR33nknDz74IAD79++nra2NLVu2zOd2QgghhBBBMery8MbZbjYUpWC3mbUuJzSaD6pRE5krw3rbnJRYfSXcAfQ1Ut8dSLgLX8NdeWag4S7EY2XdY/Daf6pUu6rnYMUd8Ln9cPmnwTSPPx+OYrVekFC042Q7RgNcvWTRPIqOAD6fGj1nXwSF8j5HCKGNAn8jeL2exsqaLJCUGxEJd16vj8aekYnGRl3qroGUwnkntW4rT6e1b5Qz/Qa49Wfw7p+qBv5H3qleZ3g96gPP7oTqF2DF7ZCr7aZFZWs/iTFmcpJjYeWd6hePRXnKXeN+9Ro2IVPrSoQQYRJvMzM4Or+Gu4xEG4kxktgtotcd63IZc3t59qjOx0oGnvG1H9e2jiD69+cqGRh18883LQvrM9rt5em4vT5eP9MdtnvO2Pgw7Pmh+ueKX0x5EGl43M0XnniTf/vLSQoccfzvZzfzzlVZs7rdipwkYi0m9tdGaMNdbwO88h3VZPf4+6D6RSi7Af7mCbjnOFx5N/g8cPZVrSvVlaExN4/tq6c43c5V5VH+DHc+mg+C0RL2PRYhRPSYUcPdZz/7WXJzc2lqauK6666jtLSUpqYmvvzlL9Pb28vVV1/NmjVr2LTprfSL++67j71791JWVsZHPvIRfvOb32A263RDWwghhBBRZV+tkzG3V7/jZH0+9WYwYwVYYsN665zkWLoGxxl1ecJ635AIJL30Nkwk3OWHccO9PCMMDXdnXoGHroRX7lWJQh/6E9zxMCTO7uHcpCYa7t4aKzvq8rCruov1BQ4cduv876GltqPgPAPLbwVjlI/GFUJErUAjWINTRw13oMbK9tSp1zQaausfZdztpSCMDfdh5fWon9OpJfO+1NYyNXp+Z1WXSq277APwyb+q8fSv3Au/vQ0G2uDFfwKTFa791rzvOR9er4/K1gGWZiViMBgg/wpIzIVjT4HXq2ltczbshK7TkCvpdkIsJPE285wTmnw+H2c6BylJj6B0OyHm4B2rsoi1mHjyYKPWpYRWoOGj7Zi2dQTJG2e7+eOhZq5anM6Ny8N7WGCb/5nwzqqOsN53Rg78EoY61QEVrwtenjzlrq5riNt+upc/HWnhhmUZPPO5zZRlzH4kr8Vk5LL8ZA439jDujpDXwR4XnPwT/PZ2+OEqeO176mD5Vd9QTXbv/z0sfrs6KFx2g/qcqhe1rVlnnjzYRP+om7u2FGHUa9r7dAJ7LJkr1FhvIYSYxIw64B588MGJtLpz+aZ48JmRkcGLL8oPNyGEEEJEnp2n1dj7qxbr9HRWX6Mahbr0prDfOjtZNfi19I5QHO0P7QMJdz111HXFkpUUQ6w1fI1V2UkxxNvMnG4LQcNdfwu88A048TSYY9Wm9xV3gzmITXCBhruetxKK9p7pYsTl4bplOvizd/wpta64Xds6hBALWkGqarir69LRSFlQY4HO/lVtNMVr9zOjXoOG+7DqawTPOKSWzvtSlxenYjEZ2FXdyV1b/COH0hfDJ16B5/8BDj4C/7UWXENwxedUqp6GmnpGGBxzszQrUf2C0Qgrb4c9P1JjWQuu0LS+OQmMO8rbNPXHCSF0xW4zz3mMZmvfKMPjHkojaZysEHMQbzPz9hWZ/PFws76bSDP003A37vbyzWeOYzUb+fbNy9UBiDAqSrOT54hlZ1UnPp8v7Pe/pEC6XUKWSoweG4DjT8IVn4WctRMf9nJlO/f8/k0Gx9x85cbFfHp7ybyaojYUOth7ppvjLX2szU8Jxv+TuXGehUO/hsO/U8+2DSZY8k5Y9xEouWbyA6/JebBoOdTsUAdnjPMa7icAj9fHL/fUkhJn4bbLcrUuRzt9jeqZxLJ3a12JECKCyU8dIYQQQiw4f63qICsphjK9PlQObLblhH9MV06Karhr1sNY2WSVcOfrbaCue2iiqSFcDAYD5RnxVLUPTHnQZdaO/gF+skE12y15F3yuArZ+ObjNdqCaJeC8hLsdJ9XJ4euWZgT3XuHm88HxP6pUwNwNWlcjhFjAkuOsJMaYqddbwl2gGUvjsbINTtXIqNuGu+4atQYh4c5uM7OuIIU3znafn3RsiYWbfgR3/BIMRoh1qNcdGjvZ2g/AsuzEt34x2sfKNu5Ta568NhFiIYm3mRmaY8JdTccggDTcCV24Y51qCnnyYJPGlYSQPRUSc1TifpT75Z5aqjsG+exVpZqkSRsMBraVpdPoHJmYahERDv5KNfhs+ZJK1Lru2+o19I5vgc+H1+vjgR1V3PXoAUxGA49+dCOfvbp03glkm4ocANqMlXWPq2dsj94M/3UZ7H5AvYe45pvwpZPwvt9B2fVTT5cov0F93VoOh69uHXupsp367mE+sKkgrIfPI07TAbVqsMcihIge0nAnhBBCiAWl0TnM2c4htpenR87pxWALNNzlrg/7rXOSVbx6c48OGu6ScgEDrq5aBkbdFGrwALA8I4GeYRddg+Nu9YDDAAAgAElEQVTBuaDPp1JmLLHwN79XD60CSX7BFpMI9vSJhjuv18fLle2UpNujP/2wab865bj8Fjk5K4TQXEGqnYZI2iQKBoe/abtH64Y79XUNd9N92HSfUWsQEu5AjeYadXk5WN9z8W+uuB0+fwj+bhfEOYJyv/moDDTcZZ3TcJexAtKXqkMJnrmlRWmqsUIlF2es0LoSIUQYqYY7z/QfOImJhrtof38mBCptNyc5lj8easLjDeKhxUiTuRI6TqkmpSjV3DvCj16qpijNzqe2F2tWx3b/WNnXqjo1q+E848Ow259ut/ZD6tcylsHq90PdLoZOPM9dj+7nRy9Xszw7kT9/bsvEaNz5uiw/BbPRwP66MDbcddXAi/8E9y+FJz8K9Xth2S3wwafh82/Ctr+HhBmOGg6Mla1+IXT1LiAP767FYjLwoSsKtC5FWxOhBuHfYxFCRA/ZHRJCCCHEgrLT/xBle5AeSESkpoNgTYDUsrDfOidZbUi36CHhzmyDhCxcznoATU7clmckAFDVHqSxsl1VMNwFK98Di98WnGtOxVE80XB3rLmPjoExrlsW5el2IONkhRARpSA1jrb+0fNTxaJdICW1p07TMgIjZfN0m3AX5Ia7smk2LeMX+Q80aO9kaz8mo+H8VCeDAVbeASNOOPOKdsXNhdejNoRy1oHJonU1QogwstvMjHu8jLln/zqgplMS7oR+GI0Gbl+bQ3v/GLtrurQuJ3QyV4LXBV2nta5kzr79pxOMuDx8++blxFi0S8+6oiQVs9Ew8axYcwd/pcaoBtLtAq7+Bl6TjfanvsrO0+3csS6Xpz59ZVDfo8RaTazISWJ/XQ/eUDasukbV5I1fvRN+sg72/lgd2L3+X+FLlfCeR/2jY2fZvpC7EWKSoUoa7ubraFMvFbVObl6dw6LEmOk/Qc+aD4EtMWjvl4UQ+iQNd0IIIYRYUHZWdWIyGriyNE3rUkLD44bWNyHnMk2St7L9CXdNemi4A0jOx9zfCEBRWvg32xdnBrnhrn6PWguuDM71ppNSpEY6jPbzUmU7ANdH+zhZrwdOPKOaCbPWaF2NEEJMpK816mmsbCDhTvORssNkJsZouhEYUt01KhEtITsol1uWlUiq3cpr1ZG/yV3Z2k9Juv3i/7Yr71BrtI2V7TgJ44MyTlaIBSg+xgwwp5S7mo5BEmLMpCfYgl2WEJq4fSGMlc1cqda2Y9rWMUevnGrnxZPtvHNVVtDS2eYqIcbCuoIUXj/TPaem5aCaLN3O75mz8AvX2yj2NfDb9bX85x2rQvL+ZGORg74RF9X+9NOg6jgFz38d7l8Cf/w4NFXAijvgw3+Buw/B5i9A/Dy+H0xmKL1WPRMfaAte3QvQw7vVe/C7thRpXInGAnss2drssQghoof8DSGEEEKIBWPc7WVvTRdr85NJitVp8kPnKXANaxZ1nhBjITHGrI+EO4CUAmzjPcQxqknCXVmGShoIXsPdXrXmXxGc603H4R8N0lPLjpPtOOxWLstPCc+9Q6V+Lwy2qXQ7vY6lFkJElQKH+vlUr6exsrYEiEvTfKRsffcw+XodJwuq4S61JGgbCEajga1laVS29tMxMBqUa4ZC/6iLpp6R88fJBqQUQt4mOPUsjIVgszFUGivUmrdJ2zqEEGEXb1MNd4Oj7ll/7pmOQUoXxWOQ9zVCJwpS7WwsdPDCiTb6RqJwPPxMRHnD3e/eaMBsNPDNdy7TuhQAtpWnM+LycKCuR9tCDj7iT7f74kS6ncvj5V/+dIJ7fv8mv7fdjtuWwpX1D2Fwh+Z19oZCBwAVtd3Bu2jtLnj4RvjpJnjjp2BPhxu/C186BXc8DEVbg/dsrexGtda8FJzrLUAtvSM8e7SVzaWpLMue5L3SQtJZqfZYcmWcrBBiatJwJ4QQQogF42B9D0PjHn2Pk20+oNacdZqVkJ0cS7NeGu6S8wHINXROJAiFU3q8jZQ4C6fbgtBw5/NB3R5IXwr21Plfbyb8DXddDac41TbANUsWYTJG+WaOjJMVQkSYQENYXfeQxpUEWUqhpgl3fcMu+kZc5Ot1nKx7DHobVMNdEG31j5XdHcEpd6da1euqpZM13AGsvFNtrpx+LoxVzVOg4S5XEu6EWGgmGu7GZtdw1zM0TvfQOKXpMk5W6Msd63IZd3v5y9EWrUsJjeRCsCZEZcOdx+ujos7JqtwkMpMiY1Rl4Bnxa1qOlXWNwJ4fQnwmrP0wAAOjLj7wi308sreOjUUOnvj8jZiv/hoMtMAbD4WkjPUF6oBsRbCaD3sb4Yn3q5SwVe+Djz4Pn62AKz4bmueSpdcBBhkrOw+Pvl6H2+vj41uKtS5Fe80H1arhHosQIjpIw50QQgghFoyd/ocn28sXaVxJCEXAm8HclFja+kbxeH2a1RA0yQUArLD3Emc1h/32BoOB8owEqtsH8fnm+fXsrVcP5sI1ThYmGu7qqo8DcF20j5P1uODk/6qmxUVLta5GCCGAt0bKNuhppCyosbJDHTCuTSNh4OtZoNeGO2ct4IPU0qBedmtZGqDxpuU0Trb0AVM03C2/FQwmOPY/YaxqnpoqwFEC9jStKxFChJl9jg13ZzpVimfJImm4E/ryjlVZxFpM+h0razRC5gpoO6oOVkaR020DDIy62VgUpkOgM7AsK5G0eOvEM2NNHPgVDLbD1i9NpNv95NUaKuqcfPiKAn738U0sSoiB9XepQ0m7H4ChIKbQ+aXYrZRnxLO/1jn/Z5A+H/zpczDWD+/5Ddz2Myi4IrSTIuyp6vDJmVfBPR66++jU0Jibx/Y1UJxu13dYwUxFwB6LECI6SMOdEEIIIRaMnVWdpMVbWa7nSPTmQ5CYA4lZmpWQnRyLy+Ojc2BMsxqCxp9wtyKuV7MSyjMSGBhz09o3z5ERgXGyYW24KwJgoKUKq9k4sQkftc7uhBGnpNsJISJKRkIMVrNRXyNlAVLUzxB66jS5fb1TNfrpdqRsd41aHcFNuFuUGMOSzAR213ThjdDDF5XTJdzZ06DkGqh5GYYiN6lvwlAXOM9C3katKxFCaCDB33A3NMuGu5oO1XAnCXdCb+JtZt6+IpPDDb0T3+e6k7kSRvugr1HrSmZln39U6aYih8aVvMVoNLCtLJ1TbQO094dmVOuUJkm3a+0b4ZE9dSzNSuSfb1qOxeTfyjdb4Zpvqia2Xd8PSTkbCh209Y/S1DPPySUHHoazf4W1H4LyG4JS24yU3QDjA9DwevjuqRN/ONDIwKibu7YUYYz26STB0HRQ7bEkZGpdiRAiwknDnRBCCCEWhPb+USpb+9lWlq7fN41jg9BxEnLWalpGTnIsgC7GyvbZVONiqSX4J0dnqjwzAYDT7fMcK1u/R63hbLiLc+CNSSZusJ7NJakT6QtR68Qf1briNm3rEEKIcxiNBgoccfpMuAPNxsoGGhgLUu2a3D/kAg13QU64AzWaq2twnJOt/UG/djBUtvWTnmAjPcF26Q9a9R7weeDkM+ErbK5knKwQC1rgPdbAXBvuJOFO6NAd63IBeOqQTlPuMleqNcrGylbUOjEaYF1hitalnGeblmNlDz6i0u22fHEi3e6HO6oZc3v56tsWX/wMe/ltkH0ZVPwiJAeTNvqbIStqnXO/iPMsvPhNSMqDG74TpMpmKNDcV/1ieO8b5TxeH7/aW0dKnIXbLsvVuhztjQ1CZ6Wk2wkhZkQa7oQQQgixIEyMk12s40j01iPg82r+ZjBbRw13Z13JeHwGcg3ajZZYnKEa7qrn3XC3V6UFJWYHoaqZ64vNI9/QzvXLovxEoHsMKv8MWWsgNbhpQEIIMV8FqXE09Qzj9ni1LiV4UgrV2qNNw11Dt85Hyoaw4W5rmXq9vas68tLh3B4vp9oGLp1uF7D4HWCJg6N/CE9h89Hkb7jL26RtHUIITcTHzDHhrnMQq9lInl5/zokF7fLiVHKSY/njoSY8EZq4Oy8TDXfHta1jFnw+HxW1TpZlJ5IYY9G6nPNsLUvDYCD8Y2VdI2o8bHwmrFPpdtXtA/zhYCOXFzu4arKxnkYjXP+v4HXBy/8W9JI2FKqGu/11c2y483rgmc+Aaxje/SDEhHnKTOYqSMiCqhfCe98o91JlO/Xdw/zt5QXEWk1al6O9CNljEUJEB2m4E0IIIcSCsLOqE4MBtpRG+UjLqTQfVGvOek3LyElRDXctOmi4q+9x0Uoqqe52zWooz1CJA6fb5jEKpb9VnTAt2BykqmburDudLIOTa0ujPDmh5iU1tkPGyQohIlC+w47L45v/+PFIkqJxwp1ziASbmeS4yNoQDJruMxCTDHHBH+m1vjCFGItRm5SQadR2DTHu9rJsuoY7W7xqumt8A3rqw1PcXDVWgDUBFi3VuhIhhAbibWpjfC4jZYvT7Jj0OgFALGhGo4Hb1+bQ3j/G7prIOwAwb+lLwWCCtqNaVzJjZzqH6B4aZ2NhqtalXCQ13saK7CR213SFt0FzIt3uHrCoZ6n/+cJpvD742tuWYDBc4u/nom1qdOrxJ6H5UFBLyk6OJSc5loq5Nty98VM1znXjp6B4e1BrmxGDAcquh+5q9RxUzMjDu2qxmox88IoCrUuJDBN7LNJwJ4SYnjTcCSGEEEL33B4vu6u7WJWTRGr8FKOjol3zAcAA2Ws0LWNipGxP9Dfc1XYN0eRLxz7SrFkNyXFWFiXYqJpPwp0W42QBl8fLgYFkADLcbWG9d9Adf0qty2/Vtg4hhJhEQapKpwmMQdWFhEwwx4ZkVNJMNDpHyE+Nu/RGV7RznlHpdiH4/xdjMbGpKJUD9c5ZN4CEWmDM7dKshOk/eOWdaj3+ZAgrmiePS2205q4Do6RRCLEQTYyUHZ3537cj4x6ae0cokXGyQsdu94+VffKgDsfKWmIgfXFUjZTdV9sNvDWyNNJsL0+nd9jF0abe8NzQNQK7fwjxGbDuIwAcrO/hxZPtvG15JpflTzN297pvg8EIO74FvuA2CW4scnC2c4iuwbHZfWLnaZW65yiB6/4lqDXNStmNaq3eoV0NUeRIYy8VdU5uXpPNooQYrcuJDBGyxyKEiA7ScCeEEEII3TvS1EffiIvtk0Xx60nzIUhfArYZbCCGUHq8DYvJoI+Eu27VcGce64PRPs3qWJyZQHXHAN65nrSt36vWMDfcVdQ6qRpfpP4lmk+Wjg/B6efUqLbkPK2rEUKIi+QHGu6cQxpXEkQGgxorq8FI2TG3h5a+kYlGRt0Z7VdpGiEYJxuwrTwdl8c3sbkaKQINd9Mm3AGUXAOxKXAsghvu2o6BewRyN2pdiRBCI/G22Y+UPdM5iM8HpenScCf0qyDVzsZCBy+caKNvxKV1OcGXuRJ662EkTA1i81RRqxLTIrXhbpv/mfFrVWFKRDz4KAy2wZYvgiUWn8/Hfc+dwmQ08JW3LZ7+8zOWwZr3Q90uNZEhiAJjZQ/MJuXO44anP6VG3d7yEFg1fB9VfBUYLTJWdoYe3q3eb39sc5HGlUSQ5kMqPVzjPRYhRHSQhjshhBBC6N5O/zir7Yt13HA30A59jSrdQmNGo4GspFiaddBwV9c9jNOSqf6lt0GzOsoWJTDq8tLYM8fkovq9kJCtGhfCaMfJdup8GepfNGiYCJqqF8A1LONkhRARqzDVDkCDnhLuABxF6uevJ7wpaU09I/h8alSvLjnPqDWUDXdlaUAYNy1nqLJ1AKvZSFHaDP7bmq0q2bbjJLQdD31xc9G0X6150nAnxEIVaLgbnGXDHUCpJNwJnbtjXS7jbi9/OdqidSnBl7lSre0ntK1jBnw+H/vOOinPiMdht2pdzqQuy08m3mZmZ1VH6G/mGoHdD5yXbvfq6Q4q6py8Z30uJTNthr7qG2COUSl3Xk/QyttYpNL1Kmp7Zv5Jux+AlsNw5d2QvylotcyJLR4KN0PdbnWAVlxSS+8Izx5rZXNpKsuyZ3AgaSEI7LHkrNW6EiFElJCGOyGEEELo3s6qThJjzKzOTda6lNBpPqjWHO0b7kCNldXDSNn67iHGE9QYEnrqNatjcaZ62Ha6bQ5jZYe6obNSpduFcSyez+fjpcp2xhIL1S9Ec8Ld8afUqI5lt2hdiRBCTConORajQWcjZUE1invd0B/eUWCBxkXdJtx1BxruSkJ2i9JF8WQlxfBadWfI7jEXla39LMlMwGya4SPRwFjZY38IXVHz0Vih1tz12tYhhNCMfS4Ndx2q4W7GTR1CRKl3rMoi1mLS51jZQMNdFIyVbeoZoa1/NGLT7QAsJiObS1N5s7GXvuEQJyIG0u023wOWWDxeH/c9d5oYi5EvXFs+8+sk5cDln1GHQ448EbTyStJVY+T+mSbctR6Fnf8B6UtVE2AkKLsRPGNwdqfWlUS0R1+vw+P18fEtxVqXEhl8PtjzI/XPOfL+SggxM9JwJ4QQQghdcw6Nc7Spl61l6TPfWItGkdZwlxLLwJib/tHoHdvRN+yiZ9iFMZAKp2HCXXmGirCv9m+MzErD62oN8zjZ0+0DNPWMsH5ZOVjjo7fhbrQPqndA4RZIyNC6GiGEmJTVbCQ7OZZ6p94a7vxjbXrqwnrb+m6VhJDv0GvDXY1aQ5hwZzAY2FqWxtnOIZrmmtAbZJ0DY3QOjLE0cxbpDXmXQ1Kear73ekNX3Fw1VkDaYjX6VgixIFlMRmxm46wa7mo6BzEYoDhdp0muQvjF28y8fUUmhxt6qZnL85RIlhE9DXdvnO0GYGNRqsaVTG1beTpeH+yuCWFCs2v0rXS79R8F4JnDzZxuH+Cjm4vITIqZ3fW23AOxDnjlXpWcFwQGg4ENhSmcaOmb/meLewye+bT651sfAsss6w+V8hvVWi1jZS9laMzNY/saKEm3s71cx1OBZsrngxf/Cd54EPI2war3aF2RECJK6HjXWQghhBACdlV34vPpfJwsQPMBMMfComVaVwJAdnIsQFSn3NX5N9vtGf5TflqOlPU33M0p4a5+r1oLNgexoum9dLIdgOuXZ6qRgNHacHfq/9Sp2OW3aV2JEEJMqSA1jvruIXw+n9alBI/D33DnDO9Y8kDjou4b7hyhTTLY5t+42VUdGWNlK1v7AVialTDzTzIa1Uj5vkZofCNElc1Rfyv0Ncg4WSEECTFmhmbTcNcxSF5KHDEWUwirEiIy3LFOTS146pDOUu7sqZCYA21Hta5kWhW1KiltUwQn3AFsK1OvXV+rCmFC86Hz0+1GXR7u31FFUqyFv9s+h/TpmCTY/lUYaIE3HgpamRsKHXh9cKh+mrGyO++D9uOw9e8h+7Kg3X/eUkvAUaIO0Orp/XEQ/eFAIwOjbu7aUozRGL6JKBHJ54Pnvw6v/wTyr4C/fQqscihBCDEz0nAnhBBCCF3beVo9JNH1SS2vF5oPQ9ZqMFm0rgaAXH/DXUtv9DfcpWUVgNEMvdqNlI23mclJjqWqfS4Nd3sgLhXSFwe/sCnsqOwgIcasRoakFEFfkzr5Gm2OP6X++y+9WetKhBBiSvkOO8PjHroGx7UuJXgmEu7C23DX6BzGYjJMHCDQne4aSMgCW2hHCW4uScNgCPGm5SwEGu6WZSfN7hMD6QaRNla2yT9OVhruhFjw7DYzA6Mza7hze7zUdg1RukjGyYqF4fLiVHKSY3nmcLO+DqaAGivbeQrckf36v6LOSWFqHBmJEZJ+dgl5jjiK0+3srOoMzfeKaxR23Q/2RRPpdr99o57m3hE+e3UJSbFzfKa7/i5IKVTJeUPdQSk1MP53yrGyTQfUPTNXwba/D8p9g6r8RuhvhvYTWlcScTxeH7/cU0dKnIXb1uZoXY62fD547quw7yF1WP0DT4JtFge0hBALnjTcCSGEEEK3vF4fr1V3siQzIeIf6syL8wyM9UXMOFk4J+EumhvuulS6TUF6kjo1rGHCHcDizATOdg7h8sxinNlovzrtXHAlGMJ3WrGjf5Qjjb1ctXgRFpNRJej4vJp/DWdt2AlnX4Xiq9XpcSGEiGCFqSqNrcE5pHElQZScBxjCn3DXPUxuShwmPZ709/mg+0xIx8kGpNitrMpNZk9NF+7ZvH4JkUDD3ZLZJNwBZCxXKdInno6sDe3GQMPdJm3rEEJozm41MzQ+s4a7BucwLo9PGu7EgmE0Grh6STqtfaNR/YxqUpkrwTMOXVVaV3JJbX2j1HcPTzRwRbrt5em09Y9SHYoRxIF0uy0q3a5/1MWDr9aQlRTDh64onPt1zVa49lsw1g+7vh+UUpdlJWK3mibSCS/iGoGn/04dUL31ZxFzAPw8ZTeoVcbKXmTHyXYanMP87eUFCzvt1uuFZ78MFT+Hwq3wgT+E/FCaEEJ/pOFOCCGEELp1srWfrsFx/Y+TbTqg1tzIabjLSYn+hrt6f8JdQWocpBRAT72mYwjKMuIZ93gn6pqRxgrV6BbucbKVHQBct3SR+oXAyLpoGytb+SfwutUoOSGEiHAF/oa7+u5hjSsJIrMNknLDmnDn9fpocA7rd5zsUKfajEudw8iqOdhWlkb/qJsjTX1hud9UTrb2k5sSS2LMHDYEV94BIz1w5pXgFzZXTfvVGLHUMq0rEUJoLD7GzNCYZ0YfW+NvIilNlw1lsXCsyk0G4GgEvB4JqsyVam07pm0dU9hXqxLXNhZFxyHGbf4JKYGJKUHjGlVpcPZFsE6l2/1851l6hl188fry+Tc9LbtVjXSt+EVQDiuZTUbWFqRwuLGXMfckP19e/jforoar/xEyls37fiFRcCVY7FD1otaVRJyHd5/FajLywSsKtC5FO14vPPtFOPAwFG2H9/+PjJEVQsyJNNwJIYQQQrd2Vi2AcbIAzQfVGkEJd1lJKlGwuSd6G+7quodIi7eSEGOB5HwYH1AbrRpZnKHSWE63zeKUbf0etRZcGYKKLu2lynbMRgNXlUd5w93xp8BkgyXv0LoSIYSYVr5DPRzWVcMdqPFIYWx67xgYY8zt1W/DXfcZtYYh4Q7e2rTcVa3tWNlRl4cznUMsy0qc2wVW3KHWY/8TvKLmwz0GLYchdwMY5fGuEAtdvM3M4AxHyp7pVAe4SiThTiwgq/0Nd0caezWuJMiioOEukJC2KUoS7i4vSsVqNvJasF+7Hvo1DLSqdDtrHB39ozy8u5ayRfHcvjZ3/tc3GuH6fwWvC165d/7XAzYUOhh3ezl2YaNq3W5446eQuxGuvDso9woJsw1KroamCjXBQgDq78H9dT3cvCabRQk6ngg0Fa8X/vx5OPgIlFwD7/89WHX6/l8IEXLyREYIIYQQurXzdCdxVhPrC6Ljoc6cNR+EuFRIjpxTaTEWE2nxNlqiOOGurnuYglT/ybbkQrVqOBK13N9wV9U+MPNPqt8LtkTIWBGiqi42Mu5hd00XGwodJMX5E2QmGu7COxJwXgbaoHYXlF2v0mOEECLC5U8k3OlopCyAo0glsoVpk+S8hFs96q5Ra5ga7tbkJRNvM/NalbYNdzUdg3i8PpbOteEupQDyLodT/wdjIRgxNlutR9UIORknK4RANdyNe7yTpxBdQBLuxEJUuiieOKuJI006a7hLLgRrArQd1bqSS6qodZKdFEOufxJGpIu1mthU5GBfrZOR8Zklh07LNQq77z8v3e5HL1cz4vLwlRsXYzIagnOfom1QdiMcfxKaD837chsK1fP0irpz3oeNDcIznwFzDNzyEBgjfBxp2Q1q8kfNy1pXEjEe3q2ezd61pUjjSjTi9cCfPgeHfwOl18H7HgdLdPz9JISITNJwJ4QQQghdGnV5ONjQwxXF6mSibrlG1UnWnPVgCNIDmiDJSY6J2pGyfSMunEPjFE403OWrtbdes5pKF8VjNMyi4c41opox8y8P6wOww409jLu9E4k2ACRkqYdx0ZRwV/lnwAcrbtO6EiGEmJF4m5m0eCv1Tr0l3Pk3AsI0VrbB//XTb8JdeBvuLCYjV5ak8mZjL30jrrDcczInW/oB5t5wB7DqTnCPwOn/C1JV89C4T625G7StQwgREew2M8CMxsrWdA6SFm9763CUEAuAyWhgRU4Sx5v78XrDk5ocFkYjZK5QzwXDlAY9G92DY1R3DLKxyIEhwp5ZTmV7eTrjbi9v+Mfhztvh36h0u81fAGsctV1DPLG/kXUFKVy/LCM49wi47l/AYIQd35r398Rl+clYTAb2157TcLfjm+rZ6PXfhrTwvJ+Yl7Ib1Fr9grZ1RIiW3hGePdbKltK0+b0vilZej2oYffN36nvjvb8DywJN+RNCBI2Od5+FEEIIsZA1OIfnl2IRLdqPq3EBETRONiAnJZaOgTHG3V6tS5m1Bv84vsJAus1Ew512CXcxFhMFqXZOz7ThrumA+t4I8zjZfWf940KKz0mWNBpVw0Q0NdwFTgMXX61tHUIIMQv5jriJn2G6kVKo1jClpAYa7iZSbvWmuwYMprAmI28rT8frg701XWG754VOtqqGuzmPlAVYdisYzXA0AsbKNlWozdQIfA8ghAi/hJhAw93UY2V9Ph9nOgYpXaTTn3FCTGF1bhKDY27OdkVAUm0wZa6E0V7oa9K6kovs9yejbSxK1biS2QkcIA1KQrNrFHbdD/Z0WP8xAL7/4mk8Xh//8PYlwW9EzFgGa94Pdbug5qV5XSrGYmJlThIH6nvweH3qegd+CYVbYcMnglRwiCVmQeYqVbs3SImFUezRvXV4vD7u2roA0+08bnj6U3D0CSh/O7z3t9JsJ4QICmm4E0IIIYQu1XapcWCFaTp/kNx8UK0RuNmWnRSLzwdtfaNalzJrtYFxcoHvnxT/pnSPdgl3AOUZ8dR3DzPqmsFDovq9ai3YHNqiLlBR6yTW/1DuPI4idQrWM/UmUMToOAEJ2RCn85HUQghdKUy10z00zuA0G+5RxRFIuKsLy+3qu/WecHdGva4xW8N2y21l/k3Lau0a7ipb+0mwmec3zsyeCiXXwplXYEi7/y/4fNBYAYuWQYzODxcJIWbEblUNdwOjU//8b+8fY3DMTU39c90AACAASURBVOkiGScrFp5VuckAvNnYp3ElQZa5Uq1tx7StYxL7agMNd9H1XKVsUTxZSTHsDEbD3eHfwEDLRLrd0aZenj3aynVLF02MbA26q74B5liVcjfPJrMNRQ4GRt1U1zfB/94N1nh494PqYG20KL8RRnrUweQFbHDMzWMVDZQuimd7Wfr0n6AnHjc8/Uk49gdY8i54z6/BbNO6KiGETkTRT0QhhBBCiJmrCzTcpep0szQg8LAgZ622dUwix7+hGY1jZev93z9FgXSb+EwwWTVNuAMoz0jA4/VxtnNo+g+u360esGWtCX1hfmNuD4caelhXkILFdMFbDUcxeN3Q1xi2eubM44aOU+pksBBCRJF8/+ue+u4Z/JyIFmEeKVvvHCY9wUasNXzj2MPG61Fps46SsN42PzWOwtQ4XqvqxKfBuDOfz0dlaz9LshIwGueZIrLyTvB54MCvglPcXPQ1qbFkeRu1q0EIEVHiAwl341M33NV0qGSv0nRpuBMLz5o81XB3tKlX40qCLIIb7ipqnaTFWylJj67D0AaDgW1l6ZztHKLROY/0cPfYeel2Pp+P/3juFAYDfOXGJcEr+EJJOXD5p6HjJBx5Yl6X2uhvCjTv+IZqHLzxu28dSo4WZTeqdYGPlX2iooGBUTcf21w0//dE0cTjgqfuguNPwdKb4M5Hwnr4TAihf9JwJ4QQQghdqguMBF0ICXeO4ohM4cpOjt6Gu8D3T6BxAaMRkvIiouEOoGq6sbLucWjcD3kbwvoQ4VhTH2Nu7+SnlwMJRdEwVtZ5FjxjKjlGCCGiSMFEw52OxsrGJkNsSvhGynYPUaDXdLu+JvXzLbU07LfeWpZOc+/IRAp1ODX3jtA/6mbpfMbJBiy9CVLL4LXvqeZ8LTRVqDVXGu6EEEq8TTWJT5dwW9Oh3keWLkoIeU1CRJrclFhS4iwcadJZwl36UjCYoO2o1pWcp3/UxcnWfjYWOYI/NjUMti8OJDTPI+Xu0K/PSbezs6u6i71nurntslwWZ4b47+Et90CsA165F1xzfy67vsDBDaYDlLb8CUqvh7UfCmKRYZKzFuJSoepFrSvRzNnOQe7fUUVmYgy3rc3RupzwcY/Dkx+Fk8/Aslvgjl+ByaJ1VUIInZGGOyGEEELoUl3XEAk2M6l2HZ9YGnaC80xEjpMFyAk03PVEY8PdEA67laTYc96EJ+erkagaJLMEBB7ITdtw1/omuEfCPk42MC5k06QNd8VqjYaGu44Tas1YoW0dQggxS/kOddBAVw13ACmFYUm46x910TPseqvhXm+6a9SaGt6EO4Bt5f5Ny2CM5pqlylb1umlZMBruLDFwy0MqtfeZT6tU3HBr9DfcScKdEMLPblMJd4PTjJSt6fQn3MlIWbEAGQwGVuUmU9nSz7jbq3U5wWOJgfTFEZdwd6DOic/3VkJatNlckobRMI/Xrhek23m9Pu57/hRWs5Ev3VAe3GInE5ME27+mGv7eeGjOl0ny9XOf9Zf0Y8d3839BFDZPYjRB6XXQfgz6mrWuJuzG3B7ufvwwIy4PD7x3DTEWHSa5T8Y9Dn/4CFT+GVbcDrc/LM12QoiQkIY7IYQQQuhSXfcQBWlxUXmKcsZaDqk1Z722dVxCoOGuJQoT7uq7hyZSgiYk54NrGIa7tSkKKEy1YzYapm+4q9+j1oIrQ1/UOfbVOrGajaz2j2o5T6DhrqcurDXNSftJtcpIWSFElAn87Gpw6mikLKixsgOt80pnmIkGf6NigUOnCcndZ9SqQcLd5cUOzEYDr1V3hf3ela39AMFJuAOVIHzF59Rr8b0/Cs41Z6OxQqV0BF5bCSEWvHh/w93QNAl3ZzqGiLeZyUi0haMsISLO6rxkxj1eTrX1a11KcGWuVAdERyJnXG7gQObGolSNK5mbpDgLa/KS2VPTjcszhwbNQLrdlZ8Hq50/H23hREs/H7q8YOJ5acit/5g6uLT7ARia47PMZ79Eiq+Xb45/mAZXUlDLC6uyG9RavfBS7v7juVOcaOnn7mvKuKIkOv88zpp7DP7nQ3D6WVh5J9z6czCZta5KCKFT0nAnhBBCCN0ZdXlo7RulMFWnm6UBzYGGu8hMuEuOsxBnNUXdSNmBURddg+MUXfj9k1Kg1p768BflZzUbKU63c3rahru9YLSEtRnT7fFysM7JmrzkyU9LJuaqmqIh4a79hBrJkhaGU8dCCBFEqXYr8Taz/hLuAmPJQ/wzuMHpb7jTa8KdU7uGu4QYC1eUpPLq6Q6eP94W1nufbOnHaCC4o7uu/kf1OuGv//FWo344uEbUyLjcjdGZMCKECIlAw920I2U7BylJt+v7YKIQU1idqxqGdDdWNpDO335C2zrOUVHrJDHGzJJQj04Noe3lixgcc3O4YZaNjO4x1eQWlwYb7mLc7eUHL1aRYDPz2avD+DrcbIVrvwVj/bDr+7P//ONPwclnaMm+nv/1bqbC30QZlUqvVc/5qndoXUlYvXSynV/tqWNjoYPPXxP+94CacI3C7/8Wqp6DVe+DW38mzXZCiJCShjshhBBC6E5gk7koTe8NdwdVA1PmSq0rmZTBYCAnOTbqEu4C3z8FFzbcpS9Ra+O+MFd0vvKMBBqdIwyPX2IzxeuBhjcgZy1Yw9cwcKKln6Fxz+TjZEE93EgpiI6Gu44TkFYGZkl+EEJEF4PBQL4jTn8NdymBhrvQjpUNfN3yHDptuOuuAXMMJOZocvvv3rqSVLuVe35/mKNN4UtgqWzrpyjNHtzxSZYYuOX/nTNa1hW8a0+l5bC6p4yTFUKcIz5m+oa7vhEXnQNjlMg4WbGArcpVafxHGiMnCS4oAs8FI2Ss7PC4m2NNfWwscmA0Rm+D77byNAB2VnXM7hMP/wb6m2HzF8Bq54n9DTQ4h/m7q0pIsVtDUOkUlt0K2ZdBxS/AOYv3UgNt8OyXIS4N800PAAb210Vxw11sCuRtgrN/VQ2RC0Bb3yhfefIISbEWfvi+NZhNC6AlxDUKv/+ASjJc8wG45adqpLAQQoTQAvjbVQghhBALTW2XGqN2UcOUnvh80HQAMleoDb8IlZ0cS3PvCD6fT+tSZqyuW33/FKZdsNlecg1Y7HDiaQ2qekt5hjodXN0+OPkHtB9Xp1fDPk5WjafYNNW4kJQi9YDPO4dxHOEyNqjG3i6ScbJCiOhUkBpHa98IY26P1qUETyDhbjabRHMQGMWr24S77hpwlIBRm8eBeY44fv6h9Xh9cNejB8JyKGNwzE199zDLskMwAit3ndpIbX0T9vww+NefTGOFWqXhTghxDrvV33A3eumGu5oO9f6xVBruxAKWnmAjJzk2rI3/YRFhDXeH6ntxe31svNSBzCixKjeZ5DgLr1V1zfyT3GOw6/6JdLuhMTf/9XI16Qk2Prq5MGS1XpLRCNf/K3hd8Mq9M/scnw/+/AUY6YF3PcCirDzyHXHsr+sJba2hVn4DuIagbrfWlYScx+vjC08cpmfYxX/esYrscI0x1pJrBB5/H9S8BJd9EG7+iTTbCSHCQhruhBBCCKE79f6GqaILG6b0pLcBhrsidpxsQE5KLGNuL91D41qXMmOBdJuLRhJbYmHx26GpAnobNahMCTTcXXKsbP1etRZsDlNFSkWtE7PRwNqC5Et/kKMYPGMw0BK+wmar85RaM5ZrW4cQQsxRfmocXh809URXwuyUUgrVGuKEuwbnMHaridRwJ0+Eg3tMvX5MLdG0jLX5Kdz/ntV0DozxsUf2Tzv+cL5Ot/UDsDQrROPMrvq6SkH+633Qdjw09zhXY4Uah5V9WejvJYSIGgn+hLuhS6WgA2cCDXfp0nAnFrZVuUnUdAwyFOLXIMHWN+zi5p/s5qWT7Rf/pj0NErLV2PkIUOE/kLlxqgOZUcBkNLClNI1jzX10Dc4wFW0i3e7zYLXz37tq6Roc557ryoizajTWsmgblN0Ix5+E5kPTf/ybj0HV87DyPbDsZgA2FDqo7RqiY2A0xMWGUNkNaq1+Uds6wuAnr9Swr9bJh68o4IblmVqXE3rjw/DYe+Hsq7DuI3DTf2l2yEwIsfDI3zZCCCGE0J1AQpmuE+6aD6o1Z722dUwjx3+CrjmKNv3r/AmJFzXcAay4Ta0aptwtzgwk3F2q4W4PGIxqVEKYeLw+KmqdrMxNmvoBoqNYrZE8Vrbdv1kuDXdCiChV4FA/vxr0NFY2IRtMNpVAGkL13cPkp9oxGKJ39NUl9dSBzwuppVpXwrtWZfOVGxdzqm2Aux87hNsTuuTbky2BhrvE0NzAbFOjinze0I+W9fnUwY/MlWDV8fscIcSs2W3qPdjAVAl3nZJwJwSo1DKvD44392ldyqzsruniaFMfv9h1iecpmSvVAUK39gde99U6ibOaWJEdotdfYbS9PB2A3dUzSLlzj8GuByAuFTZ8nK7BMX7+2hmK0uy8Z31eiCudxnX/op4V7viWek15Kb2N8Pw/QEIWvON7E7+8sSgFgAPRnHK3aBkk5kLVC1N/DaJcRa2TH71cxdKsRL7+jqValxN640Pw2Hugdiesvwve+YA02wkhwkr+xhFCCCGE7tR2DZFgM+sznSRgouEuwhPu/A134RgZFix13UMkx1lIirNc/Jsl14ItUdOGu3xHHDazkdOTjZT1+VTCXeYqiAnfg83TbQP0j7qnHxcSFQ13J9UqI2WFEFGq0D8ONZD4qwtGI6QUhHSk7LjbS0vvCAUOnSYkd9eoVeOEu4DPXFXC7WtzefV0J/c+Wxmy+5xsVQcUloeq4Q7U6/Et96hUmV33h+4+PbUw1CnjZIUQF7GYjNjMxikTu2o6BrGajOTr9eecEDO0OleNmT8SZWNl99c5Aaioc9LeP0nKWOZK8IxDV1WYKzvfmNvD4cZe1hWkYDZF/xb0Nn/D3c6qzuk/+PBvob8JNn8BrHZ+8koNQ+MevnLjYixafy0ylsGa90PdLjVyczJeL/zpczDWDzf/GGJTJn5rQ6F63ldR6wxHtaFhMKixsj21b7030pmeoXG+8MRhbGYTP/6by4ix6Hyk6tgg/O5O9X298ZPwzh9Is50QIuzkbx0hhBBC6E599zCFaTpNJwloPgi2pIhIKZlKdiDhLqoa7oYnT7cDsMTA4ndAy6GQbvpPxWQ0ULoonqq2SRLuuqpguDvs42T3+ceFXD7duJCJhjttvnYz0nESrAmQnK91JUIIMSf5gYY7p44S7gBSiqC3HryekFy+uXcEr++tr5/uTDTcRcZrR4PBwL/ftpJNRQ4e2VvHI3tC89qgsrWfVLuV9ARbSK4/YfvXVLP+a9+D1hCNc2vcr9YwphgLIaJHvM3M0Nilf0ae6RykMC1OFw0wQszHitwkDAY40hRdCXeBRiefD5471nrxB2SuVGvbsTBWdbEjjX2Mu71smu5AZpTISIxhSWYCu6o78XqnSEVzj6mDF/50u0bnML/bV8/q3CTeviJCRnpe9Q0wx6qUu8neUx14GM7+FdZ+CMquP++3itLspMVbo7vhDtRoXVApdzrj8/n4ypNHae0b5dvvXq7/RNuxAfjdHWrSy6ZPw9u/p5oqhRAizOTdlRBCCCF0ZWTcQ2vfKAV63SwF8Lih5U3IuSziT23lpERXw93QmJvOgbGJdKBJRcJY2YwE2vpH6Ru5YGxZ/R61FlwZ1noqap0YDbCuMGXqD0zOVyMsIjXhzueD9hPq5K88pBFCRKmspFgsJoO+RsoCpBSq1I7+lpBcPpAIqNvknwhruAOwmo387IPrKEqz869/Ockrp9qDen2P18eptn6WZiWG/iDOxGhZHzzzmdCMc2vcp9bcDcG/thAi6tltZgYukXA36vLQ6BzW/+a7EDOQGGOhOM3O0ShKuOsfdVHZ1s/Vi9OJtZj4y9HIbbir8B/I3Djdgcwosr08na7BcU629l/6gwLpdld+Hqx2fvDiaVweH19725LIORCelAOXf1odND3y+Pm/5zyrGvGS8uGG71z0qQaDgQ2FDirb+ukfdV30+1GjaBuYY6D6Ra0rCbpfv17PS5XtvHtNNneuy9W6nNAa7Yff3g4Nr8MVn4O3/bs8xxVCaCayd2iFEEIIIWapwZ/mUpR2iYQyPeg4Ce6RiB8nC5CRYMNkNNDcEx0Nd3X+zfaCSyXcARRfDTFJmjbclWUkAFDdfkHKXf1eteZfEbZafD4fFbVOlmUnkhgzyRjec5mtkJQbuQl3A20w4pRxskKIqGYyGshLiZv4maYbjiK19tSF5PKN/teQuj200X1GvX6Ji6zNz+Q4K7/8yAYSYy3c/dhhTrZMsZE5S3XdQ4y6vCzLDuE42XNlXwZbvwztx2DXD4J//aYKiM+UFF4hxKRUwt3kDXe1XUN4fVCSLg13QgCszk2m0TlC9+CY1qXMyMH6Hnw+Nd70mqWLOFDfQ2vfBc/ZUorAGq9G3GtoX60Tq9nI6rwkTesIpu3TjZV1j5+XbneipY//PdLCtvJ0rixNC2OlM7DlHoh1wCvfAZf/e8jrUQdGXMNwy4MQM/lr5w2FDnw+9f0YtaxxULhVPT8dm2RySJQ60dLHd56tpCA1jntvWRE5TZ6hMNoHv71NHUba/AW44V5pthNCaEoa7oQQQgihK7VdanP5kiNB9aD5oFqjoOHObDKSmRhDy4UPAiNUffcMGjbNVlhyk3qI2X0mTJWdb3Gm2ig5fW7Dnc8HdXsgfSnYw7eZfqZzkO6hcTYWzvCejmJ1ctY3xSgOrXScUGvGcm3rEEKIecpPjaOxZ2TqsUfRJiXQcBeapu3Aa4ACh05fQ3bXqHS7CNyMKEqz8/MPrmfc4+WuR/fT0T8alOtW+lNIlmYlBOV6M7LtK5CxAnZ9H1qPBO+6Y4MqhTdvQ0T+NxRCaC/eZmbwEg13NR2DAJJwJ4Tf6rxkAI42R8dY2f3+MZ4bCh3ctCoLgGcvTLkzGtVrkLZjmj1vcXu8HKzv4bK8ZGxmkyY1hMK6whRiLSZeu1TD3ZvnpNvZ4vne86fx+eCrNy4Ob6EzEZME278GAy3wxkPq1974qUoK2/gplQB3CRv9Y4L3R/1Y2RvA64Izr2pdSVAMjbm5+/HD+PDx47+5jITpDkNHM49LJds17YctX4Lrvi3vjYQQmpOGOyGEEELoSiDNpTBNp+kkEFUNdwDZyTFRmHA3zffPilvVevyPIa5ocuUTCXeDb/1ib716YBbmcbJvnFUP2jYVO2b2CY5icA3BYEcIq5qj9pNqlYQ7IUSUK3DEMe720hakxqWIEEi4C1FKar1zGJPRQHZyTEiur6mxARhsj6hxshfaWOTgvttX0do3yl2PHmB4fPKmkdkIpOUtzQpTwh2ogxm3/FT989OfDt5o2eaD4PNC7sbgXE8IoTvxMdM33EnCnRDKqlyVvna0MUoa7uqcJNjMLM1K5KrFi7BbpxgrO9oLfU3hLxI43tLP8LiHTUUzfD4UJWxmE1eWpHKwvoeBC8epusfhtR9MpNvtPdPFzqpO3r0mmxU5EZryt/5jkFIIux9QSW8v/xs4SuC6f5ny05ZmJRJvM7O/Lsob7spvUGv1C9rWEST//KcTnO0c4qs3LmFVbrLW5YRW1fOq2W7jJ+Hab0mznRAiIkjDnRBCCCF0pb57gSTcJeZCQqbWlcxITnIsPcOuoGychlrdTBMSi7arEQwajZXNSY7FbjVxuu2chLu6PWoNc8NdxTknrWfEUaxW59kQVTQPHf6GuwxpuBNCRLfAaPRAapsuJBeoNUQJdw3dw+Qkx2I26fBRWSCRN4Ib7gBuW5vL568p5VhzH/c88ea8ExorW/uxmozhbzDJWg1b/14l5772veBcs6lCrXmbgnM9IYTu2G1mxt1ext3ei36vpnMQg0Ea7oQIWJqViNlo4EhTr9alTGvU5eFIYx9rC1IwGQ3EWExctyyDNxt7aXRe8Fo/c6Va246Fv1CgorYbgI1F4Zu6EC7bytNxe328fqb7/N+YSLe7G5/Vzn3Pn8ZiMvDl6yMw3S7AbFXNSmP98OjNKu3tlofUuNUpmIwG1hakcKSxj1GXJ0zFhkBKIaQthuod4L34Z2Y0eeZwM08ebOKqxenctaVI63JC78CvwGiGrV+WZjshRMTQ4VNEIYQQQixktV1DJMSYcditWpcSGmMD0FEJOWu1rmTGspNjAWjpjfyUu7ruYRJjzCTHTRO/b7LA0pvURmrn6fAUdw6DwUBZRgJV546Urd+r1jA23Pl8PvbVdrM4I2Hmf+YiueGu/Tgk5kBsitaVCCHEvASSWhucQxpXEkSWGEjIDknCnc/no8E5PH3CbbTqrlFraom2dczAF68v5+bV2bx4sp37nj81r2tVtg5QlhGPRYsmyq1fVpveu+6HlsPzv15jBRgtqplPCCEmEW8zA2q03IXOdAySkxxLrFU/Ix6FmI8Yi4mlWYkcberFp9H41Zk62tTHuMc7Mc4T4F2rsgH4v2MXpNxp3nDnxGw0sLZAfylb28vTAdh57lhZ97h6rRfrgA2f4PnjbRxp7OX9G/PJj/T3Fctuhey1qtnuys9D/swOdWwsTGHc4+VoU3SkQ15S+Q0qAbztiNaVzFld1xD/+PQx0hNsfP/O1RiNOm9A66mDM6/A4rdHTQiBEGJhkIY7IYQQQuhKXdcwhal2DHo95dR6BPBB7nqtK5mxnBTVcNcUBWNl67uHKEqb4ffPitvUqtFY2cUZCXQPjdM1OKZ+oX4PpBRBYnbYamhwDtPeP3beg99pBRruQpRQNGceN3RWyThZIYQuBBrHdJVwB2qsbE9d0C/bOTjGiMtDviPCN8bmKpBw54j8hjuDwcD37ljF2vxkfvbaWR6vaJjTdZxD47T1j4Z3nOy5zFaVFGIw+EfLjs39Wj6fGp2UvUY1ngohxCTibaqZ7sKxsh6vj7NdQ5QuknQ7Ic61KjeJrsFxWvpGtS5lSoHUuHOnCmwrTyPBZr54rOyipWAwQdvRcJYIqL9rKmqdrMxNIs5qDvv9Q60wzU6+I46dVZ1vNWm++Tvoa4Qr78ZtjuM/XziN3Wri7mvLtC12JoxGuO0XcM0/wVVfn/GnBb4Po36sbNmNaq3eoW0dczTu9nL344cZdnn44XvXkBZv07qk0Dv0a8AH6z6idSVCCHEeabgTQgghhG6MjHto6x+lME3H42SbDqg1Z522dczCWwl3kf0Qc3jcTXv/2MQYvmkVbIG4NDVWVoMT0WUZasOkqn0A+ltUA1vB5rDWsO+sesC2qXgWDXcphWqNtIQ75xnwjMk4WSGELuSmxGEw6LDhLqUIRnthpCeol23wf50k4S4yxFhM/OJD68lzxPJPzxxnd3XXrK9R2doPoF3DHaiUme1fg85K2Hnf3K/TXaO+53M3Bq82IYTu2P0Jdxc23DX1DDPu9lIq42SFOM/qXJXCdrQxssfKVtT1YDUZWZWbNPFrNrOJ65dncKy5j/rucxKtLbGQVq5Jwt3ptgH6R92zO5AZZbaXp9PUM0Jt15A/3e4HKt1u4yf4nwNNnO0a4uNbi6On+SmtFLZ9ZVYHOlbnJWM1GamojfKGu/zLwZYIVS9oXcmcfO/5Uxxr7uMzV5WwuTRN63JCz+OCw7+F5HwovkbraoQQ4jzScCeEEEII3aj3j00r0utmKUDzQTAYIWuN1pXMWK6/4a65N7I3/QNNCYUz/f4xmWHZu6HrNHScDGFlk1ucmQBAVduAJuNkAfb5H7DN6oGqJdY/EjDCGu7aT6g1Y4W2dQghRBDEWExkJsZMvDbSDUehWoM8VjbwGiDfodNDG901EJ8JtgStK5mx1Hgbv/rIBuKsJj79u4NUtw/M6vMDDXfLtGy4A9jyRTUGdvcP1ev4uWjcp9Y8abgTQlzapUbK1nQMAkjCnRAXWJ2nGu7ebIrchjuP18eh+h5W5yURYzl/JPRN/rGyF6XcZa6E3noYDe/Iz0AS3yYdN9xt84+Vfa2qE448NpFuN2KI44cvVZFqt/KJbcUaVxlaMRYTq/OSOFTfg8cb2eOYp2SyQMnV6vX50OwP92jp1VMd/PfuWtYVpHDPdeValxMep59TI4DXflilMwohRASRv5WEEEIIoRt1XWpTecYJZdGo+SCkLwVb9Dwsj5aEu8Cp4FklJAbGyp54OgQVTW1xhr/hrmNQw4a7borT7CxKmOV4M0cxdJ/VJBnwkgINdzJSVgihEwWpcdR3D7818kgPUorUGuSx5P+fvTsPb/wu773/1mJbXmTJ8u6R19nHY3syM54hCQmkhISQ0EKA0lKeBp6u0FPORWkp7fWcp7T0lHNalqc9beGcq2Vr4LQHCJQmBBJIICGL7dnsGc9kFo/lfRlLXuVF1vL88ZU8k8Tj0fKTftLP9+u6uL7Eln66Z0a25a/u7/0Z8sUa7gx4aCMSUZGy5bv0riRhu6rsfOkDR1gJhPjQV3uYWYo/lvV8tjTcWfKi0bJm+N5HYD2J18Mj3WqVhjshxBZiDXeLN2m42ykNd0K8yq6qEoryLfSNZLYxLREXJhZYWgu+Kk425s5dFTgK83his4Y7uL7HkSHdHh8mExzdpFajuH1nOVaziecvTsJz16fbffmFQaYX1/j9X9i18b3YyDqbXCyuBTcOuOSs3fcDkZyKlZ1aWOXj3+ql1Gblb3/lEHmWbdLmcfKrYLbCbR/QuxIhhHidbfKdWAghhBDbgSc2ocyokbILE7AwBjsO611JQooLrLiK81XkQhbzbMTJJfD8abgdSqrh3GMZbx6rtBfgKMy7PuHOXnc9rjUDxuZWGJ1dSS4uxNUMa/OaRwKmZPq82ryp2CanQ4UQhtfoKmZxNcjc8rrepWhno+HOo+llh6NN9w1GnJLsn1E/c3MkTva17txVwV++8yCjsyv81tdPsLoeiut+58cXqHPYcBTlpbnCOFS3wpv/GK69Aj/7b4nff6QbSt1QWqd9bUIIwyix3WLCnUTKCvEqFrOJg3UOzo7NE87SSV2x2M7OTfZdokHVtwAAIABJREFU8q1m7m+t5vzEAlevLV3/RKzhLoOxspFIhO5BHwdqSym1ZcFrrzQpKbBytKkM0+DPYH4Yjv0Wc6ECvvSzAepdhbz/eKPeJWZE7PnY48nxWNndb1Xr5dyIlQ2FI3zs387g8wf47+9ux11mwN9dNzPrgYFnYO8DYK/RuxohhHgdabgTQgghhGHEJtzFHQmaa8ZPqXXHEX3rSEJrXSnnJxZYD4X1LuWmknr+mC1w4J3gG4DJvjRVtjmTycTeajtTU2Nw7YKabmcyZezxN+JCWpJpuItGbGRTrOxUP5TvBmu+3pUIIYQmYs1jselthuCKNtxpHCk77FumoiTfmBMpvFfUmoMT7mJ+5VgDv/OmFk4Pz/GH3+q95ZvigWCYgWtLHKjTebrdje78GNQeghf+FkZPxH+/lTnVqCfT7YQQt1Ac/Rm2tPqahrtrS5QX51NWLL/nCPFa7W4HS2tBrs4s3frGOuiJTo070li26ecf3CxWdqPhLnN7VAPX/MwsBZI7kJlj7t5TyQP8XP1H+/v4x58OsLga5A/v20u+dXu85X6ksQyTyQANdyVVUHcYrjwDoew/pPbFn17hxQEvv3a8gQfaavUuJ3NOfR2IwJEP6l2JEEJsanv89BdCCCHEtjA448duU9PUDCn25pz7qL51JOFQvZNAMMzFyUW9S7kpjzfJ50/ru9SqQ6zsnpoS9geiMSEZjpONnbQ+1lye+J2zreFubRHmhqBa4mSFEMbRGGu482b3hNmEFJZBgUP7CXe+ZWPGyYI6FAA53XAH8Mf37+NtrTU83jfBF358acvbXpleYj0UYb/ecbI3sljhXV9S03S/9+H4o2XHTgARabgTQtySPdZwd8OEu0gkwpXpJYmTFeImOuqdAPRmYaxsJBKhx+Njf83Np8bdsbOcsqLXxMoWV6gEhAxOuIvtDx1PZn8ox7y5xc795h7Gi/czZqnjqy96OFBbyjvat88k4lJbHvtrSukenCWS4bQPze25X00DH+nSu5ItnfD4+MKPL7O32s5/eWgb7V2G1uH0o+BsgJZf0LsaIYTYlDTcCSGEEMIwhrzLNFcUY8rglK+MGjsJ1kKo3K93JQnrcKtNzDMjczpXcnND3mWaypN4/tQfV5uZOsTK7qm2c8z8ivqPpjdm9LG7rvpwlxWyw1mY+J03Gu60nVCUtOkLaq1u1bcOIYTQUKNLRaQPeQ004c5kAleTpj8/ltaCzCwFEouUzyUGmHAHYDab+ML7DtHudvA/nrnCd06O3vS25ycWALKr4Q6gaj+8+U9g5hI8+1/ju89Ij1ql4U4IcQvFmzTcXVtcY3E1yC5puBNiU7G9qr7R7NurGpy59dS4PIuZtx2s5eLUIpenbjjgWtOm9jkyNLUrloDQ2bT5JD4j2bfwEiWmVb4fuoP/7+lLBIJh/viBfZjNBt2LvoljzS5mltbw5PrvmrvvU+vlp/StYwvzy+v85389Q57FxN+//zZseRa9S8qci0/C0hQcfgTM0tIihMhO8t1JCCGEEIawEggxubBq3DdLw2EYPw11h9SEjBzTXu8AsnMTE9TzZ2J+dWMaUELMZjXlbm7oeuxvhsQa7lbynFCxJ2OPO724ytUZf/JxIRuRgFky4W4qOiWwShruhBDGsREpm+tvgrxWWRMsjEFwTZPLDUf/fuqNOuHOewVMZvX3luMK8y38068fpc5h45OP9fHyVe+mt7uQrQ13AHd8FHYcgZf+Hka6b3370W6w2qC6Lf21CSFyWiwW3X9Dw92Vayomc1elNNwJsZl6VyFlRXmcGc2+CXexuM7Opq33XR5qV9GS//HaWNlQQDX5p1kkEqFr0MfuqhLKSwrS/nh6M5/7FmFMfHnuMN8+NcrtLeXcvbtC77IyLva8jDVb5qzaQ1BcBZeys+EuEonwx9/pY2xuhU+9o5Xd1Xa9S8qsk19VE8Jv+7/0rkQIIW5KGu6EEEIIYQhDPhWX1pxMw1Qu8F6GtQX1Bl0OqrLb2OEszMqYDlBRcgDNFUk2bOoUK7vHCa0mD1ds7WrqT4bE4kLekGxcSIEdiiuzp+Fu+rxaJVJWCGEgjsI8yoryGPYZKFIWoKwZiMDcsCaXi/39NBq24W5ARfBY8/WuRBNVpTb++YOdFFgt/M6/nORqtJnkRhcmFijKt2Tnv6nFCr/0j2DOi0bLrtz8tuEwjJ6AutsM8+8nhEifko0Jd6GNjw1MRxvuZMKdEJsymUy0u51cGF8gEAzrXc6rdA/OAtDZvPXUuOPNLipK8nmib/x6vGdNtFE/A7Gyo7MrTMyvJn8gM5eszMHlp/BWHGOaMiIR+OMH9hk3aWULsedl7Hmas8xm2P1WuHZBs98vtfRo1zA/7J/kofZa3tdZr3c5mTXrgYFnYO8DYK/WuxohhLgpabgTQgghhCF4ZtSbpU3JNkxlu7GTas3RhjuAjnoHl6YXXxVxky083uib7clOSHQfBUcD9H8vo7GyLu9pLKYIL4f3Zewx4XrDXUobqq6W7Gm4mzoPBaXg2GabV0IIw2soLzbehLuNKanaxMrGmu6TmnKb7cJh1XCX43Gyr7W/tpT/8f7bWFxd5ze+doJZf2Djc5FIhAsTC+yrsWdvtFfVPrjnT9X0wWf+8ua3u/aKOnAjcbJCiDhsFil7RRruhLilDreDQCjMxcnFW984g3o8Pporiqmy27a8ndVi5oGDtQxc8/NK7M+QwYa7ruj+0PGWJA9k5pJXHodQgKIj78OWZ+ah9loO1Tv1rkoXVXYbTeVFG5MYc1osVvbSj/St4zUuTCzw6cfPU+8q5K8ebtt+jZ2nvg5E4MiH9K5ECCG2JA13QgghhDCEwZnYm6XScJetOtxOIhE4N5Z9U+42GjaTfbPdZILWd8L8CIz2aFjZLQy9AMCTCy2Ew5lr9Ou66qO6tCC15gRXCyzPwKrOz4dIBKb7oepARqcECiFEJjS6ipheXGM5kH3N7kkrizbczWrTcBdrSGwwYsPdwiiE1gzXcAdwz94qPvWLrQzO+PmdR0+yFlQTnSYXVpldXs/OONkb3fH74O6El/4Bhl/e/DYjXWp1S8OdEOLW8q1m8q3m10XKFuVbqHVs3bAjxHbW7lYNU72jczpXct3UwirDvmU6m7aebhfzYDRW9vG+cfWBsmbIL4HJvnSVuCEWKXrsFtG3hnD2W2DOo/jQw/zk42/ms+/t0LsiXXU2uRj2LTO1sKp3KanZeY+KLb2cPbGyy4Egv/+/TxMOR/i7X7mNUlue3iVlVmgdTj8KzkZouUfvaoQQYkvScCeEEEIIQxiKTihLOhI0242eUBGczga9K0naxibmSPZsYsZ4vBo0bOoRKzv0IqvmYs6suxmb2yKSTEOz/gAXpxY51lye2ulKV4taNZpQlLTFCViZlThZIYQhxRqjY1PcDKGsSa0aTrgrzLNQWVKgyfWyiveKWg3YcAfw67c38aE7m+ge9PEnj53dmG4HcKAuyxvuzBYVLWvJh+99BAKbfI3GDnHIhDshRJxKCqwsrb56wt3OypLtNxVHiAS01zuA7NqriqUKdMbZxNbZ5KLKXsATfRMqVtZshuqDasJdmlMYugZ9NJYXUWP0xt7FKRh8Tk1DKyxjh7MQW55F76p01RlNvYg9X3OWzQENt6t/381ek+vgz79/nivTS/zh/Xu5rSG+xltDufgkLE3BkUfU9zMhhMhi8l1KCCGEEIYwOOOn1GalrMiAJ77WV2HqnJpul8Mb5W1uByZTdp0ajhny+ikpsFJRkp/8RepuU00A/d9TEW7pFliGsZN4yw8Txpyx+JPuaFzE8VTiZOGGhjudY2Wnzqu1ShruhBDG0+BSDXeGipV1uMGcB7MeTS435F2mwVVkzGYE74Bay3fqW0ca/T8PHuAX9lXx2Kkx/uHZK1yYUK+Hsn7CHUDlHnjLfwHfADzz6dd/fqRbvbYsqcp4aUKI3FRSYN2IlF1YXWdqYU3iZIW4hSq7jTqHjb7R7EljiMV0Hotz38ViNvH2tlo83mX6x9XhA2ra1OHChbF0lcnk/CpD3uXtMd2u/7sQCUPbu/WuJGvE/t0NESu7534IroLn53pXwvd7x/m3EyPctbuC376rRe9y9HHyK2rq4KEP6F2JEELckjTcCSGEEMIQPF4/TRXFxnyzdPIshIM5HScLavN/d1UJvSPZs4kZ45nx01ie4pvtJhO0PgyL4zByk2gwLY2dgPA6kYY7ALg4laGGu0GtGu6ikYB6N9xN96u1ulXfOoQQIg2aopN/h43UcGe2qIm/GkTKrofCjM2tGDNOFgw/4Q7UG8x/96u3sb+2lM8+dYlvdg1jMsG+GrvepcXnDR+B+uPw8hdh6MXrH1/2gfey+pwQQsSp+IaGu4HpJQBpuBMiDu1uJ5enF18Vyayn7kEfVfaCjcMz8XhoI1Z2Qn2gpk2tk2e1Lm/DxoHMlvK0PUbWOPstyCuGPQ/oXUnWaCwvotJekPsT7kBNLgS4/CNdyxj2LvOnj52loqSAz//yIcxmA77PcSuzHhh4Bva+HezVelcjhBC3JA13QgghhMh5y4EgUwtrNKUSB5rNxk6oNccb7gA63E7G5la4trimdykbVtdDjM+vavP8yWSsbPRN2bIDbwbgcoYa7roGvbiK81N/4yY24U6DhomUyIQ7IYSBNcYm3Pn8OleiMVez2ohPcaLsxNwqoXBk4+/JcLwDYCmAUrfelaRVSYGVL3/wKFX2AsbmVmguL6Yo36p3WfGJRctaC6LRstGv1VicrLtTv9qEEDnHXmDdaBgauKa+n+yslIY7IW6lo95JOALnxvQ/IDq/vM7FqUU6m10JHQo93FBGrcPG433jKlY2Ew13g15AgwOZ2c53Ve3N7n8I8g36e0MSTCYTx5pcXJxaZH5lXe9yUlOxB5yNcOmptMcw30wgGOb3//U0S2tBvvC+DirtBbrUobuTX1PrkQ/qWoYQQsRLGu6EEEIIkfNiMWlNRp1OMnZSrXW36VuHBjrqnQD0ZVGs7Igv+vyp0OD5U9Ompsic/3cIh1K/3laGXgBrIcWNR6lz2Lg4tZTex0PFEp0fX+BYU2Ibv5sqLAObE3x6N9z1q0aEQqe+dQghRBpU2gsozLMYK1IWoKxZRf4sTaZ0mVgjYqNRX0N6r6g4WbPxt/9qHYX88yOdFOVbONJYpnc5ianYBW/5f9UhhJ/8hfrYSJda64/pV5cQIucUF1hYjDbcXZEJd0LErcPtAMiKWNkTQz4iERKOaTVHY2VHZ1foHZ2Hqv1gssBkX5oqha6rPmodNtxlhWl7jKxw7jtqPfgefevIQp1NZUQicHIox6fcmUwqVnZ+GK69oksJn3vqIr0jc/zum3Zy1+5KXWrQXWgdTj+qmh9b7tG7GiGEiIvxd9yEEEIIYXieGfVmaSw2zXDGToJrJxTl/onRQ9GGu96R7Gm4G5yJvdmuwfMnFiu7NPXqWDCtBQMw0gP1nWDNZ0+NnYHpJYKh1Cb93MpJzyzhCBxv0ei56GrRN1I2tA4zF6FaptsJIYzJZDLR4CoyYMNdk1pnPSldJvb30mDEKcnBAMwNqYa7baLN7eD5T9zDp995UO9SEnf8d6Hhduj6Enh+DiPdKrasSiLvhRDxKy6wEgiGWQ+FuTK9hNVsMm5TuRAaOhhtuOvNgsOhsZjWzgQb7uB6rOwTfeOQV6imdqVpwp13aY3L00scS3ASX86JRKDvW1Dogp3SAPRax5pVnHD34KzOlWhg9/1qvZT5WNkej4//+dxVDtU7+fh9ezL++Fnj4g/APw1HHtkWh8aEEMYg362EEEIIkfM8sQl3Rmy4W/aphiT3Ub0r0cTeGjv5VjNnsuDUcMz1CYkaPX82YmUf0+Z6m5k4A8EVaLwTgL3VdgKhMEO+9DZUdA2qjd9jWsWFuFpgceJ6fFqmeQcgFJA4WSGEoTWUFzE2t8J6mpuyM8rVrNYUp6QOR39uNhgxUnbWA5GwOrSxjZSXFGDLs+hdRuLMFvilfwBrIfz778HYKdhxGCw5Eo0rhMgKdpv6nuFfCzJwbYnG8iLyLPIWkBC3UmrLo6WyOCsa7noGfdhtVvbW2BO+76F6JzuchTzRN0E4HI2VnfXAqvZ7cD0e1WB1PNpwZVhT59RBzdZ3gSVP72qyzt4aO3ablR5Pjk+4A2h6I+QVweWnMv7QT55Vk9s/83Db9v65ffKrYLbCoQ/oXYkQQsRtG3/XFkIIIYRRbEy4M+J0krFTat1xRN86NJJnMdNaV0rvyByRSETvcgDweGMTEjV6s736AFTug/Pfh1BQm2u+1tALam28A4Dd1Woj9tLkYnoeL6pr0Eupzcq+mlJtLuhqUWuKE4qSNt2v1uocnIQjhBBxaiovIhSOMD63oncp2imLNtzNptZwN+T1YzbBDqcBY7C8V9RavkvfOkT8ynfCvZ9Sr4vW/VB/XOeChBC5pjhfNdz5/AGGvH6JkxUiAYfcTkZ8K/j8Ad1qWF0PcXZsnqONZVjMiU+NM5lMPNRey/j8KqdHZlXDHcBUv8aVQrfWBzKz1dlvq7VN4mQ3YzGbONpYRt/oHKvrIb3LSU2eDZrfBMMvw0pmm297PD7Ki/PZl0SjrWH4BmHgGdj7drBX612NEELETRruhBBCCJHzPF4/pTYrZUUGPGk4dlKtBmm4A+hwO5lfWc+aeLsh7zJF+RYqSwq0u2jrw7A8A57ntbvmjYZeBHMe7FCTD/dGG+4uTqWv4W45EOTs6DydTa6kNn43FWu40ytWNrbpLJGyQggDi8WlZsvPXU3EImVTnnC3Qp2zkHyrAbfHpOEuNx377Y0JxtQf07cWIUTOKYlOuDs7Nk84gjTcCZGA9misbJ+OU+5OD8+xHorQmUIT20PtdQA83jdxveEuDbGyXYNeyovz2VlpwMPPMeEwnPsOlLqh/g16V5O1OptdrIcinBnRf0JkyvbcB5GQavzKkKW1IP3j8xxtKjN2PPOtnPq6Wo98UNcyhBAiUQbcURRCCCHEduPx+mmuKDbmL6VjJ1VjlYEmcB2qdwJkRVQHwOCMn8ZyjZ8/6YyVDYfUacsdhyFfTeXbVVWCyQSXp5a0f7yoU0NzBMMRjrdoeHpZ94a78yqqoHy3Po8vhBAZ0BiNS0137HhG5RdBSXVKE+4ikQjDXj+N5QaMkwVpuMtVZjO858vw1k/DzrfoXY0QIseUFKiGu94RFR8pDXdCxK89ulfVN6p9/Gq8YrGcx5qS33c5uKOUBlcRPzg7Qbgqupc42adFeRsWVtc5P7HAsWaXMfdiY0a6YH4E2t6tXqOJTcWerz2DBoiV3fVWtWYwVvbM8BzhCHSm8HWf80LrcPpRcDZCyz16VyOEEAmRVwhCCCGEyGnLgSBTC2s0GjFONhKB8VNQ3arG2htER6zhbkS/TcyYtWCI8fkVmrWKk42p3KOaJC/8h9o00NLUOVhb2IiTBSjMt9DgKkrrhLvuQS8Ax5rLtbvoRsNdahOKkjbdDxV7wJqvz+MLIUQGxBrKhmb8OleisbLmlCLJvf4A/kCIBpcBX0MCeAegwAHFFXpXIhJlr4E7PwoWq96VCCFyTKzh7szILAC7KrdxNJ0QCTpQW4rVbKJXxyldPR4f+VYzbdFpe8mIxcpOLaxxYsYC9lrNJ9yd9MwSicBxo8fJnovGyR6UONmttLkd5FvNdHsM0HDnrIeqVrj8tJpwmAGxv7ej27nh7uIPwD8NRx6R5lYhRM6R71pCCCGEyGmxeLSmCgO+WTo/Cv5rapKZgTSVF1Fqs2bFhLsR3wqRCOlp2Gx9J6zMwtWfaXvdoRfV2vjGV314T7WdwRk/a8GQto8X9fKgj6J8CwfrSrW7aHEF5JfoM+FudQHmhlVDqxBCGFidsxCL2WSsCXcArmZY9qrv50mIvYZscBl4wl35TjDy1BEhhBCvUhxtuOsfVz8bd1YZcJ9EiDSx5VnYV2und3SeSCSS8ccPhsKcGprlUL2TAqslpWtdj5UdV7Gy0xc0PQzaFZ1kpumBzGwTWof+70LF3uvRvGJTBVYLh+qdnBqaJRjKTJNaWu25D5Zn1CH4DDjh8VGYZ6FVy/3WXHPiKyqB5NAH9K5ECCESJg13QgghhMhpnui0Fs0nlGWDsZNq3XFE3zo0ZjKZ6Kh3cm5snnWdN2Jiz5+mdMTJtT6sVq1jZYdeAJMZ6o+96sN7q+2EwhEG0zDBaHU9xJmROY40lmG1aPgrhMmkGib0mHA3fUGtVQcy/9hCCJFBeRYz7rJChr0Ga7gra1ZrkrGywz7189KQkbJrS7A0KXGyQgixzZTYVMPdWjDMDmchRfkyKVOIRLS7ncwsrTExv5rxxz4/sYA/EEopTjZmf62dlopifnB2knB1G4QCMHNJgyqVrkEvpTYre2sMPEXz6k/V4Z6298oBljgca3LhD4Q4P5HcYaissvt+tV76Udofaj0U5vTwHLc1OMnTcr81l/gG4eqzsPftYK/WuxohhEjYNv3uLYQQQgijGPTG3iw14Mnt2Em6OmNNuAPocDtZC4a5OJm+CNR4eNL5/CnfCbUdcOFxCK5pc81IRE24q2kH26tPPu6uLgFIy99p78gcgWCYN7Sk4fSyqwXmR7T7O4rXdL9aZcKdEGIbaHAVMexb1mVaR9q4og13STZtG3rCnW9ArdJwJ4QQ20osUhZgZ1WJjpUIkZsOuZ0AusTKdm9MjUu94S4WKzuztMZlc5P6oEaxssuBIGdH5+lscmExG7gR7Ww0Trbt3frWkSM6o8/b2PM4p7k7weaEy+lvuOsfX2BlPUTndo6TPfV1tR79kL51CCFEkqThTgghhBA5bWhGvVnabMSGu7FTkFcMlXv1rkRzHfXRTUydY2Vjb7Y3pyuSuPVdsDYPA89qc72ZS+qEbeOdr/tU7GTxpSntG+603Ph9HVcLEIHZIe2vvZWp82qVCXdCiG2gsbyIlfUQ1xYz3NycTmVNap31JHX34WjEriEn3HmvqLV8p751CCGEyKjiGyba7aw04B6JEGnWXu8AoHd0PuOP3ePxYTbB4cYyTa73UEc0Vna6Qn1Ao4a708NzBMMRjrcYuEEosAyvPK4SR1wteleTEw43ODGb1PM451mssOtemOiFxcm0PtSJ6N/Xtm24C63D6UfV7/bNb9a7GiGESIo03AkhhBAipw16/ZTarDiL8vQuRVvhMIyfgbpDYLboXY3mOtxqE7NvJPObmDfyeP3Y8sxU2QvS8wCt71KrVrGynp+rtfGO132qpaIEq9nEpaklbR7rBl2DPgqsZtqj/26aim1e+q5qf+2tTJ+HAgc43Jl9XCGE0EGjS73p7jFSrGyqkbLeZVzF+dhtBnsNCeCNTbiThjshhNhO7LbrDXe7ZMKdEAnbVVlCYZ6FvgwfDo1EIpzwzNJa53jVpMpU7Km2s7uqhG9eshDJK4bJPk2u27VxIDMNCQjZ4tIPIbCk4mRFXOy2PA7UlXLCM2uMqeq771Pr5afT+jDdgz4sZhO3NTjT+jhZ6+IPwD8Nhx8Bs7SsCCFyk3z3EkIIIURO88z4aa4oxmQyWIyB9zIEFqHuNr0rSYuqUht1DpvuE+48Xj9N5Wl8/pQ1qROxr/wA1ldTv97Qi2ptuP11n8q3mmmqKNZ8wt16KMzJoVlua3BSYE1D86ceDXeRCEydg+oDYLTvHUIIsYmG6BS3oWiUuiEUV0B+SfKRsr5l6o0YJwvXJ9y5pOFOCCG2k+IbGnV2VUrDnRCJslrMtO1wcHZ0nnA4c01DA9f8eP0BzadcPdReh3c5yIJjr5pwp0EjVNdVL0X5FlrrSjWoMEud+w6YzNcP0Yq4dDa58PoDDFwzwO+cu+4FTGmNlY1EIpwYmqW1rvRVP7+3lRNfAbMVDv2a3pUIIUTSpOFOCCGEEDlrORBkenGNpnTFgepp7JRadxzWt4406qh3cmlqEf9aUJfHDwTDjM2u0JTuOOLWd6nmySs/Tu06kYhquKvcD8WbnyTeW21n2LfMSiCU2mPd4OzYPCvrIY6n6/RyrOEuyQlFSVkYh9V5iZMVQmwbsdjUWIyqIZhMaspdEj8/lgNBri2u0WjkhruSarAZ+I1QIYQQr1NccP2AlEy4EyI57W4Hi2tBrs5krmmoe2NqnDZxsjEPttcC0B9uhJVZWBhL6XprwRCnR+Y40lhGnsWgby+vzMLlp6DpLrDX6F1NTjkWbRg1RKxscTm4O2HgpxAMpOUhBq758fkDHG3cpnGyvkG4+izsfTvYq/WuRgghkmbQV0RCCCGE2A48M+pN48Z0N0zpYTzacFdn7Ia7cATOjekTKzsyu0w4Ao0VaX6zXatY2VkPLI5vGicbs6faTiQCV6a1i5WNbfweb07TBlBJDVhtmZ1wN31erdXScCeE2B4aXLEJdwZquAMoa4T50YTfBIk1HsYaEQ0lElENd+W79K5ECCFEhhVYLeRbzJQV5VFeUqB3OULkpPZ6Fe2YyVjZWIPSUY0n3O2qKmFfjZ2nfVXqA5NnU7pe3+g8gWA4fftD2eDCf0AoIHGySYg9f3sGDdBwB7DnPnWAevjFtFz+RPTrvrNJ20bbnHHqa2o9+iF96xBCiBRJw50QQgghcpYnGovWnO6GKT2MnYRCl4okNagOt9rE1CtWNharl/YJdw431B+Hiz+EQAqNDrE42S0b7tQUg4saxsp2XfWSZzFxW0OaNoDMZjWhKJMNd1P9aq1qzdxjCiGEjoryrVTZCxgy0oQ7AFczRMIwP5LQ3YajjYcNRpxwt+xVU1zLJU5WCCG2oxqHjYM7HHqXIUTO6nCrr5++0cwdDu0e9NFSWUxFGhpl39FRx8k1t/qPFBvurk/iSyEB4dpFOPNNTeJt0+Lst8GSD/vfoXclOafSXkBLZTHdRphwB7D7frVeeiotl+/xzALaN9rmhGAATj+q3vdofrPe1QghREqk4U4IIYQQOcuTqYapTAsG1CbYjsPKbNjdAAAgAElEQVQqLs2g2twOTCboHdFnwl1sQmJGnj+t74J1v4qlSFY8DXc1dgAuadRwFwpHOOGZpd3tpDDfcus7JMvVAnPDEFpP32PcKNZwJxPuhBDbSGN5EcPezEVjZURZs1oTjJW9PuHOYK8hQU23A5lwJ4QQ29Q3fvM4n/vlDr3LECJnNbiKcBblcWYkM4dDx+dWGJtb2Yjj1NqDbbVcjNQTxgyTfSld6+WrXvKtZtrdSTb1RiLw2G/B9z4Ml36UUi1psTgJg8/B7vug0Kl3NTnpWJOL0dkVJuZX9C4ldTVtYK9NbS93Cz0eH80VxVTat+FE2os/AP81OPyIOogthBA5TL6LCSGEECJneWYM2nA33a/iCwwcJwtQUmBlV2VJxjYxX2ujYTMTExIPvBMwpRYrO/SCaiworbvpTRpdReRbzZo13F2YWGBxLZj+uBBXM4SDCU8oStr0eXDUg00mPwghto8GVzGzy+vMr2SouTkTXNGGO19iDXdDRp5w5x1QqzTcCSHEtlTvKqLKbtO7DCFylslkot3t5PzEAoFgOO2P17MRK5mefZemimJ276jgKnVEJpKfcBcMhTk5NMuheie2vCQPZF75CUz0qv//w09CcC3petLi3GNABNreo3clOSv2PO42QqysyQS73wrey5qnckwtrDLsW+Zo4zaNkz35VTBb4dCv6V2JEEKkTBruhBBCCJGzPN5lHIV5lBXn612KtsZOqnXHEX3ryICOeidjcyvMLGV+k83jXabAaqY6E29GlNaqyXSXnoK1pcTvvzCupvc03rnlzawWMzsrS7g0qU3DXddGXEi6G+5a1JqJWNnQuoowqZLpdkKI7aWxXDWXxeJUDWFjwp0nobsN+dRrgCojThOQCXdCCCGEECnpcDsIBMOaHWbcSncG9l0eaq/jXKgB05wHVpNLmegfX2A5EOINydYZicBzfwPmPDj222qP6+V/TO5a6XLu25BfAnvepnclOSv2PO6RWNktnYjGyXame781G/muwtVnYd+DYK/WuxohhEiZNNwJIYQQImd5Zvw0VRhsuh3A2Gm17jD2hDtQDXcAfaOZn3I35PXTWF6E2Zyh2N7Wd0FwBS79MPH7xhEnG7O3uoTx+VUWVlOfYNR11YvZBEfTdNJ6w0bDXWITipLivQLhdYmTFUJsO7GGuyGfgWJlHW4wWRJuuBv2+mlwZfA1QCZ5r4DJDGVNelcihBBCCJGTOtxqryoTiQw9Hh81pTbcZYVpe4wH22o5H25U/zHVn9Q1rjcGlidXxNALMPIydPwK3PeXah/oZ38DCxPJXU9r3gF1AHr/OyAvff8WRucuK6Sm1EbP4KzepWij5c1gyYfL2kYgp3uyZVY79XW1HvmgrmUIIYRWpOFOCCGEEDnJvxZkenGNpnIDRoGNn4JSN5RU6V1J2h3a2MRM7oRtstZDYUZnVzIbR7z/F9Ub4P3fTfy+CTTc7amxA3B5KolJejcIhyP0eHwc3OGgpMCa0rVuKZMNd7HN5eqD6X8sIYTIIo3Rn3lDRppwZ8kDZ31CPz9C4QijsysbDYiG4x1QselWA07vE0IIIYTIgPZ6B5D+w6Gz/gCXppbobHZhMqXvIEi9q4jVilYA1sd6k7pG16AXq9nE4UZnckU891m1J/bGj6nXqff/Faz74cefSu56Wjv3HbUelDjZVJhMJjqbXVycWmRuOaB3OakrKFFpI56fJ5dYchM9Hh8VJQXGfF9jK8EAnH5UHQ5rfrPe1QghhCak4U4IIYQQOSn2ZnFGG6YyYW0Jrr2yLabbAeytsZNvNdObgVPDNxqdXSEUjmR2QqK9Wm3SXH4aVhcSu+/Qi2Cvi2tazZ4q1XCXavTJ5eklZpfXOZ6JeAOHW8WKZCJSNtZwJ5GyQohtptFlwEhZULGysx4VUxWH8bkVguEIDS6DvYYECIfBNyBxskIIIYQQKaiy26h12OgbTe/h0BNDagrYsaaytD4OwO622wGYutST8H3D4Qjdg+pAZlF+Egcyx06qCMnWh6F8p/rYnrfBrnuh719hpDvxa2opEoGz34KiCmh5k761GEDs+RyLTc15e+6HUADOfDPu3zm3sri6zoWJBTqbytLaaJuVLv4A/Nfg8CNglhYVIYQxyHczIYQQQuQkj1fFoTUbLVJ2ohci4W3TcJdvNdNaV0rv6BwRDTYt4hV7/mR8us3BhyG0BhefjP8+fi9cu6Cm28WxEbM3OuHu4mRqDXfdg14ghbiQRJgtUNaYmYa76fOqua9id/ofSwghsoizKA+7zbrxM9AwXM1qOsbSdFw3H/aphsMGlwGjohbGILgqDXdCCCGEECnqcDu5NLXIciCYtsfYiJXMwEHHtxxtZTJSRnjibML3vTi1yMJqkOMtSdb53OfUetfHr3/MZIL7PwNmKzz5CXVwRC+TZ2HmErS+S03QFimJPZ+7o8/vnLf/HZBvhyf/CP7pLeogdQp72KeG5whH4Oh2jJM9+RX1NX/bB/SuRAghNCMNd0IIIYTISYMzOjVMpdv4KbXWbY+GO1CbmHPL6xtvgGfCUPT505zpCYn7fxFMFuh/LP77DL+k1qY747r5DmchRfkWLk+n1nD38qAPkwmOZWoDyNUCs4MQDqX3cabOQ8Ue2UQVQmw7JpOJxvKijP68zYjY9NdZT1w3j01JbjTalGQA7xW1SsOdEEIIIURK2usdhCNwbizBhIIEdA/6cBTmbSQVpFOds5Cxgl1Urw6ysrKa0H27B1XjVFIJCFP9cPEJ2PsgVL8maaByDxz/XRg/DWe+kfi1tXL2W2ptkzhZLeypsuMozNt43uQ8hxt+rws6f0s1Z37jPSk13p2INiJmbL81W/iuwtWfwr4HoaRK72qEEEIz0nAnhBBCiJw0ZNQJd2OnABPUHdK7kozpqHcA0JvmqI4beWJvtmf6+VNcAc13w5WfwEqcMbpDL6q1Mb6GO7PZxO6qEi5OLiVZJEQiKi5kb7UdR1GGGtNcLSqiYWE8fY+xOg/zw1Ddmr7HEEKILNZYXszkwiqr62lubs6ksma1zg7GdfMhn3oN2WC0QxtwQ8PdTn3rEEIIIYTIcR1uJwB9o3Hu3SRoORDk3Ng8RxvLMJszEytprWunwLRO94muhO7XNejFZIIjjUk0CD3/ebXe/fHNP/+mT0BxJfzkz9WeTaaFw3DuMXA0gPtY5h/fgMxmE0cbyzg3Np/WCZEZ5dgBD34WPnom5ca77kEfRfkW9temv9E2q5z8mlqPfEjfOoQQQmPScCeEEEKInOSZWcZRmIezKF/vUrQ1dlJFXdoceleSMbFNzN6R9Gxibsbj9ZNvNVNbasvYY244+DCE1+GVJ+K7/dALUFSuprLFaU+1nZmlNXz+QFIlDs74uba4xhtaMhAnG+NqUWs6Y2WnL6j1taeqhRBim2h0FRGJwOisgabcuaINd774Gu5GfMuYTOAuM2CkrHdArTLhTgghhBAiJW3u9B4OPTM8RzAc4VgG4mRjGg++AYDBcy/FfZ/Ygcz9NaU4ChM8kOkdUAkPLffAjiOb38bmgHs/Bf5r8LO/Tuz6Whh5GRZGoe3dYJa3zLXS2ewiGI5wZjhze70ZkWLjXSAY5szIHIcbyrBattHzLRhQUyzLmqD5TXpXI4QQmtpG382FEEIIYSSDXj9NRptu5/fC3NC2ipMFaCovptRmzWjD3ZB3mUZXUcZOEb/KvofAbI0vVnZ1Hib7oPEOMMVf694adUry0lRysbKx2IdMbvxmpOFuql+tVTLhTgixPTVGp7rFYlUNYSNSNs4Jd95l6hyFFFgt6atJL74BsBSo2CMhhBBCCJG0UlseLZXFadur6o7GSnZmcN/F2aya3sITffjX4ps8dnXGz8xSgOMtSdT58y9AJAx3/9HWt+t4v9oL7foSXLuY+OOkIhYne1DiZLXUGY1LjT3P0yESiTDsXebJsxOM+DL8++1G491p6PzNGxrv7oXLP75p493ZsXnWguGNv59t4+ITqqn28CPS2CqEMBz5riaEEEKInONfC3JtcY1mo0WBjZ9W681OfRqU2Wyio97JufF51kPhtD9eMBRmxLdMY7lODZtFLnW69+pPYfkWG08j3WpzMs442Zjd1ak13HXp2XAXZ8NEUqbPq1Um3AkhtqkGl/rZZ6iGuwK7iqGKY8Jd7E2ZepcBp9uBipR1tYDZgM2EQgghhBAZ1uF2MuxbZjbJ9ICtdA/6sOWZOViXwYSLsmbWLYXsiXj48YWpuO4SO5B5PNH9oflR6P1XaLgdmm6xp2U2wwN/DeEg/PCTCcVzpiS0Dv3fg8r9UC0HM7XUtsOBLc9Mj4YNd9cW1/jJhSk+//QlHvlyN4c//TR3/82zfPgbp/j4/+nV7HES4nDDg5+7ofGuD77x7ps23p2INdo2lelRrX5OflUdPr/tA3pXIoQQmpOGOyGEEELkHI/XD6Bfw1S6jJ1U647tNeEO1Cbm6no46QaxRIzNrRAMR2jSs2Hz4MNqI/HCf2x9u6EX1Np4R0KX3xttuLs4mfyEu52VxVSUFCR1/6Q46sFkTvOEu/NQ4IDSHel7DCGEyGLXJ9z5da5EY2VNMOu55c1ml9dZXAvS6DLYa0hQMT2zQ1C+U+9KhBBCCCEMoT0aK9s3pm2s7HoozOnhOW6rLyPfmsG3ac1mItUHOWAe4one8bju0nXVC5D4RK4X/g7C63DXH8Z3+/pO6PhVGHgGLj6Z2GMla+BZWPFB23sSSpUQt5ZvNXOo3smpobmkDlcvrQV5acDLl342wEe+cZI7/9szdP7XH/MbXzvB3/3kMi9d9dJYXswjtzdyW4OTniEfM0trafiTxCnOxrsezyxWs4lDDU79as0031V16Hzfg1BSpXc1QgihOaveBQghhBBCJMozo6ayNBstUnb8lDrtVX1Q70oyLraJ2TsyT2uaT/d6olN9dI0k3vt2sOSrWNkjj9z8dkMvQkFpws+J6tICSm1WLk8tJVzaiG+ZsbkV3n+8IeH7psSar5ru4phQlJRIREXKVrfKRqoQYtuqKbWRbzUzlOnInXQra4bRHlhbgoKSm94s1mjYYLQpyQBzQxAJScOdEEIIIYRGOupVU0zvyBxv2lOp2XXPjc2zsh7KaJxsTP6ODlzjPVy4fJHF1UPYbXk3vW0kEqFr0MeuqhLKEzmQuTQNp74GtYdg11viv9+9n1IHU3/0p+p+1jQfAo3FybZJnGw6HGty8fJVH/3jCxyqv3mD2VowxCsTi/SOztE7Mk/v6BwD15Y2hsOZTLCnys57j7jpqHfS4Xayt8a+0az63dOjnB6e4ycXpnhfZ4b3Ml8r1nj3xo+pSOVTX1eNd+5Ownd/khOeEK07HBTlb6P2jJNfU+uRD+lbhxBCpMk2+o4uhBBCCKOITbjTtWFKa5EIjJ1SjVV5Nr2rybjYxkvf6FzaG708M9Hnj54TEgudsPMtcPlH4J+B4orX3yawrJ4TO+9JOBrOZDKxp9rOxalFIpEIpgQazJKOC9GCqwVGutTXg9ZNcQtjsDYvcbJCiG3NbDbR4Cpi2EiRsgCuZrXOeqDm5k3qw9FGw0YjNtx5r6i1fJe+dQghhBBCGMSB2lKsZhN9o3OaXjcWs3ks0alxWqhpA2B3eJCnz0/x8GH3TW86OrvCxPwqv5boPt1Lfw/BVbjr44nt7dhr4O4/gh//Gbz0D3DXHyT2uIkILMMrT4C7U03LFpo71lwOXKFn0Lex7xsKR7h6bYne0Xl6R+boG53jwsQigRum4LnLCnl7Wy0dbgcdbicHdzgoLrh5O8M9e6uwmE081Z8FDXcxNzbePf95OPV1zN98N18O7+IV5+9B5I7tcRg4GIAz31BfY81v0rsaIYRIC2m4E0IIIUTOud4wZaA3S+dHwT8N+x/SuxJdVJXaqHXYODOi7SbmZq5HEuv8/Dn4MFx6Es7/O3T+xus/P3ZCxW8kGCcbs6fGzomhWaYX16gujb+Js2tQxYUcby5P6nFT4mqBq8/C0pTaaNXS1Hm1VknDnRBie2t0FfHc5WuEwhEsZoNs8pfFGu4Gt264izYaGjJSVhruhBBCCCE0ZcuzsLfGzpmR+YQPM26le3AWi9nEbXrESkYb7g6ah3iib2LLhrvYgcxjiRzIXPZBzz9D5T7Yl8Qe5xs+rKbjPfdZ6PgVKK1L/BrxuPQkrPuh7b3pub7gtgYnFrOJx89OMLO0Ru/oHOfGFlhaC27cprw4nzt3lW9Mrmt3OxKbpgg4i/I53uzi+Ssz+NeCWzbnZZzDDQ99Hu76Ay595y84OPRtDl/+GPzzN+HNn1SHsY3ceHfxCfBfg9t/D8wZjM8WQogMyqKfOkIIIYQQ8RnyLuMsysNZlK93KdoZP6XWusP61qGjDreTp85PshwIpnW0/pB3mXyLmTpnYdoeIy57HwBLAfR/d/OGu6EX1dp4Z3KXr7YDcGlqMaGGu+5BH43lRdQ4dJi06GpRq++q9g130/1qrW7V9rpCCJFjGsqLWH8lwsT8Cu4ygxxeiE2lmPVsebNYlG6DyyB/7htJw50QQgghhOY66p18s2uYiflVTfaRwuEIJ4Z8HKwr1acxqOoAmMy80T7BFy9fY355HUfR5rGysQOZCTXcdf8vCCzBG/8guQYbawHc/xn43++DH38KHv5fiV8jHme/DSYztL4rPdcXFBdYadvh4MzIHL0jcxTnWzi4w8Gheift0eY6d1mhJo2s9x2o5sUBL89fvsbbDtZqUL3GHG6+WPwRutbu5Jnjp7Cd/QY8qqJmDd14d/KrYLbCoV/TuxIhhEgbaScWQgghRM4Z9Pr1jQNNh7Fow92ObdxwV+8kHIFzYwtpfRzPjJ96V6H+U30K7LD7rTD0AixOvf7zQy+AtRBqDyV1+d3VJQBcnFyM+z5TC6t4vMv6xJrAqxvutDYVbbir2q/9tYUQIoc0RpvNhowUKxuLlPUNbnmzYe8yjsK8m76pmNO8A1BQCsWVelcihBBCCGEYHW4HgGaxsleuLTG3vE6nXvsueYVQsYf9piHWQxGeOj9505t2D/pocBVR64iz0XBtEV7+ojoMc/Ddyde4537Y9Vbo+zcY7kr+OjezMguXn1YRlyVV2l9fbPjsezv4/C938NTH7qbvU/fzb79zO3/y9v082F5LvatIs6mR9x6oBuCp/k32V7NEj8eHrbIR27v+Fj56Go7+BoyfUY13/3wfDDyrd4na8g7A1Z+qSZfydSaEMDBpuBNCCCFETllaC3Jtcc1YcbIAYychr1hFLmxTHfVqE7M3jbGywVCYkdnl7GnYPPgwRMIqVvZGwQCM9EB9J1iTm+R444S7eHVF40KOt+gQJws3NNxt3TCRlKnz4GgAm0P7awshRA5pjP4MNFTDXUk15BWpSNktDPn8+kfKp4v3CpTvNOZkBCGEEEIInbS7Vexr7+i8JteLxbR2JjI1Tms1bdiXR3CaV3i8b2LTm8QOZB5PpM4TX4bVOXjjx8CSwvQ+kwne9hk1GevJT0A4nPy1NnP++xBelzjZDNhVVcLDh93sqban9eCzu6yI1rpSfvLKNMGQxs8XDUzMrzA6u3L9gLOzXkXNfvQ0HP2/Yfw0/Ms7YfB5fQvV0qmvq/XIB3UtQwgh0k0a7oQQQgiRU4a8fgCaKrKkYUoL4TBM9EJtB5gtelejm7YdDkwmOKPRqeHNTMyvsh6KbDQb6G73/WqKXf93X/3xiTMQXEk6ThagvKSAipJ8Lk0txX2frqsqLiShDVUtlTWqVesJd6F1mLkE1Qe0va4QQuSgWMPZkM+vcyUaMpnUJI0tGrZX10NMLawZM052bQkWJyROVgghhBBCY7urSijMs2g24a7HE22402vCHUBNGwDvrV/ghSszzPoDr7tJrDEw7jjZ9RV48e/BXgcdv5p6jRW74Q0fVvtjZx5N/Xo3OvstsBTA/oe0va7Q1X0HaphfWac7+jWWTXo8swAcfe3XvbMeHvoC/M5z0Rv+U4YrS5NgAM58A8qa1SRJIYQwMGm4E0IIIURO8cyoaSxZM6FMC94rsLawreNkAey2PHZWlmi2ibkZT7Rhs7kiS95sLyhRURnDL8HC+PWPD72g1sY7Urr87io7l6cWCYcjcd2+e9BHncOGuyzOuBCt5RVC6Q7tG+5mLqvTy1XScCeEEO6yIswmFa9qKGXNMD8CoeCmnx7xqT+vISfcxX5uSsOdEEIIIYSmrBYzB3eU0jcyH/feylZ6Bn3sqirBVZxcmoEmog13b6+8RjAc4Uf9r4+V7RqMHciMMwHh9KPgn4Y7PwrWAm3qvPsTUFwFP/5zWNFor3BhAjw/hz33SQKCwbw1i2NlT0SbAI/drNG2+oBqTHvlCfDPZLCyNLn4BPivwZFHwCytKEIIY5PvckIIIYTIKR4jTrgbP6XWbd5wB9DhdjLiW8G7tJaW63tm1PMnaybcgYqVJQL937v+saEXwZwHO46mdOm9NXb8gRBjcyu3vK13aY3L00sca3Zh0jOOztWiJhRFUt/I3jDVr9bqVu2uKYQQOSrfaqbWUWisSFlQE+7CQVgY3fTTsT+vISfcea+oVRruhBBCCCE01+52srgWZNCb2oTo0dllxudX9Z1uB1CtGu5azUPkW8ybxsp2D/qoddiod8VxIDMYgBf+Fooq4PAj2tVpK4V7PwXLM/Czv9bmmv2PARGJkzWg/bV23GWFPH1+ioiWe4oa6B70UWUv2Prr6cgj6rDwmW9mrrB0OfEVta996AN6VyKEEGknDXdCCCGEyCmxhqnmbGqYStXYSbXWScPdoXp1urRvdD4t1/d4s3BC4q63Ql7x9VjZcAiGX1YNmPmpNQXsqbYDcHl68Za3jcWaHG+J8/RyuriaYW0eljWMgJiWhjshhLhRY3kRQ15/1r0RkRJXs1pvEis75Is13GXRawCteAfU6mrRtw4hhBBCCAPqqHcCpJzIENt3OdZclnJNKSmphJIa8q/1c/eeCl4cmGHmhoOvPn+AS1MJHMjs+zc1afr2j6S8j/U6Hb8KO45A9/+EaxdTv97Zb0FBKey+L/VriaxiMpm470ANY3MrnJ9Y0LucDfMr61ycWqSz6RZfT/segkIXnPq6toeQM807AIM/g30Pqu81QghhcNJwJ4QQQoic4vH6cRbl4SjK07sU7YydUr9QlzXpXYnuYpuYZ0bSEys75PWTZzFR57Sl5fpJyS+CvQ/AaDfMjcDUORUx3HhnypfeU10CwMXJpVve9uWrsY1fnU9ax5oFtIyVnTqvTlbK5B8hhABUw50/EMLrD+hdinbKog13s5s33A17Y1NujTzhbqe+dQghhBBCGFCHWx0O7R1J7XBo9+AsgP4T7kDFyk5f4B0HKwlH4IfnrsfKXm8MjKPOcAh+/gUocEDnb2pfp9kMD/y1mmT9w0+m1ojkHYDx06qxKS+OyX0i59zXmn2xsqeGZ4lEoLPpFo221gLVYOq9DMMvZaa4dDj1NbUe+aCuZQghRKZIw50QQgghcsrgzHJ2TSdLVTAAk2fVNDM9YzyzxL6aUvItZnpTPDV8M4MzfurLirBasuxl8MGH1dr/XRUnC5o03O2OTri7NHXrCXfdgz4qSgpo0TuuOR0Nd9PnoXIvWAzUqCuEECmIRasbKlb2FhPuhn3L5FvN1JRmUdO9VrxXoLgKbA69KxFCCCGEMJwGVxHOoryU96p6PD7qHDbcZVlwAKSmDUJr3Fu1QL7VzON94xuf6ooeyDweT8Nd/3fBNwDHfzt9r0XdR6Hj/TDwDFz8QfLXOftttba9R5u6RNY52liGsyiPp85nT8Ndz6D6ejoaT6PtkWgk88mvpbGiNAoG4PQ31GG45jfpXY0QQmRElr3TKIQQQghxc0trQWaW1mjWuyFIS9P9EFqTONmofKuZA3Wl9I7MaR5zFwpHGPGtZOdkm51vUZEW/d8Fz8/BZIb6Yylf1lGYR63DdsuGu/nldS5MLnA83riQdIpNKNKq4W5lTkWbSJysEEJsaHSpn4XDPr/OlWjIUa9+fs56Nv30kG+Z+rJCzGaDHXCIRNQUBJniKoQQQgiRFiaTibYdDvrHF1gPhZO6hndpjSvTS/qnCsTUtAFQ7LvAPXsr6Rr0Mb24CkC3x0t5cT47K0u2vkY4DM9/HvKK4fiH01vvvX8G+SXwoz+F9dXE7x+JqDjZ4kppBDIwq8XMW/ZVc2FigRFfdhwuO+GZpaTAyv7a0lvfuHIv1L8Bzn8PVmbTX5zWXnkclmdU46BZWlCEENuDfLcTQgghRM7wzBgwCmzslFp3SMNdzKF6J7PL64z4VjS97sT8CoFQmKZsbNjMs8Het8P4KRh4FmrawRbHRkwcdlfbuTy9RCh88wbGE0M+IhE43pIFG7+urSMBEzZ9Qa1VB7S5nhBCGEBD9LWUoSbcWfOh1L3pz49QOMKob4UGl4FeQ8Ys+2B1XuJkhRBCCCHS6FC9k0AwzMXJWycIbKbHE42TzZqGu3a1TvbxUHsdkQg8eXaShdV1zo8vcCyeA5mXfqgOEh/9EBSXp7deew286RPqcM3L/5D4/Sf71CGV1ofBYtW8PJE9YrGyT2fBlLu1YIgzo3McbizDEu/Br8O/DsFV6PtWeotLh5NfAXMeHPqA3pUIIUTGSMOdEEIIIXKGx6sa7gw14W482nAnE+42tLtVBIXWsbKeGdVUkLWRxLFY2XW/JnGyMXurSwgEwwx5bz7FqCsab5AVJ60L7CoWT6sJd9P9apUJd0IIsSEWKTtspIY7AFcT+DxqgsUNJhdWCYTCG39uQ/FeUatMuBNCCCGESJt2txNIfq+qxxPdd4knVjITXM1qMt3kWX5hXxW2PBUre3JolnAkjv2hSASe/yxYCuCO389Mzcc/DK6d8NznYGH81re/0dlo85LEyRreXbsrKLCaeer8pN6lcHZ0nkAwTGdjWfx3an2nSkE59bXX/V6b1SbPwuBzcOAXoaRS71AP5uoAACAASURBVGqEECJjpOFOCCGEEDkjNoUlaxumkjF2Sk1jsVfrXUnW6KiPbmKOaNxw583yCYkt94BNNRvSeIdml91TbQfg0tTSTW/TNejDWZTHniq7Zo+bEleLdg13U+fVKhPuhBBiQ0mBlfLi/I2fjYZR1gyBRVj2vurDsaZzQ0648w2oVRruhBBCCCHSpiN6OLRvZD6p+/d4fJQV5bGr6hYxrZlitqiDiZNnKc638JZ91fR4Zvn+GdXIdsuGu6s/hbGTcNsH1PS5TLDmw9s+ow6qPv1n8d8vHIZzj4GzAdyd6atPZIWifCt37a6kxzPLrD+gay2xyZZHE2m0zS+GtvfC1LnrB/VzwYt/r9ZMNeAKIUSWkIY7IYQQQuSMwWikrGEa7gJ+uPYK7LhN70qySnN5MXabVfMJd7E327P2+WPNh4PvgbyiNDXcbR57srQW5NzYPJ1NLszxxhukm6tFNUusaPAcmOoHmxNK61K/lhBCGEhDeRHDPqNNuIvGkvteHSs7Ev1zZm3TfSpkwp0QQgghRNpVldqoddiS2qvyrwXpH1/gaFMcMa2ZVNMGKz5YGOfB9loAvnt6jFKblX01pVvf9/nPgckCd/7nDBR6gz33w+774Oz/geGX47vP8EuwMKaamLLp71+kzX2t1YTCEZ55ZVrXOno8PvIsJg5FD5fH7cgjaj35Ne2LSof5MTj3bWi6C+rkfQ4hxPYiDXdCCCGEyBlDXj9lRXk4ivL0LkUbE70QCcOOI3pXklXMZhMdbidnx+YJhsKaXXdwZhmr2YS7rFCza2ru/r+C/3QCirSLGNldrU5PX7xJw92poVlC4QjHsyFONsbVotbZwa1vdyuRCExfUKe2ZVNVCCFepam8mJmlAEtrQb1L0U5Zk1pnPa/6cGxKsnEb7kzX/+xCCCGEECIt2t0OLk0tshxI7PXzqWG175I1cbIxNW1qnTzLPXurKMq3ANDZ5MKy1YHM4S7wPA/t74OyxgwU+hr3fwbMefDkJyAcuvXtY3GyByVOdrt4y74qzCZ0jZUNhyOc8Pg4uMNBYfRrK261Hep/574DazdPLMkaXV+EcBDu+KjelQghRMZJw50QQgghcsbgzDKN2TqdLBlj0bHwdYf1rSMLddQ7WF0PbxmDmqghrx93WSFWSxa/BM6zgWOHppcsyrfS4Cri8k0a7roGVeze8eZyTR83JRsTilKMlZ0fhbV5iZMVQohNxOJVh70GmnJXFv358ZqG7aHohDt3mREb7gbAWa9eQwghhBBCiLRpdzsJR6B/fCGh+/UM+gDozKaDjgA17WqdPEthvoV791cDccTJPv9ZwAR3/UF667uZil3whg+rg8yn/2Xr2wYDcP57UNUK1bI3tF2UlxRwtNHFc5dmWF2PoykzDS5NL7KwGky+0fbwIxBYgv7HtC1Ma6vzcOKrULkPdt2rdzVCCJFxWfxuoxBCCCHEdYur68wsrdFcYaSGu5NqrTukbx1ZqMOtRu1rFSsbDkcY8hmsYTMBe6pLuHrNTyD4+omB3YM+SgqsHKi7RVxIJmnVcDd9Xq2yqSqEEK8Tm/Y27PPrXImGbhIpO+xdpqbUhi0vwckC2S4cVg13EicrhBBCCJF2sVjI3pHE9qq6PT4K8yy0ZtO+C0DVfjCZYbIPgEfuaKSpvIj7W2tufp/xM3D5KTjwS1CxO0OFbuLuP4LiKvjJX8DKFv8eV5+FlVlok+l22819rdWsrIf4+eUZXR6/xzMLwNFkG+7a3gt5RdkfK3vq6xBYhNv/E5il7UQIsf3Idz4hhBBC5IRYFFiTkRqmxk9B+W6wOfSuJOvENjH7NGq4m1hYJRAMG6thMwF7qu0EwxEGZ17dVLG6HqJ3ZJ6jTWVbx4VkWixS1udJ7TpT59Ra1ZradYQQwoBiDXceI024szmg0PX6CXdePw1GjJNdHIfgijTcCSGEEEJkwMEdav+ud3Q+7vsEgmFOD89xuNFJXrYlLuQXqX3JybMAHGl08dM/uoemrfbOnv+cWu/+wwwUuAVbKbz1z2HZCz/77ze/3Uac7LszU5fIGm89oCY26hUre8KjJlsebSxL7gK2Umh9GMZOwFS/hpVpKLQOL38RSqqh/Zf1rkYIIXSRZa/uhBBCCCE25/H+/+zdeXzcd33v+9do31fb8iJbkhPbiR0vceyEhC0FYsrWtJStbLm0hZ5DKZS253Y5p2e77e1tT0tLoe2hPbct2ymEHJbSHiAhlBJIII6d2I7txLGjkW0plqLRao2k0TLnj5+kxHiT5Bn9Zn56PR8PHt8gjX7zhocijWbe8/kERaHWFRF5sTTZB/1xWHdL2Ely0qqaMlbXlPHEmfk/iXklHTNFs5Yovtg+D1tWVwNw4sfWyj5+eoDU1HRurZMFKK8P/nOtE+66Zybcrbrx2jNJUsRsaAheSOuIUuEOoL41eIw1YzA5wdDYJC0NEXwMkDgZnBbuJEmSsq62vJiNKyoX9ObQI52DjE9Os3exU66ybfX24M0qY/NYk/v803D867D5J4OvC9uOdwTPq/7oU9Dz1MWfT43AU/8M62+D+palz6dQtTRWsqWpmgeP9zA1nV7y+9/f3semVVXUV5Ys/iK73xucuTrl7uhXYKgTbvslKCoNO40khcLCnSRJygvxmcJUZCbcdR4MznW7w82Rw3aur+VE9zDJ1OQ1XysexQmJC7Bp1aULdz9qTwBwa1sOPvHbsDEzK2XrNgTvCpUkXWBFVQmVJYXRWikLwVrZ4edgYhSAjr4Il+7nCnfXhZtDkiRpmdi5vo6ORJKBZGpet98/M+Xq1lwu3MH8Jmg99DEgDS8PebrdrIICeN0fQXoKvvmbkP6xUtXT34CJZLCaU8vSvm1NJEZSHDzdv6T32zkwStfg2OLXyc5afyusvAEOf2Hu79uckU7DD/4ciivhlveFnUaSQmPhTpIk5YXIFaa6Zgp3ay3cXc7O9XVMTac52jWPd9leRcfchMSIfP8s0MaVlRQWxHj63IWFu0fb+ygvLmT7uhxca9ywEc6fC96RvBiTKeg94TpZSbqMWCzGhsbKCE64awvOmSl3s//71kdywt2p4HTCnSRJ0pLY0bywtbL72/soKohx84ZFrpXMttnC3cxa2cvqaw/Ws7a9AtbvzX6u+WreA7veBc9+N5hm92JH7oNYIWz96VCiKXz7tq4G4P6jS7tWdnad7N7Wa/z3PhaD3ffA2GAwXTKXPPtd6D4Cu98DFTlaKJakJWDhTpIk5YV47wj1FcXUVhSHHSUzOg9CQVFurGDIUbua6wA4dGb+qzoup713hMKCGOvqyq/5WvmorLiQ1sYKnuk5P/ex1OQ0B0/3s7uljpKiHPyzoGFjcPa1L+7re0/A9CQ0bc1cJkmKmJaGCroGRklNTocdJXMaZgp3M78/TvcFhbuWqLxp48USp6CwBGrXh51EkiRpWdgx81zV4Xk8VzU9neaxjn5uWldLeUlhtqMtzlzh7vCVb/eDjweT5HJlut2Lvfo/QUk1fOt3YGIs+FiyD05+GzbeCVUrw0ynEN20roY1tWXcf6yb9I9PQMyiR9tnC3cZKKLtfEfwN1+urZV9+BMQK4CX/Nuwk0hSqHLwlTVJkqSLxRMj0ZlOlk5D5wFo2gbFZWGnyVk3NdcSi8ETGSjcdSSSrKsrz81i2RLZ3FRNPDHC2MQUAEc6BxibmOa2tsaQk13GXOFukWtle44FZ5MT7iTpcloaK5hOBytvIuOiCXczK2UjOeHuZPD7siBHX8CVJEmKmG1raygqiM1rwt2JnmEGRye4tS2Hpz9VrYKq1VeecDfUBU98Hpr3BhPuck11E7zy/4aBDnjkE8HHjv8jTE+4TnaZi8Vi3LW1iY5E8oI3IWfbY/F+VteU0VyfgTd+VzTAjW+Cju9D78lrv14mnHsSTj0IW++G+taw00hSqJbvK46SJClvDI9N0Hs+RVtUJpMMdcJIj+tkr6KmrJjrVlZxeJ5rOi5nejpNR1+ECpuLtLmpmnQaTs48wfTDZ4N3W+bsE7+zhYnFFu66jwanK2Ul6bI2NAYltHhikeu7c0Q6nSaZmuT54XHOsAqA7o7j/MvTPRzpHKK6rIi6qExJnjU1EZQKG64LO4kkSdKyUVZcyJbV1Rw6O3DViVn7MznlKptWb4ee48Hjy0t5+JMwlQqm28ViS5ttvm77N9B4PTz0MRjsDNbJFpXBDW8IO5lCttRrZQeSKZ7uHmZvWwOxTP37svue4DyYI1PuHvmL4Lzjw+HmkKQcUBR2AEmSpKvpSERsFVjnweBcd0u4OfLAjuZavnywk76RFA2VJYu6RvfwGGMT07Q2RnCyzQJsWV0NwInuYW5aV8uj7X2UFBawa31dyMkuY3bCXf8iV8r2HAtWLjRaRJCky2mdeWx1euax1lKbmJrm2edHOD8+ycj4JMnUJCPjU4zMnMnUJOfHJ0nOfWySkdTUC7cbnySZCj43+3pnjGmeKi3m2NFDvO+J/QDs3lCXuRc7ckV/R7DWy99zkiRJS2pHcx3/8Ohpzg2Nsab28hOsfjRTuNvTUr9U0RZn9XY4+QD0PgNNWy/83EgvHPg7aNoOm18bTr75KCqB1/4B/M+3wtc+CPHvw9afgrKasJMpZLdtbKC6rIj7j3XzoVdtyvr9HejoB2Bvawb/vW99efDG5EP/AK/63eD7PSxDXXDkS9DyMljnMAFJsnAnSZJyXntvMHWldUVEClNds4U7/yi9ml3r6/jywU4OnR3gJ7asWtQ14r0RK2wu0uamKgCe7h5mcmqax+J97FpfR1lxjq6hq1wBJdXXMOHuGKzYAoURm2gkSRm0YWbNakdIhbvf+NIhvvZE17xvX1pUQGVpERUlhVSVFlFfUU5laRGVJUVUlBZSWVJEZWkRI4ebuTk2wB/+xHYqSoq4Jddf5FyMxMw6ocbrw80hSZK0zOxsruUfHoVDZwYvW7hLp9Psj/expama+kW+gXTJrN4enN1PXly4++FfwkQSXvHruTvdbtbmfbDptfDMt4L/7jpZAcWFBbzqhlV87YkunhscvWJJNhP2x4PC3Z6WDE62LCiA3e+FB/8LnPhGsMo1LD/678G65jt+JbwMkpRDLNxJkqSc1zGz5qwtKitBOw9AcUVQBtIV7WwOpq8dOrP4wt3s989yn3DX0lhJSWEBJ84Nc+y5IUZSU9y2MYfXmsRi0NAGfYuYcDfaD0NnofVlmc8lSRGytq6c4sIYp/uWfqXs8eeG+NoTXexcX8cbt6+hojQo0VWUFFFZUhgU6UoLZwp2QcmuuLBgfhfv3wInH+Ttt6yDghwtll8rC3eSJEmh2DmzKeDw2QF+8qbVl7zNmb5RuofGuWtr01JGW5zVO4Lz3GHY8bYXPj46AI/+DTRught/KpxsC/WTfwCnvhM873r9XWGnUY7Yt3U1X3uii28f6+Y9t7dm9b72x/uoLiua2zSSMbveBd/5PTjw6fAKd2ND8NjfwYrNsGlfOBkkKcdYuJMkSTmvPUoTyqanoesJWLMLCn0odjU3rKmmpLCAQ2cGFn2N9tnCXVQKm4tUXFjAxpWVnOg+z4+eDdaa3NqWw4U7CNbKHvsaTIxBcdn8v67neHD++DuzJUkXKCyI0VxfEcqEuz994AQAv3f3TWxvrs3sxetbg3fdD3VB3frMXjtXWLiTJEkKxaZVVZQVF3Do7OWfq3o0Hjzvsrc1x593geDNjsWVcO7IhR/f/zcwPgSv+8P8eRNL43Xw1r+DWOHCnkdSpL1yy0pKCgu4P8uFu7GJKQ6fHeCl16+gsCDDEyGrm2DL6+Cpf4b+Dqhvyez15+PxzwY/E/b9XjB1T5KEPw0lSVLO60iM0FBZQm15BFZD9p0K/jB1ney8lBYVcuPaGg6dHSSdTi/qGh29SQpi0Fyf3ZUB+WBzUzWdA6M8+FQ3RQWx3F+x17ARSMNAx8K+rvtocK7alvFIkhQ1Gxoq6OhLMj29uN+zi3Hk7CD3H+tm39amzJftAOrbgrN/EVNS80XiZLB6vWpxE4AlSZK0OEWFBdy0tpbDZwcv+xh6f3uevNERgjJd07agcDf73FtqBB75S6jbkH+rWW98E9zw+rBTKIdUlRZxx/WNPHIqweDoRNbu59CZASam0tkr2u6+B0jDE5/PzvWvZGoCfvhXULkKdrx96e9fknKUhTtJkpTz4okRWqKyDrTzQHCuvTncHHlkV3MtfSMpzvaPLurr44kR1taVU1qUJ+/GzaLZdQY/fLaPm9bVUlGS41MWGzYGZ9+zC/u6nmPB6YQ7SbqqlsYKUpPTdA+PLdl9/um3g+l2H71rc3buoGGmcLeYteT5InEqmOARy/DkBEmSJF3VzvV1DI9NEp/ZqvDj9sf7aK4vZ01tnrz5c/V2SCZg+Lngvx/4exjtg5d+BAoj8AZoLXv7tq5mcjrNd5/uydp9PNbRD2RxsuX1r4aaZnj8czA9lZ37uJyjX4XBM3DbB5weKUkvYuFOkiTltOGxCXrPp2iLwjpZgM6DwbnulnBz5JGd6+sArriq43LS6TQdiSRty3yd7KzNTdVz/3zbxjx4l/VcYWKBhbvuo1BeD9VrMp9JkiKmZeYx1lKtlT14up/vPNXDG7av4cY1Ndm5k6hPuEuNwHCX62QlSZJCsmNmSvOlnqt6fnicZ3tHuDUf1snOWr09OM8dgclxePgTULUadr073FxShrxm6ypiMbj/WHfW7mN/vI+SwoK5nw8ZV1AIN78bhjrh5Lezcx+Xkk7Dw38OxRWw5xeW7n4lKQ9YuJMkSTlt9sXf1qgUproOQnkD1LeGnSRv7GieKdydWXjhrmd4nNGJqehMSLxGm5uq5v75tnxYazI34W4BhYl0GnqOB+tknfojSVfV0hD8jjy9RIW7P33gBLEY/OprNmXvTuo2ADHoj2fvPsI0W0S3cCdJkhSKnXPPVQ1e9LnH4sE62b358LzLrNU7gvPc4WBd5fBzcMeHnGSlyFhVXcau9XX869PPMz6Z+elwU9NpDsT72d5cS1lxFres3PwuIAYHPp29+/hx7d8Lfjbc/G6oyKOfa5K0BCzcSZKknNbeG6xmiERhajIFzx0O1slaBJq3jSsqqS4tuuSTmFcTn/n+aY3KhMRrtL6+grLiAmIx2JMP77SuWg1F5QubcDd4BsaHXCcrSfM0+xiro+/S67AyaX+8j4ee6eXunWvZ9KKpqxlXXAY1a6O7UjZxMjgbrws3hyRJ0jLV0lhBbXkxhy8x4e7R2cJdPjzvMmvVjRArgK4n4Pt/FrxZ+Jb3hZ1Kyqh9W1dzfnySR04lMn7tp88NMzw+mf1/7+s2BKtlT3wThs9l975mPfyJ4OfDSz64NPcnSXnEwp0kScpps4WpSKwE7TkGU+OwbnfYSfJKQUGMHetrOdI5yOTU9IK+Np6wcPdiBQUxXrl5Ja/cvJKasuKw41xdQUGwVnYhhbvuY8G5ysKdJM3H+pkJd/ElmHD3sftPUBCDD786i9PtZtW3RXelrIU7SZKkUMViMXY013K0a4iJH3uuan+8j8bKEq5bmUfPRZVUQOMmeOqfYaAjKNaUVl3966Q8sm9bE5CdtbKPdcwWbeszfu2L7L4H0lPBNMps6z4GJx+AG38qeI5WknQBC3eSJCmnzb742xKFwlTXweBcd0u4OfLQzuY6RiemeKbn/IK+Lj63kjgCExIz5FPv2cPfv+/WsGPMX8NGGDgNUxPzu333k8HZtC17mSQpQsqKC1ldU5b1lbIPn+rlkWcTvHl3MxtXLsGLdw2tMDYIyb7s39dSS5wKzgYLd5IkSWHZ2VzH+OQ0T58bnvvY8NgEx7qG2NNaTyzftlus3g6kobQGbn1/2GmkjLtuZRUbV1by7WPdTE+nM3rtR9uDvzv3tCzBZMstr4PKlXDwMzC9sDenL9gjnwzOO34lu/cjSXnKwp0kScpp8cQIDZUl1JbnwTSuq+k8EJxrnXC3UDvX1wFw6MzFqzqupCMxQiwGzfUW7vJWQ1vwrs2B0/O7fc/shLsbs5dJkiKmpbGCjkT2Vsqm02k+dv8JigpifPhVSzDdDoIJdxDNKXeJk8ELLOV1YSeRJElatnY01wJw+Ozg3McOnh5gOp1n62Rnrd4enHt/0ceZiqx9W1fTMzzOoUusg16sdDrN/ngfW5qqqa1YgtcwCoth1zuhPw7x72Xvfoaeg8P3woY7oHlP9u5HkvKYhTtJkpTT4r0jtDZGpCzV+TjUrIPqprCT5J1ds4W7Fz2JOR/x3iRra8spKy7MRiwthYaNwdk3z8JE9zGoa4HS6uxlkqSIaWmsYGhskoFkKivXf+iZXh7r6Oete5rZsFSP6+pbg7M/vjT3t5QSJ6Hx+rBTSJIkLWuzz1UdflFxZ//MlKtb2/KwcLfz5+D2D8FLPxJ2EilrsrFW9mz/KN1D4+xZinWys3bfE5wHPp29+3j0UzA94XQ7SboCC3eSJClnDY1NkBhJ0boiAutkUyPw/HFY53S7xWiqKWN1TdmCJtyl02niiRHXyea72QlFfc9e/baT45B4xnWykrRALY3BY62OLKyVTafT/MkDJygpLOBDSzXdDoIJqTD/wna+SPbBaD80uk5WkiQpTKtmnqt64kXPVT0a76OypJCta2pCTLZI1U3w2t93up0ibVdzHSurS7n/6LmMXXN/PISibeN10PpyeOqfYCSR+euPD8NjfwuNm2DzT2b++pIUERbuJElSzuroDV70bW2MQOHuucOQnnad7DXY0VzL093DjKam5nX758+Pk0xNzZUIlKdmJ9zNZyVg7wmYnoRVW7ObSZIiZkNDUE7v6Mt84e47T/Vw6MwA77h1PevqyjN+/cuK6krZxMngdMKdJElS6HY01/JMz3lGU1OMT07xxJkBdrfUU1Toy69SLiooiPGaG5s49fwIp54/n5Fr7o/3A7BnqVdJ774HplJw+AuZv/bjn4OxQbjjQ1DgzzNJuhx/QkqSpJwVT4wARGPCXeeB4HTC3aLtXF/H1HSao13zWys7O6UnMiuJl6vaZigont+Eu+5jwemEO0lakJaZ35UdvSMZvW46neZjD5ygpKiAD965xAWxigYoq4W++NLeb7ZZuJMkScoZL36u6vDZQVKT0+xd6tKNpAWZXSv7QIbWyu6P97G2tmxp32AGcOOboKwuWCubTmfuulOT8MhfQuVK2PGOzF1XkiLIwp0kScpZ8ZkXfSNRmOo6GJxrbw43Rx7btT5YafHEPNfKts99/0SgsLmcFRRCfev8Cnc9R4PTwp0kLUhLw8xK2QxPuPvW0W6Odg3x7ttaWF1bltFrz0t9G/THl/5+sylxKjgt3EmSJIVuZ/MLz1U92h7CWklJC3bHdY1UlhRmZK1s30iKkz3n2RvGv/fFZbDzHdD7NJz5Ueaue+yrMHgabv1AcB+SpMuycCdJknJWe6Qm3B2Exk3BpBUtyvbm4P+7Q2fnO+EuQt8/y13DxqAwMX2VdcLdx6CwFBquW5JYkhQVtRXF1FUUczqRucLd9HSaP/v2CcqKC/g3d27M2HUXpL4Vhjphcjyc+8+GxEkg9sLKXEmSJIVm9rmqw2cH2R/vo7gwNveGUUm5qbSokDu3rOLxMwP0DI9d07UeiwdF2yVfJztr9z3BefAzmbleOg0P/zkUlcOeX8jMNSUpwizcSZKknNWRSNJYWUJNWXHYUa5Nsg/6210ne41qyoq5bmUlh8/Ob8JdfKY0sKEhAhMSl7uGjTCVCkoTV9J9FFZuhsKipcklSRHS0lBBR1/mVsr+7yef46lzw9xzeyurqkN6V3xDG5CG/o5w7j8bEqegdr2TBiRJknJAbXkxG1dU8viZfg7E+9nRXEdZcWHYsSRdxb5tTaTT8ODxnmu6zmMd/QDcGlbhrmkrNO+FJ78MY/N7k/oVxb8Pzx2Cm98FlY3Xfj1JijgLd5IkKWfFe0doidI62XW3hJsjAnaur6MjkaR/JHXV28Z7R1hbW+YTnVHQMDMZ6UprZUf7YbgLmm5amkySFDEbGivpHhpnNHWVaaLzMDWd5s++/QyVJYX80itDnDo6OwWuvz28DJk0PQ19p6DRSa6SJEm5YkdzLWf6Rhken2RvWKUbSQty55ZVFBXErnmt7P54HzVlRWxaVZWhZIuw+70wOQpHvnTt13r4E0AMbv/la7+WJC0DFu4kSVJOGhqbIDGSisY60M7Hg3OtE+6u1exajkNXmXKXTqfpSCRpaYzA949mJhRx5cJd97HgXLU1+3kkKYJaZibCnu679rWyXz/Uxcme8/xfL22lobLkmq+3aLO/P/rj4WXIpOHnYCIJjdeHnUSSJEkzdjS/sEL21rb6EJNImq/a8mJesrGRH5xKcH58clHXGE1NceTsIHtaGygoiGU44QJsezOUVMGBT1/bdXqegme+BTe+6YU3P0uSrsjCnSRJykkdvcGLvW1RKEx1HoCCIli9PewkeW/2ScxDZ648Ij8xkuL8+CStKyIwIVHzm3DXM1O4a7JwJ0mLsWFmqnBH4trWyk5OTfPxB5+hurSI97885Cfp61uDsy8iE+4SJ4PTwp0kSVLO2Dnz5tBYDG5pccKdlC/2bWsiNTnN9048v6ivf+LMAJPT6fAnW5ZWwfa3wLnD0PX44q/zyCeC844PZyaXJC0DFu4kSVJOap95sbcl3yfcpdPBStmmbVBcFnaavHfjmmqKC2NXnXAX7w2+f1qjUNgU1K6HWOGVCxPdTwbnqm1Lk0mSImb2d+a1Trj78uOdtPeO8Asvb6OuIsTpdgA166CgODorZS3cSZIk5Zxta2soKoixpama2vLisONImqfX3NgEsOi1so/F+wDY25oDky133xOcBz+zuK8fPgeH74X1L4H1ezOXS5IizsKdJEnKSbOFqbyfcDfUBee7XSebIaVFhWxdU8OhMwOk0+nL3i6eCMoCrpSNiKISqFt/lcLdMShvgOrVS5dLkiKkn6fmKQAAIABJREFUZW7C3eILdxNT0/z5g89QW17Mz7+sLVPRFq+gEFbfBM/+azTWyiZOBWfjdeHmkCRJ0pyy4kL+5G07+S8/5RsApXyytq6c7etq+c5TPUxMTS/46x+N91FSVMD25tospFugtTdD03Y4/CVILWJq/aN/DVMpuONXMp9NkiLMwp0kScpJ8bkJd3m+ErTrYHCus3CXKTvX15EYSXG2f/Syt5ldh+dK2Qhp2BislL1U0TKdhp7jwSTJWGzps0lSBKyqLqWsuICOa5hw96XHznK2f5QPvGIjNWU5Mt3jrv8Kk6PwT7926d8h+SRxMpjYV7ch7CSSJEl6kbt3reO2jY1hx5C0QPu2NjE0Nsmj7X0L+rrJqWkOdvSzq7mO0qLCLKVbgFgMbrkHUsNw9CsL+9rx87D//4eG62DL67OTT5IiysKdJEnKSfHeERorS3LnxdrF6jwQnE64y5idzXUAHD47eNnbtM9MSGxpcMJdZDRsDAoTw5dY8zBwOnhCadXWpc8lSRERi8XY0FAxV1pfqPHJKT75nWdoqCzhnjtaMxvuWrS9Ana9G049CEfuCzvNtek7Ffw+LMiBF3QkSZIkKc/t2xZsyljoWtmnzg0zkppiTy6sk521/a1QVA4HPr2wr3vi8zA2AHd8CAqsjkjSQvhTU5Ik5aR4IknrigiUpToPQnEFrLwh7CSRsXN9ULg7dHbgsrfpSCRZXVNGeYkvSEdGw8bg7Hv24s91Hw3OJgt3knQtNjRU0tk/yuQi1ul8cf8ZugbH+KVXbKSqtCgL6a7Bvv8HKhrhm78FyYVNLsgZUxPBWlzXyUqSJElSRmxuqqKlsYIHjnWTXsBE9P3x4O/KvW0N2Yq2cOV1sO2n4eyjwSaQ+ZiahEc+Gfy9vPPnsptPkiLIwp0kSco5g6MT9I2kaG3M88Ld9DR0PQFrdkJhjr3wnMc2rqikurSIJ85cunCXTqeJJ0ZoaXSdbKTUtwXnpQp3PbOFu5uWLo8kRVBrYwWT02m6BsYW9HVjE1N88jsnWVFVyntvb81OuGtR0QA/+f9Bshce+N2w0yzOwGmYnrRwJ0mSJEkZEovFuOvGJroGxzjaNTTvr3ss3k8sBrs35NCEO4Dd7w3Og5+Z3+2P/2Pwt+atH4Di8uzlkqSIsnAnSZJyzuwqs9Z8L0z1nYLxQdfJZlhBQYztzbUcOTt4yQk8/ckJhscm87+wqQtdccLdseB0kqQkXZPZsnpH38LWyn7+R6fpGR7ng3del7vTZbe/Fa57FTz+OWh/KOw0C5c4GZyN14ebQ5IkSZIiZKFrZdPpNI/G+9jSVE1teXE2oy3chtthxWY49A8wcZU30qXT8PAnoKgM9r5/afJJUsRYuJMkSTknnkgC5P9K2c6DwbnOwl2m7Vxfx+jEFCefP3/R59p7Zwqb+f79owvVtwIx6G+/+HM9x4LPl1YtcShJipYNM2X1jpnHYvORTE3yV989SVNNKe+8bUO2ol27WAze8CfBiwn/9KtXf/Eh11i4kyRJkqSMu6WlnobKEu4/1j2v25/uS/L88Di35tI62VmxWDDlbrQfnvqnK9+242HoOgi73gWVjUuTT5IixsKdJEnKOfHZwlS+TyjrsnCXLTub6wA4dIm1spGZkKgLFZdBzbqLJ9xNjkPvM7BqWzi5JClCWhqC352n++ZfuPvMIx30nk/xoZ+4nrLiHJ1uN6thI9z5W0F57fsfCzvNwli4kyRJkqSMKyyI8eobVvHUuWFOz+PNZ/vj/QDsac3Bwh3Azp+DgmI4+Okr3+7hTwAxuP2XlySWJEWRhTtJkpRz5gp3K/K8MNV5AMrrob4t7CSRs2v9TOHu7OBFn5udkNiS74VNXayhDfrag5UHs55/GtJT0LQ1vFySFBHr6sspLIjNPRa7mvPjk3zqX0+xrq6ct+1dn+V0GXL7h6DpJnjoY9DzVNhp5i9xEkqqoKop7CSSJEmSFClza2WPXX2t7P72PgD2ttZnNdOiVa6AG98I7d+7+I3Ls55/Gk58A254AzRet7T5JClCLNxJkqScE0+MsKKqhOqy4rCjLN7UBJw7Amt3B6PclVGra8toqim95IS7yBQ2dbGGjTA+BMnECx/rORacTU64k6RrVVxYwNq6snlPuPv7H7TTn5zgQ6+6ntKiHJ9uN6uwGN70cZieDFbLTk+HnWh+EqeCF0J8XClJkiRJGfXyTSsoLy6c11rZ/R19NNeXs6a2fAmSLdLu9wbnwc9c+vOPfDI47/jw0uSRpIiycCdJknJOPJHM/+lkPcdgcsx1slm0s7mOp84NMzYxdcHHOxIjrKoupaKkKKRkypqGjcH54ndndh8NTlfKSlJGtDZWcrovSfrF00QvYXB0gr/+3rNsaKjgLbc0L1G6DGneA7e+H04/Ao9f5gWIXJJKwlCn62QlSZIkKQvKigt5+aYVPBbvo28kddnb9Z4f59nnR9ibq+tkZ7XdCXUt8Pjng8EALzbcDYe+AOtvgw23hRJPkqLCwp0kScopg6MT9I2kaM33wl3ngeBca+EuW3aur2NqOs3RrgvXysYTyfz//tGlNcysZ35x4a7nGBSWvlDGkyRdkw0NFSRTUzx/fvyKt/vb77czNDbJh1+9ieLCPHx66VW/C9Vr4f7/GLzgkMtmf+9ZuJMkSZKkrNi3bTXTaXjw+OX/Pnws3g/AnlxdJzuroAB2vwdGeuDENy/83P6/gakU3PEr4WSTpAjJw2dEJUlSlHUkgnWgbfm+DrTzYHA64S5rdjbXAfDEmRcKd/0jKQZHJ1wnG1WXm3C3cgsUOtFQkjKhpTH4HXo6cfm1sgPJFH/7/XY2rqjkp3etXapomVVWA6//bzA+CN/8rbDTXF46DT/6q+CfV24JN4skSZIkRdSrb1hFQYwrrpV9LN4HwK25PuEOYNe7IVZw4VrZ1Ajs/x/Bc6xbXh9eNkmKCAt3kiQpp7T3BoW7vF8p2/U41KyD6tVhJ4ms7c21ABw6MzD3sXgiIt8/urT62Ql37cGZ7IPh56DppvAySVLEbGgIfofGr1C4+5uHnmV4fJKPvGYTRfk43W7WjW+EG94IR78MJ+4PO82lPfhf4fHPwXWvhhveFHYaSZIkSYqk+soSbm1r4KFnnmc0NXXJ2+yP91FXUcx1K6uWON0i1KyBTa+Fk9+GwbPBxx7/PIz2w+2/DAWF4eaTpAjI42dFJUlSFMV7gxd321bkcWEqNQI9x2HtzWEnibTa8mI2rqzk8NkXCncdM+UAV8pGVGkVVDW9MOGu51hwNm0NL5MkRcwLE+5GLvn5xPlx/u4HcTatquKNO/J0ut2Lve6PoKQa/vnXYfx82Gku9MhfwPc/Buv2wNs/C0UlYSeSJEmSpMi6a+tqxiameeiZ5y/6XDI1yZNdQ+xpaaCgIBZCukW45R5ITwdv4pqegkc+CRWNsPOdYSeTpEiwcCdJknJKx9yEsjxeCfrcYUhPwbpbwk4Sebua64gnkgwkU8CLJyTm8fePrqxh4wuFu+6Zwt0qC3eSlCmzv0M7+i494e5T33uWZGqKX33NZgrz5UWGK6ldB6/+jzB4Gr77B2GnecGhL8C3fgdWbIF3fQlKfDOBJEmSJGXTvq1NwKXXyj5+eoCp6TR7W+uXOtbiXX8XVK+Bg5+FY1+FgQ7Y+34o8blzScoEC3eSJCmntCdGWFFVQnVZcdhRFq/rYHCu2x1ujmVg5/o6AA6dHQReKGy25vOERF1Zw0YY7QvWH3Q/GXysaVu4mSQpQipKilhZXTo3NfbFeobH+MwjcW5YXc3rblq99OGyZe8vBFPkfviX0PVE2GngxLfgqx+EmmZ4z5ehoiHsRJIkSZIUeesbKrhxTQ0PHu9mcmr6gs/tj/cBsKc1j/4+KyyCm98NQ2eDqe5FZbD3F8NOJUmRYeFOkiTllHjvSP6vA+2cKdyt2RVujmVgrnB3JlgrG08kWVFVSlVpUZixlE31bcHZ1x6slK1oDNbMSpIypqWhgtOXmHD3V989xdjENB+9a3P+rNCZj4JCeNPHIVYAX/8wTE2Gl+X0D+Hee6CsFt7zFahtDi+LJEmSJC0zd21toj85wYGO/gs+/li8n9KiAravqw0p2SLd/O7gHO2HnT8HVSvDzSNJEWLhTpIk5YzB5AT9yQla8r5wdwAar4fyurCTRN6Na6opLoy9qHA3QqvrZKOtYaZwlzgFPceDdbKxCJU+JCkHbGisoG8kxdDYxNzHnhsc5fM/Os32dbVza3YiZfVNcPuH4LlD8OinwsnQfQz+59uC4t+77oOVm8PJIUmSJEnL1KXWyk5OTXPwdD+71tdRUpRn9Yr6VrjuVUAMbv/lsNNIUqTk2W8ESZIUZfGZdaBtK/K4MJXsg/52WHdL2EmWhdKiQm5cU8OhswMMJFMMJCdcJxt1DRuDs/27kDrvOllJyoKWhuB36ekXrZX9y385RWpyml+7azOxqBadX/mbwYsR3/l9GDi9tPfd3wGfezOkkvCOz0GzjyUlSZIkaaltW1vDurpy7j92jnQ6DcCx54ZIpqbYm0/rZF/sp/8Kfv6bsGJT2EkkKVIs3EmSpJwxW7jL68JU1+PBuXZ3uDmWkZ3NdfSeT/HwqQSAE+6ibnbC3dPfCM5VW8PLIkkR1Trz5oeOmcLd2f4kX9h/ml3r67hzS4TXz5RUwBv/FCZG4J9/A2ZeXMm688/DZ38Ghs/Bm/96ZvqAJEmSJGmpxWIx7traxJm+UZ7uHgZgfzxYL7u3LU8Ld9WrYcNLwk4hSZFj4U6SJOWMeG/wom5rPq+U7TwYnOss3C2VneuD1b3/+EQXQP6vJNaVlddDeQMkg4IlTTeFm0eSImhDw0zhri94M8Rf/MtJJqbS/Pq+CE+3m3Xdq2DH2+GZb8Gxr2b//saG4PM/C32n4A1/DDe9Ofv3KUmSJEm6rLm1skeDtbL72/soiMHuDXVhxpIk5RgLd5IkKWdEY8LdQSgogtXbw06ybOxaXwvAd57qAaAtn79/ND+za2WJwaobQo0iSVE0W14/nUhyOpHkS4+d5dbWBl52/YqQky2R1/6/QcH7G78JowPZu5+JMfjCO+G5Q3Dnb8PeX8zefUmSJEmS5mVvWwO15cVza2Uf6+jjxjU1VJcVhx1NkpRDLNxJkqScEU+MsKKqlKrSorCjLF7nwWDFZXF52EmWjY0rqqgqLSI1NQ3ABlfKRt9s4a6+FUosWEpSptVXFFNdWkRHIsnHH3yGyek0H71rGUy3m1W5Avb9Ppzvhm//5+zcx/QUfPkXIf4Q7H0/vPI3s3M/kiRJkqQFKS4s4NU3rOLJziEePpWg93yKva15uk5WkpQ1Fu4kSVLOiPeO0JrPZamhLjh/znWyS6ygIMaO5mDKXWNlCTW+0zD6GtqCs2lbuDkkKaJisRgbGit4snOQrzx+ljuua+T26xrDjrW0dr0TWl8OB/4OOh7J7LXTafjnX4PjX4dtb4bX/REslzKjJEmSJOWBu2bWyv7BN44DsKe1Psw4kqQcZOFOkiTlhMHkBP3JifxeJ9t5IDjX3RJujmVoR3MdkOfriDV/sxPuVm0NN4ckRVhLYwXD45NMp+HX7tocdpylF4vBG/8MCkvh6x+ByfHMXfs7vwcH/h42/gT8zKegwKfnJEmSJCmXvGLzSkqKCniycwjACXeSpIv4jJ4kScoJ8cQIAG35XJjqPBica51wt9R2rQ8m3LXk84REzV/bK6H5Vth6d9hJJCmyWhqDx2Sv2LySPcv1hYUV18Mr/h30Pg0/+HhmrvnDv4KH/jh4g8bbPwdFJZm5riRJkiQpYypLi3j59SsA2NBQQVNNWciJJEm5xsKdJEnKCbOFu7wuTHUdhKJyWHlD2EmWnb2tDaysLuWl160IO4qWQs0a+MUHYPVNYSeRpMi6ra2B6rIi/t2+LWFHCddLPxI8tvvef4PeZ67tWofvhW/+FqzYDO/8EpRWZSajJEmSJCnjZtfKuk5WknQpFu4kSVJOaO8NCnetjXk64W56Gjofh7W7oLAo7DTLTmNVKfv//Wv42Vuaw44iSVIk3LllFYf/0z62N9eGHSVcRSXwpo/DVAr+6aOQTi/uOs88AF/9t1CzDt79ZahszGxOSZIkSVJGve6mNbx80wresXdD2FEkSTnIwp0kScoJHYkkAK35ulK271kYH3SdrCRJioxYLBZ2hNyw4SVwy/sg/hA88fmFf/2ZR+GL74HSanjPV6BufeYzSpIkSZIyqraimM/+wm3c2tYQdhRJUg6ycCdJknJCe+8IK6pKqSrN0+lwXQeDc52FO0mSpMh5zX+Gqia4/z/A+efn/3U9x+Hzb4VYDN51H6xc5it6JUmSJEmSpAiwcCdJknJCPDFC24qKsGMsXueB4LRwJ0mSFD3ldfC6P4TRfvjW78zvawZOw2ffDKkRePtnoXlPdjNKkiRJkiRJWhIW7iRJUugGkikGkhO0NObpOlmAzoNQXg/1bWEnkSRJUjZs/WnY9Fo4ci+cfPDKtx3phc/+DAw/Bz/z3+H61yxNRkmSJEmSJElZZ+FOkiSFLp5IAtC2Ik8Ld1MTcO4wrL05WBcmSZKk6InF4A1/DMWV8E8fhVTy0rcbH4bPvwUSJ+F1fwTb37K0OSVJkiRJkiRllYU7SZIUuo7ECACt+TrhrucYTI7BWtfJSpIkRVrdBnjVv4eBDvjXP7z485Pj8IV3Qdfj8MrfhNs+sPQZJUmSJEmSJGWVhTtJkhS69t6gcNfSWBFykkXqPBic624JN4ckSZKy79ZfgjW74OFPwLkjL3x8egq+/AFo/1fY8/Nw52+Hl1GSJEmSJElS1li4kyRJoYvPFO5a83WlbNds4c4Jd5IkSZFXWARv+jiQhq9/JCjapdPwv38Djn0Vtt4Nr//jYAWtJEmSJEmSpMgpCjuAJElSPJFkZXUpVaV5+tCk83GoXgvVq8NOIkmSpKWwdhe85IPwyCdh//+AZAIe+1toeyW8+W+goDDshJIkSZIkSZKyJE9f1ZYkSVEST4ywaVVV2DEWJ5WEnmOw5XVhJ5EkSdJSuvO34dg/wv3/AaZSsPZmeMfnoag07GSSJEmSJEmSssiVspIkKVQDyRQDyQlaG/N0ney5w5Cecp2sJEnSclNaBW/4k6Bs13g9vOs+KK0OO5UkSZIkSZKkLHPCnSRJClU8kQSgdUWeFu46DwbnWgt3kiRJy87mffC+b8KKzVDZGHYaSZIkSZIkSUvAwp0kSQpVvHcEIH8n3HUeCM61N4ebQ5IkSeFouT3sBJIkSZIkSZKWkCtlJUlSqNpnC3crKkJOskhdB4MVYuV1YSeRJEmSJEmSJEmSJGWZhTtJkhSqjkRQuGvJxwl3yT7oe9Z1spIkSZIkSZIkSZK0TFi4kyRJoWpPJFlZXUpVaR5uuu94ODib94SbQ5IkSZIkSZIkSZK0JCzcSZKkUMV7R2jLx+l2AEe+BMTghjeEnUSSJEmSJEmSJEmStAQs3EmSpNAMJFMMjk7Q0lgRdpSFGxuEE9+ElpdCbXPYaSRJkiRJkiRJkiRJS8DCnSRJCk177wgArSvycMLd8a/D5BjseFvYSSRJkiRJkiRJkiRJS8TCnSRJCk1HIglAWz4W7g7fC4UlsPXusJNIkiRJkiRJkiRJkpaIhTtJkhSa2Ql3ebdSdqgL2r8Hm18L5XVhp5EkSZIkSZIkSZIkLRELd5IkKTTxxMxK2cY8m3D35P8C0rDddbKSJEmSJEmSJEmStJxYuJMkSaGJJ5Ksqi6lsrQo7CgLc/iLUFYLm/aFnUSSJEmSJEmSJEmStIQs3EmSpNDEe0fyb7pdz3E4dwS23g3FZWGnkSRJkiRJkiRJkiQtIQt3kiQpFP0jKQZHJ2hdURF2lIU5fG9wuk5WkiRJkiRJkiRJkpYdC3eSJCkU8cQIAC35NOFuehqO3Ac166DlpWGnkSRJkiRJkiRJkiQtMQt3kiQpFLOFu7YVeVS4O/MjGDwN298CBT6MkiRJkiRJkiRJkqTlxleKJUlSKNp7kwC05tOEu8NfDM4dbw83hyRJkiRJkiRJkiQpFBbuJElSKNp7Z1fKVoScZJ4mU3D0K7BqGzRtCzuNJEmSJEmSJEmSJCkERWEHkCRJ0ZZOpznbP8rRrkGOdg1xtGuIJzsH6RkeZ3VNGZWlefJw5OQDMDYAL/to2EkkSZIkSZIkSZIkSSHJk1e4JUlSPpiaTvPs8+dninWDPNk5xLHnhhgcnZi7TXFhjC2rq/mJLat44841IaZdoMP3AjHY/pawk0iSJEmSJEmSJEmSQmLhTpIkLcr45BQnzp2fm1z3ZNcgTz03zOjE1NxtKkoK2bqmhm1ra9i2rpZta2vYtKqakqI822o/NghPfwNaXgq1zWGnkSRJkiRJkiRJkiSFxMKdJEm6qvPjkxx/boijnYM8ObMW9pnuYSan03O3qa8o5paWeratq2Hb2qBc19pYSWFBLMTkGXL86zA1DjveFnYSSZIkSZIkSZIkSVKILNxJkqSL9J4f574DZ3myc5BjXUO0J0ZIv9CtY01tGXduWTlXrNu2rpa1tWXEYhEo113K4S9CYQlsvTvsJJIkSZIkSZIkSZKkEFm4kyRJF/mLfznJ3/0gDkDbikpev30NN82W69bW0FhVGm7ApTTUBe0PwY1vhPK6sNNIkiRJkiRJkiRJkkJk4U6SJF2kZ3gcgEP/cR+1FcUhpwnZk/8LSMN218lKkiRJkiRJkiRJ0nJXEHYASZKUewaSKapLiyzbQbBOtqwWNu0LO4kkSZIkSZIkSZIkKWQW7iRJ0kX6Ryaoq7RsR89xOHcEtt4NxWVhp5EkSZIkSZIkSZIkhczCnSRJusjg6AR15SVhxwjf4XuD03WykiRJkiRJkiRJkiQs3EmSpEvoT6aoW+7rZKen4ch9ULMOWl4adhpJkiRJkiRJkiRJUg6wcCdJki4wPjlFMjVFfcUyn3B35ocweBq2vwUKfMgkSZIkSZIkSZIkSbJwJ0mSfsxAcgKA+uU+4W52neyOt4ebQ5IkSZIkSZIkSZKUMyzcSZKkC/QnUwDULecJd5MpOPoVWLUNmraFnUaSJEmSJEmSJEmSlCMs3EmSpAvMTrirW84T7k4+AGMDsONtYSeRJEmSJEmSJEmSJOUQC3eSJOkCAzMT7uqX84S7w/cCMdj+lrCTSJIkSZIkSZIkSZJyiIU7SZJ0gf7lPuFubBCe/ga0vBRqm8NOI0mSJEmSJEmSJEnKIRbuJEnSBfqX+4S741+HqXHXyUqSJEmSJEmSJEmSLmLhTpIkXWBgZsLdsi3cHf4iFJbA1rvDTiJJkiRJkiRJkiRJyjEW7iRJ0gUGZibc1S7HlbJDXdD+EGx+LZTXhZ1GkiRJkiRJkiRJkpRjLNxJkqQL9CcnKCyIUVNWFHaUpXfkPiAN210nK0mSJEmSJEmSJEm6mIU7SZJ0gYFkirryYmKxWNhRlt6Re6GsFjbtCzuJJEmSJEmSJEmSJCkHWbiTJEkX6E9OULcc18n2HIdzR2Dr3VBcFnYaSZIkSZIkSZIkSVIOsnAnSZIuMJBMUV9REnaMpXf43uDc8fZwc0iSJEmSJEmSJEmScpaFO0mSNCedTjOwHCfcTU/Dkfugphk23BF2GkmSJEmSJEmSJElSjrJwJ0mS5pwfn2RyOk3dcptwd+aHMHgatv8sFPjwSJIkSZIkSZIkSZJ0ab6iLEmS5gwkJwCoX24T7lwnK0mSJEmSJEmSJEmaBwt3kiRpTn8yBbC8JtxNpuDoV2DVNmjaFnYaSZIkSZIkSZIkSVIOs3AnSZLmvDDhbhkV7k4+AGMDsONtYSeRJEmSJEmSJEmSJOU4C3eSJGnOCxPultFK2cNfBGKw/S1hJ5EkSZIkSZIkSZIk5TgLd5Ikac7shLtlU7gbG4SnvwmtL4Pa5rDTSJIkSZIkSZIkSZJynIU7SZI0Z3bC3bJZKXv86zA1DtvfGnYSSZIkSZIkSZIkSVIesHAnSZLmzE64WzaFu8NfhMIS2Hp32EkkSZIkSZIkSZIkSXnAwp0kSZozMDPhblmslB3qgvaHYPNrobwu7DSSJEmSJEmSJEmSpDxg4U6SJM3pT05QVlxAWXFh2FGy78h9QBq2vy3sJJIkSZIkSZIkSZKkPGHhTpIkzRlIppbPOtkj90JZLWzaF3YSSZIkSZIkSZIkSVKesHAnSZLm9CcnqFsOhbue43DuCGy9G4rLwk4jSZIkSZIkSZIkScoTFu4kSdKc/mSK+orisGNk3+F7g3PH28PNIUmSJEmSJEmSJEnKKxbuJEkSAJNT0wyPTUZ/pez0NBy5D2qaYcMdYaeRJEmSJEmSJEmSJOURC3eSJAmAwdEJAGqjPuHuzA9h8DRs/1ko8KGQJEmSJEmSJEmSJGn+fJVZkiQB0J8MCneRXynrOllJkiRJkiRJkiRJ0iJZuJMkSQAMJFMA0V4pO5mCo1+BVdugaVvYaSRJkiRJkiRJkiRJecbCnSRJAl6YcFcX5cLdyQdgbAB2vC3sJJIkSZIkSZIkSZKkPGThTpIkAS+ecBfhlbKHvwjEYPtbwk4iSZIkSZIkSZIkScpDFu4kSRIAA3MT7iJauBsbhKe/Ca0vg9rmsNNIkiRJkiRJkiRJkvKQhTtJkgRA/8yEu8iulD32jzA1DtvfGnYSSZIkSZIkSZIkSVKesnAnSZIA6J+ZcFcf1cLdkXuhsAS23h12EkmSJEmSJEmSJElSnrJwJ0mSABiYmXBXWx7BlbJDXdD+EGx+LZTXhZ1GkiRJkiRJkiRJkpSnLNxJkiQABpIT1JQVUVgQCztK5h25D0jD9reFnUSSJEmSJEmSJEmSlMcs3EmSJAD6kynqKyO8TrasFjbtCzuJJEmSJEmSJEmSJCmPWbiTJElAMOGuriKChbue43DuCGy9G4rLwk4jSZIkSZIkSZIkScpjFu4kSRIwM+GuojjsGJl3+N7g3PEFdnYZAAAgAElEQVT2cHNIkiRJkiRJkiRJkvKehTtJksRoaorxyWnqozbhbnoajnwJapphwx1hp5EkSZIkSZIkSZIk5TkLd5IkiYHRFAC15RGbcHfmhzB4Brb/LBT4sEeSJEmSJEmSJEmSdG185VmSJNE/MgEQvQl3h78YnK6TlSRJkiRJkiRJkiRlgIU7SZLEQDKYcFdfGaEJd9NTcPSrsGobNG0LO40kSZIkSZIkSZIkKQIs3EmSJPqTwYS7uihNuBvphbEBaLk97CSSJEmSJEmSJEmSpIiwcCdJkuifnXBXEaEJd+fPBWfV6nBzSJIkSZIkSZIkSZIiw8KdJElicHRmwl15hCbcDXcHZ3VTuDkkSZIkSZIkSZIkSZFh4U6SJNE/Eky4q4vkhDsLd5IkSZIkSZIkSZKkzLBwJ0mS6E8GE+7qKyM44c7CnSRJkiRJkiRJkiQpQyzcSZIkBpIpigtjVJYUhh0lc2Yn3FWvDjeHJEmSJEmSJEmSJCkyLNxJkiQGRv8Pe/caW3l+n4f9ObzMkBxyyENyhhwtKa2snV1ppZUt2LEd21LcWBLstGnQOAEC12iDGrYRODVap0lfFEULBCiMprVzc1I1cdoEbtq0doqmqd1ItuvI8iWx7Fiz0lp7sW7k7pCzJA9neObwztMX/3NmR9JceDk3nvl8AOGnIc/5/b9zlthZYB483/1MjV1IqVTq9iits7WSlAaSS1e6PQkAAAAAAAAAfULgDgBIpbaXqdHhbo/RWtXVImw30EetfQAAAAAAAAB0lcAdAJDN2n7KYxe6PUZrba0m43PdngIAAAAAAACAPiJwBwBPuKOjejZre5ka66OGu3o9qa4kE/PdngQAAAAAAACAPiJwBwBPuK2dgxzV018Nd9uV5HBPwx0AAAAAAAAALSVwBwBPuM3tvSTJ1KU+arirrhanhjsAAAAAAAAAWkjgDgCecJXafpJkarSPGu62VopTwx0AAAAAAAAALSRwBwBPuEqtaLgrj/VTw92t4tRwBwAAAAAAAEALCdwBwBNusxG4mxrro4a7arPhTuAOAAAAAAAAgNYRuAOAJ1zlbrFStq8a7rZWi3PCSlkAAAAAAAAAWkfgDgCecJvbjcDdpX5suBO4AwAAAAAAAKB1BO4A4Al3b6XsaJ813I2Wk6GL3Z4EAAAAAAAAgD4icAcAT7hKrWi4mxrrs4a78fluTwEAAAAAAABAnxG4A4An3GZtL5cuDObCUB/9Z8HWajJhnSwAAAAAAAAArdVHf7MOAJxGpbbXX+12e3eTvS0NdwAAAAAAAAC0nMAdADzhNmv7KV8a7vYYrbO1Upwa7gAAAAAAAABoMYE7AHjCbdb2MzXaRw131dXi1HAHAAAAAAAAQIsJ3AFwLEdH9axVd7s9Bi22d3CU6u5BpsY03AEAAAAAAADA4wjcAXAs/+e/eT3f/t/8Sl564063R6GFNrf3kiTlsX5suBO4AwAAAAAAAKC1BO4AOuDnf3c5Ly7f7vYYZ/Li67dzcFTPP7/xRrdHoYU2a/tJknI/NtxZKQsAAAAAAABAiwncAbTZzv5h/vLPfyY//cuvdHuUM1naqCVJPvHSapcnoZWagbupfmy4s1IWAAAAAAAAgBYTuANos7Xqbur15CuNwNp5tVzZTpK8equaL7xZ7fI0tEqlVqyUneq3hrvhS8nFiW5PAgAAAAAAAECfEbgDaLO1ahFoWq7UUq/XuzzN6dTr9SxVahkdHkyi5a6fbDYCd+V+a7jTbgcAAAAAAABAGwjcAbTZenU3SbKzf3QvfHfeVGr7qe0d5nvfN5+xC4P5uMBd36jcWynbZw134/PdngIAAAAAAACAPiRwB9Bma43AXZIsVc7nWtmlxjrcZ66O57ufu5Lf+0olb27tPuZdnAeVfmu4O9hLtjc03AEAAAAAAADQFgJ3AG12f6tdM7h23ixXtpMkC+XRfOT5udTrya/8gZa7fnC70XDXN4G7auPnUsMdAAAAAAAAAG0gcAfQZvc33DWDa+dNs5lvoTyWP/7cXAYHStbK9olKbS8DpWRiZKjbo7RGM3Cn4Q4AAAAAAACANhC4A2iz/mi4K+ZeLI9mcmw43/4N0/nUa2u5u3vQ5ck4q0ptP5OjwxkYKHV7lNbYWilODXcAAAAAAAAAtIHAHUCbrW3tZmJkKGMXBs9vw93Gdi4ODeTKxMUkyUfeM5e9g6N88pU3uzwZZ7VZ2+ufdbKJhjsAAAAAAAAA2krgDqDN1u/u5sr4xSyWx+6tZj1vliu1PFUeTalUtKB95L1Fe5i1suffZm0/U2PD3R6jdZqBOw13AAAAAAAAALSBwB1Am61V9zIzfiGL06N5Y3M7h0f1bo90IvV6PcuV7SyWx+597amp0bzvqcv51c/fyv7hURen4yzq9Xo2a/v91XDXXCk7IXAHAAAAAAAAQOsJ3AG00cHhUSq1vcyOX8xCeSz7h/Ws3Nnp9lgn8mZ1N7sHR1koj37V1z/6/Hxub+/nd7640aXJOKva3mH2Do8y2W8Nd4MXktFytycBAAAAAAAAoA8J3AG00UZtL/V6GoG7IrC2tHG+1soubWwnSRanx77q6x95fi6JtbLnWaW2lyT913A3Ppc01h8DAAAAAAAAQCsJ3AG00dpWEWgqVsoWgbXlynY3Rzqx5UoREPzahrt3z09kcXo0n3hpNfX6+VqTS2Gztp8kKfdbw934XLenAAAAAAAAAKBPCdwBtNH63d0kRcPdYrkI3J23hrtmQLA5f1OpVMpHn5/P65vb+dwbd7oxGmfUDNxN9UvD3dFhUr2VTMx3exIAAAAAAAAA+pTAHUAbrVXvC9xNN1bKVs5X4K4ZEPzahrvEWtnzru9WytbWk/qhhjsAAAAAAAAA2kbgDqCNmitlZ8cvZGJkOFNjw1neOG8rZbczdmEw05e+PpT1Le8opzw2nI9/bqULk3FWm43A3VS/rJTdavwcargDAAAAAAAAoE0E7gDaaO2+lbJJ0RJ37hruKrUslsdSKpW+7ntDgwP5nvfM5fMrW+duVS5J5d5K2T4J3FUbTYsa7gAAAAAAAABoE4E7gDZqNtzNjBftcIvlsazc2cnewVE3xzq2w6N63tjcfuA62SZrZc+vvlspq+EOAAAAAAAAgDYTuANoo7Xqbi4ODWT84lCSZHF6LPV68sbm+Vgru3pnJ/uH9SxOjz30NR+6fiUjwwPWyp5DtxsNd30TuKs2fgbHr3Z3DgAAAAAAAAD6lsAdQBut393N7PjFe+tYFxtNcedlrexypQgGPqrhbvTCYD54/Up+50sbqdzd69RotECltpeLQwMZvTDY7VFaY6u5UlbDHQAAAAAAAADtIXAH0EZrW3uZHX+rPWyh0RS3tHE+Gu6WNopg4EL54Q13SbFW9qie/Mrnb3ViLFqkUtvP1Nhwt8donepKklJy6Uq3JwEAAAAAAACgTwncAbRJvV6/13DX1I8Nd0nyPe++moFSrJU9ZzZre/2zTjYpGu4uXUkGh7o9CQAAAAAAAAB9SuAOoE3ubB9k/7D+VYG7ZlNcM8jW65rBwMXpRzfczYxfzLc8PZ1PvvpmtvcOOzEaLdCXDXcTc92eAgAAAAAAAIA+JnAH0CZvVneTJDP3rZQdGR7MlYmL91a19rrlSi0TI0OZHH18KOujz89lZ/8on3ptrQOTcVaHR/Xc2dnvn4a7er1ouBuf7/YkAAAAAAAAAPQxgTuANllvBO7ub7hLirWyy+dkpezSxnYWy49ut2v6yPNFs5i1sufDne391OvJVL8E7nY2k8NdDXcAAAAAAAAAtJXAHUCbrFX3kiSzE18TuJsey1p1L7W9g26MdWwHh0dZubOThfLosV7/jplLeff8RH7l87dyeFRv83ScVaVW/Hz2zUrZrdXi1HAHAAAAAAAAQBsJ3AG0yVqz4e7SVzeINQNsy5Xtjs90Ejdv7+TwqJ7F6eM13CXFWtmNu3v53S9X2jgZrVCp7SdJyv0SuKs2mhUnBO4AAAAAAAAAaB+BO4A2ubdS9msb7horWnt9rexSY77jNtwlyUeeL8JO1sr2vs17DXd9slK2eqs4x62UBQAAAAAAAKB9BO4A2uTNxkrZma9puGs2xi1t9HbD3XJjvmZA8Dje99TlXJscySf+YDX1urWyvWzzXsNdnwTutjTcAQAAAAAAANB+AncAbbJW3c3gQOnrAk3NANvSRm833DUb+Bamj99wVyqV8tHn5/Ll9VpeWa22azRaoNJouOuflbKrxanhDgAAAAAAAIA2ErgDaJP16m6mL13IwEDpq75+bWokA6W3Vrb2qqVK0XC3cIKGu8Ra2fOi2XA31S+Bu2bDncAdAAAAAAAAAG0kcAfQJmvVva9bJ5skw4MDuTY52vsrZSu1lMeGM35x6ETv+7ZvmM7EyFA+/tJqmyajFZoNd1P9slK2upqMTCXDI92eBAAAAAAAAIA+JnAH0CZr1d1cmbj4wO8tlEfvrWztVUsb21mcPlm7XVIECr/n3Vfz4uu388Zmb4cKn2T3Gu5G+6jhbmK+21MAAAAAAAAA0OcE7gDaoLZ3kNreYWbHHxy4W5wey52dg9ze3u/wZMeze3CY1a2dLJ5wnWxTc63sL/+Blrtetbm9l4mRoQwN9sl/ClRXrZMFAAAAAAAAoO365G/ZAXrLerVY1/mglbJJ7gXZljZ6s+Xujc2d1OtFE99p/LHnruTC4EA+/jmBu15Vubufcr+sk92rJbt3NNwBAAAAAAAA0HYCdwBtsFbdTZLMPmSl7OJ0EWTr1bWyzSDgwilWyibJ+MWhfOczM/ntL6z3bIvfk26ztpepsT5ZJ1tdKU4NdwAAAAAAAAC0mcAdQBusNRruHrZSduFew912x2Y6ieVKMddpG+6SYq3swVE9v/byrVaNRQtVavuZ6peGu61Gk6KGOwAAAAAAAADaTOAOoA2aDXcz4w9ZKdvrDXeNuZqrb0/jw89fTakUa2V70M7+Ybb3D1PWcAcAAAAAAAAAJyJwB9AG643A3ZWHNNzNTYzkwuBAlir923B3dWIkH1icyq+9fCu7B4etGo0WaK75Lfdbw53AHQAAAAAAAABtJnAH0AaPWyk7MFDKU+XRLG30aMPdRi1XJi5mZHjwTPd89L3zubt3mN/8w/UWTUYrVGrFz+dUvzXcWSkLAAAAAAAAQJsJ3AG0wZuNhrvpSw9vEFsoj2a5sp16vd6psY5tubJ9pna7po88XzSOWSvbWyp3i4a7qdE+CdxpuAMAAAAAAACgQwTuANpgvbqbydHhXBh6+L9mF8pj2d4/vNeG1yu29w6zVt3NYnnszHe968p43nXlUn75D1ZzdNR7wcIn1Waj4a78iEDouVJdSYbHkosT3Z4EAAAAAAAAgD4ncAfQBmvVvcyMPzrMtDhdNMgtV3prrezrm8U8rWi4S4q1sm9u7eb3lzdbch9nt7ndaLgb65PA3dZq0W5XKnV7EgAAAAAAAAD6nMAdQBusVXczO37xka9pNsgtVbY7MdKxLW0U8yxOn73hLrFWthdVmg13Y32yUra6kkzMd3sKAAAAAAAAAJ4AAncALbZ/eJTN2n6uPC5w1wi0LW30VsNds3GvVQ1337QwlSsTF/Pxl1Zact+Z3fp88ubL3Z6iqzZrjYa70T5ouDvYS2rrRcMdAAAAAAAAALSZwB1Ai23cLdrDHrtSttybK2WbjXvNBr6zGhgo5SPPz+ULb97Na7eqLbnz1Or15B/9u8nf+fbkF/9ysv1krrmtNH5Gpy71QcPd3VvFqeEOAAAAAAAAgA4QuANosbXqbpI8dqXs9KULGR0evLfCtVcsV2oplZJrUyMtu7O5VvYTL3V5reztpaS6mgxeTP71/5j87T+S3PjfiyDeE6RS28/QQCkTF4e6PcrZbTV+pjTcAQAAAAAAANABAncALbZWLdrDHhe4K5VKWZwe7b2Gu43tzF8eycWhwZbd+R3vmsmlC4PdXyt780Zxft9PJn/q7yT1w+Sf/nDyD//kE7Vm9vb2XqbGhlMqlbo9ytlVGz9TGu4AAAAAAAAA6ACBO4AWW9sqGu4et1I2Kda2vr65ncOj3mlYW67UWrZOtuni0GC++91X8/tLm7l1Z6eld5/IyovFee0bkw/8+8lf/HTyzX8++dKvJ3/3O5Jf/q+Tvbvdm69DKrX9TI09/ufzXKhquAMAAAAAAACgcwTuAFps/e7xVsomyeL0WPYP61ntZgjtPtXdg1Rq+1koj7b87o8+P5d6PfnlP7jV8ruPbeVGUhpMrryn+PXYdPIn/0byQ7+cXH1P8qmfTn7m25LP/z/dm7EDNmt7mRod7vYYrdFcKavhDgAAAAAAAIAOELgDaLHmStkrxwjcNYNtSxu9sVa2ud52Ybq1DXdJ8t3PXc3QQKm7a2Vv3kiuvDsZHvnqry/+keSHfy35vv822bmd/G8/kPzjP5dUvtSNKduqXq9ns68a7ho/T+MCdwAAAAAAAAC0n8AdQIudZKXsQmN163Jlu60zHdfSRjFHOxruJkeH80ffNZPffG091d2Dlt//WLWN5M5ycu39D/7+4FDybT+a/MXfSV74s8krv5T8zLcnn/zvkoPdzs7aRlu7Bzk4qqc81kcNdwPDRVshAAAAAAAAALSZwB1Ai63d3cvo8GAuXRx67GsXpxsNd5XearhbLLe+4S5JPvL8XPYOj/IvX36zLfc/0sqN4px/SOCuaWI++f6/n/wH/yyZXEh+9a8mf/c7ky/8WttH7ITbtf0kSflSHzXcjc8lpVK3JwEAAAAAAADgCSBwB9Bia1u7mZ04XphpsbG6tdks123tbLhLkg+/Zy5JurNW9mYzcPfC8V7/DX8s+Qu/kfzx/zK5vZT8oz+V/PwPJVtdXInbApVasfJ4qp8a7ibmuj0FAAAAAAAAAE8IgTuAFlur7mbm0sVjvfbyyHAmR4d7puFuqVLL4EAp1yZH2nL/26ZG8/6Fyfzq529l//CoLc94qJUTBu6SZOhi8qH/LPmxf5U8+73JZ38++Vvfkvz2/5AcdmEtbgtUGg13U6N90HB3dJTcvZWMz3d7EgAAAAAAAACeEAJ3AC10dFTPxt29zI4fL3CXFG1yyxu9Ebhbrmzn2uRIhgbb98fDR5+fy9bOQf7VFzba9owHWnkxmXpHMjp18veWn05+4J8kf+5/Ld7///7nyd/77mTpd1o9ZdttNhruyv3QcFdbT44ONNwBAAAAAAAA0DECdwAtdHt7PwdH9cyOH789bLE8lpU7O9k76HDj29eo1+tZ3qhlsTzW1ud85Pmijayja2X3asnaK8m195/tnnf/iaLt7rt+Irn1+eRnP5z8sx9Pah0OD55B5W5zpWwfNNxVGz9DGu4AAAAAAAAA6BCBO4AWWr+7myQnarhbnB7NUT25eXu7XWMdy53tg2ztHmShPNrW5zw7N553zIzlEy+tpl6vt/VZ99x6KakfJfNnDNwlyYVLyYf/q+Qv/Eby9AeT3/uHyd/+luTf/Fyx4rTHbW4XK2XLl/qg4W5rtTg13AEAAAAAAADQIQJ3AC305lbRHnaihrvpolFuaaO7gbulSrHWtjlPu5RKpXz0+bncvL2Tz75+p63PuufmZ4qzFYG7pivPJf/h/5386b+flAaT/+vHkv/p+5KVz7buGW2wWWsE7jTcAQAAAAAAAMCJCdwBtNBatWi4mzlJw11jhWsz8NYty43nt7vhLunCWtmVF4vzrCtlv1aplLz/zyZ/8XeSb/2RZPlfJx/7UPIv/otijW0PqtSKUOjkaD803DUDd1e7OwcAAAAAAAAATwyBO4AWWq+efKVsM+C2tNHdgFazYa/dDXdJ8s3vKGf60oV8/HOrbX9WkmTlRjI2m0xca8/9o1PJn/hryQ//anLtG5Pf+tvJb/7N9jzrjCq1/YwOD2ZkeLDbo5xdtblSVsMdAAAAAAAAAJ0hcAfQQmvVoj3sysTx13UuNBrulivdXSnbyYa7wYFSPvyeq3l5dStfXr/b3ocdHiSrn0vmXyga6drpbR9IfujjycBQ8sbvt/dZp7RZ20t5rA/a7ZJGw10puaThDgAAAAAAAIDOELgDaKF7K2UvHb/hbvTCYGbHL3Z9pexSZTvDg6XMTYx05HnNtbKfeKnNLXfrryYHO61fJ/swg8NJ+Z3Fc3vQZm0/U2PHD4T2tOpqcmk2GRzq9iQAAAAAAAAAPCEE7gBaaK26l6GBUiZHT9Ygtjg9em+la7csV2p5amo0AwNtboFr+OD12YwOD7Z/rezKi8U536HAXZLMXk8qX0oO9zv3zGOq1PZSvtRHDXfj1skCAAAAAAAA0DkCdwAttFbdzcz4hROH1hbLY1mr7mZ777BNkz1avV7P0sZ2FqfHOvbMkeHBfOjZ2Xz6yxtZbzQDtsXNzxRnJwN3M88kRwdF6K6HHBweZWvnIFOjfdBwV68XDXcTc92eBAAAAAAAAIAniMAdQAutVXdPtE62aaE8mqRomeuGjbt72d4/zEK5c4G7pFgre1RPfuXzt9r3kJUbyfBYMvOu9j3ja81eL8613loru7ldNO5NjfVBw93O7WJVsIY7AAAAAAAAADpI4A6ghdare5mdOHngrtkst1zpzlrZpcZzm8G/Tvmed1/NQCntWytbrxcrZefelwwMtucZDzL7bHGu91jgrraXJCmP9UHDXbXxM6PhDgAAAAAAAIAOErgDaJG7uwfZ3j/M7KWTh5kWG81yS11quGs263VypWySlC9dyLe+czqfeu3N9qzTvb2cbFeSax1cJ5skMz3acFfro4a7rZXi1HAHAAAAAAAAQAcJ3AG0yFp1N0lO2XBXNMstbXQncLe00Z2GuyT56PPz2dk/yidffbP1l6/cKM75F1p/96NcmklGyz0XuKs0Anca7gAAAAAAAADgdATuAFpkrVqs65wdP3mY6drkaAZKbwXfOu1ew125sw13SfKR54vAVFvWyt5sBu463HCXFC13PbZSttJYKdsXDXfNwJ2GOwAAAAAAAAA6SOAOoEWaDXczl07ecHdhaCDzl0e6tlJ2qbKdkeGBU4UFz2pxeizvuXY5v/L51RwcHrX28pUXk9JgcvX51t57HLPXk9p6Utvo/LMfYvNe4K4PGu6aK2U13AEAAAAAAADQQQJ3AC2y3my4O8VK2SRZmB7LcqV7DXcL5bGUSqWuPP+jz89ls7afT3+50tqLV24kV96dDI+09t7jmHmmONdf6/yzH2Lz3kpZDXcAAAAAAAAAcBoCdwAt0my4O21L3GJ5LLe393NnZ7+VYz3W0VE9y5XtLJRHO/rc+7VlrWxtI7m9lMy/0Lo7T2L2enGu9c5a2cq9wF2fNNyNTHYnTAkAAAAAAADAE0vgDqBF3grcna7hbnG6CLwtbXR2rexadTd7B0dZLI919Ln3e+/bLuepqdF8/KWV1Ov11ly6cqM4r72/Nfed1EwjcLfeO4G7zdpeSqXk8mifNNxptwMAAAAAAACgwwTuAFqkuVJ2+tLpG+6SZGmjs2tllypFwK+bDXelUikfeX4uy5XtfH5lqzWXrrxYnPNdCtxNvzMpDfRYw91eLo8MZ3CgO6uDW2prNZmY6/YUAAAAAAAAADxhBO4AWuTN6m7KY8MZHjzdv1qbgbflSmcb7poBv8Xp7jXcJclHW71W9maj4a5bK2WHLiZT70jWX+vO8x9gs7af8lgftNvtbye7tzXcAQAAAAAAANBxAncALbJW3c3MKdfJJm8F3pYrnW24W+6Bhrsk+SPvnM7k6HA+/tJKay5cuZFMvT0ZnWrNfacxez3Z+EJydNi9Ge6zWdvP1NjpGhh7ylbjZ0TDHQAAAAAAAAAdJnAH0CLr1b3Mjp8+zDR3eSTDg6UsbXSp4a7c3Ya74cGBfMe7ZvK5N+5k9+CMAbX97WTtle6tk22afTY53Es2v9zdORoqtb3+aLirNloQNdwBAAAAAAAA0GECdwAtsHdwlNvb+5k9Q8Pd4EApT02NZqnDK2WXN2u5dGEwUz0QxGq27N26s3u2i1ZfSupHybVvbMFUZzDzTHGudX+t7PbeYXYPjlLuq4Y7gTsAAAAAAAAAOkvgDqAF1u8WAbGzBO6SYq3s0sZ26vV6K8Y6lqWN7SxOj6VUKnXsmQ8zd3kkSXLz9s7ZLlr5THF2veHuenGuv9rdOVK02yXJZA8EK8/sXsOdlbIAAAAAAAAAdJbAHUALrFeLMNNZVsomRcPb9v5h1u/utWKsxzo8queNze17zXLddm2ymGPlzhkDdzdvFOf8C2ec6IxmGoG7td4J3PVVw53AHQAAAAAAAAAdJnAH0AJvVouGu5kzNtwtlMeSJMuV7TPPdBwrd3ZycFS/99xum58sPr+V22f8/a+8mIzNJJff1oKpzmD8anLxck8E7m7X9pMk5X5quJsQuAMAAAAAAACgswTuAFrgrYa7s6+UTZKljdqZZzqO5cZzms/ttvlmw93t3dNfcnSYrH6uWCfb7TW5pVIy80yPrJQtAndT/dJwNzRahBkBAAAAAAAAoIME7gBaYK3RcHfWlbKLjdWuS5XOBO6WGk16vbJS9urExZRKycqdMzTcrb2aHGx3f51s0+z1opFt505Xx+irlbLV1aLdrtuBSgAAAAAAAACeOAJ3AC2wttUM3LWq4a4zK2WXG8G+xR5ZKTs8OJDZ8YtZub1z+ktWbhTntW9szVBnNXO9OLvccrfZCNxN9cNK2a2VZHy+21MAAAAAAAAA8AQSuANogfW7rVkpO3PpQkaHB+8F4dqtGexbmO6Nhrskmb880prA3fz7WzPQWc0+U5xrr3V1jLdWyp7zwN3hflJbKxruAAAAAAAAAKDDBO4AWmCtuptLFwYzemHwTPeUSqUslEezXOlcw93k6HAuj/ROCGt+ciS3tnZzeFQ/3QU3byTDY8nMu1o72Gn1TMNdEbg79ytlq7eKU8MdAAAAAAAAAF0gcAfQAm9u7WbmjO12TYq8zXYAACAASURBVIvTY3m9sp2j0wbOTmC5sp2Fcu+02yVFw93BUT3r1d2Tv7leLxru5t6bDJwt/NgyM+9KUkrWuh2428uFwYGMnTEU2nXVleLUcAcAAAAAAABAFwjcAbTA+t29zI63pjlssTyavcOjrG6dYa3qMewfHuXm7e0slsfa+pyTmp8cSZLcPM1a2TuvJ9uV3lknmyTDo8nUYrLe7ZWye5kaG06pVOrqHGe2tVqcGu4AAAAAAAAA6AKBO4AzOjqqZ+PuXmZb2HCXJEsb7V0re3NzJ0f19FzD3bVG4G7lzikCdzdvNC7pocBdUqyVXf/D5OioayNs1vYzNdY7q4NPTcMdAAAAAAAAAF0kcAdwRpXaXg6P6i1bKdsMwC1t1Fpy38MsV4r7mwG/XjF/uRG4O03D3UojcNdLDXdJMns9OdhO7ix3bYSi4a41LYxdVb1VnBruAAAAAAAAAOgCgTuAM1q/u5ckudKilbILjRWvy5X2NtwtNQJ3vdZwN3/WhrvSYHL1+RZPdUYzzxTn2qtdefzRUT23t/dT7oeGu61mw53AHQAAAAAAAACdJ3AHcEZrW7tJktmJFq+UrbS74W77q57XK+4F7k7VcPdicuW5ZHikxVOd0ez14lx/rSuP39o5yFE9KfdFw91qMjCUjE53exIAAAAAAAAAnkACdwBntNZouJu51JrA3eTocC6PDLV9pWzz/qemeqvhbuzCUC6PDJ08cFfbSG5/pffWySbJTCNwt/ZKVx5fqRU/o32xUnZrJRmfSwb8JwwAAAAAAAAAnedvqwHO6F7DXYtWyiZF61y7V8ouV7Yzc+lCLl0cautzTmN+cuTkK2VXXizOaz0YuLv8tmT4UtdWyr4VuOuDlbLV1SJwBwAAAAAAAABdIHAHcEZr1SJwNzPemoa7JFkoj+bm7e3sHx617M6vtVSpZaHcW+12TfOTo1m5vZN6vX78N63caLz5hfYMdRalUjLzrq6tlN2s7SdJyuc9cHd0VATuJua7PQkAAAAAAAAATyiBO4AzWq8W7WFXWhi4WyyP5aie3Nw8YcvbMe3sH2b1zm4Wpsfacv9ZzV++mO39w9zZPjj+m5oNd70YuEuS2evJndeTvbsdf/Tmdp+slN3eSI4ONNwBAAAAAAAA0DUCdwBntFbdzfBgKZdHW7eadbERhFuq1Fp25/3e2CzW1fZyw12Sk62VvXkjmXp7Mlpu01RnNHO9OLvQcle522y4O+eBu62V4tRwBwAAAAAAAECXCNwBnNFadTczly6mVCq17M7F6SJwtrTRnsDdUqUI3C2We7XhbiRJcvP29vHesL+drL2SzL+/jVOd0WwjcLf2ascfvVkrGu7O/UrZaiNwp+EOAAAAAAAAgC4RuAM4o7XqXmYnWtsc1gzCtavhbrlx72KPrpS9NlkE7laP23C3+lJSP+ztwN3MM8XZjYa7WtFwN3neA3dbq8Wp4Q4AAAAAAACALhG4AziDer2etepuZscvtvTep8rNhrtjNrydUPPeXl0pO3ev4e6YgbuVG8V57RwE7rrRcLddBO6mRs/5SlkNdwAAAAAAAAB0mcAdwBlUdw+ye3CUmUutDdyNXRjK7PiFe010rda896mp3gzcnbjhrhm46+WGu4vjyeWnkvXurJQdvziUC0Pn/I/9ZsOdwB0AAAAAAAAAXXLO/+YdoLvWq3tJ0vKVskmyUB7LUqVNDXeV7VyduJiR4cG23H9WU2PDuTA0cPyGu5s3ktHp5PLb2jvYWc08k6z/YVKvd/Sxldpeps77Otmk0XBXSsavdnsSAAAAAAAAAJ5QAncAZ7BW3U2SXGnxStkkWZwey5tbu9nZP2z53a9XalmcHmv5va1SKpVybXIkK8cJ3B0dJqufK9bJlkrtH+4sZq8ne9Vk62ZHH1u5u5/y2DlfJ5sUDXdjM8lgH4QHAQAAAAAAADiXBO4AzmCt0XA3M96Ohrti3Wur18rW9g6yVt27d3+vmr88kpXjrJRdfy052O7tdbJNM9eLc62za2U3+6nhbmK+21MAAAAAAAAA8AQTuAM4g2bD3Ww7Gu7KRQNdq9fKvt64r3l/r5qfHMlmbf/xDX83bxTntW9s/1BnNftMca690rFH7h0c5e7eYabOe8NdvV403I3PdXsSAAAAAAAAAJ5gAncAZ9DWwN10o+Fuo7UNd0uNxryeb7ibHEmSx6+VXflM4w0vtHmiFmg23K2/1rFHbm4XLYzl895wt3unaDLUcAcAAAAAAABAFwncAZzBehtXyrar4W652XA33eMNd5eLwN3NxwbuXkyGx5KZZzow1RlNLiZDIx1dKbtZ20+S899wt7VanBruAAAAAAAAAOgigTuAM1ir7qZUSqbbEGZ629RoSqVkqdUNdxvno+HuWqPhbvXOIwJ39XqxUnbuvcnAYIcmO4OBgWT6Xcl65wJ3lbt90nBXXSlODXcAAAAAAAAAdJHAHcAZrFV3Ux67kKHB1v/r9MLQQOYvj9xbAdsqy5XtDJSSa5O9HbibO07D3Z3Xk+2NZP79HZqqBWafSTaXkv3WNhc+TOVew905D9xpuAMAAAAAAACgBwjcAZzBenUvs21YJ9u0WB67twK2VZYqtcxfHsmFod7+I6AZCHxkw93NG8U5/0IHJmqRmetJ6snGFzryuNvbRcPduV8pW20E7jTcAQAAAAAAANBFx0pb/PiP/3iefvrplEqlfPazn33s15Pk1VdfzXd8x3fk2Wefzbd+67fmpZdeau3kAD3gzepuZscvtu3+henRbNb2s7Wz37I7lyvbWZgea9l97TI7fiEDpeTm7UcEDldeLM5r56nh7tniXOvMWtlmw1353AfuGitlNdwBAAAAAAAA0EXHCtz9mT/zZ/KpT30q73jHO4719ST50R/90fzIj/xIXnnllfyVv/JX8kM/9EOtmRigR+zsH2Zr5yAzbQzcLZaLYNzSRmta7rZ29rNZ289CubfXySbJ0OBArk6MZOXO7sNftHIjKQ0mV9/bucHOavaZ4lzvVOCuaLgr98tKWQ13AAAAAAAAAHTRsQJ3H/rQh7KwsHDsr9+6dSu/93u/lx/8wR9Mknz/939/vvjFL+ZLX/rS2aYF6CEbd4sgU1tXyjaa6JYqtZbc11xP2wzy9bq5yZGsPKrh7uaN5MpzyfBI54Z6jHq9np/91BfzpbW7D37BzPXiXHutI/Ns3i0a7s7/StmV5OJkMtz7YVEAAAAAAAAA+texAncntbS0lLe97W0ZGhpKkpRKpbz97W/PV77ylQe+/qd+6qeysLBw73/VarUdYwG01Fq1aF5r60rZRhPd0kZrAnfNexbPwUrZJLl2eSRvbu3m4PDo67+5XUlufyWZf6Hzgz3Ca7eq+av//KV87JNfePALRi4Xa1E72HA3UEomLg515Hlts7WaTFgnCwAAAAAAAEB3tSVwlxQhu/vV6/WHvvYnfuInsry8fO9/4+Pj7RoLoGXWq51ruGs2053VUuOe87BSNknmJ0dyVE/erD5grezKi40Xvb+zQz3GVxqhxldWtx7+opnrRcPdI/5sbJXN7f1MjV3IwEDp8S/uZdWVIqgIAAAAAAAAAF3UlsDd4uJilpeXc3BwkKQI2y0tLeXtb397Ox4H0BVvdqDhbv7ySIYHS1lu2UrZ89VwNz9ZrIpdub3z9d+8eaM4r/VW4K7ZIvjKytbDw+azzyS7t5O7b7Z9ns3aXqbGhtv+nLba3052bicT892eBAAAAAAAAIAnXFsCd1evXs0HPvCB/NzP/VyS5Bd+4Rfy9NNP5+mnn27H4wC6ohMrZQcHSnnb1GiWNlrUcLexnaGBUuYvj7TkvnZrzvnAwN1KI3A3974OTvR4zRbBrd2DrNx5wNxJ0XCXJGuvtH2eSm0/5bH2tTB2RHW1ODXcAQAAAAAAANBlxwrc/diP/VgWFhayvLycD3/4w3nmmWce+fUk+djHPpaPfexjefbZZ/OTP/mT+dmf/dn2/A4AuqS5UnamjStlk2SxPJalSu2Rq7mPa7lSy9umRjN4TtaL3mu4e1BwbeXFZPLtydh0h6d6tPvbCF9eecha2dlm4O7Vts5Sr9ezWdtL+bw33G01Anca7gAAAAAAAADosmMF7n7mZ37m3orYlZWVvPbaa4/8epI899xz+a3f+q288sor+fSnP533vve97fkdAHRJJxrukmShPJra3mE27u6d6Z56vZ7lynYWyqMtmqz9rj1spez+dvLmyz23TjbJV7URvrpaffCLZhoB9fXXHvz9Frm7d5j9w3omR897w91KcY4L3AEAAAAAAADQXW1ZKQvwJFir7mb84lBGhgfb+pzF6bEkyXLlbGtlb2/vp7p7kMXyWCvG6oi5yw9puLv1UlI/TOZ7MHBXqeXd8xNJkpdXH9JwN/WOZGC47Q13m7UipNk/DXdWygIAAAAAAADQXQJ3AKe0Xt3LbJvXySa510i3dN+q0tNoNq+dp4a7keHBlMeGc/NrG+5u3ijO+Rc6P9Qj3K7tZ2vnIC88NZkrExfz6sMCd4NDyfQ3JOvtDtztJ0nKl/ql4U7gDgAAAAAAAIDuErgDOKW16m7b18kmbzXc3b+q9DSWG4G95n0ndnSY3H79TDOcxtzlka9fKbvyYnH22ErZpfs+42fnxvPKajVHR/UHv3j2elL5cnJwtlXBj1JpNNxN9UvDncAdAAAAAAAAAF0mcAdwCodH9Wzc3ctMBxrumitgz9xw13j/qRvufv8fJ3/9fcmXfuNMc5zUtcmRrNzZSb1+X3Bt5UYyOp1cfqqjszzOW6HG0Tw7N5Ht/cO8vvmQoOTs9WItbuWLbZun0mi4mxrtg4a7oZFkZLLbkwAAAAAAAADwhBO4AziFSm0vR/V0pOFudvxCRoYHsrRxtsDdcqUIfp264W7lxaR+lHzyr51pjpOanxzJ3sHRvfBYjg6T1c8V7XalUkdneZxmC+FieSzPzk0kSV5eecha2ZnrxbnWvrWym42Gu3I/NNyNz/XcP28AAAAAAAAAnjwCdwCnsFbdTdKZwF2pVMpCeSyvV862UnZpo5YLQwO5ctqZby8V5xf+v+T13z3TLCcxf7lo5Lu3Vnb9D5P9WjL/QsdmOK63WgTfCty9cushgbvZRuBuvZ2Bu0bD3VgfNNxNzHd7CgAAAAAAAAAQuAM4jfVq0Rw224GVskmyWB7NcmU7R0f1x7/4IZYr21mYGs3AwClbwja/klwYL/7/r//Uqec4qfnJIiC4cqcROFy50fjGN3ZshuNqhhqvTlzM9bnis3rloQ13zxTn2mttm6fSbLi7dI4b7g4PkrtrRcMdAAAAAAAAAHSZwB3AKXSy4S4p1sDuHR7l1tbuqd5fr9ezXNnOU+XR0w+xuZS87QPJc/928vl/ntz6/OnvOoH5yWbDXeP3fvMzxXnt/R15/kks3RdqvDwynLdNjuTl1eqDXzw2nYzNdKThrnyeG+7u3kpS13AHAAAAAAAAQE8QuAM4hTcbwbfZiQ4F7spjSd5aWXpS63f3sr1/mMXpsdMNsL2Z7N5OJheTD/5E8bVP/fTp7jqh+csjSZKV2/c13A2NvtUQ1yOKUGMtC/d9xs/OT+QP36zm4PDowW+auZ6stS9wV6nt5eLQQEaGB9v2jLbbWilODXcAAAAAAAAA9ACBO4BTWL9brOqcudSZ5rCFRjPd0sbpAnfN9y2ctuHu9lJxTi0mC9+SvPOPJS/+H0nlS6e77wTmJxuBuzs7Sb2erLyYzL03GeitENladS87+0dZvO8zfnZuInsHR/nyw/65zT6TbG8kd9fbMtNmbf98t9slSXW1ODXcAQAAAAAAANADBO4ATmGt0w13jda05cr2qd7ffF+zKe/ENpuBu7cX5wf/UlI/TH7jb57uvhO4PDKU0eHB3Ly9k9x5I6mt9+g62Wao8b6Gu7mJJMmrq1sPftPM9eJs01rZzdpepsaG23J3x9xruBO4AwAAAAAAAKD7BO4ATmGtupsLQwOZuDjUkefdWyl72oa7Rhjs1Ctlmw13k4vF+c4PJU99S/Jvfu6tQFSblEqlXJscyeqdnWKdbJLM92DgbqP5Gd/fcDeeJHl5pfrgN802AndtWitb6YuGu1vFOWGlLAAAAAAAAADdJ3AHcArrd/cye+lCSqVSR543OTaciZGhe8G5k2o23J16pezmV4pzqhG4K5WKlrvD3eS3fuZ0d57A3OWRouHuZiNw14MNdw9qEXzm6nhKpeSVW51vuDs8qufOzn7Kl855w11Vwx0AAAAAAAAAvUPgDuAU1rZ2O7ZOtmmxPJaljdOtlF3aqGV0eDAzl07Zdrb5lSSl5PLCW1979nuTq88nn/4HSW3jdPce07XJkWztHOTgjc8kpcHiuT1m+QEtgmMXhrJYHssrKw8J3JWfLn4/a6+1fJ7b2/up15PJ0XPecLe1mgwMJWMz3Z4EAAAAAAAAAATuAE6qXq9nrbp3+vDaKS2UR3Pz9nb2D49O/N7XK9tZKI+evpHv9lIycS0Zuu/3PDCQfNdPJHvV5F//vdPde0xzkyNJkvrNG8nss8nwKZv62mhpYzuXLgymPPbVjXLPzk3ki2t3s3fwgH9uQxeS6Xe2peFus7aXJF83z7lTXUkuXS1+3gAAAAAAAACgy/ztNcAJbe0eZO/wKLPjHW64mx7LUT1Zub1zovcdHdWzXNn+qua1E9tcemud7P3e++8VLW3/6u8mu9XT3/8Y1yZHcjnVDG8t9eQ62SRZqtSyUB77ulDjs3PjOTiq54trdx/8xpnrycYXk8ODls5Tqe0nScpjfdBwNzHX7SkAAAAAAAAAIInAHcCJrW3tJkkXVsoWrW5LG7UTve/W1m72Do+yUD5lK9ze3aS2lky9/eu/NziUfOd/kmxXkt/9n093/zHMXx7J8wNfafzihbY957QOj+p5Y3M7i9Nf/xk/Nz+RJHl59SFrZWefSY72k80vt3SmZsPd1HluuKvXk+pqMj7f7UkAAAAAAAAAIInAHcCJrVWLIFOnV8o2G+qWKicL3C03Xr9YPmXD3e3l4px8QMNdknzTDxSBqN/8W8nB7ume8RjzkyN5b+lLjV/0XsPdyp2d7B/Ws/CAz/j61SJw9+rDAncz14tzrbVrZfui4a62UYQRNdwBAAAAAAAA0CME7gBOaL1ahMqudLrhrhm429g+0fuaAb1TN9xtLhXng1bKJsnQxeQ7/uOkupL8/v9yumc8xvzkSJ4f+FLjF73XcLfcaB180Nreb7hyKYMDpby88rCGu0bgbr21gbu+aLirrhSnhjsAAAAAAAAAeoTAHcAJrTUCd7PjnQ3cPTXVWCl70oa7RkDvQWGwY2muOn3QStmmb/7zyWg5+dRfTw4PTvecR5i9dDHvK305a0Nzydh0y+8/q6VK4zN+QKhxZHgwT8+M5dVb1Qe/uU0Nd5uNhrup89xwt9UI3Gm4AwAAAAAAAKBHCNwBnNC9lbLjnQ0yXbo4lJlLF7Jc6XDD3e1Gw93kIwJ3F8eTb/sLRTjvc//0dM95hIHD3bxr4PW8Vnpny+9uhaWN5mf84FDjs3MT+dL63ezsH379Ny/NJiOTyfprLZ2p0mi4K5/rhrvV4tRwBwAAAAAAAECPELgDOKFuNdwlycL02L1w13EtV7YzcXEok6OnDF41V8pOLjz6dd/6w8mF8eTXfyo5Ojrdsx7m1ksZylE+c/iO1t7bIs1Q4+L0g0ONz85NpF5PXntQy12pVLTctanh7tT/3D/zT5J/8L3J3sl+3lpKwx0AAAAAAAAAPUbgDuCE1qq7GSgl5S6s6lwsj+bW1u6Dm9IeYqlSy1Pl0ZRKpdM9dPMryaUryYXHrKQdm06+5T9K3vyD5JVfOt2zHmblRpLk07sL2TtocZivBZY3tjM1NpyJkQeH256dm0iSvLK69eALZq8nd28l25stm6lS28vlkaEMDZ7yj/rf/jvJV34r+eInWzbTid1ruBO4AwAAAAAAAKA3CNwBnNB6dS/Tly5kcOCUAbYzWJwuQm/HXSt7cHiUm5s79953KreXksnF4732j/5YMngx+fX/PqnXT//Mr3WzCNx99vDp3Nraad29LbJcqWXxIetkk+S5+fEkySurD2i4S5KZZ4qzhWtlK7X9TJ02FHr79eTm7xf//9V/0bKZTqzZcHfpavdmAAAAAAAAAID7CNwBnNBadbcr62STZKFcrCxtrjB9nJU7Ozk4qt9734kd7Bahp6ljBu4m5pMP/GDy+u8mX/yXp3vmg6y8mJ2hydzMdFbv9Fbgbu/gKDfv7Dx0nWySvGPmUoYHS49uuEtaulb2dm0v5bFTrpO911BYSl79RGvDkydRXU3GZpKhzrdJAgAAAAAAAMCDCNwBnNBada9rgbtmi9pxG+6ar3tU+9oj3V5OUk+m3n7893znjyelwaLlrhWODpPVz2ar/J4kpdy83VuBuzc2t1OvJwuP+IyHBwfyrivjjwjcPVuc660L3J2p4e7lX0oGhpNv+oGi4fDWH7RsrhPZWknG57vzbAAAAAAAAAB4AIE7gBPY2T9MdfcgM+Pdady6t1J243gNd0uN15264e72UnFOniBwV346eeHPJl/8ZLL0O6d77v3W/zDZr+Xg6gtJkpUeC9w12wYXH/MZX5+byHJlO9Xdg6//5vQ3JKWBljXc7ewfZnv/8HQNd7tbxT+7d34wed+fLr726sdbMteJ1OtFw93EXOefDQAAAAAAAAAPIXAHcAJr1d0k6VrD3dumRlIqHX+l7L2Gu+lTNtxtNgJ3x10p2/Rd/2lxfuqnTvfc+63cSJJcWPim4pe9FrjbKD7jhcd8xs/NjSdJXn1Qy93QxaJFcP21lsy0WdtPktM13L32K8nhXvLcn0je8V3J8Fh3Ane7W8l+TcMdAAAAAAAAAD1F4A7gBNaqe0nStYa7i0ODmb88ci/k9TjNYN6pG+42v1KcJ1kpmyRX3528+99JXv7FZPVzp3t2UyNwN/H0B4pf3umtwN3yvYa7Rwfurs9NJEleXa0++AUz14s2v6PDM89UqRU/p1Onabh7+ZeK87nvS4ZHknf+seQrv51sb555rhOprhanhjsAAAAAAAAAeojAHcAJrHe54S4pwnMnabibGhvOxMgpglfJfStlT9hwlyQf/Ini/NRPn+7ZTTdvJEOjuTD37sxcutB7DXeNFsHHhRqfawTuXn5Qw12SzF5PDnff+szPoNlwVz5pw93hQfLqv0jm359MLhRfe/ajSf0w+cNfPfNcJ7K1Upwa7gAAAAAAAADoIQJ3ACfQXCl7pYuBu8XyWDZr+9na2X/sa5c3ao9tXnukzaVkZDIZuXzy9z71zck3/FvJZ38h2fjC6Z5frxcNd3PvTQYGMz850nMNd0sbtVyZuJiR4cFHvm5xeiwjwwN55WGBu5lninPt7GtlN0/bcLf028l2pVgn2/TMR4rz1U+cea4T0XAHAAAAAAAAQA8SuAM4gW6vlE2ShekiQLdcefRa2b2Do6zc2Tn9OtmkWCl70nWy9/vgX0rqR8lv/I3TvX/rZlJbT+ZfSJJcmxzJ6p2dHB3VTz9Tiy1Xalk8xmc8OFDKM1fHHx64m71enOuvnnmmymkb7j7/i8X57vsCd1OLydX3Jq99Ijk6OvNsx6bhDgAAAAAAAIAeJHAHcAJrPbBSthnuWtp49FrZm7e3c1QvmtVO5fAgufN6MnmGwN3T35UsfGvy+/84ufPGyd9/80ZxXnt/kmTu8kj2D+vZaDS4dVtt7yBr1b1jf8bPzk1k9c5ubtce0E440wjcrbUicFd8PicK3NXrycu/mFxeKFbK3u/6R5L/n727D278Puz8/gbAZwIEn3ZJasmVJS25imXJieM8yHYS+2JLltxJLvnjkrlOc502MzfNNdfcJWmTS5vm6XJ3nSS93jS59maaXjuZ3txc08ulsWRLdpz4IbZrx4kl+WGXK1lacLXkLkkAxBMBEED/+AHUcpcPIPgAEPt+zWS+Fh5+/GrFyJnJZz6f3G24+VdHvlvTbLiTJEmSJEmSJEmSJHUgA3eSdAgd0XBXn4hNHNBw12jAa7nhLnMTapWg4axVoVDQclcpwed/9/DfX64H7qbfCQQNdwDL6c6Ylb1R/zNudrZ3YSoGwNVbu7TcxaahL3osDXctTcrevgLJb8HlZ4J/bndaeDo4r75w5Ls1rRG4s+FOkiRJkiRJkiRJktRBDNxJ0iGsZYvEBnro74m07Q5z48013DXebzYMdo90IjiPMikLQVhr6h3w5d+H/PrhvnvzqxAKw9TbgaDhDjoncJdIBn/GzYYaLzcCd7vNyoZCMHHpWBruUvUGvUMF7q58NDgvP3Pve7PfDQNxWDzFwF1mGfpHoK/F319JkiRJkiRJkiRJkk6AgTtJOoTVbJFzbZyTBZiJD9ITDm032O3lyA13qevBGT9Cwx0EQbL3/QMo5+GL/8vhvrv8MkwuQG/w9zATD86bGx0SuFuvN9w1OSk7PxUF4OryLoE7gMn5oFmwuMf7TUrmy/SEQ0T7e5r/0pXnoS8WzADfLdIDj/wgvPkVyN460t2all2BqHOykiRJkiRJkiRJkqTOYuBOkg5hNVtiss2Bu0g4xAOjgywlD2i4225fa7EhLNVouDti4A7gsR+B8YeDwF2zYbJCClJvwPQT2y9Nx4M/++X0/mHD03LYFsELo4MM90W4slvDHQThQoC1a0e6VypfYnSoj9Dd07B7yazA0pdh/oPQs8fv9/xTwXntE0e6W9Myy8HMriRJkiRJkiRJkiRJHcTAnSQ1aatSJZkvMRHta/dVmBsfJLGep1ar7fmZxHqeyWgfg30tzt+m6w13ow+29v07hSPw3p+BzXQwLduM5ZeDc+bOwF3QcLecLh79TscgkcwTDsHM6EBTnw+FQsxPxVhcye7+gYlLwbl6tMBdMl9i7DBzslc/BtTg8rN7f+bSB4EQXP34ke7WlPImbKZsuJMkSZIk7wD5ZQAAIABJREFUSZIkSZIkdRwDd5LUpPV8iVqNtjfcAcyODpErVUjmy3t+ZilZaL3dDoJJ2d5hGBxr/Rl3euePQ+wB+Iv/OQhUHWT5peC8o+Eu2t9DtL+H5Y3OaLhbShaYiQ/SG2n+v04vT8VYy5VYze4SGpycD861xSPdK5UvM3qYwN2V5yEUqYfq9hA9BxfeBa9+Cip7/94di+xKcNpwJ0mSJEmSJEmSJEnqMAbuJKlJq5kSQMc03MFbk6Z32yxXuJUpMjs22PoPSSWCOdlmZ0kP0tMP7/lpyN2Cv/6Dgz/faLibfnzHy9PxAZbTTQT2TkFiPX/oP+P5qSgAV3eblR1/JDhXWw/c1Wo1UoUyo0NN/p6WcvDap+DB98DQ+P6fnX8aimlIfLHl+zWlEbiz4U6SJEmSJEmSJEmS1GEM3ElSk9ZyQSNZJzTczY0HzXVLyd2b3m6kCjs+d2jVKqSXID7X2vf38p1/BwbH4XP/08EtaTdfCn7+XSGw6ZHOCNylC2U2NrcO/Wd8eToGwNXlXQJ3fUPB3/MRGu4yxS0q1Vrzk7Kv/Rlsbe4/J9sw/6HgXHyh5fs1JbMcnDbcSZIkSZIkSZIkSZI6jIE7SWpSYwK0EwJ3janYRHL3hrtG813LDXe5W1ApwujF1r6/l75h+N6fCuZqX/nDvT9X3oTb39wxJ9swHR8gV6qQ2TzhWdMDNP6M5w4523t5qh64u5Xd/QMTl2Dt1SD02IJULvhzGWu24e7Kc/WLPXPwZ2e+HYbPw9UTDtzZcCdJkiRJkiRJkiRJ6lAG7iSpSWvZYFJ28gxMyjaa7w4bBtuWSgTn6DE33AF8909CXww+8zt7h8pufwNqFZjZJXA3MgDQ9pa7pXrYsfHPolnnYv3EB3t3b7gDmJyHch4yb7Z0r2Q++D1talK2WoErH4Pzb4fxhw7+fDgctNzd/kYQmjwpNtxJkiRJkiRJkiRJkjqUgTtJatLtDmq4Oxftp78nTGKPSdlG813LDXfpepjquCdlAQbH4Lv+c1i9Alc+uvtnbr4UnNOP3/PWdLweuNtod+CutdneUCjE5akYV1cy1Gq1ez8wMR+cq63NyqYKQcPdaDOTsktfhvxqc+12DfNPBedJzspm64G76PmT+xmSJEmSJEmSJEmSJLXAwJ0kNWk1U2+4i7U/cBcKhZgdG9xuWbvbUrJAKAQXWg3cNdrLRh9s8YYHePLvQc8AfOa3YbfQ2XIjcLd3w93NNjfcHWW2d34qysbmFisbxXvfnLwUnGvXWrpXqt5wN9ZM4K4ReLz8keZ/wCMfgHAPLL7Ywu2alFmBSD8MjJ7cz5AkSZIkSZIkSZIkqQUG7iSpSWu5Iv09YYb7Iu2+ChA0qy0lC1Sr9wbWltbzTMUG6O9p8a4nOSkLQXPZu34C3vwreO1T975/86WgCS8+e89bjYa7lXYH7pIF+iJhpmIDh/7u5ekYAFdXdpmVPWLDXTJ3iEnZK89DdAoe+I7mf8BAHC4+Ca/9OZR3b1g8suwyxKYgFDqZ50uSJEmSJEmSJEmS1CIDd5LUpNVskcloP6EOCQHNjQ1R2qpuT93eaSlZaH1OFiCdgEgfDJ/gpOd7fjpoSvvM7+x8vVqBla8F7Xa7/Fk3Anc32zwpm1jPc2FskHD48L8P8+f3CdyNXICeQVi92tK9kvlgUnbsoMDd6rXgZyx8GMKH/D8H5j8EWwV4/XMt3fFAmRWITp/MsyVJkiRJkiRJkiRJOgIDd5LUpNVMqSPmZBvmxoNAXWPatCFX3GItV2JufKj1h6euQ3zu8EGswxi9CE/8GLz+Gbj+xbdeX38NyjmYfnzXr40P9dEXCbe14a5Wqx0p1LgwFQXgyvIugbtwGCYunfyk7JXngvPRQ8zJNsw/HZyLHz/8dw9S2YLc7aDhTpIkSZIkSZIkSZKkDmPgTpKaUKvVWMsVmRxuYqbzlMyOBYG6RHJn4O5GqlB/v8WGu1otmJQ9qTnZO733Z4AQfPaOlrubXw3OmXfu+pVwOMRUvJ+bbQzcreVKFMqVlkONE9F+JqN9XL2V3f0Dk/NBy2Apv/v7+0gVgoa7+IGBu+ehdwge+v5D/wzOXYb4RVh8Ifh9OU6520DNhjtJkiRJkiRJkiRJUkcycCdJTdgobFGu1JiMdlDDXT1wt7Re2PF6o/Gu8f6hFZJBw1z8FAJ35xbg7T8EVz8Gyy8Hry2/FJzTT+z5temRAVbaOCnb+DM+ymzvwlSMxZUM1eougbXJ+eBcf/XQz03mywz1Rejviez9odwaJL4Aj/wN6G3h7yEUgoWnIPk6rC4e/vv7yS4Hpw13kiRJkiRJkiRJkqQOZOBOkppwO1sEYDLWOQ1325OydzXcLSWP2HCXeiM4Rx9s+W6H8r5/GJyfqbfcLb8MPQPBrOoepuODrOVKFLcqp3DBeyXqf8YthxoJAnf5UmW7kXCHiXrgroUwWypfYmzogN/TxY9DrQqXnz3087fNP1V/1gutP2M3mZXgtOFOkiRJkiRJkiRJktSBDNxJUhPW6oG7ieHOabiLD/YS6+8hsVfDXYtzp6QSwXkak7IAD3w7XPogfO3fw+o1uPkSTD0GkZ49vzI9EvxzuLVRPJ073uXIf8YEgTuAqyuZe9+crIcN164d+rnJfInRA+dkn4NQGBaePvTzt73t+4Jg5OLHW3/GbrYb7gzcSZIkSZIkSZIkSZI6j4E7SWrCarYEwGSscwJ3oVCI2fGhXRvuwiGYjg+09uB0PXB3GpOyDd/3s0ANPvYLkF/dd04WgoY7gJvp9szKLiUbs72tT8peno4CcHUle++bjXa/VhrucuX9G+7Km3DtT2Hue2B48tDP39Y3FITu3vg8bG60/py7ZW8FZ9RJWUmSJEmSJEmSJElS5zFwJ0lNWMvVJ2WHO2dSFoLZ2JvpTbYq1e3XEsk8M/FBeiMt/is+dT04Ry8eww2b9OB74OKTcO3F4K9nDgjcjQRhwpvpXeZYT8FSssBQX4TxI/w+XDq/T8NdfwxiM7B2uMBduVIlU9wivl/D3bc+DeUcXH7mUM/e1cLTUC3Da3929Gc1ZGy4kyRJkiRJkiRJkiR1LgN3ktSE1Uw9cNdBDXcAc2NDVKq1HU1vS8kCs0doXiOVgFAkCHydpu/72bf+84ENd0HgbmWjPQ13ifU8s2ODhEKhlp8RH+xlJj6we+AOgpa71WtQqzX9zHShDMDYfoG7K88F5+Vnm37unuY/FJyLLxz9WQ3ZleD3b+gI7XuSJEmSJEmSJEmSJJ0QA3eS1ITbjUnZaIcF7saDYF1jVnZjs0y6UGZufKj1h6avw8gFiPQcxxWbd+mDMP04RPrg/Nv3/WgjcNeOSdlKtcaNVIG5sSP8GdfNT8VYvJWlUt0lVDc5D6VMEEBrUiof/J7uOSlbrcKV52FiPnj+UY29DSYvw+KLhwoG7iuzDNHzEPb/RJEkSZIkSZIkSZIkdR7/v9mS1IS1bJFIOMTo4D7NYW3QCH0trQfTqon1IHh35Ia705yTbQiF4Mf/L/iJP4a+/cNs52P9hELtabhb2dikXKkdLdRYd3kqSmmryhtruXvfnKgH4labn5VN5oOGu9G9Anc3/wqyy8czJ9sw/6HgmcsvHc/zsisQnTqeZ0mSJEmSJEmSJEmSdMwM3ElSE1azRcaH+wiHW58QPQmN0Fej4W4pGQTvWm5f29yAzRSMzh3L/Q5t9CI8+OSBH+uNhJmM9rel4e5YQo1181MxAK6uZO99s9FAt3aIwF2u0XC3RzD0m/U52Uc/0vQzD7TwdHBePYZZ2VotCNzFpo/+LEmSJEmSJEmSJEmSToCBO0lqwmq21HFzsvBW6KsRAjtyGCydCM54mwJ3hzATH2ClDYG77VDjsTTcNQJ3mXvfnLgUnKvXmn5eqtBouNsjcHfleRiagNnvOtQ99zX3vdAXg8VjCNwVklAp2XAnSZIkSZIkSZIkSepYBu4kqQlr2SKT0T1mOttouL+H8eG+7RDYkcNgqXrgrh2Tsoc0NTLASqZIpVo71Z/baBM8joa7S+ejwB6Bu9GLEOmH1atNPy+VDxrudp2UTb4Ot74GCx+GcKSV6+6upw8e+QAsfQlya0d7VmY5OG24kyRJkiRJkiRJkiR1KAN3knSAQqlCrlTpyIY7gLmxwTsmZfP0RkJMjQy09rDU9eBs16TsIczEB6hUa6xli6f6cxPrx9dwN9zfw9z44O6Bu3AEJh453KRsPmi4G9stcHfl+eC8/GwrV93f/FNADV795NGek60H7my4kyRJkiRJkiRJkiR1KAN3knSA1XqgqxMb7gBmx4dY2SiyWa6wlCzwwOggkXCotYel64G7MzAp2wgV3jzlWdlEMk98sJeRgT1mWw9p4XyM127nKG1V731z4lIQgtxqLlTYaLgb221S9spzQWPeIx84ynV3N/+h4Lz68aM9J7MSnDbcSZIkSZIkSZIkSZI6lIE7STpAI3A30bENd0HT2o1UgcR6fvuvW5JKACGIzx7P5U7QTDwI3C1vnG7gbmk9z9z40edkGxamY2xVa7y+lrv3zcl5qFVh/bWmnpXMlQmFuDcMWEjC65+Dh98PfcNHvvM9YtMw80649gmoVlp/znbDnYE7SZIkSZIkSZIkSVJnMnAnSQdYzQatYZ06KTs7FoS/Xl5KkytVtv+6JanrQXiqpzP/Xu803QjcnWLDXWmryvLG5tFCjXe5PBUD2H1WdmI+OFebm5VNFUrEB3sJ391wuPgJqFXg0ROYk22Yfxo2U7D0pdafsd1w56SsJEmSJEmSJEmSJKkzGbiTpAOsdfik7Nx4EP76/KtrO/66JenEmZiTBZgeOf2Gu5vpAtUaRws13mV+KgrA1eVdAneT9cDdWpOBu3yZsaFdfk+vPBecCx9u5YrNmX8qOBdfaP0ZjYa74fNHv48kSZIkSZIkSZIkSSfAwJ0kHWB1O3DXma1vc/Xw1+dfCwJ3LYfBygXI3YbRi8d1tRPVjoa7xHoBOGKo8S6PnIsSDsHVley9b05cCs7Va009K5kvMTp015zsVimYer3w7qC98KRceBcMTcDVIwTuMiswOA49nRlulSRJkiRJkiRJkiTJwJ0kHaDTJ2UvjA0SCsH19TwAs63OnaYSwTl6Nhruhvp6GBnoOd3AXTL4Mz7OSdmB3ghvmxjefVJ2cBSGzzXVcFer1Uju1nD3xmehuAGXnzmmG+8hHIFLH4SVl2HjzdaekV0+2VCgJEmSJEmSJEmSJElHZOBOkg7QaLgbH+7M1q3+nghTsYHtv55rteEufT04z8ikLMBMfPBUJ2UT9VDj3PjxTcoCLEzFeH0tx2a5cu+bE/Owugi12r7PKJQrlLaq9zbcXXk+OC8/e0y33cdRZ2UzKxCdOr77SJIkSZIkSZIkSZJ0zAzcSdIBVrNF4oO99PV07r8yGzOy/T1hzsVabOLbbrh78JhudfKm4gMspzepHRBGOy5LyWBStuUWwT0sTEWp1uDV27vMyk5egs0U5Nf2fUYqXwZgdPCOYGitBt98DsbeBue/7RhvvIdH/gaEwrD44uG/W8xAOWfDnSRJkiRJkiRJkiSpo3VuekSSOsRqtsRktDPb7RrmxoMAWDAvG2rtIal6w90ZmZQFmBkZoFCusFHYOpWfl0jmmYz2M9AbOdbnLkzHAHaflZ2YD87V/Wdlk/lg+njszoa75ZdhYylot2v19+IwhsZh7nvg1U/BVvFw382sBKcNd5IkSZIkSZIkSZKkDmbgTpIOsJYtMhFtsTXulDRmZOeO0ryWrjfcxWeP4UanYyoeTOne3Cicys9LrBeOfU4WgklZgKsruzXcLQTn2v6Bu+2Guzunj7fnZJ858h2bNv+hoKnujb843Peyy8Fpw50kSZIkSZIkSZIkqYMZuJOkfZQrVZL5Muc6PHA3W2+4a0zLtiSVgKFJ6Bs+pludvJl64G45vXniP6tQqrCaLR4t1LiHt00M0xsJcXV5l4a7yUbD3dV9n7Frw92Vj8LAKFx88riuerD5p4Nz8YXDfS9TD9zZcCdJkiRJkiRJkiRJ6mAG7iRpH+u5IMTU6ZOyD08GIbmHJo8QlktdP1NzsgDTI6cXuFtK5gFOpOGuryfMQ5PDXL21S+Bu9EEI98LqtX2f0Wi4Gxuq/66mb8DNr8L8UxDp3eebx2zqMRi5cPjAXbY+KWvDnSRJkiRJkiRJkiSpgxm4k6R9rGaLAB0/KfudD47xe//xu/jb33OxtQdslSBzE+JnLHDXaLjbOI3AXTBbexINdxDMyibWC+SKWzvfiPTA+ENNTMoG4dD4YD1cd+W54DzNOVmAUCiYlV27BmuvNv+9RuDOhjtJkiRJkiRJkiRJUgczcCdJ+1jNNhruOjtwFwqFePbxGYb6elp7wMYNoAajLQb22uQ0G+4S9Ya72RMK3F2eigFw7Vb23jcn5iH5OlTKe34/2Wi4G6433F15PmjGu/TB477qweafCs7FF5v/TsaGO0mSJEmSJEmSJElS5zNwJ0n7WKs33HX6pOyRpa4H5xkL3I0O9dLfEz6VhrvE+slNygLM1wN3V1Z2mZWdvATVrSB0t4dkveFubKgXNjfgW5+Gh74PBkZO4rr7e+gHINIHix9v/jvZZeiLQd8RZpElSZIkSZIkSZIkSTphBu4kaR9nZVL2yNKJ4Dxjk7KhUIjp+MDpNNytFwiH4IHRkwncXZ4OAndXl3cJ3E3MB+fq3rOyqXyZvp4wg70RePWTUC3D5WdP4qoH64/Cg++F1z8LpVxz38msQMw5WUmSJEmSJEmSJElSZzNwJ0n7aEzKnuv2wF2qHrgbPVuBOwhmZU+l4S6ZZyY+SG/kZP6r8+L4EP09Ya7uNik7WQ/cre0XuCsxNtRLKBQK5mQBLj9zAjdt0sLTUCnBa3/e3OezyxB1TlaSJEmSJEmSJEmS1NkM3EnSPt5quLtPJmXPWMMdwEx8gFS+zGa5cqI/ZylZYHbsZNrtACLhEJfOR4/UcDc62AeVMlz9OEw/AfHZE7ptE+afCs7FFw7+7FYRCkkb7iRJkiRJkiRJkiRJHc/AnSTtYzVbYrA3wnB/T7uvcrLSCeiPw+Bou29yaFPxAYATnZXd2CyTLpSZHRs6sZ8BsDAVY3ljk3ShvPON4QkYHIO1a3t+N5kvMTrUC9e/AJspePQjJ3rXA008AuOPBIG7Wm3/z2ZXgtOGO0mSJEmSJEmSJElShzNwJ0n7WM0UmYx1ebsdBA13Z3BOFmBmJAjc3TzBwF1iPQ/A3PjJNdxBELgDWFzZo+Vuj4a7arVGulBmbKivM+ZkG+afgo0bcOvr+38uUw/c2XAnSZIkSZIkSZIkSepwBu4kaR9ruSITw/3tvsbJqlaCUNToxXbfpCXT9Ya7lY2TDNwVAJg78Ya7KABXV7L3vjk5D/nVYHr1LhubZao1GBvqgSsfhZHZYFK23Rbqs7JXP77/57LLwWnDnSRJkiRJkiRJkiSpwxm4k6Q9VKs11rIlJqNdHrjL3ITqFsTPZsPddDxonTvJhrulZKPh7uQnZQGu7tZwNzkfnKv3zsqm8sEE7SPcgOTrQbtdKHRS12zeg++F3mFYfHH/z2XqgTsb7iRJkiRJkiRJkiRJHc7AnSTtIV0os1Wtca7bJ2VTieA8o5Oy0yMn33C3lKw33J3wpOyF0UGG+iK7B+4mGoG7q/e8lcyXAHg897nghU6YkwXo6YeH3w+JL+7azLctW5+UteFOkiRJkiRJkiRJktThDNxJ0h7WckWA7p+UTTcCd2dzUvZcrJ9IOMTNdOHEfkZiPU9vJMT52MCJ/QyAcDjE/FRs/4a7tcV73mo03F1a/zT0xeBt33eS1zyc+Q9BrQKv/unen2k03EXPn86dJEmSJEmSJEmSJElqkYE7SdrD7UzQGjYZ7faGuzeC84xOykbCIc5F+1neKJ7Yz0gk81wYHSQSPvmZ1stTUVazJdayd/39jD0EoQis3hu4S+ZLnCPFROolmP8g9HTQ7+z8U8F59YW9P5NdgUg/DI6dzp0kSZIkSZIkSZIkSWqRgTtJ2sNqPfA0GevyhrvU2W64A5iOD7B8Qg13tVqNxHqBufGhE3n+3RamYgBcXcnufKOnD8YehLVr93wnmS/zg5GvBH9x+dmTvuLhxC/A1Dvg2otQre7+mcwyRKcgdPKBRkmSJEmSJEmSJEmSjsLAnSTtodEwdl9MyvYOwdBEu2/SsumRAW5nimxV9gh0HcFarkShXGF27LQDd7vMyk7Mw/prUK3seDmdL/HB8F9SC0WCCddOM/8U5Nfgza/s/n52BWJTp3snSZIkSZIkSZIkSZJaYOBOkvawmg0mZc/FOmie8ySkrgdzsme4XWw6PkC1BrfvnmE9BkvJoDlvbnzw2J+9m30Dd5PzUCm9NQNcl81s8L7wK5Rnn+zMWdbGrOziLrOy1QrkbgcNd5IkSZIkSZIkSZIkdTgDd5K0h7VcfVI22sUNd7UapJdgdK7dNzmS6fgAADfTm8f+7MR6HuDUGu6mRvoZGejZo+HuUnCu7pyVnV77PAOhMpFv67A52YbZ74KBUbj68Xvfy92GWhVi06d/L0mSJEmSJEmSJEmSDsnAnSTt4XamRE84xMhAb7uvcnJyt2FrE0YvtvsmRzJTD9ytnETgLhkE7ubGTqfhLhQKsTAV4+pKllqttvPNyfngXFvc8fLl1GcBiDzaoYG7SA9c+kG4+deQWdn5XmY5OKMG7iRJkiRJkiRJkiRJnc/AnSTtYTVbZCLaRzh8dqdWD5S6Hpzxs91wNzVykg13jUnZ02m4A1iYjpEulLmVuWsid6IeuFu9I3BXrfDOwhd4NXQRxh86tTse2vzTwXntxZ2vZ+sBvJiTspIkSZIkSZIkSZKkzmfgTpL2sJYrMjHcxXOy8Fbgrlsa7jaOP3C3lMwz2BthYrjv2J+9l4XzUYB7Z2Wj56F/BNbumJRd+hKjtTRfHnjy1O7Xkks/CIRg8YWdr9twJ0mSJEmSJEmSJEk6QwzcSdIeVjMlJmNdHrhLJ4LzjAfuTrLhbilZYG58kFDo9JoOF6ZjAFxZvitwFwoFs7J3NtxdeQ6Ar8fee1rXa83wJMy+G179FFTKb71uw50kSZIkSZIkSZIk6QwxcCdJu8gVtyiUK0xGT6/VrC26ZFJ2oDfC2FAvy8fccFet1riRLDA7dnpzsgALU0HgbnEle++bE/OQXYbNDQBq33yOldooqdF3nOYVWzP/FBQ34PoX3nqtEbiz4U6SJEmSJEmSJEmSdAYYuJOkXaxlSwBMRru84S6VgEgfRM9+u9h0fJDlY264W8lsUqpUmRsbPNbnHmQy2s/EcB9X7p6UBZi8FJxri7C6SGhtkU9W3sXoWZg/nn8qOBc//tZrmWUIhYMGPEmSJEmSJEmSJEmSOpyBO0naxe1sEaD7G+7SCYjPQvjs/9fB9Eg/yxub1Gq1Y3tmYr0AwNz46TbcQdByt7iSuffvZ2I+OFevwZXnAXix+p2MDp2B39XpJ4Jw5+KLb72WXYHh8xCOtO9ekiRJkiRJkiRJkiQ16ewnLCTpBKxuB+7OQGtYq2q1YFL2jM/JNkzHByltVUnmy8f2zMR6HuDUJ2UBFqai5EoVbqQKO9+YrAfu1hbhynNUegb5i+pjjA71nvodDy0chvkPwe1vQvKN4LXMCsTOfsOiJEmSJEmSJEmSJOn+YOBOknbRmJSd6ObAXSEJpSyMdkngbmQA4FhnZZeSjYa7052UBViYjgFw9e5Z2fGHgRBc/wIkvsjt8++jSB9jZ6HhDu6YlX0hCH1mlyE63d47SZIkSZIkSZIkSZLUJAN3krSL1fthUjadCM7RB9t7j2MyE68H7jYKB3yyeYlkOxvuGoG77M43egeDkOTrn4FalTcmvx/gbDTcATz8AQj3BIG7QhIqJRvuJEmSJEmSJEmSJElnhoE7SdrFWj1wd66bG+5S14OzSyZlpxqBu3Tx2J6ZWM8zMtBDfPD0w2wL5+uBu+XMvW9O1GdlQ2G+Hn0PwNlpuBsYgYtPwrc+DcnXg9dsuJMkSZIkSZIkSZIknREG7iRpF6v1Sdmx4TMSYmpFqtFw1x2Bu+2Gu/TxNdwtJQvMjZ9+ux1AfKiXqZF+rt7aJXA3WQ/czX0Py5Vh4AwF7gAWnoatTXjlD4O/tuFOkiRJkiRJkiRJknRGGLiTpF3czhYZG+qlN9LF/5rcnpS92N57HJOpkcak7OaxPK9cqXIzXWCuDXOyDQtTMRZXslSqtZ1vNAJ3l58hlSsDQUDvzJh/Kji/+m+C04Y7SZIkSZIkSZIkSdIZ0cVJEklq3Vq2yGQ3z8lCMCkbikDsgXbf5FiMDPQw1BfhZvp4Anc3U5tUazA3Pngsz2vFwlSM4laVxHp+5xuP/Sh879+Dd/0EyXyJSDjEyEBPey7ZiskFGH0Q8mvBX8cM3EmSJEmSJEmSJEmSzgYDd5K0i9VsiYnoGZrobEXqOow8AJEzFNTaRygUYnpkgOVjCtwlkkHIbbaNDXeXp2IAXFm5a1Z2aBw+/JswOEYqX2Z0sJdQKNSGG7YoFHqr5Q4g6qSsJEmSJEmSJEmSJOlsMHAnSXcpbVVJF8rd33CXTnTNnGzDdHzg2CZlG61y7Wy4m5+KArB4d+DuDsl8idGzNCfbsPD0W/85er5995AkSZIkSZIkSZIk6RAM3EnSXdZzJYDuDtwVM1BIQnyu3Tc5VtMjA2Q2t8gVt478rEbD3VwbG+7mtxvusnt+JlUoMzZ0BtsY3/Y+6BmEwTHo6eL/XZMkSZIkSZIkSZIkdZXu2BGUpGO0mi0CMNnNk7KpRHCOdlngLj4AwPLGJo+cix7pWYn1AtDeSdlofw+zY4NcXd694a5Wq5HKl3jnbPyUb3YMegfhvX8fyoV230SSJEmSJEmSJEmSpKYZuJOku9zeDtx1cetWuhG4675JWYDl9NEDd0vJPJPRfgb7IsdxtZYtTMXbrw+4AAAgAElEQVT4zOJtypUqvZGdxbS5UoVypcboWWy4A/jAP2r3DSRJkiRJkiRJkiRJOhQnZSXpLmvZYFJ2opsDd6nrwdmFk7IQBO6OKpEsMDs2eOTnHNXCVIxypcbrq7l73kvW54/HhnpP+1qSJEmSJEmSJEmSJN2XDNxJ0l3uj0nZeuCuyxruZuJBQG5542iBu81yhduZInPj7ZuTbViYCpr6rq5k73kvlS8DnN2GO0mSJEmSJEmSJEmSzhgDd5J0l7X7aVI2PtveexyzqXjwz+yoDXdLyTwAcx3ScAdwZSVzz3upQqPhzsCdJEmSJEmSJEmSJEmnwcCdJN1ltT4p29WBu1QCotPQ011/j5PD/fSEQ9w8YuAusV4A6IiGu0vno4RDsLhL4C653XDnpKwkSZIkSZIkSZIkSafBwJ0k3WU1W2S4L8JgX6TdVzk5qeswOtfuWxy7cDjE1MgAK0eclH2r4a79gbuB3ggPTgzv3nCXD8KhBu4kSZIkSZIkSZIkSTodBu4k6S6r2RKTse5qftuhvAm5WxDvvsAdwHR84OgNd8mg4W62AyZlAebPR3ljLc9mubLj9WQuaLhzUlaSJEmSJEmSJEmSpNNh4E6S7rKaLTIx3MUBpvRScI5ebO89Tsj0yABruSKlrWrLz0is5wmF4IHRzgjcXZ6OUanWeO12bsfryXrDnYE7SZIkSZIkSZIkSZJOh4E7SbpDtVpjPVdiMtrFDXepN4KzCydlIWi4q9XgVqb1lrtEMs/MyAB9PZ3xX5PzUzEArt41K5suBA13TspKkiRJkiRJkiRJknQ6OiNJIEkdIlUoU6nWmOjmwF06EZzx7m24A1jZOELgbr3A7PjQcV3pyC7vEbhL5ksM9IYZ6I2041qSJEmSJEmSJEmSJN13DNxJ0h1Ws0UAzkW7eKIzVQ/cdeukbDwI3N1Mtxa429gsky6UmRvrnMDdQ5PD9IRDuwTuys7JSpIkSZIkSZIkSZJ0igzcSdIdVjNB4G4y1sUNd6nrwdnFk7IAyy0G7pbWCwDMjg0e252Oqq8nzEOTw1xdye54PZUvMWrgTpIkSZIkSZIkSZKkU2PgTpLusJorATAx3MWBu3QCBsehb7jdNzkRjUnZVgN3iWQegLkOmpQFWJiOcX09T760tf1aMldibKi3jbeSJEmSJEmSJEmSJOn+YuBOku6w3XDX7ZOyXTonCzBVD9zd3GgxcLdeD9x1UMMdwML5GADXbgUtd5VqjY3NLSdlJUmSJEmSJEmSJEk6RQbuJOkOa7kun5StlCHzZtfOyUIwvzoZ7WOl1UnZZDAp22kNd5enowBcWc4AkC6UAYjbcCdJkiRJkiRJkiRJ0qkxcCdJd1jNBJOyk906KbtxA2pViHdvwx0ELXc3Ww7c5emNhLab8jrF/FTQcLdYb7hL5oPfVSdlJUmSJEmSJEmSJEk6PQbuJOkOq9kifZEwI4M97b7KyUglgrOLJ2UBZuID3MpsUq3WDv3dxHqBB0YHiYRDJ3Cz1j04PkRfT3i74S61HbhzUlaSJEmSJEmSJEmSpNNi4E6S7rCaKzER7SMU6qyw1bFJXQ/OLp6UhaDhrlypsZYrHep7tVqNRDLP3FhnzckC9ETCPHIuyuJKELhL5oJJ2VEDd5IkSZIkSZIkSZIknRoDdzpztipVvrm80e5rqEutZopMRLs4wJSuN9zFuztwNxMP5mBXNg43K7ueK5EvVZgbHzyJax3Z5akob6Y32dgskyoEgTsnZSVJkiRJkiRJkiRJOj0G7nTm/NFfv8mH//ln+OtEqt1XUZep1WqsZotMRvvbfZWTc59Myk7Hg8DczfThAneJZAGA2Q5suAOYn4oBsLiS2Z6UHTVwJ0mSJEmSJEmSJEnSqTFwpzPn9dUcAF/61nqbb6JukytVKG5Vuztwl74O/SMwONrum5yo6ZGg4W75kA13S8k8AHPjnRm4u1wP3F1dyZLcDtx1cSOjJEmSJEmSJEmSJEkdpqfdF5AOay0XhExevpFu803UbVYzRYDunpRNXe/6OVmA6fqk7HK6cKjvJdYbDXcdOik7HQTurixnKFWqAIwZuJMkSZIkSZIkSZIk6dTYcKczZz0XhKIM3Om4rWaD361z3dpwV61C+kbXz8nCnYG74qG+l2g03HXopOyF0UEGeyMs3gomZUMhiA86KStJkiRJkiRJkiRJ0mkxcKczZ73ecPet1Rwbm+U230bdZDUb/G51bcNddhmqZRjt/oa7aH8Psf4eljcO23CXZ7A3wmSH/g6EwyEWpqJcWc6SypcZGeglEg61+1qSJEmSJEmSJEmSJN03DNzpzGlMygK8YsudjlGj4W6yWxvuUteD8z6YlAWYig+wnN481HeWkgVmxwYJhTo3xDY/FWM1W+RbqzlGh2y3kyRJkiRJkiRJkiTpNBm405mzni3ycM8qYOBOx2ut3nDXvYG7RHDeB5OyADOHDNxVqzVuJAvMjXfmnGzD5akYADfTm4wOdWYTnyRJkiRJkiRJkiRJ3crAnc6UrUqVv1P6t/xpz99nIZTg5Rsb7b6Sukij4a5rJ2XT9Ya7+2BSFmBqZIBcqUKmyenpW5kipUqV2bHBE77Z0cxPRbf/85gNd5IkSZIkSZIkSZIknSoDdzpTNm5c4ad6/gMAT8bXeHkp1eYbqZusZouEQjDera1h25Oy90/DHdB0y10imQdgbqzDG+6mY9v/eaxbf1clSZIkSZIkSZIkSepQBu50dtRq9L/439Af2gLg8ZFNXl/Lky40114lHWQtW2J8qI+eSJf+qzGVgJ5BGJ5s901OxdRIPXC30WTgbr0euBvv7Ia76ZEBYv09AIzacCdJkiRJkiRJkiRJ0qnq0lSJutI3/pjhxJ/z5eoCAI8MZgH42o10O2+lLrKaLXbvnCxAOhHMyYZC7b7JqWg03N1stuFuvQDAbIc33IVCIRbqLXejg138+ypJkiRJkiRJkiRJUgcycKezoZiFj/0i5d4YP1/+uwBc6NkA4GUDdzomt7NFJqP97b7GyajVgoa7+Fy7b3JqthvumgzcLTUmZcc7O3AHsDAVBWBs2IY7SZIkSZIkSZIkSZJOk4E7nQ2f/h9g4wZfufRf8q3aNJVIP+O1JGDgTsejuFUhs7nVvYG73CpsFWD0YrtvcmoaDXdNT8om88QGeogPdn6IbWGq3nA3ZMOdJEmSJEmSJEmSJEmnqafdF5AOdOub8PnfhZl38vmxHwZeozI0RV/uFg+fGzZwp2Oxli0BdO+kbPp6cI7ePw1348N99EXCTTfcJdYLzHX4nGzDD73zARZvZfmBhXPtvookSZIkSZIkSZIkSfcVG+7U2Wo1eO7noFqBj/wOa/kKAKHYFGSXefxCnDfW8qTz5TZfVGfdarYI0L0Nd6l64C5+/zTchUIhpuL9TQXuypUqN9MF5sYHT+FmRzcR7ec3f+TxM9HGJ0mSJEmSJEmSJElSNzFwp8728v8Nr38G3vUTMPtu1nNBC1lkZAZyqzwxMwzAK2/acqejaTTcnevawF0iOO+jSVmAmZHBpiZlb6Y2qdY4Mw13kiRJkiRJkiRJkiSpPQzcqXNtpuGFX4LBcfjgrwBBC9noUC/h2BRQ4zsmtgCcldWR3a433HXvpGwjcHf/TMoCTMUHWM+V2CxX9v3cUjIPwNy4gTtJkiRJkiRJkiRJkrQ3A3fqXH/2TyG7EoTthsYBWM+VGB/ug9gUAI9G84RC8PKSgTsdTaPhrqsnZcO9EJ1u901O1Ux8AIBbG8V9P5eoB+5mx87GpKwkSZIkSZIkSZIkSWoPA3fqTMuvwBf/V5j9LviO/2T75fVciYnhvu3Q0FBxlYcnh22405GtdnvDXSoB8VkI31//2p8aCQJ3B83KJtYLgA13kiRJkiRJkiRJkiRpf/dX8kJnQ7UKH/1ZoAYf+e3tgFC1WiOZbzTc1Vu6sis8fiHO9fU86Xy5fXfWmdcI3HVlw12tFkzK3mdzsvBWw93NdGHfz9lwJ0mSJEmSJEmSJEmSmmHgTp3nq/8GEl+A7/pJmHnn9supQplqDcaH+yF6Pngxu8I7LsQBbLnTkaxlS8T6exjojbT7KsdvMwXFDYhfbPdNTl2j4W7lwIa7PJPRPob6ek7jWpIkSZIkSZIkSZIk6YwycKfOUkjCi78Mw+fhA7+04631XH3y845JWTLLPDE7Chi409GsZovdPScLMHr/Be7earjbP3C3lCwwO+acrCRJkiRJkiRJkiRJ2p+BO3WWT/465FfhqV+HwdEdb61lSwDBpOzwJITCkF3hsQdGCIXg5RupdtxYXWI1W+zOOVkI5mThvpyUPRfrJxTav+Fus1zhVqbonKwkSZIkSZIkSZIkSTqQgTt1jhtfgS//Plx8DzzxY/e8vZ4LAncT0T4IR4IWvOwKw/09PHIuasOdWlap1ljPlbo3cNdouIvff4G73kiYc9H+fRvulpIFAObGbbiTJEmSJEmSJEmSJEn7M3CnzlCtwEd/Nmit+8hvQSh0z0fWcnc03AFEz0NmBYDHL8RJrBdI5UundmV1j2S+RLVGF0/KXg/O+7DhDmA6PsDKPoG7RDIPwJyTspIkSZIkSZIkSZIk6QAG7tQZvvJ/wJtfge/9L2DqsV0/sn534C42DdllqNV4/EIcwJY7tWQ1WwTo3oa79PUgzDpyod03aYvpkQFWMkUq1dqu7y+t1wN3407KSpIkSZIkSZIkSZKk/Rm4U/vlVuETvwqxGXj/L+z5se1J2eF6KCo6BZUSFJI8PmvgTq1bywa/W5OxLg3cpRIQewAive2+SVtMxweoVGus1YOVd9uelLXhTpIkSZIkSZIkSZIkHcDAndrvE/89bKbg6X8M/bE9P9aYlB0broeGYtPBmb3F22dGCIXg5SUDdzq87Ya74S6elL1P52QhCNwB3NxjVjaRzBMKwczowGleS5IkSZIkSZIkSZIknUEG7tRe178If/UH8PD74bEf3fej67kisf4e+nsiwQvRqeDMLjPc38Olc1Eb7tSS25l64K4bG+5KOSisw+jFdt+kbaZHDgjcrReYHhl4698tkiRJkiRJkiRJkiRJezBwp/apbMFHfxbCvfDsb0EotO/H17IlxqN3NJA1AneZFQAevxBnKVkgWW/Ck5q1tj1X3IUNd6lEcMZtuFvZ2LvhzjlZSZIkSZIkSZIkSZLUDAN3ap8v/2+w8jK856dhcv7Aj6/nSjsDUduTsssAPD4bB7DlToe22s0Nd6nrwXkfT8rOxAeB3RvuMptlUvkys+ODp30tSZIkSZIkSZIkSZJ0Bhm4U3tkVuBPfyNo3fr+nzvw47VajWS+xPjwHYGo7UnZW0DQcAcG7nR4K5kifT1hYv097b7K8Us3AndOyu7WcLeULADYcCdJkiRJkiRJkiRJkprShekSnQkv/ndQ3IC/+S+hb/jAj29sblGu1HY23G1PygYNd29/YIRwCF5eMnCn5iwl8/zGn3yDT1+9zeMX4oQOmDU+k7YnZe/fwN1gX4T4YC8304V73kus5wGYHbPhTpIkSZIkSZIkSZIkHczAnU7f65+Fl/4tzD8Fj36kqa+s50oAjEfvCNz1DsBAHLIrAAz19XDpfNSGOx1os1zhX336NX73U9coblV59vFp/tuPvL3d1zoZjUnZ+Gx779Fm0yMDrGwU73k90Wi4G7fhTpIkSZIkSZIkSZIkHczAnU5XpQwf/TmI9MMz/wyabBRbywZBmR0NdwDR6e3AHcA7LsT5f75yg/VcifG7P6v7Xq1W45PfuMWv/cnXub6e55Fzw/zqD72D981PtvtqJyedCNogewfafZO2mo4P8MVvrVGr1XY0GTYa7gzcSZIkSZIkSZIkSZKkZoTbfQHdZ77wL+H2N+B9/wDGH276a2uNhru7Q3SxKci8Fbh74kIcwJY73eP11Rz/2b/+Ej/5f36ZtWyRX3r223j+v/r+7g7bQTApG59r9y3abnpkgM1ylY3C1o7Xl5J5eiMhpkfu70CiJEmSJEmSJEmSJElqjg13Oj3pG/Bn/xTG3gbv+5lDfXV9r8BddAqKaSgXoHeQx2eDwN0rN9L8wMK547i1zrh8aYvf+9Sr/KtPv0apUuVHvuMCv/jMo5y/HwJW5U3ILsODT7b7Jm03HQ/+ed/cKBAf6t1+fSlZ4IHRQSLh5to2JUmSJEmSJEmSJEnS/c3AnU7Px/8RlHPwzL+G3sFDfbURuJsY7t/5RnQqODPLMP4Qb5+JEw7BS0upY7iwzrJarcbzryzzG3/ydd5Mb/LodIxf++F38N0Pjbf7aqdn40Zwjl5s7z06QCNwt5ze5NHpESD4HUms5/n2i6PtvJokSZIkSZIkSZIkSTpDDNzpdFz7JHz9j+DR/wgWnjr019ey9Ya76N2TstPBmb0F4w8x2Bdh/nyMV25sHPXGOsMWVzL8yv/7NT53bY2RgR5+7Ycf429/90V6IvfZinbqenA6KbsjcNeQzJfJlSrMjQ2161qSJEmSJEmSJEmSJOmMMXCnk7dVhOd+HnoG4cP/pKVHrOeKAEzcMynbCNwtb7/0jgtx/vArS6xli0xE72rEU1fLbJb5F59c5H//3OtsVWv82Lvn+PkPX2byfv09aATubLhjuj4hvLzxVuAusZ4HYG7cwJ0kSZIkSZIkSZIkSWqOgTudvL/4F7D+KvzgL7cc/FnLlRjqizDQG9n5RvR8cGZWtl96YjYI3L18I837L59v9dY6Q2q1Gn/01zf4zee+ye1MkSdm4/zaD7+Db5+7z6dC04ngNHDHzC4Nd4lkELibHTvcxLUkSZIkSZIkSZIkSbp/GbjTyUq+AZ/+bZiYhyd/uuXHrOdKjN/dbgd3TMrubLgDeHnJwN394GtvpvmVP/4aX3o9ydhQL//0Rx/nb717jnA41O6rtV+qHrhzUpb4YC/9PeEdDXdLyQIAs07KSpIkSZIkSZIkSZKkJhm408n62C/AVgE+8lvQs0tgrknruRLnY7vMgkangjP7VsPd22dGiIRDvHwj3fLPU+dL58v89otX+IMvvAHATzz5IP/wQwuMDrX+e9Z1UtdhcAz6o+2+SduFQiFm4gM7G+62J2VtuJMkSZIkSZIkSZIkSc0xcKeTc+VjcOU5eOxH4eH3t/yYWq3GWq7Eo9Oxe98ciEPPwI5J2cG+CPPno7xi4K4rVas1/t1fJvhnH7vCeq7Eux8c41d/+DEeeyDe7qt1nnTCOdk7TI0McGUls/3XiWSBgd4w56K7hHklSZIkSZIkSZIkSZJ2YeBOJ6NcgOf/a+iLwtP/+EiPypUqlLaqjA/vEooJhSB6fsekLMDjF+L8u79cYjVbZNIwTdf4aiLFL/+HV/jqUprJaD+/87feyY98xwVCIedj71HZgo03Yead7b5Jx5iJD/DFb61TKFUY7IuwtJ5ndmzI3x9JkiRJkiRJkiRJktS0cLsvoC712f8RUm/A+38RRh440qPWsyUAJqJ7TIVGp3c03AE8Phu0nTkr2x3WskV+4Q9f4m/+3ud45c0NfvJ9D/Gpn/sBfvRds4al9pJ5E2oVG+7uMBUfAGB5Y5NqtcZSssDcmHOykiRJkiRJkiRJkiSpeTbc6fitvQqf/edw/u3wPX/36I/LFQEYH94jcBebghtfhmoFwhEA3nGhHrhbSvOBy+ePfAe1z1euJ/lPf///Y2Nzi/c8MsGv/NBjLEztMi+snVLXg9PA3baZkXrgLr3JUF+EUqXK7NhQm28lSZIkSZIkSZIkSZLOEgN3Ol61WjAlWynCR34bIr1HfuR6Lmi42zNwF52GWhVytyE2DcDbZ0aIhEM23HWBf/+VG2xsbjkfe1ipRHDG59p7jw4yHQ/a7JY3CvRGgt+juXEb7iRJkiRJkiRJkiRJUvMM3Ol4XftE8D9P/Dg8+J5jeeRaPXA3ueek7FRwZpa3A3cDvRHmz0d5ecnA3VmX2SwD8OzjM4btDiNdD9yNGrhrmG5MyqaL26/N2XAnSZIkSZIkSZIkSZIOIdzuC6jLPPx+ePqfwFO/fmyPfKvhrn/3D8Tqgbvsyo6Xn5iNs7yxye1McZcv6azIbG7RFwkz0Btp91XOltQbwemk7LaZ7cBdgcR6AYC5cQN3kiRJkiRJkiRJkiSpeQbudLwivfDkT0H0/LE9shG4m9hvUhbuCdw9fiEOwCvOyp5pmeIW0QHLOA8tlYC+GAyMtvsmHWMy2k8kHGJ5Y5PEeh6w4U6SJEmSJEmSJEmSJB2OgTt1vLVso+Fuj8Bdo+EuszNw94564O4lZ2XPtMzmFjEDd4eXTgRzss7wbouEQ5yP9bOc3mQpWSDW38P/z969Nsd5n+mBvxpHkmgAIiEQECHZlkRJFEkpkzl4JsdJxp5ks7uJVbWb3apNZbObzcwn2E+x32A92dlN3iSp2mzsHCbJjuSdQ6aSsceTGYmUSZmSbUmkSEJoEuhusNE49L54CMq2eADQDTyNxu9XNfX3AM/zf25XwXx11XVPHfe3BQAAAAAAAADsnMAdfW+puZbxkaGcGHvEStHq9krZmz/x41efmcrIUCXvaLg71OqtdYG73draSpY/tk72IeamjhUNd3dW8+ypE6kIJAIAAAAAAAAAuyBwR9+rNduZmRh7dDBmYjapDCX1nwzcHRsdzktzk3nn+t0DmJL9Um9tZHJ8tOwxDpfGrWSznUw/V/YkfeeZ6WO5XV/LJ8utPHfyeNnjAAAAAAAAAACHjMAdfW+p0c6p6iPWySbJ0HARumvc/tyvXl+Yzq2Vtdyut/ZxQvZLp9NJY81K2V1b/qg4nxK4+2lzU8fS6SSbW508d+pE2eMAAAAAAAAAAIeMwB19r9Zs59TE+OMfqs59bqVsklx8djpJcsla2UNptb2Zza1OJo9puNuVux8Wp5Wyn/PM9LEH/1nDHQAAAAAAAACwWwJ39LV77c3cW9/MzMRjGu6SInBXv5V0Oj/x49cXisDd2x8L3B1G9dZGkmi4263twN20wN1Pm/+xwN2zJzXcAQAAAAAAAAC7I3BHX1tqriVJTj0pcDc5l2yuJa27P/HjV+YnMzJU0XB3SNVb60mSKYG73bFS9pHmp36s4c5KWQAAAAAAAABglwTu6Gu1ZjvJDgJ31fnibNz+iR8fGx3Oy3OTGu4OqfradsOdlbK7cvfDZORYMjFb9iR95ycb7qyUBQAAAAAAAAB2R+COvrZ0P3D3xJWyk/cDd/Wbn/vV689O53Z9LbdWWr0ej322vVK2quFud+5+lEw/l1QqZU/Sd+buN9zNTIxlYtzfFQAAAAAAAACwOwJ39LVaY6cNd6eLs3Hrc7+6uDCdJHlHy92hs71SdlLgbuc6nWKlrHWyD3VsdDinJ8fz/NMTZY8CAAAAAAAAABxCUiz0te2VsjPVHa6UfUTDXZK8c305Xz0/19P52F/bDXdWyu7C6lKyvlo03PFQX/8ffz7V8eGyxwAAAAAAAAAADiGBO/ra9krZUxPjj39w8n6Q7iENd6/MT2Z0uJJL1zXcHTYa7vbg7ofF+dQXyp2jj/3Mc0+VPQIAAAAAAAAAcEhZKUtfqzXXkuxkpeyjA3fjI8N5ZX4ybwvcHTrbDXdTAnc7t/xRcQrcAQAAAAAAAAD0nMAdfa3WbGd0uPLkwNXo8WR8+qErZZPktYXpLNbXcmultQ9Tsl+slN2D7YY7K2UBAAAAAAAAAHpO4I6+ttRs5+SJsVQqlSc/PDn30Ia7JLm4MJ0keftjLXeHyYqVsrt3V8MdAAAAAAAAAMB+Ebijr9Wa7cxUx3f2cPXRgbvXF55KkrxjreyhUm9tZHiokuOjw2WPcngsf5QMjSST82VPAgAAAAAAAAAwcATu6Gu1RjszE2M7e3hyPmktJ+v3Pverl+erGR2u5JLA3aHSaG2kOj6ys4ZDCnc/TKYWkiEhRQAAAAAAAACAXhO4o2+tbWymvraRUzsN3FXnivMhLXfjI8M5Nz+Vtz9eTqfT6eGU7Kf62rp1srt19yPrZAEAAAAAAAAA9onAHX3rTnM9SXYfuKs/fK3sxYXpfNpYy62VtV6MxwGotzYyeWy07DEOj9ZysrYscAcAAAAAAAAAsE8E7uhbnzaKYNyuVsomD224S5LXFqaTJG9/fLfr2TgYReBOw92O3f2oOKefK3cOAAAAAAAAAIABJXBH36o120mSU9XuV8omyevPFoG7S9eXu56N/dfpdFJvrWdK4G7n7n5YnBruAAAAAAAAAAD2hcAdfWs7cLfjhrsHK2VvPvTXL89NZmx4KG8L3B0KaxtbWd/sWCm7G8v3G+6e0nAHAAAAAAAAALAfBO7oW0vbDXcT4zt7YXK74e7hgbuxkaGce2Yyl64vp9Pp9GJE9tFKaz1JrJTdje2GOytlAQAAAAAAAAD2hcAdfavWXEuSnNppw92xp5Lh8aRx+5GPXFyYzqeNdm6utHoxIvuo3tpIInC3K3c/TCpDydRC2ZMAAAAAAAAAAAwkgTv61q5XylYqRcvdI1bKJsnrC9NJkrc/tla23zXuB+6q41bK7tjyR8nkM8nIDv83AwAAAAAAAADArgjc0beWGu0MD1UyfXwXgavqXNK49chfX7wfuLt0XeCu32m424O7H1knCwAAAAAAAACwjwTu6Fu1ZjsnT4xmaKiy85eqc0lzMdnafOivX56bzNjwkIa7Q6DeWk8icLdj7Way+mny1BfKngQAAAAAAAAAYGAJ3NG3as12Tu10ney2yfmks5U0P33or8dGhvLqM5O5dH05nU6nB1OyX7Yb7qaOWSm7I8sfF+dTGu4AAAAAAAAAAPaLwB19a2kvgbvqfHE2bj7ykYsL01lqtnNjudXFdOy3FQ13u3P9u8U5e67cOQAAAAAAAAAABpjAHX1pfXMry/fWMzMxvrsXq6eLs37rkY+8/ux0kuQda2X72nbD3aSGu5259mZxvvBXy50DAAAAAAAAAGCACdzRl+6stpNkbytlkyc23NOohocAACAASURBVCXJpesCd/3ss8Cdhrsn2tpM3v9W8szPJNXZsqcBAAAAAAAAABhYAnf0pVpzj4G76lxxNh7dcPfy3GTGRobytsBdX6tbKbtzN/5zcu9OcvarZU8CAAAAAAAAADDQBO7oS7VGEbibqe6x4e4xK2VHh4fy6jNTuXR9OZ1OZ68jss/qrY1UKsnEmMDdE22vkxW4AwAAAAAAAADYVwJ39KWl+w13MxPju3vxxNNJKo9dKZskry1MpdZs5/rde3uckP3WWNtIdWwkQ0OVskfpf9//7WR8Onn2F8qeBAAAAAAAAABgoAnc0Zf2vFJ2eCSZmH1sw12SvL7wVJLkkrWyfaveWrdOdidWa8n17yYv/HLx9w8AAAAAAAAAwL4RuKMvPWi42+1K2SSZnEsajw/cXVyYTpK8I3DXt+qtjUweGy17jP73/reSdJKXfrXsSQAAAAAAAAAABp7AHX2p1lxLsoeGuySpzheBu07nkY+8NFfN+MhQ3v5Y4K5frbQ2NNztxLW3ivPFr5Q7BwAAAAAAAADAESBwR19aarRTqSQnT+wlcDeXbLSS1qPDdKPDQ3n1malcur6czmOCeZTHStkd2NpKrr2ZnD6fTC+UPQ0AAAAAAAAAwMATuKMvLTXbeer4aIaHKrt/eXKuOJ+wVva1hencWV3Px3fu7WFC9lN7YytrG1tWyj7JrUtJ83ZyVrsdAAAAAAAAAMBBELijL9Wa7b2tk02KlbLJkwN3z04nSS5dt1a239Rb60mi4e5Jrr1ZnGe/Wu4cAAAAAAAAAABHhMAdfanWbGdmYnxvL2833NWf3HCXJG8L3PWdemsjSTTcPcm1t5LRE8kX/lzZkwAAAAAAAAAAHAkCd/Sdza1O7qx203C3vVL25mMfe+l0NeMjQxru+lBjbTtwp+HukVoryUf/KXn+LycjewynAgAAAAAAAACwKwJ39J27q+10OsmpapeBu/rjA3cjw0M5f2Yq71xfTqfT2du32BcrVso+2Q9+N9nasE4WAAAAAAAAAOAACdzRd2rNdpJkZq8Nd5Pzxdm4/cRHX1+Yzt3V9Xx8597evsW++GylrMDdI117szgF7gAAAAAAAAAADozAHX1n6X7gbs8rZUePJ+PTT1wpmyQXF6aTJO9YK9tXHgTuxkdLnqRPdTrJtbeSUy8mp54vexoAAAAAAAAAgCND4I6+U+s2cJck1dNJ/dYTH3vt2SJw9/bHAnf9pG6l7ON9+l6y/JF2OwAAAAAAAACAAyZwR99ZerBSdnzvl0zO76jh7uxsNcdGh3JJw11f+WylrIa7h7JOFgAAAAAAAACgFAJ39J1aoxcNd3NJazlZbz32sZHhoZx/ZirvXF9Op9PZ+/foKQ13T3DtzWR4PPnSXyh7EgAAAAAAAACAI0Xgjr5Ta64lSWaqXQTuJueLs/HktbKvP/tUlu+t56Pavb1/j57abrib0nD3ee3V5Id/kHzxzydjE2VPAwAAAAAAAABwpAjc0Xe2V8qePNFNw93p4txB4O7iwnSS5B1rZfvGduBuYny45En60A//Q7K5Zp0sAAAAAAAAAEAJBO7oO7VmO5PHRjI20sWfZ/V+w1395hMffe1+4O7t63f3/j16qr62kRNjwxkZ9k/U51x7szhf+tVy5wAAAAAAAAAAOIKkWeg7tWY7T1fHu7tkcq44d9Bw9+LsRI6PDueShru+UW+tZ/LYSNlj9KdrbybTzyVPv1z2JAAAAAAAAAAAR47AHX1nqdnOqYku1skmnzXc7SBwNzI8lPNnpvLOx8vpdDrdfZeeqLc2MnlstOwx+k/tg6T2fnL2K0mlUvY0AAAAAAAAAABHjsAdfaXT6eROTwJ3p4tzBytlk2Kt7EprIx/WVrv7Lj2h4e4Rrr1VnGe/Wu4cAAAAAAAAAABHlMAdfWXl3kY2tjqZ6TZwd/xkMjy+o4a7pAjcJck71sr2BQ13j3DtrWRoJHn+L5c9CQAAAAAAAADAkSRwR1/5tLmWJN033FUqSXVux4G715+9H7j7WOCubBubW1ltb2q4+2kba8kPfi957heTY9NlTwMAAAAAAAAAcCQJ3NFXas12kh4E7pJkci6p7yxw98JsNSfGhjXc9YHG2kaSZErg7id9+B+T9WZy9itlTwIAAAAAAAAAcGQJ3NFXlhpF4G6m2oPAXXUuad5Otjaf+OjwUCXnn5nKO9eX0+l0uv82e1ZvFYE7K2V/yrU3i/PsV8udAwAAAAAAAADgCBO4o6981nA33v1l1bmks5U0P93R4689O516ayM/Wlrt/tvs2Xbgrjqu4e4nXHur+Juef73sSQAAAAAAAAAAjiyBO/pKrbmWJJnpyUrZ+eJs7Gyt7GsL00lirWzJ6q31JMmklbKfWb6e3H43efErSaVS9jQAAAAAAAAAAEeWwB19ZelBw12PVsomOw7cvf6swF0/sFL2Id5/qzjPfqXcOQAAAAAAAAAAjjiBO/pKbT8Cd/WbO3r8+aerOTE2nHc+PqDA3Z/+s+Tdf3kw3zpE6msa7j7n2ptJKsmLv1L2JAAAAAAAAAAAR5pEC32l1mxnYmw4x0aHu79scrvhbmeBu+GhSi6cmcql68vZ2upkaGgfV3d2Oslv/a/Ff37xrybjk/v3rUPms4Y7/zwlSTY3kvd/J1n4ueTEqbKnAQAAAAAAAAA40jTc0VeWGu2cqvag3S5JqvPF2bi941deW3gq9bWN/Ki22psZHqX+SbK2Uvzf2/9sf791yGwH7qaslC1c/6NkbTk5+9WyJwEAAAAAAAAAOPIE7ugrtWY7pybGe3PZxGySyo5XyibJa89OJUne/vhub2Z4lMUrn/3nb/9G0XhHkmSlZaXsT/j+bxenwB0AAAAAAAAAQOkE7ugbnU4ntWY7MxM9argbHkkmnk4at3b8ymsLTyVJLl1f7s0Mj3L7fuBu/vUifPfD/7C/3ztEPlspq+EuSXLtzeT4yWThZ8ueBAAAAAAAAADgyBO4o2801jbS3tzKqV4F7pJirewuGu5eeHoiE2PDeWe/A3fbDXd/438rzm9/fX+/d4hsB+6q4xru0lhMPvmT5MVfSYaGy54GAAAAAAAAAODIE7ijb9Sa7STpXcNdkkzOJY3bO17ZOjRUyYWF6Vy6vpKtrX1c87p4tWgt+8IvFatCr/ybZPnj/fveIdJorWd8ZChjI/55yvvfKk7rZAEAAAAAAAAA+oJEC31j6X7grucNdxv3krWVHb/y2sJ0Gmsb+eFSs3dz/LhOp2i4mz2XVCrJl3896Wwmf/R/7s/3Dpl6a8M62W3X3izOF3+l3DkAAAAAAAAAAEgicEcfqTXuN9xVx3t3afV0cdZv7fiV1xamk2T/1so2bietu8nsK8X/f/aryckvJd/9v5KNtf355iFSb21k6ph1stnaSt5/K5l/LZmcL3saAAAAAAAAAAAicEcf2Z+VsveDSo2bO37ltWfvB+4+3qfA3eKV4px9tTiHhpNf+AfJ6qfJ5W/szzcPkXprPZMCd8knf5KsLlknCwAAAAAAAADQRwTu6Bv7s1J2rjgbt3f8yvMzE6mOj+Tt/Wq4W7xanNsNd0nyM38nGTmefPvr+/PNQ8RK2fu218kK3AEAAAAAAAAA9A2BO/pGrVmsU+1p4G674a6+84a7oaFKLpyZyuXry9na6vRulm0PGu7OffazE6eS1/92cv2Pkuvf7f03D4mtrU4a7Q0Nd0kRuBubTJ77xbInAQAAAAAAAADgPoE7+sZS4/5K2WovG+5OF+cuVsomycWF6TTbm/nhUrN3s2xbvJqMT38WBtz2C79WnN/+h73/5iHRaG+k04nA3b07ycffSV745WRY2x8AAAAAAAAAQL8QuKNvLDXbOTY6lBNjPQxbVbcb7m7t6rWLC1NJkks3Vno3y7bFK8U62UrlJ3/+zOvJc7+UXPrnSXOp9989BOqtjSRJdfyIh8w++J2ks2WdLAAAAAAAAABAnxG4o2/Umu3MTIz39tKxE8n4VNLYZeDuzHSS5PKN5d7O0/w0Wf20CNw9zJd/LdlcS/7zP+7tdw+Jxv3A3ZFvuLv2ZnGe/Uq5cwAAAAAAAAAA8BME7ugbtWY7pyZ6uE52W3Vu14G7F2arOTY6lMvXe9xwt3ilOGfPPfz3r/6tYt7v/B/J1mZvv30I1FvrSY544K7TSa69lTz9SvLUF8qeBgAAAAAAAACAHyNwR99Yaq7tX+CufnNXrwwPVfLqM1O5fGM5nU6nd7M8KXA3Mpb83P+cLH+UvPfvevfdQ2J7pezUsSO8Uvb2u0n9E+tkAQAAAAAAAAD6kMAdfWG1vZHW+lZm9iNwNzmXtO4m661dvXbxzHTurK7nxvLu3nusxavF+aiVsknyc/9TMjSSfPvrvfvuIbGi4c46WQAAAAAAAACAPiZwR19YarSTZJ8a7uaLs3l7V69dODOVJLl0fbl3syxeScaqyfSzj35m6plitewHv/NZQO+I2G64mzzKDXff/+1k5Hjyxb9Q9iQAAAAAAAAAAPwUgTv6Qq15P3BX3aeGuySp39rVaxcXppMkl2+s9G6WxavJ0y8nlcrjn/vyrxfnd/5h7759CHwWuDuiDXdr9eTD/5Q8/5eS0WNlTwMAAAAAAAAAwE8RuKMvbAfu9mWlbPV+4K5xc1evvTRXzehwJZd71XC3Wksat5LZc09+9gu/lMxdTP7knxQhrCOiftRXyv7g95Ot9eTsV8ueBAAAAAAAAACAhxC4oy8sbTfcTYz3/vLtwF19d4G78ZHhvHR6Mpdu9Chw9+l7xXl6B4G7SiX58q8l7Xryp/+0N98/BI78StlrbxanwB0AAAAAAAAAQF8SuKMv1JprSZJT+9FwNzlfnI3bu3714sJUbq2sZbG+1v0ci1eKcycNd0ny2t9Ojk0n3/6NpNPp/vuHwJFuuOt0kmu/nZz8UnLqhbKnAQAAAAAAAADgIQTu6AtLfbhSNkkuLkwnSS73ouVu8Wpxzr6ys+fHJpI/+3eTT68mP/i97r9/CDTWNjI6XMn4yBH8p2np/eTuh0W7XaVS9jQAAAAAAAAAADzEEUy10I9qjfsrZav7ELg7fjIZHkvqt3b96oUzU0mSyzdWup9j8UoycjyZ/sLO3/n5v5+kknz7691//xBYaW1k8thoKkcxcGadLAAAAAAAAABA3xO4oy/Umu2MDlcyOb4Pq0QrlaLlbg8Nd68+M5VKpYcNd7MvJ0O7+J/dzIvJS7+aXP2t5O5H3c/Q5+qtjaO5TjYpAnfDY8mX/lLZkwAAAAAAAAAA8AgCd/SFpWY7MxPj+9dsVp1LGrd3/dqJsZG8OFvNpetdNty1VpKV68nsud2/++VfTzpbyR/9ZnczHAL11vrRDNyt30t++PvJF/5cMl4texoAAAAAAAAAAB5B4I6+UGu2c2piH9bJbpucLwJ3W5u7fvXCmal8WFvN8r31vX9/8Wpxzr6y+3df/Epy8vnkj/9Rst7a+wyHQL21kcnx0bLHOHg/+oNko2WdLAAAAAAAAABAnxO4oy/Umu3MVPcxcFc9nXQ2k9WlXb968cx0kuTdG1203C1eKc69NNwNDSW/8A+K2S//i73P0Oc6nU4aa0d0pey1t4pT4A4AAAAAAAAAoK8J3FG61vpmGmsb+9twV50vzvrNXb96YWEqSXL5xvLev99N4C5J/uzfSUaOJ9/5jb3P0OdW25vZ3Opk8tgRbLi79mYyeSY5/WrZkwAAAAAAAAAA8BgCd5Su1mwnyT6vlJ0rzsbtXb964Zmi4e7S9W4Cd1eT4fHkqS/u7f3jJ5PX/7vk+neTj7+79zn6WL21kSRHr+Huzo+ST99Lzn4lqVTKngYAAAAAAAAAgMcQuKN024G7mYNouGvsvuFu+sRonjt1PJe7Wil7NXn6pWS4izDZl3+tOAe05a6xtp7kCAbu3rdOFgAAAAAAAADgsBC4o3RLDxruxvfvI9XTxbmHlbJJcvHMdN5fbORee3P3L681kuUP975Odtv8a8kX/nxy6Z8nzU+7u6sPrRzVhrtrbyWV4eSFv1L2JAAAAAAAAAAAPIHAHaWrNdeS7PdK2e2Gu1t7ev3CmalsdZLv3dxDy92n7xVnt4G7pGi522wnf/yPur+rz3y2Una05EkO0EY7+eB3kue+nBx/quxpAAAAAAAAAAB4AoE7SrfUuL9StrqPgbuJ00kqew/cLUwnSS5fX979y4tXi3P2lT19+ye8+jeL9bjf+c1kc6P7+/pIvXUEV8p+9IdJu5Gc/UrZkwAAAAAAAAAAsAMCd5Su9mCl7D4G7oZHkomnk/reG+6S5NL1PTTcLV4pzl403A2PJj//95OVj5P3/m339/WRI9lwd+3N4jz71XLnAAAAAAAAAABgRwTuKN124G5mPwN3SVKdSxo39/Tq6cljOT05nsuf7LHhbmg0OfX8nr79OT/395KhkeTbX+/NfX3iSDbcXXsrOfF0Mv9nyp4EAAAAAAAAAIAdELijdEvNdoaHKpna72az6lzRcNfp7On1iwvTuXqznvbG1u5eXLySzJwt2ul6YXI+Of+15Ae/l9y+0ps7+8B2w93UUQncrXyS3HqnWCc75J9iAAAAAAAAAIDDQMqD0tWa7Zw8MZahocr+fmhyPtm4l6zV9/T6hTNTWd/s5L1bu3i/vZrc+WEy+8qevvlIX/714vzOP+ztvSXaDtxVx4/IStn3v1Wc1skCAAAAAAAAABwaAneUrtZs7/862aRouEuSxq09vX7hzHSS5N0bKzt/aen7STrJ7Lk9ffORnvvFZP615E//SdLaxTx9bOWorZS99maSSvLir5Q9CQAAAAAAAAAAOyRwR+mWGms5dZCBu/rNPb1+cWEqSXLpxvLOX1q8Wpy9brirVIqWu3Yj+dN/2tu7S9JobWR4qJITY8Nlj7L/tjaLhrszP5NMPF32NAAAAAAAAAAA7JDAHaVa39zKSmsjp6oHELib7K7hbuGp45k+PppL13cTuLtSnL1uuEuSi/9tcuyp5NtfTzqd3t9/wOqtjVTHR1Kp7PNq4X5w/btJ625y9lfLngQAAAAAAAAAgF0QuKNUd5rtJDmglbLzxbnHwF2lUsnFhal875N6Nrd2GHBbvJpUhpOZF/f0zccaO5H87N8t1tZ+8Du9v/+A1dfWj9g62SRnv1ruHAAAAAAAAAAA7IrAHaVauh+4O5CVspPdrZRNkotnpnNvfTM/+LSxsxcWrySnXkhGxvf8zcf6+f8lSSX59m/sz/0HqN7ayOSx0bLHOBjX3kyOTScLP1f2JAAAAAAAAAAA7ILAHaWqbTfcVfcpkPbjqt2tlE2S82emkiSXrq88+eGNtaT2QXJ6H9bJbjv1fPLSX0ve+7fJnR/t33cOQBG4OwINd82l5PofJy/81WT4CPz3BQAAAAAAAAAYIAJ3lGrpIFfKjk0kY5PdNdwtTCdJLt9YfvLDS9eSzlYyu4+BuyT58q8X3/mj39zf7+yjTqeTems9U0chcPfB/5ekY50sAAAAAAAAAMAhJHBHqWqNtSQHtFI2KdbKNm7v+fXnZyYyMTa8s4a7xSvFud+Buxd/pVhb+8f/OFlv7e+39snaxlbWNztHY6XstTeL8+xXyp0DAAAAAAAAAIBdE7ijVAfacJck1fmksfeGu6GhSl59ZiqXbyyn0+k8/uHFq8U5+8qev7fDoZJf+LXkXi25/P/s77f2yUprPUlSHR/whrutreTaW8npC8nUmbKnAQAAAAAAAABglwTuKNV24O7AGu6qp5N7d5KNtT1fcXFhOiutjXx8597jH1y8klSGkpmze/7Wjv3M/5CMnkj+8H9PnhQE7EON1kaSZHLQV8refDtp3k5esk4WAAAAAAAAAOAwErijVLVGO5VK8tSJg1opO1+cjVt7vuLCmakkyaXry49/8PaV5OSXktHje/7Wjh1/Knn9v08++ZPk+nf3/3s9Vn8QuBvwlbIP1skK3AEAAAAAAAAAHEYCd5Sq1mzn5ImxDA9VDuaD1bnibNze8xUXzkwnSS7fWHn0QxvtpPZ+Mntuz9/ZtS//WnF+++sH980eqR+VhrtrbyWjE8lzv1T2JAAAAAAAAAAA7IHAHaVaaq4d3DrZ5LOGu/rNPV/x0lw1Y8NDuXTjMQ13tQ+SrY1k9pU9f2fX5i4kX/yLyeV/0VWgsAz11nqSAQ/ctZaTj/4weeGXk5ED/JsHAAAAAAAAAKBnBO4oVa3ZPtjAXfV0cTb2HrgbHR7KuWcmc+n6YxruFq8U50E23CXJl/9BstlO/vgfHex3u7TdcDc1yCtlP/jdpLOZnP1K2ZMAAAAAAAAAALBHAneUZnOrk7v31jNzoIG7+w13XTbAXTgzlU8ba7m90nr4A4tXi/MgG+6S5Nx/nUw+k3znN5PNjYP9dhdWjkLD3bU3i/NFgTsAAAAAAAAAgMNK4I7S3Fltp9PJoVspmyQXzkwnyaPXym433D39clff2bXh0eTn/35Sv5Fc/TcH++0ubDfcTQ5qw12nk1x7K5k5m5x6vuxpAAAAAAAAAADYI4E7SlNrtpPkYBvujp9MhkaTxq2urrm4cD9w96i1sotXk6e+kIxNdPWdPfnZv1f8d/z2bxz8t/doO3BXHdSGu/XVZOXjZOHnyp4EAAAAAAAAAIAuCNxRmqVGEbg70Ia7SiWpznXdcHdufjLDQ5VcfljD3eZGsvT9ZPbVrr6xZ5NzyYU3kh/+fnL7e+XMsEv1QV8pu7pUnCeeLncOAAAAAAAAAAC6InBHabYb7k5Vxw/2w5NzSeN2V1ccGx3O2dnqwxvu7vww2Wwns6909Y2ufPnXi/OQtNw11jaKLOTYoAbuasV54lS5cwAAAAAAAAAA0BWBO0pTa64lOeCVsklSnU+at5Otra6uubAwlet37+XO/eDgA4tXinP2XFf3d+XZX0ie+TPJn/7TpPWQFr4+U29tpDo2kqGhStmj7I8HDXcz5c4BAAAAAAAAAEBXBO4ozVKzhJWySdFwt7XxWQhqjy6cmU6SvPvJT7Xc9UPgrlIpWu7Wm8mf/JPy5tihemt9cNfJJhruAAAAAAAAAAAGhMAdpdleKXvwDXdzxdm42dU1F89MJUkuXf+pBrnFq8U5+3JX93ft4n+TjFWTS/93uXPsQL21kcljo2WPsX/ubQfuNNwBAAAAAAAAABxmAneUZrvh7mRpgbtbXV1zfjtwd+OnG+6+l0w9m4xPdnV/10aPJy//F8nH30mWPy53lidYaW0MeMOdlbIAAAAAAAAAAINA4I7S1BrtTB8fzejwAf8ZTs4XZ727wN3ksdF8aeZELt/4sYa7rc3k0+8ns690dXfPnP9acb77L8ud4wkGf6Xs/cDdcStlAQAAAAAAAAAOM4E7SlNrtg9+nWzSs5WySXJhYTo/+LSZxtpG8YO7P0o2Wsnsua7v7omXfjUZnUje/UbZkzxSe2Mraxtbg71SdnV7pazAHQAAAAAAAADAYSZwR2mWmu2cKjNw12XDXZJcODOVTif53if318ouXi3Ofmm4Gz2evPzXko/+MFm5UfY0D1VvrSdJqoPecDc+lQwPcKgQAAAAAAAAAOAIELijFFtbndxZLStwdzpJJWl0H7i7eGY6SXL5+v21sotXirNfGu6S5Pwbxdmna2W32wEHe6VsTbsdAAAAAAAAAMAAELijFMv31rO51clMtYTA3fBocmKmJ4G7C2emkiSXbvRpw11SrJUdOZ68+82yJ3moeqsI3E0N8krZe7Xibw4AAAAAAAAAgENN4I5SLDXbSVJOw12STM4n9ZtdXzNTHc8z08dy+UHg7koy+Uxy/Kmu7+6ZsYlireyH/7En/517beX+StmBbbjrdIqVssc13AEAAAAAAAAAHHYCd5Si9iBwN17OANXTRcNdp9P1VRfOTOf7t+pptdeTxff6q91u2/mvJekk3/tXZU/yOdsNdwMbuFtfTTZaGu4AAAAAAAAAAAaAwB2lqDXXkiQzZTXcVeeLIFS70fVVFxemsrHVyQ/ev5qsN5PZcz0YsMde+uvJyLHk8jfKnuRzHgTuxgd0pexqrTgF7gAAAAAAAAAADj2BO0pR/krZueKs3+r6qgtnppMkt97/0+IH/dhwN15NXvrV5Ed/0JP/zr1UH/SVsqtLxXniZLlzAAAAAAAAAADQNYE7SlFrlBy4q84XZ+Nm11ddXJhKkqxev1z8oB8b7pLk/BtJOsmV/lor+9lK2QFtuLun4Q4AAAAAAAAAYFAI3FGK7Ya7mWpZgbvTxVnvPnA3P3UsMxNjGbvzXvGDfg3cvfzXk+HxvlsrO/gNdwJ3AAAAAAAAAACDQuCOUtRKXym73XB3u+urKpVKzp+ZytP3fpDOxGxy4lTXd+6L8cnk7FeLtbKNxbKneeCzhrtBDdzdXyl7vE//LgAAAAAAAAAA2DGBO0pRa7ZTHR/J+MhwOQNU54qzBytlk+Timam8mOu5N322J/ftmwtvJJ2tvlorW18rAnfV8UEN3Gm4AwAAAAAAAAAYFAJ3lGKp2S6v3S75LHBXv9WT637+ZCuTlXv5ZOyLPblv37z815PhseTdb5Y9yQP11kZOjA1nZHhA/znabrgTuAMAAAAAAAAAOPQGNOFCv6s118oN3I1Xk7FqzxruLozdSJJc3VzoyX375th08uJXkh/8ftJcKnuaJEm9tT6462STH1spe7LcOQAAAAAAAAAA6JrAHQeu0+mk1mxnpszAXVK03DVu9+Sq060fJkm+0zzdk/v21fmvJZ3N5Mq/LnuSJEXD3eSx0bLH2D/3asn4VDJS8t87AAAAAAAAAABdE7jjwNXXNrK+2Sm34S5JJueTem8a7oY+vZok+dbSyWxtdXpy57555W8kQ6PJu98oe5IkR6Th7sSpsqcAAAAAAAAAAKAHBO44cLVGO0lyqtoHDXf3aslGu/u7Fq9mdXg6P1qbyIe11e7v20/Hn0pe/JXkg99NVmtlTzP4DXerteS4zHP1hQAAIABJREFUwB0AAAAAAAAAwCAQuOPALTWLgNvTE+PlDlKdK87Gre7u6XSSxStZnT6bpJJLN5a7Hm3fPVgr+29KHWNjcyur7c1Mjg9yw10tOTFT9hQAAAAAAAAAAPSAwB0HrnY/cFf+StntwN3t7u5p3E5adzMy/2qS5NL1lS4HOwDn/stkaKT0tbKNtY0kGdyVsu3VZOOelbIAAAAAAAAAAANC4I4DV2uuJemHlbLzxdm42d09i1eSJJPPXcz4yFAuH4aGu+Mnkxf+SvLB7yT37pQ2Rr014IG71aXi1HAHAAAAAAAAADAQBO44cJ82ioa7mX5puKv3JnA3fPpcXn1mKpdvrKTT6XQ53AE4/0aytZFc+a3SRvgscDda2gz76l6tODXcAQAAAAAAAAAMBIE7DlzfrJStbq+UvdXdPfcDd5k9l4sLU6k127m50uruzoNw7r9KKsPJu98sbYR6az3JEWi4Oy5wBwAAAAAAAAAwCATuOHDbgbuZifFyB3mwUrbbwN3VZHw6mZzPhTPTSZJL11e6HO4AnDiVvPDLyfvfSu7dLWWEgW+4W91uuLNSFgAAAAAAAABgEAjcceCWmu0cHx3O8bHhcgc5cSoZGk3qPWi4m30lqVRy8UHgbrkHAx6A819LttaT9/5dKZ+vrw16w53AHQAAAAAAAADAIBG448DVmmvlr5NNkkqlWCvbuLn3O5qfFmtDZ19Jkrw8X83IUCWXbxyChrskOfc3i7Wyl79Ryuc/a7gb1MDd/ZWyJ6yUBQAAAAAAAAAYBAJ3HLhao52Zah8E7pKkerq7hrvFK8U5ey5JMj4ynJfmJnP5xiFpuJuYSb70F5P330paBx8S3A7cTQ3qStl7Gu4AAAAAAAAAAAaJwB0HqtPpZKnZ7o+GuySZnE+at5Otrb29/1OBuyS5eGYqnyy3stRY68GAB+DCG8lmu5S1siutYqVsdXzAG+6Oa7gDAAAAAAAAABgEAnccqNX2ZtY2tvoncFedS7Y2Pmsi263Fq8V5+rPA3YUzU0lyyNbKDiXvfvPAP30kVsqOTSYjffL3DgAAAAAAAABAVwTuOFC1ZjtJMtMvgbvJ+eKs39zb+4tXkrFqMrXw4EcXF6aTJJcOy1rZ6mzyxb+QfP+3k7X6gX668SBwN6ArZVdryQntdgAAAAAAAAAAg0LgjgO1dD9wd2pivORJ7queLs7GXgN3V5PZV5JK5cGPXn1mKpVKcvn6IWm4S+6vlV1L3vv3B/rZems94yNDGRsZ0H+KVmvJiZmypwAAAAAAAAAAoEcGNOVCv6o115L0UcNd9X7DXeP27t9drSWNW8nsuZ/48cT4SJ5/eiKXD0vDXVKslU0lefcbB/rZemtjcNvtkmKlrIY7AAAAAAAAAICBIXDHgVpqbDfc9UngbnKuOPeyUnbxanHOvvK5X108M50fLq1mpbXexXAHaHLux9bKNg7ss/XWRqaOjRzY9w5UezXZuKfhDgAAAAAAAABggAjccaBq2ytlq30SuHvQcHdr9+8uXinOn2q4S5KLC1NJkndvHKK1sue/lmy0ku//vwf2yXprPZODGri7VytOgTsAAAAAAAAAgIEhcMeB2g7c9c1K2YnZ4uxxw92FM9NJksuHKXD36sGvlR3olbKrS8V53EpZAAAAAAAAAIBBIXDHgVpq9tlK2ZGxooGscXv37y5eSUaOJ9Nf+NyvLpwpGu4uX1/udsKDM/VM8oVfKtbKtpv7/rmtrU4a7Y1Uxwe04W51u+FO4A4AAAAAAAAAYFAI3HGgas12xkaG+itkVZ1PGntsuJt9ORn6/P+MnjoxlmdPHs+lG4cocJck599I1leL0N0+a7Q30ulkcFfKbjfcCdwBAAAAAAAAAAwMgTsO1FKznZmJsVQqlbJH+czkXFK/tbt3WstJ/UYye+6Rj1w4M5Vrtxu5197scsADdP5vFee739z3TzVaG0kywCtltxvuZsqdAwAAAAAAAACAnhG440DVmmv9s052W3UuWW8ma/Wdv7P4XnHOvvLIRy6emc5WJ7lyc6XLAQ/Q1JnkuV9M3vv3yfq9ff1U/UHgbkAb7u4J3AEAAAAAAAAADBqBOw7UUqPdn4G7JGnc3vk7i1eK8zENdxcXppMkl28cosBdcn+tbDO59ua+fqbeWk8ywIG77ZWyx62UBQAAAAAAAAAYFAJ3HJjW+mZW25uZ6bfA3eR8cdZv7vydHQTuLpyZSpJcvrG818nKsb1W9vI39vUz2w13UwO/UlbgDgAAAAAAAABgUAjccWCWmu0kyamJ8ZIn+SkPGu52E7i7mgyPJye/9MhHTk8dy+zkeC5dP2QNd9PPJs/+QvLev0vWW/v2mZWj0HA3NpmM9NnfOwAAAAAAAAAAeyZwx4GpNYrA3Uy1zxrutgN39Vs7f2fxavL0y8nQ8GMfu3hmKldv1rO+udXFgCU4/7Wk3Ujef2vfPrHdcDc5sA13S8mJk2VPAQAAAAAAAABADwnccWCWmmtJklP9ulK2scPA3VojWf4wmX3liY9eODOd9uZWvn+r0cWAJTj/teLcx7Wy24G76qA23N27k5yYKXsKAAAAAAAAAAB6SOCOA1N7sFK2zwJ3D1bK7jBw9+nV4pw998RHLy5MJUku3Vjey2TleeoLyZmfTa7+22RjbV8+UT8KK2UF7gAAAAAAAAAABorAHQdmO3A302+Bu/FqMlZN6jd39vziduBuZw13SfLujZW9TleeC28k7Xry/rf25frPVsoOYOBu/V6yvpocP1X2JAAAAAAAAAAA9JDAHQdmqV8b7pKkenrnDXeLV4pzBw13z548nunjo7l0/ZA13CWfrZV995v7cn1jrQjcTR0b3Zf7S7VaK04NdwAAAAAAAAAAA0XgjgNTa2w33I2XPMlDVOd3Ebi7mgyNJqeef+KjlUolF85M5d1PVrK51elyyAN28kvJMz+TXPmtfVkrW2+tZ3S4kvGRAfxnaHWpOAXuAAAAAAAAAAAGygAmXehXS812RoYqmTrehytEJ+eKkNRG+8nPLl5JZs4mwztrZru4MJ3V9mZ+uNTscsgSXHgjWVtOPvjdnl+90trI5LHRVCqVnt9dugeBu5PlzgEAAAAAAAAAQE8J3HFgas21nJwY68+AVXW+OJu3H/9cezW586Nk9pUdX33hzFSSHPK1st/o+dX11kYmj/Vh+LIX7lkpCwAAAAAAAAAwiATuODC1ZjszE2Nlj/Fw1dPFWX/CWtml7yfpJLPndnz1hTPTSZLLN1b2OFyJTr2QzL+eXPnXO2v/24V6a31wA3erAncAAAAAAAAAAINI4I4Ds9Rs51S/Bu4m7zfcNZ4QuFu8Wpy7aLh7/umJnBgbzuUbh7DhLila7lrLyQ9+r6fX1lsbmRzf2VreQ2d7pezxU+XOAQAAAAAAAABATwnccSDaG1uptzb6N3BXnSvOxs3HP7d4pThPv7rjq4eHKnn1malcur6STqezxwFLdP6N4uzhWtlOp5PG2kaqGu4AAAAAAAAAADhEBO44EHdWi3WkfbtSdrvh7kkrZRevJpXh5NSLu7r+4pmpLN9bz8d37u1xwBI9fTaZu1isld1c78mVq+3NbG51Bnil7P2GuxMa7gAAAAAAAAAABonAHQdiqXE/cFcdL3mSR9hNw93Mi8nI7oKDF85MJ0ku31jZy3TlO/9Gcu9Oz9bKNtY2kiRTxwZ4pexYNRnp0793AAAAAAAAAAD2ROCOA1FrFoG7vl0pe/xUMjSSNG4/+pn1VlL7IJl9ZdfXX1iYSpJcvrG81wnLdf5rxfnuN3tyXb1VNOUNbMPdvZp2OwAAAAAAAACAASRwx4FYaq4l6eOVskNDRctd/TENd0vXks5WMntu19e/dHoyY8NDh7fhbvbl5PT5+2tlN7q+bqVV3DGwgbvVWhHiBAAAAAAAAABgoAjccSC2V8r2bcNdUgTuGrce/fvFK8W5h8Dd2MhQXp6v5tL1Q9pwlxRrZVeXkh/9h66vqj8I3A3qStlacmKm7CkAAAAAAAAAAOgxgTsOxPZK2ZnqIQjcbW09/PeLV4tzDytlk+Timencrq/ldr21xwFLtr1W9vI3ur5qoFfKrt9L1psCdwAAAAAAAAAAA0jgjgOx1NxuuBsveZLHmJxLtjaSe3ce/vvFK0llKJk5u6frLyxMJ8nhXSt7+lzR7ve9f5VsbXZ11UA33K3WivOElbIAAAAAAAAAAING4I4DUWuuZaiSPHW8jwNW1fnibNx8+O8XryYnv5SMHt/T9RfOTCVJLh/qtbJfS1Y/TX70B11ds91wVx0fwIa7e9uBOw13AAAAAAAAAACDRuCOA1FrtnPyxFiGhiplj/Jok3PFWX9I4G6jndTeLxre9ujV+akMVZJL1w9pw12SnH+jON/9ZlfXbDfcTQ3iStnVpeLUcAcAAAAAAAAAMHAE7jgQS812Tk2MlT3G41XvB+4atz7/u9oHxbrZ2Vf2fP3xseGcPV3N5U8OccPd6VeTmZeSd/9lV2tlB3ul7P3A3XGBOwAAAAAAAACAQSNwx4GoHYrA3fZK2YcE7havFOfsq1194sKZ6XxUu5fl1fWu7ilNpZJceCNp3k4+/E97vuazwN0gNtxZKQsAAAAAAAAAMKgE7th3G5tbubu6nplqnwfuHqyUfVjg7mpxdtFwlyQXzkwlSS7fOMQtd+e/VpzvfmPPV9Rb6xkequTE2HCPhuojAncAAAAAAAAAAANL4I59d+d+m1vfN9xNnC7Oxs3P/27xSpJK8vTLXX3i4sJ0kuTyjZWu7inV3MXk1Iv318pu7emKemsj1fGRVCqVHg/XB7ZXyp6wUhYAAAAAAAAAYNAI3LHvas12kuTUxHjJkzzByFhy/NQjGu6uJE99IRk70dUnzt9vuLt0mBvuKpWi5a5xM/noD/d0RX1tfTDXySbJvfsNd8cF7gAAAAAAAAAABo3AHftuqbmWJJnp94a7JJmcTxo/Fbjb3Eg+/X4ye67r66eOjeaLMydy6fohDtwlyYU3inOPa2XrrY1MHhvt4UB9ZHUpGasmo8fKngQAgP+fvbsJjvO+7wT/bbwQ6CZAqkFBr01ZJiWR3mSmkt2dJJPd2OLkffcyVckpb3vIbjwZz3hnMhNvtmar9rK1lVNuPrgmnlOuOcxlr/Ik2XWc7HiSrG2R8oiSRUiyBaFBEkCjATTQe3jQpCVSJEh0o7uf/nyqVH/W093/5yeViqdvfX8AAAAAAAB9JnDHwN1tuBuDwN3C0/cG7tbfSg72kuVLfXnFjz53Ntc/3Eprt9OX+4bimb+f1D/92GtlN9qdLM6VtOGutabdDgAAAAAAAACgpATuGLhe4G5sGu52N5OdzbvPVq8WZx8a7pJirWy3m7z+/u2+3DcUvbWyG+8lK3/9SD/tdrvZaJd4pWxrPakJ3AEAAAAAAAAAlJHAHQO3tnnYcLcwBoG7haeK84db7vocuPvR588mSb717hgH7pIfWiv77x/pZzudg+ztd0scuFsTuAMAAAAAAAAAKCmBOwZuvFbKPlOcHwncXSvO5Vf68oofee5MkuTb793qy31D8+yPJU+8UATuHmGt7Ea7WKW7OD87qMmGZ6+d7G0ltXPDngQAAAAAAAAAgAEQuGPg7gTuamMQuFt8ujg3vn/32erV5EwjmVvsyyueXJjLM2fmx7/hrlJJ/ot/nNxeSd775pF/ttHeS5JyNtxtN4tT4A4AAAAAAAAAoJQE7hi4ta2dPFGbzcz0GPzv9vGGu4P95MPvJsuX+vqaH33+TL77wUZ2Ovt9vffEvfSzxbny/x75J6VuuGutFWfVSlkAAAAAAAAAgDIagwQU4665tTse62STZOFjDXc3v5d02sny5b6+5keeO5u9/W6++4PNvt574pY/U5yrV4/8k7uBuxI23LV6DXcCdwAAAAAAAAAAZSRwx8Ctbe7m3LgE7norZTc/KM7Va8X5VL8Dd2eSJN9691Zf7z1xC08l80/c/e90BKVeKdtruLNSFgAAAAAAAACglATuGKiDg27WW2PUcDe3mMyeTjYPG+56zW19brj70efPJkm+/d7tvt574iqV4r/N6utJt3ukn/Qa7s6UeaWshjsAAAAAAAAAgFISuGOgbm7v5aCbLJ2eG/YoR7f4dLLxg+LPvea2J1/p6yuePTufem0233l/zAN3SbJ8KdleT7ZWj/T124cNdwtlbLjbXi9ODXcAAAAAAAAAAKUkcMdANbd2kmR8VsomycLTdxvuPng9WXw2qT7R11dUKpW8+OTpvNNs9fXeoei1//XaAB+i13BnpSwAAAAAAAAAAONG4I6BWtvcTZLxWSmbFIG71lrS2Uk+fKNocBuARr2W1Y2dtPf2B3L/iXmqF7i7dqSv3w3clXilbNVKWQAAAAAAAACAMhK4Y6CaW0Xg7tzCGAXuFp8pzne/mey17ja49dn5erV4zc3tgdx/Yh6x4W5zp1gpW86Gu2YyezqZnR/2JAAAAAAAAAAADIDAHQO1tjWmDXdJ8tZ/KM4BNtwlyY1xXyu7+Gwyd+aRGu4qlWThVBkDd2vWyQIAAAAAAAAAlJjAHQPVHOfA3fVe4G4wDXeNw4a7lfUxb7irVIpQ4hEb7jbanSycmsnUVGXAgw1Bq5nU6sOeAgAAAAAAAACAARG4Y6DurJQ9PTfkSR7B4mHgbuWvi1Pg7uGWLyVbq8nW2kO/utHeK+c62STZbmq4AwAAAAAAAAAoMYE7Bqq3UrZ+enbIkzyChWeK82AvOb2c1JYG8prnnugF7sZ8pWxyN5T44cPXym60O1mcH6P/H45qr53sbgrcAQAAAAAAAACUmMAdA9Xc2sni3EzmZqaHPcrRLT5z988DardLkvnZ6Tx9Zq4kDXeH/52OsFb2druThTI23G03i7M6mIAmAAAAAAAAAADDJ3DHQK1t7mZp4dSwx3g01aVk6jAQtnxpoK9q1Gslabg7/O/0wcMDd6VdKds6DNxpuAMAAAAAAAAAKC2BOwaqubWbpdNjFribmkpOP1X8eYANd0nSqFfz4eZutnf3B/qegTvTSGZPP7ThbrdzkJ3OQTlXyrbWinNAK4gBAAAAAAAAABi+IwXuvvjFL+bFF19MpVLJt771rTvPv/vd7+anf/qn88orr+QnfuIn8p3vfOdInzEZut1u1lu7OTdugbskWXy6OE8gcJck794c85a7qalk+ZVk9doDv7a500mSkjbcCdwBAAAAAAAAAJTdkQJ3v/qrv5q/+Iu/yKc+9amPPP/85z+f3/md38kbb7yRL33pS/nt3/7tI33GZLjd7mRvvzt+DXdJsvBMcQ48cFdLktxY3x7oe07E8meSze8n2+uf+JWN9l6Skgbutq2UBQAAAAAAAAAouyMF7j772c+m0Wh85NkHH3yQb37zm/mN3/iNJMmv/Mqv5K233srbb7/9wM+YHM2t3STJuYW5IU/yGH7qnyRX/k1y+smBvub8YeBupTnmDXdJsnypOFff+MSvbLSLhrszpVwpexi4q2q4AwAAAAAAAAAoqyMF7u7nxo0bee655zIzUzRVVSqVvPDCC3nnnXce+Nn9/NEf/VEajcadfzY3Nx93LEZIc2snScZzpeyFV5PPfSmpVAb6mt5K2ZVSNNwdtgGuXv3Er9wuc8NdS8MdAAAAAAAAAEDZPXbgLimCdD+s2+0e6bOP+73f+72srKzc+WdhYeE4YzEi1jaLhruxXCl7Qp59Yj6VSlkCd72Gu2uf+JVew105A3drxVnTcAcAAAAAAAAAUFaPnXo5f/58VlZW0ul0MjMzk263mxs3buSFF15IrVb7xM+YHGtbAncPMzcznacX57OyXoKVsk+8kMxUH9hw1wvcLcyVcaXsWjJbS2arw54EAAAAAAAAAIABeeyGu6eeeio//uM/nj/5kz9Jkvzpn/5pXnzxxbz44osP/IzJ0TwM3J07PTfkSUZbo14tR8Pd1HTy5MsPabgr8UrZ7aZ1sgAAAAAAAAAAJXekwN0XvvCFNBqNrKys5Od+7ufy0ksvJUm+8pWv5Ctf+UpeeeWV/OEf/mG++tWv3vnNgz5jMtxZKbug4e5Bzi/Vsra1m62dzrBHOb7ly8ntlaR9+74fl36lrHWyAAAAAAAAAACldqTUy5e//OV8+ctfvuf5pUuX8vWvf/2+v3nQZ0yG5tZOkuSclbIP1KgXK0jfvbmdV55eHPI0x7R8qTg/fCNp/Nf3fNxruDszX8aVss1k6eKwpwAAAAAAAAAAYIAee6UsPMza1m5qp6YzPzs97FFGWi9wt7LeGvIkfbB8uThXr973482dkjbcdXaS3U0rZQEAAAAAAAAASk7gjoFpbu1mSbvdQzXqtSTJyvr2kCfpg6c+U5yfELi7fbhSdmGuZIG7VrM4Be4AAAAAAAAAAEpN4I6BaW7tWid7BHcb7koQuHviU8n0XLJ67b4fb7Q7qZ2azsx0yf7qaa0VZ21puHMAAAAAAAAAADBQJUu9MCq63W7WNNwdybNnq5mqJDeaJVgpOz2TPPnyJzbcbbT3yrdONkm2NdwBAAAAAAAAAEwCgTsGYmt3P7udgyydnhv2KCPv1MxUnjkzX46GuyRZvpTcfCfZ3brno412J4vzs0MYasA03AEAAAAAAAAATASBOwaiubmbJDm3oOHuKBr1WlbWS9BwlyTLl4vzwzfu+WijvZeFuRI23PUCd1WBOwAAAAAAAACAMhO4YyDWtnaSxErZI2rUq1lv7WVzpzPsUY5v+VJxrl6756Oi4a6Mgbv14rRSFgAAAAAAAACg1ATuGIjmVtFwJ3B3NI16NUnybhnWyvYa7lavfuRxZ/8grd39nLFSFgAAAAAAAACAMSVwx0CsHQbuzgncHUljqZYkudEswVrZpQvJ1Mw9DXdbO/tJUtKGOytlAQAAAAAAAAAmgcAdA6Hh7tH0Gu5W1ksQuJueTc69lHzw+kce327vJSlp4G67mczWklO1YU8CAAAAAAAAAMAACdwxEM07DXdzQ55kPJyvF0GtlTKslE2S5UvJ+tvJ3t1/n412J0myWNaVstrtAAAAAAAAAABKT+COgVjbPAzcLWi4O4pnzs5nqlKmwN1nknSTD79759FGmRvuWs2kJnAHAAAAAAAAAFB2AncMRHNrJ3MzU6mdmh72KGNhdnoqz56tZuVmCVbKJkXDXZKsXrvzqNwNd82kdm7YUwAAAAAAAAAAMGACdwxEc2s3506fSqVSGfYoY6NRr+ZGsywNd5eLc/XqnUcbO0XD3cJcyRruOrvJ7oaGOwAAAAAAAACACSBwx0B8uLmbJetkH0mjXsut7b3cPly9OtbOXUwq0x8N3B023J0p20rZ7WZxargDAAAAAAAAACg9gTsGorm1m6XTc8MeY6w06tUkybvrJWi5m5lLli5MxkrZ1lpxCtwBAAAAAAAAAJSewB19t727n+29/Zw7reHuUfQCdytlCNwlyfKlpHk96ewkyZ3mvsWyNdz1AndVK2UBAAAAAAAAAMpO4I6+W9sqAlZLAnePpFGvJUlW1ltDnqRPli8n3f1k7c0kyeadhruyBe56K2UF7gAAAAAAAAAAyk7gjr5rbu0mEbh7VOeXioa7G82yNNxdLs7Vq0mslAUAAAAAAAAAYPwJ3NF3a4eBOytlH80zZ+YzPVUpUcPdpeK8E7jby9zMVE7NlOyvHQ13AAAAAAAAAAATo2TJF0ZBc1PD3eOYmZ7Ks2fns7Jekoa7J19OKlMfabgrXbtdkmz3Anca7gAAAAAAAAAAyk7gjr7rrZQ9tyBw96ga9Wp5Gu5mq0n9xWT1WpJe4G5muDMNQm+lbFXDHQAAAAAAAABA2Qnc0Xe9lbJLp+eGPMn4adRrud3u5Nb23rBH6Y/ly8naf07297LR3itv4G6mmpyqDXsSAAAAAAAAAAAGTOCOvmtu7SSxUvZxnK8Xoa3StNwtX0oOOknzeokb7prWyQIAAAAAAAAATAiBO/quubWb2elKzpQxXDVgjXo1SbKyvj3kSfpk+XKS5OCD17O528ni3OyQBxqA1lpSqw97CgAAAAAAAAAAToDAHX23trWbeu1UKpXKsEcZO+UL3F1Kkux9//V0uylnw932uoY7AAAAAAAAAIAJIXBH3zW3dq2TfUyNpZKtlH3ylSTJ/g+uJkkW50vWcNfZTXZuC9wBAAAAAAAAAEwIgTv6rrm5m3MLAneP45kz85mZqpSn4e7U6eSJFzK1di1JCRvutpvFWV0a7hwAAAAAAAAAAJwIgTv6aqezn42dTpZOzw17lLE0PVXJc09Uc6NZkoa7JFm+nFPrb2Y6++UL3LUOA3ca7gAAAAAAAAAAJoLAHX21vrWXJDlnpexja9SreXd9O91ud9ij9MfypUwd7OaFygc5U7aVsq214hS4AwAAAAAAAACYCAJ39NXa1k4SgbvjaNSr2djp5PZ2Z9ij9Mfy5STJy5WVLJSu4a4XuLNSFgAAAAAAAABgEgjc0VeLc7P5jZ96IT/2whPDHmVsNeq1JMmN9ZKslV3+TJLkpcq75Vspu91bKStwBwAAAAAAAAAwCUqWfmHYXjhXy//xj//esMcYa416NUmysr6dH33+7JCn6YPlV5IkL0+9m0UrZQEAAAAAAAAAGGMa7mDEnF8qGu5WytJwN7eY26eezstlbLhrHTbcVTXcAQAAAAAAAABMAoE7GDE/3HBXFj+Ye7FYKXuqMuxR+qsXuNNwBwAAAAAAAAAwEQTuYMQ8tTif2elKeRrukrw7+0LmK3s5u/P9YY/SX621ZKaanKoNexIAAAAAAAAAAE6AwB2MmOmpSp57olqqhrvvTZ1Pkpxaf2PIk/RZay2pWScLAAAAAAAAADApBO5gBDXqReCu2+0Oe5S++G63kSSprF4b8iR9tt0UuAMAAAAAAAAAmCACdzCCztdr2dzp5GZrb9ij9MW1znPFH1avDneQfms1k9q5YU8BAAAAAAAAAMAJEbiDEdTuT3QYAAAgAElEQVSoV5OkNGtl39+dy1plqVyBu85usnM7qWq4AwAAAAAAAACYFAJ3MIIa9VqSZGW9NeRJ+mOj3cl7sy8kq28kBwfDHqc/tteLU8MdAAAAAAAAAMDEELiDEVSmhrtut5vNnU5+MP/pZG8rub0y7JH6o7VWnDUNdwAAAAAAAAAAk0LgDkZQr+HuRgka7rb39rN/0M366QvFg9Vrwx2oX7abxanhDgAAAAAAAABgYgjcwQh6anEup6anStFwt9HuFOfixeLB6tUhTtNHdxruBO4AAAAAAAAAACaFwB2MoKmpSp6vV7NSgoa7jfZekmT77EvFg7IF7qr14c4BAAAAAAAAAMCJEbiDEdWoV7Oyvp1utzvsUY7l9mHD3ezik8np5fKslG1ZKQsAAAAAAAAAMGkE7mBENerVtHb3s97aG/Yox9JbKbswN5ssXy4Cd2MeIkwicAcAAAAAAAAAMIEE7mBENeq1JMmN5nivle2tlF2cn0mWLyU7t5ON94c8VR/0VsrWloY7BwAAAAAAAAAAJ0bgDkZUo15Nkqysbw95kuPpNdwVgbvLxcMPXh/iRH2y3Uxm5pPZ2rAnAQAAAAAAAADghAjcwYjqNdytrJel4W62aLhLirWy4661VqyTrVSGPQkAAAAAAAAAACdkZtgDAPd3vmQNd2fmZ5LTnykerl4d4kR90lpLqtbJAgAAAAAAAABMEg13MKKeXJjLqZmpEjTc9VbKziannyxCaqVouFtPagJ3AAAAAAAAAACTROAORtTUVCWNJ6q5UZKGu8X5mWL96vLlouGu2x3yZMewv5fs3CpWygIAAAAAAAAAMDEE7mCENZZqWVlvpTvG4bSN9l6mpyqpnZouHixfSto3k80PhjvYcbSaxanhDgAAAAAAAABgogjcwQhr1Ktp7x1kbWt32KM8to12JwtzM6lUKsWD5cvFuXp1eEMd13YvcKfhDgAAAAAAAABgkgjcwQhr1KtJkpUxXiu7sbOXhbmZuw+WLxXn6rXhDNQPrbXiFLgDAAAAAAAAAJgoAncwwhr1WpJkZb015Eke30a7k8X5Hw7claDhrhe4q1opCwAAAAAAAAAwSQTuYIT1Gu5uNMe44a7dyZn52bsPFp9J5s6OecNdb6WswB0AAAAAAAAAwCQRuIMRdnel7Hg23HW73Wy09z7acFepFGtlV18f3mDHdWelrMAdAAAAAAAAAMAkEbiDEba8MJe5mamsrI9nw91O5yB7+92PBu6SInDXWku2PhzOYMe1vV6ctXPDnQMAAAAAAAAAgBMlcAcjrFKppFGvjm3D3Ua7kyRZ/OGVskny1GeKc/XqCU/UJ3ca7gTuAAAAAAAAAAAmicAdjLhGvZaV9e10u91hj/LINtp7SXL/hrtkvAN303PJbG3YkwAAAAAAAAAAcIIE7mDENerV7HQOsrq5M+xRHtknNtwtXy7O1WsnPFGftJpFu12lMuxJAAAAAAAAAAA4QQJ3MOIa9aJFbWV9e8iTPLpe4G7h4w13Z55PTi2Md8OddbIAAAAAAAAAABNH4A5G3PmlapJxDdwVK2XPfDxwV6kUa2XHuuGuPuwpAAAAAAAAAAA4YQJ3MOLuNty1hjzJo7u7Unbm3g+XLyebPyjCa+Nkfy/ZuaXhDgAAAAAAAABgAgncwYhr1Me34e72YcPd4vzsvR8uXyrOD984wYn6YHu9OAXuAAAAAAAAAAAmjsAdjLhzp09lfnYqN5olbLhLkg9eP8GJ+qC1VpzVpeHOAQAAAAAAAADAiRO4gxFXqVTSqNfy7hg23G3u9AJ3D2i4W712ghP1QW8FroY7AAAAAAAAAICJI3AHY+B8vZqVm9s5OOgOe5RHsnFnpex9Gu7OvpDM1pLVqyc81TH1Gu4E7gAAAAAAAAAAJo7AHYyBRr2W3c5BPtzcGfYoj6S3Unbh1H0Cd1NTyZOvjGHDXS9wVx/uHAAAAAAAAAAAnDiBOxgDjXo1SXJjzNbKbrQ7WZibydRU5f5fWL6cbLyXtG+d7GDHsW2lLAAAAAAAAADApBK4gzHQqNeSJCvrrSFP8mg22nv3Xyfbs3ypOFffOJmB+qElcAcAAAAAAAAAMKkE7mAM9BruVsaw4e7BgbvLxbl69WQG6ofeStnq0nDnAAAAAAAAAADgxAncwRg4vzSeDXe3250szs9+8hfuNNyNU+CumUzPJadOD3sSAAAAAAAAAABOmMAdjIF6bTa1U9Nj2HD3kJWy9ReL8NrqtROb6dhaa0ltKalUhj0JAAAAAAAAAAAnTOAOxkClUkmjXh2rwN1u5yA7nYMHN9xNTSdPvjJegbvtZlI7N+wpAAAAAAAAAAAYAoE7GBONei3vrm/n4KA77FGOZHOnkyQPbrhLirWyt95JdjZPYKo+6DXcAQAAAAAAAAAwcQTuYEw06tXs7h/kg42dYY9yJBvtvSRHCdxdLs4Px6Dlbr+TtG8lVYE7AAAAAAAAAIBJJHAHY+J8vZYkWVlvDXmSo9loFw13Zx60UjYpGu6S8Vgru71enFbKAgAAAAAAAABMJIE7GBONejVJsrK+PeRJjub2YcPdwtxDGu6e+kxxrl4d8ER90ForToE7AAAAAAAAAICJJHAHY6Ixpg13D10pW/90MjU7Hg13dwJ3VsoCAAAAAAAAAEwigTsYE72GuxvN8Wi4uxu4e8hK2emZ5MmXx6PhbrtZnBruAAAAAAAAAAAmksAdjIknarM5fWo6KzfHpeGuWCn70Ia7JFm+lKx/L9kd8X83DXcAAAAAAAAAABNN4A7GRKVSyfmlWlbWx63h7iiBu8tJusnadwc71HH1AndVgTsAAAAAAAAAgEkkcAdjpFGv5r2b29k/6A57lIfa3CkCd2cetlI2KRrukmT12gAn6oOWlbIAAAAAAAAAAJNM4A7GSKNey95+Nx9stIc9ykM92krZy8W5enWAE/WBwB0AAAAAAAAAwEQTuIMx0qhXkyQ3mqO/Vvb24UrZhbkjBO6WLiaV6eSDUQ/crSXTp5JTp4c9CQAAAAAAAAAAQyBwB2OkF7hbWW8NeZKH22h3Up2dzsz0Ef6amTmVnLs4+g13282i3a5SGfYkAAAAAAAAAAAMgcAdjJFGvZYkWVkf/Ya7jfbe0dbJ9ixfStbfSvZGeF1ua806WQAAAAAAAACACSZwB2Pk/J3A3Xg03D1a4O4zSfcgWfvPgxvquFprSbU+7CkAAAAAAAAAABgSgTsYI2eqM1mcmxmjhrvZo/9g+VJxjupa2f1O0r6l4Q4AAAAAAAAAYIIJ3MEYqVQqeb5ezY1SNtxdLs7Va4MZ6Li214uztjTcOQAAAAAAAAAAGBqBOxgzjXot799sp7N/MOxRPtH+QTet3f2ceZSGu3MvJZWp0W24224Wp4Y7AAAAAAAAAICJJXAHY+b8UjWdg25+sLEz7FE+0Wa7kySP1nA3O5/UPz26DXetteIUuAMAAAAAAAAAmFgCdzBmGvVakmSlObprZW+395I8YuAuKdbKNt9MOrsDmOqYeoG7qpWyAAAAAAAAAACTSuAOxkyjXk2S3FjfHvIkn2zjsOFuYe4RVsomyfKl5KCTNK8PYKpjalkpCwAAAAAAAAAw6QTuYMz0Ancr66PbcLdxnIa7JFl9vc8T9cGdlbIa7gAAAAAAAAAAJpXAHYyZOytlx6Dh7tEDd5eKc/VanyfqA4E7AAAAAAAAAICJJ3AHY+ZsdTZn5mdGu+Fup9dw94grZZ98JUklWb3a/6GOa3u9OK2UBQAAAAAAAACYWAJ3MIYa9dpYNNydedSGu1O1pP6p0W24mz6VnFoY9iQAAAAAAAAAAAyJwB2MoUa9mvdvtdPZPxj2KPd1d6XsIzbcJcny5eTD7yb7nT5PdUyttaS6lFQqw54EAAAAAAAAAIAhEbiDMdSo17J/0M37t9rDHuW+7gbuHrHhLkmWLyUHe8n6W32e6phaTetkAQAAAAAAAAAmnMAdjKFGvZokI7tWdqO9l+RxA3eXi3P1ah8n6oPWWlJbGvYUAAAAAAAAAAAMkcAdjKHzS7Ukycp6a8iT3F+v4W7hcRvuktEK3O13kvZNgTsAAAAAAAAAgAkncAdjaBwa7k7NTGVuZvrRf/zkK8W5eq2/Qx1H+2ZxWikLAAAAAAAAADDRBO5gDD1/GLi7McINd2cep90uSeYWk7PnR6vhrrVWnAJ3AAAAAAAAAAATTeAOxtCZ+dmcrc6OcMNdJ4vzs49/wfKl5MPvJgf7/RvqOFrN4qxaKQsAAAAAAAAAMMkE7mBMNerVvDuygbu9LD5uw12SLF9OOu1k/e2+zXQsGu4AAAAAAAAAAIjAHYyt8/Va3r+1nb39g2GPco+i4e6YgbskWb3Wn4GO607gTsMdAAAAAAAAAMAkE7iDMdWoV3PQTb5/qz3sUT7i4KCbzd1OFueOs1K2F7i72p+hjmv7cKWswB0AAAAAAAAAwEQTuIMx1ahXkyQ3mq0hT/JRW7uddLs5ZsPdK8U5cg13VsoCAAAAAAAAAEwygTsYU416LUmysr495Ek+aqPdSZIszh+j4W7+bLL43Og03LUOG+6qGu4AAAAAAAAAACaZwB2MqcZS0XC3sj5aDXe9wN3CcRrukmT5UvLhG8nBQR+mOqZWM5maTeYWhz0JAAAAAAAAAABDJHAHY2p0G+72kiRnjh24u5zstZJbN/ow1TG11op1spXKsCcBAAAAAAAAAGCIBO5gTC3MzaRemx3BwF1vpWwfGu6SZPXaMSfqg9ZaUrNOFgAAAAAAAABg0gncwRhr1Gu5MWIrZW8fNtwtzs8e76Lly8W5+voxJ+qD7WbRcAcAAAAAAAAAwEQTuIMx1qhX8/3b7ex2DoY9yh2la7jb7yTbNzXcAQAAAAAAAAAgcAfjrFGvpttN3r81Omtl7wbujtlwV1tKTj+VrF7tw1TH0L6ZpJtUBe4AAAAAAAAAACadwB2MsfNLtSTJyvroBO42d3orZY/ZcJckT10uGu663ePf9bhazeK0UhYAAAAAAAAAYOIJ3MEYa9SrSZKV9daQJ7mrbytlk2T5crK7mdx+9/h3Pa7WWnEK3AEAAAAAAAAATDyBOxhjjXrRcHejOToNd3cCd3PHXCmbJMuXinOYa2XvBO6slAUAAAAAAAAAmHQCdzDGnn9iFBvu9jIzVcn8bB/+elm+XJyr145/1+PatlIWAAAAAAAAAICCwB2MsdNzM1k6fSor66PTcHe73cni/EwqlcrxL7sTuNNwBwAAAAAAAADA8AncwZg7X6+OVOBuo93J4nwf1skmyekni2a5YTbctQ4b7qoCdwAAAAAAAAAAk07gDsZco17LDzba2ensD3uUJMVK2cX5mf5duHy5aLjrdvt356NoWSkLAAAAAAAAAEBB4A7GXKNeTbebvHezPexRkvQa7voZuLuUtG8lt1b6d+ejaK0lUzPJ3OJw3g8AAAAAAAAAwMgQuIMx16hXkyQr660hT5J0u91s7vRxpWySnP+p4nz7z/t356PYbhbtdpXKcN4PAAAAAAAAAMDIELiDMdeo15IkK+vbQ54k2d7bz/5Bt78NdxdeLc43X+vfnY+itWadLAAAAAAAAAAASQTuYOydXxqdhruNdidJcqafDXeLTydP/Uhy/WtJt9u/e4+qtZZUl07+vQAAAAAAAAAAjByBOxhzzz8xOg13G+29JMnCXB8b7pLk4pVk64PkB9/u770Pc7CfbN9MagJ3AAAAAAAAAAAI3MHYq56azpMLp3KjOfyGu9uHDXd9XSmb3F0re/1r/b33YbZvJulaKQsAAAAAAAAAQBKBOyiF5+u1EWm46wXu+rhSNkk+9dPJ9Knk+mv9vfdhWmvFqeEOAAAAAAAAAIAI3EEpNOrVfLCxk/be/lDn6K2U7XvD3anTyfmfTN7+v5POTn/vfpDtZnFquAMAAAAAAAAAIAJ3UAqNejVJ8t7N4bbcbQxqpWxSrJXtbCc3vtH/uz/JnYY7gTsAAAAAAAAAAATuoBTO12tJMvS1sncb7vq8UjZJLl4pzjdPcK1sL3BXtVIWAAAAAAAAAACBOyiFXsPdjfXWUOfYPGy4OzOIhrtnfyyZfyK5/rX+3/1JWlbKAgAAAAAAAABwl8AdlEBjRBrubt9ZKTuAhrup6eTTn03e+093g3CDdmelrIY7AAAAAAAAAAAE7qAUeg13ww7cbRwG7hYG0XCXHK6V7SZv/dlg7v+4Ow13AncAAAAAAAAAAAjcQSnMz07nyYW5rAx5pexGey9TleT0qenBvODCleK8/tpg7v+47WYyNZPMnTmZ9wEAAAAAAAAAMNIE7qAkzi9VR6LhbmFuJpVKZTAvWPp0Un8xuf61wdz/ca21pHYuGdS/DwAAAAAAAAAAY0XgDkqiUa9ldWMn7b39oc2wsbOXxfnZwb7kwqvJ+ttJ863BvicpVspWrZMFAAAAAAAAAKAgcAcl0ahXk2SoLXcb7U4W52cG+5KTXCvba7gDAAAAAAAAAIAI3EFp3A3ctYY2w0a7kzODbrj79GeTVJI3Bxy4O9hPtteTWn2w7wEAAAAAAAAAYGwI3EFJNOq1JMNtuNs8iYa72lLy3I8nb/1ZEYoblPatJF0NdwAAAAAAAAAA3CFwByVx/rDh7saQGu7ae/vZ3T8YfOAuSS68mrRvJu//zeDe0VorToE7AAAAAAAAAAAOCdxBSTz3RG+l7HAa7jbanSTJ4qBXyibJxSvFOci1sr3AXXVpcO8AAAAAAAAAAGCsCNxBSczPTuepxbkhBu72kiQLJ9Fwd/4nk9lacv1rg3tHq1mcGu4AAAAAAAAAADgkcAcl0qhX8+6QVsrebbg7gcDdzFzyqZ9O3vnLZHdrMO+wUhYAAAAAAAAAgI8RuIMSadRr+XBzN9u7+yf+7hNdKZskF64kB3vJ974+mPvvBO6slAUAAAAAAAAAoCBwByVyfqmaJFkZQstdb6XsmZNouEuSC68W5/XXBnP/dm+lrMAdAAAAAAAAAAAFgTsokUa9liRZWd8+8Xef6ErZJHn6R5LTTyVvDihwZ6UsAAAAAAAAAAAfI3AHJdKoD6/h7vZhw92JrZStVIqWuw++nWz8oP/3t5rJ1Ewyd6b/dwMAAAAAAAAAMJYE7qBEhtlwt7lzwg13SXLxSnFe/1r/7241k+pSEewDAAAAAAAAAIAI3EGpPPfEfCqVYa+UPaGGu6RouEsGFLhbs04WAAAAAAAAAICPELiDEpmbmc7Ti/O5MYSVshuHK2UX5k6w4e7Mc8mTl5LrryXdbn/vbq0ltaX+3gkAAAAAAAAAwFgTuIOSadSrQ224O9HAXVKsld14P1m91r87D/aT9k2BOwAAAAAAAAAAPkLgDkqmUa+mubWbrZ3Oib53o93JwtxMpqcqJ/reXLhSnNdf69+d7VtJ98BKWQAAAAAAAAAAPkLgDkqmUa8lSd69ebItdxvtvSzOn3C7XZK8+N8kUzPJm30M3LWaxVnVcAcAAAAAAAAAwF0Cd1AyjXo1SbKy3jrR9260O8MJ3M0tJo1/kLz9F8n+Xn/ubK0Vp4Y7AAAAAAAAAAB+iMAdlMz5paLh7kbzZBvubrc7WZyfPdF33nHhSrK3laz8dX/uuxO403AHAAAAAAAAAMBdAndQMsNquNvcGdJK2SS5eKU4+7VWdvtwpayGOwAAAAAAAAAAfojAHZTMs2erqVSSlfWTa7jb2z9Ie+9geA13z/2XydzZ5HqfAndWygIAAAAAAAAAcB8Cd1Ayp2am8syZ+RMN3G20O0mShbkhNdxNzySf/pnk3f+YtG8d/75e4K5aP/5dAAAAAAAAAACUhsAdlFCjXj3RlbIb7b0kyZlhrZRNkguvJt2D5K0/P/5dLStlAQAAAAAAAAC4l8AdlND5ei3rrb1s7nRO5H29hrvFoQburhRnP9bKtppJZTqZP3v8uwAAAAAAAAAAKA2BOyihRr2aJCfWcnf7sOFucX72RN53X+cuJmfPJ2/2I3C3ltSWkkrl+HcBAAAAAAAAAFAaAndQQo16LUmy0tw+kfeNRMNdpVKslW2+mdx853h3bTetkwUAAAAAAAAA4B4Cd1BCJ91wdzdwN8SGu6QI3CXJ9a8d757WmsAdAAAAAAAAAAD3ELiDErrTcLd+Ug13vZWyQ2y4S+4G7o6zVvbgINleT6r1fkwEAAAAAAAAAECJCNxBCT37xHymKsmNE2q42xyFlbJJcvrJ5Jm/n7z1H4rg3ONo30y6BxruAAAAAAAAAAC4h8AdlNDs9FSePVs9uYa7nSJwd2bYK2WT5OKVYiXs9//u8X7fahanwB0AAAAAAAAAAB8jcAcl9Xz9BAN3hytlF+aG3HCXJBeuFOf1rz3e71trxVlb6ss4AAAAAAAAAACUh8AdlFSjXs2t7b3cPgzDDdLtw5WyC8NeKZskL/xUMj2XXH/t8X6/reEOAAAAAAAAAID7E7iDkmrUa0mSd0+g5W6j3Ul1djqz0yPwV8psNfnUP0y+9/Vk7zH+3e803AncAQAAAAAAAADwUSOQjgEG4Xy9miS50WwN/F0b7b0sjkK7Xc+FK8n+TvLO1x/9t63DhruqlbIAAAAAAAAAAHyUwB2UVK/hbuWEGu5GKnB38UpxvvkYa2XvNNwJ3AEAAAAAAAAA8FECd1BSLz5ZBO7+/d++l82dzkDfVTTczQ70HY/k6b9XrIS9/rVH/63AHQAAAAAAAAAAn0DgDkrq2bPVfP5zF/K3N27mf/h3f5WN9t7A3rU5ag13U1PJpz+XfP/vkq0PH+232+tJZTqZOzuY2QAAAAAAAAAAGFsCd1Bif/BLl/P5z17If/ze+sBCd/sH3Wzt7ufMKDXcJXfXyj5qy11rrWi3m/LXIwAAAAAAAAAAHyVRAiVWqVTyB798OZ//3IV8853BNN1ttot1tQtzI9RwlyQXeoG71x7td621pGqdLAAAAAAAAAAA9xK4g5KrVCr5g1+6nN999WK++c7N/Na/+6vc7mPornfXSK2UTZInzifnXkre/FrS7R79d61mUjs3sLEAAAAAAAAAABhfAncwASqVSr70i5fyT1+9mP/0zs381lf7F7rbOGy4Wxy1lbJJcuHV5PZKsvbm0b5/cJBsN4uVsgAAAAAAAAAA8DECdzAhKpVKfv8XL+ULVy7mb27czG9+9a9ya/v4obuNUW24Sx59rWz7ZtI9ELgDAAAAAAAAAOC+BO5gglQqlfzrX7iUf3blpfztjZv5ra9+49ihu7sNdyMYuPv0zySV6eTNIwbutteL00pZAAAAAAAAAADuQ+AOJkylUsm/+oVX8s//0Uv525Vbxw7dbez0Gu5GcKXs/Nnk+f8qefvPk/3Ow7/fWitOgTsAAAAAAAAAAO5D4A4mUKVSye/9/Cv54mHo7je/+o3caj1e6K7XcHdmFBvukuTilWTndvLeNx/+3V7grmqlLAAAAAAAAAAA9xK4gwlVqVTyL3/+lXzxZ1/O363cym88Zuju7krZEWy4S5ILrxbnUdbKtprFqeEOAAAAAAAAAID7ELiDCdZruvuff/bl/H/vPl7orhe4WxjVhrvGP0hOLSTXjxK4s1IWAAAAAAAAAIBPJnAH5F/+UOju17/6l7nZ2j3ybzfaRUBvcVQDd9OzyYv/bbLy18nOxoO/u91ruLNSFgAAAAAAAACAewncAUmK0N2/+LmX8613b+fX//gbRw7d3V0pO6KBuyS5cCU56CRv/8WDv3en4U7gDgAAAAAAAACAewncAXf8i597Jb/386/k2+8dPXS30d7LqZmpzM1Mn8CEj+nCq8V5/WsP/l6rmVSmk7mzAx4IAAAAAAAAAIBxJHAHfMQXf/bl/KvD0N2v/dtvZH3rwaG7jXYnZ0a53S5Jli8li88mb7724O+1mkm1nkz5qxEAAAAAAAAAgHtJlQD3+Oc/+3L+9S+8ku+8XzTdPSh0t9HuZHF+9gSnewyVSrFW9sNrya13P/l7rbWkdu7k5gIAAAAAAAAAYKwI3AH39c/+0cv5/V+8lO+8fzu/9sffSPMTQncb7b0sjnrDXZJcvFKcD1orK3AHAAAAAAAAAMADCNwBn+gLV17K7//ipbz+/u382r/9y/uG7jZ2OuMRuLvwanF+UuDu4CDZXk9qSyc0EAAAAAAAAAAA40bgDnigL1x5KV/6pUu5+v2Ne0J3BwfdbO50sjg34itlk2ThqeSpHykCd93uvZ/v3Eq6+wJ3AAAAAAAAAAB8IoE74KH+6asv5X/5pct3QndrmztJkq3dTrrdZGEcGu6SYq3s1gfJD75972etZnFWBe4AAAAAAAAAALg/gTvgSH731Yv5g18uQne//sffyNrmTjbanSQZj5WySXLhSnFef+3ez3qBu9q5k5sHAAAAAAAAAICxInAHHNk/+dzF/K+/3Gu6+0beXttKkizOj8FK2ST51E8n06eSN+8XuFsrToE7AAAAAAAAAAA+wZjUUgGj4vOfu5hKJfk//6+r+d0/+WaS5My4NNydqiXnfzL53v+TdHaSmbm7n90J3FkpCwAAAAAAAADA/Wm4Ax7Z73z2Yv7Nf/eZ3NreSzJGK2WT5MKrSWc7ufGNjz7ftlIWAAAAAAAAAIAHE7gDHsv/9NkL+d/++89kdrqSi8sLwx7n6C5eKc6Pr5W1UhYAAAAAAAAAgIcYo1oqYNT8jz9zIb/5Dz+VuZnpYY9ydM/+WDL/RHL9tST/+93nvcBdtT6UsQAAAAAAAAAAGH0a7oBjGauwXZJMTScXPpe89zdJq3n3eauZVKaKMB4AAAAAAAAAANyHwB0weS68mqSbvPVnd5+1mkl1KZny1yIAAAAAAAAAAPcnWQJMngtXivP6a3efbTeT2v/f3v2Fdl3vcRx//aYnTzsrzD+DTOdvhrvQQUklZVpKF9mhIINgpGEUTIiuY3RRBmVg0UVUtzKIhMAiGMQID6dDkKGUiEVz6rYcUtoOnWOGo9XvXKw8ZUXCdZUAAAtrSURBVFM+hyP8fmuPx82P3/e3i/fdm+9nT77fefWZBwAAAAAAAACAaUFwB8w889qTa6rJsV8Fd9+PJc3z6zYSAAAAAAAAAACNT3AHzEzLNiTfjiT/PJ7UapOvlBXcAQAAAAAAAABwCYI7YGa6/pfXyv49OfevpPZjcuU1dR0JAAAAAAAAAIDGJrgDZqbquiSVydfKfj82ec0T7gAAAAAAAAAAuATBHTAzNc9LFq1Khv6RnD398zXBHQAAAAAAAAAAFye4A2au6zck575Njv1t8nvzvPrOAwAAAAAAAABAQxPcATPXsg2Tn4f3TH56wh0AAAAAAAAAAJcguANmriWrkz81J2NHJ79f6Ql3AAAAAAAAAABcnOAOmLlmz0mWrvnvd0+4AwAAAAAAAADgEgR3wMz2y2tlk6TZE+4AAAAAAAAAALg4wR0ws13/c3BXaUr+PLe+swAAAAAAAAAA0NBm13sAgLpqXZH8pTWp/Zg0aZABAAAAAAAAALg4wR0ws1UqyV93Juf+Xe9JAAAAAAAAAABocII7gJWb6j0BAAAAAAAAAADTgPcnAgAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABQQ3AEAAAAAAAAAAEABwR0AAAAAAAAAAAAUENwBAAAAAAAAAABAAcEdAAAAAAAAAAAAFBDcAQAAAAAAAAAAQAHBHQAAAAAAAAAAABSo1Gq1Wr2HuNCcOXOycOHCeo/B/+G7775LS0tLvccAAArZ3QAw/djfADC92N0AMP3Y3wAz1+nTpzM+Pj7lbw0Z3DH9LV68OKOjo/UeAwAoZHcDwPRjfwPA9GJ3A8D0Y38DMBWvlAUAAAAAAAAAAIACgjsAAAAAAAAAAAAoMGv79u3b6z0Ef0y33XZbvUcAAP4HdjcATD/2NwBML3Y3AEw/9jcAF6rUarVavYcAAAAAAAAAAACARueVsgAAAAAAAAAAAFBAcAcAAAAAAAAAAAAFBHcAAAAAAAAAAABQQHDHZTU4OJg1a9ako6Mjq1evzueff17vkQCAXzl37lzuv//+dHR05MYbb8zGjRszPDycJDl16lQ2btyY5cuXp7OzMx9++GF9hwUAfuPZZ59NpVLJ4cOHk7gHB4BGNj4+nieeeCLLly/PypUrs2XLliT2NwA0qv7+/tx0001ZtWpVOjs709vbm8S5OQBTE9xxWW3bti3d3d05cuRInnzyyTz22GP1HgkAuEB3d3cGBgZy8ODB3Hvvvenu7k6S9PT05NZbb83g4GB27dqVzZs3Z2Jios7TAgBJ8sknn2Tfvn1pa2s7f809OAA0rp6enjQ1NeXIkSP57LPP8uKLLyaxvwGgEdVqtTz00EPZtWtXPv300/T19WXbtm05c+aMc3MAplSp1Wq1eg/BH8OpU6fS0dGRb775JrNnz06tVsu1116bffv2pVqt1ns8AGAKBw4cSFdXV44ePZqWlpYMDQ1l4cKFSZLVq1dn586dWb9+fX2HBIAZbnx8POvXr8+bb76ZDRs2pK+vL62tre7BAaBBnT17Ntddd11GR0fT0tJy/rozdABoTLVaLQsWLMg777yTO+64I4cOHco999yToaGhzJs3z7k5AL/jCXdcNidOnMiiRYsye/bsJEmlUklbW1u+/PLLOk8GAFzMK6+8kvvuuy9jY2P56aefzh8aJEm1WrXHAaABPP3009myZUva29vPX3MPDgCN69ixY5k/f36ee+653HzzzVm3bl327t1rfwNAg6pUKnnrrbfywAMPZOnSpVm7dm16e3tz5swZ5+YATElwx2VVqVR+890DFAGgce3YsSODg4N5/vnnk9jjANCIPvroo+zfvz+PP/74736zuwGgMf3www85fvx4VqxYkQMHDuTVV19NV1dXJiYm7G8AaEATExN54YUX8u6772ZkZCR79+7N1q1bk7j3BmBqgjsumyVLlmR0dPT8O+trtVpOnDiRtra2Ok8GAFzopZdeyttvv5333nsvzc3NmT9/fpLk9OnT5/9mZGTEHgeAOvvggw/yxRdfpL29PdVqNaOjo7n77rtz+PBh9+AA0KCWLl2apqambN68OUlyww03pL29PSMjI/Y3ADSggwcP5uTJk7n99tuTJLfccksWLVqUQ4cOJXFuDsDvCe64bFpbW7Nq1aq88cYbSZI9e/akWq2mWq3WdzAA4Ddefvnl7N69O++//37mzp17/vqDDz6Y1157LUmyf//+fPXVV1m7dm29xgQAkvT09OTkyZMZHh7O8PBwFi9enP7+/mzdutU9OAA0qAULFuSuu+5Kf39/ksl/zA8NDWXdunX2NwA0oF8eLDMwMJAkOXr0aI4dO5aOjg7n5gBMqVLzzFMuo4GBgTzyyCMZGxvL1Vdfnd7e3qxcubLeYwEAPxsdHc2SJUuybNmyXHXVVUmSOXPm5OOPP87XX3+dhx9+OENDQ7niiivy+uuv584776zzxADAr1Wr1fT19aWzs9M9OAA0sOPHj+fRRx/N2NhYZs2alWeeeSabNm2yvwGgQe3evTs7duxIU1NTarVannrqqXR1dTk3B2BKgjsAAAAAAAAAAAAo4JWyAAAAAAAAAAAAUEBwBwAAAAAAAAAAAAUEdwAAAAAAAAAAAFBAcAcAAAAAAAAAAAAFBHcAAAAAAAAAAABQQHAHAAAAAAAAAAAABQR3AAAAAAAAAAAAUEBwBwAAAAAAAAAAAAX+A4vqaJ7g9Yj0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), true_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last 8 days + prediction of last 4 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(8), true_y_test[-8:])\n",
    "plt.plot(range(8), np.append(true_y_test[-8:-4], predicted_y_test[-4:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
