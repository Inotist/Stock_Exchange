{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from joblib import load\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./datasets/IBM_daily.csv').sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>1999-11-02</td>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>1999-11-03</td>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>1999-11-04</td>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1999-11-05</td>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-07-24</td>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-27</td>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-28</td>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date  1. open   2. high  3. low  4. close   5. volume\n",
       "5217  1999-11-01    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216  1999-11-02    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215  1999-11-03    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214  1999-11-04    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213  1999-11-05    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...          ...      ...       ...     ...       ...         ...\n",
       "4     2020-07-22   125.90  129.4700  125.80    128.67   8195366.0\n",
       "3     2020-07-23   129.10  129.3700  127.15    127.33   4220136.0\n",
       "2     2020-07-24   126.48  127.6459  125.50    125.79   3531076.0\n",
       "1     2020-07-27   124.86  126.3200  124.71    126.21   3733547.0\n",
       "0     2020-07-28   125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5217</th>\n",
       "      <td>98.50</td>\n",
       "      <td>98.8100</td>\n",
       "      <td>96.37</td>\n",
       "      <td>96.75</td>\n",
       "      <td>9551800.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5216</th>\n",
       "      <td>96.75</td>\n",
       "      <td>96.8100</td>\n",
       "      <td>93.69</td>\n",
       "      <td>94.81</td>\n",
       "      <td>11105400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5215</th>\n",
       "      <td>95.87</td>\n",
       "      <td>95.9400</td>\n",
       "      <td>93.50</td>\n",
       "      <td>94.37</td>\n",
       "      <td>10369100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5214</th>\n",
       "      <td>94.44</td>\n",
       "      <td>94.4400</td>\n",
       "      <td>90.00</td>\n",
       "      <td>91.56</td>\n",
       "      <td>16697600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>92.75</td>\n",
       "      <td>92.9400</td>\n",
       "      <td>90.19</td>\n",
       "      <td>90.25</td>\n",
       "      <td>13737600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.90</td>\n",
       "      <td>129.4700</td>\n",
       "      <td>125.80</td>\n",
       "      <td>128.67</td>\n",
       "      <td>8195366.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>129.10</td>\n",
       "      <td>129.3700</td>\n",
       "      <td>127.15</td>\n",
       "      <td>127.33</td>\n",
       "      <td>4220136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.48</td>\n",
       "      <td>127.6459</td>\n",
       "      <td>125.50</td>\n",
       "      <td>125.79</td>\n",
       "      <td>3531076.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>124.86</td>\n",
       "      <td>126.3200</td>\n",
       "      <td>124.71</td>\n",
       "      <td>126.21</td>\n",
       "      <td>3733547.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.82</td>\n",
       "      <td>126.3400</td>\n",
       "      <td>124.15</td>\n",
       "      <td>124.47</td>\n",
       "      <td>4157538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5218 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      1. open   2. high  3. low  4. close   5. volume\n",
       "5217    98.50   98.8100   96.37     96.75   9551800.0\n",
       "5216    96.75   96.8100   93.69     94.81  11105400.0\n",
       "5215    95.87   95.9400   93.50     94.37  10369100.0\n",
       "5214    94.44   94.4400   90.00     91.56  16697600.0\n",
       "5213    92.75   92.9400   90.19     90.25  13737600.0\n",
       "...       ...       ...     ...       ...         ...\n",
       "4      125.90  129.4700  125.80    128.67   8195366.0\n",
       "3      129.10  129.3700  127.15    127.33   4220136.0\n",
       "2      126.48  127.6459  125.50    125.79   3531076.0\n",
       "1      124.86  126.3200  124.71    126.21   3733547.0\n",
       "0      125.82  126.3400  124.15    124.47   4157538.0\n",
       "\n",
       "[5218 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns='date')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence for the LSTM network\n",
    "backlook = 92\n",
    "\n",
    "# Days to predict\n",
    "days = 2\n",
    "\n",
    "# Size of data split for testing\n",
    "train_size = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test split\n",
    "split = int(len(data) * train_size)\n",
    "\n",
    "train = data.to_numpy()[:split]\n",
    "test = data.to_numpy()[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load normalisers\n",
    "normaliser = load('./normalisers/x_normaliser.joblib')\n",
    "y_normaliser = load('./normalisers/y_normaliser.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalise data\n",
    "train_norm = normaliser.transform(train)\n",
    "test_norm = normaliser.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now I get indexes for chunks from 2 in 2 days (history doubles the backlook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(train),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_train = np.array([train_norm[ix].copy() for ix in ordered_index])\n",
    "Y_train = np.array([train_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_train = np.expand_dims(Y_train, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_train = X_train[:Y_train.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Same for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(days):\n",
    "    index.append(np.arange(i,len(test),days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_index = []\n",
    "\n",
    "for i in range(len(index[0]) - backlook):\n",
    "    for e in range(days):\n",
    "        try: ordered_index.append(index[e][i:i+backlook])\n",
    "        except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalised train chunks\n",
    "X_test = np.array([test_norm[ix].copy() for ix in ordered_index])\n",
    "Y_test = np.array([test_norm[ordered_index[i+days][-1],0].copy() for i in range(len(ordered_index) - days)])\n",
    "Y_test = np.expand_dims(Y_test, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete those sequences that doesn't have a -th day in the results\n",
    "X_test = X_test[:Y_test.shape[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model constructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm(x, y, batch_size=512, epochs=24, **params):\n",
    "    \n",
    "    # List of parameters\n",
    "    if 'lstmsize' not in params: params['lstmsize'] = x.shape[1]\n",
    "    if 'density' not in params: params['density'] = int((params['lstmsize']//1.5)*2)\n",
    "    if 'activation' not in params: params['activation'] = 'relu'\n",
    "    if 'twice' not in params: params['twice'] = False\n",
    "    if 'optimizer' not in params: params['optimizer'] = 'adam'\n",
    "    if 'shuffle' not in params: params['shuffle'] = False\n",
    "    \n",
    "    # Model definition\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(LSTM(params['lstmsize'], input_shape=x.shape[1:], return_sequences=params['twice']))\n",
    "    \n",
    "    if 'dropout' in params:\n",
    "        model.add(Dropout(params['dropout']))\n",
    "    \n",
    "    if params['twice']:\n",
    "        model.add(LSTM(params['lstmsize']))\n",
    "        \n",
    "        if 'dropout' in params:\n",
    "            model.add(Dropout(params['dropout']))\n",
    "            \n",
    "    model.add(Dense(params['density'], activation=params['activation']))\n",
    "    \n",
    "    if 'full_density' in params and params['full_density']:\n",
    "        density = params['density']//2\n",
    "        while density >= 12:\n",
    "            model.add(Dense(density, activation=params['activation']))\n",
    "            density //= 2\n",
    "            \n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', optimizer=params['optimizer'])\n",
    "    \n",
    "    if 'callbacks' in params:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'],\n",
    "                            callbacks=params['callbacks'])\n",
    "    else:\n",
    "        callback = model.fit(x=x, y=y, validation_split=0.1, batch_size=batch_size, epochs=epochs, shuffle=params['shuffle'])\n",
    "    \n",
    "    return [model, callback, params]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evolutive algorith to search for the most optimal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_genes(x, y, population_size, population=[]):\n",
    "    if population_size-len(population) < 0:\n",
    "        print('population size must be greater or equal than actual population')\n",
    "        return\n",
    "    \n",
    "    if len(population) > 0:\n",
    "        if len(population) < 3:\n",
    "            print('population should be empty or 3 at least')\n",
    "            return\n",
    "        \n",
    "        population[2] = breed_genes(x, y, population[0][2].copy())\n",
    "        population[1] = breed_genes(x, y, combine=(population[0][2], population[1][2]))\n",
    "        population = population[:3]\n",
    "    \n",
    "    for _ in range(population_size-len(population)):\n",
    "        subject = breed_genes(x, y)\n",
    "        population.append(subject)\n",
    "        \n",
    "    return population\n",
    "\n",
    "def breed_genes(x, y, genes={}, combine=None):\n",
    "    genes['x'] = x\n",
    "    genes['y'] = y\n",
    "    \n",
    "    if type(combine) is list or type(combine) is tuple:\n",
    "        genes['lstmsize'] = combine[np.random.randint(0,2)]['lstmsize']\n",
    "        genes['density'] = combine[np.random.randint(0,2)]['density']\n",
    "        genes['activation'] = combine[np.random.randint(0,2)]['activation']\n",
    "        genes['twice'] = combine[np.random.randint(0,2)]['twice']\n",
    "        genes['optimizer'] = combine[np.random.randint(0,2)]['optimizer']\n",
    "        genes['shuffle'] = combine[np.random.randint(0,2)]['shuffle']\n",
    "        \n",
    "        genes['dropout'] = combine[np.random.randint(0,2)].get('dropout')\n",
    "        if genes['dropout'] is None: del genes['dropout']\n",
    "        genes['full_density'] = combine[np.random.randint(0,2)].get('full_density')\n",
    "        if genes['full_density'] is None: del genes['full_density']\n",
    "            \n",
    "    else:\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['lstmsize'] = int((np.random.randint(x.shape[1],x.shape[1]*2)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['density'] = int((np.random.randint(x.shape[1]//2,x.shape[1]*2.66)//2)*2)\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            activation = [\n",
    "                'relu',\n",
    "                'sigmoid',\n",
    "                'softplus',\n",
    "                'softsign',\n",
    "                'tanh',\n",
    "                'selu',\n",
    "                'elu',\n",
    "                'exponential'\n",
    "            ]\n",
    "            genes['activation'] = activation[np.random.randint(0,8)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['twice'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            optimizer = [\n",
    "                'sgd',\n",
    "                'rmsprop',\n",
    "                'adam',\n",
    "                'adadelta',\n",
    "                'adagrad',\n",
    "                'adamax',\n",
    "                'nadam'\n",
    "            ]\n",
    "            genes['optimizer'] = optimizer[np.random.randint(0,7)]\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['shuffle'] = True\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['dropout'] = np.random.randint(1,4)/10\n",
    "\n",
    "        if np.random.randint(0,3) == 1:\n",
    "            genes['full_density'] = True\n",
    "            \n",
    "    new_model = build_lstm(**genes)\n",
    "        \n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_population(x, y, generations, population_size, population=[]):\n",
    "    \n",
    "    if generations > 1 and population_size < 3:\n",
    "        print('population size should be of a minimum of 3 for more than one generation')\n",
    "        return\n",
    "    \n",
    "    for g in range(generations):\n",
    "        print(f'\\nGENERATION {g}\\n')\n",
    "        population = set_genes(x, y, population_size, population)\n",
    "        population = sorted(population, key=lambda x: x[1].history['val_loss'][-1]+x[1].history['loss'][-1])\n",
    "        \n",
    "    return population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "GENERATION 0\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow-gpu\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 1s 273us/step - loss: 0.1016 - val_loss: 0.0334\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0136 - val_loss: 0.0092\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 0.0063 - val_loss: 7.8213e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 0.0017 - val_loss: 6.6367e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 8.6626e-04 - val_loss: 6.1638e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 7.4782e-04 - val_loss: 7.3978e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 6.9344e-04 - val_loss: 8.2700e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 152us/step - loss: 6.5749e-04 - val_loss: 6.5795e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 160us/step - loss: 6.2473e-04 - val_loss: 6.2132e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 5.9516e-04 - val_loss: 6.0740e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 162us/step - loss: 5.6287e-04 - val_loss: 5.5195e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 5.2661e-04 - val_loss: 5.2086e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 5.0135e-04 - val_loss: 4.9901e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 4.8180e-04 - val_loss: 4.5832e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 163us/step - loss: 4.6354e-04 - val_loss: 4.4530e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 161us/step - loss: 4.4805e-04 - val_loss: 4.1469e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 163us/step - loss: 4.3014e-04 - val_loss: 4.3372e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 4.2851e-04 - val_loss: 3.9501e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 159us/step - loss: 4.1147e-04 - val_loss: 3.9316e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 4.0149e-04 - val_loss: 3.8306e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 162us/step - loss: 3.9322e-04 - val_loss: 3.7326e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 161us/step - loss: 3.8801e-04 - val_loss: 3.7063e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 3.8178e-04 - val_loss: 3.6110e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0549 - val_loss: 0.0067\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 0.0130 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0060 - val_loss: 6.1316e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0035 - val_loss: 6.2801e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0021 - val_loss: 6.1665e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 155us/step - loss: 0.0017 - val_loss: 4.8456e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 159us/step - loss: 0.0015 - val_loss: 7.1811e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0014 - val_loss: 4.5529e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 0.0014 - val_loss: 5.3253e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 0.0013 - val_loss: 4.6096e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 155us/step - loss: 0.0012 - val_loss: 4.4680e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0013 - val_loss: 4.8078e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 0.0012 - val_loss: 4.2851e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 0.0011 - val_loss: 4.3927e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 159us/step - loss: 0.0011 - val_loss: 4.2581e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 0.0010 - val_loss: 4.2413e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 155us/step - loss: 0.0011 - val_loss: 4.1972e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 159us/step - loss: 9.4621e-04 - val_loss: 4.0303e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 9.8142e-04 - val_loss: 3.9858e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 9.5135e-04 - val_loss: 3.9517e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 9.3103e-04 - val_loss: 3.9123e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 8.8005e-04 - val_loss: 3.8852e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 2s 498us/step - loss: 0.0597 - val_loss: 0.0363\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0124 - val_loss: 0.0110\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0034 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0022 - val_loss: 9.7855e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0020 - val_loss: 9.2823e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0017 - val_loss: 9.1369e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0017 - val_loss: 9.5916e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0016 - val_loss: 8.9083e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0015 - val_loss: 9.0990e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0015 - val_loss: 8.6677e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0015 - val_loss: 8.3473e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0015 - val_loss: 8.5639e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0015 - val_loss: 8.8020e-04\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0014 - val_loss: 8.8694e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0014 - val_loss: 8.0041e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0013 - val_loss: 8.0405e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0013 - val_loss: 7.8000e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0579 - val_loss: 0.0256\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0098 - val_loss: 0.0010\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0047 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0019 - val_loss: 8.1242e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0017 - val_loss: 9.7668e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0016 - val_loss: 7.8162e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0014 - val_loss: 7.9110e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0015 - val_loss: 8.8844e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0014 - val_loss: 7.6943e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0014 - val_loss: 7.4057e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0013 - val_loss: 7.3568e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0013 - val_loss: 7.8036e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0013 - val_loss: 7.1543e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0012 - val_loss: 7.1412e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0012 - val_loss: 7.0314e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0012 - val_loss: 7.1762e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0012 - val_loss: 6.9860e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0012 - val_loss: 6.8785e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0011 - val_loss: 6.7517e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0011 - val_loss: 6.7068e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0011 - val_loss: 6.8296e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 2s 603us/step - loss: 0.0625 - val_loss: 0.0284\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0118 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0057 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0037 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0027 - val_loss: 8.8122e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0024 - val_loss: 8.4606e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0022 - val_loss: 9.7552e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0022 - val_loss: 9.8432e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0022 - val_loss: 8.5552e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0020 - val_loss: 8.1482e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0020 - val_loss: 8.0995e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0020 - val_loss: 7.9723e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0019 - val_loss: 7.8875e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0019 - val_loss: 8.4792e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0017 - val_loss: 8.2960e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0017 - val_loss: 7.9794e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0016 - val_loss: 7.9410e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0017 - val_loss: 8.2971e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0017 - val_loss: 7.8120e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0016 - val_loss: 7.3608e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0016 - val_loss: 7.2808e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0016 - val_loss: 7.2136e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0015 - val_loss: 7.2283e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 625us/step - loss: 0.0752 - val_loss: 0.0387\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0144 - val_loss: 0.0074\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0057 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0038 - val_loss: 8.7962e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0029 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0027 - val_loss: 9.5199e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0024 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0022 - val_loss: 8.3638e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0021 - val_loss: 7.9727e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0019 - val_loss: 8.1957e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0019 - val_loss: 7.8325e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0018 - val_loss: 7.7784e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0017 - val_loss: 8.1147e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0017 - val_loss: 7.5721e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0017 - val_loss: 7.5272e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0017 - val_loss: 7.8647e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0016 - val_loss: 7.5291e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0016 - val_loss: 7.4450e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0016 - val_loss: 7.8389e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0016 - val_loss: 8.8351e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0016 - val_loss: 8.0129e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0015 - val_loss: 8.7540e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0015 - val_loss: 8.5708e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 771us/step - loss: 3.5470 - val_loss: 0.1235\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0625 - val_loss: 0.2847\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0490 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0111 - val_loss: 0.0202\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0329 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0040 - val_loss: 0.0169\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0088 - val_loss: 0.0308\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0054 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0039 - val_loss: 0.0043\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0058 - val_loss: 0.0028\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0024 - val_loss: 0.0038\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0033 - val_loss: 0.0089\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0041 - val_loss: 0.0056\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0023 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0026 - val_loss: 0.0026\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 772us/step - loss: 1.2264 - val_loss: 0.0360\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0464 - val_loss: 0.1055\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0297 - val_loss: 0.0117\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0252 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0066 - val_loss: 0.0137\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0066 - val_loss: 0.0315\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0112 - val_loss: 0.0255\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0065 - val_loss: 0.0128\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0067 - val_loss: 0.0231\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0076 - val_loss: 0.0164\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0046 - val_loss: 0.0053\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0044 - val_loss: 0.0106\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0045 - val_loss: 0.0072\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0042 - val_loss: 0.0108\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0046 - val_loss: 0.0056\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0028 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0048 - val_loss: 0.0074\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0025 - val_loss: 0.0058\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 815us/step - loss: 0.5907 - val_loss: 0.1520\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0626 - val_loss: 0.0663\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0220 - val_loss: 0.0308\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0098 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0060 - val_loss: 0.0098\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0028 - val_loss: 9.0914e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0024 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0022 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0022 - val_loss: 9.1328e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0021 - val_loss: 8.8574e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0021 - val_loss: 8.2479e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0020 - val_loss: 8.0199e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0019 - val_loss: 8.5301e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0019 - val_loss: 8.4347e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0018 - val_loss: 7.7474e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0017 - val_loss: 7.7110e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0017 - val_loss: 7.4889e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0017 - val_loss: 7.4195e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 732us/step - loss: 1.1115 - val_loss: 0.4780\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.1674 - val_loss: 0.0797\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0676 - val_loss: 0.0217\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0697 - val_loss: 0.0202\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0681 - val_loss: 0.0297\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0662 - val_loss: 0.0374\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0659 - val_loss: 0.0400\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0659 - val_loss: 0.0396\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0659 - val_loss: 0.0392\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0659 - val_loss: 0.0396\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0659 - val_loss: 0.0393\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0658 - val_loss: 0.0398\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0659 - val_loss: 0.0398\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0658 - val_loss: 0.0391\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0658 - val_loss: 0.0390\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0659 - val_loss: 0.0389\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0659 - val_loss: 0.0388\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0658 - val_loss: 0.0377\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0659 - val_loss: 0.0398\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0659 - val_loss: 0.0391\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0658 - val_loss: 0.0396\n",
      "\n",
      "GENERATION 1\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0568 - val_loss: 0.0078\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 0.0060 - val_loss: 0.0062\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0027 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 9.5283e-04 - val_loss: 9.8769e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 7.5048e-04 - val_loss: 8.0055e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 6.5323e-04 - val_loss: 5.5774e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 6.1213e-04 - val_loss: 5.6502e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 5.9700e-04 - val_loss: 5.5086e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 5.8647e-04 - val_loss: 5.3467e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 5.7714e-04 - val_loss: 5.3700e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 5.7134e-04 - val_loss: 5.4174e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 5.6869e-04 - val_loss: 5.2104e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 5.5999e-04 - val_loss: 5.2309e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 5.5831e-04 - val_loss: 5.4685e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 5.4611e-04 - val_loss: 5.0754e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 5.3258e-04 - val_loss: 4.9607e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 5.1561e-04 - val_loss: 4.8566e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 4.9941e-04 - val_loss: 4.9620e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 4.8342e-04 - val_loss: 4.4348e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 4.5754e-04 - val_loss: 4.3745e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.4300e-04 - val_loss: 4.1708e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.2701e-04 - val_loss: 3.9596e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.2468e-04 - val_loss: 3.8975e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 2s 381us/step - loss: 0.0371 - val_loss: 0.0056\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 0.0054 - val_loss: 0.0043\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 0.0024 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 159us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 155us/step - loss: 7.8153e-04 - val_loss: 5.4344e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 6.7375e-04 - val_loss: 8.4246e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 6.1466e-04 - val_loss: 5.5528e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 5.7919e-04 - val_loss: 6.6985e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 5.6595e-04 - val_loss: 5.1790e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 153us/step - loss: 5.4717e-04 - val_loss: 6.0961e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 5.3099e-04 - val_loss: 5.0693e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 5.2122e-04 - val_loss: 5.5076e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 155us/step - loss: 5.1242e-04 - val_loss: 4.9598e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 5.0445e-04 - val_loss: 4.8444e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 4.9654e-04 - val_loss: 5.3421e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 155us/step - loss: 4.8819e-04 - val_loss: 4.9276e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 4.7777e-04 - val_loss: 4.7440e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 155us/step - loss: 4.6791e-04 - val_loss: 4.4939e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 4.5733e-04 - val_loss: 4.6092e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 159us/step - loss: 4.4671e-04 - val_loss: 4.3972e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 4.3524e-04 - val_loss: 4.0582e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 159us/step - loss: 4.2448e-04 - val_loss: 3.9479e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 162us/step - loss: 4.2057e-04 - val_loss: 3.9531e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 621us/step - loss: 0.0973 - val_loss: 0.0037\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 311us/step - loss: 0.0099 - val_loss: 0.0056\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0025 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0016 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 313us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 311us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 310us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 312us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 312us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0010 - val_loss: 9.7931e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 313us/step - loss: 0.0010 - val_loss: 9.6253e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 9.9588e-04 - val_loss: 9.2942e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 311us/step - loss: 9.7150e-04 - val_loss: 8.9160e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 314us/step - loss: 9.3999e-04 - val_loss: 8.6741e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 9.1226e-04 - val_loss: 8.7181e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 312us/step - loss: 8.9767e-04 - val_loss: 8.2998e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 312us/step - loss: 8.9526e-04 - val_loss: 8.4712e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 681us/step - loss: 0.0610 - val_loss: 0.0177\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0143 - val_loss: 0.0085\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0098 - val_loss: 0.0091\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0080 - val_loss: 0.0055\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0060 - val_loss: 0.0088\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0074 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.0051 - val_loss: 0.0085\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0069 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0046 - val_loss: 0.0079\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0078 - val_loss: 0.0088\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0049 - val_loss: 0.0062\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0056 - val_loss: 0.0054\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0053 - val_loss: 0.0071\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0051 - val_loss: 0.0054\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0039 - val_loss: 0.0045\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0043 - val_loss: 0.0058\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0056 - val_loss: 0.0079\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0053 - val_loss: 0.0048\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0040 - val_loss: 0.0052\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0052 - val_loss: 0.0087\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0043 - val_loss: 0.0028\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 667us/step - loss: 0.2190 - val_loss: 0.2310\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.1250 - val_loss: 0.1269\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0818 - val_loss: 0.0764\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0612 - val_loss: 0.0495\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0514 - val_loss: 0.0348\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0466 - val_loss: 0.0266\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0437 - val_loss: 0.0219\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0412 - val_loss: 0.0190\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0395 - val_loss: 0.0171\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0371 - val_loss: 0.0155\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0353 - val_loss: 0.0144\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 325us/step - loss: 0.0330 - val_loss: 0.0134\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0315 - val_loss: 0.0123\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0297 - val_loss: 0.0114\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0279 - val_loss: 0.0103\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0262 - val_loss: 0.0092\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0248 - val_loss: 0.0082\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0233 - val_loss: 0.0072\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0216 - val_loss: 0.0065\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0198 - val_loss: 0.0058\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0186 - val_loss: 0.0051\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0174 - val_loss: 0.0045\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0157 - val_loss: 0.0039\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0148 - val_loss: 0.0034\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 887us/step - loss: 0.0937 - val_loss: 0.0433\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0457 - val_loss: 0.0263\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0408 - val_loss: 0.0218\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0373 - val_loss: 0.0193\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0337 - val_loss: 0.0175\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0303 - val_loss: 0.0156\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0270 - val_loss: 0.0139\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0237 - val_loss: 0.0117\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0205 - val_loss: 0.0095\n",
      "Epoch 10/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0177 - val_loss: 0.0076\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0150 - val_loss: 0.0062\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0128 - val_loss: 0.0047\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0108 - val_loss: 0.0037\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0094 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0082 - val_loss: 0.0023\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0072 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0047 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 0.0046 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 898us/step - loss: 0.1065 - val_loss: 0.0271\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0492 - val_loss: 0.0206\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0389 - val_loss: 0.0156\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0304 - val_loss: 0.0118\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0238 - val_loss: 0.0087\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0181 - val_loss: 0.0061\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0140 - val_loss: 0.0039\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0109 - val_loss: 0.0027\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0088 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0073 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0064 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0057 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0054 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0050 - val_loss: 0.0025\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0049 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0050 - val_loss: 0.0029\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0048 - val_loss: 0.0030\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0046 - val_loss: 0.0032\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0047 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0045 - val_loss: 0.0034\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0046 - val_loss: 0.0038\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 952us/step - loss: 0.0668 - val_loss: 0.0044\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0096 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0075 - val_loss: 0.0072\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0085 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0077 - val_loss: 0.0086\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0071 - val_loss: 0.0076\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0077 - val_loss: 0.0085\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0064 - val_loss: 0.0089\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0072 - val_loss: 0.0092\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0063 - val_loss: 0.0079\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0074 - val_loss: 0.0092\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0064 - val_loss: 0.0059\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0052 - val_loss: 0.0105\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0072 - val_loss: 0.0080\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0048 - val_loss: 0.0057\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0044 - val_loss: 0.0079\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0071 - val_loss: 0.0105\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0048 - val_loss: 0.0060\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0039 - val_loss: 0.0078\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0061 - val_loss: 0.0079\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0040 - val_loss: 0.0059\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0048 - val_loss: 0.0100\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0060 - val_loss: 0.0093\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0032 - val_loss: 0.0049\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 970us/step - loss: 0.0583 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0053 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0094 - val_loss: 0.0116\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0071 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0035 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0097 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0059 - val_loss: 0.0019\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0062 - val_loss: 0.0025\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0071 - val_loss: 0.0036\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0067 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0037 - val_loss: 0.0012\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0053 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0051 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0043 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0047 - val_loss: 0.0051\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0067 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0045 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0048 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0039 - val_loss: 0.0015\n",
      "\n",
      "GENERATION 2\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.2136 - val_loss: 0.0168\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 0.1266 - val_loss: 0.0241\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 0.0268 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0060 - val_loss: 0.0038\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 155us/step - loss: 0.0053 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 0.0053 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 159us/step - loss: 0.0036 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 0.0033 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 158us/step - loss: 0.0027 - val_loss: 9.6422e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 159us/step - loss: 0.0050 - val_loss: 0.0052\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 0.0031 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 154us/step - loss: 0.0022 - val_loss: 8.4822e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 156us/step - loss: 0.0023 - val_loss: 8.5424e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 153us/step - loss: 0.0077 - val_loss: 0.0047\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0039 - val_loss: 9.9691e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 157us/step - loss: 0.0021 - val_loss: 7.9655e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 2s 609us/step - loss: 0.0593 - val_loss: 0.0020\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0052 - val_loss: 0.0030\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0013 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.8172e-04 - val_loss: 7.4295e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 7.0972e-04 - val_loss: 9.3685e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 6.2927e-04 - val_loss: 4.9980e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 5.7649e-04 - val_loss: 5.4076e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 5.4938e-04 - val_loss: 5.7353e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 5.2322e-04 - val_loss: 4.7435e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.9998e-04 - val_loss: 4.6313e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.7699e-04 - val_loss: 4.4425e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.4968e-04 - val_loss: 4.1837e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.3217e-04 - val_loss: 3.8737e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.1065e-04 - val_loss: 4.0423e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 3.9693e-04 - val_loss: 3.7061e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 3.8572e-04 - val_loss: 3.6200e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 3.8013e-04 - val_loss: 3.5297e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 3.6577e-04 - val_loss: 3.5376e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 3.6018e-04 - val_loss: 3.4930e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 3.5613e-04 - val_loss: 3.3622e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 3.4901e-04 - val_loss: 3.4091e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 3.4552e-04 - val_loss: 3.2799e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 3.5877e-04 - val_loss: 3.9558e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 912us/step - loss: 0.0631 - val_loss: 0.0080\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 471us/step - loss: 0.0040 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 472us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 469us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 473us/step - loss: 0.0012 - val_loss: 8.6901e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 474us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 472us/step - loss: 0.0010 - val_loss: 8.6526e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 470us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 471us/step - loss: 9.9007e-04 - val_loss: 9.3010e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 473us/step - loss: 9.7596e-04 - val_loss: 8.9742e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 472us/step - loss: 9.6268e-04 - val_loss: 9.2574e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 467us/step - loss: 9.5475e-04 - val_loss: 9.1654e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 468us/step - loss: 9.4987e-04 - val_loss: 8.7411e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 472us/step - loss: 9.4023e-04 - val_loss: 9.0537e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 473us/step - loss: 9.3320e-04 - val_loss: 8.7756e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 471us/step - loss: 9.2721e-04 - val_loss: 9.0356e-04\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 473us/step - loss: 9.2058e-04 - val_loss: 8.4003e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 472us/step - loss: 9.1984e-04 - val_loss: 8.7698e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 466us/step - loss: 9.0875e-04 - val_loss: 8.5789e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 473us/step - loss: 9.0247e-04 - val_loss: 8.4131e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 472us/step - loss: 8.9605e-04 - val_loss: 8.4020e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 472us/step - loss: 8.9114e-04 - val_loss: 8.2854e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 471us/step - loss: 8.8502e-04 - val_loss: 8.4250e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 468us/step - loss: 8.8063e-04 - val_loss: 8.2643e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 914us/step - loss: 0.1615 - val_loss: 0.0353\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 440us/step - loss: 0.0125 - val_loss: 0.0102\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 443us/step - loss: 0.0053 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 445us/step - loss: 0.0041 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 445us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 444us/step - loss: 0.0014 - val_loss: 9.4045e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 440us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 447us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 442us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 444us/step - loss: 0.0011 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 442us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 440us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 444us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 445us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 444us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 444us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 443us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 443us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 442us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 442us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 443us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 440us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 443us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 442us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 870us/step - loss: 0.0606 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 390us/step - loss: 0.0069 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 386us/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 387us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 386us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 389us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 386us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 390us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 385us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 390us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 385us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 384us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 389us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 387us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 386us/step - loss: 9.9257e-04 - val_loss: 9.7405e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 386us/step - loss: 9.7677e-04 - val_loss: 9.6137e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: 9.6160e-04 - val_loss: 9.8894e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 9.5084e-04 - val_loss: 9.1911e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 965us/step - loss: 0.0480 - val_loss: 0.0249\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0104 - val_loss: 0.0082\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 0.0068 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0042 - val_loss: 0.0045\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0052 - val_loss: 0.0074\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0066 - val_loss: 0.0050\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: 0.0049 - val_loss: 0.0058\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 387us/step - loss: 0.0051 - val_loss: 0.0046\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0047 - val_loss: 0.0058\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0056 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0044 - val_loss: 0.0052\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 390us/step - loss: 0.0048 - val_loss: 0.0040\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 0.0042 - val_loss: 0.0048\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: 0.0048 - val_loss: 0.0047\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 0.0035 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: 0.0046 - val_loss: 0.0041\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0040 - val_loss: 0.0071\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 389us/step - loss: 0.0052 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: 0.0041 - val_loss: 0.0040\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 0.0038 - val_loss: 0.0039\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 916us/step - loss: 0.0432 - val_loss: 0.0117\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 359us/step - loss: 0.0064 - val_loss: 0.0103\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 362us/step - loss: 0.0094 - val_loss: 0.0066\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0061 - val_loss: 0.0062\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 362us/step - loss: 0.0070 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.0049 - val_loss: 0.0056\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 357us/step - loss: 0.0069 - val_loss: 0.0077\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 363us/step - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 359us/step - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 365us/step - loss: 0.0057 - val_loss: 0.0057\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0064 - val_loss: 0.0076\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0054 - val_loss: 0.0054\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.0058 - val_loss: 0.0051\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 364us/step - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 362us/step - loss: 0.0043 - val_loss: 0.0034\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 363us/step - loss: 0.0055 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0059 - val_loss: 0.0058\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 362us/step - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0036 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 360us/step - loss: 0.0034 - val_loss: 0.0052\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 359us/step - loss: 0.0045 - val_loss: 0.0058\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 358us/step - loss: 0.0055 - val_loss: 0.0058\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 366us/step - loss: 0.0060 - val_loss: 0.0057\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 361us/step - loss: 0.0051 - val_loss: 0.0026\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 958us/step - loss: 0.0577 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 381us/step - loss: 0.0061 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 376us/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 378us/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0112 - val_loss: 0.0158\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 375us/step - loss: 0.0128 - val_loss: 0.0051\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 380us/step - loss: 0.0057 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 378us/step - loss: 0.0123 - val_loss: 0.0051\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 376us/step - loss: 0.0066 - val_loss: 0.0033\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 376us/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 375us/step - loss: 0.0077 - val_loss: 0.0072\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 380us/step - loss: 0.0084 - val_loss: 0.0076\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 375us/step - loss: 0.0075 - val_loss: 0.0043\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 380us/step - loss: 0.0064 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 375us/step - loss: 0.0079 - val_loss: 0.0075\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0064 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 378us/step - loss: 0.0059 - val_loss: 0.0025\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 381us/step - loss: 0.0057 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 382us/step - loss: 0.0059 - val_loss: 0.0041\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 376us/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 382us/step - loss: 0.0059 - val_loss: 0.0071\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0084 - val_loss: 0.0069\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 382us/step - loss: 0.0062 - val_loss: 0.0023\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1ms/step - loss: 0.0786 - val_loss: 0.0210\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 380us/step - loss: 0.0153 - val_loss: 0.0133\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 377us/step - loss: 0.0118 - val_loss: 0.0161\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 380us/step - loss: 0.0109 - val_loss: 0.0080\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 374us/step - loss: 0.0075 - val_loss: 0.0086\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 380us/step - loss: 0.0074 - val_loss: 0.0123\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 381us/step - loss: 0.0088 - val_loss: 0.0097\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 380us/step - loss: 0.0082 - val_loss: 0.0106\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 378us/step - loss: 0.0082 - val_loss: 0.0093\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 380us/step - loss: 0.0098 - val_loss: 0.0088\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0068 - val_loss: 0.0095\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 380us/step - loss: 0.0092 - val_loss: 0.0075\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 376us/step - loss: 0.0057 - val_loss: 0.0100\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 381us/step - loss: 0.0086 - val_loss: 0.0079\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 377us/step - loss: 0.0070 - val_loss: 0.0067\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 378us/step - loss: 0.0059 - val_loss: 0.0103\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 375us/step - loss: 0.0046 - val_loss: 0.0060\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 381us/step - loss: 0.0066 - val_loss: 0.0064\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0075 - val_loss: 0.0053\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 384us/step - loss: 0.0041 - val_loss: 0.0096\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 377us/step - loss: 0.0061 - val_loss: 0.0065\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 380us/step - loss: 0.0071 - val_loss: 0.0100\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0068 - val_loss: 0.0091\n",
      "\n",
      "GENERATION 3\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 4s 907us/step - loss: 0.0856 - val_loss: 0.0054\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0099 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 0.0048 - val_loss: 0.0041\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 0.0026 - val_loss: 0.0039\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 318us/step - loss: 0.0013 - val_loss: 9.1666e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 318us/step - loss: 0.0011 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 321us/step - loss: 0.0011 - val_loss: 9.9614e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 0.0010 - val_loss: 9.5340e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 9.8801e-04 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 9.6500e-04 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 320us/step - loss: 9.4397e-04 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 9.2314e-04 - val_loss: 9.2918e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 9.0356e-04 - val_loss: 8.3239e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 324us/step - loss: 8.8791e-04 - val_loss: 8.5230e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 8.6743e-04 - val_loss: 8.0609e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 318us/step - loss: 8.5334e-04 - val_loss: 8.5093e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 8.2907e-04 - val_loss: 7.5592e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 323us/step - loss: 8.1787e-04 - val_loss: 7.4698e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 320us/step - loss: 7.9504e-04 - val_loss: 7.4146e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 318us/step - loss: 7.7787e-04 - val_loss: 7.6246e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 7.6124e-04 - val_loss: 7.2954e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 7.4742e-04 - val_loss: 6.8724e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 808us/step - loss: 0.0517 - val_loss: 0.0060\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0078 - val_loss: 9.7782e-04\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 0.0030 - val_loss: 6.1531e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0015 - val_loss: 5.5567e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 8.5831e-04 - val_loss: 7.8140e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 6.9109e-04 - val_loss: 5.3567e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 6.2909e-04 - val_loss: 6.8935e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 5.8128e-04 - val_loss: 5.2445e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 5.5397e-04 - val_loss: 5.0163e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 5.4034e-04 - val_loss: 5.4573e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 5.2043e-04 - val_loss: 4.9976e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 5.1117e-04 - val_loss: 4.7968e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.9934e-04 - val_loss: 4.7558e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.8425e-04 - val_loss: 4.6064e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.7799e-04 - val_loss: 4.5519e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.6519e-04 - val_loss: 4.4693e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.5280e-04 - val_loss: 4.4849e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 4.3776e-04 - val_loss: 4.2063e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.2347e-04 - val_loss: 4.2014e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.1679e-04 - val_loss: 4.0550e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 4.0299e-04 - val_loss: 3.9739e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 3.9202e-04 - val_loss: 3.8074e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 3.8008e-04 - val_loss: 3.8848e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 3.7471e-04 - val_loss: 3.7752e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 3s 845us/step - loss: 0.1094 - val_loss: 0.0413\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 0.0661 - val_loss: 0.0130\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 0.0658 - val_loss: 0.0156\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 0.0527 - val_loss: 0.0290\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 0.0462 - val_loss: 0.0243\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0368 - val_loss: 0.0087\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0265 - val_loss: 0.0044\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0219 - val_loss: 0.0093\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0211 - val_loss: 0.0124\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0211 - val_loss: 0.0116\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0208 - val_loss: 0.0101\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0207 - val_loss: 0.0089\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0207 - val_loss: 0.0084\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0208 - val_loss: 0.0085\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 0.0207 - val_loss: 0.0087\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0207 - val_loss: 0.0087\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 0.0207 - val_loss: 0.0089\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 0.0208 - val_loss: 0.0091\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 0.0208 - val_loss: 0.0085\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0209 - val_loss: 0.0086\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0214 - val_loss: 0.0078\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0220 - val_loss: 0.0068\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0230 - val_loss: 0.0048\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0221 - val_loss: 0.0042\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.2594 - val_loss: 0.0066\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0856 - val_loss: 0.0372\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0687 - val_loss: 0.0798\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0740 - val_loss: 0.0747\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0693 - val_loss: 0.0500\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0661 - val_loss: 0.0341\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0663 - val_loss: 0.0309\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0662 - val_loss: 0.0353\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0659 - val_loss: 0.0408\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0659 - val_loss: 0.0417\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0659 - val_loss: 0.0395\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0658 - val_loss: 0.0386\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0658 - val_loss: 0.0385\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0659 - val_loss: 0.0399\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0658 - val_loss: 0.0391\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0658 - val_loss: 0.0382\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0658 - val_loss: 0.0385\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0658 - val_loss: 0.0399\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0658 - val_loss: 0.0391\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0658 - val_loss: 0.0387\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0658 - val_loss: 0.0390\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0658 - val_loss: 0.0392\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0658 - val_loss: 0.0399\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0657 - val_loss: 0.0393\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.0787 - val_loss: 0.0197\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0698 - val_loss: 0.0251\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0630 - val_loss: 0.0470\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0579 - val_loss: 0.0290\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0465 - val_loss: 0.0254\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0445 - val_loss: 0.0653\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0628 - val_loss: 0.0320\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0665 - val_loss: 0.0375\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0661 - val_loss: 0.0450\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0659 - val_loss: 0.0337\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0659 - val_loss: 0.0416\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0660 - val_loss: 0.0397\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0659 - val_loss: 0.0362\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0659 - val_loss: 0.0430\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0659 - val_loss: 0.0360\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0659 - val_loss: 0.0414\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0659 - val_loss: 0.0387\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0660 - val_loss: 0.0393\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0659 - val_loss: 0.0380\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0659 - val_loss: 0.0416\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0659 - val_loss: 0.0390\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0659 - val_loss: 0.0382\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0659 - val_loss: 0.0410\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1ms/step - loss: 1.6754 - val_loss: 1.5088\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.8597 - val_loss: 0.7840\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.4269 - val_loss: 0.4476\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.2407 - val_loss: 0.2783\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.1533 - val_loss: 0.1851\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.1100 - val_loss: 0.1310\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0883 - val_loss: 0.0980\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 333us/step - loss: 0.0769 - val_loss: 0.0772\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0712 - val_loss: 0.0635\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0682 - val_loss: 0.0545\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0668 - val_loss: 0.0483\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0661 - val_loss: 0.0440\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0658 - val_loss: 0.0412\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0656 - val_loss: 0.0398\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0656 - val_loss: 0.0388\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0656 - val_loss: 0.0385\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0655 - val_loss: 0.0386\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0655 - val_loss: 0.0381\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0655 - val_loss: 0.0383\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0655 - val_loss: 0.0376\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0654 - val_loss: 0.0375\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0654 - val_loss: 0.0373\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 328us/step - loss: 0.0654 - val_loss: 0.0365\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0653 - val_loss: 0.0367\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1ms/step - loss: 0.1555 - val_loss: 0.0975\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0701 - val_loss: 0.0488\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 351us/step - loss: 0.0641 - val_loss: 0.0398\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 342us/step - loss: 0.0631 - val_loss: 0.0366\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 346us/step - loss: 0.0623 - val_loss: 0.0351\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 352us/step - loss: 0.0614 - val_loss: 0.0349\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 337us/step - loss: 0.0602 - val_loss: 0.0345\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0585 - val_loss: 0.0317\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 332us/step - loss: 0.0560 - val_loss: 0.0300\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 349us/step - loss: 0.0514 - val_loss: 0.0259\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 343us/step - loss: 0.0414 - val_loss: 0.0140\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 331us/step - loss: 0.0280 - val_loss: 0.0045\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 345us/step - loss: 0.0202 - val_loss: 0.0041\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0161 - val_loss: 0.0052\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0136 - val_loss: 0.0084\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0117 - val_loss: 0.0089\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 329us/step - loss: 0.0103 - val_loss: 0.0104\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0087 - val_loss: 0.0103\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0077 - val_loss: 0.0082\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0075 - val_loss: 0.0050\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 326us/step - loss: 0.0075 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0087 - val_loss: 0.0028\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 330us/step - loss: 0.0076 - val_loss: 0.0031\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 327us/step - loss: 0.0068 - val_loss: 0.0023\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.1307 - val_loss: 0.0703\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0657 - val_loss: 0.0413\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0630 - val_loss: 0.0370\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0617 - val_loss: 0.0339\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0600 - val_loss: 0.0331\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0575 - val_loss: 0.0300\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0530 - val_loss: 0.0270\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0425 - val_loss: 0.0133\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0265 - val_loss: 0.0043\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0176 - val_loss: 0.0047\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0142 - val_loss: 0.0082\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0123 - val_loss: 0.0083\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0108 - val_loss: 0.0079\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0094 - val_loss: 0.0116\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0082 - val_loss: 0.0107\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0074 - val_loss: 0.0089\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0073 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0081 - val_loss: 0.0030\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0090 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 544us/step - loss: 0.0085 - val_loss: 0.0025\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0068 - val_loss: 0.0038\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0081 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0069 - val_loss: 0.0030\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0085 - val_loss: 0.0023\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.6334 - val_loss: 0.3153\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 504us/step - loss: 0.1278 - val_loss: 0.0952\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 505us/step - loss: 0.0716 - val_loss: 0.0532\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: 0.0661 - val_loss: 0.0421\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0656 - val_loss: 0.0396\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0655 - val_loss: 0.0398\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0655 - val_loss: 0.0391\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: 0.0655 - val_loss: 0.0385\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0654 - val_loss: 0.0377\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0654 - val_loss: 0.0385\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0653 - val_loss: 0.0394\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0653 - val_loss: 0.0373\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0653 - val_loss: 0.0361\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 504us/step - loss: 0.0651 - val_loss: 0.0361\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 504us/step - loss: 0.0651 - val_loss: 0.0384\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: 0.0651 - val_loss: 0.0461\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0650 - val_loss: 0.0378\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 504us/step - loss: 0.0649 - val_loss: 0.0376\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: 0.0649 - val_loss: 0.0392\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: 0.0650 - val_loss: 0.0393\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0647 - val_loss: 0.0298\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0645 - val_loss: 0.0401\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0643 - val_loss: 0.0294\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 504us/step - loss: 0.0642 - val_loss: 0.0287\n",
      "\n",
      "GENERATION 4\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.0450 - val_loss: 0.0109\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 318us/step - loss: 0.0095 - val_loss: 0.0095\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 0.0041 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 320us/step - loss: 0.0029 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0022 - val_loss: 0.0027\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0012 - val_loss: 9.4103e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 0.0010 - val_loss: 9.4799e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 9.2424e-04 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 8.8472e-04 - val_loss: 8.8432e-04\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 318us/step - loss: 8.5736e-04 - val_loss: 8.5410e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 8.3776e-04 - val_loss: 9.0632e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 8.2625e-04 - val_loss: 8.8706e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 318us/step - loss: 8.1341e-04 - val_loss: 7.8776e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 7.9743e-04 - val_loss: 7.7932e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 315us/step - loss: 7.8706e-04 - val_loss: 8.6503e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 319us/step - loss: 7.6431e-04 - val_loss: 7.4747e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 7.6595e-04 - val_loss: 8.0700e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 7.6860e-04 - val_loss: 7.2241e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 320us/step - loss: 7.5410e-04 - val_loss: 7.0224e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 317us/step - loss: 7.3271e-04 - val_loss: 7.9895e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 316us/step - loss: 7.0538e-04 - val_loss: 6.9918e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 318us/step - loss: 6.8599e-04 - val_loss: 6.6911e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1ms/step - loss: 0.0419 - val_loss: 0.0107\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 0.0058 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 8.6962e-04 - val_loss: 5.6433e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 6.8614e-04 - val_loss: 8.5050e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 6.4024e-04 - val_loss: 5.3088e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 5.7189e-04 - val_loss: 5.2567e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.3426e-04 - val_loss: 5.1373e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 5.2467e-04 - val_loss: 4.8271e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 5.1235e-04 - val_loss: 4.8524e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.9894e-04 - val_loss: 4.6146e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.8454e-04 - val_loss: 4.5716e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.7124e-04 - val_loss: 4.7156e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.6068e-04 - val_loss: 4.4713e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.5166e-04 - val_loss: 4.1652e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.3994e-04 - val_loss: 4.0262e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.1842e-04 - val_loss: 3.8672e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.0501e-04 - val_loss: 3.8288e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 3.9327e-04 - val_loss: 3.6785e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 3.8541e-04 - val_loss: 3.6831e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.0230e-04 - val_loss: 3.5822e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 3.9293e-04 - val_loss: 4.2072e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 3.8444e-04 - val_loss: 3.9924e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 3.7513e-04 - val_loss: 3.6039e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 4s 1ms/step - loss: 0.0385 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 8.7136e-04 - val_loss: 7.0950e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 6.8635e-04 - val_loss: 8.9410e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 6.1471e-04 - val_loss: 5.2192e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 5.7828e-04 - val_loss: 6.3091e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.6312e-04 - val_loss: 5.1888e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 5.4991e-04 - val_loss: 5.5348e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 5.3493e-04 - val_loss: 4.9115e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 5.2814e-04 - val_loss: 5.1311e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 5.1764e-04 - val_loss: 5.0454e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 5.1027e-04 - val_loss: 4.7291e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 5.0160e-04 - val_loss: 4.6869e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 4.9168e-04 - val_loss: 4.8402e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.8497e-04 - val_loss: 4.6445e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 4.7752e-04 - val_loss: 4.4629e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 4.6454e-04 - val_loss: 4.4352e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.5405e-04 - val_loss: 4.3974e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.4523e-04 - val_loss: 4.2436e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.3759e-04 - val_loss: 4.1414e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 4.3238e-04 - val_loss: 4.0651e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.2216e-04 - val_loss: 4.0220e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 4.1934e-04 - val_loss: 3.9810e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.3423 - val_loss: 0.0759\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0306 - val_loss: 0.0346\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0135 - val_loss: 0.0052\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0101 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0065 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0059 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0056 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0052 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0051 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0048 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0048 - val_loss: 0.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0046 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0047 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0044 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0039 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0039 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.3766 - val_loss: 0.0185\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0658 - val_loss: 0.0828\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0589 - val_loss: 0.0194\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0499 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0303 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0076 - val_loss: 0.0052\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0067 - val_loss: 0.0065\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0038 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0032 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0024 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0021 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.2061 - val_loss: 0.0460\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0685 - val_loss: 0.0494\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0514 - val_loss: 0.0037\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0272 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0074 - val_loss: 0.0089\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0054 - val_loss: 0.0034\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0038 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0030 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0024 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0023 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 2ms/step - loss: 1.8055 - val_loss: 0.0837\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.1236 - val_loss: 0.0982\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0819 - val_loss: 0.0846\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0689 - val_loss: 0.0353\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0667 - val_loss: 0.0252\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0661 - val_loss: 0.0351\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0643 - val_loss: 0.0420\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0630 - val_loss: 0.0392\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0607 - val_loss: 0.0333\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0567 - val_loss: 0.0256\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0495 - val_loss: 0.0187\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0418 - val_loss: 0.0177\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0309 - val_loss: 0.0059\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0192 - val_loss: 0.0040\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0115 - val_loss: 0.0086\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0099 - val_loss: 0.0039\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0088 - val_loss: 0.0033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0079 - val_loss: 0.0041\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0067 - val_loss: 0.0036\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0050 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0045 - val_loss: 0.0030\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0041 - val_loss: 0.0036\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 2ms/step - loss: 0.3065 - val_loss: 0.0650\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0545 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0230 - val_loss: 0.0139\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0067 - val_loss: 0.0049\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0031 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0028 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0027 - val_loss: 0.0025\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 506us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 2ms/step - loss: 0.0665 - val_loss: 0.0069\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0081 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0043 - val_loss: 0.0069\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0034 - val_loss: 9.7419e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0028 - val_loss: 0.0033\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 507us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 505us/step - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0016 - val_loss: 9.6880e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0015 - val_loss: 9.9301e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "\n",
      "GENERATION 5\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 2ms/step - loss: 0.0438 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0048 - val_loss: 0.0037\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0015 - val_loss: 9.0390e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0010 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 9.7857e-04 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 9.6241e-04 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 9.2491e-04 - val_loss: 8.6551e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 8.8972e-04 - val_loss: 8.5981e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 8.7565e-04 - val_loss: 8.5868e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 8.5742e-04 - val_loss: 8.5282e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 8.4561e-04 - val_loss: 8.7524e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 8.4836e-04 - val_loss: 7.7203e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 8.3024e-04 - val_loss: 8.0621e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 8.3082e-04 - val_loss: 7.7042e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 8.1909e-04 - val_loss: 7.9091e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 7.9186e-04 - val_loss: 8.4311e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 7.6343e-04 - val_loss: 6.9714e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 7.3047e-04 - val_loss: 6.8376e-04\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 528us/step - loss: 7.1242e-04 - val_loss: 6.6775e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 6.9718e-04 - val_loss: 6.5004e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 6.8563e-04 - val_loss: 6.3805e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 6.6815e-04 - val_loss: 6.2523e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.0536 - val_loss: 0.0074\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0068 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0029 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0010 - val_loss: 8.8251e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 7.7817e-04 - val_loss: 9.9051e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 6.7265e-04 - val_loss: 5.9357e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 6.3986e-04 - val_loss: 6.4681e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 6.1792e-04 - val_loss: 5.7905e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 6.0760e-04 - val_loss: 5.7054e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 6.0495e-04 - val_loss: 6.0926e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 6.0095e-04 - val_loss: 5.5502e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 5.9266e-04 - val_loss: 5.5662e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 5.8937e-04 - val_loss: 6.0439e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 5.8321e-04 - val_loss: 5.4087e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 5.7544e-04 - val_loss: 5.4483e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 5.6996e-04 - val_loss: 5.5879e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 5.6096e-04 - val_loss: 5.2819e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 5.5956e-04 - val_loss: 5.3965e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.5153e-04 - val_loss: 5.3102e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.4613e-04 - val_loss: 5.1452e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.4165e-04 - val_loss: 5.1110e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 5.3521e-04 - val_loss: 5.0653e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 5.2945e-04 - val_loss: 5.0409e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 7.3162 - val_loss: 0.0350\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0534 - val_loss: 0.0114\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0265 - val_loss: 0.0040\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0093 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0027 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0024 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0021 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0020 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: nan - val_loss: nan\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: nan - val_loss: nan\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.6464 - val_loss: 0.4169\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.1694 - val_loss: 0.1222\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0745 - val_loss: 0.0398\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 0.0671 - val_loss: 0.0205\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0701 - val_loss: 0.0188\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 0.0694 - val_loss: 0.0233\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0673 - val_loss: 0.0300\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0662 - val_loss: 0.0362\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0658 - val_loss: 0.0400\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0659 - val_loss: 0.0416\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0659 - val_loss: 0.0415\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0659 - val_loss: 0.0405\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0658 - val_loss: 0.0398\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0658 - val_loss: 0.0392\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0658 - val_loss: 0.0389\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0658 - val_loss: 0.0387\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0658 - val_loss: 0.0388\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0658 - val_loss: 0.0390\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0658 - val_loss: 0.0391\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0658 - val_loss: 0.0392\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0658 - val_loss: 0.0392\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0658 - val_loss: 0.0392\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0658 - val_loss: 0.0394\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0658 - val_loss: 0.0393\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 5s 1ms/step - loss: 0.0662 - val_loss: 0.0321\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0608 - val_loss: 0.0328\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0480 - val_loss: 0.0101\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0271 - val_loss: 0.0046\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0135 - val_loss: 0.0278\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 0.0104 - val_loss: 0.0033\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0061 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 0.0035 - val_loss: 0.0079\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0029 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0022 - val_loss: 0.0031\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0018 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.0885 - val_loss: 0.0146\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0713 - val_loss: 0.0208\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0631 - val_loss: 0.0414\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 0.0614 - val_loss: 0.0424\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0571 - val_loss: 0.0328\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 0.0510 - val_loss: 0.0481\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0477 - val_loss: 0.0531\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0455 - val_loss: 0.0566\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0438 - val_loss: 0.0590\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0429 - val_loss: 0.0604\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0423 - val_loss: 0.0621\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0416 - val_loss: 0.0633\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0411 - val_loss: 0.0647\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0407 - val_loss: 0.0664\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0405 - val_loss: 0.0667\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0403 - val_loss: 0.0673\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0403 - val_loss: 0.0689\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0402 - val_loss: 0.0674\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0403 - val_loss: 0.0689\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0403 - val_loss: 0.0683\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0403 - val_loss: 0.0699\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 0.0403 - val_loss: 0.0702\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0402 - val_loss: 0.0684\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0402 - val_loss: 0.0684\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.1238 - val_loss: 0.0242\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0721 - val_loss: 0.0122\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0704 - val_loss: 0.0271\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0643 - val_loss: 0.0423\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0629 - val_loss: 0.0441\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0610 - val_loss: 0.0373\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0572 - val_loss: 0.0295\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0536 - val_loss: 0.0239\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0501 - val_loss: 0.0216\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0470 - val_loss: 0.0196\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0452 - val_loss: 0.0165\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0435 - val_loss: 0.0143\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0408 - val_loss: 0.0120\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0324 - val_loss: 0.0076\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0237 - val_loss: 0.0046\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0209 - val_loss: 0.0075\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0193 - val_loss: 0.0115\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0188 - val_loss: 0.0145\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0181 - val_loss: 0.0175\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0178 - val_loss: 0.0199\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0177 - val_loss: 0.0220\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0176 - val_loss: 0.0232\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0176 - val_loss: 0.0238\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0176 - val_loss: 0.0243\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.0568 - val_loss: 0.0148\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0105 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0075 - val_loss: 0.0062\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0031 - val_loss: 0.0041\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0012 - val_loss: 9.4999e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0011 - val_loss: 9.6496e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0010 - val_loss: 9.5361e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.7873e-04 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.6971e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.4368e-04 - val_loss: 0.0010\n",
      "\n",
      "GENERATION 6\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.1576 - val_loss: 0.0771\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 0.0224 - val_loss: 0.0129\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 0.0077 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 0.0036 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0020 - val_loss: 6.9979e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 9.9659e-04 - val_loss: 8.2576e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 8.4461e-04 - val_loss: 7.0194e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 7.5857e-04 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 7.2938e-04 - val_loss: 6.4552e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 7.0026e-04 - val_loss: 8.1464e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 6.7707e-04 - val_loss: 7.0656e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 6.6520e-04 - val_loss: 7.1299e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 6.5510e-04 - val_loss: 7.0645e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 6.4649e-04 - val_loss: 6.3320e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 6.3595e-04 - val_loss: 7.0750e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 6.2732e-04 - val_loss: 6.8173e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 6.1845e-04 - val_loss: 6.7714e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 6.0881e-04 - val_loss: 6.4899e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 5.9937e-04 - val_loss: 6.1962e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.9227e-04 - val_loss: 6.3232e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.8871e-04 - val_loss: 6.7715e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 5.7712e-04 - val_loss: 6.1685e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 5.6728e-04 - val_loss: 5.7103e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.0495 - val_loss: 0.0076\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0064 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 0.0010 - val_loss: 5.3588e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 8.0875e-04 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 6.9883e-04 - val_loss: 5.2347e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 5.9781e-04 - val_loss: 5.1745e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.8961e-04 - val_loss: 5.5106e-04\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.5640e-04 - val_loss: 6.4611e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.4485e-04 - val_loss: 5.1792e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 5.3052e-04 - val_loss: 4.8983e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 5.1540e-04 - val_loss: 4.8090e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 4.9222e-04 - val_loss: 4.5494e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 4.6882e-04 - val_loss: 4.4004e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.4373e-04 - val_loss: 4.1919e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.2302e-04 - val_loss: 3.9419e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.0252e-04 - val_loss: 3.7585e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 3.9138e-04 - val_loss: 3.8890e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 3.8341e-04 - val_loss: 3.5662e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 3.6973e-04 - val_loss: 3.5020e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 3.6125e-04 - val_loss: 3.4463e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 3.6009e-04 - val_loss: 3.6513e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 3.6745e-04 - val_loss: 4.2177e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 3.8309e-04 - val_loss: 3.9442e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 6s 1ms/step - loss: 0.0561 - val_loss: 0.0119\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0064 - val_loss: 0.0075\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 9.6908e-04 - val_loss: 6.6122e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 7.8235e-04 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 6.7232e-04 - val_loss: 5.5263e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 6.4234e-04 - val_loss: 6.5987e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 6.1921e-04 - val_loss: 6.5141e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 5.9826e-04 - val_loss: 5.5112e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 5.7925e-04 - val_loss: 5.7206e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 5.5808e-04 - val_loss: 5.7425e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 5.3903e-04 - val_loss: 5.4474e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 5.1279e-04 - val_loss: 4.8573e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 4.8429e-04 - val_loss: 4.8716e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 4.6602e-04 - val_loss: 4.5614e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 4.5735e-04 - val_loss: 4.1273e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 4.4473e-04 - val_loss: 4.0450e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.2115e-04 - val_loss: 3.9207e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 4.1038e-04 - val_loss: 3.8601e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 3.9940e-04 - val_loss: 3.8344e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 3.9221e-04 - val_loss: 3.7051e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 3.8492e-04 - val_loss: 3.8377e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 3.8165e-04 - val_loss: 3.5803e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 8s 2ms/step - loss: 0.0923 - val_loss: 0.0162\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0158 - val_loss: 0.0154\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0077 - val_loss: 0.0042\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0036 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0024 - val_loss: 0.0031\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 542us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0013 - val_loss: 9.8304e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0013 - val_loss: 9.3078e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0012 - val_loss: 9.8532e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 8s 2ms/step - loss: 0.0842 - val_loss: 0.0252\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0125 - val_loss: 0.0104\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0048 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0015 - val_loss: 9.9654e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0015 - val_loss: 9.8428e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0014 - val_loss: 9.7454e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0014 - val_loss: 9.3951e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0014 - val_loss: 9.6704e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0013 - val_loss: 9.1235e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0013 - val_loss: 9.1348e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0013 - val_loss: 8.8592e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0013 - val_loss: 8.7580e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0013 - val_loss: 8.9962e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0013 - val_loss: 8.6376e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0013 - val_loss: 8.7163e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 8s 2ms/step - loss: 0.0468 - val_loss: 0.0233\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0083 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0042 - val_loss: 0.0054\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0030 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0021 - val_loss: 9.6355e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0015 - val_loss: 9.0270e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0014 - val_loss: 8.8841e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0014 - val_loss: 8.9365e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0014 - val_loss: 9.6770e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0013 - val_loss: 8.7321e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0013 - val_loss: 8.2730e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0013 - val_loss: 7.9628e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0013 - val_loss: 8.2488e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0012 - val_loss: 8.5193e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0012 - val_loss: 7.5549e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0011 - val_loss: 8.7692e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0011 - val_loss: 7.1704e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0011 - val_loss: 7.5820e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0010 - val_loss: 9.1229e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 8s 2ms/step - loss: 0.1179 - val_loss: 0.0093\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0152 - val_loss: 0.0158\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0067 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 520us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0013 - val_loss: 9.7164e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0010 - val_loss: 8.8051e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 9.9554e-04 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 9.9339e-04 - val_loss: 0.0018\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 8s 2ms/step - loss: 1.4132 - val_loss: 0.0111\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0409 - val_loss: 0.0728\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0342 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0071 - val_loss: 0.0223\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0068 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0034 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0033 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0019 - val_loss: 0.0017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 509us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0021 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 8s 2ms/step - loss: 0.1935 - val_loss: 0.2436\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0533 - val_loss: 0.0093\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0115 - val_loss: 0.0128\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0086 - val_loss: 0.0063\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0049 - val_loss: 0.0084\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 510us/step - loss: 0.0018 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0018 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 518us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 516us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 517us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 513us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0017 - val_loss: 8.4246e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 515us/step - loss: 0.0012 - val_loss: 9.6547e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 511us/step - loss: 0.0014 - val_loss: 9.4658e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 514us/step - loss: 0.0017 - val_loss: 8.2440e-04\n",
      "\n",
      "GENERATION 7\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 8s 2ms/step - loss: 0.0620 - val_loss: 0.0286\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0118 - val_loss: 0.0048\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0054 - val_loss: 9.8784e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0033 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0028 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0024 - val_loss: 9.2745e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0021 - val_loss: 9.4646e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0020 - val_loss: 8.9914e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0019 - val_loss: 8.8603e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0014 - val_loss: 0.0027\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0661 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0056 - val_loss: 5.8857e-04\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0023 - val_loss: 5.3209e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0015 - val_loss: 5.0780e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 7.8494e-04 - val_loss: 4.9908e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 6.7679e-04 - val_loss: 9.5316e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 6.1009e-04 - val_loss: 4.8410e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.6119e-04 - val_loss: 5.4456e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.3736e-04 - val_loss: 5.9067e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 5.2592e-04 - val_loss: 5.2408e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.1333e-04 - val_loss: 5.2851e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 5.0134e-04 - val_loss: 5.1364e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.8988e-04 - val_loss: 4.6031e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.7650e-04 - val_loss: 4.4756e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 4.6292e-04 - val_loss: 4.3431e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 4.5035e-04 - val_loss: 4.3020e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 4.3948e-04 - val_loss: 4.0520e-04\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.3277e-04 - val_loss: 3.9246e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.0838e-04 - val_loss: 3.9017e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 3.9611e-04 - val_loss: 3.7839e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 3.8263e-04 - val_loss: 3.6403e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 3.7196e-04 - val_loss: 4.1184e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 3.6928e-04 - val_loss: 3.4364e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 3.4926e-04 - val_loss: 3.3573e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 7s 2ms/step - loss: 0.0331 - val_loss: 0.0157\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0063 - val_loss: 0.0049\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0029 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0015 - val_loss: 8.4683e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0013 - val_loss: 6.5066e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0012 - val_loss: 5.7784e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0011 - val_loss: 5.2178e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0010 - val_loss: 5.0841e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0011 - val_loss: 5.0830e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0010 - val_loss: 4.9429e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 9.7418e-04 - val_loss: 4.8664e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 9.0909e-04 - val_loss: 4.9106e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 9.0586e-04 - val_loss: 5.7376e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 8.9581e-04 - val_loss: 4.8946e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 8.9700e-04 - val_loss: 5.2650e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 8.5629e-04 - val_loss: 5.0129e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 8.2469e-04 - val_loss: 4.6011e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 7.8706e-04 - val_loss: 4.6320e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 7.5804e-04 - val_loss: 4.4010e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 7.5173e-04 - val_loss: 4.4354e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 7.4406e-04 - val_loss: 4.6366e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 7.2386e-04 - val_loss: 4.4568e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 6.8513e-04 - val_loss: 4.3833e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 8s 2ms/step - loss: 0.0830 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0022 - val_loss: 7.4329e-04\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0028 - val_loss: 7.2647e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0015 - val_loss: 7.1737e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0026 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0017 - val_loss: 6.4948e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0013 - val_loss: 8.9033e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0016 - val_loss: 6.2503e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0012 - val_loss: 8.8715e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0019 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0014 - val_loss: 5.3544e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 9.4139e-04 - val_loss: 8.0849e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0012 - val_loss: 7.6519e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 9.5616e-04 - val_loss: 7.0366e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0021 - val_loss: 0.0040\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0024 - val_loss: 7.1661e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 9.8619e-04 - val_loss: 7.1860e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0011 - val_loss: 8.4240e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 0.1463 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0034 - val_loss: 0.0214\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0097 - val_loss: 9.0840e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0063 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0026 - val_loss: 7.9080e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0021 - val_loss: 9.4625e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0036 - val_loss: 0.0067\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0059 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0025 - val_loss: 8.3149e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0051 - val_loss: 0.0043\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0026 - val_loss: 0.0036\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0038 - val_loss: 0.0042\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0036 - val_loss: 0.0024\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0018 - val_loss: 7.6059e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0053 - val_loss: 0.0021\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 0.0818 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0031 - val_loss: 0.0079\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0116 - val_loss: 0.0188\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0097 - val_loss: 0.0121\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0113 - val_loss: 0.0114\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0065 - val_loss: 0.0130\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0110 - val_loss: 0.0164\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0085 - val_loss: 0.0142\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0071 - val_loss: 0.0091\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0066 - val_loss: 0.0103\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0065 - val_loss: 0.0163\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0110 - val_loss: 0.0099\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0066 - val_loss: 0.0131\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0068 - val_loss: 0.0120\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0064 - val_loss: 0.0110\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0059 - val_loss: 0.0187\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0080 - val_loss: 0.0141\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0065 - val_loss: 0.0124\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0066 - val_loss: 0.0103\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0060 - val_loss: 0.0099\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0063 - val_loss: 0.0081\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0044 - val_loss: 0.0105\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 10s 2ms/step - loss: 0.0688 - val_loss: 0.0257\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0645 - val_loss: 0.0457\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0553 - val_loss: 0.0232\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0520 - val_loss: 0.0575\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0660 - val_loss: 0.0294\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0660 - val_loss: 0.0462\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0657 - val_loss: 0.0336\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0647 - val_loss: 0.0388\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0581 - val_loss: 0.0158\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0391 - val_loss: 0.0060\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0299 - val_loss: 0.0441\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0395 - val_loss: 0.0305\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0875 - val_loss: 0.0455\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0710 - val_loss: 0.0568\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0588 - val_loss: 0.0132\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0627 - val_loss: 0.0209\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0595 - val_loss: 0.0382\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0603 - val_loss: 0.0314\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0597 - val_loss: 0.0258\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0597 - val_loss: 0.0284\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0598 - val_loss: 0.0320\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0597 - val_loss: 0.0286\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0595 - val_loss: 0.0289\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0589 - val_loss: 0.0301\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 10s 2ms/step - loss: 0.0871 - val_loss: 0.0230\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0127 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0075 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0023 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0019 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0015 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0012 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0011 - val_loss: 8.7001e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0011 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 10s 2ms/step - loss: 0.1596 - val_loss: 0.0202\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0324 - val_loss: 0.0051\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0120 - val_loss: 0.0082\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0057 - val_loss: 0.0051\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0030 - val_loss: 0.0037\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0015 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "\n",
      "GENERATION 8\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 8s 2ms/step - loss: 0.0675 - val_loss: 0.0043\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0071 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 9.4952e-04 - val_loss: 5.5854e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 7.3744e-04 - val_loss: 7.7072e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 6.4714e-04 - val_loss: 5.3341e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.9978e-04 - val_loss: 6.7699e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.7099e-04 - val_loss: 5.2453e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.5095e-04 - val_loss: 6.0065e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.3980e-04 - val_loss: 5.3049e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 5.2778e-04 - val_loss: 5.2908e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.1875e-04 - val_loss: 5.1338e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 5.0760e-04 - val_loss: 4.9636e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.9245e-04 - val_loss: 4.6710e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.7869e-04 - val_loss: 4.5061e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.6728e-04 - val_loss: 4.4439e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.5660e-04 - val_loss: 4.4341e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.4218e-04 - val_loss: 4.3707e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.2902e-04 - val_loss: 4.3483e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.1540e-04 - val_loss: 3.9393e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.0536e-04 - val_loss: 4.3142e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.1391e-04 - val_loss: 4.2596e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 3.8743e-04 - val_loss: 3.7004e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 8s 2ms/step - loss: 0.0309 - val_loss: 0.0165\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0050 - val_loss: 0.0051\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 8.2915e-04 - val_loss: 5.6752e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 6.8311e-04 - val_loss: 6.3067e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 6.3421e-04 - val_loss: 6.8057e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 6.0697e-04 - val_loss: 5.4386e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 5.8603e-04 - val_loss: 6.0998e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.5771e-04 - val_loss: 6.0014e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.4537e-04 - val_loss: 6.4881e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 5.2256e-04 - val_loss: 5.7852e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.8842e-04 - val_loss: 5.0605e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.5819e-04 - val_loss: 4.4266e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.2368e-04 - val_loss: 4.0242e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.0575e-04 - val_loss: 4.0229e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 3.9250e-04 - val_loss: 3.8170e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 3.8367e-04 - val_loss: 3.6712e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 3.7961e-04 - val_loss: 3.7943e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 3.7364e-04 - val_loss: 4.0416e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 3.6930e-04 - val_loss: 3.5582e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 3.6712e-04 - val_loss: 3.4859e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 3.5507e-04 - val_loss: 3.3681e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 3.4752e-04 - val_loss: 3.3141e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 0.0457 - val_loss: 8.7205e-04\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0011 - val_loss: 8.5881e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 9.3558e-04 - val_loss: 9.1998e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0011 - val_loss: 0.0043\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0029 - val_loss: 0.0039\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0023 - val_loss: 0.0047\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0017 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0018 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0021 - val_loss: 0.0057\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0033 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0014 - val_loss: 0.0029\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0011 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0020 - val_loss: 0.0039\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0020 - val_loss: 0.0028\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0017 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0018 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0016 - val_loss: 0.0029\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 0.0533 - val_loss: 0.0010\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0013 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0031 - val_loss: 0.0026\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0014 - val_loss: 0.0021\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0011 - val_loss: 8.6937e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 7.2906e-04 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0015 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 8.9688e-04 - val_loss: 9.0429e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 7.9210e-04 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 7.5894e-04 - val_loss: 8.8458e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 7.5857e-04 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0010 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 9.1667e-04 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0044 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 7.0850e-04 - val_loss: 4.7082e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 4.8846e-04 - val_loss: 4.4679e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 4.6784e-04 - val_loss: 5.0342e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 4.7864e-04 - val_loss: 4.9702e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 0.0550 - val_loss: 0.0076\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0029 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0019 - val_loss: 8.6407e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 219us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 217us/step - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0016 - val_loss: 0.0028\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 214us/step - loss: 0.0016 - val_loss: 8.6933e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 213us/step - loss: 7.9119e-04 - val_loss: 6.0098e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 213us/step - loss: 0.0010 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0011 - val_loss: 6.2211e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 9.5685e-04 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 214us/step - loss: 0.0017 - val_loss: 9.0897e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 212us/step - loss: 9.5557e-04 - val_loss: 7.1909e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 8.2573e-04 - val_loss: 6.3977e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 6.7159e-04 - val_loss: 6.0598e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 213us/step - loss: 9.0499e-04 - val_loss: 6.6901e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 8.6332e-04 - val_loss: 7.5359e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 8.7179e-04 - val_loss: 5.3201e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 5.7687e-04 - val_loss: 6.7738e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 6.9126e-04 - val_loss: 4.6447e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 8.5732e-04 - val_loss: 8.4514e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 8.6187e-04 - val_loss: 7.9877e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 212us/step - loss: 8.8203e-04 - val_loss: 7.1708e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 0.0606 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0370 - val_loss: 6.4188e-04\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0011 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 213us/step - loss: 0.0311 - val_loss: 0.0287\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0096 - val_loss: 9.8504e-04\n",
      "Epoch 6/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0016 - val_loss: 0.0068\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 214us/step - loss: 0.0209 - val_loss: 0.0361\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 214us/step - loss: 0.0216 - val_loss: 0.0114\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0096 - val_loss: 0.0107\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 219us/step - loss: 0.0095 - val_loss: 0.0127\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 214us/step - loss: 0.0130 - val_loss: 0.0175\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 212us/step - loss: 0.0140 - val_loss: 0.0151\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0127 - val_loss: 0.0118\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 214us/step - loss: 0.0114 - val_loss: 0.0166\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0150 - val_loss: 0.0167\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 214us/step - loss: 0.0128 - val_loss: 0.0140\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0120 - val_loss: 0.0131\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0107 - val_loss: 0.0131\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 213us/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 213us/step - loss: 0.0109 - val_loss: 0.0139\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0119 - val_loss: 0.0144\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0111 - val_loss: 0.0153\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 217us/step - loss: 0.0134 - val_loss: 0.0164\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 214us/step - loss: 0.0133 - val_loss: 0.0158\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 0.9353 - val_loss: 0.0114\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 220us/step - loss: 0.0531 - val_loss: 0.0175\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 220us/step - loss: 0.0613 - val_loss: 0.0548\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 217us/step - loss: 0.0482 - val_loss: 0.1209\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0510 - val_loss: 0.0794\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0473 - val_loss: 0.0580\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0401 - val_loss: 0.0511\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0361 - val_loss: 0.0400\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0330 - val_loss: 0.0320\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 222us/step - loss: 0.0267 - val_loss: 0.0404\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0255 - val_loss: 0.0390\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 219us/step - loss: 0.0237 - val_loss: 0.0322\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 219us/step - loss: 0.0200 - val_loss: 0.0273\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 222us/step - loss: 0.0192 - val_loss: 0.0316\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 0.0181 - val_loss: 0.0181\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0178 - val_loss: 0.0151\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 0.0160 - val_loss: 0.0189\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0143 - val_loss: 0.0233\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 0.0152 - val_loss: 0.0233\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 0.0122 - val_loss: 0.0114\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 0.0138 - val_loss: 0.0152\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0116 - val_loss: 0.0152\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0122 - val_loss: 0.0094\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 0.0106 - val_loss: 0.0063\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 1.7043 - val_loss: 0.0472\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 214us/step - loss: 0.0831 - val_loss: 0.0118\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 214us/step - loss: 0.1133 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.1356 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0951 - val_loss: 0.0384\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 212us/step - loss: 0.0922 - val_loss: 0.0591\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0869 - val_loss: 0.0538\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0667 - val_loss: 0.0517\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 217us/step - loss: 0.0474 - val_loss: 0.0611\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0422 - val_loss: 0.0657\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0393 - val_loss: 0.0613\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0379 - val_loss: 0.0473\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0344 - val_loss: 0.0522\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 213us/step - loss: 0.0242 - val_loss: 0.0533\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 213us/step - loss: 0.0329 - val_loss: 0.0303\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0265 - val_loss: 0.0490\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 217us/step - loss: 0.0216 - val_loss: 0.0689\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0203 - val_loss: 0.0356\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0249 - val_loss: 0.0270\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0189 - val_loss: 0.0215\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0193 - val_loss: 0.0173\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 213us/step - loss: 0.0127 - val_loss: 0.0250\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0156 - val_loss: 0.0207\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0153 - val_loss: 0.0234\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 10s 2ms/step - loss: 0.1172 - val_loss: 0.0074\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 217us/step - loss: 0.0659 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 217us/step - loss: 0.0217 - val_loss: 0.0487\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 219us/step - loss: 0.0459 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 217us/step - loss: 0.0141 - val_loss: 0.0735\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0200 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 219us/step - loss: 0.0279 - val_loss: 0.0068\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0064 - val_loss: 0.0515\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0236 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 219us/step - loss: 0.0190 - val_loss: 0.0027\n",
      "Epoch 11/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0132 - val_loss: 0.0155\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 219us/step - loss: 0.0109 - val_loss: 0.0330\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0129 - val_loss: 0.0114\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 217us/step - loss: 0.0139 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 221us/step - loss: 0.0123 - val_loss: 0.0036\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 219us/step - loss: 0.0093 - val_loss: 0.0075\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0084 - val_loss: 0.0096\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 216us/step - loss: 0.0112 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0083 - val_loss: 0.0067\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 219us/step - loss: 0.0081 - val_loss: 0.0048\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 219us/step - loss: 0.0084 - val_loss: 0.0027\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0072 - val_loss: 0.0154\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 215us/step - loss: 0.0080 - val_loss: 0.0025\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 218us/step - loss: 0.0068 - val_loss: 0.0032\n",
      "\n",
      "GENERATION 9\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 9s 2ms/step - loss: 0.0859 - val_loss: 8.9737e-04\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0066 - val_loss: 6.3912e-04\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0014 - val_loss: 0.0019\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 9.1271e-04 - val_loss: 8.0212e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 6.7329e-04 - val_loss: 7.6105e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.6436e-04 - val_loss: 4.8431e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 5.3658e-04 - val_loss: 4.6611e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.1762e-04 - val_loss: 5.3794e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.9068e-04 - val_loss: 4.5636e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 4.7462e-04 - val_loss: 4.3866e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.6527e-04 - val_loss: 4.7468e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.5394e-04 - val_loss: 4.6241e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.3768e-04 - val_loss: 4.3381e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.2374e-04 - val_loss: 4.0840e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.1204e-04 - val_loss: 3.8978e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 3.9902e-04 - val_loss: 3.7936e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 3.8952e-04 - val_loss: 3.7398e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 3.8058e-04 - val_loss: 3.7955e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 3.7793e-04 - val_loss: 3.6334e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 3.6793e-04 - val_loss: 3.6444e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 3.6059e-04 - val_loss: 3.6034e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 3.5895e-04 - val_loss: 3.5823e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 3.6727e-04 - val_loss: 3.9274e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 10s 2ms/step - loss: 0.1386 - val_loss: 0.0187\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0101 - val_loss: 0.0087\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0038 - val_loss: 0.0043\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 7.3826e-04 - val_loss: 5.7967e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 6.7855e-04 - val_loss: 5.9546e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 6.5865e-04 - val_loss: 6.1438e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 6.2978e-04 - val_loss: 6.0320e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 6.1254e-04 - val_loss: 5.4499e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.9843e-04 - val_loss: 5.3191e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 5.8350e-04 - val_loss: 5.1801e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 5.6922e-04 - val_loss: 5.0569e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.4951e-04 - val_loss: 4.9963e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 5.3259e-04 - val_loss: 4.8832e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 5.1871e-04 - val_loss: 4.9805e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.0510e-04 - val_loss: 4.8370e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.9283e-04 - val_loss: 4.4487e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.7469e-04 - val_loss: 4.4595e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 4.6172e-04 - val_loss: 4.2383e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.5089e-04 - val_loss: 4.3776e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.3803e-04 - val_loss: 4.0288e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 4.2828e-04 - val_loss: 3.9577e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 4.1561e-04 - val_loss: 3.9584e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 10s 2ms/step - loss: 0.0498 - val_loss: 0.0141\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0076 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0030 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0016 - val_loss: 9.0627e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 9.8036e-04 - val_loss: 6.1165e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 7.7411e-04 - val_loss: 6.2285e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 6.8395e-04 - val_loss: 5.9751e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 6.4991e-04 - val_loss: 6.1107e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 6.2584e-04 - val_loss: 5.7900e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 6.1275e-04 - val_loss: 5.8997e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 6.0384e-04 - val_loss: 5.7059e-04\n",
      "Epoch 12/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.9658e-04 - val_loss: 5.9091e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.9150e-04 - val_loss: 5.5678e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 5.8208e-04 - val_loss: 5.6263e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 5.7047e-04 - val_loss: 5.6137e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 265us/step - loss: 5.6236e-04 - val_loss: 5.4026e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.5125e-04 - val_loss: 5.4151e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.4360e-04 - val_loss: 5.7471e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 5.2874e-04 - val_loss: 5.1444e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.0882e-04 - val_loss: 4.9261e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.9199e-04 - val_loss: 4.8545e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 4.8184e-04 - val_loss: 4.7803e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 4.6699e-04 - val_loss: 4.7654e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.5729e-04 - val_loss: 4.6168e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 11s 3ms/step - loss: 0.0474 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0052 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0025 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0018 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0011 - val_loss: 9.0071e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0010 - val_loss: 8.5312e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 9.7828e-04 - val_loss: 8.7056e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 9.5419e-04 - val_loss: 9.5178e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 9.3384e-04 - val_loss: 9.4077e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 8.9886e-04 - val_loss: 8.7617e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 8.8487e-04 - val_loss: 9.1549e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 8.6895e-04 - val_loss: 8.5459e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 8.4108e-04 - val_loss: 7.8161e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 8.2294e-04 - val_loss: 7.7135e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 8.0602e-04 - val_loss: 7.4166e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 7.8628e-04 - val_loss: 7.3399e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 7.7323e-04 - val_loss: 7.1502e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 7.6679e-04 - val_loss: 7.4260e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 7.4730e-04 - val_loss: 7.5473e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 7.3730e-04 - val_loss: 6.9583e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 7.2083e-04 - val_loss: 6.6893e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 7.1405e-04 - val_loss: 6.5837e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 7.0297e-04 - val_loss: 6.4756e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 12s 3ms/step - loss: 0.0570 - val_loss: 0.0237\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0075 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0036 - val_loss: 0.0056\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0011 - val_loss: 8.7360e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0010 - val_loss: 9.5561e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 9.8869e-04 - val_loss: 9.6883e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 9.5828e-04 - val_loss: 9.5901e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 9.3953e-04 - val_loss: 9.3751e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 9.1783e-04 - val_loss: 8.8619e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 541us/step - loss: 9.0117e-04 - val_loss: 8.4276e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 8.8625e-04 - val_loss: 9.1573e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 8.7234e-04 - val_loss: 8.7118e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 8.5492e-04 - val_loss: 9.3966e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 8.5034e-04 - val_loss: 8.3196e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 8.2126e-04 - val_loss: 8.0875e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 8.0674e-04 - val_loss: 7.9038e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 7.7606e-04 - val_loss: 6.9481e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 7.5828e-04 - val_loss: 6.6699e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 7.4691e-04 - val_loss: 7.6989e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 7.3009e-04 - val_loss: 6.4707e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 7.0767e-04 - val_loss: 6.6128e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 11s 3ms/step - loss: 0.0903 - val_loss: 0.0277\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0184 - val_loss: 0.0061\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0120 - val_loss: 0.0035\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0094 - val_loss: 0.0029\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0077 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0063 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0044 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0038 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 13/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0019 - val_loss: 0.0014\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 539us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 537us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 538us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 12s 3ms/step - loss: 0.2165 - val_loss: 0.1653\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0885 - val_loss: 0.0685\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0495 - val_loss: 0.0319\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0370 - val_loss: 0.0175\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0310 - val_loss: 0.0116\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0281 - val_loss: 0.0089\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0258 - val_loss: 0.0073\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0230 - val_loss: 0.0062\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0214 - val_loss: 0.0055\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0195 - val_loss: 0.0048\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0180 - val_loss: 0.0042\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0163 - val_loss: 0.0038\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0149 - val_loss: 0.0034\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0135 - val_loss: 0.0030\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0122 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0113 - val_loss: 0.0026\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0107 - val_loss: 0.0023\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0093 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0086 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0077 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0076 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0067 - val_loss: 0.0016\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0065 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0061 - val_loss: 0.0015\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 12s 3ms/step - loss: 0.1586 - val_loss: 0.1405\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0756 - val_loss: 0.0643\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0534 - val_loss: 0.0382\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 566us/step - loss: 0.0470 - val_loss: 0.0277\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0442 - val_loss: 0.0235\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0422 - val_loss: 0.0209\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0404 - val_loss: 0.0196\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0385 - val_loss: 0.0180\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0363 - val_loss: 0.0169\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0347 - val_loss: 0.0156\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0329 - val_loss: 0.0142\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0309 - val_loss: 0.0131\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0288 - val_loss: 0.0124\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0273 - val_loss: 0.0112\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 564us/step - loss: 0.0253 - val_loss: 0.0102\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0235 - val_loss: 0.0091\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0217 - val_loss: 0.0083\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0198 - val_loss: 0.0074\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0179 - val_loss: 0.0064\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0162 - val_loss: 0.0053\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0146 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0131 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0119 - val_loss: 0.0034\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0105 - val_loss: 0.0029\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 12s 3ms/step - loss: 0.1853 - val_loss: 0.1806\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0981 - val_loss: 0.0950\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0666 - val_loss: 0.0576\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0554 - val_loss: 0.0407\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0507 - val_loss: 0.0327\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0481 - val_loss: 0.0284\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0460 - val_loss: 0.0258\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0443 - val_loss: 0.0239\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0427 - val_loss: 0.0225\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0413 - val_loss: 0.0214\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0397 - val_loss: 0.0203\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0379 - val_loss: 0.0189\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0366 - val_loss: 0.0177\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0344 - val_loss: 0.0166\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0332 - val_loss: 0.0153\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 563us/step - loss: 0.0313 - val_loss: 0.0143\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0294 - val_loss: 0.0135\n",
      "Epoch 18/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0278 - val_loss: 0.0122\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0264 - val_loss: 0.0113\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0245 - val_loss: 0.0102\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0229 - val_loss: 0.0094\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0212 - val_loss: 0.0084\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0194 - val_loss: 0.0074\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0178 - val_loss: 0.0066\n",
      "\n",
      "GENERATION 10\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 11s 3ms/step - loss: 0.0517 - val_loss: 0.0121\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0062 - val_loss: 0.0095\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0042 - val_loss: 9.3735e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0015 - val_loss: 5.1298e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0012 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 8.2073e-04 - val_loss: 5.0519e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 6.9914e-04 - val_loss: 4.7490e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 6.2470e-04 - val_loss: 5.9704e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.8000e-04 - val_loss: 5.6498e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.4634e-04 - val_loss: 5.2174e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.2252e-04 - val_loss: 4.5951e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.0392e-04 - val_loss: 4.5048e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.8548e-04 - val_loss: 4.2152e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.7244e-04 - val_loss: 4.2085e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 4.5779e-04 - val_loss: 4.2602e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.4315e-04 - val_loss: 4.2416e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.3499e-04 - val_loss: 4.2147e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.2524e-04 - val_loss: 4.0849e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.1788e-04 - val_loss: 4.0445e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.1149e-04 - val_loss: 3.9498e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.0639e-04 - val_loss: 3.9224e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.0273e-04 - val_loss: 3.9346e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.0370e-04 - val_loss: 3.8818e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 3.9585e-04 - val_loss: 4.0334e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 11s 3ms/step - loss: 0.0569 - val_loss: 0.0062\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0063 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 0.0027 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 9.6582e-04 - val_loss: 6.0408e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 7.3695e-04 - val_loss: 9.7567e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 6.1662e-04 - val_loss: 4.8449e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 5.6834e-04 - val_loss: 5.8368e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.2598e-04 - val_loss: 5.5642e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 5.0862e-04 - val_loss: 5.0061e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.9291e-04 - val_loss: 5.0568e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.7341e-04 - val_loss: 4.8619e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.5865e-04 - val_loss: 4.4557e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 4.3479e-04 - val_loss: 4.4254e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.2179e-04 - val_loss: 4.2933e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.0853e-04 - val_loss: 3.9520e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.0881e-04 - val_loss: 3.8278e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 3.8690e-04 - val_loss: 3.7490e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 3.7782e-04 - val_loss: 3.7246e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 3.7244e-04 - val_loss: 3.6340e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 3.5368e-04 - val_loss: 3.4291e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 3.4732e-04 - val_loss: 3.4136e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 3.4723e-04 - val_loss: 3.7261e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 3.4295e-04 - val_loss: 3.2904e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 12s 3ms/step - loss: 0.4057 - val_loss: 0.0342\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 500us/step - loss: 0.0282 - val_loss: 0.0047\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 504us/step - loss: 0.0266 - val_loss: 0.0156\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 503us/step - loss: 0.0140 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 498us/step - loss: 0.0051 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 508us/step - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 500us/step - loss: 0.0027 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 498us/step - loss: 0.0023 - val_loss: 9.8253e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 499us/step - loss: 0.0025 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 500us/step - loss: 0.0021 - val_loss: 9.8895e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 512us/step - loss: 0.0021 - val_loss: 9.0386e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 499us/step - loss: 0.0020 - val_loss: 9.0209e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 494us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0019 - val_loss: 9.5200e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 494us/step - loss: 0.0019 - val_loss: 9.0969e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0019 - val_loss: 9.8299e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0019 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 500us/step - loss: 0.0018 - val_loss: 9.6165e-04\n",
      "Epoch 19/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 498us/step - loss: 0.0018 - val_loss: 9.1780e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 504us/step - loss: 0.0017 - val_loss: 8.0603e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 504us/step - loss: 0.0017 - val_loss: 8.0726e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 498us/step - loss: 0.0016 - val_loss: 8.1998e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0016 - val_loss: 8.8564e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0016 - val_loss: 9.1606e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 13s 3ms/step - loss: 0.2973 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 498us/step - loss: 0.0274 - val_loss: 0.0203\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0282 - val_loss: 0.0022\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 503us/step - loss: 0.0173 - val_loss: 0.0048\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 501us/step - loss: 0.0049 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 502us/step - loss: 0.0041 - val_loss: 0.0048\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 498us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 500us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 500us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 503us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 502us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 499us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 495us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 497us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 499us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 494us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 496us/step - loss: 0.0018 - val_loss: 9.8166e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 499us/step - loss: 0.0017 - val_loss: 9.4617e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 501us/step - loss: 0.0017 - val_loss: 9.3307e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 502us/step - loss: 0.0017 - val_loss: 9.4003e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 13s 3ms/step - loss: 0.1631 - val_loss: 0.0323\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0334 - val_loss: 0.0042\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0255 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0083 - val_loss: 0.0085\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0044 - val_loss: 0.0062\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0023 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0020 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0015 - val_loss: 9.3628e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0015 - val_loss: 8.6193e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 13s 3ms/step - loss: 0.1146 - val_loss: 0.0392\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 589us/step - loss: 0.0266 - val_loss: 0.0278\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0096 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0025 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0019 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0018 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0018 - val_loss: 0.0016\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0014 - val_loss: 0.0031\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 23/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0013 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 14s 3ms/step - loss: 0.1200 - val_loss: 0.0460\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0265 - val_loss: 0.0225\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0106 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 576us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0015 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0014 - val_loss: 0.0024\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 14s 3ms/step - loss: 0.0951 - val_loss: 0.0327\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0128 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0057 - val_loss: 0.0045\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0031 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0026 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0019 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0014 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0014 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0013 - val_loss: 0.0028\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 0.0022\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0012 - val_loss: 0.0027\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0012 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0012 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0011 - val_loss: 0.0035\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0011 - val_loss: 0.0034\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 14s 4ms/step - loss: 0.0892 - val_loss: 0.0542\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0225 - val_loss: 0.0205\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0093 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0047 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0026 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0020 - val_loss: 0.0025\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0015 - val_loss: 9.9184e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0014 - val_loss: 9.6672e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0014 - val_loss: 9.1855e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0014 - val_loss: 9.1270e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0013 - val_loss: 9.2973e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0013 - val_loss: 9.4390e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0013 - val_loss: 8.4665e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0012 - val_loss: 8.2142e-04\n",
      "\n",
      "GENERATION 11\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 12s 3ms/step - loss: 0.0769 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0063 - val_loss: 0.0012\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 9.4434e-04 - val_loss: 6.2592e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 7.2450e-04 - val_loss: 8.7338e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - ETA: 0s - loss: 6.4498e-0 - 1s 255us/step - loss: 6.4527e-04 - val_loss: 5.3759e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 6.0435e-04 - val_loss: 5.5279e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 5.6555e-04 - val_loss: 6.3218e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 5.4992e-04 - val_loss: 5.1908e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 5.2904e-04 - val_loss: 4.7862e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 5.1548e-04 - val_loss: 4.6908e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.9384e-04 - val_loss: 4.5133e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.7582e-04 - val_loss: 4.3934e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 4.5928e-04 - val_loss: 4.3341e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.3754e-04 - val_loss: 4.3029e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.1811e-04 - val_loss: 3.8895e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 4.0667e-04 - val_loss: 4.1584e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 3.9287e-04 - val_loss: 3.7054e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 3.7850e-04 - val_loss: 3.7082e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 3.7300e-04 - val_loss: 3.5369e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 3.6852e-04 - val_loss: 3.4733e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - ETA: 0s - loss: 3.6721e-0 - 1s 254us/step - loss: 3.6524e-04 - val_loss: 3.4809e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 3.5649e-04 - val_loss: 3.4225e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 13s 3ms/step - loss: 0.0413 - val_loss: 0.0128\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0063 - val_loss: 0.0058\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0026 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0014 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 9.1218e-04 - val_loss: 5.6059e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 6.9575e-04 - val_loss: 8.0431e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 6.2441e-04 - val_loss: 5.1741e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.9125e-04 - val_loss: 6.9143e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 5.6336e-04 - val_loss: 5.2012e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 5.5059e-04 - val_loss: 6.2877e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.4099e-04 - val_loss: 5.3356e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 5.3288e-04 - val_loss: 5.7005e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 5.2007e-04 - val_loss: 5.3685e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.0667e-04 - val_loss: 5.0413e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.8463e-04 - val_loss: 4.9095e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.7181e-04 - val_loss: 4.4943e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 4.5728e-04 - val_loss: 4.4117e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.4214e-04 - val_loss: 4.3181e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.2605e-04 - val_loss: 4.3909e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 4.1389e-04 - val_loss: 3.9925e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 4.0111e-04 - val_loss: 3.7979e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 3.8893e-04 - val_loss: 3.7224e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 3.7747e-04 - val_loss: 3.7383e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 3.6947e-04 - val_loss: 3.6585e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 13s 3ms/step - loss: 0.0914 - val_loss: 0.0025\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0111 - val_loss: 6.5686e-04\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0055 - val_loss: 7.9071e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0042 - val_loss: 8.7253e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0034 - val_loss: 5.8586e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0027 - val_loss: 8.7730e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0025 - val_loss: 5.1766e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0023 - val_loss: 6.8085e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - ETA: 0s - loss: 0.002 - 1s 260us/step - loss: 0.0021 - val_loss: 5.2557e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0020 - val_loss: 7.0728e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0020 - val_loss: 5.6850e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0020 - val_loss: 4.9527e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0019 - val_loss: 7.5914e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 264us/step - loss: 0.0017 - val_loss: 6.6599e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0017 - val_loss: 5.3943e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0017 - val_loss: 6.5825e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0016 - val_loss: 5.9308e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0015 - val_loss: 5.8455e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0015 - val_loss: 5.4246e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0013 - val_loss: 5.0330e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0014 - val_loss: 5.4946e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - ETA: 0s - loss: 0.001 - 1s 258us/step - loss: 0.0013 - val_loss: 6.0311e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0013 - val_loss: 8.4390e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0012 - val_loss: 8.7341e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 15s 4ms/step - loss: 0.0682 - val_loss: 0.0328\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 413us/step - loss: 0.0162 - val_loss: 0.0146\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0089 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0048 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0042 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 407us/step - loss: 0.0039 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0036 - val_loss: 9.4454e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0033 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0033 - val_loss: 9.2611e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0031 - val_loss: 9.8997e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0030 - val_loss: 9.0230e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0030 - val_loss: 8.9865e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0029 - val_loss: 9.9437e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0028 - val_loss: 8.6936e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 453us/step - loss: 0.0027 - val_loss: 8.9361e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0026 - val_loss: 8.6792e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0026 - val_loss: 8.8808e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0026 - val_loss: 8.4926e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0025 - val_loss: 9.7135e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0025 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0023 - val_loss: 9.8445e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 14s 4ms/step - loss: 0.0571 - val_loss: 0.0174\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0105 - val_loss: 0.0040\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0076 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0061 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0099 - val_loss: 0.0047\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0064 - val_loss: 0.0040\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0063 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 407us/step - loss: 0.0052 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0066 - val_loss: 0.0069\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0052 - val_loss: 0.0035\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0060 - val_loss: 0.0100\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0067 - val_loss: 0.0081\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0068 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0041 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0032 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0034 - val_loss: 0.0037\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0079 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0042 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0055 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0049 - val_loss: 0.0016\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0043 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0047 - val_loss: 0.0016\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 15s 4ms/step - loss: 0.0845 - val_loss: 0.0101\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0074 - val_loss: 0.0095\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0112 - val_loss: 0.0122\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0076 - val_loss: 0.0096\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0078 - val_loss: 0.0070\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0058 - val_loss: 0.0058\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0080 - val_loss: 0.0086\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0074 - val_loss: 0.0109\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 407us/step - loss: 0.0081 - val_loss: 0.0059\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0047 - val_loss: 0.0036\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0054 - val_loss: 0.0073\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0071 - val_loss: 0.0053\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0058 - val_loss: 0.0056\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0066 - val_loss: 0.0057\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0052 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0066 - val_loss: 0.0054\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0049 - val_loss: 0.0034\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0057 - val_loss: 0.0039\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0040 - val_loss: 0.0028\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0058 - val_loss: 0.0044\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0043 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0039 - val_loss: 0.0028\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 15s 4ms/step - loss: 0.0567 - val_loss: 0.0113\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0113 - val_loss: 0.0069\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0103 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0085 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0083 - val_loss: 0.0071\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 340us/step - loss: 0.0066 - val_loss: 0.0028\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 337us/step - loss: 0.0048 - val_loss: 0.0020\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 337us/step - loss: 0.0063 - val_loss: 0.0062\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 337us/step - loss: 0.0067 - val_loss: 0.0083\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 342us/step - loss: 0.0070 - val_loss: 0.0042\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 335us/step - loss: 0.0049 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 337us/step - loss: 0.0043 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 342us/step - loss: 0.0046 - val_loss: 0.0078\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0073 - val_loss: 0.0083\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 341us/step - loss: 0.0059 - val_loss: 0.0049\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 336us/step - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 337us/step - loss: 0.0058 - val_loss: 0.0043\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0045 - val_loss: 0.0024\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0043 - val_loss: 0.0078\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0050 - val_loss: 0.0045\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0045 - val_loss: 0.0051\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 339us/step - loss: 0.0046 - val_loss: 0.0036\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 338us/step - loss: 0.0040 - val_loss: 0.0031\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 16s 4ms/step - loss: 0.1537 - val_loss: 0.0153\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0351 - val_loss: 0.0226\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0250 - val_loss: 0.0145\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0201 - val_loss: 0.0202\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0151 - val_loss: 0.0189\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0145 - val_loss: 0.0163\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0123 - val_loss: 0.0090\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0099 - val_loss: 0.0122\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0081 - val_loss: 0.0107\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0070 - val_loss: 0.0123\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0089 - val_loss: 0.0076\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0070 - val_loss: 0.0078\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0061 - val_loss: 0.0103\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0072 - val_loss: 0.0070\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0058 - val_loss: 0.0063\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0051 - val_loss: 0.0036\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0042 - val_loss: 0.0056\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0063 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0052 - val_loss: 0.0078\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0071 - val_loss: 0.0077\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0066 - val_loss: 0.0077\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0059 - val_loss: 0.0044\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 16s 4ms/step - loss: 0.0854 - val_loss: 0.0118\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0206 - val_loss: 0.0184\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0154 - val_loss: 0.0085\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0122 - val_loss: 0.0133\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0103 - val_loss: 0.0098\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0093 - val_loss: 0.0082\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0098 - val_loss: 0.0061\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0075 - val_loss: 0.0056\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0057 - val_loss: 0.0101\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0080 - val_loss: 0.0044\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0065 - val_loss: 0.0059\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0070 - val_loss: 0.0058\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0068 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0058 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0066 - val_loss: 0.0052\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0067 - val_loss: 0.0085\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0070 - val_loss: 0.0052\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0057 - val_loss: 0.0060\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0056 - val_loss: 0.0043\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0049 - val_loss: 0.0051\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0051 - val_loss: 0.0029\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0048 - val_loss: 0.0056\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0056 - val_loss: 0.0042\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0053 - val_loss: 0.0045\n",
      "\n",
      "GENERATION 12\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 16s 4ms/step - loss: 0.1360 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0197 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0090 - val_loss: 0.0132\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0060 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0039 - val_loss: 0.0039\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0032 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0027 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0026 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0024 - val_loss: 0.0030\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0023 - val_loss: 0.0034\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0023 - val_loss: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0021 - val_loss: 0.0027\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0021 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0021 - val_loss: 0.0032\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0020 - val_loss: 0.0031\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0019 - val_loss: 0.0047\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0018 - val_loss: 0.0048\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0018 - val_loss: 0.0049\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0017 - val_loss: 0.0059\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0017 - val_loss: 0.0067\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0018 - val_loss: 0.0068\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0017 - val_loss: 0.0076\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0016 - val_loss: 0.0076\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 15s 4ms/step - loss: 0.0323 - val_loss: 0.0121\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0036 - val_loss: 8.1057e-04\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0015 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 8.8954e-04 - val_loss: 5.4696e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 7.0979e-04 - val_loss: 6.0661e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 6.4248e-04 - val_loss: 5.1495e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.8689e-04 - val_loss: 6.7148e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.5535e-04 - val_loss: 5.8324e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 5.3829e-04 - val_loss: 5.6697e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.1717e-04 - val_loss: 5.1280e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.9163e-04 - val_loss: 4.6169e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.8436e-04 - val_loss: 4.9448e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 4.6364e-04 - val_loss: 4.1728e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 4.4563e-04 - val_loss: 4.2434e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.3072e-04 - val_loss: 3.8905e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.1951e-04 - val_loss: 3.8872e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.0830e-04 - val_loss: 3.9881e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.0369e-04 - val_loss: 3.6814e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 3.9476e-04 - val_loss: 3.6540e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 3.8356e-04 - val_loss: 3.5923e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 3.8240e-04 - val_loss: 3.6036e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 3.6896e-04 - val_loss: 3.4809e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 3.6473e-04 - val_loss: 3.5565e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 3.6165e-04 - val_loss: 3.5020e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 17s 4ms/step - loss: 0.0642 - val_loss: 0.0338\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0105 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0041 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0016 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 0.0012 - val_loss: 9.3014e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0010 - val_loss: 9.9287e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 9.7381e-04 - val_loss: 9.8617e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 9.5267e-04 - val_loss: 0.0010\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 9.3652e-04 - val_loss: 9.1317e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 9.0704e-04 - val_loss: 8.9209e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 8.7924e-04 - val_loss: 7.9768e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 8.4712e-04 - val_loss: 8.0960e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 8.2071e-04 - val_loss: 7.5338e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 536us/step - loss: 7.9216e-04 - val_loss: 7.2986e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 7.7314e-04 - val_loss: 7.7380e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 7.5502e-04 - val_loss: 6.8758e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 7.4907e-04 - val_loss: 6.7124e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 7.2973e-04 - val_loss: 6.5800e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 7.0845e-04 - val_loss: 6.7408e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 6.9119e-04 - val_loss: 6.4079e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 16s 4ms/step - loss: 0.0534 - val_loss: 0.0208\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 464us/step - loss: 0.0067 - val_loss: 0.0016\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 463us/step - loss: 0.0030 - val_loss: 0.0067\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 464us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 463us/step - loss: 0.0013 - val_loss: 9.5289e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 471us/step - loss: 0.0012 - val_loss: 9.0219e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 465us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 462us/step - loss: 9.9541e-04 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 465us/step - loss: 9.6743e-04 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 466us/step - loss: 9.2413e-04 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 463us/step - loss: 8.9271e-04 - val_loss: 8.6354e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 465us/step - loss: 8.5915e-04 - val_loss: 8.4860e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 465us/step - loss: 8.2928e-04 - val_loss: 7.6291e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 465us/step - loss: 8.0059e-04 - val_loss: 7.2708e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 467us/step - loss: 7.7432e-04 - val_loss: 7.0129e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 463us/step - loss: 7.4779e-04 - val_loss: 7.2447e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 465us/step - loss: 7.2950e-04 - val_loss: 6.8548e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 466us/step - loss: 7.1506e-04 - val_loss: 6.6573e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 463us/step - loss: 7.1036e-04 - val_loss: 7.0054e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 463us/step - loss: 6.9250e-04 - val_loss: 6.3606e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 463us/step - loss: 6.7088e-04 - val_loss: 6.1967e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 468us/step - loss: 6.5240e-04 - val_loss: 6.1767e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 466us/step - loss: 6.4410e-04 - val_loss: 5.9794e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 464us/step - loss: 6.2972e-04 - val_loss: 6.0591e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 17s 4ms/step - loss: 0.0551 - val_loss: 0.0117\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0101 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0046 - val_loss: 9.5395e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0036 - val_loss: 0.0058\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0030 - val_loss: 0.0012\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0023 - val_loss: 8.7815e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0020 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 491us/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0018 - val_loss: 9.1174e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0017 - val_loss: 8.8305e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0016 - val_loss: 8.5491e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 489us/step - loss: 0.0016 - val_loss: 8.6402e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0016 - val_loss: 9.0395e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 8.3682e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 489us/step - loss: 0.0015 - val_loss: 9.1998e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0014 - val_loss: 9.8372e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0015 - val_loss: 7.0833e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0014 - val_loss: 6.8454e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 489us/step - loss: 0.0013 - val_loss: 9.0891e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0013 - val_loss: 9.4521e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0012 - val_loss: 6.7351e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 489us/step - loss: 0.0013 - val_loss: 8.2565e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 17s 4ms/step - loss: 0.0614 - val_loss: 0.0129\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0262 - val_loss: 0.0089\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0186 - val_loss: 0.0057\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0129 - val_loss: 0.0037\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0096 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0074 - val_loss: 0.0017\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0058 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0048 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0043 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0039 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0038 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0038 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0036 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0035 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0034 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0036 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0034 - val_loss: 0.0017\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0032 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0031 - val_loss: 0.0015\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 18s 4ms/step - loss: 0.0766 - val_loss: 0.0119\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0288 - val_loss: 0.0075\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0197 - val_loss: 0.0048\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 483us/step - loss: 0.0139 - val_loss: 0.0027\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 492us/step - loss: 0.0100 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0077 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 475us/step - loss: 0.0061 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0056 - val_loss: 0.0015\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 477us/step - loss: 0.0047 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 479us/step - loss: 0.0047 - val_loss: 0.0017\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 476us/step - loss: 0.0043 - val_loss: 0.0018\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 475us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 476us/step - loss: 0.0042 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 476us/step - loss: 0.0042 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0041 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0042 - val_loss: 0.0022\n",
      "Epoch 17/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 476us/step - loss: 0.0040 - val_loss: 0.0022\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 474us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 476us/step - loss: 0.0039 - val_loss: 0.0020\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 476us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 475us/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 476us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 475us/step - loss: 0.0037 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 477us/step - loss: 0.0038 - val_loss: 0.0021\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 17s 4ms/step - loss: 0.1683 - val_loss: 0.0016\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 479us/step - loss: 0.0061 - val_loss: 0.0280\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 482us/step - loss: 0.0119 - val_loss: 0.0145\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 477us/step - loss: 0.0124 - val_loss: 0.0133\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0156 - val_loss: 0.0079\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0109 - val_loss: 0.0170\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 477us/step - loss: 0.0155 - val_loss: 0.0396\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0145 - val_loss: 0.0040\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0087 - val_loss: 0.0134\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 475us/step - loss: 0.0152 - val_loss: 0.0186\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0096 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0072 - val_loss: 0.0211\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0123 - val_loss: 0.0045\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0070 - val_loss: 0.0096\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 480us/step - loss: 0.0098 - val_loss: 0.0140\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 476us/step - loss: 0.0083 - val_loss: 0.0263\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 482us/step - loss: 0.0087 - val_loss: 8.5022e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 477us/step - loss: 0.0047 - val_loss: 0.0093\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 481us/step - loss: 0.0069 - val_loss: 0.0059\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 477us/step - loss: 0.0066 - val_loss: 0.0107\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 481us/step - loss: 0.0066 - val_loss: 6.7952e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 481us/step - loss: 0.0054 - val_loss: 0.0065\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 478us/step - loss: 0.0058 - val_loss: 0.0035\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 18s 5ms/step - loss: 0.1377 - val_loss: 0.0315\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0197 - val_loss: 0.0059\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0173 - val_loss: 0.0198\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0160 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0135 - val_loss: 0.0234\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0135 - val_loss: 0.0112\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0114 - val_loss: 0.0280\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0127 - val_loss: 0.0140\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0108 - val_loss: 0.0192\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0094 - val_loss: 0.0162\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 561us/step - loss: 0.0104 - val_loss: 0.0055\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0080 - val_loss: 0.0145\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0110 - val_loss: 0.0065\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0060 - val_loss: 0.0283\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0085 - val_loss: 0.0109\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0057 - val_loss: 0.0238\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0083 - val_loss: 0.0141\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0079 - val_loss: 0.0051\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0059 - val_loss: 0.0107\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0076 - val_loss: 0.0046\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0052 - val_loss: 0.0103\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 560us/step - loss: 0.0068 - val_loss: 0.0051\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 562us/step - loss: 0.0056 - val_loss: 0.0059\n",
      "\n",
      "GENERATION 13\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 16s 4ms/step - loss: 0.0729 - val_loss: 9.4963e-04\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 225us/step - loss: 0.0097 - val_loss: 0.0013\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 0.0046 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 226us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 226us/step - loss: 0.0021 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 224us/step - loss: 0.0018 - val_loss: 6.6717e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 226us/step - loss: 0.0017 - val_loss: 6.6537e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 225us/step - loss: 0.0016 - val_loss: 4.8433e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 0.0015 - val_loss: 5.9046e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 223us/step - loss: 0.0014 - val_loss: 6.5048e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 224us/step - loss: 0.0013 - val_loss: 6.0698e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 225us/step - loss: 0.0013 - val_loss: 7.0678e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 223us/step - loss: 0.0012 - val_loss: 7.3320e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 224us/step - loss: 0.0012 - val_loss: 7.8617e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 223us/step - loss: 0.0012 - val_loss: 9.2482e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 224us/step - loss: 0.0011 - val_loss: 8.4720e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 223us/step - loss: 0.0010 - val_loss: 9.5380e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 224us/step - loss: 0.0010 - val_loss: 7.3632e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 224us/step - loss: 9.7161e-04 - val_loss: 9.4106e-04\n",
      "Epoch 21/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 223us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 224us/step - loss: 9.4457e-04 - val_loss: 0.0014\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 225us/step - loss: 8.8987e-04 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 223us/step - loss: 8.3704e-04 - val_loss: 0.0013\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 17s 4ms/step - loss: 0.0411 - val_loss: 0.0053\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0047 - val_loss: 0.0041\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0022 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 7.3674e-04 - val_loss: 5.4892e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 6.2285e-04 - val_loss: 8.6565e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.9292e-04 - val_loss: 4.7787e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.5367e-04 - val_loss: 5.3454e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.3003e-04 - val_loss: 5.2363e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.1808e-04 - val_loss: 4.8284e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 5.0770e-04 - val_loss: 5.1218e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 4.9772e-04 - val_loss: 4.7575e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.8764e-04 - val_loss: 4.7655e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 4.6948e-04 - val_loss: 4.6298e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.5318e-04 - val_loss: 4.2797e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.3795e-04 - val_loss: 4.1527e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 4.2485e-04 - val_loss: 4.1573e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.1206e-04 - val_loss: 3.8484e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 3.9610e-04 - val_loss: 3.7819e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 3.8806e-04 - val_loss: 3.7259e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 3.7656e-04 - val_loss: 3.9171e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 3.7119e-04 - val_loss: 3.5778e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 3.6280e-04 - val_loss: 3.6245e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 3.5412e-04 - val_loss: 3.7545e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 18s 4ms/step - loss: 1.0219 - val_loss: 0.0068\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 407us/step - loss: 0.0057 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0058 - val_loss: 0.0073\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0027 - val_loss: 0.0024\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0025 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0023 - val_loss: 0.0021\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0023 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0022 - val_loss: 0.0021\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0022 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 407us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 406us/step - loss: 0.0021 - val_loss: 0.0019\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 18s 5ms/step - loss: 4.0953 - val_loss: 0.0031\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0113 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0100 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0085 - val_loss: 0.0023\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0080 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0076 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0073 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 428us/step - loss: 0.0076 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0069 - val_loss: 0.0021\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0066 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0067 - val_loss: 0.0020\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0062 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0062 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0063 - val_loss: 0.0021\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0060 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0057 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0055 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0054 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0052 - val_loss: 0.0017\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 18s 5ms/step - loss: 1.4979 - val_loss: 0.0071\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0170 - val_loss: 0.0031\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0129 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0110 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0094 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0091 - val_loss: 0.0023\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0085 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0081 - val_loss: 0.0022\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0078 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0076 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0076 - val_loss: 0.0021\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0068 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0069 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0066 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0061 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0062 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0058 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0059 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0055 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0056 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0054 - val_loss: 0.0017\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 19s 5ms/step - loss: 1.8565 - val_loss: 0.0026\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0101 - val_loss: 0.0029\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0086 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0075 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0078 - val_loss: 0.0026\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0074 - val_loss: 0.0026\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0067 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0067 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0065 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0063 - val_loss: 0.0023\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0061 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0058 - val_loss: 0.0022\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0057 - val_loss: 0.0020\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0054 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0052 - val_loss: 0.0020\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0052 - val_loss: 0.0019\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0051 - val_loss: 0.0021\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0049 - val_loss: 0.0019\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0050 - val_loss: 0.0020\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0048 - val_loss: 0.0019\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0046 - val_loss: 0.0018\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 19s 5ms/step - loss: 3.3188 - val_loss: 0.0064\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0119 - val_loss: 0.0035\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0103 - val_loss: 0.0033\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0091 - val_loss: 0.0031\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 426us/step - loss: 0.0102 - val_loss: 0.0068\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0084 - val_loss: 0.0032\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0084 - val_loss: 0.0037\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0078 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0073 - val_loss: 0.0028\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0074 - val_loss: 0.0029\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0072 - val_loss: 0.0028\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0072 - val_loss: 0.0028\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0067 - val_loss: 0.0025\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0065 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0067 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0062 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0063 - val_loss: 0.0025\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0060 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0063 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0057 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0056 - val_loss: 0.0021\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 19s 5ms/step - loss: 1.5815 - val_loss: 0.0030\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0104 - val_loss: 0.0038\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 423us/step - loss: 0.0091 - val_loss: 0.0033\n",
      "Epoch 4/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0088 - val_loss: 0.0025\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0087 - val_loss: 0.0029\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0077 - val_loss: 0.0025\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0071 - val_loss: 0.0024\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0074 - val_loss: 0.0023\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0070 - val_loss: 0.0022\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0067 - val_loss: 0.0028\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0065 - val_loss: 0.0023\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0062 - val_loss: 0.0021\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0063 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0059 - val_loss: 0.0023\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0060 - val_loss: 0.0020\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0057 - val_loss: 0.0021\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0057 - val_loss: 0.0020\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0053 - val_loss: 0.0019\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0050 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0050 - val_loss: 0.0019\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0052 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0049 - val_loss: 0.0019\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 19s 5ms/step - loss: 3.6057 - val_loss: 0.0058\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0131 - val_loss: 0.0033\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0113 - val_loss: 0.0034\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0106 - val_loss: 0.0032\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0102 - val_loss: 0.0032\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0098 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0088 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0087 - val_loss: 0.0030\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0087 - val_loss: 0.0029\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0082 - val_loss: 0.0027\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0077 - val_loss: 0.0027\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0079 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0077 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0074 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0074 - val_loss: 0.0025\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0072 - val_loss: 0.0024\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0070 - val_loss: 0.0024\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0069 - val_loss: 0.0023\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0066 - val_loss: 0.0023\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0067 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0061 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0064 - val_loss: 0.0022\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0064 - val_loss: 0.0022\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0060 - val_loss: 0.0021\n",
      "\n",
      "GENERATION 14\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 19s 5ms/step - loss: 0.0630 - val_loss: 0.0240\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0115 - val_loss: 0.0039\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0044 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0022 - val_loss: 4.6979e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0011 - val_loss: 6.7641e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 7.9918e-04 - val_loss: 4.7132e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 6.3629e-04 - val_loss: 6.3626e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.5166e-04 - val_loss: 4.4822e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.2926e-04 - val_loss: 5.2375e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.1387e-04 - val_loss: 4.4394e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.1022e-04 - val_loss: 4.8347e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.0432e-04 - val_loss: 4.4565e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 5.0210e-04 - val_loss: 4.7210e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.9545e-04 - val_loss: 4.4696e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.9100e-04 - val_loss: 4.4021e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.8597e-04 - val_loss: 4.4269e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.8152e-04 - val_loss: 4.4060e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.7691e-04 - val_loss: 4.4403e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.7276e-04 - val_loss: 4.2940e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 4.6811e-04 - val_loss: 4.2977e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.6419e-04 - val_loss: 4.2166e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.5994e-04 - val_loss: 4.1870e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.5504e-04 - val_loss: 4.2558e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.5136e-04 - val_loss: 4.1919e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 18s 4ms/step - loss: 0.0597 - val_loss: 0.0073\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0080 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0030 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 8.3239e-04 - val_loss: 6.4279e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 6.7874e-04 - val_loss: 6.8740e-04\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 255us/step - loss: 5.8019e-04 - val_loss: 5.3885e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.5464e-04 - val_loss: 4.8424e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.4577e-04 - val_loss: 5.3786e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.3343e-04 - val_loss: 5.0144e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 5.2106e-04 - val_loss: 4.7937e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 5.1255e-04 - val_loss: 4.9160e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.0354e-04 - val_loss: 4.6389e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.9376e-04 - val_loss: 4.6618e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.8543e-04 - val_loss: 4.6103e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.7758e-04 - val_loss: 4.6378e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.7017e-04 - val_loss: 4.3849e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.5571e-04 - val_loss: 4.3539e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 4.4641e-04 - val_loss: 4.2319e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.3548e-04 - val_loss: 3.9964e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.2957e-04 - val_loss: 4.0024e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 4.2163e-04 - val_loss: 3.9754e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.1499e-04 - val_loss: 3.7670e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 4.1130e-04 - val_loss: 3.8380e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 21s 5ms/step - loss: 0.0669 - val_loss: 0.0329\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0090 - val_loss: 0.0034\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0038 - val_loss: 0.0063\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0022 - val_loss: 9.3521e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 9.7543e-04 - val_loss: 8.6474e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 9.3529e-04 - val_loss: 8.4913e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 528us/step - loss: 9.1444e-04 - val_loss: 8.1591e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 9.0233e-04 - val_loss: 7.8941e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 8.6777e-04 - val_loss: 7.7482e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 8.5315e-04 - val_loss: 8.2975e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 8.2870e-04 - val_loss: 7.4742e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 8.0558e-04 - val_loss: 7.4075e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 7.8998e-04 - val_loss: 7.2176e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 7.6816e-04 - val_loss: 7.2816e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 7.6628e-04 - val_loss: 7.5455e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 7.5219e-04 - val_loss: 7.1463e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 7.5425e-04 - val_loss: 6.8199e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 7.3342e-04 - val_loss: 6.8106e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 7.0978e-04 - val_loss: 6.8344e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 6.9879e-04 - val_loss: 6.3698e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 20s 5ms/step - loss: 0.0997 - val_loss: 0.0083\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0162 - val_loss: 0.0113\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0081 - val_loss: 0.0065\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0025 - val_loss: 0.0020\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0016 - val_loss: 0.0010\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0015 - val_loss: 9.8201e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0015 - val_loss: 9.8534e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0014 - val_loss: 9.5117e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0013 - val_loss: 9.1132e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0013 - val_loss: 8.7310e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 416us/step - loss: 0.0012 - val_loss: 9.8273e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0011 - val_loss: 8.6569e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0011 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0010 - val_loss: 0.0010\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 21s 5ms/step - loss: 0.2061 - val_loss: 0.0083\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0220 - val_loss: 0.0247\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0106 - val_loss: 0.0023\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0042 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0028 - val_loss: 0.0023\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0018 - val_loss: 0.0011\n",
      "Epoch 9/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0015 - val_loss: 0.0011\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 421us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0014 - val_loss: 0.0016\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 519us/step - loss: 0.0013 - val_loss: 0.0016\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 21s 5ms/step - loss: 0.1448 - val_loss: 0.0402\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0243 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0091 - val_loss: 0.0076\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0050 - val_loss: 0.0015\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0033 - val_loss: 0.0038\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0026 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 434us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0019 - val_loss: 0.0020\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 429us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 432us/step - loss: 0.0017 - val_loss: 0.0013\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 431us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 438us/step - loss: 0.0016 - val_loss: 0.0018\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 441us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 439us/step - loss: 0.0015 - val_loss: 0.0024\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 23s 6ms/step - loss: 0.1098 - val_loss: 0.0049\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 373us/step - loss: 0.0183 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 372us/step - loss: 0.0082 - val_loss: 0.0021\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 377us/step - loss: 0.0050 - val_loss: 0.0017\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 376us/step - loss: 0.0032 - val_loss: 0.0014\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 383us/step - loss: 0.0028 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 388us/step - loss: 0.0027 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0024 - val_loss: 0.0015\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 383us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 384us/step - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 376us/step - loss: 0.0021 - val_loss: 0.0016\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 384us/step - loss: 0.0020 - val_loss: 0.0017\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 374us/step - loss: 0.0020 - val_loss: 0.0022\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 375us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0019 - val_loss: 0.0019\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0019 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0018 - val_loss: 0.0031\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0018 - val_loss: 0.0034\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 382us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 379us/step - loss: 0.0018 - val_loss: 0.0027\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 383us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 378us/step - loss: 0.0017 - val_loss: 0.0034\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.0612 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0034 - val_loss: 0.0015\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 413us/step - loss: 0.0063 - val_loss: 0.0094\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0117 - val_loss: 0.0150\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0101 - val_loss: 0.0110\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 413us/step - loss: 0.0082 - val_loss: 0.0102\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 448us/step - loss: 0.0070 - val_loss: 0.0109\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 422us/step - loss: 0.0096 - val_loss: 0.0165\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 424us/step - loss: 0.0095 - val_loss: 0.0085\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 414us/step - loss: 0.0084 - val_loss: 0.0041\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0072 - val_loss: 0.0075\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0076 - val_loss: 0.0112\n",
      "Epoch 14/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 430us/step - loss: 0.0087 - val_loss: 0.0070\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 435us/step - loss: 0.0067 - val_loss: 0.0110\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 452us/step - loss: 0.0082 - val_loss: 0.0099\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 447us/step - loss: 0.0061 - val_loss: 0.0071\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0076 - val_loss: 0.0122\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 419us/step - loss: 0.0089 - val_loss: 0.0070\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0055 - val_loss: 0.0083\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0071 - val_loss: 0.0059\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0064 - val_loss: 0.0089\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 418us/step - loss: 0.0078 - val_loss: 0.0116\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 417us/step - loss: 0.0074 - val_loss: 0.0085\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.0630 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0041 - val_loss: 0.0017\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0031 - val_loss: 0.0029\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0134 - val_loss: 0.0144\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 412us/step - loss: 0.0110 - val_loss: 0.0139\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 420us/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0075 - val_loss: 0.0098\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0080 - val_loss: 0.0113\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0077 - val_loss: 0.0117\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0087 - val_loss: 0.0169\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 425us/step - loss: 0.0097 - val_loss: 0.0093\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0064 - val_loss: 0.0095\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0067 - val_loss: 0.0115\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0076 - val_loss: 0.0126\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0079 - val_loss: 0.0126\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0070 - val_loss: 0.0086\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0066 - val_loss: 0.0129\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0078 - val_loss: 0.0063\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 409us/step - loss: 0.0044 - val_loss: 0.0081\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 410us/step - loss: 0.0051 - val_loss: 0.0100\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0076 - val_loss: 0.0111\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 411us/step - loss: 0.0068 - val_loss: 0.0086\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 415us/step - loss: 0.0053 - val_loss: 0.0074\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 408us/step - loss: 0.0063 - val_loss: 0.0124\n",
      "\n",
      "GENERATION 15\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 23s 6ms/step - loss: 0.0687 - val_loss: 0.0469\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0132 - val_loss: 0.0053\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0050 - val_loss: 0.0032\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 527us/step - loss: 0.0027 - val_loss: 0.0026\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0017 - val_loss: 8.9076e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 525us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 0.0010 - val_loss: 8.9562e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 9.7039e-04 - val_loss: 8.4178e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 9.5039e-04 - val_loss: 0.0010\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 9.3174e-04 - val_loss: 8.9420e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 9.1647e-04 - val_loss: 8.3525e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 8.9686e-04 - val_loss: 9.2116e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 524us/step - loss: 8.8113e-04 - val_loss: 8.3990e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 8.6620e-04 - val_loss: 8.4814e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 8.5449e-04 - val_loss: 7.8222e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 526us/step - loss: 8.3891e-04 - val_loss: 8.4361e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 8.3094e-04 - val_loss: 8.2148e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 8.1885e-04 - val_loss: 7.5311e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 523us/step - loss: 8.0460e-04 - val_loss: 7.5754e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 522us/step - loss: 7.9387e-04 - val_loss: 7.8961e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 7.8452e-04 - val_loss: 7.4150e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 521us/step - loss: 7.7171e-04 - val_loss: 7.1407e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 21s 5ms/step - loss: 0.0979 - val_loss: 0.0014\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0061 - val_loss: 8.3766e-04\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0015 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 9.1415e-04 - val_loss: 7.6230e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 6.8404e-04 - val_loss: 6.7460e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 6.2966e-04 - val_loss: 5.5551e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 6.0826e-04 - val_loss: 5.5504e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.9456e-04 - val_loss: 5.5539e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.8697e-04 - val_loss: 5.4302e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.7588e-04 - val_loss: 5.4655e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.6891e-04 - val_loss: 5.3373e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.5811e-04 - val_loss: 5.1965e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.4238e-04 - val_loss: 5.0742e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 5.2622e-04 - val_loss: 4.9767e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 5.1348e-04 - val_loss: 4.8691e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 5.0731e-04 - val_loss: 4.5873e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.8425e-04 - val_loss: 4.4951e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.7184e-04 - val_loss: 4.3298e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.6097e-04 - val_loss: 4.2398e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 4.4562e-04 - val_loss: 4.1382e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.3996e-04 - val_loss: 4.0339e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 4.2519e-04 - val_loss: 3.9567e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 4.1663e-04 - val_loss: 3.9961e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.0485 - val_loss: 9.1190e-04\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0021 - val_loss: 0.0022\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0056 - val_loss: 0.0028\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0021 - val_loss: 7.0576e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0016 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0034 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0024 - val_loss: 0.0023\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0019 - val_loss: 0.0035\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0023 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0016 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0020 - val_loss: 0.0065\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0025 - val_loss: 0.0023\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0014 - val_loss: 0.0026\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0020 - val_loss: 0.0037\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0017 - val_loss: 0.0017\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0013 - val_loss: 0.0021\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 270us/step - loss: 0.0017 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0016 - val_loss: 0.0021\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 264us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0014 - val_loss: 0.0033\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0012 - val_loss: 0.0021\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 273us/step - loss: 0.0017 - val_loss: 0.0018\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 266us/step - loss: 0.0012 - val_loss: 0.0023\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.0510 - val_loss: 0.0013\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0037 - val_loss: 0.0045\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0040 - val_loss: 0.0071\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0060 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0032 - val_loss: 0.0042\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0031 - val_loss: 0.0031\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0033 - val_loss: 0.0043\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0040 - val_loss: 0.0043\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0039 - val_loss: 0.0047\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0039 - val_loss: 0.0022\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0030 - val_loss: 0.0024\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0027 - val_loss: 0.0028\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0025 - val_loss: 0.0016\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0031 - val_loss: 0.0018\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0017 - val_loss: 6.9449e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - ETA: 0s - loss: 0.001 - 1s 255us/step - loss: 0.0017 - val_loss: 9.9013e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 22s 5ms/step - loss: 0.0673 - val_loss: 0.0200\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0075 - val_loss: 0.0014\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0055 - val_loss: 0.0086\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0063 - val_loss: 0.0050\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0056 - val_loss: 0.0081\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0074 - val_loss: 0.0095\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0055 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0035 - val_loss: 0.0041\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0051 - val_loss: 0.0079\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0057 - val_loss: 0.0058\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0043 - val_loss: 0.0049\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0030 - val_loss: 0.0022\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0026 - val_loss: 0.0027\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0033 - val_loss: 0.0051\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0043 - val_loss: 0.0050\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0034 - val_loss: 0.0045\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0035 - val_loss: 0.0026\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0021 - val_loss: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0028 - val_loss: 0.0054\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0040 - val_loss: 0.0038\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0026 - val_loss: 0.0021\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 24s 6ms/step - loss: 0.0528 - val_loss: 0.0010\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0024 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0023 - val_loss: 0.0010\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0034 - val_loss: 0.0096\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0117 - val_loss: 0.0128\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0059 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0030 - val_loss: 0.0039\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0065 - val_loss: 0.0091\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0065 - val_loss: 0.0041\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0036 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 559us/step - loss: 0.0052 - val_loss: 0.0050\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0040 - val_loss: 0.0040\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0031 - val_loss: 0.0049\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0058 - val_loss: 0.0090\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0044 - val_loss: 0.0051\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0046 - val_loss: 0.0059\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0040 - val_loss: 0.0071\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.0049 - val_loss: 0.0054\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0045 - val_loss: 0.0062\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0047 - val_loss: 0.0033\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0041 - val_loss: 0.0059\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0044 - val_loss: 0.0048\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 24s 6ms/step - loss: 0.0470 - val_loss: 0.0125\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0072 - val_loss: 0.0024\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0031 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0019 - val_loss: 9.5370e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0015 - val_loss: 9.5323e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0016 - val_loss: 8.3953e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: 0.0014 - val_loss: 7.9857e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0013 - val_loss: 7.5876e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0013 - val_loss: 7.7151e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: 0.0013 - val_loss: 7.2715e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0012 - val_loss: 7.1949e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0011 - val_loss: 7.1459e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0012 - val_loss: 7.0748e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0011 - val_loss: 7.0492e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0011 - val_loss: 6.9511e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0011 - val_loss: 6.9309e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0011 - val_loss: 6.7605e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 569us/step - loss: 0.0010 - val_loss: 6.6332e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0011 - val_loss: 7.0449e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0010 - val_loss: 6.6362e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0010 - val_loss: 6.6698e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 567us/step - loss: 0.0010 - val_loss: 7.3981e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 25s 6ms/step - loss: 0.4788 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0315 - val_loss: 0.0337\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0171 - val_loss: 0.0119\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0081 - val_loss: 0.0053\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0045 - val_loss: 0.0052\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0030 - val_loss: 0.0011\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0020 - val_loss: 7.7384e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 577us/step - loss: 0.0018 - val_loss: 8.0422e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 574us/step - loss: 0.0017 - val_loss: 7.9821e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0017 - val_loss: 8.5939e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 7.8817e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0017 - val_loss: 8.0095e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0015 - val_loss: 7.2842e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0015 - val_loss: 7.5177e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0016 - val_loss: 7.8324e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0015 - val_loss: 7.1838e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0014 - val_loss: 7.8245e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0015 - val_loss: 7.6620e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 7.0882e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0014 - val_loss: 7.0216e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0014 - val_loss: 7.0473e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0014 - val_loss: 7.6186e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 25s 6ms/step - loss: 0.2686 - val_loss: 0.0073\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0259 - val_loss: 0.0096\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 572us/step - loss: 0.0091 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0047 - val_loss: 0.0098\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0035 - val_loss: 8.4293e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0023 - val_loss: 0.0022\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.0018 - val_loss: 0.0030\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0016 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0014 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 575us/step - loss: 0.0015 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0014 - val_loss: 9.7214e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0013 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 573us/step - loss: 0.0012 - val_loss: 9.7494e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 571us/step - loss: 0.0012 - val_loss: 9.7056e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 568us/step - loss: 0.0012 - val_loss: 8.4260e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 570us/step - loss: 0.0012 - val_loss: 9.7709e-04\n",
      "\n",
      "GENERATION 16\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 26s 6ms/step - loss: 1.3591 - val_loss: 0.0045\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 558us/step - loss: 0.1088 - val_loss: 0.0100\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0401 - val_loss: 0.0017\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 556us/step - loss: 0.0196 - val_loss: 0.0097\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0131 - val_loss: 0.0063\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0101 - val_loss: 0.0029\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0093 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0076 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0068 - val_loss: 0.0011\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0061 - val_loss: 0.0020\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0058 - val_loss: 0.0012\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0053 - val_loss: 0.0018\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0052 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0048 - val_loss: 0.0015\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0047 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0043 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0042 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0039 - val_loss: 9.3905e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0035 - val_loss: 0.0010\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0037 - val_loss: 9.6774e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0034 - val_loss: 8.7372e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 557us/step - loss: 0.0033 - val_loss: 9.3149e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0032 - val_loss: 8.5590e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 24s 6ms/step - loss: 0.0459 - val_loss: 0.0129\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0057 - val_loss: 0.0068\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 7.2648e-04 - val_loss: 5.1070e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 5.8415e-04 - val_loss: 4.7988e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 5.6511e-04 - val_loss: 6.4989e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 5.3352e-04 - val_loss: 4.8355e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 5.0976e-04 - val_loss: 4.7485e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 4.8840e-04 - val_loss: 4.3792e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 4.6239e-04 - val_loss: 4.5171e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 4.3718e-04 - val_loss: 4.0988e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 4.2035e-04 - val_loss: 3.9028e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 3.9819e-04 - val_loss: 4.0272e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 3.8403e-04 - val_loss: 3.5991e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 3.7610e-04 - val_loss: 3.4881e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 3.7091e-04 - val_loss: 4.0068e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 3.6635e-04 - val_loss: 3.3685e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 3.4947e-04 - val_loss: 3.4467e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 3.4209e-04 - val_loss: 3.3098e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 3.4370e-04 - val_loss: 3.2382e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 3.3931e-04 - val_loss: 3.1959e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 3.3415e-04 - val_loss: 3.2869e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 3.2666e-04 - val_loss: 3.1340e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 25s 6ms/step - loss: 0.1194 - val_loss: 0.0264\n",
      "Epoch 2/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 267us/step - loss: 0.0109 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 268us/step - loss: 0.0044 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 269us/step - loss: 0.0014 - val_loss: 8.4966e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 265us/step - loss: 9.0490e-04 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 7.9857e-04 - val_loss: 6.4424e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 7.5106e-04 - val_loss: 6.2682e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 266us/step - loss: 7.0760e-04 - val_loss: 7.6836e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 268us/step - loss: 6.8809e-04 - val_loss: 6.6973e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 6.6282e-04 - val_loss: 6.1149e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 6.3060e-04 - val_loss: 5.5681e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 5.8901e-04 - val_loss: 6.0542e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 268us/step - loss: 5.5154e-04 - val_loss: 5.0657e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 5.0716e-04 - val_loss: 5.1053e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 266us/step - loss: 4.7370e-04 - val_loss: 4.5198e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 268us/step - loss: 4.3470e-04 - val_loss: 4.4734e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 268us/step - loss: 4.1776e-04 - val_loss: 3.9266e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 3.9777e-04 - val_loss: 3.8328e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 272us/step - loss: 3.8922e-04 - val_loss: 3.7486e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 3.8033e-04 - val_loss: 3.8253e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 3.7919e-04 - val_loss: 4.8603e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 3.9736e-04 - val_loss: 4.4222e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 266us/step - loss: 3.7782e-04 - val_loss: 3.6847e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 25s 6ms/step - loss: 0.2670 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 0.0024 - val_loss: 0.0032\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 265us/step - loss: 0.0012 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 264us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 8.5908e-04 - val_loss: 0.0016\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 265us/step - loss: 7.9449e-04 - val_loss: 0.0013\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 7.2188e-04 - val_loss: 0.0015\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 8.2042e-04 - val_loss: 9.9347e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 6.1490e-04 - val_loss: 0.0014\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 7.8985e-04 - val_loss: 8.7957e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - ETA: 0s - loss: 6.5355e-0 - 1s 264us/step - loss: 6.7209e-04 - val_loss: 0.0015\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 264us/step - loss: 7.0623e-04 - val_loss: 0.0017\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 264us/step - loss: 7.1614e-04 - val_loss: 9.3456e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 264us/step - loss: 5.8920e-04 - val_loss: 7.5581e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 264us/step - loss: 5.2439e-04 - val_loss: 4.4413e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 264us/step - loss: 8.5175e-04 - val_loss: 5.2507e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 5.8282e-04 - val_loss: 5.1187e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 265us/step - loss: 6.2078e-04 - val_loss: 5.3698e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 6.2850e-04 - val_loss: 4.5640e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 6.0706e-04 - val_loss: 4.3387e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 264us/step - loss: 5.5011e-04 - val_loss: 4.3410e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 4.8390e-04 - val_loss: 4.4684e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 7.9349e-04 - val_loss: 4.4428e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 264us/step - loss: 5.2976e-04 - val_loss: 4.1804e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 24s 6ms/step - loss: 0.2041 - val_loss: 0.0280\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0624 - val_loss: 0.1229\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0245 - val_loss: 0.0016\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0026 - val_loss: 0.0011\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0021 - val_loss: 0.0020\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0011 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0011 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0011 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0011 - val_loss: 9.8324e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 0.0011 - val_loss: 9.9002e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0011 - val_loss: 9.6480e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0011 - val_loss: 0.0019\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 0.0010 - val_loss: 0.0016\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0012 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0010 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 9.3103e-04 - val_loss: 8.4943e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 0.0011 - val_loss: 9.1515e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 26s 6ms/step - loss: 0.1986 - val_loss: 0.0976\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0306 - val_loss: 0.0066\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0119 - val_loss: 0.0190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0053 - val_loss: 0.0064\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0032 - val_loss: 0.0085\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 404us/step - loss: 0.0029 - val_loss: 0.0042\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0022 - val_loss: 0.0066\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0029 - val_loss: 0.0046\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0016 - val_loss: 0.0016\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0015 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0017 - val_loss: 0.0014\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0018 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0018 - val_loss: 0.0013\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0014 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 405us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0012 - val_loss: 0.0017\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 26s 6ms/step - loss: 0.2618 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0038 - val_loss: 0.0276\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0073 - val_loss: 0.0024\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0013 - val_loss: 0.0020\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0028 - val_loss: 0.0108\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0014 - val_loss: 0.0059\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 0.0023 - val_loss: 0.0028\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 407us/step - loss: 9.8436e-04 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 8.4996e-04 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0023 - val_loss: 0.0046\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 8.2917e-04 - val_loss: 0.0011\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 7.8646e-04 - val_loss: 9.7023e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 8.6631e-04 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 400us/step - loss: 9.5360e-04 - val_loss: 7.8023e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 7.6956e-04 - val_loss: 6.8076e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 403us/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 0.0011 - val_loss: 7.0306e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 8.3830e-04 - val_loss: 7.1395e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 9.1702e-04 - val_loss: 7.5678e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 402us/step - loss: 9.5868e-04 - val_loss: 7.8452e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 401us/step - loss: 8.5821e-04 - val_loss: 7.9952e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 27s 7ms/step - loss: 0.0743 - val_loss: 0.0376\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0125 - val_loss: 0.0088\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0055 - val_loss: 0.0020\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0034 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0026 - val_loss: 9.8974e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0022 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0019 - val_loss: 9.1960e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 545us/step - loss: 0.0018 - val_loss: 9.4505e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0017 - val_loss: 9.3206e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0016 - val_loss: 8.6240e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 9.5896e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0015 - val_loss: 8.7238e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 7.1864e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0014 - val_loss: 8.4484e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0014 - val_loss: 9.0775e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0014 - val_loss: 7.8966e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0014 - val_loss: 7.1685e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0013 - val_loss: 7.3303e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0013 - val_loss: 7.4723e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0013 - val_loss: 6.9343e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 27s 7ms/step - loss: 0.1700 - val_loss: 0.0186\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0331 - val_loss: 0.0088\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0259 - val_loss: 0.0019\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0076 - val_loss: 0.0080\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0053 - val_loss: 0.0070\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0032 - val_loss: 0.0026\n",
      "Epoch 7/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0032 - val_loss: 0.0013\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0024 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0021 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0020 - val_loss: 0.0013\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 546us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0019 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0018 - val_loss: 0.0012\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "\n",
      "GENERATION 17\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 26s 6ms/step - loss: 0.0523 - val_loss: 0.0036\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 0.0072 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 0.0025 - val_loss: 0.0012\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 8.4600e-04 - val_loss: 6.3246e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 6.7797e-04 - val_loss: 8.8708e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 5.8856e-04 - val_loss: 4.9788e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 5.4571e-04 - val_loss: 5.4005e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 5.2238e-04 - val_loss: 5.3902e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 5.0882e-04 - val_loss: 4.9498e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 4.9258e-04 - val_loss: 4.8062e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 4.7874e-04 - val_loss: 4.7733e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 4.5840e-04 - val_loss: 4.7660e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 4.4716e-04 - val_loss: 4.6110e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 4.3392e-04 - val_loss: 4.1701e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 4.0684e-04 - val_loss: 3.8029e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 3.9331e-04 - val_loss: 3.9668e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 3.8366e-04 - val_loss: 3.7577e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 3.6166e-04 - val_loss: 3.5613e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 3.5258e-04 - val_loss: 3.3882e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 3.4824e-04 - val_loss: 3.7118e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 3.3327e-04 - val_loss: 3.1785e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 3.2988e-04 - val_loss: 3.1264e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 3.2210e-04 - val_loss: 3.0783e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 26s 6ms/step - loss: 0.0921 - val_loss: 0.0029\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 0.0069 - val_loss: 0.0012\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0027 - val_loss: 8.1576e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0014 - val_loss: 5.2742e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 8.2586e-04 - val_loss: 6.6008e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 6.5552e-04 - val_loss: 5.8242e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 5.7361e-04 - val_loss: 4.6007e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 5.2643e-04 - val_loss: 5.6859e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 5.0745e-04 - val_loss: 5.2706e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 4.9847e-04 - val_loss: 4.3397e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 4.8935e-04 - val_loss: 4.3396e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 4.7709e-04 - val_loss: 4.6260e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 4.5881e-04 - val_loss: 4.6696e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 4.4298e-04 - val_loss: 4.4861e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 4.2910e-04 - val_loss: 4.2628e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 4.1882e-04 - val_loss: 4.3603e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 4.1184e-04 - val_loss: 3.7896e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 3.9462e-04 - val_loss: 3.6506e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 3.8301e-04 - val_loss: 4.0550e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 3.8589e-04 - val_loss: 3.6072e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 3.6863e-04 - val_loss: 3.4594e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 3.5490e-04 - val_loss: 3.3337e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 3.4529e-04 - val_loss: 3.2788e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 3.3995e-04 - val_loss: 3.2400e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 26s 6ms/step - loss: 0.1361 - val_loss: 0.0032\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 265us/step - loss: 0.0203 - val_loss: 0.0044\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0076 - val_loss: 0.0049\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0045 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0037 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0032 - val_loss: 4.7265e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0026 - val_loss: 4.6872e-04\n",
      "Epoch 8/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0025 - val_loss: 7.0190e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0023 - val_loss: 5.0115e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0021 - val_loss: 5.1988e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0021 - val_loss: 5.2976e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0020 - val_loss: 5.3393e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0019 - val_loss: 5.6134e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0019 - val_loss: 5.0318e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0019 - val_loss: 5.0533e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0018 - val_loss: 5.0721e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0017 - val_loss: 5.0564e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0017 - val_loss: 4.8061e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0016 - val_loss: 4.6088e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0015 - val_loss: 4.8711e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0015 - val_loss: 5.2887e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0015 - val_loss: 4.7860e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0015 - val_loss: 4.2993e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 0.0015 - val_loss: 4.8077e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 27s 7ms/step - loss: 0.0818 - val_loss: 0.0173\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0137 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0068 - val_loss: 8.6237e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0044 - val_loss: 4.1821e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0031 - val_loss: 0.0010\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0026 - val_loss: 3.9816e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0024 - val_loss: 7.0132e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0022 - val_loss: 3.8787e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0020 - val_loss: 4.7422e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0019 - val_loss: 3.9389e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 0.0018 - val_loss: 4.4184e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0018 - val_loss: 4.5821e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0017 - val_loss: 3.9976e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0017 - val_loss: 4.6609e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0016 - val_loss: 4.5686e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0016 - val_loss: 4.2029e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0015 - val_loss: 4.9286e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0015 - val_loss: 4.2605e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0014 - val_loss: 3.8556e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0014 - val_loss: 4.0768e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0014 - val_loss: 4.7544e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0013 - val_loss: 3.8426e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0013 - val_loss: 3.9040e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 0.0013 - val_loss: 4.0595e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 27s 7ms/step - loss: 0.0464 - val_loss: 5.5705e-04\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0020 - val_loss: 0.0018\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 0.0026 - val_loss: 4.1133e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 0.0013 - val_loss: 3.9213e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0013 - val_loss: 3.8309e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0073 - val_loss: 0.0021\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 0.0016 - val_loss: 3.5797e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 0.0011 - val_loss: 4.0824e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 0.0011 - val_loss: 4.5739e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0013 - val_loss: 0.0029\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0032 - val_loss: 0.0053\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 0.0017 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0010 - val_loss: 5.8247e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 8.6423e-04 - val_loss: 3.8641e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 8.2434e-04 - val_loss: 3.3462e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0010 - val_loss: 0.0025\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 264us/step - loss: 0.0044 - val_loss: 0.0039\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 0.0019 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 0.0013 - val_loss: 5.4508e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 0.0011 - val_loss: 5.0030e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 0.0010 - val_loss: 4.0481e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 27s 7ms/step - loss: 0.0357 - val_loss: 0.0011\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 174us/step - loss: 0.0053 - val_loss: 0.0180\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 178us/step - loss: 0.0047 - val_loss: 9.2174e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0023 - val_loss: 9.1238e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 174us/step - loss: 0.0025 - val_loss: 0.0065\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 173us/step - loss: 0.0086 - val_loss: 0.0021\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0022 - val_loss: 7.7691e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0037 - val_loss: 0.0083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 174us/step - loss: 0.0040 - val_loss: 0.0016\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 173us/step - loss: 0.0014 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0014 - val_loss: 5.5172e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0012 - val_loss: 3.8252e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 178us/step - loss: 0.0021 - val_loss: 0.0083\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 177us/step - loss: 0.0051 - val_loss: 0.0033\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 176us/step - loss: 0.0023 - val_loss: 0.0012\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0012 - val_loss: 4.3567e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 174us/step - loss: 0.0011 - val_loss: 5.8506e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0013 - val_loss: 0.0018\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 174us/step - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 175us/step - loss: 0.0014 - val_loss: 4.8186e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 27s 7ms/step - loss: 0.0530 - val_loss: 0.0018\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0086 - val_loss: 0.0196\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0044 - val_loss: 4.6275e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0022 - val_loss: 5.7164e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0025 - val_loss: 0.0034\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0040 - val_loss: 0.0062\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0045 - val_loss: 0.0018\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0019 - val_loss: 5.9567e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0036 - val_loss: 0.0044\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0028 - val_loss: 0.0022\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0018 - val_loss: 0.0010\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 0.0020 - val_loss: 0.0027\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 0.0029 - val_loss: 0.0026\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0026 - val_loss: 0.0023\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0020 - val_loss: 4.5185e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0012 - val_loss: 5.5764e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 0.0015 - val_loss: 0.0029\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0036 - val_loss: 0.0030\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 0.0018 - val_loss: 5.2671e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 0.0011 - val_loss: 3.2921e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 0.0017 - val_loss: 0.0029\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 30s 7ms/step - loss: 0.0547 - val_loss: 0.0091\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0090 - val_loss: 0.0079\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0090 - val_loss: 0.0046\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0061 - val_loss: 0.0138\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0057 - val_loss: 8.0541e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0029 - val_loss: 0.0043\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0084 - val_loss: 0.0019\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0041 - val_loss: 0.0011\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0026 - val_loss: 0.0013\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0052 - val_loss: 0.0057\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0045 - val_loss: 0.0032\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0033 - val_loss: 0.0020\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0034 - val_loss: 0.0046\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0040 - val_loss: 0.0013\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0028 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 553us/step - loss: 0.0035 - val_loss: 0.0017\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0033 - val_loss: 0.0066\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0048 - val_loss: 9.5774e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0019 - val_loss: 5.5836e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 554us/step - loss: 0.0016 - val_loss: 5.5477e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0016 - val_loss: 0.0023\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0042 - val_loss: 0.0039\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 555us/step - loss: 0.0024 - val_loss: 0.0012\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0015 - val_loss: 8.5598e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 28s 7ms/step - loss: 0.0817 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0050 - val_loss: 0.0177\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0104 - val_loss: 0.0025\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0043 - val_loss: 0.0068\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0058 - val_loss: 0.0052\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0040 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0070 - val_loss: 0.0106\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0058 - val_loss: 0.0016\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0022 - val_loss: 7.0106e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0021 - val_loss: 0.0012\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0048 - val_loss: 0.0125\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 550us/step - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 15/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0044 - val_loss: 0.0024\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0029 - val_loss: 0.0014\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0024 - val_loss: 0.0034\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0033 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 547us/step - loss: 0.0029 - val_loss: 0.0015\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 552us/step - loss: 0.0024 - val_loss: 0.0022\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 548us/step - loss: 0.0033 - val_loss: 8.7861e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 549us/step - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 551us/step - loss: 0.0033 - val_loss: 0.0021\n",
      "\n",
      "GENERATION 18\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 29s 7ms/step - loss: 0.0576 - val_loss: 0.0050\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 0.0086 - val_loss: 0.0028\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 0.0025 - val_loss: 0.0024\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 0.0017 - val_loss: 6.4374e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 0.0013 - val_loss: 5.6924e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 0.0012 - val_loss: 5.9301e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 0.0011 - val_loss: 5.9356e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 0.0010 - val_loss: 5.5753e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 0.0010 - val_loss: 5.2289e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 9.0426e-04 - val_loss: 5.1288e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 9.4527e-04 - val_loss: 4.9786e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 8.9818e-04 - val_loss: 5.3874e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 8.5303e-04 - val_loss: 5.4448e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 8.3071e-04 - val_loss: 4.5578e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 7.5463e-04 - val_loss: 6.5198e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 7.3928e-04 - val_loss: 6.7484e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 6.9477e-04 - val_loss: 5.9434e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 6.7385e-04 - val_loss: 9.7449e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 6.3181e-04 - val_loss: 6.9682e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 6.4230e-04 - val_loss: 6.4321e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 6.1093e-04 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 5.6905e-04 - val_loss: 0.0011\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 5.6442e-04 - val_loss: 0.0014\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 27s 7ms/step - loss: 0.0629 - val_loss: 0.0021\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 0.0069 - val_loss: 0.0011\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 0.0029 - val_loss: 0.0013\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0017 - val_loss: 0.0010\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 9.5721e-04 - val_loss: 6.6624e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 7.1011e-04 - val_loss: 7.8377e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 5.9444e-04 - val_loss: 5.1708e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 5.7441e-04 - val_loss: 5.4409e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 5.5435e-04 - val_loss: 5.3752e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 5.4293e-04 - val_loss: 4.9546e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 5.2914e-04 - val_loss: 4.9507e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 5.1818e-04 - val_loss: 4.8267e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 5.0775e-04 - val_loss: 4.7276e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 4.9191e-04 - val_loss: 4.4388e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 4.7979e-04 - val_loss: 4.3299e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 4.6445e-04 - val_loss: 4.2454e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 4.5318e-04 - val_loss: 4.2221e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 4.4253e-04 - val_loss: 4.0493e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 4.2990e-04 - val_loss: 4.1649e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 4.1967e-04 - val_loss: 3.8704e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 4.0428e-04 - val_loss: 3.6911e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 3.8988e-04 - val_loss: 3.6827e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 3.7619e-04 - val_loss: 3.5411e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 227us/step - loss: 3.6618e-04 - val_loss: 3.4713e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 28s 7ms/step - loss: 0.0738 - val_loss: 0.0246\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 186us/step - loss: 0.0087 - val_loss: 0.0117\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 186us/step - loss: 0.0036 - val_loss: 0.0051\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 183us/step - loss: 0.0017 - val_loss: 0.0016\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 186us/step - loss: 9.5906e-04 - val_loss: 0.0017\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 184us/step - loss: 6.9519e-04 - val_loss: 4.9182e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 185us/step - loss: 5.8337e-04 - val_loss: 7.8192e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 184us/step - loss: 5.1698e-04 - val_loss: 4.3230e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 185us/step - loss: 4.8714e-04 - val_loss: 5.3333e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 185us/step - loss: 4.6775e-04 - val_loss: 4.7794e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 184us/step - loss: 4.5468e-04 - val_loss: 4.5836e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 188us/step - loss: 4.4350e-04 - val_loss: 4.4838e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 187us/step - loss: 4.3416e-04 - val_loss: 4.4416e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 185us/step - loss: 4.2163e-04 - val_loss: 4.1606e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 185us/step - loss: 4.1327e-04 - val_loss: 4.1942e-04\n",
      "Epoch 16/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 184us/step - loss: 4.0765e-04 - val_loss: 4.0344e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 184us/step - loss: 4.0192e-04 - val_loss: 4.0841e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 184us/step - loss: 3.8987e-04 - val_loss: 4.1763e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 185us/step - loss: 3.8010e-04 - val_loss: 4.0122e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 185us/step - loss: 3.6851e-04 - val_loss: 3.6301e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 183us/step - loss: 3.6047e-04 - val_loss: 3.6048e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 185us/step - loss: 3.5812e-04 - val_loss: 3.7423e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 185us/step - loss: 3.4997e-04 - val_loss: 3.4810e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 183us/step - loss: 3.4314e-04 - val_loss: 3.3869e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 29s 7ms/step - loss: 0.0686 - val_loss: 0.0167\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 367us/step - loss: 0.0310 - val_loss: 0.0103\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 369us/step - loss: 0.0223 - val_loss: 0.0064\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 371us/step - loss: 0.0158 - val_loss: 0.0041\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 367us/step - loss: 0.0118 - val_loss: 0.0028\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 371us/step - loss: 0.0090 - val_loss: 0.0019\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 370us/step - loss: 0.0071 - val_loss: 0.0017\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0061 - val_loss: 0.0018\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0054 - val_loss: 0.0020\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0052 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 370us/step - loss: 0.0048 - val_loss: 0.0024\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 367us/step - loss: 0.0046 - val_loss: 0.0026\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 369us/step - loss: 0.0046 - val_loss: 0.0029\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0047 - val_loss: 0.0028\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 369us/step - loss: 0.0046 - val_loss: 0.0030\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0044 - val_loss: 0.0032\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0044 - val_loss: 0.0033\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0043 - val_loss: 0.0032\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0042 - val_loss: 0.0033\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0042 - val_loss: 0.0034\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 369us/step - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 368us/step - loss: 0.0041 - val_loss: 0.0033\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 31s 8ms/step - loss: 0.2120 - val_loss: 0.2394\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 578us/step - loss: 0.1311 - val_loss: 0.1540\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0924 - val_loss: 0.1043\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0733 - val_loss: 0.0753\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0640 - val_loss: 0.0578\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0593 - val_loss: 0.0471\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0568 - val_loss: 0.0404\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0552 - val_loss: 0.0360\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0540 - val_loss: 0.0331\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0530 - val_loss: 0.0311\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0520 - val_loss: 0.0296\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0512 - val_loss: 0.0284\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0502 - val_loss: 0.0275\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0492 - val_loss: 0.0265\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0483 - val_loss: 0.0257\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0472 - val_loss: 0.0248\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0462 - val_loss: 0.0238\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0450 - val_loss: 0.0229\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0440 - val_loss: 0.0222\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.0427 - val_loss: 0.0211\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0415 - val_loss: 0.0203\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 580us/step - loss: 0.0401 - val_loss: 0.0191\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0387 - val_loss: 0.0179\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 579us/step - loss: 0.0372 - val_loss: 0.0170\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 31s 8ms/step - loss: 3.1781 - val_loss: 0.0419\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0646 - val_loss: 0.0429\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0802 - val_loss: 0.6943\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.2478 - val_loss: 0.0876\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.1209 - val_loss: 0.7851\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.1630 - val_loss: 0.1186\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.1469 - val_loss: 0.0788\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 582us/step - loss: 0.1404 - val_loss: 0.0779\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0974 - val_loss: 0.1770\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0794 - val_loss: 0.2786\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0686 - val_loss: 0.0712\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0848 - val_loss: 0.0111\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0657 - val_loss: 0.1338\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0379 - val_loss: 0.0506\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0615 - val_loss: 0.0208\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0421 - val_loss: 0.0952\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 581us/step - loss: 0.0359 - val_loss: 0.0349\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0468 - val_loss: 0.0038\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0400 - val_loss: 0.0381\n",
      "Epoch 20/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0253 - val_loss: 0.0420\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 583us/step - loss: 0.0359 - val_loss: 0.0096\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0326 - val_loss: 0.0151\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0241 - val_loss: 0.0313\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0259 - val_loss: 0.0149\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 32s 8ms/step - loss: 0.1093 - val_loss: 0.0027\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 488us/step - loss: 0.0072 - val_loss: 0.0372\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0114 - val_loss: 0.0117\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0129 - val_loss: 0.0164\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0110 - val_loss: 0.0261\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0216 - val_loss: 0.0070\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 490us/step - loss: 0.0024 - val_loss: 0.0028\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0017 - val_loss: 0.0041\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0322 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0049 - val_loss: 0.0011\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0056 - val_loss: 0.0048\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0047 - val_loss: 0.0048\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 484us/step - loss: 0.0080 - val_loss: 0.0017\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 487us/step - loss: 0.0049 - val_loss: 0.0139\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0135 - val_loss: 0.0011\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0064 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 483us/step - loss: 0.0016 - val_loss: 0.0013\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0075 - val_loss: 0.0011\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0039 - val_loss: 0.0044\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0068 - val_loss: 0.0014\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0042 - val_loss: 0.0024\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 489us/step - loss: 0.0055 - val_loss: 0.0182\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 486us/step - loss: 0.0068 - val_loss: 0.0013\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 485us/step - loss: 0.0029 - val_loss: 0.0021\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 32s 8ms/step - loss: 0.0529 - val_loss: 0.0022\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 540us/step - loss: 0.0093 - val_loss: 0.0019\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0057 - val_loss: 0.0011\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0044 - val_loss: 0.0030\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0033 - val_loss: 0.0055\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0025 - val_loss: 0.0037\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 529us/step - loss: 0.0022 - val_loss: 0.0029\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0020 - val_loss: 0.0032\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0019 - val_loss: 0.0026\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0016 - val_loss: 0.0011\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 531us/step - loss: 0.0015 - val_loss: 0.0015\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0015 - val_loss: 0.0014\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0014 - val_loss: 0.0018\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 533us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0014 - val_loss: 0.0015\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 534us/step - loss: 0.0013 - val_loss: 0.0013\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0013 - val_loss: 0.0011\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 535us/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0013 - val_loss: 0.0017\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 532us/step - loss: 0.0013 - val_loss: 8.1996e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 530us/step - loss: 0.0012 - val_loss: 0.0020\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 34s 8ms/step - loss: 1.8168 - val_loss: 0.0549\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0835 - val_loss: 0.1217\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0381 - val_loss: 0.0439\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0152 - val_loss: 0.0083\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 593us/step - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0052 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0038 - val_loss: 0.0011\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0032 - val_loss: 0.0010\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 586us/step - loss: 0.0027 - val_loss: 9.5027e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0027 - val_loss: 9.4066e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0025 - val_loss: 8.8222e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0025 - val_loss: 8.7801e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0023 - val_loss: 8.6161e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0023 - val_loss: 8.6400e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 584us/step - loss: 0.0023 - val_loss: 8.3508e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0022 - val_loss: 8.2328e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0022 - val_loss: 8.1684e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 587us/step - loss: 0.0021 - val_loss: 8.1763e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0020 - val_loss: 7.9725e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 585us/step - loss: 0.0021 - val_loss: 7.9252e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0020 - val_loss: 8.3917e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0020 - val_loss: 8.0391e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 588us/step - loss: 0.0020 - val_loss: 8.5119e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 590us/step - loss: 0.0019 - val_loss: 8.2245e-04\n",
      "\n",
      "GENERATION 19\n",
      "\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 31s 8ms/step - loss: 0.0950 - val_loss: 0.0214\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0095 - val_loss: 0.0052\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 0.0039 - val_loss: 0.0018\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0022 - val_loss: 9.2795e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0016 - val_loss: 7.5286e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0013 - val_loss: 5.4341e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 0.0011 - val_loss: 5.3232e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 0.0011 - val_loss: 5.4699e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0011 - val_loss: 5.1951e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0010 - val_loss: 5.0820e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 0.0010 - val_loss: 5.0102e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 9.5627e-04 - val_loss: 5.3038e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 9.3971e-04 - val_loss: 5.4808e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 9.3936e-04 - val_loss: 5.1859e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 9.0690e-04 - val_loss: 5.6294e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 8.9433e-04 - val_loss: 5.3372e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 8.2047e-04 - val_loss: 5.4919e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 8.1880e-04 - val_loss: 6.1596e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 7.7991e-04 - val_loss: 6.1524e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 7.8997e-04 - val_loss: 6.5485e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 7.3776e-04 - val_loss: 5.0963e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 7.3953e-04 - val_loss: 5.6332e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 6.7612e-04 - val_loss: 6.2396e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 228us/step - loss: 7.0809e-04 - val_loss: 4.1838e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 32s 8ms/step - loss: 0.0565 - val_loss: 0.0012\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 0.0071 - val_loss: 7.2582e-04\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 0.0027 - val_loss: 8.1823e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 0.0015 - val_loss: 5.8753e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 8.4764e-04 - val_loss: 8.7233e-04\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 229us/step - loss: 6.6098e-04 - val_loss: 5.8008e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 5.8672e-04 - val_loss: 5.6194e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 5.5326e-04 - val_loss: 6.4431e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 5.2633e-04 - val_loss: 5.2658e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 5.0346e-04 - val_loss: 5.1689e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 4.7854e-04 - val_loss: 4.8656e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 4.5350e-04 - val_loss: 4.5674e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 4.2837e-04 - val_loss: 4.3837e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 4.0863e-04 - val_loss: 3.9969e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 3.8642e-04 - val_loss: 3.9415e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 3.7095e-04 - val_loss: 3.7232e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 3.6279e-04 - val_loss: 3.8091e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 3.5523e-04 - val_loss: 3.4029e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 3.5160e-04 - val_loss: 3.8357e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 3.5055e-04 - val_loss: 3.2864e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 3.4333e-04 - val_loss: 3.3330e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 3.4854e-04 - val_loss: 3.8594e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 3.4822e-04 - val_loss: 3.5825e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 3.4363e-04 - val_loss: 3.5968e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 32s 8ms/step - loss: 0.0546 - val_loss: 0.0075\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 0.0100 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 0.0039 - val_loss: 7.7890e-04\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 0.0019 - val_loss: 5.7178e-04\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 0.0012 - val_loss: 0.0022\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 1s 231us/step - loss: 8.9205e-04 - val_loss: 4.9535e-04\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 7.6896e-04 - val_loss: 0.0014\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 7.0272e-04 - val_loss: 5.2529e-04\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 6.7627e-04 - val_loss: 9.0765e-04\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 6.3784e-04 - val_loss: 6.0541e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 6.1278e-04 - val_loss: 6.9724e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 1s 230us/step - loss: 5.9241e-04 - val_loss: 6.5738e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 5.7588e-04 - val_loss: 6.1028e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 5.6050e-04 - val_loss: 6.5266e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 5.4864e-04 - val_loss: 5.5102e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 5.3307e-04 - val_loss: 5.4947e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 5.2173e-04 - val_loss: 6.1840e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 1s 232us/step - loss: 5.0671e-04 - val_loss: 5.0508e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 4.9498e-04 - val_loss: 5.0323e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 4.8187e-04 - val_loss: 5.1846e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 4.7216e-04 - val_loss: 5.4334e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 4.6200e-04 - val_loss: 4.3236e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 1s 233us/step - loss: 4.5627e-04 - val_loss: 4.6450e-04\n",
      "Epoch 24/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 235us/step - loss: 4.4459e-04 - val_loss: 5.0033e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 34s 8ms/step - loss: 0.0720 - val_loss: 0.0042\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 469us/step - loss: 0.0091 - val_loss: 0.0020\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 472us/step - loss: 0.0059 - val_loss: 0.0014\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 468us/step - loss: 0.0039 - val_loss: 0.0036\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 470us/step - loss: 0.0029 - val_loss: 0.0025\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 469us/step - loss: 0.0020 - val_loss: 0.0012\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 472us/step - loss: 0.0014 - val_loss: 9.6541e-04\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 471us/step - loss: 9.9095e-04 - val_loss: 0.0013\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 469us/step - loss: 8.4333e-04 - val_loss: 0.0010\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 470us/step - loss: 8.2200e-04 - val_loss: 8.5000e-04\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 471us/step - loss: 7.9925e-04 - val_loss: 8.0601e-04\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 469us/step - loss: 7.5677e-04 - val_loss: 8.7417e-04\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 469us/step - loss: 7.3567e-04 - val_loss: 8.4819e-04\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 468us/step - loss: 7.2054e-04 - val_loss: 7.1952e-04\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 470us/step - loss: 7.1845e-04 - val_loss: 7.5361e-04\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 470us/step - loss: 6.9206e-04 - val_loss: 6.9910e-04\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 470us/step - loss: 6.7910e-04 - val_loss: 7.7728e-04\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 470us/step - loss: 6.6334e-04 - val_loss: 6.8138e-04\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 469us/step - loss: 6.5290e-04 - val_loss: 7.0151e-04\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 468us/step - loss: 6.4525e-04 - val_loss: 6.6699e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 470us/step - loss: 6.3393e-04 - val_loss: 6.5891e-04\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 468us/step - loss: 6.1913e-04 - val_loss: 6.5358e-04\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 473us/step - loss: 6.2112e-04 - val_loss: 6.6420e-04\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 469us/step - loss: 6.2264e-04 - val_loss: 0.0012\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 34s 8ms/step - loss: 0.5931 - val_loss: 0.0318\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.1071 - val_loss: 0.1775\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0938 - val_loss: 0.0425\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0686 - val_loss: 0.0095\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0572 - val_loss: 0.0209\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0290 - val_loss: 0.0122\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0101 - val_loss: 0.0205\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0053 - val_loss: 0.0020\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0027 - val_loss: 0.0034\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0025 - val_loss: 0.0026\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0021 - val_loss: 0.0034\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 397us/step - loss: 0.0020 - val_loss: 0.0019\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0018 - val_loss: 0.0014\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0017 - val_loss: 0.0012\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0016 - val_loss: 0.0012\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0015 - val_loss: 0.0012\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0014 - val_loss: 0.0011\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0013 - val_loss: 0.0014\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0012 - val_loss: 9.7488e-04\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 395us/step - loss: 0.0012 - val_loss: 0.0011\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 399us/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0012 - val_loss: 0.0010\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 396us/step - loss: 0.0012 - val_loss: 8.5927e-04\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 34s 8ms/step - loss: 0.5540 - val_loss: 0.0312\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 0.0641 - val_loss: 0.0407\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 390us/step - loss: 0.0640 - val_loss: 0.0408\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 390us/step - loss: 0.0642 - val_loss: 0.0393\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0637 - val_loss: 0.0356\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0636 - val_loss: 0.0428\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0635 - val_loss: 0.0371\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0634 - val_loss: 0.0407\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 398us/step - loss: 0.0632 - val_loss: 0.0372\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0631 - val_loss: 0.0464\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0632 - val_loss: 0.0376\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 0.0629 - val_loss: 0.0308\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 0.0629 - val_loss: 0.0411\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 390us/step - loss: 0.0627 - val_loss: 0.0308\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 390us/step - loss: 0.0627 - val_loss: 0.0409\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0625 - val_loss: 0.0420\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 392us/step - loss: 0.0623 - val_loss: 0.0362\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 0.0622 - val_loss: 0.0367\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 391us/step - loss: 0.0620 - val_loss: 0.0314\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 394us/step - loss: 0.0623 - val_loss: 0.0347\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 389us/step - loss: 0.0618 - val_loss: 0.0343\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 393us/step - loss: 0.0618 - val_loss: 0.0326\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 389us/step - loss: 0.0616 - val_loss: 0.0304\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 390us/step - loss: 0.0616 - val_loss: 0.0374\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 35s 9ms/step - loss: 0.0882 - val_loss: 0.0334\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0654 - val_loss: 0.0389\n",
      "Epoch 3/24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 2s 455us/step - loss: 0.0653 - val_loss: 0.0356\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0653 - val_loss: 0.0346\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0655 - val_loss: 0.0443\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0652 - val_loss: 0.0390\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0652 - val_loss: 0.0352\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0651 - val_loss: 0.0402\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0649 - val_loss: 0.0350\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 456us/step - loss: 0.0649 - val_loss: 0.0390\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0648 - val_loss: 0.0364\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 456us/step - loss: 0.0647 - val_loss: 0.0341\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 456us/step - loss: 0.0648 - val_loss: 0.0381\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0647 - val_loss: 0.0400\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 456us/step - loss: 0.0646 - val_loss: 0.0380\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 455us/step - loss: 0.0647 - val_loss: 0.0438\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 456us/step - loss: 0.0646 - val_loss: 0.0409\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0645 - val_loss: 0.0382\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 455us/step - loss: 0.0644 - val_loss: 0.0383\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0643 - val_loss: 0.0403\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 455us/step - loss: 0.0643 - val_loss: 0.0358\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 455us/step - loss: 0.0642 - val_loss: 0.0351\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0643 - val_loss: 0.0318\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0643 - val_loss: 0.0374\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 35s 9ms/step - loss: 0.1214 - val_loss: 0.0427\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 461us/step - loss: 0.0678 - val_loss: 0.0444\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 461us/step - loss: 0.0677 - val_loss: 0.0415\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 461us/step - loss: 0.0671 - val_loss: 0.0422\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 459us/step - loss: 0.0672 - val_loss: 0.0422\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0667 - val_loss: 0.0461\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 464us/step - loss: 0.0665 - val_loss: 0.0397\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0663 - val_loss: 0.0374\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0667 - val_loss: 0.0283\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 459us/step - loss: 0.0664 - val_loss: 0.0298\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0657 - val_loss: 0.0402\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0656 - val_loss: 0.0453\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0657 - val_loss: 0.0474\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0654 - val_loss: 0.0475\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 459us/step - loss: 0.0654 - val_loss: 0.0364\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 461us/step - loss: 0.0647 - val_loss: 0.0446\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0644 - val_loss: 0.0356\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0642 - val_loss: 0.0472\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 461us/step - loss: 0.0642 - val_loss: 0.0374\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0638 - val_loss: 0.0340\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0636 - val_loss: 0.0399\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 465us/step - loss: 0.0635 - val_loss: 0.0441\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 465us/step - loss: 0.0633 - val_loss: 0.0396\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 462us/step - loss: 0.0631 - val_loss: 0.0457\n",
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/24\n",
      "4059/4059 [==============================] - 36s 9ms/step - loss: 0.0874 - val_loss: 0.0294\n",
      "Epoch 2/24\n",
      "4059/4059 [==============================] - 2s 455us/step - loss: 0.0676 - val_loss: 0.0458\n",
      "Epoch 3/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0670 - val_loss: 0.0314\n",
      "Epoch 4/24\n",
      "4059/4059 [==============================] - 2s 460us/step - loss: 0.0667 - val_loss: 0.0464\n",
      "Epoch 5/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0662 - val_loss: 0.0434\n",
      "Epoch 6/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0655 - val_loss: 0.0455\n",
      "Epoch 7/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0655 - val_loss: 0.0342\n",
      "Epoch 8/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0649 - val_loss: 0.0443\n",
      "Epoch 9/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0644 - val_loss: 0.0394\n",
      "Epoch 10/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0639 - val_loss: 0.0363\n",
      "Epoch 11/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0632 - val_loss: 0.0400\n",
      "Epoch 12/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0631 - val_loss: 0.0386\n",
      "Epoch 13/24\n",
      "4059/4059 [==============================] - 2s 459us/step - loss: 0.0624 - val_loss: 0.0303\n",
      "Epoch 14/24\n",
      "4059/4059 [==============================] - 2s 459us/step - loss: 0.0619 - val_loss: 0.0381\n",
      "Epoch 15/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0621 - val_loss: 0.0366\n",
      "Epoch 16/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0610 - val_loss: 0.0359\n",
      "Epoch 17/24\n",
      "4059/4059 [==============================] - 2s 459us/step - loss: 0.0605 - val_loss: 0.0379\n",
      "Epoch 18/24\n",
      "4059/4059 [==============================] - 2s 458us/step - loss: 0.0602 - val_loss: 0.0411\n",
      "Epoch 19/24\n",
      "4059/4059 [==============================] - 2s 459us/step - loss: 0.0594 - val_loss: 0.0330\n",
      "Epoch 20/24\n",
      "4059/4059 [==============================] - 2s 462us/step - loss: 0.0589 - val_loss: 0.0351\n",
      "Epoch 21/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0585 - val_loss: 0.0450\n",
      "Epoch 22/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0579 - val_loss: 0.0367\n",
      "Epoch 23/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0573 - val_loss: 0.0330\n",
      "Epoch 24/24\n",
      "4059/4059 [==============================] - 2s 457us/step - loss: 0.0570 - val_loss: 0.0283\n"
     ]
    }
   ],
   "source": [
    "best_models = breed_population(X_train, Y_train, generations=20, population_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.003633963642641902,\n",
       " 0.0010908538242802024,\n",
       " 0.0011943696299567819,\n",
       " 0.0012956435093656182,\n",
       " 0.0006324644782580435,\n",
       " 0.0008870841702446342,\n",
       " 0.000497878179885447,\n",
       " 0.0005400548106990755,\n",
       " 0.0005390173173509538,\n",
       " 0.000494978332426399,\n",
       " 0.0004806231299880892,\n",
       " 0.00047732575330883265,\n",
       " 0.0004766011843457818,\n",
       " 0.00046109987306408584,\n",
       " 0.0004170116735622287,\n",
       " 0.00038028950802981853,\n",
       " 0.0003966812219005078,\n",
       " 0.000375769886886701,\n",
       " 0.0003561267803888768,\n",
       " 0.0003388232726138085,\n",
       " 0.0003711828903760761,\n",
       " 0.0003178548067808151,\n",
       " 0.00031263864366337657,\n",
       " 0.00030783069087192416]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[0][1].history['val_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimal parameters\n",
      "_______________________\n",
      "density: 222\n",
      "shuffle: True\n",
      "activation: relu\n",
      "twice: False\n",
      "lstmsize: 138\n",
      "optimizer: adam\n"
     ]
    }
   ],
   "source": [
    "print('optimal parameters')\n",
    "print('_______________________')\n",
    "for key,val in best_models[0][2].items():\n",
    "    if key != 'x' and key != 'y': print(f'{key}: {val}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_155\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_255 (LSTM)              (None, 138)               79488     \n",
      "_________________________________________________________________\n",
      "dense_565 (Dense)            (None, 222)               30858     \n",
      "_________________________________________________________________\n",
      "dense_566 (Dense)            (None, 1)                 223       \n",
      "=================================================================\n",
      "Total params: 110,569\n",
      "Trainable params: 110,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_models[0][0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_checkpoint = ModelCheckpoint(\n",
    "    filepath='./checkpoints/IBM.{epoch}-{val_loss}.hdf5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = best_models[0][2]\n",
    "params['x'] = X_train\n",
    "params['y'] = Y_train\n",
    "params['epochs'] = 2000\n",
    "params['callbacks'] = [ibm_checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4059 samples, validate on 451 samples\n",
      "Epoch 1/2000\n",
      "4059/4059 [==============================] - 34s 8ms/step - loss: 0.0745 - val_loss: 0.0034\n",
      "Epoch 2/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 0.0072 - val_loss: 7.3033e-04\n",
      "Epoch 3/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 0.0027 - val_loss: 5.1355e-04\n",
      "Epoch 4/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 0.0013 - val_loss: 7.9419e-04\n",
      "Epoch 5/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 8.2179e-04 - val_loss: 4.7648e-04\n",
      "Epoch 6/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 6.6168e-04 - val_loss: 8.4220e-04\n",
      "Epoch 7/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 5.8230e-04 - val_loss: 4.6211e-04\n",
      "Epoch 8/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 5.2410e-04 - val_loss: 5.2124e-04\n",
      "Epoch 9/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 4.8948e-04 - val_loss: 5.6076e-04\n",
      "Epoch 10/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 4.7734e-04 - val_loss: 4.6800e-04\n",
      "Epoch 11/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 4.6022e-04 - val_loss: 4.4554e-04\n",
      "Epoch 12/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 4.4609e-04 - val_loss: 4.2474e-04\n",
      "Epoch 13/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 4.3327e-04 - val_loss: 4.2385e-04\n",
      "Epoch 14/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 4.1926e-04 - val_loss: 4.0407e-04\n",
      "Epoch 15/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 4.0720e-04 - val_loss: 4.2036e-04\n",
      "Epoch 16/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 3.9907e-04 - val_loss: 4.0317e-04\n",
      "Epoch 17/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 3.8507e-04 - val_loss: 3.7779e-04\n",
      "Epoch 18/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 3.7893e-04 - val_loss: 3.7191e-04\n",
      "Epoch 19/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 3.7422e-04 - val_loss: 3.6016e-04\n",
      "Epoch 20/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 3.6083e-04 - val_loss: 3.5742e-04\n",
      "Epoch 21/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 3.5418e-04 - val_loss: 3.4807e-04\n",
      "Epoch 22/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 3.4785e-04 - val_loss: 3.5745e-04\n",
      "Epoch 23/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 3.4757e-04 - val_loss: 3.4663e-04\n",
      "Epoch 24/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 3.4434e-04 - val_loss: 3.4444e-04\n",
      "Epoch 25/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 3.3508e-04 - val_loss: 3.2746e-04\n",
      "Epoch 26/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 3.2784e-04 - val_loss: 3.1528e-04\n",
      "Epoch 27/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 3.2209e-04 - val_loss: 3.2219e-04\n",
      "Epoch 28/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 3.2156e-04 - val_loss: 3.1783e-04\n",
      "Epoch 29/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 3.2071e-04 - val_loss: 3.2347e-04\n",
      "Epoch 30/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 3.1380e-04 - val_loss: 3.2759e-04\n",
      "Epoch 31/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 3.2661e-04 - val_loss: 3.0286e-04\n",
      "Epoch 32/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 3.1110e-04 - val_loss: 3.0708e-04\n",
      "Epoch 33/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 3.0681e-04 - val_loss: 2.9716e-04\n",
      "Epoch 34/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 3.0059e-04 - val_loss: 2.9739e-04\n",
      "Epoch 35/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 3.0149e-04 - val_loss: 2.9244e-04\n",
      "Epoch 36/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 3.0350e-04 - val_loss: 3.1452e-04\n",
      "Epoch 37/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.9893e-04 - val_loss: 2.8818e-04\n",
      "Epoch 38/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.9259e-04 - val_loss: 3.0302e-04\n",
      "Epoch 39/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.9618e-04 - val_loss: 2.9020e-04\n",
      "Epoch 40/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 3.0468e-04 - val_loss: 2.9282e-04\n",
      "Epoch 41/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 2.9529e-04 - val_loss: 3.4375e-04\n",
      "Epoch 42/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.9805e-04 - val_loss: 2.7948e-04\n",
      "Epoch 43/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.9439e-04 - val_loss: 2.8566e-04\n",
      "Epoch 44/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.8817e-04 - val_loss: 2.9139e-04\n",
      "Epoch 45/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.8545e-04 - val_loss: 3.0065e-04\n",
      "Epoch 46/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.8959e-04 - val_loss: 3.2602e-04\n",
      "Epoch 47/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.8146e-04 - val_loss: 2.7483e-04\n",
      "Epoch 48/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.7675e-04 - val_loss: 2.7076e-04\n",
      "Epoch 49/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.7733e-04 - val_loss: 2.8280e-04\n",
      "Epoch 50/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.7168e-04 - val_loss: 2.6838e-04\n",
      "Epoch 51/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.7495e-04 - val_loss: 2.6687e-04\n",
      "Epoch 52/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.7841e-04 - val_loss: 3.0494e-04\n",
      "Epoch 53/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.8073e-04 - val_loss: 3.1861e-04\n",
      "Epoch 54/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.7054e-04 - val_loss: 2.9531e-04\n",
      "Epoch 55/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 2.6960e-04 - val_loss: 3.2674e-04\n",
      "Epoch 56/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.8010e-04 - val_loss: 2.6956e-04\n",
      "Epoch 57/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.6885e-04 - val_loss: 2.6525e-04\n",
      "Epoch 58/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.6546e-04 - val_loss: 2.5883e-04\n",
      "Epoch 59/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.6364e-04 - val_loss: 2.6074e-04\n",
      "Epoch 60/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.5922e-04 - val_loss: 2.6188e-04\n",
      "Epoch 61/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 2.5814e-04 - val_loss: 2.6662e-04\n",
      "Epoch 62/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.6313e-04 - val_loss: 2.5641e-04\n",
      "Epoch 63/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 2.6784e-04 - val_loss: 2.7765e-04\n",
      "Epoch 64/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.6921e-04 - val_loss: 2.6374e-04\n",
      "Epoch 65/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.5860e-04 - val_loss: 2.5215e-04\n",
      "Epoch 66/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.5562e-04 - val_loss: 2.5297e-04\n",
      "Epoch 67/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.5507e-04 - val_loss: 2.6059e-04\n",
      "Epoch 68/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.5184e-04 - val_loss: 2.4963e-04\n",
      "Epoch 69/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.6160e-04 - val_loss: 2.6382e-04\n",
      "Epoch 70/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.5374e-04 - val_loss: 2.4860e-04\n",
      "Epoch 71/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 2.5902e-04 - val_loss: 2.5712e-04\n",
      "Epoch 72/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.5658e-04 - val_loss: 2.9683e-04\n",
      "Epoch 73/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 2.5354e-04 - val_loss: 2.7088e-04\n",
      "Epoch 74/2000\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 2.4970e-04 - val_loss: 2.4615e-04\n",
      "Epoch 75/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.4465e-04 - val_loss: 2.5824e-04\n",
      "Epoch 76/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.5034e-04 - val_loss: 3.1691e-04\n",
      "Epoch 77/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 2.4604e-04 - val_loss: 2.4292e-04\n",
      "Epoch 78/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 2.4626e-04 - val_loss: 2.4871e-04\n",
      "Epoch 79/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 2.4271e-04 - val_loss: 2.4198e-04\n",
      "Epoch 80/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.4301e-04 - val_loss: 2.4555e-04\n",
      "Epoch 81/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.4834e-04 - val_loss: 2.7543e-04\n",
      "Epoch 82/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.4883e-04 - val_loss: 2.6087e-04\n",
      "Epoch 83/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 2.5630e-04 - val_loss: 3.0476e-04\n",
      "Epoch 84/2000\n",
      "4059/4059 [==============================] - 1s 271us/step - loss: 2.8170e-04 - val_loss: 2.4030e-04\n",
      "Epoch 85/2000\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 2.4883e-04 - val_loss: 2.3866e-04\n",
      "Epoch 86/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 2.3900e-04 - val_loss: 2.4095e-04\n",
      "Epoch 87/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 2.4395e-04 - val_loss: 2.3847e-04\n",
      "Epoch 88/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 2.4050e-04 - val_loss: 2.3677e-04\n",
      "Epoch 89/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 2.4334e-04 - val_loss: 2.4289e-04\n",
      "Epoch 90/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.4120e-04 - val_loss: 2.5034e-04\n",
      "Epoch 91/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 2.3625e-04 - val_loss: 2.4734e-04\n",
      "Epoch 92/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 2.3538e-04 - val_loss: 2.4480e-04\n",
      "Epoch 93/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.3458e-04 - val_loss: 2.3463e-04\n",
      "Epoch 94/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 2.3703e-04 - val_loss: 2.7213e-04\n",
      "Epoch 95/2000\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 2.3886e-04 - val_loss: 2.3481e-04\n",
      "Epoch 96/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 2.3708e-04 - val_loss: 2.3402e-04\n",
      "Epoch 97/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.3572e-04 - val_loss: 2.3955e-04\n",
      "Epoch 98/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.4810e-04 - val_loss: 2.6775e-04\n",
      "Epoch 99/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 2.3962e-04 - val_loss: 2.3241e-04\n",
      "Epoch 100/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.4175e-04 - val_loss: 2.4387e-04\n",
      "Epoch 101/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.3782e-04 - val_loss: 2.6450e-04\n",
      "Epoch 102/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.3228e-04 - val_loss: 2.3133e-04\n",
      "Epoch 103/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.3987e-04 - val_loss: 2.3695e-04\n",
      "Epoch 104/2000\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 2.4332e-04 - val_loss: 2.5656e-04\n",
      "Epoch 105/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.3215e-04 - val_loss: 2.3275e-04\n",
      "Epoch 106/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 2.3304e-04 - val_loss: 2.2838e-04\n",
      "Epoch 107/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 2.3233e-04 - val_loss: 2.2876e-04\n",
      "Epoch 108/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.3042e-04 - val_loss: 2.5411e-04\n",
      "Epoch 109/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 2.3868e-04 - val_loss: 2.4266e-04\n",
      "Epoch 110/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.3366e-04 - val_loss: 2.2634e-04\n",
      "Epoch 111/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.2927e-04 - val_loss: 2.2524e-04\n",
      "Epoch 112/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.2795e-04 - val_loss: 2.2488e-04\n",
      "Epoch 113/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.3269e-04 - val_loss: 2.2582e-04\n",
      "Epoch 114/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.2617e-04 - val_loss: 2.2390e-04\n",
      "Epoch 115/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.2799e-04 - val_loss: 2.5609e-04\n",
      "Epoch 116/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.4406e-04 - val_loss: 2.4943e-04\n",
      "Epoch 117/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.3928e-04 - val_loss: 2.7444e-04\n",
      "Epoch 118/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.3150e-04 - val_loss: 2.2238e-04\n",
      "Epoch 119/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.2886e-04 - val_loss: 2.3556e-04\n",
      "Epoch 120/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 2.3673e-04 - val_loss: 3.2207e-04\n",
      "Epoch 121/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 2.4814e-04 - val_loss: 2.4866e-04\n",
      "Epoch 122/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.4264e-04 - val_loss: 2.2150e-04\n",
      "Epoch 123/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.5919e-04 - val_loss: 3.9943e-04\n",
      "Epoch 124/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.5553e-04 - val_loss: 2.4339e-04\n",
      "Epoch 125/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.3302e-04 - val_loss: 2.2030e-04\n",
      "Epoch 126/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.2700e-04 - val_loss: 2.4915e-04\n",
      "Epoch 127/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.3219e-04 - val_loss: 2.3475e-04\n",
      "Epoch 128/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.3079e-04 - val_loss: 2.7352e-04\n",
      "Epoch 129/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.3182e-04 - val_loss: 2.4038e-04\n",
      "Epoch 130/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.2536e-04 - val_loss: 2.1943e-04\n",
      "Epoch 131/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.2828e-04 - val_loss: 2.2947e-04\n",
      "Epoch 132/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.4088e-04 - val_loss: 2.3532e-04\n",
      "Epoch 133/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 2.3250e-04 - val_loss: 2.9504e-04\n",
      "Epoch 134/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.3730e-04 - val_loss: 2.4790e-04\n",
      "Epoch 135/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.3837e-04 - val_loss: 2.1863e-04\n",
      "Epoch 136/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 2.2371e-04 - val_loss: 2.1682e-04\n",
      "Epoch 137/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1844e-04 - val_loss: 2.1529e-04\n",
      "Epoch 138/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.3068e-04 - val_loss: 2.4683e-04\n",
      "Epoch 139/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.2345e-04 - val_loss: 2.3649e-04\n",
      "Epoch 140/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1951e-04 - val_loss: 2.2783e-04\n",
      "Epoch 141/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.2579e-04 - val_loss: 2.3117e-04\n",
      "Epoch 142/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1884e-04 - val_loss: 2.2310e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 143/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.1429e-04 - val_loss: 2.1547e-04\n",
      "Epoch 144/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1567e-04 - val_loss: 2.1891e-04\n",
      "Epoch 145/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1622e-04 - val_loss: 2.2941e-04\n",
      "Epoch 146/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1965e-04 - val_loss: 2.1181e-04\n",
      "Epoch 147/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.2910e-04 - val_loss: 3.1654e-04\n",
      "Epoch 148/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.2955e-04 - val_loss: 2.4460e-04\n",
      "Epoch 149/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.2125e-04 - val_loss: 2.4978e-04\n",
      "Epoch 150/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.2904e-04 - val_loss: 2.1286e-04\n",
      "Epoch 151/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.1164e-04 - val_loss: 2.1096e-04\n",
      "Epoch 152/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.1789e-04 - val_loss: 2.3384e-04\n",
      "Epoch 153/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.5109e-04 - val_loss: 3.5765e-04\n",
      "Epoch 154/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.4349e-04 - val_loss: 2.3084e-04\n",
      "Epoch 155/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.3370e-04 - val_loss: 2.1118e-04\n",
      "Epoch 156/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.1850e-04 - val_loss: 2.5516e-04\n",
      "Epoch 157/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.2649e-04 - val_loss: 2.1126e-04\n",
      "Epoch 158/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.5976e-04 - val_loss: 2.2484e-04\n",
      "Epoch 159/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 2.4851e-04 - val_loss: 2.6982e-04\n",
      "Epoch 160/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.2548e-04 - val_loss: 2.2953e-04\n",
      "Epoch 161/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1469e-04 - val_loss: 2.0751e-04\n",
      "Epoch 162/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 2.1173e-04 - val_loss: 2.1322e-04\n",
      "Epoch 163/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1451e-04 - val_loss: 2.0744e-04\n",
      "Epoch 164/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.1115e-04 - val_loss: 2.0784e-04\n",
      "Epoch 165/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.0930e-04 - val_loss: 2.0936e-04\n",
      "Epoch 166/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.0902e-04 - val_loss: 2.1148e-04\n",
      "Epoch 167/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.1277e-04 - val_loss: 2.1015e-04\n",
      "Epoch 168/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1797e-04 - val_loss: 2.0877e-04\n",
      "Epoch 169/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.0735e-04 - val_loss: 2.2389e-04\n",
      "Epoch 170/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.1196e-04 - val_loss: 2.2474e-04\n",
      "Epoch 171/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.1460e-04 - val_loss: 2.0603e-04\n",
      "Epoch 172/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.1026e-04 - val_loss: 2.1364e-04\n",
      "Epoch 173/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.1084e-04 - val_loss: 2.0276e-04\n",
      "Epoch 174/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.0626e-04 - val_loss: 2.0412e-04\n",
      "Epoch 175/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 2.0833e-04 - val_loss: 2.0368e-04\n",
      "Epoch 176/2000\n",
      "4059/4059 [==============================] - 1s 272us/step - loss: 2.0908e-04 - val_loss: 2.1295e-04\n",
      "Epoch 177/2000\n",
      "4059/4059 [==============================] - 1s 266us/step - loss: 2.1015e-04 - val_loss: 2.1279e-04\n",
      "Epoch 178/2000\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 2.0653e-04 - val_loss: 2.0127e-04\n",
      "Epoch 179/2000\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 2.0435e-04 - val_loss: 2.0049e-04\n",
      "Epoch 180/2000\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 2.0458e-04 - val_loss: 2.0284e-04\n",
      "Epoch 181/2000\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 2.0320e-04 - val_loss: 2.0116e-04\n",
      "Epoch 182/2000\n",
      "4059/4059 [==============================] - 1s 271us/step - loss: 2.0187e-04 - val_loss: 2.0342e-04\n",
      "Epoch 183/2000\n",
      "4059/4059 [==============================] - 1s 265us/step - loss: 2.0632e-04 - val_loss: 1.9912e-04\n",
      "Epoch 184/2000\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 2.2367e-04 - val_loss: 2.0108e-04\n",
      "Epoch 185/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 2.0795e-04 - val_loss: 3.3986e-04\n",
      "Epoch 186/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 2.5646e-04 - val_loss: 2.0982e-04\n",
      "Epoch 187/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 2.1525e-04 - val_loss: 2.0338e-04\n",
      "Epoch 188/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 2.1679e-04 - val_loss: 2.0635e-04\n",
      "Epoch 189/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.0268e-04 - val_loss: 2.0230e-04\n",
      "Epoch 190/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 2.0086e-04 - val_loss: 1.9908e-04\n",
      "Epoch 191/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.0335e-04 - val_loss: 1.9746e-04\n",
      "Epoch 192/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 2.1078e-04 - val_loss: 2.1836e-04\n",
      "Epoch 193/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 2.1043e-04 - val_loss: 2.0795e-04\n",
      "Epoch 194/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 2.0575e-04 - val_loss: 2.0131e-04\n",
      "Epoch 195/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.9993e-04 - val_loss: 1.9870e-04\n",
      "Epoch 196/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 2.0159e-04 - val_loss: 2.0130e-04\n",
      "Epoch 197/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 2.1572e-04 - val_loss: 2.4771e-04\n",
      "Epoch 198/2000\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 2.1421e-04 - val_loss: 1.9843e-04\n",
      "Epoch 199/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 2.2492e-04 - val_loss: 3.8811e-04\n",
      "Epoch 200/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 2.5099e-04 - val_loss: 2.0452e-04\n",
      "Epoch 201/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 2.2016e-04 - val_loss: 1.9713e-04\n",
      "Epoch 202/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 2.1298e-04 - val_loss: 2.1953e-04\n",
      "Epoch 203/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 2.1741e-04 - val_loss: 2.3928e-04\n",
      "Epoch 204/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 2.1047e-04 - val_loss: 2.0264e-04\n",
      "Epoch 205/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 2.0333e-04 - val_loss: 2.0152e-04\n",
      "Epoch 206/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 2.0432e-04 - val_loss: 1.9446e-04\n",
      "Epoch 207/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.9945e-04 - val_loss: 1.9496e-04\n",
      "Epoch 208/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 2.0051e-04 - val_loss: 2.0901e-04\n",
      "Epoch 209/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 2.0488e-04 - val_loss: 1.9932e-04\n",
      "Epoch 210/2000\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 2.1600e-04 - val_loss: 2.4651e-04\n",
      "Epoch 211/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 2.1568e-04 - val_loss: 2.3157e-04\n",
      "Epoch 212/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 2.0831e-04 - val_loss: 2.0110e-04\n",
      "Epoch 213/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.2166e-04 - val_loss: 2.2693e-04\n",
      "Epoch 214/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 2.1036e-04 - val_loss: 2.9936e-04\n",
      "Epoch 215/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 2.2945e-04 - val_loss: 2.0940e-04\n",
      "Epoch 216/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.3122e-04 - val_loss: 1.9276e-04\n",
      "Epoch 217/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 2.3048e-04 - val_loss: 2.2132e-04\n",
      "Epoch 218/2000\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 2.0765e-04 - val_loss: 2.2504e-04\n",
      "Epoch 219/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 2.0823e-04 - val_loss: 1.9312e-04\n",
      "Epoch 220/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 2.1150e-04 - val_loss: 2.1304e-04\n",
      "Epoch 221/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 2.0150e-04 - val_loss: 2.1431e-04\n",
      "Epoch 222/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.9533e-04 - val_loss: 1.9858e-04\n",
      "Epoch 223/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 2.0168e-04 - val_loss: 2.0196e-04\n",
      "Epoch 224/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 2.1639e-04 - val_loss: 1.9218e-04\n",
      "Epoch 225/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.9639e-04 - val_loss: 1.9324e-04\n",
      "Epoch 226/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.9430e-04 - val_loss: 1.9128e-04\n",
      "Epoch 227/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.9617e-04 - val_loss: 1.9411e-04\n",
      "Epoch 228/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.9846e-04 - val_loss: 2.2634e-04\n",
      "Epoch 229/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.0331e-04 - val_loss: 2.0768e-04\n",
      "Epoch 230/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.9416e-04 - val_loss: 2.3831e-04\n",
      "Epoch 231/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.0093e-04 - val_loss: 2.2421e-04\n",
      "Epoch 232/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.9508e-04 - val_loss: 2.1828e-04\n",
      "Epoch 233/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.9358e-04 - val_loss: 2.0342e-04\n",
      "Epoch 234/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 2.1723e-04 - val_loss: 2.2031e-04\n",
      "Epoch 235/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 2.0377e-04 - val_loss: 2.0112e-04\n",
      "Epoch 236/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.9976e-04 - val_loss: 1.9148e-04\n",
      "Epoch 237/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.9972e-04 - val_loss: 2.2412e-04\n",
      "Epoch 238/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.0753e-04 - val_loss: 2.1258e-04\n",
      "Epoch 239/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.1255e-04 - val_loss: 1.9993e-04\n",
      "Epoch 240/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 2.0130e-04 - val_loss: 2.4878e-04\n",
      "Epoch 241/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.0858e-04 - val_loss: 2.0983e-04\n",
      "Epoch 242/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.9885e-04 - val_loss: 2.0550e-04\n",
      "Epoch 243/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.9937e-04 - val_loss: 1.9617e-04\n",
      "Epoch 244/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.9822e-04 - val_loss: 1.9307e-04\n",
      "Epoch 245/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.0121e-04 - val_loss: 2.1281e-04\n",
      "Epoch 246/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 2.0990e-04 - val_loss: 1.9073e-04\n",
      "Epoch 247/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.9645e-04 - val_loss: 1.9987e-04\n",
      "Epoch 248/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.9043e-04 - val_loss: 2.0013e-04\n",
      "Epoch 249/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.9989e-04 - val_loss: 2.7585e-04\n",
      "Epoch 250/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.2342e-04 - val_loss: 2.4506e-04\n",
      "Epoch 251/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.2715e-04 - val_loss: 3.1474e-04\n",
      "Epoch 252/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.6005e-04 - val_loss: 3.1137e-04\n",
      "Epoch 253/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 2.5686e-04 - val_loss: 1.9166e-04\n",
      "Epoch 254/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 2.1959e-04 - val_loss: 2.1570e-04\n",
      "Epoch 255/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.2632e-04 - val_loss: 1.9847e-04\n",
      "Epoch 256/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 2.0006e-04 - val_loss: 1.9538e-04\n",
      "Epoch 257/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.9071e-04 - val_loss: 2.2532e-04\n",
      "Epoch 258/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.9604e-04 - val_loss: 1.8766e-04\n",
      "Epoch 259/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8927e-04 - val_loss: 2.0201e-04\n",
      "Epoch 260/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.9061e-04 - val_loss: 1.8907e-04\n",
      "Epoch 261/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.8768e-04 - val_loss: 1.8832e-04\n",
      "Epoch 262/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.9197e-04 - val_loss: 1.8565e-04\n",
      "Epoch 263/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.8516e-04 - val_loss: 2.0977e-04\n",
      "Epoch 264/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.8967e-04 - val_loss: 1.8701e-04\n",
      "Epoch 265/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.9058e-04 - val_loss: 1.8456e-04\n",
      "Epoch 266/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.8722e-04 - val_loss: 1.8432e-04\n",
      "Epoch 267/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.9200e-04 - val_loss: 1.9668e-04\n",
      "Epoch 268/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 2.0990e-04 - val_loss: 1.8401e-04\n",
      "Epoch 269/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.9557e-04 - val_loss: 2.0743e-04\n",
      "Epoch 270/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 2.0200e-04 - val_loss: 2.2536e-04\n",
      "Epoch 271/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.9935e-04 - val_loss: 1.8961e-04\n",
      "Epoch 272/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8661e-04 - val_loss: 1.9455e-04\n",
      "Epoch 273/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.8623e-04 - val_loss: 1.8586e-04\n",
      "Epoch 274/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.8575e-04 - val_loss: 1.9938e-04\n",
      "Epoch 275/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8998e-04 - val_loss: 2.2490e-04\n",
      "Epoch 276/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 1.8723e-04 - val_loss: 1.8630e-04\n",
      "Epoch 277/2000\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 1.8560e-04 - val_loss: 1.9124e-04\n",
      "Epoch 278/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 1.8423e-04 - val_loss: 1.8542e-04\n",
      "Epoch 279/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.9119e-04 - val_loss: 1.8289e-04\n",
      "Epoch 280/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.8426e-04 - val_loss: 1.8440e-04\n",
      "Epoch 281/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.9370e-04 - val_loss: 2.4325e-04\n",
      "Epoch 282/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.9149e-04 - val_loss: 1.8466e-04\n",
      "Epoch 283/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8248e-04 - val_loss: 1.8635e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 284/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8904e-04 - val_loss: 1.8222e-04\n",
      "Epoch 285/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8783e-04 - val_loss: 1.8378e-04\n",
      "Epoch 286/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.8411e-04 - val_loss: 1.8164e-04\n",
      "Epoch 287/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8528e-04 - val_loss: 2.0192e-04\n",
      "Epoch 288/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.8396e-04 - val_loss: 1.9143e-04\n",
      "Epoch 289/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.8678e-04 - val_loss: 2.0106e-04\n",
      "Epoch 290/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.8922e-04 - val_loss: 2.1376e-04\n",
      "Epoch 291/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.9362e-04 - val_loss: 1.8600e-04\n",
      "Epoch 292/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.8396e-04 - val_loss: 1.8985e-04\n",
      "Epoch 293/2000\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 1.8663e-04 - val_loss: 1.8117e-04\n",
      "Epoch 294/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.8324e-04 - val_loss: 1.8926e-04\n",
      "Epoch 295/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.8446e-04 - val_loss: 1.8121e-04\n",
      "Epoch 296/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 1.8358e-04 - val_loss: 1.8292e-04\n",
      "Epoch 297/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8506e-04 - val_loss: 1.8240e-04\n",
      "Epoch 298/2000\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 1.8304e-04 - val_loss: 1.9719e-04\n",
      "Epoch 299/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8262e-04 - val_loss: 1.8101e-04\n",
      "Epoch 300/2000\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 1.8306e-04 - val_loss: 1.8935e-04\n",
      "Epoch 301/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.8060e-04 - val_loss: 1.8708e-04\n",
      "Epoch 302/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8193e-04 - val_loss: 1.9179e-04\n",
      "Epoch 303/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.9049e-04 - val_loss: 1.8863e-04\n",
      "Epoch 304/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.0191e-04 - val_loss: 2.6370e-04\n",
      "Epoch 305/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.1647e-04 - val_loss: 1.8178e-04\n",
      "Epoch 306/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9638e-04 - val_loss: 2.1345e-04\n",
      "Epoch 307/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8297e-04 - val_loss: 1.8194e-04\n",
      "Epoch 308/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.8609e-04 - val_loss: 1.9079e-04\n",
      "Epoch 309/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8449e-04 - val_loss: 2.0048e-04\n",
      "Epoch 310/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8448e-04 - val_loss: 1.9808e-04\n",
      "Epoch 311/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8198e-04 - val_loss: 1.8015e-04\n",
      "Epoch 312/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8266e-04 - val_loss: 1.7976e-04\n",
      "Epoch 313/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8199e-04 - val_loss: 1.7991e-04\n",
      "Epoch 314/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8279e-04 - val_loss: 1.8896e-04\n",
      "Epoch 315/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7969e-04 - val_loss: 1.7987e-04\n",
      "Epoch 316/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8627e-04 - val_loss: 2.1591e-04\n",
      "Epoch 317/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.9290e-04 - val_loss: 2.0135e-04\n",
      "Epoch 318/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8683e-04 - val_loss: 1.8256e-04\n",
      "Epoch 319/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8350e-04 - val_loss: 1.8171e-04\n",
      "Epoch 320/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8700e-04 - val_loss: 1.9693e-04\n",
      "Epoch 321/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8161e-04 - val_loss: 1.8053e-04\n",
      "Epoch 322/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8239e-04 - val_loss: 1.8385e-04\n",
      "Epoch 323/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8460e-04 - val_loss: 1.8613e-04\n",
      "Epoch 324/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7947e-04 - val_loss: 1.7956e-04\n",
      "Epoch 325/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9762e-04 - val_loss: 2.0733e-04\n",
      "Epoch 326/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.3339e-04 - val_loss: 2.8196e-04\n",
      "Epoch 327/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 2.0570e-04 - val_loss: 1.8048e-04\n",
      "Epoch 328/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8061e-04 - val_loss: 1.8285e-04\n",
      "Epoch 329/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8256e-04 - val_loss: 1.8455e-04\n",
      "Epoch 330/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.0700e-04 - val_loss: 2.1638e-04\n",
      "Epoch 331/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.0583e-04 - val_loss: 2.2057e-04\n",
      "Epoch 332/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.0222e-04 - val_loss: 2.3173e-04\n",
      "Epoch 333/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.9678e-04 - val_loss: 2.0119e-04\n",
      "Epoch 334/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 2.0577e-04 - val_loss: 1.8722e-04\n",
      "Epoch 335/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1061e-04 - val_loss: 2.3524e-04\n",
      "Epoch 336/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.0513e-04 - val_loss: 2.0396e-04\n",
      "Epoch 337/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8633e-04 - val_loss: 2.0274e-04\n",
      "Epoch 338/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7986e-04 - val_loss: 1.7973e-04\n",
      "Epoch 339/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8095e-04 - val_loss: 1.9225e-04\n",
      "Epoch 340/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8180e-04 - val_loss: 1.7995e-04\n",
      "Epoch 341/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7967e-04 - val_loss: 1.8429e-04\n",
      "Epoch 342/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7802e-04 - val_loss: 1.7936e-04\n",
      "Epoch 343/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7940e-04 - val_loss: 2.0747e-04\n",
      "Epoch 344/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.8366e-04 - val_loss: 1.9140e-04\n",
      "Epoch 345/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8543e-04 - val_loss: 1.7936e-04\n",
      "Epoch 346/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7898e-04 - val_loss: 1.9392e-04\n",
      "Epoch 347/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8920e-04 - val_loss: 1.9310e-04\n",
      "Epoch 348/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8401e-04 - val_loss: 1.8847e-04\n",
      "Epoch 349/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8129e-04 - val_loss: 1.8010e-04\n",
      "Epoch 350/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7864e-04 - val_loss: 1.7902e-04\n",
      "Epoch 351/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7950e-04 - val_loss: 1.8982e-04\n",
      "Epoch 352/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8455e-04 - val_loss: 1.8495e-04\n",
      "Epoch 353/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.1349e-04 - val_loss: 2.2158e-04\n",
      "Epoch 354/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.3335e-04 - val_loss: 2.8612e-04\n",
      "Epoch 355/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.0301e-04 - val_loss: 1.9425e-04\n",
      "Epoch 356/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8691e-04 - val_loss: 2.1499e-04\n",
      "Epoch 357/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9732e-04 - val_loss: 1.7958e-04\n",
      "Epoch 358/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8877e-04 - val_loss: 1.7944e-04\n",
      "Epoch 359/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7876e-04 - val_loss: 1.7947e-04\n",
      "Epoch 360/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7643e-04 - val_loss: 1.7958e-04\n",
      "Epoch 361/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.7667e-04 - val_loss: 1.8116e-04\n",
      "Epoch 362/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8105e-04 - val_loss: 1.8455e-04\n",
      "Epoch 363/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7976e-04 - val_loss: 1.9345e-04\n",
      "Epoch 364/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.0165e-04 - val_loss: 2.3019e-04\n",
      "Epoch 365/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.8702e-04 - val_loss: 1.8600e-04\n",
      "Epoch 366/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7883e-04 - val_loss: 1.8722e-04\n",
      "Epoch 367/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8258e-04 - val_loss: 1.7920e-04\n",
      "Epoch 368/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.9062e-04 - val_loss: 2.3753e-04\n",
      "Epoch 369/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.0013e-04 - val_loss: 1.7983e-04\n",
      "Epoch 370/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.8268e-04 - val_loss: 1.7949e-04\n",
      "Epoch 371/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8585e-04 - val_loss: 1.9187e-04\n",
      "Epoch 372/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8460e-04 - val_loss: 1.9530e-04\n",
      "Epoch 373/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8058e-04 - val_loss: 1.8791e-04\n",
      "Epoch 374/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8073e-04 - val_loss: 1.8745e-04\n",
      "Epoch 375/2000\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 1.8201e-04 - val_loss: 1.9514e-04\n",
      "Epoch 376/2000\n",
      "4059/4059 [==============================] - 1s 270us/step - loss: 1.8754e-04 - val_loss: 2.2006e-04\n",
      "Epoch 377/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.9826e-04 - val_loss: 2.1124e-04\n",
      "Epoch 378/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8742e-04 - val_loss: 2.0684e-04\n",
      "Epoch 379/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9005e-04 - val_loss: 1.8145e-04\n",
      "Epoch 380/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.8249e-04 - val_loss: 1.7890e-04\n",
      "Epoch 381/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7809e-04 - val_loss: 1.8710e-04\n",
      "Epoch 382/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.7668e-04 - val_loss: 1.7925e-04\n",
      "Epoch 383/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7640e-04 - val_loss: 1.8891e-04\n",
      "Epoch 384/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.9383e-04 - val_loss: 2.2795e-04\n",
      "Epoch 385/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8970e-04 - val_loss: 1.8566e-04\n",
      "Epoch 386/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8210e-04 - val_loss: 1.8669e-04\n",
      "Epoch 387/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7862e-04 - val_loss: 1.7890e-04\n",
      "Epoch 388/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7704e-04 - val_loss: 1.7940e-04\n",
      "Epoch 389/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7891e-04 - val_loss: 1.8095e-04\n",
      "Epoch 390/2000\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 1.8977e-04 - val_loss: 1.9955e-04\n",
      "Epoch 391/2000\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 1.8629e-04 - val_loss: 1.7867e-04\n",
      "Epoch 392/2000\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 1.7603e-04 - val_loss: 1.7905e-04\n",
      "Epoch 393/2000\n",
      "4059/4059 [==============================] - 1s 272us/step - loss: 1.7726e-04 - val_loss: 1.9378e-04\n",
      "Epoch 394/2000\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 1.7883e-04 - val_loss: 2.1186e-04\n",
      "Epoch 395/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 2.0087e-04 - val_loss: 1.7838e-04\n",
      "Epoch 396/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.0082e-04 - val_loss: 2.0158e-04\n",
      "Epoch 397/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 2.1560e-04 - val_loss: 2.9955e-04\n",
      "Epoch 398/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1207e-04 - val_loss: 2.4288e-04\n",
      "Epoch 399/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8975e-04 - val_loss: 1.7974e-04\n",
      "Epoch 400/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7543e-04 - val_loss: 1.9655e-04\n",
      "Epoch 401/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8494e-04 - val_loss: 1.8353e-04\n",
      "Epoch 402/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8254e-04 - val_loss: 1.7986e-04\n",
      "Epoch 403/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7758e-04 - val_loss: 1.9069e-04\n",
      "Epoch 404/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7708e-04 - val_loss: 1.7950e-04\n",
      "Epoch 405/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8348e-04 - val_loss: 2.4660e-04\n",
      "Epoch 406/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8826e-04 - val_loss: 2.5506e-04\n",
      "Epoch 407/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.9649e-04 - val_loss: 2.0053e-04\n",
      "Epoch 408/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.9612e-04 - val_loss: 1.9774e-04\n",
      "Epoch 409/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.9899e-04 - val_loss: 1.8144e-04\n",
      "Epoch 410/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8688e-04 - val_loss: 2.0734e-04\n",
      "Epoch 411/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8284e-04 - val_loss: 1.8945e-04\n",
      "Epoch 412/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8221e-04 - val_loss: 1.9433e-04\n",
      "Epoch 413/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8035e-04 - val_loss: 1.9730e-04\n",
      "Epoch 414/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8416e-04 - val_loss: 1.8000e-04\n",
      "Epoch 415/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7981e-04 - val_loss: 1.8627e-04\n",
      "Epoch 416/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7852e-04 - val_loss: 1.8634e-04\n",
      "Epoch 417/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7645e-04 - val_loss: 1.7768e-04\n",
      "Epoch 418/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7582e-04 - val_loss: 1.8257e-04\n",
      "Epoch 419/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8038e-04 - val_loss: 1.7878e-04\n",
      "Epoch 420/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7972e-04 - val_loss: 1.7769e-04\n",
      "Epoch 421/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8364e-04 - val_loss: 1.7955e-04\n",
      "Epoch 422/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8306e-04 - val_loss: 2.0284e-04\n",
      "Epoch 423/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8641e-04 - val_loss: 2.1543e-04\n",
      "Epoch 424/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.9613e-04 - val_loss: 2.4927e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 425/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.9857e-04 - val_loss: 2.2419e-04\n",
      "Epoch 426/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.9181e-04 - val_loss: 1.7991e-04\n",
      "Epoch 427/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8635e-04 - val_loss: 1.8544e-04\n",
      "Epoch 428/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8348e-04 - val_loss: 1.7992e-04\n",
      "Epoch 429/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8121e-04 - val_loss: 2.0436e-04\n",
      "Epoch 430/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8150e-04 - val_loss: 1.8013e-04\n",
      "Epoch 431/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7787e-04 - val_loss: 1.7827e-04\n",
      "Epoch 432/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7659e-04 - val_loss: 1.8461e-04\n",
      "Epoch 433/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8048e-04 - val_loss: 2.0408e-04\n",
      "Epoch 434/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7855e-04 - val_loss: 1.7801e-04\n",
      "Epoch 435/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8161e-04 - val_loss: 1.9769e-04\n",
      "Epoch 436/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7665e-04 - val_loss: 1.7751e-04\n",
      "Epoch 437/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.7995e-04 - val_loss: 1.8673e-04\n",
      "Epoch 438/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8150e-04 - val_loss: 1.7792e-04\n",
      "Epoch 439/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7831e-04 - val_loss: 1.8453e-04\n",
      "Epoch 440/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7807e-04 - val_loss: 1.8470e-04\n",
      "Epoch 441/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7801e-04 - val_loss: 2.0315e-04\n",
      "Epoch 442/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.8510e-04 - val_loss: 1.7811e-04\n",
      "Epoch 443/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7758e-04 - val_loss: 1.7971e-04\n",
      "Epoch 444/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8162e-04 - val_loss: 1.9074e-04\n",
      "Epoch 445/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7548e-04 - val_loss: 1.7871e-04\n",
      "Epoch 446/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7380e-04 - val_loss: 1.7805e-04\n",
      "Epoch 447/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8034e-04 - val_loss: 1.7775e-04\n",
      "Epoch 448/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8055e-04 - val_loss: 1.7800e-04\n",
      "Epoch 449/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7924e-04 - val_loss: 1.8481e-04\n",
      "Epoch 450/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8071e-04 - val_loss: 1.8725e-04\n",
      "Epoch 451/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8459e-04 - val_loss: 1.7818e-04\n",
      "Epoch 452/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7947e-04 - val_loss: 1.8502e-04\n",
      "Epoch 453/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8517e-04 - val_loss: 1.7908e-04\n",
      "Epoch 454/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8212e-04 - val_loss: 1.8562e-04\n",
      "Epoch 455/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8471e-04 - val_loss: 1.9787e-04\n",
      "Epoch 456/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8056e-04 - val_loss: 1.8185e-04\n",
      "Epoch 457/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7544e-04 - val_loss: 1.8476e-04\n",
      "Epoch 458/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8407e-04 - val_loss: 2.5919e-04\n",
      "Epoch 459/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 2.0794e-04 - val_loss: 1.8446e-04\n",
      "Epoch 460/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 2.1262e-04 - val_loss: 2.3088e-04\n",
      "Epoch 461/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.1047e-04 - val_loss: 2.6661e-04\n",
      "Epoch 462/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 2.0557e-04 - val_loss: 2.0112e-04\n",
      "Epoch 463/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8117e-04 - val_loss: 1.9386e-04\n",
      "Epoch 464/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8458e-04 - val_loss: 1.8272e-04\n",
      "Epoch 465/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8000e-04 - val_loss: 1.7760e-04\n",
      "Epoch 466/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7613e-04 - val_loss: 1.8407e-04\n",
      "Epoch 467/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7576e-04 - val_loss: 1.8699e-04\n",
      "Epoch 468/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7587e-04 - val_loss: 1.7848e-04\n",
      "Epoch 469/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7660e-04 - val_loss: 1.7766e-04\n",
      "Epoch 470/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7610e-04 - val_loss: 1.8883e-04\n",
      "Epoch 471/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8280e-04 - val_loss: 1.8964e-04\n",
      "Epoch 472/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8472e-04 - val_loss: 1.7928e-04\n",
      "Epoch 473/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7538e-04 - val_loss: 1.8146e-04\n",
      "Epoch 474/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8246e-04 - val_loss: 1.7814e-04\n",
      "Epoch 475/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7874e-04 - val_loss: 2.2081e-04\n",
      "Epoch 476/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8177e-04 - val_loss: 1.9144e-04\n",
      "Epoch 477/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8359e-04 - val_loss: 1.8626e-04\n",
      "Epoch 478/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8109e-04 - val_loss: 1.8051e-04\n",
      "Epoch 479/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8705e-04 - val_loss: 1.7866e-04\n",
      "Epoch 480/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.9601e-04 - val_loss: 1.8435e-04\n",
      "Epoch 481/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.9106e-04 - val_loss: 2.2214e-04\n",
      "Epoch 482/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8871e-04 - val_loss: 1.9858e-04\n",
      "Epoch 483/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7989e-04 - val_loss: 1.7719e-04\n",
      "Epoch 484/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7506e-04 - val_loss: 1.7882e-04\n",
      "Epoch 485/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8014e-04 - val_loss: 1.9034e-04\n",
      "Epoch 486/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7615e-04 - val_loss: 2.0601e-04\n",
      "Epoch 487/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8696e-04 - val_loss: 1.7938e-04\n",
      "Epoch 488/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.8647e-04 - val_loss: 1.7726e-04\n",
      "Epoch 489/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7928e-04 - val_loss: 1.7840e-04\n",
      "Epoch 490/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8023e-04 - val_loss: 1.7934e-04\n",
      "Epoch 491/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7517e-04 - val_loss: 1.7789e-04\n",
      "Epoch 492/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7410e-04 - val_loss: 1.7751e-04\n",
      "Epoch 493/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7677e-04 - val_loss: 1.7871e-04\n",
      "Epoch 494/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7369e-04 - val_loss: 1.7752e-04\n",
      "Epoch 495/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7453e-04 - val_loss: 1.7821e-04\n",
      "Epoch 496/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8461e-04 - val_loss: 1.9834e-04\n",
      "Epoch 497/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.9060e-04 - val_loss: 1.9284e-04\n",
      "Epoch 498/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9172e-04 - val_loss: 1.8600e-04\n",
      "Epoch 499/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7897e-04 - val_loss: 1.9209e-04\n",
      "Epoch 500/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7955e-04 - val_loss: 2.2215e-04\n",
      "Epoch 501/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8049e-04 - val_loss: 1.8518e-04\n",
      "Epoch 502/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7528e-04 - val_loss: 1.7712e-04\n",
      "Epoch 503/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.7527e-04 - val_loss: 1.7793e-04\n",
      "Epoch 504/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8296e-04 - val_loss: 1.7691e-04\n",
      "Epoch 505/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8064e-04 - val_loss: 1.7834e-04\n",
      "Epoch 506/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7960e-04 - val_loss: 2.0639e-04\n",
      "Epoch 507/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.9728e-04 - val_loss: 1.8213e-04\n",
      "Epoch 508/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7558e-04 - val_loss: 1.8341e-04\n",
      "Epoch 509/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7804e-04 - val_loss: 2.0037e-04\n",
      "Epoch 510/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8439e-04 - val_loss: 2.1607e-04\n",
      "Epoch 511/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7887e-04 - val_loss: 1.8602e-04\n",
      "Epoch 512/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7556e-04 - val_loss: 1.8452e-04\n",
      "Epoch 513/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8342e-04 - val_loss: 1.8466e-04\n",
      "Epoch 514/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8848e-04 - val_loss: 2.4446e-04\n",
      "Epoch 515/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.9882e-04 - val_loss: 2.6445e-04\n",
      "Epoch 516/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8421e-04 - val_loss: 1.7757e-04\n",
      "Epoch 517/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7810e-04 - val_loss: 1.7839e-04\n",
      "Epoch 518/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7345e-04 - val_loss: 1.7964e-04\n",
      "Epoch 519/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8135e-04 - val_loss: 1.8506e-04\n",
      "Epoch 520/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8773e-04 - val_loss: 1.9288e-04\n",
      "Epoch 521/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7453e-04 - val_loss: 1.8325e-04\n",
      "Epoch 522/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7462e-04 - val_loss: 1.8093e-04\n",
      "Epoch 523/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7438e-04 - val_loss: 1.8227e-04\n",
      "Epoch 524/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7413e-04 - val_loss: 1.7695e-04\n",
      "Epoch 525/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7930e-04 - val_loss: 1.7720e-04\n",
      "Epoch 526/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7472e-04 - val_loss: 1.7904e-04\n",
      "Epoch 527/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7869e-04 - val_loss: 1.9459e-04\n",
      "Epoch 528/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7845e-04 - val_loss: 1.8907e-04\n",
      "Epoch 529/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.9198e-04 - val_loss: 2.1411e-04\n",
      "Epoch 530/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8537e-04 - val_loss: 1.8807e-04\n",
      "Epoch 531/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8542e-04 - val_loss: 1.8057e-04\n",
      "Epoch 532/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8933e-04 - val_loss: 2.1910e-04\n",
      "Epoch 533/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.9604e-04 - val_loss: 2.4992e-04\n",
      "Epoch 534/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.9976e-04 - val_loss: 2.0419e-04\n",
      "Epoch 535/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7804e-04 - val_loss: 1.7936e-04\n",
      "Epoch 536/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7235e-04 - val_loss: 1.8656e-04\n",
      "Epoch 537/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7554e-04 - val_loss: 1.7756e-04\n",
      "Epoch 538/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7307e-04 - val_loss: 1.7674e-04\n",
      "Epoch 539/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7651e-04 - val_loss: 1.8480e-04\n",
      "Epoch 540/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7779e-04 - val_loss: 1.8607e-04\n",
      "Epoch 541/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7900e-04 - val_loss: 2.1610e-04\n",
      "Epoch 542/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8113e-04 - val_loss: 1.8965e-04\n",
      "Epoch 543/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7638e-04 - val_loss: 1.7681e-04\n",
      "Epoch 544/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7237e-04 - val_loss: 1.7734e-04\n",
      "Epoch 545/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7547e-04 - val_loss: 1.9290e-04\n",
      "Epoch 546/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8267e-04 - val_loss: 2.1159e-04\n",
      "Epoch 547/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7986e-04 - val_loss: 1.8111e-04\n",
      "Epoch 548/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7552e-04 - val_loss: 2.0689e-04\n",
      "Epoch 549/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9377e-04 - val_loss: 1.7657e-04\n",
      "Epoch 550/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8657e-04 - val_loss: 1.7899e-04\n",
      "Epoch 551/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7729e-04 - val_loss: 1.7749e-04\n",
      "Epoch 552/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7363e-04 - val_loss: 1.8911e-04\n",
      "Epoch 553/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7623e-04 - val_loss: 1.7796e-04\n",
      "Epoch 554/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7264e-04 - val_loss: 1.9616e-04\n",
      "Epoch 555/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8199e-04 - val_loss: 2.0437e-04\n",
      "Epoch 556/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.9681e-04 - val_loss: 2.6401e-04\n",
      "Epoch 557/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.9296e-04 - val_loss: 2.3567e-04\n",
      "Epoch 558/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.8210e-04 - val_loss: 1.8317e-04\n",
      "Epoch 559/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.7241e-04 - val_loss: 1.7687e-04\n",
      "Epoch 560/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7531e-04 - val_loss: 1.7704e-04\n",
      "Epoch 561/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7136e-04 - val_loss: 1.7931e-04\n",
      "Epoch 562/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7501e-04 - val_loss: 1.7761e-04\n",
      "Epoch 563/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.7621e-04 - val_loss: 1.8725e-04\n",
      "Epoch 564/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7671e-04 - val_loss: 1.8563e-04\n",
      "Epoch 565/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7378e-04 - val_loss: 1.8628e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 566/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7356e-04 - val_loss: 1.7877e-04\n",
      "Epoch 567/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7412e-04 - val_loss: 1.8949e-04\n",
      "Epoch 568/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7350e-04 - val_loss: 1.8171e-04\n",
      "Epoch 569/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7662e-04 - val_loss: 1.8191e-04\n",
      "Epoch 570/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7504e-04 - val_loss: 1.7740e-04\n",
      "Epoch 571/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7472e-04 - val_loss: 1.8202e-04\n",
      "Epoch 572/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7064e-04 - val_loss: 1.7656e-04\n",
      "Epoch 573/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7651e-04 - val_loss: 1.8275e-04\n",
      "Epoch 574/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7611e-04 - val_loss: 1.7786e-04\n",
      "Epoch 575/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7956e-04 - val_loss: 1.7675e-04\n",
      "Epoch 576/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7300e-04 - val_loss: 1.7899e-04\n",
      "Epoch 577/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8401e-04 - val_loss: 1.7782e-04\n",
      "Epoch 578/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8269e-04 - val_loss: 2.0391e-04\n",
      "Epoch 579/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8285e-04 - val_loss: 1.9579e-04\n",
      "Epoch 580/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8129e-04 - val_loss: 1.8134e-04\n",
      "Epoch 581/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7333e-04 - val_loss: 1.9014e-04\n",
      "Epoch 582/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7445e-04 - val_loss: 1.7651e-04\n",
      "Epoch 583/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7244e-04 - val_loss: 2.0693e-04\n",
      "Epoch 584/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7515e-04 - val_loss: 1.8637e-04\n",
      "Epoch 585/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9306e-04 - val_loss: 2.0307e-04\n",
      "Epoch 586/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9204e-04 - val_loss: 1.9314e-04\n",
      "Epoch 587/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8676e-04 - val_loss: 1.7638e-04\n",
      "Epoch 588/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7363e-04 - val_loss: 1.8009e-04\n",
      "Epoch 589/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7234e-04 - val_loss: 1.7841e-04\n",
      "Epoch 590/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7343e-04 - val_loss: 1.9409e-04\n",
      "Epoch 591/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7972e-04 - val_loss: 2.0486e-04\n",
      "Epoch 592/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9513e-04 - val_loss: 1.7903e-04\n",
      "Epoch 593/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9080e-04 - val_loss: 1.7668e-04\n",
      "Epoch 594/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8475e-04 - val_loss: 1.7632e-04\n",
      "Epoch 595/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7374e-04 - val_loss: 1.8969e-04\n",
      "Epoch 596/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7957e-04 - val_loss: 1.8737e-04\n",
      "Epoch 597/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7840e-04 - val_loss: 1.7683e-04\n",
      "Epoch 598/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7283e-04 - val_loss: 1.8477e-04\n",
      "Epoch 599/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.9517e-04 - val_loss: 1.8263e-04\n",
      "Epoch 600/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7770e-04 - val_loss: 1.7664e-04\n",
      "Epoch 601/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7861e-04 - val_loss: 1.9687e-04\n",
      "Epoch 602/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8097e-04 - val_loss: 2.2076e-04\n",
      "Epoch 603/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8615e-04 - val_loss: 2.5403e-04\n",
      "Epoch 604/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.9055e-04 - val_loss: 2.0474e-04\n",
      "Epoch 605/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8748e-04 - val_loss: 2.0781e-04\n",
      "Epoch 606/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8221e-04 - val_loss: 1.8371e-04\n",
      "Epoch 607/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7673e-04 - val_loss: 1.7704e-04\n",
      "Epoch 608/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7579e-04 - val_loss: 1.7924e-04\n",
      "Epoch 609/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7642e-04 - val_loss: 1.7868e-04\n",
      "Epoch 610/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7708e-04 - val_loss: 1.7686e-04\n",
      "Epoch 611/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7341e-04 - val_loss: 1.8420e-04\n",
      "Epoch 612/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.7748e-04 - val_loss: 1.8430e-04\n",
      "Epoch 613/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7743e-04 - val_loss: 1.7773e-04\n",
      "Epoch 614/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7982e-04 - val_loss: 1.7702e-04\n",
      "Epoch 615/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7416e-04 - val_loss: 1.8037e-04\n",
      "Epoch 616/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7876e-04 - val_loss: 2.1136e-04\n",
      "Epoch 617/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7513e-04 - val_loss: 1.7818e-04\n",
      "Epoch 618/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7663e-04 - val_loss: 1.9512e-04\n",
      "Epoch 619/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8037e-04 - val_loss: 1.9600e-04\n",
      "Epoch 620/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8558e-04 - val_loss: 1.7780e-04\n",
      "Epoch 621/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7328e-04 - val_loss: 1.7631e-04\n",
      "Epoch 622/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7411e-04 - val_loss: 1.7608e-04\n",
      "Epoch 623/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7455e-04 - val_loss: 1.8781e-04\n",
      "Epoch 624/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7281e-04 - val_loss: 1.8531e-04\n",
      "Epoch 625/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7361e-04 - val_loss: 1.7981e-04\n",
      "Epoch 626/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7758e-04 - val_loss: 1.7748e-04\n",
      "Epoch 627/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7227e-04 - val_loss: 1.9129e-04\n",
      "Epoch 628/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7199e-04 - val_loss: 1.9218e-04\n",
      "Epoch 629/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8327e-04 - val_loss: 1.7582e-04\n",
      "Epoch 630/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7554e-04 - val_loss: 1.8247e-04\n",
      "Epoch 631/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7558e-04 - val_loss: 1.7967e-04\n",
      "Epoch 632/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.8123e-04 - val_loss: 1.9126e-04\n",
      "Epoch 633/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7251e-04 - val_loss: 1.7856e-04\n",
      "Epoch 634/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7404e-04 - val_loss: 1.7729e-04\n",
      "Epoch 635/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7456e-04 - val_loss: 1.7763e-04\n",
      "Epoch 636/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8787e-04 - val_loss: 2.3232e-04\n",
      "Epoch 637/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.9635e-04 - val_loss: 2.3769e-04\n",
      "Epoch 638/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.9020e-04 - val_loss: 2.0050e-04\n",
      "Epoch 639/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.9685e-04 - val_loss: 2.0271e-04\n",
      "Epoch 640/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9081e-04 - val_loss: 1.8667e-04\n",
      "Epoch 641/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.8294e-04 - val_loss: 1.8414e-04\n",
      "Epoch 642/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.9844e-04 - val_loss: 1.8220e-04\n",
      "Epoch 643/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8471e-04 - val_loss: 1.7656e-04\n",
      "Epoch 644/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.9089e-04 - val_loss: 1.7669e-04\n",
      "Epoch 645/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9348e-04 - val_loss: 1.7966e-04\n",
      "Epoch 646/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7796e-04 - val_loss: 1.8579e-04\n",
      "Epoch 647/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9253e-04 - val_loss: 1.9403e-04\n",
      "Epoch 648/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7722e-04 - val_loss: 2.2052e-04\n",
      "Epoch 649/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8775e-04 - val_loss: 2.1139e-04\n",
      "Epoch 650/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.9978e-04 - val_loss: 2.2439e-04\n",
      "Epoch 651/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8932e-04 - val_loss: 2.2193e-04\n",
      "Epoch 652/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7948e-04 - val_loss: 1.7625e-04\n",
      "Epoch 653/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8022e-04 - val_loss: 1.8738e-04\n",
      "Epoch 654/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7439e-04 - val_loss: 1.7580e-04\n",
      "Epoch 655/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7909e-04 - val_loss: 1.7710e-04\n",
      "Epoch 656/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7684e-04 - val_loss: 1.7589e-04\n",
      "Epoch 657/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7106e-04 - val_loss: 1.8427e-04\n",
      "Epoch 658/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7124e-04 - val_loss: 1.7893e-04\n",
      "Epoch 659/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8016e-04 - val_loss: 1.9606e-04\n",
      "Epoch 660/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7919e-04 - val_loss: 1.8372e-04\n",
      "Epoch 661/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7494e-04 - val_loss: 2.0724e-04\n",
      "Epoch 662/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7864e-04 - val_loss: 1.9497e-04\n",
      "Epoch 663/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7598e-04 - val_loss: 1.7729e-04\n",
      "Epoch 664/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7162e-04 - val_loss: 1.7559e-04\n",
      "Epoch 665/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7345e-04 - val_loss: 1.8115e-04\n",
      "Epoch 666/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7379e-04 - val_loss: 1.9169e-04\n",
      "Epoch 667/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7928e-04 - val_loss: 1.8253e-04\n",
      "Epoch 668/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.7267e-04 - val_loss: 1.8444e-04\n",
      "Epoch 669/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.7058e-04 - val_loss: 1.7986e-04\n",
      "Epoch 670/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6979e-04 - val_loss: 1.7744e-04\n",
      "Epoch 671/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7064e-04 - val_loss: 1.7909e-04\n",
      "Epoch 672/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.7328e-04 - val_loss: 1.8434e-04\n",
      "Epoch 673/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7416e-04 - val_loss: 2.0887e-04\n",
      "Epoch 674/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.7603e-04 - val_loss: 1.7604e-04\n",
      "Epoch 675/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.7517e-04 - val_loss: 1.7639e-04\n",
      "Epoch 676/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7310e-04 - val_loss: 1.7701e-04\n",
      "Epoch 677/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7798e-04 - val_loss: 1.7590e-04\n",
      "Epoch 678/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7333e-04 - val_loss: 1.7809e-04\n",
      "Epoch 679/2000\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 1.7102e-04 - val_loss: 1.7869e-04\n",
      "Epoch 680/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 1.7305e-04 - val_loss: 2.2226e-04\n",
      "Epoch 681/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8015e-04 - val_loss: 1.8027e-04\n",
      "Epoch 682/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7258e-04 - val_loss: 1.7805e-04\n",
      "Epoch 683/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7436e-04 - val_loss: 1.8856e-04\n",
      "Epoch 684/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8970e-04 - val_loss: 1.9419e-04\n",
      "Epoch 685/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8112e-04 - val_loss: 1.8340e-04\n",
      "Epoch 686/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7108e-04 - val_loss: 1.8427e-04\n",
      "Epoch 687/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7383e-04 - val_loss: 1.7712e-04\n",
      "Epoch 688/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7350e-04 - val_loss: 1.7657e-04\n",
      "Epoch 689/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7091e-04 - val_loss: 1.7774e-04\n",
      "Epoch 690/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7786e-04 - val_loss: 1.8264e-04\n",
      "Epoch 691/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7994e-04 - val_loss: 1.7605e-04\n",
      "Epoch 692/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7332e-04 - val_loss: 1.8716e-04\n",
      "Epoch 693/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7501e-04 - val_loss: 2.0232e-04\n",
      "Epoch 694/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.8397e-04 - val_loss: 2.1390e-04\n",
      "Epoch 695/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 1.8524e-04 - val_loss: 2.1059e-04\n",
      "Epoch 696/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8079e-04 - val_loss: 1.8077e-04\n",
      "Epoch 697/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7137e-04 - val_loss: 1.9874e-04\n",
      "Epoch 698/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7446e-04 - val_loss: 1.9230e-04\n",
      "Epoch 699/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7112e-04 - val_loss: 1.8533e-04\n",
      "Epoch 700/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7263e-04 - val_loss: 2.2979e-04\n",
      "Epoch 701/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.7870e-04 - val_loss: 1.9488e-04\n",
      "Epoch 702/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7611e-04 - val_loss: 1.7709e-04\n",
      "Epoch 703/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.8442e-04 - val_loss: 1.7603e-04\n",
      "Epoch 704/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7875e-04 - val_loss: 1.7981e-04\n",
      "Epoch 705/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7199e-04 - val_loss: 1.7680e-04\n",
      "Epoch 706/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 1.7300e-04 - val_loss: 1.8148e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 707/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7039e-04 - val_loss: 1.7601e-04\n",
      "Epoch 708/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6809e-04 - val_loss: 1.7781e-04\n",
      "Epoch 709/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6967e-04 - val_loss: 1.9148e-04\n",
      "Epoch 710/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7572e-04 - val_loss: 1.8359e-04\n",
      "Epoch 711/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8051e-04 - val_loss: 1.8942e-04\n",
      "Epoch 712/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7409e-04 - val_loss: 1.9077e-04\n",
      "Epoch 713/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7868e-04 - val_loss: 2.2262e-04\n",
      "Epoch 714/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7947e-04 - val_loss: 1.8743e-04\n",
      "Epoch 715/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7207e-04 - val_loss: 1.7796e-04\n",
      "Epoch 716/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7036e-04 - val_loss: 1.7627e-04\n",
      "Epoch 717/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7215e-04 - val_loss: 2.0509e-04\n",
      "Epoch 718/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.7695e-04 - val_loss: 1.9224e-04\n",
      "Epoch 719/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8682e-04 - val_loss: 2.6282e-04\n",
      "Epoch 720/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.9270e-04 - val_loss: 2.1314e-04\n",
      "Epoch 721/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7908e-04 - val_loss: 1.8826e-04\n",
      "Epoch 722/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6961e-04 - val_loss: 1.8530e-04\n",
      "Epoch 723/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7746e-04 - val_loss: 1.7872e-04\n",
      "Epoch 724/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7783e-04 - val_loss: 1.8539e-04\n",
      "Epoch 725/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8367e-04 - val_loss: 1.9107e-04\n",
      "Epoch 726/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7490e-04 - val_loss: 1.7709e-04\n",
      "Epoch 727/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7308e-04 - val_loss: 1.7712e-04\n",
      "Epoch 728/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7268e-04 - val_loss: 1.8550e-04\n",
      "Epoch 729/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7234e-04 - val_loss: 1.8035e-04\n",
      "Epoch 730/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7302e-04 - val_loss: 2.1861e-04\n",
      "Epoch 731/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8903e-04 - val_loss: 2.3998e-04\n",
      "Epoch 732/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8618e-04 - val_loss: 2.0559e-04\n",
      "Epoch 733/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7755e-04 - val_loss: 1.8398e-04\n",
      "Epoch 734/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7301e-04 - val_loss: 1.8886e-04\n",
      "Epoch 735/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7875e-04 - val_loss: 1.9181e-04\n",
      "Epoch 736/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7483e-04 - val_loss: 1.8230e-04\n",
      "Epoch 737/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8467e-04 - val_loss: 2.6144e-04\n",
      "Epoch 738/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8693e-04 - val_loss: 2.2520e-04\n",
      "Epoch 739/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.7445e-04 - val_loss: 1.9082e-04\n",
      "Epoch 740/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6952e-04 - val_loss: 1.7604e-04\n",
      "Epoch 741/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6881e-04 - val_loss: 2.0585e-04\n",
      "Epoch 742/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8042e-04 - val_loss: 2.2069e-04\n",
      "Epoch 743/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8434e-04 - val_loss: 2.4907e-04\n",
      "Epoch 744/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.9239e-04 - val_loss: 1.9947e-04\n",
      "Epoch 745/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7825e-04 - val_loss: 1.7951e-04\n",
      "Epoch 746/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7199e-04 - val_loss: 1.7919e-04\n",
      "Epoch 747/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8510e-04 - val_loss: 1.7811e-04\n",
      "Epoch 748/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8465e-04 - val_loss: 1.7945e-04\n",
      "Epoch 749/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6899e-04 - val_loss: 1.7652e-04\n",
      "Epoch 750/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6974e-04 - val_loss: 1.8499e-04\n",
      "Epoch 751/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7657e-04 - val_loss: 2.0058e-04\n",
      "Epoch 752/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7849e-04 - val_loss: 2.5635e-04\n",
      "Epoch 753/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8365e-04 - val_loss: 1.8221e-04\n",
      "Epoch 754/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6959e-04 - val_loss: 1.9261e-04\n",
      "Epoch 755/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7562e-04 - val_loss: 1.7714e-04\n",
      "Epoch 756/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7392e-04 - val_loss: 1.7821e-04\n",
      "Epoch 757/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7007e-04 - val_loss: 1.7711e-04\n",
      "Epoch 758/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6933e-04 - val_loss: 1.7965e-04\n",
      "Epoch 759/2000\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 1.7010e-04 - val_loss: 1.8655e-04\n",
      "Epoch 760/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.6992e-04 - val_loss: 1.7903e-04\n",
      "Epoch 761/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6918e-04 - val_loss: 1.7932e-04\n",
      "Epoch 762/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.6944e-04 - val_loss: 1.7945e-04\n",
      "Epoch 763/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7283e-04 - val_loss: 1.8223e-04\n",
      "Epoch 764/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7449e-04 - val_loss: 1.9466e-04\n",
      "Epoch 765/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7692e-04 - val_loss: 1.8563e-04\n",
      "Epoch 766/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8063e-04 - val_loss: 2.5478e-04\n",
      "Epoch 767/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8375e-04 - val_loss: 1.9236e-04\n",
      "Epoch 768/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7494e-04 - val_loss: 2.0744e-04\n",
      "Epoch 769/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7366e-04 - val_loss: 1.9990e-04\n",
      "Epoch 770/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6975e-04 - val_loss: 1.7678e-04\n",
      "Epoch 771/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7558e-04 - val_loss: 1.7761e-04\n",
      "Epoch 772/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.6767e-04 - val_loss: 1.7912e-04\n",
      "Epoch 773/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6851e-04 - val_loss: 1.7682e-04\n",
      "Epoch 774/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7858e-04 - val_loss: 1.7716e-04\n",
      "Epoch 775/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.7508e-04 - val_loss: 1.7832e-04\n",
      "Epoch 776/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.8445e-04 - val_loss: 1.8475e-04\n",
      "Epoch 777/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.8291e-04 - val_loss: 1.7837e-04\n",
      "Epoch 778/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.7422e-04 - val_loss: 1.8063e-04\n",
      "Epoch 779/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6887e-04 - val_loss: 1.8238e-04\n",
      "Epoch 780/2000\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 1.6916e-04 - val_loss: 1.8968e-04\n",
      "Epoch 781/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.7402e-04 - val_loss: 1.8562e-04\n",
      "Epoch 782/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7561e-04 - val_loss: 2.1461e-04\n",
      "Epoch 783/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7374e-04 - val_loss: 1.7732e-04\n",
      "Epoch 784/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7279e-04 - val_loss: 1.7775e-04\n",
      "Epoch 785/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7191e-04 - val_loss: 1.7708e-04\n",
      "Epoch 786/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7479e-04 - val_loss: 1.9032e-04\n",
      "Epoch 787/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8937e-04 - val_loss: 2.5986e-04\n",
      "Epoch 788/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.9658e-04 - val_loss: 1.9559e-04\n",
      "Epoch 789/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7474e-04 - val_loss: 1.7953e-04\n",
      "Epoch 790/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6820e-04 - val_loss: 1.7701e-04\n",
      "Epoch 791/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6917e-04 - val_loss: 1.8039e-04\n",
      "Epoch 792/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6797e-04 - val_loss: 1.8117e-04\n",
      "Epoch 793/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.7055e-04 - val_loss: 2.1314e-04\n",
      "Epoch 794/2000\n",
      "4059/4059 [==============================] - ETA: 0s - loss: 1.7980e-0 - 1s 246us/step - loss: 1.7395e-04 - val_loss: 1.8456e-04\n",
      "Epoch 795/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7112e-04 - val_loss: 1.7730e-04\n",
      "Epoch 796/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6776e-04 - val_loss: 1.7799e-04\n",
      "Epoch 797/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7364e-04 - val_loss: 1.8361e-04\n",
      "Epoch 798/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7625e-04 - val_loss: 1.7782e-04\n",
      "Epoch 799/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.7137e-04 - val_loss: 1.7921e-04\n",
      "Epoch 800/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7102e-04 - val_loss: 1.9245e-04\n",
      "Epoch 801/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7059e-04 - val_loss: 1.8331e-04\n",
      "Epoch 802/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6943e-04 - val_loss: 1.7814e-04\n",
      "Epoch 803/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7296e-04 - val_loss: 1.8751e-04\n",
      "Epoch 804/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.6799e-04 - val_loss: 1.7839e-04\n",
      "Epoch 805/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6890e-04 - val_loss: 1.8507e-04\n",
      "Epoch 806/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7182e-04 - val_loss: 1.8499e-04\n",
      "Epoch 807/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.6729e-04 - val_loss: 1.8019e-04\n",
      "Epoch 808/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.6961e-04 - val_loss: 1.8669e-04\n",
      "Epoch 809/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7503e-04 - val_loss: 1.8869e-04\n",
      "Epoch 810/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.6988e-04 - val_loss: 1.8545e-04\n",
      "Epoch 811/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.7879e-04 - val_loss: 2.3773e-04\n",
      "Epoch 812/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.9984e-04 - val_loss: 1.9032e-04\n",
      "Epoch 813/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7724e-04 - val_loss: 1.7993e-04\n",
      "Epoch 814/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7386e-04 - val_loss: 1.7918e-04\n",
      "Epoch 815/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.7013e-04 - val_loss: 1.8434e-04\n",
      "Epoch 816/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6894e-04 - val_loss: 1.7940e-04\n",
      "Epoch 817/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8843e-04 - val_loss: 1.7821e-04\n",
      "Epoch 818/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6924e-04 - val_loss: 1.9385e-04\n",
      "Epoch 819/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8535e-04 - val_loss: 1.9581e-04\n",
      "Epoch 820/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7069e-04 - val_loss: 1.9037e-04\n",
      "Epoch 821/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7944e-04 - val_loss: 1.8454e-04\n",
      "Epoch 822/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6743e-04 - val_loss: 1.8158e-04\n",
      "Epoch 823/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7019e-04 - val_loss: 1.7893e-04\n",
      "Epoch 824/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6959e-04 - val_loss: 1.8950e-04\n",
      "Epoch 825/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7267e-04 - val_loss: 2.3587e-04\n",
      "Epoch 826/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7554e-04 - val_loss: 1.8965e-04\n",
      "Epoch 827/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7139e-04 - val_loss: 1.7894e-04\n",
      "Epoch 828/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.6971e-04 - val_loss: 1.7966e-04\n",
      "Epoch 829/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7446e-04 - val_loss: 1.8077e-04\n",
      "Epoch 830/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7432e-04 - val_loss: 2.1360e-04\n",
      "Epoch 831/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7666e-04 - val_loss: 1.7949e-04\n",
      "Epoch 832/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.6564e-04 - val_loss: 1.7842e-04\n",
      "Epoch 833/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.6737e-04 - val_loss: 1.9013e-04\n",
      "Epoch 834/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7227e-04 - val_loss: 1.8774e-04\n",
      "Epoch 835/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7281e-04 - val_loss: 1.9028e-04\n",
      "Epoch 836/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7141e-04 - val_loss: 1.7872e-04\n",
      "Epoch 837/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7636e-04 - val_loss: 1.7868e-04\n",
      "Epoch 838/2000\n",
      "4059/4059 [==============================] - 1s 263us/step - loss: 1.6617e-04 - val_loss: 1.7932e-04\n",
      "Epoch 839/2000\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 1.6919e-04 - val_loss: 1.8459e-04\n",
      "Epoch 840/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 1.6761e-04 - val_loss: 1.8455e-04\n",
      "Epoch 841/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 1.6772e-04 - val_loss: 1.8253e-04\n",
      "Epoch 842/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.6922e-04 - val_loss: 1.7785e-04\n",
      "Epoch 843/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 1.6588e-04 - val_loss: 1.7868e-04\n",
      "Epoch 844/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 1.6748e-04 - val_loss: 1.9047e-04\n",
      "Epoch 845/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8289e-04 - val_loss: 1.8428e-04\n",
      "Epoch 846/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.8107e-04 - val_loss: 1.8018e-04\n",
      "Epoch 847/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.8755e-04 - val_loss: 1.7865e-04\n",
      "Epoch 848/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7303e-04 - val_loss: 1.8201e-04\n",
      "Epoch 849/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.7078e-04 - val_loss: 1.9050e-04\n",
      "Epoch 850/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.9146e-04 - val_loss: 1.8914e-04\n",
      "Epoch 851/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.9768e-04 - val_loss: 1.7972e-04\n",
      "Epoch 852/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.8719e-04 - val_loss: 1.7961e-04\n",
      "Epoch 853/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7355e-04 - val_loss: 1.8765e-04\n",
      "Epoch 854/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6833e-04 - val_loss: 1.7979e-04\n",
      "Epoch 855/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6784e-04 - val_loss: 1.8161e-04\n",
      "Epoch 856/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6958e-04 - val_loss: 1.7992e-04\n",
      "Epoch 857/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8025e-04 - val_loss: 1.9301e-04\n",
      "Epoch 858/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.7487e-04 - val_loss: 1.7929e-04\n",
      "Epoch 859/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7031e-04 - val_loss: 1.9312e-04\n",
      "Epoch 860/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7286e-04 - val_loss: 1.8197e-04\n",
      "Epoch 861/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6765e-04 - val_loss: 1.7986e-04\n",
      "Epoch 862/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6562e-04 - val_loss: 1.7841e-04\n",
      "Epoch 863/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 1.6917e-04 - val_loss: 1.8161e-04\n",
      "Epoch 864/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.6720e-04 - val_loss: 1.9096e-04\n",
      "Epoch 865/2000\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 1.6586e-04 - val_loss: 1.7911e-04\n",
      "Epoch 866/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.6686e-04 - val_loss: 1.8188e-04\n",
      "Epoch 867/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6683e-04 - val_loss: 1.7938e-04\n",
      "Epoch 868/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.6480e-04 - val_loss: 1.8737e-04\n",
      "Epoch 869/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6733e-04 - val_loss: 1.8522e-04\n",
      "Epoch 870/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.6584e-04 - val_loss: 1.7967e-04\n",
      "Epoch 871/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6618e-04 - val_loss: 1.8776e-04\n",
      "Epoch 872/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7028e-04 - val_loss: 1.7937e-04\n",
      "Epoch 873/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6691e-04 - val_loss: 1.8576e-04\n",
      "Epoch 874/2000\n",
      "4059/4059 [==============================] - ETA: 0s - loss: 1.6352e-0 - 1s 246us/step - loss: 1.6636e-04 - val_loss: 1.8349e-04\n",
      "Epoch 875/2000\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 1.6643e-04 - val_loss: 1.9644e-04\n",
      "Epoch 876/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.6912e-04 - val_loss: 1.8239e-04\n",
      "Epoch 877/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6581e-04 - val_loss: 1.7855e-04\n",
      "Epoch 878/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6720e-04 - val_loss: 2.2183e-04\n",
      "Epoch 879/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7677e-04 - val_loss: 2.0886e-04\n",
      "Epoch 880/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.8598e-04 - val_loss: 2.3405e-04\n",
      "Epoch 881/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.8785e-04 - val_loss: 2.0381e-04\n",
      "Epoch 882/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7273e-04 - val_loss: 1.8666e-04\n",
      "Epoch 883/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7011e-04 - val_loss: 1.9288e-04\n",
      "Epoch 884/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7409e-04 - val_loss: 1.8915e-04\n",
      "Epoch 885/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7183e-04 - val_loss: 1.8688e-04\n",
      "Epoch 886/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6641e-04 - val_loss: 1.7922e-04\n",
      "Epoch 887/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6940e-04 - val_loss: 2.0161e-04\n",
      "Epoch 888/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6933e-04 - val_loss: 1.8060e-04\n",
      "Epoch 889/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6748e-04 - val_loss: 1.7898e-04\n",
      "Epoch 890/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6707e-04 - val_loss: 1.8481e-04\n",
      "Epoch 891/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6793e-04 - val_loss: 1.8856e-04\n",
      "Epoch 892/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6819e-04 - val_loss: 1.9015e-04\n",
      "Epoch 893/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7077e-04 - val_loss: 1.8825e-04\n",
      "Epoch 894/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6868e-04 - val_loss: 1.9073e-04\n",
      "Epoch 895/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6540e-04 - val_loss: 1.8300e-04\n",
      "Epoch 896/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6773e-04 - val_loss: 1.8031e-04\n",
      "Epoch 897/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6882e-04 - val_loss: 1.9433e-04\n",
      "Epoch 898/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6553e-04 - val_loss: 2.0192e-04\n",
      "Epoch 899/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7472e-04 - val_loss: 2.1031e-04\n",
      "Epoch 900/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7514e-04 - val_loss: 1.8255e-04\n",
      "Epoch 901/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7166e-04 - val_loss: 1.9772e-04\n",
      "Epoch 902/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.8063e-04 - val_loss: 1.9127e-04\n",
      "Epoch 903/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 1.6591e-04 - val_loss: 1.7871e-04\n",
      "Epoch 904/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6406e-04 - val_loss: 1.8097e-04\n",
      "Epoch 905/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6749e-04 - val_loss: 1.8321e-04\n",
      "Epoch 906/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7532e-04 - val_loss: 2.0531e-04\n",
      "Epoch 907/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.9039e-04 - val_loss: 1.8909e-04\n",
      "Epoch 908/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.8666e-04 - val_loss: 1.7889e-04\n",
      "Epoch 909/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.7536e-04 - val_loss: 1.8473e-04\n",
      "Epoch 910/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7021e-04 - val_loss: 1.8267e-04\n",
      "Epoch 911/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6546e-04 - val_loss: 1.9232e-04\n",
      "Epoch 912/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6843e-04 - val_loss: 2.0171e-04\n",
      "Epoch 913/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8132e-04 - val_loss: 1.8033e-04\n",
      "Epoch 914/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7309e-04 - val_loss: 2.0131e-04\n",
      "Epoch 915/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7521e-04 - val_loss: 1.8068e-04\n",
      "Epoch 916/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6439e-04 - val_loss: 1.8468e-04\n",
      "Epoch 917/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6644e-04 - val_loss: 1.8289e-04\n",
      "Epoch 918/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6792e-04 - val_loss: 2.0369e-04\n",
      "Epoch 919/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.7128e-04 - val_loss: 2.0025e-04\n",
      "Epoch 920/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7391e-04 - val_loss: 2.0827e-04\n",
      "Epoch 921/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6937e-04 - val_loss: 1.9139e-04\n",
      "Epoch 922/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6952e-04 - val_loss: 1.8028e-04\n",
      "Epoch 923/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7136e-04 - val_loss: 1.8576e-04\n",
      "Epoch 924/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6821e-04 - val_loss: 1.9689e-04\n",
      "Epoch 925/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6968e-04 - val_loss: 1.9736e-04\n",
      "Epoch 926/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7846e-04 - val_loss: 1.8712e-04\n",
      "Epoch 927/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7450e-04 - val_loss: 1.9393e-04\n",
      "Epoch 928/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7656e-04 - val_loss: 2.0314e-04\n",
      "Epoch 929/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7428e-04 - val_loss: 1.8013e-04\n",
      "Epoch 930/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6423e-04 - val_loss: 1.8161e-04\n",
      "Epoch 931/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6692e-04 - val_loss: 1.8131e-04\n",
      "Epoch 932/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6643e-04 - val_loss: 1.8830e-04\n",
      "Epoch 933/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7020e-04 - val_loss: 2.0243e-04\n",
      "Epoch 934/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.7068e-04 - val_loss: 1.9600e-04\n",
      "Epoch 935/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6811e-04 - val_loss: 1.9811e-04\n",
      "Epoch 936/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7157e-04 - val_loss: 1.8824e-04\n",
      "Epoch 937/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6921e-04 - val_loss: 1.8936e-04\n",
      "Epoch 938/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.7034e-04 - val_loss: 1.7992e-04\n",
      "Epoch 939/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6452e-04 - val_loss: 1.8364e-04\n",
      "Epoch 940/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.6401e-04 - val_loss: 2.1031e-04\n",
      "Epoch 941/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7534e-04 - val_loss: 2.0388e-04\n",
      "Epoch 942/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7669e-04 - val_loss: 1.9254e-04\n",
      "Epoch 943/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7382e-04 - val_loss: 2.0430e-04\n",
      "Epoch 944/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7510e-04 - val_loss: 1.8156e-04\n",
      "Epoch 945/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7026e-04 - val_loss: 1.9112e-04\n",
      "Epoch 946/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.6593e-04 - val_loss: 1.8273e-04\n",
      "Epoch 947/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6404e-04 - val_loss: 1.8802e-04\n",
      "Epoch 948/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6412e-04 - val_loss: 1.8462e-04\n",
      "Epoch 949/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6624e-04 - val_loss: 1.8164e-04\n",
      "Epoch 950/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6524e-04 - val_loss: 2.1151e-04\n",
      "Epoch 951/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7586e-04 - val_loss: 1.9569e-04\n",
      "Epoch 952/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.7505e-04 - val_loss: 1.8632e-04\n",
      "Epoch 953/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7109e-04 - val_loss: 2.0417e-04\n",
      "Epoch 954/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8100e-04 - val_loss: 2.0580e-04\n",
      "Epoch 955/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7842e-04 - val_loss: 1.8569e-04\n",
      "Epoch 956/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7451e-04 - val_loss: 1.7906e-04\n",
      "Epoch 957/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6621e-04 - val_loss: 1.9103e-04\n",
      "Epoch 958/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6355e-04 - val_loss: 1.8195e-04\n",
      "Epoch 959/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6293e-04 - val_loss: 1.8192e-04\n",
      "Epoch 960/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6385e-04 - val_loss: 1.8408e-04\n",
      "Epoch 961/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6504e-04 - val_loss: 1.9478e-04\n",
      "Epoch 962/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6827e-04 - val_loss: 1.8355e-04\n",
      "Epoch 963/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6725e-04 - val_loss: 1.8255e-04\n",
      "Epoch 964/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6884e-04 - val_loss: 1.8132e-04\n",
      "Epoch 965/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6367e-04 - val_loss: 1.8178e-04\n",
      "Epoch 966/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6636e-04 - val_loss: 2.0109e-04\n",
      "Epoch 967/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7348e-04 - val_loss: 2.0311e-04\n",
      "Epoch 968/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.6995e-04 - val_loss: 1.8522e-04\n",
      "Epoch 969/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.7154e-04 - val_loss: 2.2091e-04\n",
      "Epoch 970/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7529e-04 - val_loss: 2.2218e-04\n",
      "Epoch 971/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7613e-04 - val_loss: 1.8003e-04\n",
      "Epoch 972/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7381e-04 - val_loss: 1.8441e-04\n",
      "Epoch 973/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7187e-04 - val_loss: 1.9137e-04\n",
      "Epoch 974/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.6797e-04 - val_loss: 1.8600e-04\n",
      "Epoch 975/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6858e-04 - val_loss: 2.2028e-04\n",
      "Epoch 976/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.7906e-04 - val_loss: 1.9724e-04\n",
      "Epoch 977/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.8019e-04 - val_loss: 1.8273e-04\n",
      "Epoch 978/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6658e-04 - val_loss: 1.8347e-04\n",
      "Epoch 979/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6443e-04 - val_loss: 1.8391e-04\n",
      "Epoch 980/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6337e-04 - val_loss: 1.8275e-04\n",
      "Epoch 981/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6428e-04 - val_loss: 1.8252e-04\n",
      "Epoch 982/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6522e-04 - val_loss: 1.8817e-04\n",
      "Epoch 983/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6983e-04 - val_loss: 1.8411e-04\n",
      "Epoch 984/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.6414e-04 - val_loss: 1.8474e-04\n",
      "Epoch 985/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 1.6277e-04 - val_loss: 1.8146e-04\n",
      "Epoch 986/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6304e-04 - val_loss: 2.0106e-04\n",
      "Epoch 987/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7113e-04 - val_loss: 1.9487e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 988/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6669e-04 - val_loss: 1.8373e-04\n",
      "Epoch 989/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6664e-04 - val_loss: 1.8751e-04\n",
      "Epoch 990/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6457e-04 - val_loss: 1.8228e-04\n",
      "Epoch 991/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6724e-04 - val_loss: 1.9041e-04\n",
      "Epoch 992/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8174e-04 - val_loss: 2.1386e-04\n",
      "Epoch 993/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7813e-04 - val_loss: 1.8508e-04\n",
      "Epoch 994/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6754e-04 - val_loss: 1.8128e-04\n",
      "Epoch 995/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.6254e-04 - val_loss: 1.8199e-04\n",
      "Epoch 996/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6423e-04 - val_loss: 1.8187e-04\n",
      "Epoch 997/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6339e-04 - val_loss: 1.8489e-04\n",
      "Epoch 998/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.6671e-04 - val_loss: 1.9113e-04\n",
      "Epoch 999/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.6796e-04 - val_loss: 1.8098e-04\n",
      "Epoch 1000/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6488e-04 - val_loss: 1.8503e-04\n",
      "Epoch 1001/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7017e-04 - val_loss: 1.8942e-04\n",
      "Epoch 1002/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.6917e-04 - val_loss: 1.8346e-04\n",
      "Epoch 1003/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.7719e-04 - val_loss: 1.8364e-04\n",
      "Epoch 1004/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7729e-04 - val_loss: 1.8315e-04\n",
      "Epoch 1005/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6982e-04 - val_loss: 1.9387e-04\n",
      "Epoch 1006/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.6767e-04 - val_loss: 2.0119e-04\n",
      "Epoch 1007/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 1.7145e-04 - val_loss: 1.9290e-04\n",
      "Epoch 1008/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 1.6783e-04 - val_loss: 2.1198e-04\n",
      "Epoch 1009/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 1.6685e-04 - val_loss: 1.8793e-04\n",
      "Epoch 1010/2000\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 1.6219e-04 - val_loss: 1.8999e-04\n",
      "Epoch 1011/2000\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 1.6731e-04 - val_loss: 1.8868e-04\n",
      "Epoch 1012/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 1.6816e-04 - val_loss: 2.1881e-04\n",
      "Epoch 1013/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7063e-04 - val_loss: 1.9984e-04\n",
      "Epoch 1014/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6744e-04 - val_loss: 1.9677e-04\n",
      "Epoch 1015/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6556e-04 - val_loss: 1.8423e-04\n",
      "Epoch 1016/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.6780e-04 - val_loss: 1.8536e-04\n",
      "Epoch 1017/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 1.6905e-04 - val_loss: 1.8590e-04\n",
      "Epoch 1018/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 1.6394e-04 - val_loss: 1.8468e-04\n",
      "Epoch 1019/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.6198e-04 - val_loss: 1.8613e-04\n",
      "Epoch 1020/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6250e-04 - val_loss: 1.8746e-04\n",
      "Epoch 1021/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6249e-04 - val_loss: 1.9776e-04\n",
      "Epoch 1022/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7171e-04 - val_loss: 2.0070e-04\n",
      "Epoch 1023/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7056e-04 - val_loss: 1.8273e-04\n",
      "Epoch 1024/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6488e-04 - val_loss: 1.8516e-04\n",
      "Epoch 1025/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6542e-04 - val_loss: 1.8637e-04\n",
      "Epoch 1026/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6684e-04 - val_loss: 1.8564e-04\n",
      "Epoch 1027/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6783e-04 - val_loss: 1.8157e-04\n",
      "Epoch 1028/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6598e-04 - val_loss: 1.8387e-04\n",
      "Epoch 1029/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6387e-04 - val_loss: 1.8925e-04\n",
      "Epoch 1030/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.6419e-04 - val_loss: 1.8508e-04\n",
      "Epoch 1031/2000\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 1.6002e-04 - val_loss: 1.8319e-04\n",
      "Epoch 1032/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.6110e-04 - val_loss: 1.8465e-04\n",
      "Epoch 1033/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6071e-04 - val_loss: 1.8311e-04\n",
      "Epoch 1034/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6368e-04 - val_loss: 1.8696e-04\n",
      "Epoch 1035/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6039e-04 - val_loss: 1.8185e-04\n",
      "Epoch 1036/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6051e-04 - val_loss: 1.8340e-04\n",
      "Epoch 1037/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6093e-04 - val_loss: 1.8649e-04\n",
      "Epoch 1038/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6476e-04 - val_loss: 1.8432e-04\n",
      "Epoch 1039/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6657e-04 - val_loss: 1.8911e-04\n",
      "Epoch 1040/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6832e-04 - val_loss: 1.8936e-04\n",
      "Epoch 1041/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6663e-04 - val_loss: 1.8517e-04\n",
      "Epoch 1042/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6325e-04 - val_loss: 2.1781e-04\n",
      "Epoch 1043/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6919e-04 - val_loss: 2.3091e-04\n",
      "Epoch 1044/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7375e-04 - val_loss: 1.9980e-04\n",
      "Epoch 1045/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7458e-04 - val_loss: 1.8538e-04\n",
      "Epoch 1046/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6015e-04 - val_loss: 1.8358e-04\n",
      "Epoch 1047/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7253e-04 - val_loss: 1.8206e-04\n",
      "Epoch 1048/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7570e-04 - val_loss: 1.9524e-04\n",
      "Epoch 1049/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7787e-04 - val_loss: 1.8258e-04\n",
      "Epoch 1050/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.7442e-04 - val_loss: 1.9072e-04\n",
      "Epoch 1051/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8318e-04 - val_loss: 1.9789e-04\n",
      "Epoch 1052/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6968e-04 - val_loss: 1.8590e-04\n",
      "Epoch 1053/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7821e-04 - val_loss: 1.9872e-04\n",
      "Epoch 1054/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7630e-04 - val_loss: 1.8901e-04\n",
      "Epoch 1055/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6700e-04 - val_loss: 1.8446e-04\n",
      "Epoch 1056/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.6716e-04 - val_loss: 1.8360e-04\n",
      "Epoch 1057/2000\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 1.6814e-04 - val_loss: 1.8319e-04\n",
      "Epoch 1058/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 248us/step - loss: 1.6407e-04 - val_loss: 1.8508e-04\n",
      "Epoch 1059/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6849e-04 - val_loss: 1.9815e-04\n",
      "Epoch 1060/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.6622e-04 - val_loss: 2.1765e-04\n",
      "Epoch 1061/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.6305e-04 - val_loss: 1.8979e-04\n",
      "Epoch 1062/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5986e-04 - val_loss: 2.0356e-04\n",
      "Epoch 1063/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6800e-04 - val_loss: 2.0538e-04\n",
      "Epoch 1064/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6607e-04 - val_loss: 1.9779e-04\n",
      "Epoch 1065/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7186e-04 - val_loss: 1.9758e-04\n",
      "Epoch 1066/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6763e-04 - val_loss: 2.3368e-04\n",
      "Epoch 1067/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6709e-04 - val_loss: 1.8991e-04\n",
      "Epoch 1068/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6382e-04 - val_loss: 1.8460e-04\n",
      "Epoch 1069/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6375e-04 - val_loss: 1.9256e-04\n",
      "Epoch 1070/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7141e-04 - val_loss: 1.8334e-04\n",
      "Epoch 1071/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6661e-04 - val_loss: 1.9167e-04\n",
      "Epoch 1072/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6148e-04 - val_loss: 1.8841e-04\n",
      "Epoch 1073/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6579e-04 - val_loss: 1.8411e-04\n",
      "Epoch 1074/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6584e-04 - val_loss: 2.0020e-04\n",
      "Epoch 1075/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6414e-04 - val_loss: 1.8833e-04\n",
      "Epoch 1076/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.6023e-04 - val_loss: 1.9365e-04\n",
      "Epoch 1077/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5861e-04 - val_loss: 1.8913e-04\n",
      "Epoch 1078/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5985e-04 - val_loss: 1.8481e-04\n",
      "Epoch 1079/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.6168e-04 - val_loss: 1.8789e-04\n",
      "Epoch 1080/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6235e-04 - val_loss: 1.8531e-04\n",
      "Epoch 1081/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.5976e-04 - val_loss: 1.9352e-04\n",
      "Epoch 1082/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6203e-04 - val_loss: 1.8847e-04\n",
      "Epoch 1083/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.6262e-04 - val_loss: 1.9133e-04\n",
      "Epoch 1084/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 1.6173e-04 - val_loss: 1.9228e-04\n",
      "Epoch 1085/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6170e-04 - val_loss: 2.0180e-04\n",
      "Epoch 1086/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.6526e-04 - val_loss: 1.9647e-04\n",
      "Epoch 1087/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.6089e-04 - val_loss: 2.0933e-04\n",
      "Epoch 1088/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.6435e-04 - val_loss: 1.8270e-04\n",
      "Epoch 1089/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.5657e-04 - val_loss: 1.8727e-04\n",
      "Epoch 1090/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.6053e-04 - val_loss: 2.0368e-04\n",
      "Epoch 1091/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.6518e-04 - val_loss: 1.9401e-04\n",
      "Epoch 1092/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 1.6416e-04 - val_loss: 2.2768e-04\n",
      "Epoch 1093/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.7186e-04 - val_loss: 2.0022e-04\n",
      "Epoch 1094/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.6307e-04 - val_loss: 2.0085e-04\n",
      "Epoch 1095/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5872e-04 - val_loss: 1.9417e-04\n",
      "Epoch 1096/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6267e-04 - val_loss: 2.0404e-04\n",
      "Epoch 1097/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6036e-04 - val_loss: 1.8886e-04\n",
      "Epoch 1098/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 1.5616e-04 - val_loss: 1.8411e-04\n",
      "Epoch 1099/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.5697e-04 - val_loss: 1.9162e-04\n",
      "Epoch 1100/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6129e-04 - val_loss: 2.1349e-04\n",
      "Epoch 1101/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6649e-04 - val_loss: 2.2709e-04\n",
      "Epoch 1102/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6534e-04 - val_loss: 2.3143e-04\n",
      "Epoch 1103/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.6969e-04 - val_loss: 1.9502e-04\n",
      "Epoch 1104/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.6222e-04 - val_loss: 2.0466e-04\n",
      "Epoch 1105/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6480e-04 - val_loss: 1.8598e-04\n",
      "Epoch 1106/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5991e-04 - val_loss: 1.9039e-04\n",
      "Epoch 1107/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6199e-04 - val_loss: 1.8527e-04\n",
      "Epoch 1108/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6466e-04 - val_loss: 1.8698e-04\n",
      "Epoch 1109/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5641e-04 - val_loss: 2.0021e-04\n",
      "Epoch 1110/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.5725e-04 - val_loss: 1.8749e-04\n",
      "Epoch 1111/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.6062e-04 - val_loss: 1.8541e-04\n",
      "Epoch 1112/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5903e-04 - val_loss: 1.9246e-04\n",
      "Epoch 1113/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5665e-04 - val_loss: 1.8706e-04\n",
      "Epoch 1114/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.5870e-04 - val_loss: 2.0173e-04\n",
      "Epoch 1115/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6291e-04 - val_loss: 2.0696e-04\n",
      "Epoch 1116/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6842e-04 - val_loss: 2.0002e-04\n",
      "Epoch 1117/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6038e-04 - val_loss: 1.9950e-04\n",
      "Epoch 1118/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6237e-04 - val_loss: 1.8942e-04\n",
      "Epoch 1119/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.7331e-04 - val_loss: 2.1585e-04\n",
      "Epoch 1120/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.7482e-04 - val_loss: 1.8279e-04\n",
      "Epoch 1121/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5931e-04 - val_loss: 2.0026e-04\n",
      "Epoch 1122/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.5683e-04 - val_loss: 1.9682e-04\n",
      "Epoch 1123/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6404e-04 - val_loss: 2.3973e-04\n",
      "Epoch 1124/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6616e-04 - val_loss: 1.8833e-04\n",
      "Epoch 1125/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5624e-04 - val_loss: 1.8479e-04\n",
      "Epoch 1126/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5815e-04 - val_loss: 1.9358e-04\n",
      "Epoch 1127/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7369e-04 - val_loss: 2.2545e-04\n",
      "Epoch 1128/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6672e-04 - val_loss: 1.8858e-04\n",
      "Epoch 1129/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6073e-04 - val_loss: 1.8438e-04\n",
      "Epoch 1130/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5895e-04 - val_loss: 1.8877e-04\n",
      "Epoch 1131/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6054e-04 - val_loss: 1.8434e-04\n",
      "Epoch 1132/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6044e-04 - val_loss: 1.9233e-04\n",
      "Epoch 1133/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5554e-04 - val_loss: 1.8883e-04\n",
      "Epoch 1134/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6045e-04 - val_loss: 1.8359e-04\n",
      "Epoch 1135/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.6035e-04 - val_loss: 1.8609e-04\n",
      "Epoch 1136/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5369e-04 - val_loss: 1.8629e-04\n",
      "Epoch 1137/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5354e-04 - val_loss: 1.8532e-04\n",
      "Epoch 1138/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5566e-04 - val_loss: 1.9083e-04\n",
      "Epoch 1139/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5427e-04 - val_loss: 1.9542e-04\n",
      "Epoch 1140/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.5646e-04 - val_loss: 1.8749e-04\n",
      "Epoch 1141/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5531e-04 - val_loss: 1.8902e-04\n",
      "Epoch 1142/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6558e-04 - val_loss: 2.5222e-04\n",
      "Epoch 1143/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.8296e-04 - val_loss: 2.7314e-04\n",
      "Epoch 1144/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.8982e-04 - val_loss: 3.6958e-04\n",
      "Epoch 1145/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 2.1047e-04 - val_loss: 2.2779e-04\n",
      "Epoch 1146/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.8554e-04 - val_loss: 1.8645e-04\n",
      "Epoch 1147/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6378e-04 - val_loss: 1.8686e-04\n",
      "Epoch 1148/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5862e-04 - val_loss: 1.9169e-04\n",
      "Epoch 1149/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6032e-04 - val_loss: 1.8247e-04\n",
      "Epoch 1150/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5983e-04 - val_loss: 1.8515e-04\n",
      "Epoch 1151/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6101e-04 - val_loss: 1.8916e-04\n",
      "Epoch 1152/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5802e-04 - val_loss: 1.8722e-04\n",
      "Epoch 1153/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5558e-04 - val_loss: 1.9455e-04\n",
      "Epoch 1154/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5561e-04 - val_loss: 1.8406e-04\n",
      "Epoch 1155/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.5392e-04 - val_loss: 1.8685e-04\n",
      "Epoch 1156/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5436e-04 - val_loss: 1.9129e-04\n",
      "Epoch 1157/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5514e-04 - val_loss: 1.8529e-04\n",
      "Epoch 1158/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5303e-04 - val_loss: 1.9303e-04\n",
      "Epoch 1159/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5588e-04 - val_loss: 2.0881e-04\n",
      "Epoch 1160/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5747e-04 - val_loss: 1.9550e-04\n",
      "Epoch 1161/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6157e-04 - val_loss: 1.8731e-04\n",
      "Epoch 1162/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6125e-04 - val_loss: 1.8956e-04\n",
      "Epoch 1163/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6372e-04 - val_loss: 1.8691e-04\n",
      "Epoch 1164/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6572e-04 - val_loss: 1.8585e-04\n",
      "Epoch 1165/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6395e-04 - val_loss: 1.9364e-04\n",
      "Epoch 1166/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.6123e-04 - val_loss: 1.9208e-04\n",
      "Epoch 1167/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5737e-04 - val_loss: 1.8970e-04\n",
      "Epoch 1168/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6122e-04 - val_loss: 2.0604e-04\n",
      "Epoch 1169/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.6417e-04 - val_loss: 2.0129e-04\n",
      "Epoch 1170/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6788e-04 - val_loss: 2.1668e-04\n",
      "Epoch 1171/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6305e-04 - val_loss: 1.9428e-04\n",
      "Epoch 1172/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5826e-04 - val_loss: 1.9782e-04\n",
      "Epoch 1173/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5785e-04 - val_loss: 2.2652e-04\n",
      "Epoch 1174/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.6208e-04 - val_loss: 2.0492e-04\n",
      "Epoch 1175/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5847e-04 - val_loss: 2.1345e-04\n",
      "Epoch 1176/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5961e-04 - val_loss: 1.8646e-04\n",
      "Epoch 1177/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.5914e-04 - val_loss: 2.0261e-04\n",
      "Epoch 1178/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6983e-04 - val_loss: 1.9438e-04\n",
      "Epoch 1179/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.7050e-04 - val_loss: 1.8810e-04\n",
      "Epoch 1180/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5517e-04 - val_loss: 1.8579e-04\n",
      "Epoch 1181/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5271e-04 - val_loss: 1.8754e-04\n",
      "Epoch 1182/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.5597e-04 - val_loss: 1.8925e-04\n",
      "Epoch 1183/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.5726e-04 - val_loss: 1.9652e-04\n",
      "Epoch 1184/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5569e-04 - val_loss: 1.9709e-04\n",
      "Epoch 1185/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5111e-04 - val_loss: 1.8372e-04\n",
      "Epoch 1186/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5382e-04 - val_loss: 1.9083e-04\n",
      "Epoch 1187/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5981e-04 - val_loss: 2.1774e-04\n",
      "Epoch 1188/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6176e-04 - val_loss: 1.9047e-04\n",
      "Epoch 1189/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5304e-04 - val_loss: 1.8923e-04\n",
      "Epoch 1190/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5911e-04 - val_loss: 1.8391e-04\n",
      "Epoch 1191/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.6014e-04 - val_loss: 1.8737e-04\n",
      "Epoch 1192/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5889e-04 - val_loss: 1.8613e-04\n",
      "Epoch 1193/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5737e-04 - val_loss: 1.9289e-04\n",
      "Epoch 1194/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6324e-04 - val_loss: 2.1617e-04\n",
      "Epoch 1195/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6333e-04 - val_loss: 1.9537e-04\n",
      "Epoch 1196/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5682e-04 - val_loss: 1.9618e-04\n",
      "Epoch 1197/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6155e-04 - val_loss: 1.9935e-04\n",
      "Epoch 1198/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5612e-04 - val_loss: 1.8572e-04\n",
      "Epoch 1199/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.5338e-04 - val_loss: 2.0589e-04\n",
      "Epoch 1200/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6132e-04 - val_loss: 2.2700e-04\n",
      "Epoch 1201/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5763e-04 - val_loss: 1.8771e-04\n",
      "Epoch 1202/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5319e-04 - val_loss: 1.9676e-04\n",
      "Epoch 1203/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5399e-04 - val_loss: 1.9090e-04\n",
      "Epoch 1204/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5365e-04 - val_loss: 1.8890e-04\n",
      "Epoch 1205/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5065e-04 - val_loss: 1.8515e-04\n",
      "Epoch 1206/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5071e-04 - val_loss: 1.9280e-04\n",
      "Epoch 1207/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5433e-04 - val_loss: 1.9016e-04\n",
      "Epoch 1208/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5158e-04 - val_loss: 1.8587e-04\n",
      "Epoch 1209/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.5094e-04 - val_loss: 2.1447e-04\n",
      "Epoch 1210/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5168e-04 - val_loss: 1.9002e-04\n",
      "Epoch 1211/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5099e-04 - val_loss: 2.1917e-04\n",
      "Epoch 1212/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5994e-04 - val_loss: 1.9937e-04\n",
      "Epoch 1213/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5636e-04 - val_loss: 1.8934e-04\n",
      "Epoch 1214/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5042e-04 - val_loss: 1.8844e-04\n",
      "Epoch 1215/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5092e-04 - val_loss: 1.8940e-04\n",
      "Epoch 1216/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.5064e-04 - val_loss: 1.9280e-04\n",
      "Epoch 1217/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5327e-04 - val_loss: 2.0947e-04\n",
      "Epoch 1218/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.5206e-04 - val_loss: 1.9408e-04\n",
      "Epoch 1219/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5326e-04 - val_loss: 2.3467e-04\n",
      "Epoch 1220/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5570e-04 - val_loss: 1.9397e-04\n",
      "Epoch 1221/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5081e-04 - val_loss: 1.8432e-04\n",
      "Epoch 1222/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5272e-04 - val_loss: 1.9696e-04\n",
      "Epoch 1223/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5387e-04 - val_loss: 1.8913e-04\n",
      "Epoch 1224/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4970e-04 - val_loss: 1.8587e-04\n",
      "Epoch 1225/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.4885e-04 - val_loss: 1.9147e-04\n",
      "Epoch 1226/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5173e-04 - val_loss: 1.8616e-04\n",
      "Epoch 1227/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5041e-04 - val_loss: 1.9115e-04\n",
      "Epoch 1228/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4820e-04 - val_loss: 1.8968e-04\n",
      "Epoch 1229/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5238e-04 - val_loss: 1.8770e-04\n",
      "Epoch 1230/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4885e-04 - val_loss: 1.9151e-04\n",
      "Epoch 1231/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.4812e-04 - val_loss: 1.8980e-04\n",
      "Epoch 1232/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4687e-04 - val_loss: 1.9167e-04\n",
      "Epoch 1233/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4893e-04 - val_loss: 1.8467e-04\n",
      "Epoch 1234/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.6513e-04 - val_loss: 1.9256e-04\n",
      "Epoch 1235/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5956e-04 - val_loss: 1.9491e-04\n",
      "Epoch 1236/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5890e-04 - val_loss: 1.8560e-04\n",
      "Epoch 1237/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5766e-04 - val_loss: 2.0401e-04\n",
      "Epoch 1238/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5283e-04 - val_loss: 1.9844e-04\n",
      "Epoch 1239/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4789e-04 - val_loss: 1.8903e-04\n",
      "Epoch 1240/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5295e-04 - val_loss: 1.9130e-04\n",
      "Epoch 1241/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5065e-04 - val_loss: 1.8791e-04\n",
      "Epoch 1242/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5054e-04 - val_loss: 1.9844e-04\n",
      "Epoch 1243/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.5368e-04 - val_loss: 1.9722e-04\n",
      "Epoch 1244/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4970e-04 - val_loss: 1.9001e-04\n",
      "Epoch 1245/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.4808e-04 - val_loss: 1.9153e-04\n",
      "Epoch 1246/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.4853e-04 - val_loss: 1.9460e-04\n",
      "Epoch 1247/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5363e-04 - val_loss: 1.9125e-04\n",
      "Epoch 1248/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5637e-04 - val_loss: 1.9624e-04\n",
      "Epoch 1249/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5367e-04 - val_loss: 2.0413e-04\n",
      "Epoch 1250/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4849e-04 - val_loss: 1.9082e-04\n",
      "Epoch 1251/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.4958e-04 - val_loss: 1.9294e-04\n",
      "Epoch 1252/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.4565e-04 - val_loss: 1.9155e-04\n",
      "Epoch 1253/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4797e-04 - val_loss: 2.0079e-04\n",
      "Epoch 1254/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5184e-04 - val_loss: 1.9179e-04\n",
      "Epoch 1255/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.4880e-04 - val_loss: 1.8816e-04\n",
      "Epoch 1256/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5124e-04 - val_loss: 2.1163e-04\n",
      "Epoch 1257/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.6483e-04 - val_loss: 1.8806e-04\n",
      "Epoch 1258/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5703e-04 - val_loss: 1.8615e-04\n",
      "Epoch 1259/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.5346e-04 - val_loss: 2.1134e-04\n",
      "Epoch 1260/2000\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 1.6013e-04 - val_loss: 1.9724e-04\n",
      "Epoch 1261/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5121e-04 - val_loss: 2.0109e-04\n",
      "Epoch 1262/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 1.5068e-04 - val_loss: 2.1714e-04\n",
      "Epoch 1263/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.6662e-04 - val_loss: 2.7293e-04\n",
      "Epoch 1264/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.7632e-04 - val_loss: 2.0221e-04\n",
      "Epoch 1265/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6135e-04 - val_loss: 2.2661e-04\n",
      "Epoch 1266/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.6113e-04 - val_loss: 2.1143e-04\n",
      "Epoch 1267/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.6158e-04 - val_loss: 1.9898e-04\n",
      "Epoch 1268/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4740e-04 - val_loss: 1.9150e-04\n",
      "Epoch 1269/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4553e-04 - val_loss: 1.9127e-04\n",
      "Epoch 1270/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4916e-04 - val_loss: 1.9550e-04\n",
      "Epoch 1271/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.5364e-04 - val_loss: 1.9093e-04\n",
      "Epoch 1272/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5094e-04 - val_loss: 1.8920e-04\n",
      "Epoch 1273/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4706e-04 - val_loss: 2.0443e-04\n",
      "Epoch 1274/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4682e-04 - val_loss: 1.9170e-04\n",
      "Epoch 1275/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.4873e-04 - val_loss: 1.9232e-04\n",
      "Epoch 1276/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4562e-04 - val_loss: 2.0264e-04\n",
      "Epoch 1277/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5386e-04 - val_loss: 2.0472e-04\n",
      "Epoch 1278/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4824e-04 - val_loss: 1.9292e-04\n",
      "Epoch 1279/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.4854e-04 - val_loss: 1.9240e-04\n",
      "Epoch 1280/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.5936e-04 - val_loss: 1.9057e-04\n",
      "Epoch 1281/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5008e-04 - val_loss: 2.1386e-04\n",
      "Epoch 1282/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.5201e-04 - val_loss: 2.2993e-04\n",
      "Epoch 1283/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5135e-04 - val_loss: 1.9154e-04\n",
      "Epoch 1284/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4397e-04 - val_loss: 1.9140e-04\n",
      "Epoch 1285/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.4440e-04 - val_loss: 1.9352e-04\n",
      "Epoch 1286/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4446e-04 - val_loss: 2.0187e-04\n",
      "Epoch 1287/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5203e-04 - val_loss: 2.1057e-04\n",
      "Epoch 1288/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5206e-04 - val_loss: 1.9766e-04\n",
      "Epoch 1289/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.6179e-04 - val_loss: 2.0190e-04\n",
      "Epoch 1290/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.6351e-04 - val_loss: 1.8964e-04\n",
      "Epoch 1291/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.5625e-04 - val_loss: 2.0362e-04\n",
      "Epoch 1292/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.4925e-04 - val_loss: 1.9693e-04\n",
      "Epoch 1293/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4716e-04 - val_loss: 1.9387e-04\n",
      "Epoch 1294/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.5164e-04 - val_loss: 2.1869e-04\n",
      "Epoch 1295/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.5112e-04 - val_loss: 2.2931e-04\n",
      "Epoch 1296/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.4703e-04 - val_loss: 1.9965e-04\n",
      "Epoch 1297/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.4274e-04 - val_loss: 1.9425e-04\n",
      "Epoch 1298/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.3892e-04 - val_loss: 1.9465e-04\n",
      "Epoch 1299/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.3900e-04 - val_loss: 1.9868e-04\n",
      "Epoch 1300/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.4105e-04 - val_loss: 2.0645e-04\n",
      "Epoch 1301/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4865e-04 - val_loss: 2.0305e-04\n",
      "Epoch 1302/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4674e-04 - val_loss: 2.1117e-04\n",
      "Epoch 1303/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4404e-04 - val_loss: 2.0092e-04\n",
      "Epoch 1304/2000\n",
      "4059/4059 [==============================] - 1s 234us/step - loss: 1.4313e-04 - val_loss: 2.1440e-04\n",
      "Epoch 1305/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4795e-04 - val_loss: 2.3461e-04\n",
      "Epoch 1306/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.5054e-04 - val_loss: 2.0340e-04\n",
      "Epoch 1307/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5539e-04 - val_loss: 1.9522e-04\n",
      "Epoch 1308/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.4963e-04 - val_loss: 1.8683e-04\n",
      "Epoch 1309/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.5337e-04 - val_loss: 2.2576e-04\n",
      "Epoch 1310/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.5067e-04 - val_loss: 2.0101e-04\n",
      "Epoch 1311/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.5201e-04 - val_loss: 1.9844e-04\n",
      "Epoch 1312/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.5453e-04 - val_loss: 1.9905e-04\n",
      "Epoch 1313/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.4645e-04 - val_loss: 1.9306e-04\n",
      "Epoch 1314/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4003e-04 - val_loss: 1.9292e-04\n",
      "Epoch 1315/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.3878e-04 - val_loss: 1.9986e-04\n",
      "Epoch 1316/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4224e-04 - val_loss: 2.1190e-04\n",
      "Epoch 1317/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.4200e-04 - val_loss: 2.0320e-04\n",
      "Epoch 1318/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4388e-04 - val_loss: 2.0916e-04\n",
      "Epoch 1319/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.4158e-04 - val_loss: 2.0461e-04\n",
      "Epoch 1320/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.3991e-04 - val_loss: 1.9945e-04\n",
      "Epoch 1321/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.3769e-04 - val_loss: 1.9683e-04\n",
      "Epoch 1322/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.4389e-04 - val_loss: 2.0973e-04\n",
      "Epoch 1323/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5039e-04 - val_loss: 2.0709e-04\n",
      "Epoch 1324/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5036e-04 - val_loss: 1.9650e-04\n",
      "Epoch 1325/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4818e-04 - val_loss: 2.0614e-04\n",
      "Epoch 1326/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4472e-04 - val_loss: 1.9594e-04\n",
      "Epoch 1327/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.4056e-04 - val_loss: 1.9329e-04\n",
      "Epoch 1328/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4315e-04 - val_loss: 2.1919e-04\n",
      "Epoch 1329/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.5574e-04 - val_loss: 2.1415e-04\n",
      "Epoch 1330/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.4656e-04 - val_loss: 2.0938e-04\n",
      "Epoch 1331/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4619e-04 - val_loss: 1.9323e-04\n",
      "Epoch 1332/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4303e-04 - val_loss: 2.2428e-04\n",
      "Epoch 1333/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4492e-04 - val_loss: 2.0342e-04\n",
      "Epoch 1334/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3821e-04 - val_loss: 1.9445e-04\n",
      "Epoch 1335/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.3723e-04 - val_loss: 2.4348e-04\n",
      "Epoch 1336/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.5791e-04 - val_loss: 1.9741e-04\n",
      "Epoch 1337/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.5610e-04 - val_loss: 2.0710e-04\n",
      "Epoch 1338/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5427e-04 - val_loss: 2.2052e-04\n",
      "Epoch 1339/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5137e-04 - val_loss: 2.5958e-04\n",
      "Epoch 1340/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.5456e-04 - val_loss: 1.8968e-04\n",
      "Epoch 1341/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.3947e-04 - val_loss: 2.0679e-04\n",
      "Epoch 1342/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.4405e-04 - val_loss: 2.0061e-04\n",
      "Epoch 1343/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4149e-04 - val_loss: 2.0907e-04\n",
      "Epoch 1344/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.4166e-04 - val_loss: 2.2250e-04\n",
      "Epoch 1345/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4132e-04 - val_loss: 1.9706e-04\n",
      "Epoch 1346/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3909e-04 - val_loss: 1.9593e-04\n",
      "Epoch 1347/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4289e-04 - val_loss: 2.0565e-04\n",
      "Epoch 1348/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4230e-04 - val_loss: 1.9586e-04\n",
      "Epoch 1349/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4559e-04 - val_loss: 2.0480e-04\n",
      "Epoch 1350/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.4039e-04 - val_loss: 1.9607e-04\n",
      "Epoch 1351/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.3892e-04 - val_loss: 2.0002e-04\n",
      "Epoch 1352/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.5078e-04 - val_loss: 2.2680e-04\n",
      "Epoch 1353/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.4893e-04 - val_loss: 2.0691e-04\n",
      "Epoch 1354/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.4326e-04 - val_loss: 2.0799e-04\n",
      "Epoch 1355/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.4085e-04 - val_loss: 2.2648e-04\n",
      "Epoch 1356/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4000e-04 - val_loss: 2.0811e-04\n",
      "Epoch 1357/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4833e-04 - val_loss: 2.2110e-04\n",
      "Epoch 1358/2000\n",
      "4059/4059 [==============================] - 1s 235us/step - loss: 1.3821e-04 - val_loss: 2.0269e-04\n",
      "Epoch 1359/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4002e-04 - val_loss: 2.1698e-04\n",
      "Epoch 1360/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4014e-04 - val_loss: 2.1591e-04\n",
      "Epoch 1361/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4339e-04 - val_loss: 2.0513e-04\n",
      "Epoch 1362/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.3822e-04 - val_loss: 1.9850e-04\n",
      "Epoch 1363/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3814e-04 - val_loss: 2.2305e-04\n",
      "Epoch 1364/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.4280e-04 - val_loss: 2.1159e-04\n",
      "Epoch 1365/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4738e-04 - val_loss: 2.1310e-04\n",
      "Epoch 1366/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 1.4391e-04 - val_loss: 2.0217e-04\n",
      "Epoch 1367/2000\n",
      "4059/4059 [==============================] - 1s 265us/step - loss: 1.3612e-04 - val_loss: 2.3432e-04\n",
      "Epoch 1368/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 1.4135e-04 - val_loss: 2.2726e-04\n",
      "Epoch 1369/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.3490e-04 - val_loss: 2.1000e-04\n",
      "Epoch 1370/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.4166e-04 - val_loss: 2.2108e-04\n",
      "Epoch 1371/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 1.4994e-04 - val_loss: 2.2813e-04\n",
      "Epoch 1372/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 1.5281e-04 - val_loss: 2.4938e-04\n",
      "Epoch 1373/2000\n",
      "4059/4059 [==============================] - 1s 277us/step - loss: 1.4727e-04 - val_loss: 2.3616e-04\n",
      "Epoch 1374/2000\n",
      "4059/4059 [==============================] - 1s 277us/step - loss: 1.4643e-04 - val_loss: 2.2787e-04\n",
      "Epoch 1375/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 1.4156e-04 - val_loss: 2.1731e-04\n",
      "Epoch 1376/2000\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 1.4146e-04 - val_loss: 2.1382e-04\n",
      "Epoch 1377/2000\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 1.3896e-04 - val_loss: 2.0390e-04\n",
      "Epoch 1378/2000\n",
      "4059/4059 [==============================] - 1s 280us/step - loss: 1.3785e-04 - val_loss: 2.0828e-04\n",
      "Epoch 1379/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 1.3586e-04 - val_loss: 1.9832e-04\n",
      "Epoch 1380/2000\n",
      "4059/4059 [==============================] - 1s 267us/step - loss: 1.3478e-04 - val_loss: 2.0436e-04\n",
      "Epoch 1381/2000\n",
      "4059/4059 [==============================] - 1s 269us/step - loss: 1.3610e-04 - val_loss: 2.2187e-04\n",
      "Epoch 1382/2000\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 1.3887e-04 - val_loss: 2.0683e-04\n",
      "Epoch 1383/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 1.3531e-04 - val_loss: 2.1877e-04\n",
      "Epoch 1384/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 1.3736e-04 - val_loss: 2.0533e-04\n",
      "Epoch 1385/2000\n",
      "4059/4059 [==============================] - 1s 261us/step - loss: 1.4686e-04 - val_loss: 2.1381e-04\n",
      "Epoch 1386/2000\n",
      "4059/4059 [==============================] - 1s 284us/step - loss: 1.4140e-04 - val_loss: 2.1671e-04\n",
      "Epoch 1387/2000\n",
      "4059/4059 [==============================] - 1s 280us/step - loss: 1.4584e-04 - val_loss: 2.0833e-04\n",
      "Epoch 1388/2000\n",
      "4059/4059 [==============================] - 1s 273us/step - loss: 1.4245e-04 - val_loss: 2.1526e-04\n",
      "Epoch 1389/2000\n",
      "4059/4059 [==============================] - 1s 266us/step - loss: 1.4145e-04 - val_loss: 2.3047e-04\n",
      "Epoch 1390/2000\n",
      "4059/4059 [==============================] - 1s 256us/step - loss: 1.4075e-04 - val_loss: 2.1069e-04\n",
      "Epoch 1391/2000\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 1.3461e-04 - val_loss: 2.1298e-04\n",
      "Epoch 1392/2000\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 1.3428e-04 - val_loss: 2.1223e-04\n",
      "Epoch 1393/2000\n",
      "4059/4059 [==============================] - 1s 265us/step - loss: 1.3358e-04 - val_loss: 2.0765e-04\n",
      "Epoch 1394/2000\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 1.3354e-04 - val_loss: 2.2107e-04\n",
      "Epoch 1395/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.3893e-04 - val_loss: 2.1158e-04\n",
      "Epoch 1396/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.4012e-04 - val_loss: 2.0919e-04\n",
      "Epoch 1397/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.4892e-04 - val_loss: 1.9879e-04\n",
      "Epoch 1398/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.4136e-04 - val_loss: 2.1479e-04\n",
      "Epoch 1399/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4090e-04 - val_loss: 2.1989e-04\n",
      "Epoch 1400/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.3707e-04 - val_loss: 2.1153e-04\n",
      "Epoch 1401/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.3238e-04 - val_loss: 2.1152e-04\n",
      "Epoch 1402/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.3007e-04 - val_loss: 2.0987e-04\n",
      "Epoch 1403/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.3580e-04 - val_loss: 2.2399e-04\n",
      "Epoch 1404/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.3990e-04 - val_loss: 2.0278e-04\n",
      "Epoch 1405/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3310e-04 - val_loss: 2.2379e-04\n",
      "Epoch 1406/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.3312e-04 - val_loss: 2.1012e-04\n",
      "Epoch 1407/2000\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 1.3288e-04 - val_loss: 2.1573e-04\n",
      "Epoch 1408/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3444e-04 - val_loss: 2.3156e-04\n",
      "Epoch 1409/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.3066e-04 - val_loss: 2.0659e-04\n",
      "Epoch 1410/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.3074e-04 - val_loss: 2.2824e-04\n",
      "Epoch 1411/2000\n",
      "4059/4059 [==============================] - 1s 268us/step - loss: 1.3899e-04 - val_loss: 2.2002e-04\n",
      "Epoch 1412/2000\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 1.3406e-04 - val_loss: 2.3507e-04\n",
      "Epoch 1413/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.3370e-04 - val_loss: 2.1976e-04\n",
      "Epoch 1414/2000\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 1.2978e-04 - val_loss: 2.2417e-04\n",
      "Epoch 1415/2000\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 1.3433e-04 - val_loss: 2.6163e-04\n",
      "Epoch 1416/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.3184e-04 - val_loss: 2.1117e-04\n",
      "Epoch 1417/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2967e-04 - val_loss: 2.2386e-04\n",
      "Epoch 1418/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3274e-04 - val_loss: 2.3358e-04\n",
      "Epoch 1419/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3878e-04 - val_loss: 2.3927e-04\n",
      "Epoch 1420/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3238e-04 - val_loss: 2.1380e-04\n",
      "Epoch 1421/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2937e-04 - val_loss: 2.4109e-04\n",
      "Epoch 1422/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3054e-04 - val_loss: 2.3384e-04\n",
      "Epoch 1423/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.2835e-04 - val_loss: 2.1429e-04\n",
      "Epoch 1424/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2876e-04 - val_loss: 2.2706e-04\n",
      "Epoch 1425/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.3260e-04 - val_loss: 2.1715e-04\n",
      "Epoch 1426/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.3459e-04 - val_loss: 2.2620e-04\n",
      "Epoch 1427/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3846e-04 - val_loss: 2.3420e-04\n",
      "Epoch 1428/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.3747e-04 - val_loss: 2.3934e-04\n",
      "Epoch 1429/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4532e-04 - val_loss: 2.3725e-04\n",
      "Epoch 1430/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3417e-04 - val_loss: 2.1333e-04\n",
      "Epoch 1431/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3015e-04 - val_loss: 2.2926e-04\n",
      "Epoch 1432/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.3887e-04 - val_loss: 2.2364e-04\n",
      "Epoch 1433/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3633e-04 - val_loss: 2.0990e-04\n",
      "Epoch 1434/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.3548e-04 - val_loss: 2.4117e-04\n",
      "Epoch 1435/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3740e-04 - val_loss: 2.2185e-04\n",
      "Epoch 1436/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3906e-04 - val_loss: 2.3077e-04\n",
      "Epoch 1437/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3493e-04 - val_loss: 2.2054e-04\n",
      "Epoch 1438/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.4646e-04 - val_loss: 2.1685e-04\n",
      "Epoch 1439/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4756e-04 - val_loss: 2.0739e-04\n",
      "Epoch 1440/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.3538e-04 - val_loss: 2.3854e-04\n",
      "Epoch 1441/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.3135e-04 - val_loss: 2.1540e-04\n",
      "Epoch 1442/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.3115e-04 - val_loss: 2.2068e-04\n",
      "Epoch 1443/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.2518e-04 - val_loss: 2.1563e-04\n",
      "Epoch 1444/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.2367e-04 - val_loss: 2.1349e-04\n",
      "Epoch 1445/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2670e-04 - val_loss: 2.2758e-04\n",
      "Epoch 1446/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2604e-04 - val_loss: 2.1934e-04\n",
      "Epoch 1447/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.2594e-04 - val_loss: 2.3554e-04\n",
      "Epoch 1448/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2024e-04 - val_loss: 2.1748e-04\n",
      "Epoch 1449/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2342e-04 - val_loss: 2.2062e-04\n",
      "Epoch 1450/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2820e-04 - val_loss: 2.2111e-04\n",
      "Epoch 1451/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.2714e-04 - val_loss: 2.2088e-04\n",
      "Epoch 1452/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3174e-04 - val_loss: 2.3228e-04\n",
      "Epoch 1453/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2731e-04 - val_loss: 2.4939e-04\n",
      "Epoch 1454/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3664e-04 - val_loss: 2.7842e-04\n",
      "Epoch 1455/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3351e-04 - val_loss: 2.1797e-04\n",
      "Epoch 1456/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.3587e-04 - val_loss: 2.7175e-04\n",
      "Epoch 1457/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4051e-04 - val_loss: 2.1775e-04\n",
      "Epoch 1458/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3309e-04 - val_loss: 2.2322e-04\n",
      "Epoch 1459/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.3272e-04 - val_loss: 2.2988e-04\n",
      "Epoch 1460/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.3096e-04 - val_loss: 2.1931e-04\n",
      "Epoch 1461/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2617e-04 - val_loss: 2.2786e-04\n",
      "Epoch 1462/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2415e-04 - val_loss: 2.2737e-04\n",
      "Epoch 1463/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2846e-04 - val_loss: 2.3589e-04\n",
      "Epoch 1464/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.2582e-04 - val_loss: 2.5428e-04\n",
      "Epoch 1465/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.3043e-04 - val_loss: 2.5873e-04\n",
      "Epoch 1466/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2868e-04 - val_loss: 2.2304e-04\n",
      "Epoch 1467/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2492e-04 - val_loss: 2.6746e-04\n",
      "Epoch 1468/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3013e-04 - val_loss: 2.3161e-04\n",
      "Epoch 1469/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2508e-04 - val_loss: 2.2855e-04\n",
      "Epoch 1470/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2654e-04 - val_loss: 2.3613e-04\n",
      "Epoch 1471/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3684e-04 - val_loss: 2.6028e-04\n",
      "Epoch 1472/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.3299e-04 - val_loss: 2.2164e-04\n",
      "Epoch 1473/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.2762e-04 - val_loss: 2.3128e-04\n",
      "Epoch 1474/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.2395e-04 - val_loss: 2.3981e-04\n",
      "Epoch 1475/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.1999e-04 - val_loss: 2.3554e-04\n",
      "Epoch 1476/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.2559e-04 - val_loss: 2.4497e-04\n",
      "Epoch 1477/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2695e-04 - val_loss: 2.4187e-04\n",
      "Epoch 1478/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2657e-04 - val_loss: 2.4600e-04\n",
      "Epoch 1479/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.3172e-04 - val_loss: 2.3244e-04\n",
      "Epoch 1480/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2176e-04 - val_loss: 2.4161e-04\n",
      "Epoch 1481/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2630e-04 - val_loss: 2.3844e-04\n",
      "Epoch 1482/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2672e-04 - val_loss: 2.3387e-04\n",
      "Epoch 1483/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.4144e-04 - val_loss: 2.6863e-04\n",
      "Epoch 1484/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3852e-04 - val_loss: 2.3307e-04\n",
      "Epoch 1485/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3290e-04 - val_loss: 2.4099e-04\n",
      "Epoch 1486/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.3623e-04 - val_loss: 2.3144e-04\n",
      "Epoch 1487/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 1.3285e-04 - val_loss: 2.3912e-04\n",
      "Epoch 1488/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.2652e-04 - val_loss: 2.3716e-04\n",
      "Epoch 1489/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3100e-04 - val_loss: 2.3749e-04\n",
      "Epoch 1490/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.2677e-04 - val_loss: 2.2881e-04\n",
      "Epoch 1491/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2424e-04 - val_loss: 2.6680e-04\n",
      "Epoch 1492/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.2559e-04 - val_loss: 2.4395e-04\n",
      "Epoch 1493/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1678e-04 - val_loss: 2.3086e-04\n",
      "Epoch 1494/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1937e-04 - val_loss: 2.4192e-04\n",
      "Epoch 1495/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2337e-04 - val_loss: 2.5188e-04\n",
      "Epoch 1496/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2594e-04 - val_loss: 2.6149e-04\n",
      "Epoch 1497/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3023e-04 - val_loss: 2.2475e-04\n",
      "Epoch 1498/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2956e-04 - val_loss: 2.4842e-04\n",
      "Epoch 1499/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.3807e-04 - val_loss: 2.3292e-04\n",
      "Epoch 1500/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3575e-04 - val_loss: 2.4035e-04\n",
      "Epoch 1501/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3201e-04 - val_loss: 2.5770e-04\n",
      "Epoch 1502/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3104e-04 - val_loss: 2.2771e-04\n",
      "Epoch 1503/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.2938e-04 - val_loss: 2.5978e-04\n",
      "Epoch 1504/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.4017e-04 - val_loss: 2.6144e-04\n",
      "Epoch 1505/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2668e-04 - val_loss: 2.3697e-04\n",
      "Epoch 1506/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2231e-04 - val_loss: 2.3456e-04\n",
      "Epoch 1507/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1806e-04 - val_loss: 2.3241e-04\n",
      "Epoch 1508/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1529e-04 - val_loss: 2.5775e-04\n",
      "Epoch 1509/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.1970e-04 - val_loss: 2.4097e-04\n",
      "Epoch 1510/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2123e-04 - val_loss: 2.7067e-04\n",
      "Epoch 1511/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2722e-04 - val_loss: 2.3658e-04\n",
      "Epoch 1512/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2128e-04 - val_loss: 2.4185e-04\n",
      "Epoch 1513/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.1782e-04 - val_loss: 2.5393e-04\n",
      "Epoch 1514/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2025e-04 - val_loss: 2.4091e-04\n",
      "Epoch 1515/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1803e-04 - val_loss: 2.4517e-04\n",
      "Epoch 1516/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1751e-04 - val_loss: 2.3980e-04\n",
      "Epoch 1517/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1979e-04 - val_loss: 3.1466e-04\n",
      "Epoch 1518/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.3045e-04 - val_loss: 2.4325e-04\n",
      "Epoch 1519/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3257e-04 - val_loss: 2.3912e-04\n",
      "Epoch 1520/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2442e-04 - val_loss: 2.5593e-04\n",
      "Epoch 1521/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2823e-04 - val_loss: 2.7864e-04\n",
      "Epoch 1522/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2788e-04 - val_loss: 2.4605e-04\n",
      "Epoch 1523/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1768e-04 - val_loss: 2.5404e-04\n",
      "Epoch 1524/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.1775e-04 - val_loss: 2.5282e-04\n",
      "Epoch 1525/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1871e-04 - val_loss: 2.7614e-04\n",
      "Epoch 1526/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1514e-04 - val_loss: 2.9244e-04\n",
      "Epoch 1527/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2439e-04 - val_loss: 2.5022e-04\n",
      "Epoch 1528/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2120e-04 - val_loss: 2.5326e-04\n",
      "Epoch 1529/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.1863e-04 - val_loss: 2.4194e-04\n",
      "Epoch 1530/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1592e-04 - val_loss: 2.5401e-04\n",
      "Epoch 1531/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2161e-04 - val_loss: 2.5609e-04\n",
      "Epoch 1532/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1879e-04 - val_loss: 2.4809e-04\n",
      "Epoch 1533/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2369e-04 - val_loss: 2.6992e-04\n",
      "Epoch 1534/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.1880e-04 - val_loss: 2.6179e-04\n",
      "Epoch 1535/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.1135e-04 - val_loss: 2.5077e-04\n",
      "Epoch 1536/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.1472e-04 - val_loss: 2.4941e-04\n",
      "Epoch 1537/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.1668e-04 - val_loss: 2.8544e-04\n",
      "Epoch 1538/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.2821e-04 - val_loss: 2.4957e-04\n",
      "Epoch 1539/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.1732e-04 - val_loss: 2.3932e-04\n",
      "Epoch 1540/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2068e-04 - val_loss: 2.5467e-04\n",
      "Epoch 1541/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1904e-04 - val_loss: 2.6438e-04\n",
      "Epoch 1542/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.1701e-04 - val_loss: 3.0799e-04\n",
      "Epoch 1543/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2257e-04 - val_loss: 2.5409e-04\n",
      "Epoch 1544/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2130e-04 - val_loss: 2.5630e-04\n",
      "Epoch 1545/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.3254e-04 - val_loss: 2.6830e-04\n",
      "Epoch 1546/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3310e-04 - val_loss: 3.0407e-04\n",
      "Epoch 1547/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2414e-04 - val_loss: 2.6425e-04\n",
      "Epoch 1548/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1428e-04 - val_loss: 2.7795e-04\n",
      "Epoch 1549/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1762e-04 - val_loss: 2.6231e-04\n",
      "Epoch 1550/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.1106e-04 - val_loss: 2.5742e-04\n",
      "Epoch 1551/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1733e-04 - val_loss: 2.7418e-04\n",
      "Epoch 1552/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2625e-04 - val_loss: 3.1518e-04\n",
      "Epoch 1553/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2988e-04 - val_loss: 2.7173e-04\n",
      "Epoch 1554/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2218e-04 - val_loss: 2.9260e-04\n",
      "Epoch 1555/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.1666e-04 - val_loss: 2.6860e-04\n",
      "Epoch 1556/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1496e-04 - val_loss: 2.7504e-04\n",
      "Epoch 1557/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2330e-04 - val_loss: 2.6280e-04\n",
      "Epoch 1558/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.1965e-04 - val_loss: 2.5104e-04\n",
      "Epoch 1559/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.1706e-04 - val_loss: 2.7534e-04\n",
      "Epoch 1560/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2078e-04 - val_loss: 2.5888e-04\n",
      "Epoch 1561/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1217e-04 - val_loss: 2.5975e-04\n",
      "Epoch 1562/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0848e-04 - val_loss: 2.8555e-04\n",
      "Epoch 1563/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1353e-04 - val_loss: 2.6986e-04\n",
      "Epoch 1564/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1191e-04 - val_loss: 2.6598e-04\n",
      "Epoch 1565/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.1488e-04 - val_loss: 2.8448e-04\n",
      "Epoch 1566/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1300e-04 - val_loss: 2.6113e-04\n",
      "Epoch 1567/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1289e-04 - val_loss: 2.6914e-04\n",
      "Epoch 1568/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1408e-04 - val_loss: 3.0201e-04\n",
      "Epoch 1569/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2480e-04 - val_loss: 2.5684e-04\n",
      "Epoch 1570/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1964e-04 - val_loss: 2.6921e-04\n",
      "Epoch 1571/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.0857e-04 - val_loss: 2.7330e-04\n",
      "Epoch 1572/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1575e-04 - val_loss: 2.7947e-04\n",
      "Epoch 1573/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3110e-04 - val_loss: 2.8087e-04\n",
      "Epoch 1574/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1579e-04 - val_loss: 2.8308e-04\n",
      "Epoch 1575/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.1381e-04 - val_loss: 2.9436e-04\n",
      "Epoch 1576/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1730e-04 - val_loss: 2.6445e-04\n",
      "Epoch 1577/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.1969e-04 - val_loss: 2.7327e-04\n",
      "Epoch 1578/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1693e-04 - val_loss: 2.7187e-04\n",
      "Epoch 1579/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1511e-04 - val_loss: 2.7970e-04\n",
      "Epoch 1580/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1301e-04 - val_loss: 2.6449e-04\n",
      "Epoch 1581/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1547e-04 - val_loss: 2.6573e-04\n",
      "Epoch 1582/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1496e-04 - val_loss: 2.9598e-04\n",
      "Epoch 1583/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.2025e-04 - val_loss: 2.6144e-04\n",
      "Epoch 1584/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1233e-04 - val_loss: 2.6440e-04\n",
      "Epoch 1585/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1111e-04 - val_loss: 2.7422e-04\n",
      "Epoch 1586/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1393e-04 - val_loss: 3.0883e-04\n",
      "Epoch 1587/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1692e-04 - val_loss: 2.9571e-04\n",
      "Epoch 1588/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1968e-04 - val_loss: 2.9181e-04\n",
      "Epoch 1589/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.1570e-04 - val_loss: 2.8752e-04\n",
      "Epoch 1590/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0986e-04 - val_loss: 2.7385e-04\n",
      "Epoch 1591/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.1011e-04 - val_loss: 3.0689e-04\n",
      "Epoch 1592/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.1270e-04 - val_loss: 2.7813e-04\n",
      "Epoch 1593/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.0960e-04 - val_loss: 2.7394e-04\n",
      "Epoch 1594/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0655e-04 - val_loss: 2.7398e-04\n",
      "Epoch 1595/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1601e-04 - val_loss: 3.0047e-04\n",
      "Epoch 1596/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1153e-04 - val_loss: 2.9807e-04\n",
      "Epoch 1597/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1238e-04 - val_loss: 2.9231e-04\n",
      "Epoch 1598/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1026e-04 - val_loss: 2.9439e-04\n",
      "Epoch 1599/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.0926e-04 - val_loss: 3.1418e-04\n",
      "Epoch 1600/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0938e-04 - val_loss: 3.0310e-04\n",
      "Epoch 1601/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.0432e-04 - val_loss: 3.0093e-04\n",
      "Epoch 1602/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0714e-04 - val_loss: 3.0282e-04\n",
      "Epoch 1603/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0773e-04 - val_loss: 2.7081e-04\n",
      "Epoch 1604/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1257e-04 - val_loss: 2.8324e-04\n",
      "Epoch 1605/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0726e-04 - val_loss: 3.1168e-04\n",
      "Epoch 1606/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1007e-04 - val_loss: 3.3096e-04\n",
      "Epoch 1607/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0886e-04 - val_loss: 2.9114e-04\n",
      "Epoch 1608/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.0932e-04 - val_loss: 3.0140e-04\n",
      "Epoch 1609/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1241e-04 - val_loss: 2.9530e-04\n",
      "Epoch 1610/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.0984e-04 - val_loss: 3.1587e-04\n",
      "Epoch 1611/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1466e-04 - val_loss: 3.0310e-04\n",
      "Epoch 1612/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0794e-04 - val_loss: 2.8083e-04\n",
      "Epoch 1613/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.0981e-04 - val_loss: 3.1300e-04\n",
      "Epoch 1614/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1168e-04 - val_loss: 3.2580e-04\n",
      "Epoch 1615/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0844e-04 - val_loss: 3.0322e-04\n",
      "Epoch 1616/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.0248e-04 - val_loss: 2.8523e-04\n",
      "Epoch 1617/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0332e-04 - val_loss: 3.0469e-04\n",
      "Epoch 1618/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.0895e-04 - val_loss: 3.3900e-04\n",
      "Epoch 1619/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.2346e-04 - val_loss: 3.2405e-04\n",
      "Epoch 1620/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.3291e-04 - val_loss: 3.3066e-04\n",
      "Epoch 1621/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.4492e-04 - val_loss: 3.8654e-04\n",
      "Epoch 1622/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.3134e-04 - val_loss: 3.3478e-04\n",
      "Epoch 1623/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.2447e-04 - val_loss: 3.3029e-04\n",
      "Epoch 1624/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.2249e-04 - val_loss: 3.0464e-04\n",
      "Epoch 1625/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0802e-04 - val_loss: 2.8439e-04\n",
      "Epoch 1626/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1084e-04 - val_loss: 3.6990e-04\n",
      "Epoch 1627/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.1997e-04 - val_loss: 3.0823e-04\n",
      "Epoch 1628/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.0523e-04 - val_loss: 3.0965e-04\n",
      "Epoch 1629/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0615e-04 - val_loss: 3.1524e-04\n",
      "Epoch 1630/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0140e-04 - val_loss: 2.9905e-04\n",
      "Epoch 1631/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0415e-04 - val_loss: 3.0991e-04\n",
      "Epoch 1632/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0371e-04 - val_loss: 3.1222e-04\n",
      "Epoch 1633/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0063e-04 - val_loss: 3.4392e-04\n",
      "Epoch 1634/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0498e-04 - val_loss: 3.2613e-04\n",
      "Epoch 1635/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1257e-04 - val_loss: 2.9346e-04\n",
      "Epoch 1636/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1185e-04 - val_loss: 3.0616e-04\n",
      "Epoch 1637/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1871e-04 - val_loss: 3.1959e-04\n",
      "Epoch 1638/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1666e-04 - val_loss: 3.1388e-04\n",
      "Epoch 1639/2000\n",
      "4059/4059 [==============================] - 1s 236us/step - loss: 1.1601e-04 - val_loss: 2.9740e-04\n",
      "Epoch 1640/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0780e-04 - val_loss: 2.8395e-04\n",
      "Epoch 1641/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.0473e-04 - val_loss: 3.2799e-04\n",
      "Epoch 1642/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0204e-04 - val_loss: 3.2102e-04\n",
      "Epoch 1643/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.0558e-04 - val_loss: 3.6875e-04\n",
      "Epoch 1644/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1036e-04 - val_loss: 3.6866e-04\n",
      "Epoch 1645/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0846e-04 - val_loss: 3.0854e-04\n",
      "Epoch 1646/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.9730e-05 - val_loss: 3.0888e-04\n",
      "Epoch 1647/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.0408e-04 - val_loss: 3.1257e-04\n",
      "Epoch 1648/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.1368e-04 - val_loss: 3.2755e-04\n",
      "Epoch 1649/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0666e-04 - val_loss: 3.2527e-04\n",
      "Epoch 1650/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0340e-04 - val_loss: 3.3706e-04\n",
      "Epoch 1651/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 1.0197e-04 - val_loss: 3.2853e-04\n",
      "Epoch 1652/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0383e-04 - val_loss: 3.2477e-04\n",
      "Epoch 1653/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1285e-04 - val_loss: 3.0477e-04\n",
      "Epoch 1654/2000\n",
      "4059/4059 [==============================] - 1s 237us/step - loss: 1.1995e-04 - val_loss: 3.2069e-04\n",
      "Epoch 1655/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.1728e-04 - val_loss: 2.9541e-04\n",
      "Epoch 1656/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.0687e-04 - val_loss: 3.4236e-04\n",
      "Epoch 1657/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.0518e-04 - val_loss: 3.2727e-04\n",
      "Epoch 1658/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.0064e-04 - val_loss: 3.4881e-04\n",
      "Epoch 1659/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0031e-04 - val_loss: 2.9985e-04\n",
      "Epoch 1660/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0156e-04 - val_loss: 3.0186e-04\n",
      "Epoch 1661/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0678e-04 - val_loss: 3.0527e-04\n",
      "Epoch 1662/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0779e-04 - val_loss: 3.2615e-04\n",
      "Epoch 1663/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0270e-04 - val_loss: 2.7680e-04\n",
      "Epoch 1664/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0172e-04 - val_loss: 3.1279e-04\n",
      "Epoch 1665/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0323e-04 - val_loss: 3.0937e-04\n",
      "Epoch 1666/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0410e-04 - val_loss: 3.0781e-04\n",
      "Epoch 1667/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.0200e-04 - val_loss: 3.4361e-04\n",
      "Epoch 1668/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0781e-04 - val_loss: 2.9654e-04\n",
      "Epoch 1669/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0464e-04 - val_loss: 3.3794e-04\n",
      "Epoch 1670/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0340e-04 - val_loss: 3.6656e-04\n",
      "Epoch 1671/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0491e-04 - val_loss: 3.3557e-04\n",
      "Epoch 1672/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.0071e-04 - val_loss: 3.1877e-04\n",
      "Epoch 1673/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0107e-04 - val_loss: 3.3523e-04\n",
      "Epoch 1674/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.1016e-04 - val_loss: 3.2337e-04\n",
      "Epoch 1675/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 1.1015e-04 - val_loss: 3.1996e-04\n",
      "Epoch 1676/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 9.8355e-05 - val_loss: 3.4427e-04\n",
      "Epoch 1677/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.0086e-04 - val_loss: 3.6511e-04\n",
      "Epoch 1678/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.0526e-04 - val_loss: 3.2338e-04\n",
      "Epoch 1679/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.0006e-04 - val_loss: 3.1749e-04\n",
      "Epoch 1680/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.7518e-05 - val_loss: 3.1380e-04\n",
      "Epoch 1681/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.0449e-04 - val_loss: 3.0946e-04\n",
      "Epoch 1682/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.0037e-04 - val_loss: 3.5930e-04\n",
      "Epoch 1683/2000\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 1.0172e-04 - val_loss: 3.4684e-04\n",
      "Epoch 1684/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.0495e-04 - val_loss: 3.6092e-04\n",
      "Epoch 1685/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.6845e-05 - val_loss: 3.5515e-04\n",
      "Epoch 1686/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.0463e-04 - val_loss: 4.0667e-04\n",
      "Epoch 1687/2000\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 1.0670e-04 - val_loss: 3.7299e-04\n",
      "Epoch 1688/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 256us/step - loss: 1.0307e-04 - val_loss: 3.3815e-04\n",
      "Epoch 1689/2000\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 1.0388e-04 - val_loss: 3.3835e-04\n",
      "Epoch 1690/2000\n",
      "4059/4059 [==============================] - 1s 265us/step - loss: 1.0121e-04 - val_loss: 3.3353e-04\n",
      "Epoch 1691/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 9.7163e-05 - val_loss: 3.1669e-04\n",
      "Epoch 1692/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.9679e-05 - val_loss: 3.4127e-04\n",
      "Epoch 1693/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 9.6734e-05 - val_loss: 3.3376e-04\n",
      "Epoch 1694/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 9.6543e-05 - val_loss: 3.1219e-04\n",
      "Epoch 1695/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.0738e-04 - val_loss: 3.3916e-04\n",
      "Epoch 1696/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0645e-04 - val_loss: 3.3930e-04\n",
      "Epoch 1697/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0486e-04 - val_loss: 3.5872e-04\n",
      "Epoch 1698/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0110e-04 - val_loss: 3.4008e-04\n",
      "Epoch 1699/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 9.7951e-05 - val_loss: 3.3542e-04\n",
      "Epoch 1700/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.0016e-04 - val_loss: 3.2633e-04\n",
      "Epoch 1701/2000\n",
      "4059/4059 [==============================] - 1s 247us/step - loss: 9.8313e-05 - val_loss: 3.4723e-04\n",
      "Epoch 1702/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 9.7338e-05 - val_loss: 3.6750e-04\n",
      "Epoch 1703/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.0521e-04 - val_loss: 3.6467e-04\n",
      "Epoch 1704/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 1.0047e-04 - val_loss: 3.6455e-04\n",
      "Epoch 1705/2000\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 9.5906e-05 - val_loss: 3.7321e-04\n",
      "Epoch 1706/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 1.0143e-04 - val_loss: 3.4063e-04\n",
      "Epoch 1707/2000\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 9.7223e-05 - val_loss: 3.5434e-04\n",
      "Epoch 1708/2000\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 1.0134e-04 - val_loss: 3.6300e-04\n",
      "Epoch 1709/2000\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 1.0427e-04 - val_loss: 3.4262e-04\n",
      "Epoch 1710/2000\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 9.9726e-05 - val_loss: 3.4456e-04\n",
      "Epoch 1711/2000\n",
      "4059/4059 [==============================] - 1s 257us/step - loss: 9.3929e-05 - val_loss: 3.7311e-04\n",
      "Epoch 1712/2000\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 9.7057e-05 - val_loss: 3.3566e-04\n",
      "Epoch 1713/2000\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 9.7170e-05 - val_loss: 3.7959e-04\n",
      "Epoch 1714/2000\n",
      "4059/4059 [==============================] - 1s 258us/step - loss: 9.7007e-05 - val_loss: 3.9055e-04\n",
      "Epoch 1715/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 9.3998e-05 - val_loss: 3.8780e-04\n",
      "Epoch 1716/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 9.7691e-05 - val_loss: 3.8078e-04\n",
      "Epoch 1717/2000\n",
      "4059/4059 [==============================] - 1s 262us/step - loss: 9.7422e-05 - val_loss: 3.7557e-04\n",
      "Epoch 1718/2000\n",
      "4059/4059 [==============================] - 1s 260us/step - loss: 1.0469e-04 - val_loss: 3.7370e-04\n",
      "Epoch 1719/2000\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 9.8553e-05 - val_loss: 3.4842e-04\n",
      "Epoch 1720/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 1.0118e-04 - val_loss: 3.4125e-04\n",
      "Epoch 1721/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 9.3641e-05 - val_loss: 3.3576e-04\n",
      "Epoch 1722/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 9.4257e-05 - val_loss: 3.8632e-04\n",
      "Epoch 1723/2000\n",
      "4059/4059 [==============================] - 1s 250us/step - loss: 9.5920e-05 - val_loss: 4.1161e-04\n",
      "Epoch 1724/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.1390e-04 - val_loss: 3.8180e-04\n",
      "Epoch 1725/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.9582e-05 - val_loss: 3.9646e-04\n",
      "Epoch 1726/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 9.7472e-05 - val_loss: 4.0664e-04\n",
      "Epoch 1727/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 9.8680e-05 - val_loss: 3.6621e-04\n",
      "Epoch 1728/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.5908e-05 - val_loss: 3.3197e-04\n",
      "Epoch 1729/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 1.0010e-04 - val_loss: 4.0622e-04\n",
      "Epoch 1730/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 9.4782e-05 - val_loss: 3.5267e-04\n",
      "Epoch 1731/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 9.3659e-05 - val_loss: 3.6568e-04\n",
      "Epoch 1732/2000\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 8.9009e-05 - val_loss: 3.5650e-04\n",
      "Epoch 1733/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.7863e-05 - val_loss: 3.7873e-04\n",
      "Epoch 1734/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 9.1616e-05 - val_loss: 3.5593e-04\n",
      "Epoch 1735/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.2744e-05 - val_loss: 4.0360e-04\n",
      "Epoch 1736/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.9113e-05 - val_loss: 3.9576e-04\n",
      "Epoch 1737/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 9.5459e-05 - val_loss: 4.0301e-04\n",
      "Epoch 1738/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 9.5277e-05 - val_loss: 3.6538e-04\n",
      "Epoch 1739/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 9.5873e-05 - val_loss: 3.6328e-04\n",
      "Epoch 1740/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.5366e-05 - val_loss: 3.9323e-04\n",
      "Epoch 1741/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.5838e-05 - val_loss: 4.3068e-04\n",
      "Epoch 1742/2000\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 9.2942e-05 - val_loss: 3.8581e-04\n",
      "Epoch 1743/2000\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 9.2847e-05 - val_loss: 4.0931e-04\n",
      "Epoch 1744/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 9.3391e-05 - val_loss: 3.7976e-04\n",
      "Epoch 1745/2000\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 9.2696e-05 - val_loss: 3.9291e-04\n",
      "Epoch 1746/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 9.2823e-05 - val_loss: 3.5731e-04\n",
      "Epoch 1747/2000\n",
      "4059/4059 [==============================] - 1s 259us/step - loss: 8.8542e-05 - val_loss: 4.1936e-04\n",
      "Epoch 1748/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 9.5251e-05 - val_loss: 3.4300e-04\n",
      "Epoch 1749/2000\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 1.0121e-04 - val_loss: 3.9329e-04\n",
      "Epoch 1750/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 1.0435e-04 - val_loss: 3.5830e-04\n",
      "Epoch 1751/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 1.0283e-04 - val_loss: 4.1602e-04\n",
      "Epoch 1752/2000\n",
      "4059/4059 [==============================] - 1s 255us/step - loss: 9.4897e-05 - val_loss: 3.5660e-04\n",
      "Epoch 1753/2000\n",
      "4059/4059 [==============================] - 1s 254us/step - loss: 9.1320e-05 - val_loss: 3.8324e-04\n",
      "Epoch 1754/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 8.8390e-05 - val_loss: 3.7237e-04\n",
      "Epoch 1755/2000\n",
      "4059/4059 [==============================] - 1s 253us/step - loss: 9.0273e-05 - val_loss: 3.7393e-04\n",
      "Epoch 1756/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 9.0304e-05 - val_loss: 3.9073e-04\n",
      "Epoch 1757/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 9.0946e-05 - val_loss: 3.8347e-04\n",
      "Epoch 1758/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 251us/step - loss: 8.8874e-05 - val_loss: 3.8781e-04\n",
      "Epoch 1759/2000\n",
      "4059/4059 [==============================] - 1s 251us/step - loss: 9.1291e-05 - val_loss: 3.8581e-04\n",
      "Epoch 1760/2000\n",
      "4059/4059 [==============================] - 1s 252us/step - loss: 9.0099e-05 - val_loss: 4.5166e-04\n",
      "Epoch 1761/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 9.3367e-05 - val_loss: 4.2235e-04\n",
      "Epoch 1762/2000\n",
      "4059/4059 [==============================] - 1s 248us/step - loss: 9.1051e-05 - val_loss: 3.2084e-04\n",
      "Epoch 1763/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.6948e-05 - val_loss: 3.8202e-04\n",
      "Epoch 1764/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.9587e-05 - val_loss: 3.8073e-04\n",
      "Epoch 1765/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0213e-04 - val_loss: 3.6954e-04\n",
      "Epoch 1766/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.6157e-05 - val_loss: 3.9738e-04\n",
      "Epoch 1767/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.4159e-05 - val_loss: 3.7244e-04\n",
      "Epoch 1768/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.1032e-05 - val_loss: 4.1894e-04\n",
      "Epoch 1769/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.1274e-05 - val_loss: 4.2398e-04\n",
      "Epoch 1770/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.7575e-05 - val_loss: 3.9987e-04\n",
      "Epoch 1771/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.3384e-05 - val_loss: 4.0340e-04\n",
      "Epoch 1772/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.4782e-05 - val_loss: 3.7768e-04\n",
      "Epoch 1773/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.1700e-05 - val_loss: 4.0864e-04\n",
      "Epoch 1774/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.0069e-04 - val_loss: 3.8598e-04\n",
      "Epoch 1775/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0902e-04 - val_loss: 3.5492e-04\n",
      "Epoch 1776/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.0074e-04 - val_loss: 3.9224e-04\n",
      "Epoch 1777/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.1081e-05 - val_loss: 4.0997e-04\n",
      "Epoch 1778/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.8237e-05 - val_loss: 3.7120e-04\n",
      "Epoch 1779/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.9030e-05 - val_loss: 3.9017e-04\n",
      "Epoch 1780/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.2193e-05 - val_loss: 3.9569e-04\n",
      "Epoch 1781/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.2086e-05 - val_loss: 4.3418e-04\n",
      "Epoch 1782/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.0122e-05 - val_loss: 4.2649e-04\n",
      "Epoch 1783/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.8155e-05 - val_loss: 4.1522e-04\n",
      "Epoch 1784/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.9760e-05 - val_loss: 4.1789e-04\n",
      "Epoch 1785/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 8.6214e-05 - val_loss: 4.0141e-04\n",
      "Epoch 1786/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 8.2270e-05 - val_loss: 4.2289e-04\n",
      "Epoch 1787/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.7731e-05 - val_loss: 4.3944e-04\n",
      "Epoch 1788/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.1093e-05 - val_loss: 4.4377e-04\n",
      "Epoch 1789/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 8.7338e-05 - val_loss: 4.1001e-04\n",
      "Epoch 1790/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.8840e-05 - val_loss: 4.0239e-04\n",
      "Epoch 1791/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.6879e-05 - val_loss: 4.0217e-04\n",
      "Epoch 1792/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.2626e-05 - val_loss: 4.1734e-04\n",
      "Epoch 1793/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.4363e-05 - val_loss: 4.4558e-04\n",
      "Epoch 1794/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.0658e-05 - val_loss: 4.1932e-04\n",
      "Epoch 1795/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.8769e-05 - val_loss: 4.1429e-04\n",
      "Epoch 1796/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.2741e-05 - val_loss: 4.4462e-04\n",
      "Epoch 1797/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.9443e-05 - val_loss: 4.3401e-04\n",
      "Epoch 1798/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 8.9673e-05 - val_loss: 4.5212e-04\n",
      "Epoch 1799/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.1669e-05 - val_loss: 4.2362e-04\n",
      "Epoch 1800/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.3841e-05 - val_loss: 3.6680e-04\n",
      "Epoch 1801/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 9.1018e-05 - val_loss: 4.2008e-04\n",
      "Epoch 1802/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 8.9409e-05 - val_loss: 3.7850e-04\n",
      "Epoch 1803/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.1261e-05 - val_loss: 4.2322e-04\n",
      "Epoch 1804/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.8283e-05 - val_loss: 4.3508e-04\n",
      "Epoch 1805/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.6207e-05 - val_loss: 4.1938e-04\n",
      "Epoch 1806/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.0521e-05 - val_loss: 4.6975e-04\n",
      "Epoch 1807/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.3451e-05 - val_loss: 4.4455e-04\n",
      "Epoch 1808/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 9.4071e-05 - val_loss: 4.0055e-04\n",
      "Epoch 1809/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.4146e-05 - val_loss: 4.0108e-04\n",
      "Epoch 1810/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 9.6401e-05 - val_loss: 3.8693e-04\n",
      "Epoch 1811/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.7829e-05 - val_loss: 3.9972e-04\n",
      "Epoch 1812/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.0545e-04 - val_loss: 4.0603e-04\n",
      "Epoch 1813/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.1826e-05 - val_loss: 4.3780e-04\n",
      "Epoch 1814/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.8371e-05 - val_loss: 4.0824e-04\n",
      "Epoch 1815/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.0076e-05 - val_loss: 4.6646e-04\n",
      "Epoch 1816/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.6205e-05 - val_loss: 4.4051e-04\n",
      "Epoch 1817/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.6585e-05 - val_loss: 4.7401e-04\n",
      "Epoch 1818/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 9.2058e-05 - val_loss: 4.4117e-04\n",
      "Epoch 1819/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.6208e-05 - val_loss: 4.3889e-04\n",
      "Epoch 1820/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 8.3583e-05 - val_loss: 4.4114e-04\n",
      "Epoch 1821/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.5418e-05 - val_loss: 4.8198e-04\n",
      "Epoch 1822/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.1680e-05 - val_loss: 4.5180e-04\n",
      "Epoch 1823/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.6818e-05 - val_loss: 4.7901e-04\n",
      "Epoch 1824/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.3372e-05 - val_loss: 4.4500e-04\n",
      "Epoch 1825/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 9.0588e-05 - val_loss: 4.0348e-04\n",
      "Epoch 1826/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.8420e-05 - val_loss: 4.1662e-04\n",
      "Epoch 1827/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.2580e-05 - val_loss: 4.4247e-04\n",
      "Epoch 1828/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.4688e-05 - val_loss: 4.9372e-04\n",
      "Epoch 1829/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 8.2573e-05 - val_loss: 3.8886e-04\n",
      "Epoch 1830/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.2514e-05 - val_loss: 4.6716e-04\n",
      "Epoch 1831/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 8.9318e-05 - val_loss: 4.5065e-04\n",
      "Epoch 1832/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.6542e-05 - val_loss: 4.5218e-04\n",
      "Epoch 1833/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.1151e-05 - val_loss: 4.4019e-04\n",
      "Epoch 1834/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 8.2017e-05 - val_loss: 4.0954e-04\n",
      "Epoch 1835/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.3526e-05 - val_loss: 4.7892e-04\n",
      "Epoch 1836/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.9458e-05 - val_loss: 4.8102e-04\n",
      "Epoch 1837/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.2937e-05 - val_loss: 4.3910e-04\n",
      "Epoch 1838/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 9.0076e-05 - val_loss: 4.8213e-04\n",
      "Epoch 1839/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 8.3914e-05 - val_loss: 4.2884e-04\n",
      "Epoch 1840/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.3137e-05 - val_loss: 4.6268e-04\n",
      "Epoch 1841/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.3825e-05 - val_loss: 4.7598e-04\n",
      "Epoch 1842/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.9141e-05 - val_loss: 4.5794e-04\n",
      "Epoch 1843/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.4620e-05 - val_loss: 4.9316e-04\n",
      "Epoch 1844/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 8.7606e-05 - val_loss: 4.5828e-04\n",
      "Epoch 1845/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.5557e-05 - val_loss: 4.6157e-04\n",
      "Epoch 1846/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.6173e-05 - val_loss: 4.4755e-04\n",
      "Epoch 1847/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.1655e-05 - val_loss: 4.3883e-04\n",
      "Epoch 1848/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.2406e-05 - val_loss: 4.4984e-04\n",
      "Epoch 1849/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.9744e-05 - val_loss: 4.2688e-04\n",
      "Epoch 1850/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 8.4900e-05 - val_loss: 4.6514e-04\n",
      "Epoch 1851/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.7724e-05 - val_loss: 4.1747e-04\n",
      "Epoch 1852/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.3579e-05 - val_loss: 4.8043e-04\n",
      "Epoch 1853/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.1432e-05 - val_loss: 4.6251e-04\n",
      "Epoch 1854/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.6889e-05 - val_loss: 5.0598e-04\n",
      "Epoch 1855/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 8.2483e-05 - val_loss: 4.5777e-04\n",
      "Epoch 1856/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.6610e-05 - val_loss: 4.6067e-04\n",
      "Epoch 1857/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.2245e-05 - val_loss: 4.6718e-04\n",
      "Epoch 1858/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.3142e-05 - val_loss: 4.2579e-04\n",
      "Epoch 1859/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.1694e-05 - val_loss: 4.8069e-04\n",
      "Epoch 1860/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.4374e-05 - val_loss: 4.6375e-04\n",
      "Epoch 1861/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.4004e-05 - val_loss: 4.4072e-04\n",
      "Epoch 1862/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.3343e-05 - val_loss: 4.9707e-04\n",
      "Epoch 1863/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.2463e-05 - val_loss: 4.9628e-04\n",
      "Epoch 1864/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 1.0002e-04 - val_loss: 4.4037e-04\n",
      "Epoch 1865/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.6364e-05 - val_loss: 4.3033e-04\n",
      "Epoch 1866/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.3799e-05 - val_loss: 4.0471e-04\n",
      "Epoch 1867/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.0751e-05 - val_loss: 4.6435e-04\n",
      "Epoch 1868/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.2381e-05 - val_loss: 4.4274e-04\n",
      "Epoch 1869/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 8.6253e-05 - val_loss: 4.7799e-04\n",
      "Epoch 1870/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.4058e-05 - val_loss: 4.5587e-04\n",
      "Epoch 1871/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.9730e-05 - val_loss: 4.3115e-04\n",
      "Epoch 1872/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.0494e-05 - val_loss: 4.4388e-04\n",
      "Epoch 1873/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.0782e-05 - val_loss: 4.6619e-04\n",
      "Epoch 1874/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.5875e-05 - val_loss: 4.5027e-04\n",
      "Epoch 1875/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.4600e-05 - val_loss: 5.0022e-04\n",
      "Epoch 1876/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 7.6745e-05 - val_loss: 4.6070e-04\n",
      "Epoch 1877/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.0978e-05 - val_loss: 5.0355e-04\n",
      "Epoch 1878/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.4373e-05 - val_loss: 4.6901e-04\n",
      "Epoch 1879/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.8737e-05 - val_loss: 4.8743e-04\n",
      "Epoch 1880/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.5052e-05 - val_loss: 5.0322e-04\n",
      "Epoch 1881/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.1101e-05 - val_loss: 4.6405e-04\n",
      "Epoch 1882/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.9812e-05 - val_loss: 4.5786e-04\n",
      "Epoch 1883/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 7.7880e-05 - val_loss: 4.6965e-04\n",
      "Epoch 1884/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.5889e-05 - val_loss: 5.2511e-04\n",
      "Epoch 1885/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.6796e-05 - val_loss: 4.9477e-04\n",
      "Epoch 1886/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.6681e-05 - val_loss: 4.9329e-04\n",
      "Epoch 1887/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.9849e-05 - val_loss: 4.6987e-04\n",
      "Epoch 1888/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.4413e-05 - val_loss: 4.9903e-04\n",
      "Epoch 1889/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 9.3267e-05 - val_loss: 4.7869e-04\n",
      "Epoch 1890/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.5912e-05 - val_loss: 4.8185e-04\n",
      "Epoch 1891/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.4833e-05 - val_loss: 4.5399e-04\n",
      "Epoch 1892/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 7.7853e-05 - val_loss: 4.7506e-04\n",
      "Epoch 1893/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.4869e-05 - val_loss: 4.9046e-04\n",
      "Epoch 1894/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.8181e-05 - val_loss: 4.5490e-04\n",
      "Epoch 1895/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.5660e-05 - val_loss: 4.6432e-04\n",
      "Epoch 1896/2000\n",
      "4059/4059 [==============================] - 1s 249us/step - loss: 7.6776e-05 - val_loss: 4.8242e-04\n",
      "Epoch 1897/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.6603e-05 - val_loss: 5.4256e-04\n",
      "Epoch 1898/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.7584e-05 - val_loss: 4.8864e-04\n",
      "Epoch 1899/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 7.6716e-05 - val_loss: 4.8136e-04\n",
      "Epoch 1900/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 7.4098e-05 - val_loss: 4.7553e-04\n",
      "Epoch 1901/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.5170e-05 - val_loss: 4.8089e-04\n",
      "Epoch 1902/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 7.6884e-05 - val_loss: 4.9729e-04\n",
      "Epoch 1903/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.7500e-05 - val_loss: 5.2986e-04\n",
      "Epoch 1904/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.8833e-05 - val_loss: 5.1360e-04\n",
      "Epoch 1905/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 8.2078e-05 - val_loss: 5.6158e-04\n",
      "Epoch 1906/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0973e-04 - val_loss: 5.4556e-04\n",
      "Epoch 1907/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.0193e-04 - val_loss: 5.0150e-04\n",
      "Epoch 1908/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.2256e-05 - val_loss: 4.9269e-04\n",
      "Epoch 1909/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 9.5693e-05 - val_loss: 6.3651e-04\n",
      "Epoch 1910/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 1.2548e-04 - val_loss: 4.6373e-04\n",
      "Epoch 1911/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 1.0521e-04 - val_loss: 4.0915e-04\n",
      "Epoch 1912/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.8991e-05 - val_loss: 4.1803e-04\n",
      "Epoch 1913/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 8.3801e-05 - val_loss: 4.6591e-04\n",
      "Epoch 1914/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.6576e-05 - val_loss: 4.8859e-04\n",
      "Epoch 1915/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 8.0159e-05 - val_loss: 4.7029e-04\n",
      "Epoch 1916/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.2456e-05 - val_loss: 5.2511e-04\n",
      "Epoch 1917/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 7.3630e-05 - val_loss: 5.1697e-04\n",
      "Epoch 1918/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.8696e-05 - val_loss: 5.1881e-04\n",
      "Epoch 1919/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.6106e-05 - val_loss: 5.1604e-04\n",
      "Epoch 1920/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 7.4900e-05 - val_loss: 5.0512e-04\n",
      "Epoch 1921/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 7.3066e-05 - val_loss: 5.1200e-04\n",
      "Epoch 1922/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 7.2908e-05 - val_loss: 4.8653e-04\n",
      "Epoch 1923/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.1636e-05 - val_loss: 5.2835e-04\n",
      "Epoch 1924/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.0668e-05 - val_loss: 4.9610e-04\n",
      "Epoch 1925/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.3144e-05 - val_loss: 5.4362e-04\n",
      "Epoch 1926/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.2061e-05 - val_loss: 4.7538e-04\n",
      "Epoch 1927/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.1254e-05 - val_loss: 5.0815e-04\n",
      "Epoch 1928/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.2860e-05 - val_loss: 5.1972e-04\n",
      "Epoch 1929/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 7.3870e-05 - val_loss: 5.3811e-04\n",
      "Epoch 1930/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 7.8214e-05 - val_loss: 5.1000e-04\n",
      "Epoch 1931/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 1.0352e-04 - val_loss: 4.8347e-04\n",
      "Epoch 1932/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 9.4401e-05 - val_loss: 5.0944e-04\n",
      "Epoch 1933/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 8.5510e-05 - val_loss: 5.2530e-04\n",
      "Epoch 1934/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.3082e-05 - val_loss: 5.1515e-04\n",
      "Epoch 1935/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.9355e-05 - val_loss: 5.3155e-04\n",
      "Epoch 1936/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 7.9284e-05 - val_loss: 5.2473e-04\n",
      "Epoch 1937/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 7.2098e-05 - val_loss: 5.1051e-04\n",
      "Epoch 1938/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.0823e-05 - val_loss: 5.1975e-04\n",
      "Epoch 1939/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 7.3550e-05 - val_loss: 5.8334e-04\n",
      "Epoch 1940/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.3273e-05 - val_loss: 5.0078e-04\n",
      "Epoch 1941/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.0463e-05 - val_loss: 5.4147e-04\n",
      "Epoch 1942/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.2234e-05 - val_loss: 5.1383e-04\n",
      "Epoch 1943/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.2193e-05 - val_loss: 5.4948e-04\n",
      "Epoch 1944/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 7.3675e-05 - val_loss: 5.7085e-04\n",
      "Epoch 1945/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.5673e-05 - val_loss: 5.7577e-04\n",
      "Epoch 1946/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 6.9448e-05 - val_loss: 5.6362e-04\n",
      "Epoch 1947/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.6707e-05 - val_loss: 5.2239e-04\n",
      "Epoch 1948/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 8.5267e-05 - val_loss: 5.9243e-04\n",
      "Epoch 1949/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 8.6030e-05 - val_loss: 5.3926e-04\n",
      "Epoch 1950/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 7.6570e-05 - val_loss: 5.2931e-04\n",
      "Epoch 1951/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 7.3568e-05 - val_loss: 5.2243e-04\n",
      "Epoch 1952/2000\n",
      "4059/4059 [==============================] - 1s 246us/step - loss: 7.2618e-05 - val_loss: 5.0927e-04\n",
      "Epoch 1953/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 7.8337e-05 - val_loss: 5.3801e-04\n",
      "Epoch 1954/2000\n",
      "4059/4059 [==============================] - ETA: 0s - loss: 8.0556e-0 - 1s 247us/step - loss: 7.9809e-05 - val_loss: 5.3067e-04\n",
      "Epoch 1955/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 7.4861e-05 - val_loss: 5.0485e-04\n",
      "Epoch 1956/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 7.3167e-05 - val_loss: 5.4155e-04\n",
      "Epoch 1957/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 7.1364e-05 - val_loss: 5.4136e-04\n",
      "Epoch 1958/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 6.8207e-05 - val_loss: 5.2444e-04\n",
      "Epoch 1959/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 6.7370e-05 - val_loss: 5.3435e-04\n",
      "Epoch 1960/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 6.7319e-05 - val_loss: 5.4773e-04\n",
      "Epoch 1961/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 6.7279e-05 - val_loss: 5.3604e-04\n",
      "Epoch 1962/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 6.9516e-05 - val_loss: 5.8087e-04\n",
      "Epoch 1963/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.6397e-05 - val_loss: 5.5596e-04\n",
      "Epoch 1964/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 7.7461e-05 - val_loss: 4.8923e-04\n",
      "Epoch 1965/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.8193e-05 - val_loss: 5.1495e-04\n",
      "Epoch 1966/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 8.3670e-05 - val_loss: 5.3203e-04\n",
      "Epoch 1967/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.7511e-05 - val_loss: 5.3716e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1968/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.3986e-05 - val_loss: 5.2164e-04\n",
      "Epoch 1969/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.9851e-05 - val_loss: 5.2296e-04\n",
      "Epoch 1970/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.7500e-05 - val_loss: 5.4477e-04\n",
      "Epoch 1971/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 7.5487e-05 - val_loss: 5.3290e-04\n",
      "Epoch 1972/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.8408e-05 - val_loss: 5.4486e-04\n",
      "Epoch 1973/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.7014e-05 - val_loss: 5.4862e-04\n",
      "Epoch 1974/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 7.4764e-05 - val_loss: 5.2629e-04\n",
      "Epoch 1975/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 7.3310e-05 - val_loss: 5.3378e-04\n",
      "Epoch 1976/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.6349e-05 - val_loss: 5.4903e-04\n",
      "Epoch 1977/2000\n",
      "4059/4059 [==============================] - 1s 239us/step - loss: 7.0006e-05 - val_loss: 5.6112e-04\n",
      "Epoch 1978/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 6.8925e-05 - val_loss: 5.5355e-04\n",
      "Epoch 1979/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 6.5678e-05 - val_loss: 5.4614e-04\n",
      "Epoch 1980/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 7.3099e-05 - val_loss: 5.4834e-04\n",
      "Epoch 1981/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 8.1228e-05 - val_loss: 5.9776e-04\n",
      "Epoch 1982/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 7.8953e-05 - val_loss: 5.7123e-04\n",
      "Epoch 1983/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 8.5734e-05 - val_loss: 5.9170e-04\n",
      "Epoch 1984/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.6311e-05 - val_loss: 5.2400e-04\n",
      "Epoch 1985/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 7.1573e-05 - val_loss: 5.2060e-04\n",
      "Epoch 1986/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 6.9803e-05 - val_loss: 5.5116e-04\n",
      "Epoch 1987/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.4592e-05 - val_loss: 5.5119e-04\n",
      "Epoch 1988/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.0470e-05 - val_loss: 5.7204e-04\n",
      "Epoch 1989/2000\n",
      "4059/4059 [==============================] - 1s 240us/step - loss: 7.0662e-05 - val_loss: 5.9780e-04\n",
      "Epoch 1990/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.1176e-05 - val_loss: 5.4708e-04\n",
      "Epoch 1991/2000\n",
      "4059/4059 [==============================] - 1s 244us/step - loss: 7.0932e-05 - val_loss: 5.5640e-04\n",
      "Epoch 1992/2000\n",
      "4059/4059 [==============================] - 1s 238us/step - loss: 6.9990e-05 - val_loss: 5.9398e-04\n",
      "Epoch 1993/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.0888e-05 - val_loss: 5.6856e-04\n",
      "Epoch 1994/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 6.6322e-05 - val_loss: 5.8225e-04\n",
      "Epoch 1995/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 6.5020e-05 - val_loss: 5.6896e-04\n",
      "Epoch 1996/2000\n",
      "4059/4059 [==============================] - 1s 242us/step - loss: 6.6917e-05 - val_loss: 5.5820e-04\n",
      "Epoch 1997/2000\n",
      "4059/4059 [==============================] - 1s 245us/step - loss: 6.4712e-05 - val_loss: 5.5720e-04\n",
      "Epoch 1998/2000\n",
      "4059/4059 [==============================] - 1s 243us/step - loss: 7.2341e-05 - val_loss: 5.6354e-04\n",
      "Epoch 1999/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.0579e-05 - val_loss: 5.6994e-04\n",
      "Epoch 2000/2000\n",
      "4059/4059 [==============================] - 1s 241us/step - loss: 7.1688e-05 - val_loss: 6.1425e-04\n"
     ]
    }
   ],
   "source": [
    "final_model = build_lstm(**params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'density': 222,\n",
       " 'shuffle': True,\n",
       " 'activation': 'relu',\n",
       " 'twice': False,\n",
       " 'lstmsize': 138,\n",
       " 'optimizer': 'adam',\n",
       " 'callbacks': [<keras.callbacks.callbacks.ModelCheckpoint at 0x293ad0b2b48>]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_182\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_296 (LSTM)              (None, 138)               79488     \n",
      "_________________________________________________________________\n",
      "dense_669 (Dense)            (None, 222)               30858     \n",
      "_________________________________________________________________\n",
      "dense_670 (Dense)            (None, 1)                 223       \n",
      "=================================================================\n",
      "Total params: 110,569\n",
      "Trainable params: 110,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "final_model[0].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model[0].load_weights('./checkpoints/IBM_2days/IBM.(best).hdf5')\n",
    "y_predicted = final_model[0].predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_y_test = y_normaliser.inverse_transform(y_predicted)\n",
    "true_y_test = y_normaliser.inverse_transform(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 9.24\n",
      "Medium error is 2.11\n"
     ]
    }
   ],
   "source": [
    "loss = np.mean((true_y_test - predicted_y_test)**2)\n",
    "medium_error = np.mean(abs(true_y_test - predicted_y_test))\n",
    "print(f'MSE is {loss:.2f}\\nMedium error is {medium_error:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "up_down_test = []\n",
    "up_down_predicted = []\n",
    "\n",
    "for y,x in zip(Y_test,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_test.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_test.append(-1)\n",
    "    else: up_down_test.append(0)\n",
    "        \n",
    "for y,x in zip(y_predicted,X_test):\n",
    "    if y[0] > x[-1][0]: up_down_predicted.append(1)\n",
    "    elif y[0] < x[-1][0]: up_down_predicted.append(-1)\n",
    "    else: up_down_predicted.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trend accuracy is: 66.96%\n"
     ]
    }
   ],
   "source": [
    "print(f'Trend accuracy is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == p)/len(up_down_test))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for upward trend is: 60.80%\n",
      "Accuracy for downward trend is: 73.75%\n"
     ]
    }
   ],
   "source": [
    "print(f'Accuracy for upward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == 1 and p == 1)/sum(1 for v in up_down_test if v == 1))*100:.2f}%')\n",
    "print(f'Accuracy for downward trend is: {(sum(1 for r,p in zip(up_down_test,up_down_predicted) if r == -1 and p == -1)/sum(1 for v in up_down_test if v == -1))*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions over the last 92 days in test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.pyplot import figure\n",
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(92), true_y_test[-92:])\n",
    "plt.plot(range(92), predicted_y_test[-92:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Last 8 days + prediction of last 4 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 3200x2400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure(num=None, figsize=(40, 30), dpi=80, facecolor='w', edgecolor='k')\n",
    "\n",
    "plt.plot(range(8), true_y_test[-8:])\n",
    "plt.plot(range(8), np.append(true_y_test[-8:-4], predicted_y_test[-4:]))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
